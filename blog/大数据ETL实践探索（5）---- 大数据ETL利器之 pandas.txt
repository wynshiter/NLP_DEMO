






文章大纲官方文档及权威参考文档其他权威参考文件加载csv文件加载xlsx、xls文件加载添加数据列apply 函数作用生成新列报错索引的那些坑DataFrame创建遍历增按照列增加按照行增加删改查聚合操作保存数据清洗1. 删除多列数据2. 转换 Dtypes3. 将分类变量转换为数值变量4. 检查缺失的数据5. 删除列中的字符串6. 删除列中的空格7. 将两列字符串数据（在一定条件下）拼接起来8. 转换时间戳（从字符串类型转换为日期「DateTime」格式）探索性数据分析百分比计算数据可视化中文显示参考教程杂项pandas 将某一列移动到最前面jupyter notebook 技巧pandas 在jupyter 中显示所有行和列 及内容多行显示代码自动补全参考

官方文档及权威参考
文档
官网：http://pandas.pydata.org/pandas-docs/stable/
中文文档
官网快速入门
其他权威参考
最近看到的python 杰出的自学资料这个项目里面的例子基本都是开源领域的大咖写的，让你用不到500行的Python代码实现一个非常牛逼实用的功能。
比如说做一个Python解释器，在比如说做一个光学文字识别系统。听起来就非常高大上。然后500行以内就能搞定，但是这个项目肯定需要大家有了一定水平之后才能去研究了。
链接：
http://aosabook.org/en/index.html

文件加载
csv文件加载
read_csv
path = r'./data/ren_pd.csv'

df_pifu = pd.read_csv(path,low_memory=False,dtype={'MBR_NO':np.str})

##文件不规则，行尾有分隔符，则可以设定index_col=False 来是的pandas不适用第一列作为行索引。

head_name = ["体检ID","体检编号"]

tijian_pdf = pd.read_csv(path_tijian,encoding='utf-8',engine='python',dtype='object', skiprows =1,header=None,names=head_name)


官网参数解析：pandas.read_csv
xlsx、xls文件加载
pandas 使用第三方库对xlsx、xls 进行解析，可以使用的库有xlrd 或者openpyxl

所有 python 操作work with Excel files 的开源库
openpyxl 文档：https://openpyxl.readthedocs.io/en/stable/
xlrd 文档：https://xlrd.readthedocs.io/en/latest/

read_excel()方法使用Python的xlrd模块来读取Excel 2003（.xls)版的文件，而Excel 2007+ （.xlsx)版本的是用xlrd或者openpyxl模块来读取的。to_excel()方法则是用来把DataFrame数据存储为Excel格式。一般来说，它的语法同使用csv数据是类似的，更多高级的用法可以参考cookbook
测试数据 = '测试数据20200410.xlsx'
测试数据_pdf = pd.read_excel(测试数据,dtype=object)

官网文档 pandas.read_excel

添加数据列
apply 函数 文档
apply 函数作用生成新列报错
报错代码：
  mapped = lib.map_infer(values, f, convert=convert_dtype)

stackoverflow: 这个可能是空值引起的报错
那么显而易见的，从字典中获取数据，要判断异常，当然try/except代码是必须的，不过这里有一种简单方法，尝试在字典中找key，如果没有找到对应的value将用第二个参数设为其变量值。
data = { user : 1,  name :  Max ,  three : 4}
try:
   is_admin = data[ admin ]
except KeyError:
   is_admin = False

#替换成这样

data = { user : 1,  name :  Max ,  three : 4}
is_admin = data.get( admin , False)


索引的那些坑
# pandas groupby 之后都需要进行索引的重新设置
df_pifu["CNT"] = df_pifu["CODE_DESC"].apply(lambda x : 1)
df_pifu_疾病 = df_pifu.groupby(["CODE_DESC"])["CNT"].count().reset_index()
df_pifu_疾病 = df_pifu_疾病.sort_values(by=['CNT'],ascending = False).head(10)


DataFrame
文档：pandas DataFrame
参数inplace默认为False,只能在生成的新数据块中实现编辑效果。当inplace=True时执行内部编辑，不返回任何值，原数据发生改变。
还有一个操作需要大家注意就是，DataFrame 操作尽量按照列为单位进行操作，这样速度较快。
创建
# 创建一个空的 DataFrame
df_empty = pd.DataFrame(columns=['A', 'B', 'C', 'D'])

遍历

iterrows():  按行遍历，将DataFrame的每一行迭代为(index, Series)对，可以通过row[name]对元素进行访问。
itertuples():  按行遍历，将DataFrame的每一行迭代为元祖，可以通过row[name]对元素进行访问，比iterrows()效率高。
iteritems(): 按列遍历，将DataFrame的每一列迭代为(列名, Series)对，可以通过row[index]对元素进行访问。

#遍历每一行
for row in df.itertuples():
    ID = getattr(row, 'ID')

增
按照列增加
按照行增加
删
改
查
找到特定值的 行索引
df[df['row_name'] == value].index.tolist()

聚合操作
Groupby两列并获得计数

new_df = old_pdf.groupby([old_df['名称'],old_df['编码']])['号码'].count().reset_index()
new_df = new_df.sort_values(by=['号码'],ascending = False)
new_df.rename(columns={"号码":"累计次数"},inplace = True)

new_df.to_excel('编码及次数.xls')



保存
保存为xls 表格：
new_file ="xxx.xls"
result_pdf.to_excel(new_file,'Sheet1', index=False)


数据清洗
在下面的代码片段中，数据清洗代码被封装在了一些函数中，代码的目的十分直观。你可以直接使用这些代码，无需将它们嵌入到需要进行少量参数修改的函数中。
1. 删除多列数据
def drop_multiple_col(col_names_list, df): 
    '''
    AIM    -> Drop multiple columns based on their column names 

    INPUT  -> List of column names, df

    OUTPUT -> updated df with dropped columns 
    ------
    '''
    df.drop(col_names_list, axis=1, inplace=True)
    return df

有时，并不是所有列的数据都对我们的数据分析工作有用。因此，「df.drop」可以方便地删掉你选定的列。
2. 转换 Dtypes

def change_dtypes(col_int, col_float, df): 
    '''
    AIM    -> Changing dtypes to save memory

    INPUT  -> List of column names (int, float), df

    OUTPUT -> updated df with smaller memory  
    ------
    '''
    df[col_int] = df[col_int].astype('int32')
    df[col_float] = df[col_float].astype('float32')


当我们面对更大的数据集时，我们需要对「dtypes」进行转换，从而节省内存。如果你有兴趣学习如何使用「Pandas」来处理大数据，我强烈推荐你阅读「Why and How to Use Pandas with Large Data」这篇文章（https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c）。
3. 将分类变量转换为数值变量
def convert_cat2num(df):
    # Convert categorical variable to numerical variable
    num_encode = {'col_1' : {'YES':1, 'NO':0},
                  'col_2'  : {'WON':1, 'LOSE':0, 'DRAW':0}}  
    df.replace(num_encode, inplace=True)  

有一些机器学习模型要求变量是以数值形式存在的。这时，我们就需要将分类变量转换成数值变量然后再将它们作为模型的输入。对于数据可视化任务来说，我建议大家保留分类变量，从而让可视化结果有更明确的解释，便于理解。
4. 检查缺失的数据
def check_missing_data(df):
    # check for any missing data in the df (display in descending order)
    return df.isnull().sum().sort_values(ascending=False)

如果你想要检查每一列中有多少缺失的数据，这可能是最快的方法。这种方法可以让你更清楚地知道哪些列有更多的缺失数据，帮助你决定接下来在数据清洗和数据分析工作中应该采取怎样的行动。
5. 删除列中的字符串
def remove_col_str(df):
    # remove a portion of string in a dataframe column - col_1
    df['col_1'].replace('\n', '', regex=True, inplace=True)

    # remove all the characters after &# (including &#) for column - col_1
    df['col_1'].replace(' &#.*', '', regex=True, inplace=True)

有时你可能会看到一行新的字符，或在字符串列中看到一些奇怪的符号。你可以很容易地使用 df[‘col_1’].replace 来处理该问题，其中「col_1」是数据帧 df 中的一列。
6. 删除列中的空格
def remove_col_white_space(df):
    # remove white space at the beginning of string 
    df[col] = df[col].str.lstrip()

当数据十分混乱时，很多意想不到的情况都会发生。在字符串的开头有一些空格是很常见的。因此，当你想要删除列中字符串开头的空格时，这种方法很实用。
7. 将两列字符串数据（在一定条件下）拼接起来
def concat_col_str_condition(df):
    # concat 2 columns with strings if the last 3 letters of the first column are 'pil'
    mask = df['col_1'].str.endswith('pil', na=False)
    col_new = df[mask]['col_1'] + df[mask]['col_2']
    col_new.replace('pil', ' ', regex=True, inplace=True)  # replace the 'pil' with emtpy space

当你希望在一定条件下将两列字符串数据组合在一起时，这种方法很有用。例如，你希望当第一列以某些特定的字母结尾时，将第一列和第二列数据拼接在一起。根据你的需要，还可以在拼接工作完成后将结尾的字母删除掉。
8. 转换时间戳（从字符串类型转换为日期「DateTime」格式）
def convert_str_datetime(df): 
    '''
    AIM    -> Convert datetime(String) to datetime(format we want)

    INPUT  -> df

    OUTPUT -> updated df with new datetime format 
    ------
    '''
    df.insert(loc=2, column='timestamp', value=pd.to_datetime(df.transdate, format='%Y-%m-%d %H:%M:%S.%f'))

在处理时间序列数据时，你可能会遇到字符串格式的时间戳列。这意味着我们可能不得不将字符串格式的数据转换为根据我们的需求指定的日期「datetime」格式，以便使用这些数据进行有意义的分析和展示

探索性数据分析
https://www.jianshu.com/p/8982ad63eb85

https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651667552&idx=1&sn=14e11d8ba698d92696cf4a125807564e&chksm=bd4c1bf38a3b92e507cc4464f6a8f90d92132f2af5a72f86939c826362ebfd4803fa39b4d66c&mpshare=1&scene=1&srcid=0209WG9hxbGM0awtUZcvl0dj#rd
百分比计算
比如直接由 spark dataframe 统计的结果转化成pandas 的dataframe 两列相除就好

#理赔金额最高大类
temp_top_df = tichu_df.select(tichu_df.MBR_NO,tichu_df.CODE,tichu_df.AMT
                        ).groupBy(tichu_df.CODE
                                 ).agg(F.sum(tichu_df.AMT
                                              ).alias('最多金额'))


temp_top_pdf = temp_top_df .orderBy(F.desc("最多金额")).toPandas()

temp_top_pdf ['百分比'] = temp_top_pdf ['最多金额大类']/temp_lipebigjibingjinetop_pdf['最多金额大类'].sum()



数据可视化
中文显示
pandas 处理完成数据后，大家经常使用的可视化库有matplotlib ，seaborn，pyecharts 等
前两个中文字体显示成问题，最后一个因为是国产库中文支持比较好但是在jupyter notebook中生成的结果是网页，图片不知道怎么显示出来。 以下参考链接为 我博客另一个系列中针对matplotlib ，seaborn中文显示问题的探讨：
以 matplotlib 为基础的库的可视化库的中文显示问题 
参考教程
https://tianchi.aliyun.com/course/courseDetail?courseId=261

杂项
pandas 将某一列移动到最前面
基本思想，首先获取这一列，删除，然后插入到最前面。

temp = orgin_file_pdf['code']

orgin_file_pdf.drop(labels=['code'], axis=1,inplace = True)
orgin_file_pdf.insert(0, 'code', temp)


jupyter notebook 技巧
设置宽幅显示
%load_ext autoreload
%autoreload 2


from IPython.core.display import display, HTML
display(HTML("<style>.container { width:100% !important; }</style>"))
# set up display area to show dataframe in jupyter qtconsole

import matplotlib
%matplotlib inline


pandas 在jupyter 中显示所有行和列 及内容
#显示列的条数
pd.set_option('max_columns',1000) 
#显示行的条数
pd.set_option('max_row',300) 
#显示数值的精度
pd.set_option('display.float_format', lambda x: '%.5f' % x)

#设置value的显示长度为100，默认为50
pd.set_option('max_colwidth',100)


多行显示
#支持多行输出
from IPython.core.interactiveshell import InteractiveShell 
InteractiveShell.ast_node_interactivity = 'all'

代码自动补全
#代码自动完成---运行过的内容加入代码提示
#import导入包也可以提示使用tab
%config IPCompleter.greedy=True



参考

机器知心：pandas 数据清洗工具框架代码（还在为数据清洗抓狂？这里有一个简单实用的清洗代码集）




