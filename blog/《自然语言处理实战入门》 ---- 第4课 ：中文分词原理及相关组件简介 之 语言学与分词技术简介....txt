




《自然语言处理实战入门》 ---- 第4课 ：中文分词原理及相关组件简介 之 语言学与分词技术简介
https://edu.csdn.net/course/play/20769/259544
本文为上述课程的讲稿

文章大纲
0.内容梗概
1. 汉语语言学简介
    1.1 汉语与汉字的起源
    1.2 汉字的统一与演变
    1.3 印欧语系与汉藏语系
    1.4 语言区别对于NLP 的影响
2. 词汇与分词技术简介
    2.1 汉语词汇
    2.2 汉语分词的挑战
    2.3 汉语分词技术及其历史发展
    2.4 分词的重要性
3. 思考：我们真的还需要分词么？
参考文献


0.内容梗概
《自然语言处理实战入门》 第4课 ：中文分词原理及相关组件简介的 主要内容 有如下三个部分：

汉语语言学简介汉语分词领域主要服务、手段、方法分词原理最佳实践（以jieba为例）

由于博客太长，我拆分成三篇分别进行阐述

中文分词原理及相关组件简介 之 ---- 语言学与分词技术简介中文分词原理及相关组件简介 之 ---- 分词领域主要分词服务、手段、方法中文分词原理及相关组件简介 之 ---- 分词原理最佳实践（以jieba分词为例）


1. 汉语语言学简介

下面我们进入首先介绍，汉语语言学。

1.1 汉语与汉字的起源
汉语，即汉族的语言，是中国通用语言，国际通用语言之一，属汉藏语系,汉语历史悠久，使用人数最多，世界上使用汉语的人数至少15亿 ，超过世界总人口的20%
汉字最早起源于商朝的甲骨文，距今已经有3000-4000年的历史了。 文字的目的是为了记录，古汉语以独字为核心，即使隋唐以后汉语书面语逐渐向口语化发展。
从古至今，汉语的表达基本单位是字，造字的方法六书：
象形，指事，会意，转注，假借，形声

汉语中每个字都有非常丰富的含义。比如图片中的会意字，顺字，就在字本身上表达出了，柔顺通顺的含义。
从甲骨文出现至今的4000年中，汉语基本的语法格局和造字方法始终没有本质变化。

1.2 汉字的统一与演变


秦朝李斯受命统一文字，图中这种文字就是小篆。通行于秦代。形体偏长，匀圆齐整，由大篆衍变而成。小篆也叫“秦篆”。东汉许慎《说文解字·叙》 称：“秦始皇帝初兼天下……罢其不与秦文合者。”李斯作《仓颉篇》，中车府令赵高作《爰历篇》，太史令胡毋敬作《博学篇》，“皆取史籀大篆，或颇省改，所谓小篆者也。”今存《琅琊台刻石》、 《泰山刻石》残石，即小篆代表作。
汉字统一后，我们的祖先通过造字并且成词，成句，最终留下了浩如烟海的璀璨文化。
汉字书体的演进主要目的其实就是为了书写的方便，包括近代繁体字简化为简化字。我们来看看各种书体的代表作：


汉隶唐楷，说的就是这两种字体在对应朝代被发扬光大
值得一提的是，对于计算机可以理解的语料库，知识库，我国起步很晚。
1979年开始，中国开始机器可读的语料库的建设，至1991年开始建设国家级的语料库。现在我们使用汉语分词开源组件的大部分语料库都是基于《人民日报》加工的，一般项目包括词语切分、词性标注、专有名词（专有名词短语）标注。还要对多音词注音。

1.3 印欧语系与汉藏语系
人类经过漫长的历史发展，在世界各地形成了很多不同的语言分支，四大语系是指世界语言的主要分类，分别是印欧语系、汉藏语系、闪含语系和阿尔泰语系。
其中英语、法语、意大利语、西班牙语等属于印欧语系，汉语和藏缅、壮侗、苗瑶等语族属于汉藏语系。其中汉藏语系和印欧语系是使用人数最多的两支。英语是印欧语系的代表，而汉语则是汉藏语系的代表。
英语（English）是印欧语系-日耳曼语族下的语言，由26个字母组成，英文字母渊源于拉丁字母，拉丁字母渊源于希腊字母，而希腊字母则是由腓尼基字母演变而来的。腓尼基字母是腓尼基人在楔形字基础上将原来的几十个简单的象形字字母化形成，时间约在在公元前1500年左右。
由于英语是目前全球使用最广泛的语言，并且和计算机编程关系紧密，所以前沿的NLP 工作基本都是针对英语来做的。
现在的字母文字，几乎都可追溯到腓尼基字母
 当然印欧语系与汉语的诸多不同中，有如下两点是至关重要的。
第一，印欧语系都实行分词连写，词与词之间用空格分割，因此没有分词问题。第二，印欧语种大多数都通过形态变化构造语法结构，有很强 的规范性。

1.4 语言区别对于NLP 的影响

基于印欧语系上述 的特点，在自然语言诞生的初期阶段，句法分析已经成为西方NLP的核心主题。
在汉语自然语言处理的过程中，遇到的问题与印欧语言有诸多不同：首先中文分词就是西方语言所不曾遇到的问题。
另外在句法解析环节，如果照搬西方语言的算法理论，越来越多 的事实证明，句法分析的在汉语上的精度要显著低于西方语言。
为什么呢？我想更深层次的原因可能是，中文意合，英文形合。
意合和形合是语言表现法.所谓“形合”(hypotaxis)是指借助语言形式手段（包括词汇手段和形态手段）实现词语或句子的连接；所谓“意合”(parataxis)是指不借助语言形式手段而借助词语或句子所含意义的逻辑联系来实现它们之间的连接. 前者注重语言形式上的接应(cohesion),后者注重意义上的连贯(coherence).
意合 作为更高级的语言表现形式，随着全球一体化的发展，世界各国的语言及思维模式会渐渐朝着这个方向去演进，这也是NLP技术未来的挑战之一。
整体来看，中英文NLP 到底存在哪些不同能，推荐大家阅读文章：
达观数据：中文对比英文自然语言处理NLP的区别综述

2. 词汇与分词技术简介
汉语词汇是汉语语言中能够独立运用的最小语言单位，是语言中的原子结构。 独立运用意味着，单独做句法成分或单独起语法作用。
因此对中文进行分词就显的至关重要。汉字有5-20万多个，但是常用的汉字仅有6000个，在线新华字典中收录了约52万个汉语词汇。
在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂得多、困难得多。（比如北京大学的划分，是单独成词还是两个词，这样的中文词汇还有很多）

2.1 汉语词汇
说到汉语词汇，汉语词汇有三个重要特性：
1.稳固性 2.常用性 3.能产性
前两个特性很好理解，能产性说的是，人们给小孩子起名就是词汇能产性的生动体现，汉语的构词机制是一个动态的自组织认知系统，所以汉语自然语言处理的魅力就在于，对于此类在社会发展过程中出现的新词，人名，组织机构名，如何正确切分并且识别。

2.2 汉语分词的挑战
经典论文《中文分词十年回顾》[4] 提到，人与人之间 的词语平均认同率只有 0. 76 左右的结论，可见汉语分词还是充满挑战的。总的来说中文分词研究的四个难题如下 :
(1) “词”是否有清晰的 界定
词语的界定不具有可计算性。人与人之间 的词语平均认同率只有 0. 76 左右
(2) 分词和理解孰先孰后 ;
自动分词所依 据的只能是文本的表层信息。所以 ,尽管人在识别 句子中的词语时是以理解 为基础的 ,然而从实用 的角度考虑 ,计算机自动分词系统不可能完全照搬 人类的分词模式 ,而通常会选择“先分词后理解”的 处理策略。
(3) 分词歧义消解 ;
结婚的和尚未结婚的

(4) 未登录词(Out2of2vocabulary ,简称 OOV) 识 别
我们看到每年层出不穷的 网络新词，是汉语分词器的一大挑战，老一点的分词器可能支付宝，微信这两个新词都不能正确的分出来，更不要提对它们进行词性标注了。
2018年 -- “锦鲤”、“官宣”、“杠精” 2019年 -- “复读机”、“鸽子精”、“真香怪”

2.3 汉语分词技术及其历史发展
由于国际上常用的NLP算法，深层次的语法语义分析通常都是以词作为基本单位，很多中文的自然语言处理的任务，也就多了一个预处理的过程来把连续的汉字分隔成更具有语言语义学上意义的词。这个过程就叫做分词。
简要来说分词就是：把没有明显分界标志的字串切分为词串
中文分词研究经历20于年，主要分化为三个流派。

1.机械式分词法（基于词典） 2.基于语法和规则的分词法 3.基于统计的分词法

最终较为成功的实现了中文词汇的自动切分技术（最近兴起的深度学习技术，又提供了新的分词思路）
尽管在语言学语义学上，词有着相对清晰的定义，对于计算机处理自然语言来说，分词很多时候没有放之四海皆准的共同标准。由于分词本身更多的时候是作为一个预处理的过程，判断其质量的好坏更多的时候需要结合下游的应用来进行。

2.4 分词的重要性
分词问题为中文文本处理的基础性工作,分词效果的好坏对后面的中文信息处理其关键作用。传统的中文自然语言处理通常会把分词作为一个预处理的过程，所以系统是pipeline形式的，这样带来的一个问题就是error propagation。也就是分词的错误会影响到后面更深层次的语言语义分析，比如POS tagging, chunking, parsing等等。(参考：深入NLP———看中文分词如何影响你的生活点滴)。
所以对于中文来说，只要做好分词（并且现在的分词准确率还相当不错，能达到96%左右的F-score [Zhang et al. 2016, Transition-Based Neural Word Segmentation]），就可以跟对接现在比较主流的英文NLP算法。

3. 思考：我们真的还需要分词么？
中文NLP的分词真有必要吗？李纪为团队四项任务评测一探究竟 | ACL 2019
在深度学习中，词往往是操作的基本单位，本文将此种模型称为基于词语的模型（word model）。在模型中，分词后得到的词语，再使用固定长度的向量来表示，这就和英语词语的处理方式相同了。那 word model 存在哪些缺陷呢？要点：

首先，data sparsity 会导致模型出现过拟合，OOV 则会限制模型的学习能力。
第二，现在的分词技术还存在很多问题，分词不当产生的错误会导致 NLP 任务出现偏差。
第三，分词产生的收益效果尚不明确。

作者将两种模型在 以下几个 NLP 任务中实验的评测结果

语言建模 机器翻译 句子匹配 文本分类 领域适应能力

基于字符的模型的表现均优于基于词语的模型。
当然，随着深度学习技术近年来在NLP领域成功的应用，一些seq2seq学习过程可以不再使用分词，而是直接将字作为输入序列，让神经网络自动学习其中的特征，这在一些端到端的应用中（如自动摘要、机器翻译、文本分类等）确实省略了中文分词这一步骤，但是，基于以下3点，中文分词在一段时间内依然不可替代：

1.很多的NLP应用离不开分词的结果，如关键词提取、命名实体识别、搜索引擎等；
2.切分所得的词汇也可以和单字一起作为特征输入，用以增强效果。因此分词仍然是工程界进行中文处理时的一项重要技术。
3.可视化分词结果，词云，主题模型，TF-IDF,TEXTRANK 等仍不失为用机器快速理解语料篇章的有效手段。


参考文献
1.《自然语言处理理论与实践》
2.《智能问答与深度学习》 https://github.com/l11x0m7/book-of-qna-code
3.《Python自然语言处理实战：核心技术与算法》 https://github.com/nlpinaction/learning-nlp
4.黄昌宁, 赵海. 中文分词十年回顾[J]. 中文信息学报, 2007, 21(3):8-19.
5.一文详解中英文在NLP上的10大差异点
6.中文NLP的分词真有必要吗？李纪为团队四项任务评测一探究竟 | ACL 2019
7.深入NLP———看中文分词如何影响你的生活点滴

往期课程
1.《自然语言处理实战课程》---- 第一课：自然语言处理简介
2.《自然语言处理实战入门》 ---- 第二课 ：网络爬虫简介
3.《自然语言处理实战入门》 ---- 第3课 ：本人CSDN博客的爬取




