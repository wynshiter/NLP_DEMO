



 


 
 
七月份写过一篇日志，年终总结我们就从下半年开始吧。
这半年来总的来说，档期很满，所有事情基本按照规划都步入正轨，这让我想起来2013年考研时候教毛中特的包松老师在课程快要结束的时候给我们讲到，你对考研成功有强烈的渴求么吗？强烈到像溺水时候渴求空气一样的强烈吗？我有时候想做一件事情非常强烈的想要把它做成，后来，因为这种渴求，我经常能把一些事情做成功。同学们，虽然这样讲有些唯心主义，但是如果你们真的尝试去这样想，这样渴求，就真的离成果不远了。
 
 
 
你若要为你的意义而欢喜，就必须给这个世界以意义。----------歌德
这是一个酥脆香甜外焦里嫩的菜煎饼
咬下第一口，啊，life，之前你都到哪儿去了？
咬下第二口，这个小摊，冰天雪地的坚持到十一点半给同学们卖宵夜，这是怎样的一种职业操守，而且还支持微信支付，满满的感动！
咬下第三口，2016年之前吃饭大学的书都白念了，未曾吃过如此沁人心脾催人泪下之夜宵，没想到，最难翻越的，是习惯！相信世间所有的相遇都是久别重逢！
爱情使所有的人变成雄辩家，这话说得绝对正确。------罗格林

    张老师给学生讲数学的时候我听过，用的还是比较危言耸听的讲法。我初中的数学老师也和张老师差不多漂亮，讲课也挺好，当年我初中的同学们都很喜欢漂亮的女老师，数学都学的不烂，不知道为啥现在的小孩成天补习数学，所以张老师上课的负担也不小。我曾给张老师不屑的讲，初中题目能难到哪里去，你这交初中岂不是大材小用，结果她发了两道题让我做做，我当然不能给陕西吃饭大学丢脸，果断没做对。想当年我中考数学也只扣了三分，对现在题出这么难表示不理解。。。
    张老师  跟我一块的时候不太能说，主要由我负责指点江山，但是只要在微信里面遭遇，说话肯定一套一套的，俨然一副雄辩家的模样，有时候我根本不知道怎么回答她，只好发去。。。，她依据此引经据典又是一顿侃侃而谈，而且每次不同，小生心里佩服的紧呐。
     张老师作为人类灵魂的工程师，工作辛苦，有时候我去接她下班，一起吃饭，她总是胃口大开，从我们认识到现在她吃饭前都说要减肥说她少吃点就行了让我随便点，我总当她是开玩笑，没有当真，所以我吃完就结账拉她走人的时候也不知为什么张老师总是一脸不悦。直到最近张老师认真起来了，我一吃完，她说你等等，我终于明白张老师是在暗示我，谈恋爱，大家要互相迁就，谁吃的快了，就等一下对方，大家共同成长嘛！
我和张老师彼此相识于学雷锋纪念日，一路走来也有将近两年的时间了，今后的日子还长，我们会共同努力，在不同的战线上为实现共产主义奉献力量。
那天坐滴滴的时候有一个非常有意思的师傅，
我看师傅开的是斯柯达明锐，我说这车好！师傅说不要钱的车最好，我问师傅优步和滴滴哪个好？师傅说不要钱的最好，他说他接到过一单滴滴，12000从西安到天津，我忽然想到这个事儿，可以写成剧本儿拍个公路犯罪类型的电影，然后让滴滴打车植入广告一定大卖！我跟师傅一路走一路聊，张老师就在一边傻笑，现在期望司机师傅能开慢点，好让我们几个的欢乐能够得以延续，想到那天小米开年会，老总雷军说，一五年，他们太关注，手机出货量，你整个公司上上下下都背上了沉重的包袱过的一点儿都不欢乐，2016年要把，重心重新关注到手机的电量系统、拍照等细节问题上，带着使命感把这些问题解决好，重新回到为发烧而生的道路上来。
我想我们这个年纪的人多少需要在自由和责任中，做出一个去选择，是追随自己的内心，还是向现实妥协,，选择什么都没有错，不过既然已经选择了，不如让他欢乐一些，你饿不？，我去给你煮碗面

致谢
生活处处有惊喜，希望16年还能继续惊喜下去，感谢这一年来我的努力，张老师的支持，朋友们老师们的关照。
 
后记--
朱光潜在《谈文学》中对于如何做文章讲到：
你不肯用俗滥的语言，自然也就不肯用俗滥的思想感情，你遇事就会朝深一层去想，你的文章就不致落入下乘。现在马上毕业了，马马虎虎的走完了学业生涯，对自己一直要求不高，希望在后续走入社会的过程中，对于自己凡事严格要求，取法为上，仅得为中，取法为中，故为其下，与各位共勉。
 











绪论
2016年的生活有些忙碌，到年底一整年连续的日子成了离散的关键词。2015年这个时候，我还在学校深更半夜因为一个菜煎饼感动的痛哭流涕，一转眼2016年都要过完了。

江湖有江湖的道义，武林有武林规矩，洒家的2016罗列如下：

老张是个好老师
与老张恋爱三年有余，彼此互相包容忍让，共同进步，谁不会闹点小误会呢？毕业那会，正处多事之秋。几年的好哥们，都将去各处远行，心中有些酸楚。彼时又和张老师闹了别扭，一气之下几天没吱声，现再回想起来这是非常不负责任的，在此向老张再次郑重道歉。张老师工作辛苦，你可能要说这年头哪还有容易的活啊。然而作为人类灵魂的工程师，如果是我去教初中数学，面对一个1/2不知道等于0.5的初中生，可能真的忍不住要爆粗口甚至动手削那些熊孩子。而老张呢，虽然威严不减也还是不紧不慢的悉心指导，末了还要应付熊孩子的家长们。
有好几次，我都觉的有点过分。一点多了老张还没吃饭，打电话过去发现张老师依然在和家长沟通学生的情况。一个在老师饭点还冷怂给老师倾诉自己小孩怎么都学不进去不知道咋办的家长可能真的要反思一下，娃学不进去是不是自己的问题。
我们可敬的张老师当然和我不一样，每当出现这样的坑货家长，她都会不厌其烦的帮助她们分析总结，宁可自己饿一会，也会安抚好家长，找到解决问题的办法。人常说，教师是神圣的职业，但教师也是人，老张却用行动诠释了，什么是师者所以传道授业解惑也，不但给学生授业，也给家长解惑。
在此，致敬所有老师！
在此，借用***情书的结尾，吻你万千。

毕业是一件大事
毕业是一件大事，分别也是一件。离校最后的两天宿舍挨个放空，我有些不舍，于是挨个拥抱了所有同学（女）又开车回去游了几回泳，最后送走了大飞，才算离开学校，一脚踏入现实的泥潭。
回想老郑走的时候，山东大汉偷偷掉了眼泪，他说你可别笑话我。“西安这么好，别走了吧”，我告诉他。可他听了之后还是头也不回的去检票了，还撂下一句：你们回吧。林总和老王走的时候就没这么多痛苦。因为以后和老王聚的时候还多，结果到现在也没聚过一次。林总一想到深圳离卅城就两站路，就开心的浑身热血沸腾，一溜烟上了头班616拍马而去。黄兄要南下蜀地，后来多次沟通工作上对IT个大领域的发展畅想，黄兄想法见地之深刻令人耳目一新，这年头敢唱衰大数据的人不多，黄兄算是有理有据的一个。
抱道不曲，拥书自雄，与诸位同学共勉。


大数据时代的思维转变
毕业后没想到阴差阳错的进入了大数据处理领域，才发现在视觉领域浸泡许久，思维和大数据处理上截然不同。视觉上的处理要求精确，单机高效，并行，更多是因果关系，图像中出现了人，因此有人脸，从而有人脸识别，从而有表情识别。而大数据条件下更多是要求关联关系，只要发现了两个现象之间存在显著的相关性，就可以创造巨大的经济或者社会效应，比如Google通过追踪大量用户搜索流感字样的人群位置，做出了流感的趋势预测。

唱衰大数据
Susan langer 在《哲学新视野》一书中说：某些观念有时候会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速的抓住它们，作为进入某种新实证科学的法宝，作为可以用来构建一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
大数据时代，大数据这一手段俨然成为了一种万能工具，我们今天在这里就是要唱衰大数据，因为越是万能的，就越是空洞的。
大数据的核心是预测，如果不能进行预测，仅仅进行简单的数据统计分析，那么和传统的领域我认为是没有区分开的，从事这样的行业价值不大，当今大数据框架之成熟解决方案之完备，完全可以让一个没什么计算机经验的高中生经过几个月的培训就接手各种修改配置的部署工作中去，CDH，zookeeper，hue等等管理框架又都提供了图形化管理的界面，如今各大开源社区的贡献已经让尽可能多的人成为了大数据行业中的价值制造者，那么从事大数据行业的人还有什么可以深入发掘的点呢？
大数据人才大致可以分为以下三个方向：

偏重基建与架构的大数据架构方向。
偏重建模与分析的大数据分析方向。
偏重应用实现的大数据开发方向。

机遇与挑战似乎一直存在，你能找到他们么？

老王和他的IT界朋友们
工作不多时来到北京，借此有机会看望了IT界的名企大牛同学们（时间有限BAT,GOOGLE等还没走完），虽然都身在新闻联播的帝都里，幸福像花儿一样，然而漂泊本无根，几年过去了，大家都没怎么变化，这又让我想起一句诗：人面不知何处去，桃花依旧笑春风，诸位累了就回西安吧。




逃离北上广，我们有情怀的雷总在西安迎接大家，有留迹，让故事留在他发生的地方.


帅不帅，留给别人去评判，反正天下我最帅！
2016年是我准备开始运营《老王和他的IT界朋友们》这个品牌的开局之年，感谢各位亲朋好友的支持，公众号至今为止以有208位粉丝，他们不属于IT界，就一定是IT界的朋友。书上说做人得要有：高远意志，平宽心情。我们这个小圈子一定会竭尽全力带领各位实现目标，剖析自己，送上更多的人文关怀。

后记
2016年已经离我们远去，世事尽管有些未尽人意，您可千万别灰心丧志。挫折如火，劫难如焚；火能焚木为灰，却能炼铁成钢！
最后祝大家新年快乐



欢迎关注公众号：老王和他的IT界朋友们






















2017年钟声敲响的时候，人们总是习惯于性质勃勃地写下一张全年的to do list：例如读完800本书，买个大房子等等。立志之后，就陷入到忙忙碌碌的新一年中，上班扎进电脑和手机，下班一头扎进被子，直到猛一抬头发现2017年只剩几天。。。

十八般武艺 VS 亢龙有悔
矛锤弓弩铳，鞭简剑链挝，斧钺并戈戟，牌棒与枪杈
古语有云：有志者立常智，无智者常立志。随着现代社会的迅速变化，立常志变得几乎不可能，更多的情况是你的理想需要随着现实情况的变化而做适当的调整。但即便如此，我还是认为需要一个相对恒定的理想。不忘初心，是整个国家，社会对于回归纯粹生活的热切期望。
工作一年半以来，由于单位没有互联网，手机俨然成为了我躯体的又一器官。当我发现手机严重影响 我的专注度和思维能力已经 为时过晚。远离手机的时间，大脑通过冥想可以将一些看似没有太多关联的事情联系起来。所以当我和任务独处的时候我能感觉到和整个宇宙都在产生联系，但是当手机加入，就只有我和手机了。 
自媒体的迅速发展，既容易造成注意力的集中，也容易造成注意力的消解，使人们对需要严肃对待的事情越来越缺乏耐心，面对铺天盖地的信息，往往需要耗费大量时间甄选有用信息 ，本来是打开手机搜索一个问题，由于顺道开了微信，刷了一圈朋友圈八卦，又顺道看了两篇公众号文章，而忘了自己原本要打开手机的目的，长此以往根本没法集中注意力，干什么都不专心，做什么都delay，当今社会犯错成本太高，我们还是需要小心翼翼，千万不要养成时不时看手机的毛病而误了大事。
两弹一星元勋科学家钱学森出身书香门第，他不但学贯中西更是精通琴棋书画，1935年，24岁的钱学森甚至还发表过一篇题为《音乐与音乐的内容》的论文。看来天龙八部中聪辩先生苏星河精通琴棋书画，却不擅长武学，因花太多时间于杂学之上，并未学会逍遥派太多高深的功夫，他有点像我现在的状态，在技术上缺乏一个focus 的点，郭靖大侠当年将一招亢龙有悔使到极致照样威震武林，当然他也可能还是天赋有限。我也天赋有限，工作生活中还是要保持专注度，远离手机，保持纯粹的追求，也许总有一天，自己也能十八般武艺样样精通，成为一代全栈程序宗师。

 天下攘攘皆为利往
以下一个小节完全转载自，安晓辉《 程序视界》

很多开发者追逐 AI ，也是从这点出发，为了自己更好的未来。但实际上，趋势并不属于每个人。它往往属于那些已经为这个趋势做了很多年准备的人。
你必须知道的是，现在 AI 趋势里风生水起的专家、科学家、公司，哪个不是之前已经在相关领域做了很多年的研究？
如果你只是看到趋势就盲目扑过去，往往沦为跟风，甚至会跟丢，跟来跟去找不到自己的位置。所以，如果你决定要跟，也要了解怎样去跟。
人工智能开发的四种类别

最后，提醒一下，并不是每个程序员都要追逐人工智能软件开发这个浪潮。软件开发的方向很多，应用场景也很多，你有非常大的可选择余地——只要你能成为你所处领域的局部头部，你就会拥有很多机会。而如果缺乏成为头部的思维、能力和行动，不论去追赶什么浪潮，结果都只能是望洋兴叹。

参考这篇安大神的文章分析，我可以有一个简单的判断，从现在做起还不算晚。 
http://mp.weixin.qq.com/s/TdG3ML195g55hD9a9UuxcQ 
(以上内容转自上述链接)

我一直追寻着你心情的足迹
张老师的小学教师生涯并不是一副歌舞升平的盛世景象，她有时候甚至问我：自己是不是适合教师这个职业。家长到处范二，练习册丢了问老师，作业布置的啥问老师，恨不得把老师当成7*24小时不间断服务的人肉机器人，问的时候还不加敬称，你你你的呼来唤去。我看了心里都很不爽，张老师还是不卑不亢的耐心回答，就评这一点小张就应该获得优秀教师勋章。
国家说要提高基层教师工资待遇，喊了很久，张老师也没涨工资。大学教授一个月1w7带两三个研究生天天给自己报销发票有几个真正推进了我国现代化进程的进步？小学幼儿园初高中老师一个月几大千一人带80多个祖国的花朵，拿着卖白菜 的钱操着卖白粉的心。谁手中掌握着祖国的未来？多劳多得按劳分配也应该给她们涨涨工资。
记得有一次和高指导聊天龙八部，发现金庸竟然在新版改了结局，知乎上有人说，更相信王语嫣和段誉仍然是一对。后来长大后便慢慢醒悟爱情的意义。明白了金老先生的深意。其实木婉清刚出场那时，已经折服了多少人的心，他和段誉本是良偶，于是王语嫣与我，从神仙姐姐，变成了岳灵珊、变成了周芷若。
和张老师的爱情长跑将近1400多天，我们已经有了明确的人生规划，在人生大事上基本达成了共识，爱情在我们两个人的生活当中产生了微妙的变化，好像慢慢的在向柴米油盐等琐碎的事情上迁移，张老师批评我说热恋还没完，怎么就要开始准备结婚了。说起来万分惭愧，是这一年来我因为工作的原因聚少离多，给她的惊喜太少了吧。
特别感谢小张老师，她是一名优秀的产品经理，经常能敏锐且毫不客气的指出我的不足，更难得的是她胃口很好，哈哈

任何事情要做好且做爽，必然是内驱的
2015年的关键词：少说多做 
http://blog.csdn.net/wangyaninglm/article/details/50640972 
2016年的关键词：努力，奋斗 
http://blog.csdn.net/wangyaninglm/article/details/53959333 
2017年中的关键词：让我们一起为梦想窒息！ 
http://blog.csdn.net/wangyaninglm/article/details/74612482
过去的时间我基本保持 ，每半年更新一篇总结过去，展望未来的文章，2016年底我希望自己能够成为大数据全栈工程师，还顺道唱衰了一下大数据觉得大数据什么的都是使用开源的产品，一年过去发现，好家伙用开源产品也得知道怎么用数以万计的api呀，hadoop生态圈十几二十个产品真不是盖的。和圈内专家聊了两句就露馅，人家说，您这就不叫大数据研发，充其量就是使用开源组件—-而已！
所以这半年比较尴尬，甚至没有一个可以写到简历上用来show 的项目。代码没写过多少，淡是越扯越好了。 
想起csdn专家群里一个专家总结最近面试人的经历，大多数是：一问三不会，开口十几k 
我呢？开不了口。。。
总结总是有喜有悲的，在单位，吃了个饭，睡了个觉，出了个差，半年过去了。这些时日我总发现自己穷的很，不单单是物质层面上的，更是精神上的穷。
造成这种身心惧穷的根本原因是基本上把钱看的比什么都重要，做事情的时候我会不自觉的去衡量事情的金钱价值，而真正应该 有的态度是首先把事情做好，顺便赚钱。至少冯仑说李嘉诚是这么认为的。
工作说完了，咱们再来聊聊人生有何意义？胡适先生说，科学家是为求真理。庄子虽有“吾生也有涯，而知也无涯，殆已”的话头，但是我们还是要向上做去，得一分就是一分，一寸就是一寸，可以有阿基米德氏发现浮力时叫Eureka   的快活。有了这种精神，做人就不会失望。所以人生的意味，全靠你自己的工作；你要它圆就圆，方就方，是有意味；因为真理无穷，趣味无穷，进步快活也无穷。
记得前段时候有一篇文章说第一批九零后已经秃了，当然没有人能躲过生活，只不过现在轮到90后，罗曼罗兰曾说过，世界上只有一种真正的英雄主义，那就是在认清生活的真相后依然热爱生活。
共勉！

特别鸣谢

小张老师
胡适先生
《人人都是产品经理》
《黑客与画家》
安晓辉 《程序视界》


All Rights Reservered

注： 
在大型组织内部，有一个专门的术语描述这种跟随大多数人的选择的做法，叫做“业界最佳实践”。 









文章大纲程序员的美德优秀是一种习惯自我激励相信自己的直觉，思考的更深入一些结构化，工程化的思维忙碌的一年韭菜的自我修养？人工智能 之我见那些年我写过的总结

魏超 说 他很期待老王我的年终总结，我有点激动的不能自已，而且骤然发现2018年是我踏入IT 的第十个年头了，值得大书特书。于是决定将这篇年中总结分成两个部分，在2018年年底，和2019年年初分别发布。上篇主要回顾和总结，下篇用来畅想未来。

程序员的美德
编程珠玑上说，程序员有三大美德：

对数值敏感
实验的欲望
良好的数学功底

从我的IT十年路来看，关于如何成为一名优秀的程序员，我其实可以充当反面教材，看的书不少，写的代码太少。随着投身行业的时间逐渐增长，遇到的bug，身边的大牛，总有一些方面尤其感触良多，印象深刻。下面分享几个今年的感悟。

优秀是一种习惯
自我激励
相信自己的直觉，思考的更深入一些
结构化，工程化的思维


优秀是一种习惯

最早写博客是上了大学以后，每个人内在都有一个渴望被别人了解的社会性需求。我开始是在qq 空间上面写，总是一些剖析自己，畅想未来的套路。后来发现自己其实没什么好剖析的，还是剖析剖析IT相关的技术细节。就开始混迹csdn，那时候论坛还有很多人。
一些具体的程序设计问题，配置问题，在坛子里会有一些大牛悉心的回复。碰的坑多了，久而久之就成了专家。久病成医就是这个道理。但是其实，正规的，工程化的套路不应该是这种样子，拿到一个第三方库，或者插件，我们应该先看文档，然后才下手去做，去实践。
然而国内IT的氛围比较紧张，项目经理经常从需求那边拿到的反馈就是三个字：明天要。 谁有心情仔细钻研这些个开源组件的来龙去脉呢，其实前几天阿里开源的组件圣诞节期间自爆彩蛋不就是这个事情的最好说明么。
所以我认为，优秀的程序员会有一种习惯，总是未雨绸缪的

自我激励
试图引经据典，找到一些前进的方向。
如果翻看我曾经写过的文章，你就会发现我特别喜欢引用名人的话来证明自己的观点，并以此找到一些前进的方向，我总是容易陷入阶段性的迷茫中，迷失了自我和目标
还记得，得到第一个真正的篮球时，我还是个孩子。
我喜欢它在手中的感觉，对它一见倾心。我甚至舍不得拍它或用它，因为不愿破坏那些鹅卵石般的皮革颗粒，还有那些完美的凹槽。
我不想毁了那种奇妙的感觉。 

我也喜欢它发出的声响，那种在硬木地板上反弹发出的“砰、砰、砰”。清脆，清晰，易于预测。
那是生命之声，光芒之声。 这正是我热爱篮球、热爱比赛的一部分原因，也是我篮球之道的核心与根基。
因为它们，我才能经受我所能经受的一切，倾注我所能倾注的所有，探索我所能探索的全部。

一切都源于孩童时期，第一次听到那让我心醉神迷的“砰，砰，砰”。
                                                 							----《曼巴精神：科比自传》

我们公司有个分析师，是个在美国的印度人，他说当他看到我的流川枫头像，想起来他小时候也是看slamdunk漫画和机器猫龙珠长大的。也知道《直到世界尽头》这首歌，我想说的是你看Kobe自传里面写的这些个场景，难道Kobe也是看了灌篮高手听了WANDS的歌了么？
原来每个人小时候的成长环境都或多或少的一样。而且那些放之四海而皆准的至理名言和人生哲理，既然对别人都有用，那对我也一定可以起作用。

相信自己的直觉，思考的更深入一些
前段时间工作上有个项目，需求收集的比较模糊，开完会之后发邮件，所有人的意见都指向往简单了去做。但是我心里觉的实际上肯定没有这么简单。但是还是为了避免不必要的麻烦，最后沟通总结邮件时候也是按照简单的方式做了总结。
果不其然晚上就被领导们教育了一番。这种总结性的邮件，如果我没有更深入的进行一些思考，那么其他对接的方面怎么可能尽量理解的清楚呢。
所以凡事相信自己的直觉，思考的更深入一些，举个《编程珠玑第二版》的例子来说
什么是用户的真正需求：
一个运筹学者接到任务，设计末座大楼的电梯调度策略，使乘客等待的时间最短，在走访了这座大楼之后，他认识到雇主真正想要解决的问题是，尽量减少乘客的不适（ 乘客不喜欢等电梯）。他这样解决问题：在每部电梯附近装上几面镜子。乘客在等电梯时候，可以自我欣赏一下，对电梯速度的抱怨大幅减少了。
他思考的更进一步，发现了用户的真正需求

结构化，工程化的思维
Oracle 如何处理一个 bug


开始处理一个新的 bug 。


花两周的时间试图理解 20 个不同的 flag ，这些 flag 以神秘的方式相互交互，导致这个困境。


再添加一个 flag 来处理新的特殊场景。添加几行代码来检查此 flag ，并解决有问题的情况，规避该 bug 。


将更改提交到包含大约100-200台服务器的测试服务器集群，这些服务器将编译代码，构建新的 Oracle 数据库，并以分布式方式运行数百万个测试。


回家。第二天来上班，继续处理别的 bug 。测试可能需要20-30个小时才能完成。


再回家。再来上班，检查你的集群测试结果。顺利的话，会有大约100个失败的测试。倒霉的话，将有大约1000个失败的测试。随机选择一些测试并试图搞清楚你的假设出了什么问题。或许还需要考虑10多个 flag 才能真正理解 bug 的本质。


再添加一些 flag 以尝试解决问题。再次提交更改以进行测试。再等20-30个小时。


来来回回重复两周，直到你得到了将这些 flag 组合起来的“神秘咒语”。


终有一天，你会成功，不再出现测试失败。


为你的新更改添加100多个测试，以确保下一个不幸接触这段新代码的开发人员永远不会破坏你的修复。


提交最后一轮测试的成果。然后提交以供审核。审查本身可能还需要2周到2个月。所以接下来继续去处理下一个 bug 。


在2周到2个月之后，一切已就绪，代码将最终合并到主分支中。


以上是oracle 处理一个 bug 的过程，据说我最喜欢的数据的库Oracle 12c 有2500w 行c 语言代码。你写过的最大的个人代码库有多少行代码？
所以，当解决复杂问题的时候，个人单打独斗的时代已经离我们远去了。我们需要的是工程化，结构化的思维模式，这样才能面对风云变幻的国际形势立于不败之地。
忙碌的一年




今年是非常忙碌的一年，上半年年还没过完，就被单位忽悠到北京保卫祖国和人民，连续两年我的正月十五都是在北京过的。反正去年年底已经铁了心的要走，索性最后送佛送到西，也算是不留遗憾。怎奈身体的健康下降了太多，人老先老腿。这一点在我身上体现的特别明显。作为一个程序员，一天中有80%时间在电脑跟前坐着，腿部肌肉退化萎缩的厉害。大学时候我可以跑1500米全校第一，没觉得什么。现在只要跑两步就觉的腿很沉。
但是，雪莱说：过去属于死神，未来属于自己。身体容不得半点马虎。我依旧坚信，每天锻炼三十分，健康工作三十年。
年初的时候csdn 博客的访问才130万，今年一年又增加了40万，虽然只写了20多篇博客，还有一些是厚着脸问魏少、黄兄要的（此处特别鸣谢）。今年的技术上，似乎相关spark 和python 以及oracle 多一些。NLP也算是在字词，可视化的初步探索上有了自己的一些积累。后面希望自己将NLP这些东西融会贯通起来。
回首往事，一年的时光荏苒，当我翻看朋友圈，很难想象，年初，我还在北京常驻进行大数据集群的运维，做着不知疲倦的数据搬运工，年底我已经在知盛深入健康保险行业的大数据分析了。
底下这张照片我很喜欢，这是2017年底，赶头一班高铁回家，在高铁上拍到的，北京总是很早的时候就开始堵车

回首这十年，每一年的年终总结，我似乎都会加上忙碌两字。忙可以，但是碌碌无为就不太好了。很多时候，我一直明白，生活在周而复始的阶段性颓废和奋进中挣扎徘徊，就好像北京每天早上都堵车，我们一定要让生活非得这样么？
能不能买个直升机上下班

韭菜的自我修养？
2018年初，准备结婚，我妈叫我把手里的股票基金清空，我看着我逐渐从3000点建仓起来的大概15%的收益，我说等等。我还能多赚点。我和一个老股民有了争论（我妈），她说，瓜娃，落袋为安。
后来，到现在2018年底，我还没卖，抄底还抄在半山腰，我说，真正成了韭菜，真是难以自拔。
有一天无意中看到蚂蚁财富号上不知道谁写的特别有道理的一段话：
牛市之中，不管是买方还是卖方都是你的战友。
而熊市之中，不管是买方还是卖方，都是你的敌人。
什么意思呢？或者说这是为什么呢？
很多人不理解为什么老交易员经常讲：牛市胆子要大，熊市要懂的寂寞，刀枪入库，马放南山。
因为，在牛市里，不管是买方还是卖方，双方都是实质性赚钱。
在熊市里，不管买方还是卖方，二者都是实质性亏钱。

人工智能 之我见
AI时代该学什么？
人工智能时代，程式化的、重复性的、仅靠记忆与练习就可以掌握的技能将是最没有价值的技能，几乎一定可以由机器来完成；反之，那些最能体现人的综合素质的技能，例如，人对于复杂系统的综合分析、决策能力，对于艺术和文化的审美能力和创造性思维，由生活经验及文化熏陶产生的直觉、常识，基于人自身的情感（爱、恨、热情、冷漠等）与他人互动的能力……这些是人工智能时代最有价值，最值得培养、学习的技能。而且，这些技能中，大多数都是因人而异，需要“定制化”教育或培养，不可能从传统的“批量”教育中获取。

那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事











文章大纲视线所及只剩生活挣钱迷茫之后10条建议那些年我写过的总结

2018 初入IT十年（上）----成为一名优秀的程序员
初入IT十年下，本来打算在2019年初写完，结果拖到了现在。在程序员节之前，发出来，权当是年终加半年总结。

视线所及只剩生活
996 icu 事件已然过去一段时间，那时候
周鸿祎毫不忌讳地说，在中国，工资只能解决糊口问题。你想买房，就要拿到公司股份，而不是指望996。“在座的哪位如果能够真正做到快乐工作，平衡好家庭和工作的关系，我就叫他一声大爷。
我深以为然，穷是21世纪的顽疾，不单单是金钱，更是时间上的。
凤姐在微博上曾逻辑严密的给996 的人算过一笔账，如果加上上下班来回，执行996工作制的人回家只剩睡觉的时间了，资本家福报理论的司马昭之心昭然若揭。

挣钱
说几个这些年来关于挣钱的感受。在上一篇文章里面讲到: 韭菜的自我修养？
今天再补充几个。
看懂了这个，你再去炒股；股市暴跌，为啥散户炒股票总赔钱？李永乐老师用数学告诉你！


李永乐老师的两个建议：
1.把自己的心态调整好，把自己的时间和钱用在更有意义的事情上
2.如果一定要买股票的话，请买那些基本面良好有发展前景的股票，慎重购买题材股，因为题材股上有很多的庄稼，他们会通过一定的策略让你一直输钱。
我的建议和经验：
1.股票反着买，别墅靠大海
中国的资本市场也在逐渐转向价值投资，那么如果我们选择做长线，巴菲特曾说：“别人贪婪时候我们要恐惧，别人恐惧的时候我们贪婪。”。
我来简单说两个买入点：
第一个8月份，中美贸易战打的不可开交，大盘一度只有2700，那时候同学们分分钟都在朋友圈说要奔着2400去了，你敢买么？
第二个10月1国庆过节前，因为大部分人不敢持币过节，所以出货上证下探到了2900低点，过节后行情会变好么，你敢买么？
如果在第一个点买入，过了两个月就有7%的收益！
如果在第二个点买入，国庆过完的周末就有将近3%的收益！

2.逐渐积累价值投资的一般性规律
比如 部分公司出年报前会涨一波，叫金三银四。还有五穷六绝七翻身，金九银十等等，大势所趋，世间的事大抵如此。

迷茫之后
人到中年，不免迷茫，其实归根结底一句话：身体是自己的，公司是别人的。
下面给大家介绍一个最近看到的瞭望智库和吴晓波的专访实录，很有启发:
瞭望智库：
前阵子，中兴有位员工因裁员就含愤坠楼，这背后反映了什么行业问题？
吴晓波：
中国每天都有很多公司在裁员，很多人被减薪或者失业。
之所以受到如此高度关注，无非因为发生在中兴。
中兴这次事件体现了这些通讯公司职场竞争的残酷性。
举个例子，华为招工有两项特别要求：第一个，必须要工作5年以上；第二个，40岁就可以退休。
这说明它对人才的挤压性使用是别的行业所罕见的。
现在，中国的BAT员工平均年龄是27岁。40岁左右，除非你是高管，如果只是普通员工，你很可能要被淘汰。而且，很多公司有10%的强制性末位淘汰。
实际上，这是中国制造业之所以能够保证野蛮战斗力的原因之一。中兴这件事情并不能代表什么东西，只能提醒中兴公司：你们需要有一支心理老师队伍，或者一个专门的部门来帮助大家缓和心理上的问题。
悲剧会不会重演？
瞭望智库：
我的一些互联网行业的朋友看到这个消息感到非常不安——现在处于互联网行业飞速发展的阶段，我们可以拿着高薪，每天都会有猎头hr找我们跳槽。
但是，等我们步入中年将何去何从呢？悲剧会不会重演？
吴晓波：
15年前，我在一个报社当副总编，工资是两万块人民币。现在全中国最好的报社的副总编工资也就是两万人民币。这15年来，中国的M2已经从12万亿左右增加到160万亿。那么，你怎么没看到报社副总编跳楼呢？
而且，这15年，这些互联网人抢了我们报社的很多生意，对不对？所以，为什么报社的人不跳楼，而互联网的人要跳楼？这毫无道理。
每个人职业生涯中都可能出现波动期，需要我们做一个认真的选择。十年后，这个问题可能会越来越严峻。
现在有人工智能，它可能会替代很多东西，可能很多“码农”甚至陆家嘴的很多证券分析师、精算师、会计师都会失业。那么，陆家嘴每天都有人跳楼？不会。
人总会在绝境中给自己找一条路走下去的，大家要做好心理建设才是最关键的。

10条建议
1. Wake Early
2. Daily Exercise
3. Review and Rewrite your goals
4. Read and Listen to Motivational Material
5. Visualize the Day Ahead
6. Write a “To-do” List
7. Check the News Headlines
8. Take a Multivitamin
9. Tidy up
10. Take time to look good

那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员











文章大纲看图说话----序西安公司杭州总部上海BMS 学习出差路上阶段性成绩技术积累身体健康消费支出那些年我写过的总结

看图说话----序
2019年是学习节奏缓慢的一年，生活工作中会遇到很过破事，处理不好就会让人放慢节奏，想要的太多，诱惑也太多，难免堕落。蒋方舟说，人一旦堕落哪怕是短暂的几年，上帝就会以更快的速度收走你的天赋与力量。人常说30而立，立不住，那就保持简单，保持移动。人常说不能老呆在舒适区，那是因为，你怎么知道没有一个更舒适的地方在等你呢？
这篇文章大部分都是图，大家做好心理准备。
新年伊始祖国大好河山，我喜欢登山，因为山高人为峰，让人很有成就感。

回母校，清华桥上我想起了曾经吃饭大学的食堂。

动态血糖仪测试，亲身试验，陕西人吃面不能太多，吃完再喝一碗面汤，那血糖飙升到12 -345 ，简直不能太危险。遂自学加百度，写下了这篇博文：
连续血糖监测(CGM) 初探

陕西人的最爱，扯面，108合一

见识我爷的勋章，共和国大庆，老爷子全国劳模，也是深藏功与名，那个年代的人，需求简单，不求闻达于诸侯，国家人民需要的，就是我需要的。
这个年代的我想法太多，行动太少。。。。

见识了国家健康医疗大数据中心，惠民惠企惠政惠医，这十几个大屏展示效果真是刚刚的。


西安公司
公司在21楼，楼上的风景很好，边上还有公园，吃完饭没事的时候可以去遛弯。
在公司从早到晚，我在这里的时光多于陪我媳妇。


西安近些年来，污染严重，不知为何一直不能解决。每每冬天雾霾，我总想起火星救援里面的台词：I’m the first person to be alone on an entire planet.



公司边上的云水公园，除了冬天，其他时候景色宜人，中饭后，常来遛弯消食，路上针砭时弊，留下很多美好的记忆。





杭州总部
杭州总部在钱塘江边，风景也很好，加班完，晚上还可以去钱塘江边跑步，不过杭州总下雨。如果加班太晚，晚上也没有力气。
公司总部挂了很多许老师的"世界名画" 这张简直精髓，我忍不住cosplay 一下。

杭州卫生 信息中心学习

公司的，早上，傍晚和午夜。



钱塘江边小跑一次，发现似乎宝刀未老，锻炼是重在坚持。
每天锻炼30分，
健康工作100年，
向天再借500年，
还完房贷，
幸福生活一辈子。


开完年会，我们去钱塘江边喝酒。

杭州市政府吃了个爆甜的句子----爆橘


上海BMS 学习
为啥单独把这个列出来，因为这个公司高端到，两个中国人面对面开会，都不想说中文，因为还有全球的研发中心在听。


出差路上

2019年飞了18次，每一次出差都是对心灵的考验。还好目前都是短差。我还挺喜欢这种新鲜的感觉。
偶尔换换地方生活也不错。





阶段性成绩
生命即将迈入奔四，尤其35岁，是技术人的分水岭。
35岁，对于很多工程师而言是个坎，很多工程师懒得搞技术了，就另谋生路去做产品、售前和项目管理，现在只有云计算售前有行业红利，收入暂时高的惊人；而产品经理是在职场冒险，项目管理一直是苦力活。这些另谋生路的朋友，长期看还不如固守IT技能的基本盘。
35岁的裁员潮，其实被淘汰最多的不是干活的工程师，而是基层管理岗位。如果是带头干活的组长经理，就算被裁了还能找到工作；老工程师不能和应届生拼手速拼加班强度。
计算机有很深的理论体系，这是我们这些老工程师构筑经验壁垒的好机会，这套润物无声的理论体系，怎么沉浸下来进入自己的体系呢，写写博客，写写代码，多积累，唯手熟尔。
技术积累
开博10年，总体还算是说的过去，期待能有厚积薄发的那一天。希望 我的2020年能够完成《自然语言实战入门》这个课程的总体ppt 以及视频、博客。
付费专栏：自然语言处理实战入门
付费单篇系列：自然语言处理实战
视频课程：自然语言处理实战入门
免费专栏：简单NLP分析套路
目前，主要是在csdn 上面发发，今年尝试将一些干货写成付费的，发现还是看的人少，可能水平有限吧，后面我还是得坚持下去。很多平台都设置了可以同步，这个功能很好，懒得复制粘贴了。



身体健康
尝试了一下 健身房的健康指数测量器，还有美年大健康的体检。主要就是几个原则：
少熬夜，多运动，戒烟限酒，保持积极的心态，说着容易，做到那那么容易

消费支出
看来主要支出都是倒腾还房贷了。支付宝绑了，信用卡，这俩消费有重叠



最后放一张杭州的广告牌，共勉




那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员

2019年：视线所及只剩生活

2019 初入IT十年（下）---- 视线所及只剩生活











题目：
讨论帖：
点击打开链接


int main()
{
switch (getchar() - '0')
{
case 2: puts("3"); break;
case 3: puts("25"); break;
case 4: puts("253"); break;
case 5: puts("3121"); break;
case 6: puts("46651"); break;
case 7: puts("823537"); break;
case 8: puts("16777209"); break;
}
#include <stdio.h>
#include <math.h>
size_t apple(size_t b)
{
    return b>0?pow(b,b)-(b-1):0;
}
int main()
{
    printf("%d\n",apple(8));
    return 0;
}



void apple(short bear, short apple_sum, short count){
	if(count == bear){
		return;
	}
	apple_sum += pow(count,count) - count + 1;
	count++;
	apple(bear, apple_sum, count);
}
2.
讨论帖子：
http://bbs.csdn.net/topics/391830032


void print(vector<char>& vData)
{
vector<char>::iterator it = vData.begin();
for(; it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '7' || *it == '8' || *it == '9')
{
cout<<" - ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '4' || *it == '8' || *it == '9')
{
cout<<"| |";
}
else if(*it == '5' || *it == '6')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '1' || *it == '7')
{
cout<<"   ";
}
else if(*it == '*')
{
cout<<"*";
}
else
{
cout<<" - ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '6' || *it == '8')
{
cout<<"| |";
}
else if(*it == '2')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '8' || *it == '9')
{
cout<<" _ ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
}

int main()
{
int n, i, k;
while(cin>>n)
{
i = 2;
if(n < 2)
continue;
vector<int> vData;
while(n >= i)
{
if(n % i == 0)
{
n = n / i;
vData.push_back(i);
}
else
{
i++;
}
}

vector<char> vRes;
int vDataSize = vData.size();
for(k = 0; k < vDataSize; k++)
{
stack<int> temp;
while(vData[k] > 0)
{
int value = vData[k] % 10;
temp.push(value);
vData[k] /= 10;
}
while(!temp.empty())
{
vRes.push_back(temp.top() + 48);
temp.pop();
}
vRes.push_back('*');
}
if(!vRes.empty())
{
vRes.pop_back();
}

print(vRes);
}
return 0;
}

﻿﻿
﻿﻿









文章大纲前言揭开深度学习的面纱从竞技场杀出的世界级创业者两国演义和七巨头人工智能发展的四波浪潮乌托邦、反乌托邦和真正的人工智能危机一个癌症患者的思考简评

前言
随之而来，拥有世界最庞大手机用户群的中国得以最快地积累移动应用数据。移动用户基数使得中国的数据优势是美国的3倍，移动食品配送是美国的10倍，移动支付是美国的50倍，共享单车设施是美国的300倍。而利用这些丰富的数据资源，中国的计算机视觉、无人机、语音识别、语音合成和机器翻译公司，成为全球价值最高的创业企业。
相比人工智能，人类的优势在于创造力和同情心。让人工智能做它擅长的，我们可以创造更多有人情味的职业和岗位，可以有更多富有同情心的医护人员利用人工智能进行医疗诊治、护理，可以有超过现在10倍的老师来帮助孩子在这个新世界获得生存能力并勇敢地茁壮成长。

揭开深度学习的面纱
深度学习是所谓的“狭义人工智能”（narrow AI，或译作“弱人工智能”）——仅用于在特定领域能做出决策、预测和分类的人工智能应用。这已经能产生巨大价值，但仍远远未成为科幻片里的“通用人工智能”（general AI，或译作“强人工智能”）——人类能做的，人工智能都可以做。
深度学习最自然的应用领域是保险、贷款之类的金融业务，因为借款人的相关数据非常多（信用评分、收入、信用卡近期使用情况等），而最优的目标（降低还款违约率）很明确。更进一步的话，深度学习还可以进行自动驾驶，帮助车辆“看”到行驶的路况，如识别像素组成的形状（比如红色圆形），判断它和什么有关（比如红灯“禁行”），以此信息来做出决策（刹车并停车），以达到期望的结果（用最少的时间把我安全送到家）。
人们听到深度学习就兴奋，是因为它的核心能力——识别规律、得出最优解、做出决策可应用在很多日常问题上。
人工智能新时代，谁能保持领先
西方国家点燃了深度学习的火炬，但最大的受益者将会是中国，这种全球性的变化是由两方面转变引起的：从发明的年代转变为实干的年代；从专家的年代转变为数据的年代。
实干的年代
深度学习的先驱吴恩达认为，人工智能类似于第二次工业革命中电力的发明[插图]，本身是一项突破性的技术，一旦被大幅采用，就能革新许多不同的产业。就像19世纪的创业者很快学会运用电力烹饪食物、照亮房间、启动工业设备，今天的人工智能创业者也运用深度学习来落实各种创新应用。人工智能许多抽象的研究工作大都已经完成，研究中遇到的困难大都也已解决，现在是创业者“撸起袖子加油干”，把深度学习算法转换为持续经营的事业的时候了。
数据的年代
现今，成功的人工智能算法需要三样东西：大数据、强大的电脑运算能力，以及优秀（但未必顶尖）的人工智能算法工程师。想在新领域善用深度学习的能力，这三者都是必要的。但在实干的年代，这三者当中最重要的还是数据，因为当电脑的运算能力和工程师的能力达到一定门槛水准之后，数据量的多寡就成为决定算法整体效能与精准度的关键所在。
中国的优势
今天，若想妥善利用人工智能的能力（即21世纪的电力），也需要四项要素：大量的数据、热切的创业者、人工智能科学家，以及对人工智能友善的政策环境。比较各国在这四项要素上的优劣，可以预测未来人工智能新世界的发展情况以及权力天平向哪边倾斜。
人工智能时代真正的危机
人工智能产业倾向于“赢家通吃”，这种倾向将会加剧获利与财富集中的问题。
人工智能时代的新世界秩序
人工智能时代的世界秩序，将会结合下列因素进一步发展：“赢家通吃”的经济，财富空前集中在中、美少数几家公司。我认为，这才是人工智能造成的最大的潜在威胁，因为严重的失业和财富分配不均问题将会造成社会不稳定

从竞技场杀出的世界级创业者
美国企业界对中国创业者掀起的全球浪潮尚未做好准备，因为他们从根本上误解了“克隆家”的成功秘诀——王兴的成功并不是因为他只会借鉴，而是因为他是从血与火的竞争中熬炼出来的冠军角斗士。
“成二代”和“穷二代”
中国经济的飞速崛起没能明显减轻这种匮乏心态，反而在某种程度上加强了大众对新创富机会的极端渴望。很多中国人都曾目睹在政策和法规与市场竞争的状态不充分匹配时，产业、城市与个人是如何在崛起和倾覆间徘徊的。改革开放的总设计师说“先让一部分人富起来”[插图]，才能进一步发展。闪电般的发展速度在某种程度上加重了部分人的焦虑感：如果不抓住新的机会，进入新的市场，就只能眼睁睁地看着身边的人变富。以上三个要素：接受借鉴的文化环境、匮乏心态，以及为抓住创富机会而愿意投入有前景的新产业的迫切，构成了中国互联网生态系统的心理基础。
什么都可以模仿
中国的第一个搜索引擎是麻省理工学院物理学博士张朝阳建立的。他在美国目睹了互联网的早期腾飞，想在祖国带动类似的发展。于是他带着麻省理工教授提供的资金返回中国，试图建造中国互联网的核心基础设施。但是，在和雅虎（Yahoo!）的创办人杨致远面谈之后，张朝阳转换了焦点，打算做一个简体中文的搜索引擎和入口网站。他把这家创新公司命名为“Sohoo”（搜乎），直白地结合了中文“搜索”里的“搜”字，代表这家公司的主要功能，并且仿效了美国公司“Yahoo”的尾音。
模仿到底是一种阻力，还是助力？
硅谷投资人深信，纯正的创新心态是打造谷歌、Facebook、亚马逊、苹果等一流公司的基石。“不同凡想”（think different）的能力，驱动乔布斯、扎克伯格、杰夫·贝佐斯等人打造出了改变整个世界的公司。
谷歌与百度：黄页与购物商场
我在谷歌的4年期间，这样的奋战层出不穷。平心而论，谷歌总部给予我们的自由度，已经远大于大多数硅谷企业给其中国分公司的自由度，我们也利用这一点，发展出许多针对中国需求而优化的产品特点，赢回不少谷歌中国前几年流失的用户。但是总部一直拒绝过多代码“分支”，我们发展每一项新功能，都要与总部打一场硬仗，这让我们动作迟缓，也让我们精疲力竭。许多谷歌中国的员工厌倦了和总公司的斗争，沮丧地离开了。
硅谷大腕为何在中国变成“纸老虎”
我在美国公司工作多年，又花了许多年给它们在中国的竞争对手做投资，我发现硅谷进军中国的方式才是它们在中国市场上失败的重要原因，它们输在了自身的策略与管理上，与中国政府的管理并无关系。美国公司把中国市场和其他市场一视同仁，把中国企业当作一排排等待它们征服的对手，等待着把这些企业从市场的“生死簿”中一个个勾选掉。他们不投入资源，没有耐性，也不给中国团队自由，让团队没办法和中国顶尖的创业者（也是全球顶尖的创业者）竞争。他们认为，在中国市场的主要工作就是向中国用户销售目前已有的产品。而实际上，他们应该根据中国用户的特性与需求，针对性地调整已有产品，或是从头打造更适合中国市场的新产品。他们对产品本地化的抗拒降低了产品迭代的速度，使得本地团队举步维艰。
天生“精益”的创业斗士
“精益创业”方法最早出现于硅谷，《精益创业》（The Lean Startup）[插图]一书的出版让这个方法流行起来。“精益创业”的核心理念是：创始人不知道市场需要怎样的产品，只有市场才知道。因此，创业公司不应该花大量时间，投入大笔金钱，默默地开发自己眼中完美的产品，而是应该快速推出“最小可行产品”（minimum viable product），以此测试市场对该产品不同功能的需求。互联网创业公司能根据用户反馈获得实时数据，立刻开始迭代产品：丢弃用户不用的功能，加上需要的新功能，继续在市场中试水。
王兴的蜕变
在“千团大战”中，王兴用上了他所有的技巧。他在2010年年初创立美团，招募了他先前创立校内网和饭否网时身经百战的老员工来领导公司。他不再采用过去原样借鉴Facebook和Twitter的手法，而是打造了更加迎合中国用户偏好的用户界面——把信息填满了用户界面。
美团建立时团购大战刚开始升温，竞争者在一年时间内为线下广告砸的钱超过了10亿元人民币。当时的主流思想是要想在众多竞争者中脱颖而出，公司必须通过融资获得一大笔钱，并把这笔钱花在广告和补贴上以赢得用户。更高的市场占有率可以融更多的钱，进而重复这个循环。热情的投资人在数千家几乎完全相同的公司上投入了大笔资本，中国的城市居民用低到不可思议的优惠价格，成群结队地在餐馆内用餐。这几乎是中国的创投界在招待全中国人吃晚餐。
创业者、电力与燃料
王兴的故事并非只是“借鉴致富”，他的创业故事背后是中国互联网科技生态系统的进化史，这个生态系统最大的资产就是一批坚毅勇敢、百折不挠的创业者。他们先是在本土节节击退硅谷巨头，学会了如何在全球最残酷的创业环境中生存下来，然后利用中国互联网革命和移动互联网的爆炸式发展，为现在由消费带动的中国新经济注入了活力。这些成就固然了不起，但与这些创业者即将用人工智能带来的改变相比，则是小巫见大巫。互联网在中国的萌发，就像电报的发明，缩短了人与人之间的距离、加速了信息流通、促进了商务拓展。而人工智能在中国的萌发，则会像电力的应用那样，为各行各业赋能，改变市场格局。在竞技场上磨炼过的中国创业者现在看到了这项新技术的潜力，已经在寻找能借此获利的产业与应用。
互联网的未知海域
中国的科技创业公司没有这么好的条件，它们身边满是凶猛的竞争者，虎视眈眈地准备对它们现有的产品逆向分析。它们必须用规模、资金以及劳动力的效率来跟竞争者拉开差距——疯狂烧钱，依靠大量廉价劳动力来运作它们的产品，使它们的商业模式难以复制。这是中国互联网世界的重要特质，是脑袋里根植着硅谷正统观念的美国分析师们无论如何也无法理解的特质。
人工智能时代的数据王国
送外卖、汽车维修、共享单车、街头便利店等行业的互联网化，使中国拥有了人工智能时代的大量关键资源——数据。靠着实地苦干，中国在这方面远远超越了美国，成为全球最大的数据生产国（并且差距还在日益扩大），为中国在人工智能实干年代的领导地位奠定了基础。
轻量与重磅
O2O展示了硅谷与中国之间更深层的区别，我称为“轻量”（going light）和“重磅”（going heavy）。这两个词指的是互联网公司在一项产品或服务方面的涉入有多深，还代表着公司连接线上与线下世界时的垂直整合程度。这一模式的选择在人工智能的实干时代影响会更大。打算颠覆新产业时，美国的互联网公司往往采取“轻量”模式。它们普遍认为，互联网的根本力量在于分享信息，消除知识鸿沟，用数字的方式连接大众。它们身为互联网公司，坚守着这股力量。硅谷创业公司会自己建立平台，但会选择让实体企业处理现实世界里的工作。它们希望通过智取战胜竞争对手，用优雅的代码解决信息问题。
愿意重磅——花钱、管理劳动力、提供跑腿、建立规模经济——改变数字经济的同时也改变了实体经济。中国的互联网更深入地渗透了大众的经济生活，并且影响着消费趋势及就业市场。在麦肯锡公司（McKinsey &Company）2016年做的一项调查中，65%的中国O2O用户说移动应用让他们在吃饭上花了更多的钱。另外，分别有72%和42%的用户说移动应用增加了他们在旅行和交通上的消费。
模糊的界限与美丽新世界
世界排行前五大的新创公司，包括蚂蚁金服、小米、滴滴出行、Uber和美团网，中国已经占有四席，这五家公司都是数据驱动+AI
但是中国还有未被发掘的更大宝藏。如同长期埋藏在地下的有机物质最终变成推动工业革命的化石燃料一般，中国互联网公司利用现实世界中丰富的互动获得了推动其人工智能革命的庞大数据。这个多维世界的每一个维度都为数据的增加提供了新的增长点，这些规模空前的数据能够细致描绘现实世界用户的消费及出行习惯。O2O业务的爆炸式增长提供了海量的用户线下生活数据：每天的餐饮、按摩、美容美发及其他日常活动的时间、地点和内容。移动支付打开了实体世界消费的黑匣子，给这些公司提供了消费者行为精确、实时的数据图。共享单车在各个城市投放的物联网交通器材，追踪记录了数千万前往公司、商店、住所及初次约会地点的行程。这些数据在量与质方面都远远胜过了Uber及来福车（Lyft）之类公司手中的数据。

两国演义和七巨头
毫不夸张地说，1999年以前，中国科技人员对人工智能几乎一无所知。那一年，我到中国科学技术大学做讲座，给同学们介绍刚成立一年的微软中国研究院在图像识别研究上的进展。这所大学的工程学院在全国名列前茅，但它不在北京，坐落于相对偏远的安徽省合肥市。
这些学生手里拿的课本是当时中国最好的教材，虽然大多数版本老旧、翻译不佳。在当时，优秀学生很难出国读书，除非有全额奖学金，在互联网没有普及的校园里，泛黄的教科书和偶尔来访的学者的讲座，是他们接触全球人工智能研究的唯二途径。20年过去，现在一切都不一样了。
人工智能超级大国的那些事
在21世纪要建设人工智能超级大国，需要具备四个条件：大量的数据、执着的企业家、优秀的人工智能科学家和有利的政策环境。中国创业公司的竞技场选拔出了世界上最精明强悍的企业家，中国的另类互联网世界创造了世界上最丰富的数据生态环境，再加上另外两项助力——人工智能专家的涌现和中国政府的政策支持，在这个人工智能实干的年代，硅谷的优势将不复存在。
诺奖得主与无名工匠
费米和曼哈顿计划代表了在专业知识领域，质量高于数量的时代。20世纪三四十年代是核物理学基础学科取得突破的时代。为了实现这些突破，一个恩里科·费米比一千个普通的物理学家都重要。这个时代的美国确立在世界上的主导地位，很大程度是由于吸引了像费米一样的天才。但并非每次科技革命都是这种模式。通常，基础领域的突破出现后，发展的重心会很快从顶尖科学家转移到无名工匠，即有足够专业能力将这种新技术应用于解决不同问题的工程师，尤其是当技术突破性成果的应用范围遍布整个社会经济体系，而非集中于某几个实验室或者武器系统的应用时。
人工智能的电网、电池之战
“电网”式的目标就是将机器学习的力量转化成标准化服务，可以由任何公司购买，无论是达成学术目的还是个人使用都可以通过云计算平台实现共享，甚至可以免费使用。这个模式中，云计算机平台就是电网，作用是根据用户提供的不同数据，实现复杂机器学习最佳化。“电网”式可以降低专业门槛，提升云人工智能平台的功能。连入“电网”就能让有大数据的传统公司轻易使用到最棒的人工智能，而不用将优化人工智能作为核心工作。
相对较小的人工智能创业公司则选择了另一条路：为各行各业打造具有高度针对性的人工智能“电池”，这时“电网”还没有成形。这些创业公司靠的是深度而非广度。它们不打算提供通用型的机器学习能力，而是为特定目的打造产品、打磨算法，如医疗诊断、抵押贷款和自动无人机等。它们把宝押在了传统商业日常运营中，众多琐碎细节无法很好地跟通用网络契合在一点上。准确地说，这些创业公司不是要让传统公司“用标准的”人工智能，而是为传统公司量身打造能即刻融入公司正常流程的人工智能。
中国芯片的机会与挑战
现在，随着传统计算机程序逐渐被人工智能算法替代，需求再次发生了变化。机器学习需要快速运行复杂的数学计算，这一点是英特尔或者高通公司的芯片都不曾注重的。于是，以设计电子游戏所需的高性能图像处理芯片闻名的英伟达（Nvidia）乘虚而入，图像处理背后的数学原理与人工智能算法的需求十分匹配，英伟达也因此成了芯片市场的新星。当英特尔犹豫不定时，仅百度一家公司从英伟达购进的深度学习芯片的数量就达到向英特尔采购数量的4倍。2016年到2018年年初，英伟达的股价翻了10倍。
人工智能发展的四波浪潮

目前，人工智能革命分为四波浪潮：互联网智能化（Internet AI）、商业智能化（business AI）、实体世界智能化（perception AI）、自主智能化（autonomous AI）。每一波浪潮都将以不同方式利用人工智能的力量，颠覆不同产业，让人工智能更深层次地融入我们的生活。
第二波浪潮：商业智能化
第一波人工智能浪潮的基础是给互联网用户的浏览数据贴标签，而商用人工智能则是给传统公司数十年来积累的大量专业数据贴标签，如保险公司理赔事故中鉴别保险欺诈，银行核发贷款时记录还款率，医院保存医疗诊断记录及患者存活率等。
这些细微的关联性往往没人能解释清因果，例如为何在星期三取得贷款的借款人往往能较快地偿还贷款。
请到算法诊所就诊
商用人工智能并非只能用在跟钱有关的领域，它同样可以用在数据驱动的公共服务上，让许多之前负担不起这些服务的人享受科技带来的红利，促成高质量服务大规模推广。这方面，最具前景的领域之一是医疗诊断。
曾经在硅谷及百度从事深度学习工作的中国人工智能研究人员邓侃，创立了大数医达科技公司，该公司研发了专门训练医疗领域的人工智能算法，使它们成为能够部署在全国各地的超级诊断师。它们并不想用算法取代医生，而是要辅助医生诊断。算法在诊断流程中扮演“导航”的角色，用大数据规划最佳路径，但人类医生会主导最终的判断。诊断的范围随着算法得到的信息增加而缩小，这时更详细、高度确定的数据可以帮助判断症状的起因，以及其他诊断结果的正确性及患病概率。这款应用给医生的建议，是依靠其超过4亿条医疗记录（并且还在持续扫描最新医学文献）的数据，把全球顶尖医学知识平均分配在医疗资源不均衡的社会中，让所有医生和护士都能聚焦在机器做不到的人类工作上，如使病患感受到关怀，更人性化地和病患分享诊断结果。
看不见的法庭助手
科大讯飞率先把人工智能应用在另一个资源和能力分布高度不均的领域——司法界。在上海进行的试点中，科大讯飞使用以往案例数据，向法官提出有关证据及判决的建议。该公司开发的证据交互参照系统，使用语音识别与自然语言处理技术来比较所有证据，如证词、文件及背景资料等，并找出其中的矛盾点，同时提醒法官注意这些有争议的地方，让法院审理人员可以进一步核实。量刑时，法官可以把被告的犯罪记录、年龄、造成的伤害等相关信息输入判决辅助人工智能系统。该系统存储了大量的判决记录，可以从类似案例中做出有关量刑或罚款的建议。
OMO驱动的教育
现行的教育体系大致上仍然是19世纪的“工厂模式”：所有学生在同一地点、同一时间，以相同速度及相同方式学习。学校采用“流水线”模式，让孩子一年升一级。在老师投入教学、辅导与评估学生的时间与精力非常有限的情况下，这种模式是有道理的。但现在人工智能可以消除这些限制，人工智能的感知、识别与建议能力，能够针对每个学生打造不同的学习流程，也可以让老师腾出更多时间，对学生提供一对一辅导。人工智能驱动的教育有四种应用场景：课堂教学、家庭作业与练习、考试与评分、量身打造的家教辅导。
公共数据与个人隐私
这样收集数据可能会令许多美国人感到不安，他们不想暴露太多的个人隐私。但中国人更容易接受自己的面孔、声音及购物选择被记录与数字化，更愿意用个人的信息来换取便利。中国的各大城市已在使用大量的摄影机与传感器网络。这个监控网络把视频数据直接导入负责管理交通、公安以及紧急服务的优化算法中。
深圳制造
现在，中国制造业的最大优势不是廉价劳力，印度尼西亚及越南之类的国家的工资更低。中国制造业现在的最大优势是无可匹敌的供应链灵活性，以及能够研发出新器材的原型并且量产优秀的工程师。
谷歌模式与特斯拉模式
谷歌在收集这部分资料的过程中，采取缓慢稳定的步速，他们用小规模车队装备高级传感设备，上路测试、收集数据。特斯拉则在其商业车款上安装较便宜的设备，让车主在使用特定自动驾驶的同时，也为特斯拉收集了数据。这两种不同的模式导致谷歌与特斯拉的数据收集量产生了巨大差距。截至2018年6月，谷歌花了8年收集到800万英里的现实世界驾驶数据，而特斯拉仅用了2年就收集到12亿英里的现实世界驾驶数据。
中国的特斯拉模式
雄安新区将成为全球第一个从开始就容纳自动驾驶汽车的城市，百度已经和当地政府签约，打造“人工智能城”，聚焦于交通管理、自动驾驶汽车及环境保护。混凝土中需要加入传感器，交通信号灯装备计算机视觉硬件，十字路口可以知道每一位行人的年龄，泊车所需的空间明显减少。当人人都能随时随地召唤自动驾驶的出租车时，甚至可以把停车场改成城市公园。
围绕自主人工智能技术的较量
美国和中国在自动驾驶汽车这个领域胜出的机会是五五开，至于自主无人机之类的硬件密集型应用领域，中国将具备优势
征服当地市场&武装当地公司
中国的公司避开了直接竞争，转而投资硅谷公司试图消灭的当地创业公司。比如在印度及东南亚，阿里巴巴和腾讯投资了当地与亚马逊等巨头竞争的本土创业公司，这是中国智慧的体现。马云等中国的创业家深知，强龙不压地头蛇。因此，在进军国外市场时，中国的公司不会试图消灭当地的创业公司，而是与之组成联盟。
从中国市场打到国际市场的共享出行
中国公司的全球化策略在共享出行市场已经启动。这可以总结为人工智能全球化的另一种模式：结合人工智能技术与当地的数据，对当地创业公司赋能。这种以合作为基础，而非征服的模式，或许更适合把人工智能这类需要顶尖工程师、由下而上收集数据的技术推广至全球。
人工智能力量进入我们的世界后，真正的分歧不在国家之间，而在每个国家内部。

乌托邦、反乌托邦和真正的人工智能危机
谷歌首席未来学家雷·库兹韦尔（Ray Kurzweil）设想了一个极端的未来，他认为人类和机器将完全融合。他预言，我们会将自己的思维上传到云，通过放入我们血流中的智能纳米机器人不断更新我们的身体。而现在距离实现强人工智能只差10年，2045年，我们将会迎来奇点时刻。
DeepMind创始人哈萨比斯则预言，创造超级智能可以让人类文明解决目前无解的难题，如为全球变暖和不治之症带来绝妙的解决方案。
反乌托邦阵营中的大部分人其实并不担心人工智能会像《终结者》（The Terminator）等科幻电影中想象的那样接管世界，他们真正恐惧的是如果人类本身成为超级智能实现某一目标的障碍，例如改变全球变暖，它们可以轻易甚至是无意中将人类从地球上抹去。对于想象力远超人类的计算机程序而言，抹杀人类根本不需要像电影中持枪机器人一样粗鲁。对于化学、物理和纳米技术的深刻理解，让它们可以用巧妙得多的方式立即完成任务。
盲目乐观的终结
1980年到2016年，随着ICT的收益越来越多地集中到前1%的人手中，美国的精英群体在国民经济中的份额近乎翻倍[插图]。到2017年，站在美国金字塔尖1%的人拥有的财富几乎是下层90%的人拥有的总财富的两倍[插图]。而普通美国人的实际工资在30年中保持不变，最贫穷的美国人的工资还降低了[插图]。美国的工作岗位和工资水平停滞不前，ICT在其中发挥了多大作用？全球化、工会衰落和外包都是相关因素，但有一个特点很明显：ICT不同于蒸汽机和电气化，它“偏重技能”（skill-bias），通过打破信息传播障碍，增强了世界顶尖知识工作者的力量，而将中间许多人的经济作用缩减了一半。所以，有一件事越来越明确：没人能保证提高了生产力的GPTs还能为工人带来更多的工作岗位或更高的工资。
硬件：更好，更快，更强
人工智能会在三个催化剂的作用下加速自身的应用与扩散进程，这些催化剂在蒸汽动力和电力投入广泛应用时是不存在的。
第一个催化剂是人工智能算法的易复制性。
第二个催化剂是风险投资业（VC）的诞生。
如今，VC已是新技术商业化的一种常见投资方式。2017年，全球风险投资创造了1480亿美元的新纪录。
第三个催化剂是中国的影响力。
综上所述，我相信我们可以确定以下几件事：第一，在工业时代，新技术带来了长期就业机会增长和工资水平的增长；第二，新的GPTs依然很罕见且重要，应单独评估各个GPT对于就业的影响；第三，在被广泛认可的三个GPTs中，蒸汽动力和电气化同时推动了生产力和就业率提高，ICT提高了生产力却不一定增加就业；第四，人工智能也会是一种GPT，它偏重于技能，应用速度快（受到数字传播、风险投资和中国影响力的加持），这两个特性表明人工智能会对就业和收入分配产生不利影响。
人工智能的“可以”与“不可以”

体力劳动

脑力劳动
两类失业：“一对一取代”和“彻底清除”
换句话说，“工作任务分析法”研究的是机器一对一取代人类工人的可能性。而我是一名技术专家和早期风险投资者，我的专业背景教会我尝试以不同的方法解决问题。在职业生涯早期，我致力于将先进的人工智能技术转化为有用的产品。同时，作为风险资本家，我也投资和协助一些新的创业公司。这两份工作让我发现人工智能对工作岗位构成的威胁不只是“一对一取代”，还有“彻底清除”。
中美失业问题对比与莫拉维克悖论
著名科技评论家维韦克·瓦德华（Vivek Wadhwa）预测，智能机器人将削弱中国在劳动力方面的优势，制造业的春天将再次降临在美国，但不会为人类创造工作岗位。瓦德华写道：“美国机器人和中国机器人一样勤奋，而且都不会抱怨，也不会加入工会。”
与一般的观点相反，让人工智能模仿成年人高知识水平或运算能力比较容易，但要让机器人具备婴儿的感知和感官运动能力，则困难得多。本质上，人工智能是“演算的巨人，行动的矮子”。
担心算法还是担心机器人？
人工智能算法对脑力劳动的替代像是导弹空袭，但机器人对体力劳动的打击则接近于地面的堑壕战。长期来看，我认为中国和美国自动化的风险是相似的，但说到对变化的适应，中国的特殊经济结构将会为其争取到一定的时间。
随之而来的个人危机
自工业革命以来的数个世纪里，工作不仅是一种谋生手段，更是一种自我认可以及生活意义的源泉。当我们身处社会之中，需要自我介绍或介绍他人时，首先提到的就是工作。工作让我们过得充实，给人一种规律感，让我们和其他人联结。固定的薪水不仅是一种劳动报酬方式，也代表了个人对于社会的价值，表明每个人都是社会的重要成员。

一个癌症患者的思考
生活就像一套具有明确优化目标的算法：最大化个人影响力的同时就会最小化对该目标无益的任何事情。
你想在墓碑上写什么？
找到自己使命感最好的方法，就是想想自己死后墓碑上会写什么内容。
向死而生
面对死亡，最艰难的是面对无法重来的人生。治疗护士兼作家邦妮·韦尔（Bronnie Ware）记录了许多病人在弥留之际最常见的遗憾。面对生命的终点，这些病人清晰地回顾了他们曾经因专注于工作而忽略了生活。他们谈到，由于没有过上无愧于心的生活而感受到痛苦，后悔过于专注工作，意识到生活的意义是身边的人赋予的。没有人在回顾自己一生的时候会后悔没有工作得更努力一些，许多人后悔的都是没用更多的时间陪伴自己爱的人。
山顶上的法师
我们必须放低自己的姿态。我们必须在骨子里认识到自己的渺小，必须承认，在世界上，没有什么可以比与他人分享爱这个简单的行为更重要、更有价值。如果我们从这点出发，其余的事情就顺其自然了。这是我们真正实现自我的唯一方式。
第二意见和第二次机会
人类分辨变量之间关联的能力非常有限，需要基于少量最明显的特征——“强特征”做决策，基于简单特征对复杂疾病分期就是一个例子。再比如银行贷款时，银行调取贷款人的征信也是“强特征”，如贷款人的收入、房产价值和信用评级等信息。对于淋巴癌的分级，“强特征”只有肿瘤的数量和位置。这些“强特征”其实不能特别准确地将知识分类，它们只是为了便于知识在人类之间传承。目前，医学研究已经确定了数十个淋巴癌的其他特征，这些特征有助于更好地估计患者的预期寿命。但记住这么多因素之间复杂的相关性和预测的准确率，即使最优秀的医学生也无法做到。因此大多数医生在给患者进行癌症分期时，不会考虑那么多因素。
解脱与重生
这些领悟也令我重新审视人与机器、人类心灵与人工思维之间的关系。我回想生病的经历，从PET开始、到诊断、感受自身的痛苦以及随后的生理和心理上的恢复，通过这些我逐渐认识到，治愈我的药物包含两个部分：科技和情感。这两点都将成为人工智能未来的支柱（对此我将在下一章解释）。
我坚信的未来是由人工智能的思考能力，加上人类爱的能力构筑的。如果我们能够创造这种协同作用，我们就能在发扬最根本的人性的同时，利用人工智能无比强大的力量创造一个繁荣的世界。
危机考验与新的社会契约
即将到来的人工智能革命，无论是规模、速度还是对技术的偏向，都表明我们面临着全新且史无前例的挑战。即使失业状况没有向着最坏的方向发展，人工智能还是会继续大幅拉开互联网时代的贫富差距。在美国，我们已经开始看到一些工资停滞不前与贫富差距拉大导致的社会不稳定。随着人工智能在经济和社会其他方面的深层次应用，这个趋势将会速度更快、涉及的范围更广。历史上，就业市场最终能依靠市场的力量找回平衡，但是这一次人工智能来得太凶猛，我们必须面对失业和贫富差距加剧的考验。
3R：再培训、减时间、重分配
硅谷针对人工智能将引发的失业问题，提出三类解决方案：就业者再培训（retraining workers）、减少工作时间（reducing work hours）或重新分配收入（redistributing income）。每一类方案的出发点均是调节就业市场的某一个变量（技能、时间、报酬）。
全民基本收入
时下，最流行的再分配方案是全民基本收入（Universal Basic Income, UBI），其核心思想很简单——每个公民（或每个成年人）从政府那里定期领取收入补助金，这笔钱的申领没有任何附加条件。
人机共存：优化与人情
有关创意和关爱工作人工智能几乎不可能完成。考虑到这一点，我们应该积极发展STEM[STEM是科学（Science）、技术（Technology）、工程（Engineering）、数学（Mathematics）四门学科]教育，在教育上强调创意和思维的培养，这与下文要分析的关爱型工作，是未来教育的两个重点。在未来，由于人工智能的进步，左下角人工智能的圆圈会往右边扩张。[插图]人类与人工智能在未来可以共存
芬克的信与影响力投资
我们必须重新构思、重振企业的社会责任感（CSR）、影响力投资以及公益创业（social entrepreneurship）。过去，企业只有在时间、金钱都有富余时才会做这些事。企业家们很多时候会这样想，既然有钱了，就投资些房地产企业或初创公司，所谓社会责任感，就是捐些钱给留守儿童，还可以发发新闻稿，好好宣传一下。但是在人工智能时代，我们需要以更认真的态度来参与这些活动，同时也要拓展我们对这些活动的定义。国际大企业之前做的社会责任感项目都是传统慈善，例如环保和扶贫。如果想要应对人工智能时代的社会冲击，则需要更进一步的解决方案——为失业者创造大量的服务性工作岗位。
我希望未来能出现这样一个风投生态体系：将创造“人性服务”岗位本身视为美好的事业，同时也投资相关的产业，将资金引入能吸纳大量劳动力的、以人为本的服务项目中，如产后护理哺乳顾问、青少年运动教练、口述历史收集人、国家公园向导或者老年人陪聊等。这类岗位对社会、对个人都是有意义的，许多岗位还可以产生经济价值和营收。但投资这些创造岗位的公司不会像投资独角兽科技公司那样，可以获得100倍的回报。
政府的角色
对此我有不同的看法。我并不想生活在这样的社会：人工智能精英与世隔绝，坐拥惊人的财富，用最少量的施舍来保证广大的失业人员不闹事。我希望，我们可以共同创造出一个全员协同发展的制度，妥善运用人工智能创造出来的财富，建立更有人情味、更有爱心、更人性化的社会。
结束语 现在已是未来
乔布斯建议他们未必要预先规划好人生和事业。乔布斯告诉在座的学生：“（人生是由无数转折点组成的）你在向前展望时不可能将这些转折点串联起来，只能在回顾时将点点滴滴联系起来。所以，你必须相信这些点在未来都可能联结起来。”
人人都是撰写者
人工智能未来如何发展，最重要的因素是人类如何采取行动。
我们生活在地球上，不是仅仅为了埋头苦干，不断做那些重复性的工作。我们不需要只为了积累财富而忙碌一生，最终在过世后把财富传给下一代，然后让他们重复这一过程。如果我们相信生命的意义远不止物质上的盲目追逐，那么人工智能就有可能帮助我们揭开更深层次的意义。

简评
开复博士，毕业以后，或者说走向导师的路途上，看到的万事万物太宏观了。具体和宏观结合的点依然不可避免的走向宏观，以至于我看了书，觉得他说的什么都对。
当然，这也是问题所在










《AI进化论：解码人工智能商业场景与案例 》
数据原作者：亿欧智库
简评：亿欧智库的报告、书籍总是令人印象深刻受益匪浅，亿欧坚持使用数据说话，细分行业横向对比，向大家强烈推荐。
文章大纲业内人士力荐序第一章 跨越AI商业化“奇点”第二章 金融狂欢下的泡影第三章 积重难返？医疗AI的颠覆之路第四章 智慧安防：罪恶无处遁形第五章 自动驾驶：定义未来出行第七章 内容不再是人的专利第八章 AI赋能下的法律新格局第九章 AI进驻，教育革命即将到来

业内人士力荐
我们不再以旁观者的身份观看着变革的发生，每个人都有机会参与其中，成为这场最伟大技术变革的推动者，真正通过最先进的技术手段，来解决世界上最贴近民生的问题。
很多人问我为什么要做AI，我的答案可以追溯到五岁的时候，那时候我遇到了一个无解的问题——死亡，它让我恐惧。当我意识到这个问题是一个无解问题的时候，我开始想如何让人生更有意义，而那时我认为我需要做一个机器人，我希望可以创造另外一种智慧。也许AI对别人来说是一种选择，对我来讲则是一种使命，我希望用AI去造福人类，去创造有价值的东西。
——旷视科技创始人兼CEO印奇

序
当你认为自己理解了一件事情时，你只掌握了30%；当你可以把它讲给别人听时，则掌握了50%；当你可以将它编纂成书时，则掌握了70%。
谈及人工智能，公众层面的认知大多起源于2016年年初AlphaGo击败李世石的人机大战。但是，稍对人工智能有所了解的人士都知道，在这场机器取得胜利的大战以前，人工智能已经走过了长达60多年的“进化”历程，经历了所谓的“三起三落”。而在过去数十年，受益于机器学习算法的进步（尤其是以Geoffrey Hinton、Yoshua Bengio和Yann LeCun等人的理论为代表的深度学习），互联网服务积累的海量数据，摩尔定律的驱动，以及大公司依托其商业实力所建设的计算能力，人工智能似乎迎来了一个真正爆发的时机，最显著的表现是，其应用场景已经部分落地，并且正在创造着规模化的商业成绩。这是一项技术真正开始走向成熟的标志与信号，也让我们感受到人工智能的商业突破点可能即将到来。
站在中国的角度，当下的中国具备非常好的发展基础和环境，主要体现在：
（1）数据——中国作为商业大国和人口大国，产生的可计算数据量是绝对领先的；
（2）人才——中国正在培养大量的数学、计算机科学方面人才；
（3）商业环境——以互联网为代表的新经济，塑造了富有创新活力的商业氛围；
（4）资本——大量的风险投资基金（中国乃至全球）在中国市场投入了可观的资金，用以支持人工智能相关企业成长；
（5）政策——中国政府先后在政府工作报告和新一代人工智能发展规划方面做出了极大程度的政策支持，与人工智能相关的基础课程也即将开设于大、中、小学。
古代战场上一个人能对付两三个人就很了不起了，俗话说“双掌难敌四手”。但是在现在这个满世界都是廉价工具的环境下，处理起事务来“以一当千”完全有可能，几台电脑、几千行代码，可以轻松完成以前需要几万个人的手工作业，够震撼人心了吧？但我个人认为，信息革命30年，这些还只是前奏，等到人工智能发展起来，等到对大数据的分析趋向成熟，等到信息技术充分渗透到其他产业，等到传统的文科因为更多数据的到来而变成基础扎实的理工科……到那个时候，我们再回头来看，今天的这些成就，不过只是历史的先声。
由天宇亿欧公司副总裁 亿欧智库研究院院长2018年4月于北京

第一章 跨越AI商业化“奇点”
思维使我们在感知世界的同时，也在改造着世界。
看到这里，或许你会发现，不论是木棒，还是飞机，这些工具都是对人们行动的辅助，而非“模仿”。1956年，电视刚刚开始走入人们的生活，世界上第一台电子计算机ENIAC才刚刚问世，而那时已经有一群科学家在谈论“用机器模仿人的智能”这种仅停留于概念层面的话题，不由得令人感慨人类思维的广度。也正是在这场会议中，“人工智能”（Artificial Intelligence，简称AI）一词正式诞生，由此开启了此后半个多世纪的计算机科学、神经生物学等学科的发展进程，并引发了人类对于拥有意识与学习能力的“超级人工智能”的想象。这场会议叫作“达特茅斯会议”（Dartmouth Conference）。

第一节 揭开AI的神秘面纱

当人们大谈人工智能的时候，究竟是在谈什么？
在长达半个多世纪的人工智能研究历程中，大量学者对其概念进行了不同维度的界定。综合来看，大致可分为两类。第一类，从行为和功能的角度出发，定义人工智能机器的外在行为和能够实现的功能。
第二类，则将“人工智能”定义为一门新学科或新科学。
人工智能相关研究的最终目标，是由机器替代人类完成部分相对简单的重复性任务，使人类拥有更多时间进行创造性的劳动，享受更加高效便捷的生活，真正步入“智能时代”。
今天，不少人会狭隘地认为“人工智能=深度学习”。其实，假设我们身处于20世纪80年代，我们很可能会片面地认为“人工智能=专家系统”。事实上，人工智能在不同的发展阶段——不论过去还是未来——都会因技术进步或新技术的诞生，而进一步得到发展。就目前的技术发展而言，人工智能以机器学习、数据挖掘为两大技术核心，两者技术范畴上有所交叉。
机器学习又包含对抗学习等诸多种类，其中备受瞩目的就是深度学习。按照拓扑结构分类，深度学习可分为卷积神经网络、循环神经网络和全连接神经网络，并通过算法框架实现深度学习过程。在机器学习与数据挖掘的技术之上，实现了目前市场上最常见的三大技术应用，即计算机视觉、智能语音技术和自然语言处理


第二节 当资本位移，谁被颠覆

亿欧智库AI创投数据库显示，2012年至2017年间，中国共有439家AI企业获得投资，这439家企业大多数成立于2012年之后。2015年出现AI创业热潮，新创AI企业多达117家。2016年这一数字开始下降，2017年则仅出现27家AI新创企业。我们可以预见，2018年后AI市场的角逐竞争将在存量的AI“玩家”间展开

（2012—2017年获投企业）。[插图]图1-2 中国AI企业成立时间（2012—2017年获投企业）来源：亿欧智库AI创投数据库
2018年将可能是“大浪淘沙”的一年，预计将会有大批AI企业被淘汰。从行业角度来看，投资事件数量和投资金额最高的四大行业分别是企业服务、汽车交通、医疗健康和金融。

第二章 金融狂欢下的泡影
金融行业在发展过程中积累了大量的数据，包括客户信息、交易信息、资产负债信息等，放眼各垂直领域，金融被认为是人工智能落地最快的领域之一。
第二节 前台到后台的多点繁荣
随着人力成本的提高、客户消费体验要求的提升及人工智能技术的发展，劳动力密集型的传统客服已经不能适应市场需求，对客服提出了更高的要求。客户群体数目大，咨询频率高，人工客服成本高，难以满足需求，智能客服的出现可以帮助解决这些问题。据统计，智能机器人客服可以解决85%的常见客服问题，而一个机器人客服的花费只相当于一个人工客服的10%。
智能客服系统主要由四部分构成：客户、渠道、处理内容及对话管理系统，客户通过手机、电脑等渠道将文字、语音、图像等处理内容传递给对话管理系统，由系统内部处理后再将回复内容原路反馈给客户。智能客服系统通过自然语言理解、自然语言生成及知识图谱等技术，掌握客户需求，自动推送客户特征、知识库等内容，如图所示

智能营销是指在可量化的数据基础上分析消费者个体的消费模式和特点，并以此来划分顾客群体，精准地找到目标客户，然后进行精准营销和个性化推荐的过程。与传统营销相比，智能营销基于大数据、机器学习计算框架等技术，具有时效性强、精准性高、关联性强、性价比高、个性化强等特点。
金融的本质在于风险定价，风控对于金融机构和平台来说都是一种保障。
金融市场参与者众多，金融业务面临众多的风险挑战：
首先，群体欺诈多，大多是有组织、有规模“进攻”的；
第二，数据使用难，金融大数据积累多但非结构化；
第三，高价值数据少，目前风控采取的数据多为日常交易数据，央行征信数据依然很少；
第四，风险高，客群下沉，欺诈成本低；
最后，量大，人工无法大规模审核，成本高。
智能风控整个流程主要分为四个阶段：
第一阶段，数据收集，数据是智能风控的基础，主要数据来源为网络行为数据、授权数据、交易时产生的数据、第三方数据等；
第二阶段，行为建模，在这个过程中，需要对大量数据进行结构化处理，形成最有效的信用评估组合；
第三阶段，用户画像，通过前期的数据收集和行为建模，形成对每个用户的画像；
第四阶段，风险定价，主要包括行为监控、反欺诈违约和催收。

金融业务风控新挑战和智能风控基本流程见图2-5。 金融业务风控新挑战和智能风控基本流程
第三节 保险科技：AI全流程嵌入
第三节 保险科技：AI全流程嵌入中国保险业已经经历了六十多年的发展历程，主要经历了三个阶段。第一阶段为传统保险时代，1949年，中国第一家国有保险公司成立，拉开了中国保险业发展的帷幕。
第二阶段为互联网保险时代，伴随着整个信息技术革命的时代浪潮，互联网、移动互联网技术开始渗透到包括保险业在内的各个产业。
第三阶段为保险科技时代，随着信息技术的大发展，近两年越来越多的前沿技术也开始被应用到金融乃至保险行业。具体而言，区块链、人工智能、大数据、云计算、物联网等技术，开始逐步运用于产品创新、保险营销和保险公司内部管理等方面，保险的方方面面都开始从科技进步的红利中得益，企业通过创建新的平台、运用新的技术更好地为保险消费者服务。
数据显示，过去的十年间，中国保险行业在普及度和精密度上都发生了比较大的改变。年保费规模从2006年的5600亿元上升到2016年的3万亿元，年均增幅达20%，保险的深度及密度（保险深度：某地保费收入占该地GDP之比；保险密度：按当地人口计算的人均保险费额）也从2006年的2.6%及430元/人，快速增长至2016年的4.2%及2200元/人。但是保险大国并不等于保险强国，中国保险市场仍然存在着保险深度和保险密度不够、渗透率低、行业影响力不足等问题。
第四节 技术先行，应用多久落地
人工智能的滚滚洪流，正在影响金融领域的各个应用场景。我们认为，智能金融未来发展将围绕智能化、场景化和个性化展开。智能化为基础，可分为三个层次：
第一层次为Robot，即可以实现简单的数据收集整理工作（助理分析师）；
第二层次为Smart，即可以实现数据的简单分析（初级分析师）；
第三层次为Intelligent，即可以实现数据的决策支持和深度洞察（高级分析师）。

第三章 积重难返？医疗AI的颠覆之路


医疗，关乎民生之根本，涉及每一个人的身体与精神健康。今天，中国的医疗产业——涵盖医疗救护、医药、保健、生物技术等多个领域——已然是一个具有万亿元市场规模的大产业。2016年，中共中央、国务院印发的《“健康中国2030”规划纲要》中指出，到2020年，健康服务业总规模将超过8万亿元，到2030年达到16万亿元。

◆ 第一节 医疗变革时代的黎明

所谓“赋能”，字面意义上就是指为某个主体赋予某种能力或能量。人工智能技术与医疗产品、医疗服务的结合，事实上就是一种赋能现象，它不仅使得医疗生产活动成本降低、效率提升、效果增强，而且牵动整个医疗产业链发生新变化，如图3-1所示。[插图]图3-1 医疗产业链（部分）示意图

◆ 第二节 院内院外，医疗AI应用百花齐放

亿欧智库将医疗人工智能的应用场景分为七类，
分别是：
虚拟助理、
医学影像、
大数据辅助诊疗、
药物研发、
医院管理、
科研平台、
健康管理。
部分应用场景又存在多类子应用，涉及医院内部的各个流程，以及医院以外的各类健康相关环节，应用可谓“百花齐放”。


医学影像在当今医学诊断中具有举足轻重的作用，与医学临床的距离最近，而众多疑难问题尚未得到解决，由此医学影像成了医疗人工智能最热门的应用场景。综合来看，人工智能与医疗影像的结合，主要体现于运用图像识别技术实现三类核心功能：病灶自动分析与识别、影像自动勾画与自适应放疗、影像三维重建。


肺癌的早期筛查类产品是最多的。
一方面是由于国内在各类癌症中肺癌的发病率、死亡率均位居首位；
另一方面是因为以卷积神经网络为主的肺结节检测算法相对成熟。
以推想科技为例，其智能CT辅助筛查产品AI-CT完成一张肺部CT片的识别用时仅5秒，而人类医生通常需要十几分钟到半个小时；对于人的肉眼容易遗漏掉的三毫米以内的小病灶，AI-CT更容易识别，肺结节发现准确率高达90%。


上图展示的就是推想科技智能CT辅助筛查产品（AI-CT）的功能界面。其他国内典型企业代表有腾讯觅影、健培科技、羽医甘蓝等。[插图]图3-4 推想科技智能CT辅助筛查产品（AI-CT）功能界面来源：推想科技
由于AI+医学影像类产品涉及诊疗环节，属于CFDA（国家食品药品监督管理总局）规定的三类医疗器械目录范围，所以产品申报与认证过程十分严格，耗时较长。
目前基本成型的AI+医学影像产品大多数处于医院试用阶段，未来可见的业务模式主要有两类：
第一类，面向医院、体检中心和第三方医学影像中心，出售软件的使用权限（License），以及收取一定的技术服务费用；
第二类，向医疗器械厂商寻求合作，将软件与硬件设备捆绑销售，或将产品功能嵌入硬件设备中。近年来，国产医疗器械逐渐发展起来，与雅培、罗氏、西门子、瓦里安、医科达等海外公司产品形成竞争，“AI+医学影像”软件与医疗器械的结合，可帮助医疗器械厂商提供先进的软硬一体化解决方案，将大大提升医疗器械厂商的产品竞争力。

全世界每日产生的医疗数据量十分巨大，其中蕴藏着巨大的利用价值，然而由于各地区数据结构化程度低，缺乏统一的标准，并且有些地区的医疗数字化程度还很低。根据IDC Digital预测，截至2020年，全球的医疗数据量将达40万亿GB，其中约80%的数据为非结构化数据，如图3-6所示。[插图]图3-6 全球产生的医疗数据量预测（万亿GB）来源：IDC Digital



中国的医药市场，是一个不断增长的千亿元级消费市场。中康CMH的监测数据显示，2010—2016年间，中国零售药店市场总规模（以终端零售价格计算）年均增长率达10%以上，2016年总规模已达到3377亿元，如下图所示。围绕中国巨大的医药市场，处于产业链上游的药物研发环节被重点关注。[插图]图3-7 2009—2016年中国零售药店销售规模（亿元）来源：中康CMH



药物研发包含新药研发、老药新用、药物筛选、药物副作用预测、药物跟踪研究等方面的内容，以“研发成本高、周期长、风险大”为主要特点。

一款成功获批上市的新药，需要经过化合物研究、临床前研究、临床研究（临床Ⅰ、Ⅱ、Ⅲ期试验）、SCFDA或CFDA审批等流程，耗时往往达10年之久，平均研发费用约有15亿美元之多。
此外，药物研发的成功率较低，平均5000种合成化合物中，仅有1种能进入临床Ⅱ期实验。人工智能深度学习算法能够帮助科研工作者快速、准确地挖掘和筛选合适的化合物或生物，达到缩短新药研发周期、降低新药研发成本、提高新药研发成功率的目的。目前深度学习在药物研发方面的主要贡献包括两点：

第一，提高化合物的筛选效率，优化化合物构效关系（即药物的化学结构与药效的关系）；
第二，同一种药物的不同晶型在外观、溶解度、生物有效性等方面可能会有显著不同，深度学习算法能够辅助预测小分子药物晶型结构，以把握药物的稳定性、生物利用度及疗效。

目前，人工智能的主要成果体现于抗肿瘤药、心血管药、孤儿药（罕见药），以及经济欠发达地区常见的传染病药，其中抗肿瘤药占1/3。人工智能与药物研发结合最典型的案例，是硅谷公司Atomwise通过IBM超级计算机，在分子结构数据库中筛选治疗方法，筛选出820万种候选化合物，研发成本仅为数千美元，研究周期仅需要几天。

2015年，Atomwise基于现有的候选药物，应用AI算法，不到一天时间就成功地寻找出能控制埃博拉病毒的两种候选药物，以往类似研究需要耗时数月甚至数年时间。


病历结构化，是指针对医院多年积累下的非结构化数据的结构化处理，从而使数据真正发挥其价值。病历结构化主要用到自然语言处理技术，随着深度学习的发展，循环神经网络进一步推动了自然语言处理技术的发展。图3-8所示为自然语言处理结构图。


图3-8 自然语言处理结构图
目前国内提供病历结构化服务的公司，往往面向医院提供开放性平台服务，以服务换数据，实现共赢。具体的业务模式分为两类：

第一类，是开放性的中文病历语义API，提供能与医院无缝对接的“可插拔式”模块；
第二类，是提供智能病历分析服务，服务类型和范围较广，如为保险公司做医疗风险评估、精准医学大数据中心的业务规划和组织架构设计、协助重大研究课题进行前期分析研究、开发医疗人才培养系统，等等。

提供病历结构化服务的公司，未来在保险与医药行业也存在较大的盈利空间，例如帮助保险公司发现并减少过度医疗行为，帮助药企监控新产品的安全性等。森亿智能是国内专注于医学文本分析的人工智能公司，其主要业务是通过机器学习和自然语言处理技术自动抓取医学文本中的临床变量，将积压的病例自动转化为结构化数据，生成标准化的数据库。智能算法能挖掘变量相关性，从而为临床科研提供专业性的统计分析支持。
其他国内典型企业代表有零氪科技、大数医达、深思考等。DRGs智能系统中的“DRGs”，英文全称是Diagnosis Related Groups，可翻译为疾病诊断相关分类。它能够根据病人的年龄、性别、住院天数、临床诊断、病症、手术情况、疾病严重程度等因素把病人分入500～600个诊断相关组，然后决定应该给医院多少补偿。DRGs智能系统能有效降低医疗保险机构的管理难度和费用，有利于宏观预测和控制医疗费用。过去常常出现某些患有重大疾病的患者在手术及用药过程中占用太多补偿保额的情况，而DRGs智能系统可以帮助医院合理分配保额，帮助医院合理控制费用。国内典型企业是医渡云。

许多医疗人工智能公司抓住了医生的科研需求，依托其本身的技术算法能力和计算能力，制作易于操作的人工智能科研平台，为医生科研提供以数据分析为方向的辅助性服务。打造科研平台，本身就是对企业现有技术能力和资源的商业价值的充分挖掘。其更大的意义在于，企业能够借助科研平台，与医生、医院或研究机构建立科研合作机会，以换取模型训练数据及未来的商业变现渠道，其具体情况如图3-9所示。国内典型的企业包括推想科技、零氪科技、新屿科技等。


企业与医疗机构资源优势互补，形成科研合作
健康管理

从目前来看，国内将AI与精神健康管理相结合的企业较少，而精神健康管理与每一个人都息息相关，潜在市场较大。根据2009年世界卫生组织的调查，中国精神疾病患者占中国总人口的7%，已经超过心脏病和癌症，成为中国医疗体系最大的负担。2015年，英国世界权威医学杂志《柳叶刀》中的一项研究指出，中国约有1.73亿人有精神疾病，其中1.58亿人从未接受过专业治疗。从全球范围来看，AI在精神健康管理方面的应用，主要有情绪管理和精神疾病管理两类。AI在情绪调节场景中的运用，主要是通过人脸识别用户情绪，以聊天、推送音乐或视频等多种交互方式帮助用户调节心情。典型的企业有美国创业公司Emotient（已被苹果公司收购）、英国创业公司Realeyes等。



◆ 第三节 下注未来，医疗AI的春天不是现在

隐私与伦理问题，将是国家立法机构、AI技术服务企业所面临的紧迫问题。我国有关保护患者隐私权的法律规定，对医疗人工智能公司获取足量的患者数据造成较大的阻碍。我国自2010年正式施行的《中华人民共和国侵权责任法》第六十二条规定，医疗机构及其医务人员应当对患者的隐私保密。泄露患者隐私或者未经患者同意公开其病历资料，造成患者损害的，应当承担侵权责任。随着人工智能技术的不断进步，人类所产生的数据类型越来越多（例如基因数据），保护每一个人的数据安全的法律体系尚未建立，这将是医疗人工智能产品落地过程中的隐形挑战。由于模型训练中使用的数据多样性有限，可能无形中构成对部分社会群体的歧视。例如，某些语音识别产品无法识别一些方言，使这些方言使用者被排除于产品使用范围以外。由于医疗人工智能产品的价格普遍较高，可能会首先被收入水平较高的群体使用。尤其当癌症等致死率较高的病症通过人工智能手段找到治愈方法后，价格问题会加剧患者间的机会不平等，这将可能在医疗领域掀起一场有关道德伦理的大讨论。

第四章 智慧安防：罪恶无处遁形
◆ 第二节 社会需求驱动智慧安防


根据博思数据公布的调查数据，截至2016年中国前端摄像头出货量已达到4338万台，预计在2020年出货量将会达到5422万台，如图4-3所示。这意味着中国每日视频监控录像达上千PB，而过去累积的历史数据更多，并且海量视频监控数据中99%以上都是非结构化数据。利用“人海战术”进行视频检索和分析的方式，不仅需要消耗大量人力，而且效果不佳。IMS Research的一项实验表明，人在盯着视频画面仅仅22分钟之后，人眼将对视频画面里95%以上的活动信息视而不见。


第五章 自动驾驶：定义未来出行

◆ 第二节 三头六臂，引领风潮

自动驾驶安全分为两类：
其一为行驶安全（safety），针对汽车系统可能发生的故障；
其二是信息安全，包括数据的存储、应用、传输安全，以及来自传感器、车联网等不同系统的信息安全。黑客通过网络侵入汽车，篡改或偷取车内数据信息，干扰甚至控制汽车，将严重威胁用户和社会安全。鉴于这个问题，360、腾讯等企业已经开始未雨绸缪，在信息安全方面进行布局。


自动驾驶带来新的交通出行生态，共享被认为是未来汽车行业的发展趋势。研究机构普华永道预测，未来汽车产业价值将发生显著变化：
以往占产业利润41%的汽车销售业务在未来将下降到29%，而共享出行业务所产生的利润将从10%以下猛涨至20%。类似滴滴、神州优车这样的出行运营商将有机会彻底改变传统的汽车消费模式，通过汽车共享和网络效应占据消费市场，竞争汽车行业核心地位。
因此，滴滴大力研发自动驾驶，设立研究院，在各地试验智慧交通技术就在情理之中了。目前国内部分车企已有转型为服务运营商的倾向（如吉利汽车）。亿欧智库认为，出行服务属于公共领域，国内车企具备成功转型的可能性。出行市场to C的特质，将使最先取得网络效应的企业拥有赢者通吃的机会。


第七章 内容不再是人的专利

◆ 第一节 AI挑战记者和作家

文本类内容，如诗歌、小说、新闻稿、散文等，是日常生活中最基本的内容形式。围绕文本类内容的生产，诞生了记者、作家、编剧等职业。近两年来，AI开始逐渐参与文本类内容的创作，其创作出的部分内容，已难以分辨是由人还是由机器所创作。AI在文本内容生产中的应用主要包括写诗、编剧、写小说、写新闻、编程、辅助内容创作等。AI写新闻稿已经在头部媒体中投入实际应用，具体用于个别题材的新闻生产，所生产的内容在全部媒体内容中的占比还很小。AI在剧本结果预测、前期素材搜集、文本纠错等方面也已经得到应用，未来可能被整合到各种文本编辑器和工具之中。AI在作诗、编剧等方面也都取得了一些进展，但目前均处于尝试研究阶段。


新闻对写作速度的要求较高，机器写作显然比人类快很多，因此国内外多家媒体一直在进行机器写稿的研究。AI的发展为此提供了可能，越来越多的主流媒体开始应用机器人写稿。此前，机器只能处理财经、体育、地震等内容结构相对固定领域的新闻。


AI能够辅助语句纠错。2017年6月，百度百家号平台上线了“语义纠错”功能，该功能通过对作者在百家号上创作的文章正文进行快速校对，帮助作者识别和更正内容中的错别字，准确率达到75%。百家号此次上线的AI智能语义纠错功能，能够结合上下文理解词语，找出不符合语义的错别字。例如“通过锻炼，回复效果比较好”这句话，错别字纠错功能识别不出错别字，但语义纠错就会提示“回复”应修改为“恢复”。

◆ 第六节 AI+内容生产：万里长征第一步

在目前不具备推理能力的弱人工智能阶段，AI在小部分领域能够实现自动生产内容，在大部分领域，更适合与人协作，提升素材搜集、整理、检查等方面的效率。在与人协作的过程中，机器可能会完成大部分机械重复工作，人完成小部分创造性工作


人机协作目前有三种方式：
一是机器生成初稿，人进行修改和润色；
二是人提出框架，机器完成细节填充；
三是机器作为工具帮人搜集筛选素材、检验纠错等。


第八章 AI赋能下的法律新格局

展示了基于人工智能的产品与服务用于法律各参与主体相关工作的情况

法律事件的参与者有三个主体，分别是当事人（个人或企业）、律师和法院。对不同的主体，AI能够提供的服务也不尽相同。
人工智能在法律当中的应用主要包括：
为当事人提供法律咨询、律师匹配、公司法务协助；
为律师和律师事务所提供案件查询、文案整理、案情预测、智能咨询服务；
为法院提供文字处理、辅助审判、智能客服服务。


第九章 AI进驻，教育革命即将到来


百年大计，教育为本。
教育作为民族振兴、社会进步的基石，一直是我国优先发展的行业。
目前，我国教育观念相对落后，内容方法比较陈旧，教育结构和布局不尽完善，人民对良好的教育有着强烈期盼。虽然随着互联网的发展，线上录播课和直播课等教育形式解决了部分教育资源不足的问题，但是并没有从根本上解决问题。那么，人工智能的出现，能否加速中国教育产业的改革创新？它改变了哪些传统教育工作？


◆ 第一节 繁重教育工作的解放

虽然“人工智能+教育”概念已被频繁提及，但目前行业内仅有一个模糊的概念，内涵和外延界定不清晰，为了方便解释，这里我们将“AI+教育”用AIED（Artificial Intelligence in Education）表示。我们认为，AIED是人工智能技术对教育产业的赋能现象，本质上是人工智能对教育工作的替代和辅助，将教师和学生从低效重复的工作中解放出来，进而提升教学与学习效率。

人工智能在教育领域的应用，从教育主体来看可分为三类：

● 教育机构的教务工作、人事财务工作、学校管理工作等。
● 教师的教研、教学、测评、管理工作。
● 学生在学校和家庭中的学习任务。



根据国家统计局和财政部数据，2012年至2016年，我国教育经费总投入累计接近17万亿元，年均增长率达7.9%。2016年，全国财政性教育经费高达31396.3亿元，与2015年的29221.45亿元相比，增长了7.44%，占GDP的4.22%，财政性教育经费占GDP的比例自2012年以来连续5年保持在4%以上。可以看出，国家高度重视教育工作，不断加大教育投入。


互联网与移动互联网技术的发展与成熟，催生了以在线教育为代表的新形态教育模式。据CNNIC数据显示，2016年中国在线教育和手机在线教育总规模达23562万人，互联网与移动互联网在学校教育与家庭教育中的重要性日益凸显。随着人工智能技术的成熟，语音识别与图像识别被应用于教育领域，出现了英语语音测评、智能批改、拍照搜题、智能陪练、智能情绪识别等各类AIED产品。



◆ 第二节 教育生态的新变革

人工智能在学校管理工作中的应用主要包括智能图书馆、智能行政管理、智能招生管理、智能财务管理、智能升学和职业规划、智能分班排课和智慧校园安防。


目前国内服务于教育机构的AI企业较少，技术服务能力有待提升。AI应用主要集中于智能分班排课、智能升学和职业规划。


教师的日常工作主要包括教研、教学、测评及学生管理工作。
教师通过教学研究，挖掘与反思教学问题，总结教学经验，研究出更适合学生的教学方法，包括课堂授课、学生辅导、课后答疑解惑等多个环节。
此外，教师还要通过作业与考试的形式，对学生的学习情况进行评价，以及进行课堂与班级管理等。人工智能对教师的这四部分工作均已表现出一定的替代性，从而使得教师有更多时间和精力来对学生进行个性化的教学与辅导，同时缓解了学生个性化教学需求与教师时间相对有限之间的矛盾，实现了自适应学习。


市场上已知的AIED产品主要分为五类：
英语语音测评、
智能批改与习题推荐、
分级阅读、
教育机器人和智能陪练。


其中，英语语音测评、智能批改与习题推荐、教育机器人的相关AI企业均在10家以上，而分级阅读和智能陪练的较少。
此外，还有智能学情分析、智能情绪识别等产品形态。智能学情分析是在积累了学生学习成绩、学习进度、学习习惯等数据后，对其进行智能分析，并给出分析报告，协助教师对学生学习情况进行管理，设计个性化教学方案，如极课大数据的“极课EI”。目前专门做智能学情分析的公司较少，其产品主要渗透在以上五类产品之中，对学生学习效果进行分析并反馈。

图 教师被人工智能替代的工作内容


◆ 第三节 AI+教育未来发展趋势与挑战

从教育机构发展的角度看，教师需要具备与人工智能配合教学的能力。教育系统的各个方面、各个维度关系复杂，目前的AIED产品只是一种辅助、替代部分教育工作的手段和工具，还不足以改变整个系统。


然而，作为学校和教育培训机构的管理者，不仅要改进和完善现有教育体系，满足学生需求，更要能够预见来自新技术的威胁并及时采取相应的应对措施。未来教师的重复性工作将会被逐渐替代，教师的工作内容也会逐渐改变，管理者要及时改变教师的培训方式。对于教师来说，能够与人工智能系统配合、分析智能系统的数据报告、找到适合孩子的学习路径的技能显得愈发重要。同时，学生的学习心理方面的辅导需求也会越来越多。








 


 
 
七月份写过一篇日志，年终总结我们就从下半年开始吧。
这半年来总的来说，档期很满，所有事情基本按照规划都步入正轨，这让我想起来2013年考研时候教毛中特的包松老师在课程快要结束的时候给我们讲到，你对考研成功有强烈的渴求么吗？强烈到像溺水时候渴求空气一样的强烈吗？我有时候想做一件事情非常强烈的想要把它做成，后来，因为这种渴求，我经常能把一些事情做成功。同学们，虽然这样讲有些唯心主义，但是如果你们真的尝试去这样想，这样渴求，就真的离成果不远了。
 
 
 
你若要为你的意义而欢喜，就必须给这个世界以意义。----------歌德
这是一个酥脆香甜外焦里嫩的菜煎饼
咬下第一口，啊，life，之前你都到哪儿去了？
咬下第二口，这个小摊，冰天雪地的坚持到十一点半给同学们卖宵夜，这是怎样的一种职业操守，而且还支持微信支付，满满的感动！
咬下第三口，2016年之前吃饭大学的书都白念了，未曾吃过如此沁人心脾催人泪下之夜宵，没想到，最难翻越的，是习惯！相信世间所有的相遇都是久别重逢！
爱情使所有的人变成雄辩家，这话说得绝对正确。------罗格林

    张老师给学生讲数学的时候我听过，用的还是比较危言耸听的讲法。我初中的数学老师也和张老师差不多漂亮，讲课也挺好，当年我初中的同学们都很喜欢漂亮的女老师，数学都学的不烂，不知道为啥现在的小孩成天补习数学，所以张老师上课的负担也不小。我曾给张老师不屑的讲，初中题目能难到哪里去，你这交初中岂不是大材小用，结果她发了两道题让我做做，我当然不能给陕西吃饭大学丢脸，果断没做对。想当年我中考数学也只扣了三分，对现在题出这么难表示不理解。。。
    张老师  跟我一块的时候不太能说，主要由我负责指点江山，但是只要在微信里面遭遇，说话肯定一套一套的，俨然一副雄辩家的模样，有时候我根本不知道怎么回答她，只好发去。。。，她依据此引经据典又是一顿侃侃而谈，而且每次不同，小生心里佩服的紧呐。
     张老师作为人类灵魂的工程师，工作辛苦，有时候我去接她下班，一起吃饭，她总是胃口大开，从我们认识到现在她吃饭前都说要减肥说她少吃点就行了让我随便点，我总当她是开玩笑，没有当真，所以我吃完就结账拉她走人的时候也不知为什么张老师总是一脸不悦。直到最近张老师认真起来了，我一吃完，她说你等等，我终于明白张老师是在暗示我，谈恋爱，大家要互相迁就，谁吃的快了，就等一下对方，大家共同成长嘛！
我和张老师彼此相识于学雷锋纪念日，一路走来也有将近两年的时间了，今后的日子还长，我们会共同努力，在不同的战线上为实现共产主义奉献力量。
那天坐滴滴的时候有一个非常有意思的师傅，
我看师傅开的是斯柯达明锐，我说这车好！师傅说不要钱的车最好，我问师傅优步和滴滴哪个好？师傅说不要钱的最好，他说他接到过一单滴滴，12000从西安到天津，我忽然想到这个事儿，可以写成剧本儿拍个公路犯罪类型的电影，然后让滴滴打车植入广告一定大卖！我跟师傅一路走一路聊，张老师就在一边傻笑，现在期望司机师傅能开慢点，好让我们几个的欢乐能够得以延续，想到那天小米开年会，老总雷军说，一五年，他们太关注，手机出货量，你整个公司上上下下都背上了沉重的包袱过的一点儿都不欢乐，2016年要把，重心重新关注到手机的电量系统、拍照等细节问题上，带着使命感把这些问题解决好，重新回到为发烧而生的道路上来。
我想我们这个年纪的人多少需要在自由和责任中，做出一个去选择，是追随自己的内心，还是向现实妥协,，选择什么都没有错，不过既然已经选择了，不如让他欢乐一些，你饿不？，我去给你煮碗面

致谢
生活处处有惊喜，希望16年还能继续惊喜下去，感谢这一年来我的努力，张老师的支持，朋友们老师们的关照。
 
后记--
朱光潜在《谈文学》中对于如何做文章讲到：
你不肯用俗滥的语言，自然也就不肯用俗滥的思想感情，你遇事就会朝深一层去想，你的文章就不致落入下乘。现在马上毕业了，马马虎虎的走完了学业生涯，对自己一直要求不高，希望在后续走入社会的过程中，对于自己凡事严格要求，取法为上，仅得为中，取法为中，故为其下，与各位共勉。
 











绪论
2016年的生活有些忙碌，到年底一整年连续的日子成了离散的关键词。2015年这个时候，我还在学校深更半夜因为一个菜煎饼感动的痛哭流涕，一转眼2016年都要过完了。

江湖有江湖的道义，武林有武林规矩，洒家的2016罗列如下：

老张是个好老师
与老张恋爱三年有余，彼此互相包容忍让，共同进步，谁不会闹点小误会呢？毕业那会，正处多事之秋。几年的好哥们，都将去各处远行，心中有些酸楚。彼时又和张老师闹了别扭，一气之下几天没吱声，现再回想起来这是非常不负责任的，在此向老张再次郑重道歉。张老师工作辛苦，你可能要说这年头哪还有容易的活啊。然而作为人类灵魂的工程师，如果是我去教初中数学，面对一个1/2不知道等于0.5的初中生，可能真的忍不住要爆粗口甚至动手削那些熊孩子。而老张呢，虽然威严不减也还是不紧不慢的悉心指导，末了还要应付熊孩子的家长们。
有好几次，我都觉的有点过分。一点多了老张还没吃饭，打电话过去发现张老师依然在和家长沟通学生的情况。一个在老师饭点还冷怂给老师倾诉自己小孩怎么都学不进去不知道咋办的家长可能真的要反思一下，娃学不进去是不是自己的问题。
我们可敬的张老师当然和我不一样，每当出现这样的坑货家长，她都会不厌其烦的帮助她们分析总结，宁可自己饿一会，也会安抚好家长，找到解决问题的办法。人常说，教师是神圣的职业，但教师也是人，老张却用行动诠释了，什么是师者所以传道授业解惑也，不但给学生授业，也给家长解惑。
在此，致敬所有老师！
在此，借用***情书的结尾，吻你万千。

毕业是一件大事
毕业是一件大事，分别也是一件。离校最后的两天宿舍挨个放空，我有些不舍，于是挨个拥抱了所有同学（女）又开车回去游了几回泳，最后送走了大飞，才算离开学校，一脚踏入现实的泥潭。
回想老郑走的时候，山东大汉偷偷掉了眼泪，他说你可别笑话我。“西安这么好，别走了吧”，我告诉他。可他听了之后还是头也不回的去检票了，还撂下一句：你们回吧。林总和老王走的时候就没这么多痛苦。因为以后和老王聚的时候还多，结果到现在也没聚过一次。林总一想到深圳离卅城就两站路，就开心的浑身热血沸腾，一溜烟上了头班616拍马而去。黄兄要南下蜀地，后来多次沟通工作上对IT个大领域的发展畅想，黄兄想法见地之深刻令人耳目一新，这年头敢唱衰大数据的人不多，黄兄算是有理有据的一个。
抱道不曲，拥书自雄，与诸位同学共勉。


大数据时代的思维转变
毕业后没想到阴差阳错的进入了大数据处理领域，才发现在视觉领域浸泡许久，思维和大数据处理上截然不同。视觉上的处理要求精确，单机高效，并行，更多是因果关系，图像中出现了人，因此有人脸，从而有人脸识别，从而有表情识别。而大数据条件下更多是要求关联关系，只要发现了两个现象之间存在显著的相关性，就可以创造巨大的经济或者社会效应，比如Google通过追踪大量用户搜索流感字样的人群位置，做出了流感的趋势预测。

唱衰大数据
Susan langer 在《哲学新视野》一书中说：某些观念有时候会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速的抓住它们，作为进入某种新实证科学的法宝，作为可以用来构建一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
大数据时代，大数据这一手段俨然成为了一种万能工具，我们今天在这里就是要唱衰大数据，因为越是万能的，就越是空洞的。
大数据的核心是预测，如果不能进行预测，仅仅进行简单的数据统计分析，那么和传统的领域我认为是没有区分开的，从事这样的行业价值不大，当今大数据框架之成熟解决方案之完备，完全可以让一个没什么计算机经验的高中生经过几个月的培训就接手各种修改配置的部署工作中去，CDH，zookeeper，hue等等管理框架又都提供了图形化管理的界面，如今各大开源社区的贡献已经让尽可能多的人成为了大数据行业中的价值制造者，那么从事大数据行业的人还有什么可以深入发掘的点呢？
大数据人才大致可以分为以下三个方向：

偏重基建与架构的大数据架构方向。
偏重建模与分析的大数据分析方向。
偏重应用实现的大数据开发方向。

机遇与挑战似乎一直存在，你能找到他们么？

老王和他的IT界朋友们
工作不多时来到北京，借此有机会看望了IT界的名企大牛同学们（时间有限BAT,GOOGLE等还没走完），虽然都身在新闻联播的帝都里，幸福像花儿一样，然而漂泊本无根，几年过去了，大家都没怎么变化，这又让我想起一句诗：人面不知何处去，桃花依旧笑春风，诸位累了就回西安吧。




逃离北上广，我们有情怀的雷总在西安迎接大家，有留迹，让故事留在他发生的地方.


帅不帅，留给别人去评判，反正天下我最帅！
2016年是我准备开始运营《老王和他的IT界朋友们》这个品牌的开局之年，感谢各位亲朋好友的支持，公众号至今为止以有208位粉丝，他们不属于IT界，就一定是IT界的朋友。书上说做人得要有：高远意志，平宽心情。我们这个小圈子一定会竭尽全力带领各位实现目标，剖析自己，送上更多的人文关怀。

后记
2016年已经离我们远去，世事尽管有些未尽人意，您可千万别灰心丧志。挫折如火，劫难如焚；火能焚木为灰，却能炼铁成钢！
最后祝大家新年快乐



欢迎关注公众号：老王和他的IT界朋友们






















2017年钟声敲响的时候，人们总是习惯于性质勃勃地写下一张全年的to do list：例如读完800本书，买个大房子等等。立志之后，就陷入到忙忙碌碌的新一年中，上班扎进电脑和手机，下班一头扎进被子，直到猛一抬头发现2017年只剩几天。。。

十八般武艺 VS 亢龙有悔
矛锤弓弩铳，鞭简剑链挝，斧钺并戈戟，牌棒与枪杈
古语有云：有志者立常智，无智者常立志。随着现代社会的迅速变化，立常志变得几乎不可能，更多的情况是你的理想需要随着现实情况的变化而做适当的调整。但即便如此，我还是认为需要一个相对恒定的理想。不忘初心，是整个国家，社会对于回归纯粹生活的热切期望。
工作一年半以来，由于单位没有互联网，手机俨然成为了我躯体的又一器官。当我发现手机严重影响 我的专注度和思维能力已经 为时过晚。远离手机的时间，大脑通过冥想可以将一些看似没有太多关联的事情联系起来。所以当我和任务独处的时候我能感觉到和整个宇宙都在产生联系，但是当手机加入，就只有我和手机了。 
自媒体的迅速发展，既容易造成注意力的集中，也容易造成注意力的消解，使人们对需要严肃对待的事情越来越缺乏耐心，面对铺天盖地的信息，往往需要耗费大量时间甄选有用信息 ，本来是打开手机搜索一个问题，由于顺道开了微信，刷了一圈朋友圈八卦，又顺道看了两篇公众号文章，而忘了自己原本要打开手机的目的，长此以往根本没法集中注意力，干什么都不专心，做什么都delay，当今社会犯错成本太高，我们还是需要小心翼翼，千万不要养成时不时看手机的毛病而误了大事。
两弹一星元勋科学家钱学森出身书香门第，他不但学贯中西更是精通琴棋书画，1935年，24岁的钱学森甚至还发表过一篇题为《音乐与音乐的内容》的论文。看来天龙八部中聪辩先生苏星河精通琴棋书画，却不擅长武学，因花太多时间于杂学之上，并未学会逍遥派太多高深的功夫，他有点像我现在的状态，在技术上缺乏一个focus 的点，郭靖大侠当年将一招亢龙有悔使到极致照样威震武林，当然他也可能还是天赋有限。我也天赋有限，工作生活中还是要保持专注度，远离手机，保持纯粹的追求，也许总有一天，自己也能十八般武艺样样精通，成为一代全栈程序宗师。

 天下攘攘皆为利往
以下一个小节完全转载自，安晓辉《 程序视界》

很多开发者追逐 AI ，也是从这点出发，为了自己更好的未来。但实际上，趋势并不属于每个人。它往往属于那些已经为这个趋势做了很多年准备的人。
你必须知道的是，现在 AI 趋势里风生水起的专家、科学家、公司，哪个不是之前已经在相关领域做了很多年的研究？
如果你只是看到趋势就盲目扑过去，往往沦为跟风，甚至会跟丢，跟来跟去找不到自己的位置。所以，如果你决定要跟，也要了解怎样去跟。
人工智能开发的四种类别

最后，提醒一下，并不是每个程序员都要追逐人工智能软件开发这个浪潮。软件开发的方向很多，应用场景也很多，你有非常大的可选择余地——只要你能成为你所处领域的局部头部，你就会拥有很多机会。而如果缺乏成为头部的思维、能力和行动，不论去追赶什么浪潮，结果都只能是望洋兴叹。

参考这篇安大神的文章分析，我可以有一个简单的判断，从现在做起还不算晚。 
http://mp.weixin.qq.com/s/TdG3ML195g55hD9a9UuxcQ 
(以上内容转自上述链接)

我一直追寻着你心情的足迹
张老师的小学教师生涯并不是一副歌舞升平的盛世景象，她有时候甚至问我：自己是不是适合教师这个职业。家长到处范二，练习册丢了问老师，作业布置的啥问老师，恨不得把老师当成7*24小时不间断服务的人肉机器人，问的时候还不加敬称，你你你的呼来唤去。我看了心里都很不爽，张老师还是不卑不亢的耐心回答，就评这一点小张就应该获得优秀教师勋章。
国家说要提高基层教师工资待遇，喊了很久，张老师也没涨工资。大学教授一个月1w7带两三个研究生天天给自己报销发票有几个真正推进了我国现代化进程的进步？小学幼儿园初高中老师一个月几大千一人带80多个祖国的花朵，拿着卖白菜 的钱操着卖白粉的心。谁手中掌握着祖国的未来？多劳多得按劳分配也应该给她们涨涨工资。
记得有一次和高指导聊天龙八部，发现金庸竟然在新版改了结局，知乎上有人说，更相信王语嫣和段誉仍然是一对。后来长大后便慢慢醒悟爱情的意义。明白了金老先生的深意。其实木婉清刚出场那时，已经折服了多少人的心，他和段誉本是良偶，于是王语嫣与我，从神仙姐姐，变成了岳灵珊、变成了周芷若。
和张老师的爱情长跑将近1400多天，我们已经有了明确的人生规划，在人生大事上基本达成了共识，爱情在我们两个人的生活当中产生了微妙的变化，好像慢慢的在向柴米油盐等琐碎的事情上迁移，张老师批评我说热恋还没完，怎么就要开始准备结婚了。说起来万分惭愧，是这一年来我因为工作的原因聚少离多，给她的惊喜太少了吧。
特别感谢小张老师，她是一名优秀的产品经理，经常能敏锐且毫不客气的指出我的不足，更难得的是她胃口很好，哈哈

任何事情要做好且做爽，必然是内驱的
2015年的关键词：少说多做 
http://blog.csdn.net/wangyaninglm/article/details/50640972 
2016年的关键词：努力，奋斗 
http://blog.csdn.net/wangyaninglm/article/details/53959333 
2017年中的关键词：让我们一起为梦想窒息！ 
http://blog.csdn.net/wangyaninglm/article/details/74612482
过去的时间我基本保持 ，每半年更新一篇总结过去，展望未来的文章，2016年底我希望自己能够成为大数据全栈工程师，还顺道唱衰了一下大数据觉得大数据什么的都是使用开源的产品，一年过去发现，好家伙用开源产品也得知道怎么用数以万计的api呀，hadoop生态圈十几二十个产品真不是盖的。和圈内专家聊了两句就露馅，人家说，您这就不叫大数据研发，充其量就是使用开源组件—-而已！
所以这半年比较尴尬，甚至没有一个可以写到简历上用来show 的项目。代码没写过多少，淡是越扯越好了。 
想起csdn专家群里一个专家总结最近面试人的经历，大多数是：一问三不会，开口十几k 
我呢？开不了口。。。
总结总是有喜有悲的，在单位，吃了个饭，睡了个觉，出了个差，半年过去了。这些时日我总发现自己穷的很，不单单是物质层面上的，更是精神上的穷。
造成这种身心惧穷的根本原因是基本上把钱看的比什么都重要，做事情的时候我会不自觉的去衡量事情的金钱价值，而真正应该 有的态度是首先把事情做好，顺便赚钱。至少冯仑说李嘉诚是这么认为的。
工作说完了，咱们再来聊聊人生有何意义？胡适先生说，科学家是为求真理。庄子虽有“吾生也有涯，而知也无涯，殆已”的话头，但是我们还是要向上做去，得一分就是一分，一寸就是一寸，可以有阿基米德氏发现浮力时叫Eureka   的快活。有了这种精神，做人就不会失望。所以人生的意味，全靠你自己的工作；你要它圆就圆，方就方，是有意味；因为真理无穷，趣味无穷，进步快活也无穷。
记得前段时候有一篇文章说第一批九零后已经秃了，当然没有人能躲过生活，只不过现在轮到90后，罗曼罗兰曾说过，世界上只有一种真正的英雄主义，那就是在认清生活的真相后依然热爱生活。
共勉！

特别鸣谢

小张老师
胡适先生
《人人都是产品经理》
《黑客与画家》
安晓辉 《程序视界》


All Rights Reservered

注： 
在大型组织内部，有一个专门的术语描述这种跟随大多数人的选择的做法，叫做“业界最佳实践”。 









文章大纲看图说话----序西安公司杭州总部上海BMS 学习出差路上阶段性成绩技术积累身体健康消费支出那些年我写过的总结

看图说话----序
2019年是学习节奏缓慢的一年，生活工作中会遇到很过破事，处理不好就会让人放慢节奏，想要的太多，诱惑也太多，难免堕落。蒋方舟说，人一旦堕落哪怕是短暂的几年，上帝就会以更快的速度收走你的天赋与力量。人常说30而立，立不住，那就保持简单，保持移动。人常说不能老呆在舒适区，那是因为，你怎么知道没有一个更舒适的地方在等你呢？
这篇文章大部分都是图，大家做好心理准备。
新年伊始祖国大好河山，我喜欢登山，因为山高人为峰，让人很有成就感。

回母校，清华桥上我想起了曾经吃饭大学的食堂。

动态血糖仪测试，亲身试验，陕西人吃面不能太多，吃完再喝一碗面汤，那血糖飙升到12 -345 ，简直不能太危险。遂自学加百度，写下了这篇博文：
连续血糖监测(CGM) 初探

陕西人的最爱，扯面，108合一

见识我爷的勋章，共和国大庆，老爷子全国劳模，也是深藏功与名，那个年代的人，需求简单，不求闻达于诸侯，国家人民需要的，就是我需要的。
这个年代的我想法太多，行动太少。。。。

见识了国家健康医疗大数据中心，惠民惠企惠政惠医，这十几个大屏展示效果真是刚刚的。


西安公司
公司在21楼，楼上的风景很好，边上还有公园，吃完饭没事的时候可以去遛弯。
在公司从早到晚，我在这里的时光多于陪我媳妇。


西安近些年来，污染严重，不知为何一直不能解决。每每冬天雾霾，我总想起火星救援里面的台词：I’m the first person to be alone on an entire planet.



公司边上的云水公园，除了冬天，其他时候景色宜人，中饭后，常来遛弯消食，路上针砭时弊，留下很多美好的记忆。





杭州总部
杭州总部在钱塘江边，风景也很好，加班完，晚上还可以去钱塘江边跑步，不过杭州总下雨。如果加班太晚，晚上也没有力气。
公司总部挂了很多许老师的"世界名画" 这张简直精髓，我忍不住cosplay 一下。

杭州卫生 信息中心学习

公司的，早上，傍晚和午夜。



钱塘江边小跑一次，发现似乎宝刀未老，锻炼是重在坚持。
每天锻炼30分，
健康工作100年，
向天再借500年，
还完房贷，
幸福生活一辈子。


开完年会，我们去钱塘江边喝酒。

杭州市政府吃了个爆甜的句子----爆橘


上海BMS 学习
为啥单独把这个列出来，因为这个公司高端到，两个中国人面对面开会，都不想说中文，因为还有全球的研发中心在听。


出差路上

2019年飞了18次，每一次出差都是对心灵的考验。还好目前都是短差。我还挺喜欢这种新鲜的感觉。
偶尔换换地方生活也不错。





阶段性成绩
生命即将迈入奔四，尤其35岁，是技术人的分水岭。
35岁，对于很多工程师而言是个坎，很多工程师懒得搞技术了，就另谋生路去做产品、售前和项目管理，现在只有云计算售前有行业红利，收入暂时高的惊人；而产品经理是在职场冒险，项目管理一直是苦力活。这些另谋生路的朋友，长期看还不如固守IT技能的基本盘。
35岁的裁员潮，其实被淘汰最多的不是干活的工程师，而是基层管理岗位。如果是带头干活的组长经理，就算被裁了还能找到工作；老工程师不能和应届生拼手速拼加班强度。
计算机有很深的理论体系，这是我们这些老工程师构筑经验壁垒的好机会，这套润物无声的理论体系，怎么沉浸下来进入自己的体系呢，写写博客，写写代码，多积累，唯手熟尔。
技术积累
开博10年，总体还算是说的过去，期待能有厚积薄发的那一天。希望 我的2020年能够完成《自然语言实战入门》这个课程的总体ppt 以及视频、博客。
付费专栏：自然语言处理实战入门
付费单篇系列：自然语言处理实战
视频课程：自然语言处理实战入门
免费专栏：简单NLP分析套路
目前，主要是在csdn 上面发发，今年尝试将一些干货写成付费的，发现还是看的人少，可能水平有限吧，后面我还是得坚持下去。很多平台都设置了可以同步，这个功能很好，懒得复制粘贴了。



身体健康
尝试了一下 健身房的健康指数测量器，还有美年大健康的体检。主要就是几个原则：
少熬夜，多运动，戒烟限酒，保持积极的心态，说着容易，做到那那么容易

消费支出
看来主要支出都是倒腾还房贷了。支付宝绑了，信用卡，这俩消费有重叠



最后放一张杭州的广告牌，共勉




那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员

2019年：视线所及只剩生活

2019 初入IT十年（下）---- 视线所及只剩生活











题目：
讨论帖：
点击打开链接


int main()
{
switch (getchar() - '0')
{
case 2: puts("3"); break;
case 3: puts("25"); break;
case 4: puts("253"); break;
case 5: puts("3121"); break;
case 6: puts("46651"); break;
case 7: puts("823537"); break;
case 8: puts("16777209"); break;
}
#include <stdio.h>
#include <math.h>
size_t apple(size_t b)
{
    return b>0?pow(b,b)-(b-1):0;
}
int main()
{
    printf("%d\n",apple(8));
    return 0;
}



void apple(short bear, short apple_sum, short count){
	if(count == bear){
		return;
	}
	apple_sum += pow(count,count) - count + 1;
	count++;
	apple(bear, apple_sum, count);
}
2.
讨论帖子：
http://bbs.csdn.net/topics/391830032


void print(vector<char>& vData)
{
vector<char>::iterator it = vData.begin();
for(; it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '7' || *it == '8' || *it == '9')
{
cout<<" - ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '4' || *it == '8' || *it == '9')
{
cout<<"| |";
}
else if(*it == '5' || *it == '6')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '1' || *it == '7')
{
cout<<"   ";
}
else if(*it == '*')
{
cout<<"*";
}
else
{
cout<<" - ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '6' || *it == '8')
{
cout<<"| |";
}
else if(*it == '2')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '8' || *it == '9')
{
cout<<" _ ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
}

int main()
{
int n, i, k;
while(cin>>n)
{
i = 2;
if(n < 2)
continue;
vector<int> vData;
while(n >= i)
{
if(n % i == 0)
{
n = n / i;
vData.push_back(i);
}
else
{
i++;
}
}

vector<char> vRes;
int vDataSize = vData.size();
for(k = 0; k < vDataSize; k++)
{
stack<int> temp;
while(vData[k] > 0)
{
int value = vData[k] % 10;
temp.push(value);
vData[k] /= 10;
}
while(!temp.empty())
{
vRes.push_back(temp.top() + 48);
temp.pop();
}
vRes.push_back('*');
}
if(!vRes.empty())
{
vRes.pop_back();
}

print(vRes);
}
return 0;
}

﻿﻿
﻿﻿









作者：一人

Featuretools如你所言能够自动完成特征工程，它属于AutoML范畴，接下来我还是主要谈AutoML1吧。由于机器学习应用高门槛和应用范围的广阔，所以很多组织于2017和2018年开始自动化的机器学习尝试，想降低机器学习应用的门槛，让非专业人员也能够应用。机器学习的工作流通常为数据清洗、特征工程、模型选择、模型训练、模型评估，针对机器学习的自动化尝试，也在这几个步骤展开。
由于数据清洗和数据强关联，在这一部分只能根据具体应用和情景进行处理，无法抽象出来使用通用方法解决；针对特征工程部分，据我查阅所看，自动化工具很少，Featuretools算是一个吧；但是针对后面模型选择与模型训练、模型评估的自动化工具就比较多了，例如Google的automl,Microsoft的NNI2以及autosklearn3等。
当前自动化的工具主要根据机器学习算法分为两个类别4：
自动传统机器学习方法与自动神经网络方法。自动传统机器学习方法最为典型的应用就是auto-sklearn，面向的算法主要是LR，SVM，GBDT等。而针对自动化神经网络的工具当前处于研究的前沿，具有代表性的工具除过上面google和Microsoft之外还有auto-Keras,百度的AutoDL等，由于神经网络能够自动化完成特征工程，因此所有的工具都主要集中在网络架构和参数搜索上了。
automl从2017年开始引起关注，2018号称automl的元年，由此也能看出来其离实际应用还有比较长的距离。虽然如此说，但是针对传统机器学习的自动化工具现在还是值得尝试。
传统机器学习方法已经发展很多年了，针对这部分自动化工具也诞生有些年头了，auto-sklearn已4年。但是很不幸，据使用过的人说，效果还是比较有限，不如人工做出来的效果好，如果对于效果要求不很高，不妨试试，毕竟构建快成本低。自动神经网络就不用在说了。从目前发展状况来看，短期内这个领域应该不会有什么大的突破，但是长期看自动化机器学习还是很有前途的。
如果要想进一步了解AutoML的内容，可以查看zhihu中automl话题下的讨论，https://www.zhihu.com/topic/20173754/hot

机器学习技术落地难，急需懂算法的产品人员。
算法工程师从业人员已经饱和。学习资料易得，学习门槛降低。还记得在2016年底时我们俩谈过：由于现在的各种教程漫天飞，这个领域必将涌入大量的从业人员。
从近两年发展来看现状确实如此，去年校招的很多报道说：算法岗收到的简历与职位的比例远远大于100:1，各大公司现如今对于算法工程师的门槛要求也是水涨船高，高的我看见都发怵。机器学习在产品上的应用远没有想象的那样迅速铺展开来，新进入人员没有新坑能占。当前机器学习应用比较广的领域：

图像的监控与文字识别，
NLP的智能助手与智能客服；
推荐、搜索、广告系统等。

这些都是发展很多年的领域并不新，所以也就没有新的岗位创造出来，进一步加深了行业人员的饱和。因此，当前行业并不缺懂算法的工程师，或者说并不缺初中级算法工程师。
急需能够让算法落地的产品人员。不用质疑机器学习的应用范围是很广的，但是应用的落地速度并不如预期，这在一定程度上反应出来：算法人员不懂产品，产品人员不懂算法。这种隔阂才是算法不能迅速落地的关键因素。
所以，如果在这个方向的从业人员应该多多将精力放在如何填补这鸿沟上，要么产品人员多学学算法，要么算法人员多多了解产品知识。
个人观点：能够掌握主流的算法原理，有两三个算法实际项目，能够掌握产品方面的技能，这种人才才是当前的香饽饽。



机器之心，AutoML、AutoKeras…这四个「Auto」的自动机器学习方法你分得清吗？https://zhuanlan.zhihu.com/p/49494212 ↩︎

Microsoft, NNI,  https://github.com/Microsoft/nni ↩︎

Machine Learning Professorship Freiburg, Auto-sklearn, https://automl.github.io/auto-sklearn/stable/# ↩︎

第四范式，AutoML在推荐系统中的应用，https://zhuanlan.zhihu.com/p/52907645 ↩︎













文章大纲Aws 的优势架构完善的框架（WAF）

Aws 学习笔记
Aws架构中心
Aws 的优势
4.速度优势
5.全球优势
数分钟内实现全球部署
Aws全球基础设施
Aws 数据中心
来自多家ODM（白牌机器）
1.考虑当地法律法律法规
2.考虑速度，和用户的距离，是否提供对应的业务
3.考虑成本
Aws 可用区
每个区由一个或者多个数据中心组成
专为故障隔离而设计
使用高速专用链接与其他可用区域互联
您可以选择可用区
Aws建议跨可用区复制以便实现弹性。
Aws 边缘站点协助客户实现高可用、高响应
架构完善的框架（WAF）
5大支柱：
1.安全性
2.可靠性
3.成本优化
4.性能效率
5.卓越运维
安全性
身份机制
实现可追踪性
在所有层确保安全性
风险评估与缓解策略
可靠性
动态获取计算资源以满足要求
成本优化
衡量效率
消除不必要的支出
考虑使用托管服务
卓越运维
能够运行和监控各种系统
持续改进支持流程和程序
部署方式
更新方式
操作方式
性能效率
选择有效的资源并在需求变化时保持资源效率
普及先进技术
了解技术


20191017 下午课程 aws 简单架构
Aws s3
Amazon s3 对象存储（扁平化，对象，元数据）
设计为提供99.999999999%的持久性（9个九+2个九= 11个九）
事件触发器
静态网站托管
S3访问控制
S3 使用案例
计算和大规模分析的的数据存储
限制：上传5G，存放5T
版本控制
备份工具
Aws Glacier
右上角换成amazon s3 智能分层
EC2 添加计算功能
使用amazon 系统镜像AMI 启动 Amazon EC2 实例
自定义启动配置的相关组件
EC2 和数据存储
EBS 弹性实例存储
实例存储是临时性的
跨可用区的数据复制要收钱，快照是可以复制。
跨可用区复制。
先对卷做快照-实际上是在s3上面，在另一个可用区用快照恢复
用户数据及实例元数据
https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-instance-metadata.html
EC2 实例类型
EC2定价选项
会话处理放在外部，ec2只是一个计算的模块。
架构一定是无状态的。
EMR按需结合竞价来做.任务可以提前完成而且成本更低。
标签最佳实践
添加数据库层
选择什么样的数据更适合什么样的场景
数据库层的选择注意事项
关系型与非关系型数据库对比
Oracle 大部分扩展是用垂直扩展，mysql 支持水平扩展
事务查询用关系型数据库。
Nosql 天生支持水平扩展形式
amazon aurora
老师强烈推荐了 amazon aurora 是自己提升了性能，并开始将自身的Oracle逐渐下线改为amazon aurora
Amazon DynamoDB
以购买火车票场景为例
查看余票：最终一致性
下单：强一致性
为什么有这两个区别：
CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。
数据库的安全管理
RDS
DynamoDB
数据库的迁移

20191018 早上课程 网络
云中的安全性
链接网络
虚拟私有网络
VGW需要购买
Aws Direct Connect
多个vpc 互联互通

20191018 下午课程
AWS 负载均衡器
高可用
多区域高可用及DNS
Aws Identity and access management
弹性高可用和监控
弹性
高可用
监控
CloudWatch
获得弹性并扩展架构

20191019 上午课程
实现基础设施自动化
Aws CloudFormation
可以直接托拉拽的设计方式
快速入门由AWS 解决方案架构师和合作伙伴编写,旨在依据安全性和高可用性 方面的AWS 最佳实践,帮助您部署基于AWS 的热门解决方案。这些参考部署可在AWS 云上自动实施关键技术,通常只需单击一下即可在一小时内完成实施。 您可以通过简单几步构建测试或生产环境,然后便可立即开始使用。 (AWS)
Aws system manager
AWS Systems Manager 是一项管理服务,可帮助您自动收集软件清单、应用操作 系统修补程序、创建系统映像并配置Windows 和 Linux 操作系统。这些功能可 帮助您定义和跟踪系统配置,防止偏差,并确保Amazon EC2 和本地配置的软件 合规性。AWS Systems Manager 提供的管理方法是根据云的规模和敏捷性专门设 计的,可以扩展到您的本地数据中心,使您可以更轻松地将现有基础设施与 AWS 进行无缝桥接。
Aws Opsworks
缓存
Aws cloudfront
构建解耦架构
传统基础设施以紧密集成的服务器链为中心,其中每个服务器都有特定的目的。 然而,当其中一个组件/层发生故障时,就会对系统的造成灾难性的破坏。此外, 它这种情况也妨碍了扩展。如果在一个层添加或删除服务器,则每个连接层上 的每个服务器也必须相应地进行连接 (AWS)
Aws SQS
引入 SQS 队列有助于改进您的订购应用程序。您可以使用队列将处理逻辑隔离 到其组件中,并在一个独立于Web 应用程序的进程中运行它。这反过来又让系 统能够更灵活地应对流量峰值,同时支持系统仅在必要时快速执行工作以便管 理成本。此外,这还为您提供了一种机制,让您可以将订单作为消息持久保存 (队列充当临时数据库),并将您的事务范围与数据库向堆栈更下层移动。如 果发生应用程序异常或事务失败,这可以确保将订单处理停用或重定向到 Amazon SQS 死信队列 (DLQ),以便日后进行重新处理。 (AWS)
Amazon Simple Queue Service (Amazon SQS) 是一种分布式队列系统,它使Web 服务应用程序能够对应用程序中的一个组件生成的消息(以供另一个组件使用) 进行排队。队列是一个临时存储库,用于存储等待处理的消息,并将消息保留 1 到 14 天(默认为 4 天)。使用Amazon SQS,您可以将应用程序的组件解耦,以 便它们独立运行。消息可包含最多 256KB 的任何格式的文本。Amazon SQS 支持 多个生产者和使用者与同一队列进行交互。Amazon SQS 可与多种AWS 产品一起 使用,包括:Amazon EC2、Amazon S3、Amazon ECS、AWS Lambda 和Amazon DynamoDB。
Amazon SQS 提供了两种类型的消息队列。标准队列提供最大吞吐量、尽力排序 和至少一次传递。Amazon SQS FIFO 队列旨在保证消息严格按照其发送顺序仅处 理一次,吞吐量有限。以下情景描述了Amazon SQS 队列中消息的生命周期(从 创建到删除)。在这个情景中,有一个生产者向队列发送了一条消息,消息以 冗余方式跨Amazon SQS 服务器分布。 (AWS)
Amazon SNS
Amazon Simple Notification Service (SNS) 是一种Web 服务,让用户可以轻松地在 云中设置、操作和发送通知。该服务遵循“发布 – 订阅”(pub-sub)消息收发范 例,使用“推送”机制将通知传递给客户端。
您可以创建一个主题,然后定义策略来确定哪些发布者和订阅者可以与其进行 通信,从而控制对该主题的访问。发布者可以向他们创建的主题或他们发布权 限的主题发送消息。发布者不需要在每条消息中包含特定的目标地址,只需将 消息发送至主题。然后,Amazon SNS 会将主题与该主题的订阅者列表进行匹配, 并将消息传递给每个订阅者。每个主题都有一个唯一的名称,为发布者和订阅 者标识Amazon SNS 终端节点,以便他们发布消息和订阅注册通知。订阅者会收 到发布至他们所订阅主题的所有消息,且一个主题的所有订阅者收到的消息都 相同。
Amazon SNS 支持加密主题。当您将消息发送至加密主题时,Amazon SNS 会使用 由AWS KMS (https://aws.amazon.com/kms/) 提供支持的客户主密钥 (CMK) 来加密 您的消息。Amazon SNS 支持客户托管的 CMK,也支持AWS 托管的 CMK。只要 收到您的消息,Amazon SNS 便在服务器上使用 256 位AES-GCM 算法进行加密。 为实现持久性,这些消息以加密形式存储在多个可用区 (AZ) 中,并在传输到订 阅终端节点(例如,Amazon Simple Queue Service [Amazon SQS] 队列、AWS
Lambda 函数,以及HTTP 和HTTPS Webhook)之前解密。 (AWS)
上述两个组件的消息的延迟性比较大，而kinesis 的处理主要是针对近实时性的。
kinesis stream 相当于管道。
Kinesis firehouse 进行转发转接，kinesis 转发到另外的组件进行集成展示业务。
Kinesis 是一整套系统，kafka 只是数据接下来存好。
20191019 下午课程
微服务和无服务架构
Amazon ECS
Amazon Elastic Container Service (Amazon ECS) 是一种高度可扩展的高性能容器管 理服务,其支持Docker 容器,让您能够在托管的Amazon EC2 实例集群上轻松 运行应用程序。
Amazon ECS 是一种可扩展的集群服务,用于托管容器,可以: • 扩展到数千个实例 • 监控容器的部署 • 管理集群的完整状态 • 使用内置的计划程序或第三方计划程序(例如 Apache Mesos、Blox)对容器 进行计划
• 使用API 来扩展 群集可以使用 Spot 实例和预留实例 (AWS)
无服务架构
Aws api Gateway
防止暴露终端节点
防护DDos 攻击和注入攻击
灾难预防
存储备份
计算备份
恢复策略
参考资料
EMR 弹性扩展
https://aws.amazon.com/cn/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/
https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-automatic-scaling.html











0.绪论
之前完全没有接触过大数据相关的东西，都是书上啊，媒体上各种吹嘘啊，我对大数据，集群啊，分布式计算等等概念真是高山仰止，充满了仰望之情，觉得这些东西是这样的：

当我搭建的过程中，发现这些东西是这样的：

对于初学者来说，我认为缺点如下：

1.需要控制，配置的东西太多，并且配置对应并不是很清晰（以后优化集群是否会有很高含金量？）
2.整个集群，我觉的从硬件到软件整体来说还是稳定性有待提高，尤其CDH   集群这块一会这个主机失去联系，一会NameNode挂，一会monitor挂，整个使用过程就是在不断的挂，看日志，挑错。基本离自动化，智能化还有很大距离。

CDH集群测试主要包括以下几个方面的内容：
1.装机（pxe），搭建服务器集群基础环境 
2.安装CDH集群，调试集群的健康状况，使集群可用 
3.测试集群性能，优化集群，使用测试框架（如Intel的HiBench框架）测试集群性能

1.基础建设简称基建
上一篇文章，我们已经介绍了集群安装操作系统的大杀器：
 pxe无人值守安装linux机器笔记
在批量安装完毕系统之后，本节主要围绕搭建CDH集群的基础建设进行介绍，基础建设简称基建，主要是为了支撑CDH集群后序工作流畅进行的一系列Linux系统的设置工作，基础建设工作没有做好，后面安装使用集群过程中会出现很多莫名奇妙的错误。基建主要包括，免密登录，时间同步，格式化硬盘，挂载目录等一些设置，下面为大家分别介绍：
1.1 建立主机分发脚本
新建一个host文件里面逐行设置为主机ip 
eg.

192.168.1.1 
  192.168.1.2 
  192.168.1.3

新建一个自定义脚本文件：

#!/bin/sh 
      host= `cat host` 
      for i in   $host 
      do 
      echo $i 
   #将需要分发的命令复制在此处 
  Done

1.2 免密码登陆
配置免密码登录 
1. 执行ssh-keygen命令，点击两次“回车”，生成/root/.ssh/id_rsa.pub文件；(使用脚本分发下面两条命令) 
2. cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys 
3. scp -r /root/.ssh $hostname:/root/
1.3 配置主机基础环境

修改默认语言为英文

vi /etc/sysconfig/i18n  
  LANG=”en_US.UTF-8”

修改host文件

scp /etc/hosts root@$i:/etc

关闭防火墙以及SELinux

ssh $i ‘service iptables stop’ 
  ssh $i ‘chkconfig iptables off’ 
  ssh $i ‘service ip6tables stop’ 
  ssh $i ‘chkconfig ip6tables off’ 
  ssh $i ‘setenforce 0’ 
  ssh $i ‘echo ‘service iptables stop’ >> /etc/rc.local’ 
  ssh $i ‘echo ‘service ip6tables stop’ >> /etc/rc.local’ 
  ssh $i ‘sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config’

同步时间 启动ntp服务，每5分钟向服务器同步一次（还需修改时间服务器上的部分配置，具体请百度）

ssh $i ‘cat >>/var/spool/cron/root  << EOF 
  */5 * * * * /usr/sbin/ntpdate serverIP> /dev/null 2>&1 
  EOF’ 
  ssh $i ‘echo ‘SYNC_HWCLOCK=yes’ >> /etc/sysconfig/ntpd’ 
  ssh $i ‘hwclock -w’

修改用户句柄限制

ssh $i ‘cat >> /etc/security/limits.conf << EOF 
  hadoop  soft    nofile  65000 
  hadoop  hard    nofile  65000 
  hadoop  soft    nproc  401408 
  hadoop  hard    nproc  401408 
  *  soft    nofile  65000 
  *  hard    nofile  65000 
  *  soft    nproc  401408 
  *  hard    nproc  401408 
  EOF’

建立挂载目录(根据自己的硬盘个数)

ssh $i ‘mkdir /data01 /data02 /data03 /data04 /data05  /data06  /data07  /data08  /data09  ‘

格式化硬盘（需批量执行，此处脚本有待升级）

ssh $i  
  ‘yes|parted /dev/sdb mklabel gpt  
  parted /dev/sdb mkpart primary 0% 100% 
  mkfs.ext4 -T largefile /dev/sdb1

修改/etc/fstab文件

ssh $i ‘cat >> /etc/fstab << EOF 
  /dev/sdb1   /data01            ext4    defaults,noatime        0    0

挂载目录

ssh $i  
  ‘mount /dev/sdb1   /data01

关闭swap交换分区

ssh $i ‘swapoff -a’ 
  ssh $i ‘sysctl -w vm.swappiness=0’ 
  ssh $i ‘echo ‘vm.swappiness=0’ >> /etc/sysctl.conf’

关闭大内存页面

ssh $i ‘cat >> /sys/kernel/mm/transparent_hugepage/defrag << EOF 
  never 
  EOF
ssh $i ‘cat >> /etc/rc.local << EOF 
  echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag 
  EOF

卸载自带的java环境，可以根据自己的java版本卸载 
检查集群机器是否安装过openJDK,如果有安装过，请卸载，执行命令 ：

rpm -qa | grep jdk 
  rpm -e xxx #xxx为上一步输出的rpm包名
ssh $i  
  ‘rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-devel-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-javadoc-1.6.0.0-1.66.1.13.0.el6.x86_64’

安装pscp和scala包

ssh $i ‘rpm -i /root/rpms/pssh-2.3.1-5.el6.noarch.rpm /root/rpms/scala-2.10.4.rpm’

配置java1.8.0_66环境

scp -r /usr/java/jdk1.8.0_66 root@$i:/usr/java/ 
  ssh $i ‘rm -rf /usr/java/lastest’ 
  ssh $i ‘ln -s /usr/java/jdk1.8.0_66 /usr/java/lastest’
ssh $i ‘cat >> /etc/profile << EOF 
  JAVA_HOME=/usr/java/jdk1.8.0_66 
  CLASS_PATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar 
  export JAVA_HOME 
  PATH=\$HOME/bin:\$JAVA_HOME/bin:\$PATH 
  export PATH 
  export CLASS_PATH 
  EOF’
scp /etc/profile root@$i:/etc/ 
  ssh $i ‘source /etc/profile’
done

时间同步

ssh $i ‘service ntpd stop 
  ntpdate lcgm2 
  ssh $i ‘hwclock -w’ 
  ssh $i ‘chkconfig ntpd on’ 
  done

配置yum源，开启http服务 
Yum源先mount在var/www/html/下面，在 
/etc/yum.repos.d/rhel-source.repo文件修改内容


一些可能用到的命令：
建立多级目录: mkdir -p /x/xx 
查看系统是否开启cloudera相关服务：chkconfig –list|grep cloudera 
查看eth0网卡网络速度：ethtool eth0|grep -i speed
1.4 绑定网卡
决定集群性能很大因素是集群的网络性能呢，所以一般大数据集群都是多个网卡绑定的bond0模式，绑定shell如下 
nmcli命令可能需要NetworkManager服务来支撑
 ifconfig
 systemctl stop firewalld.service 
 service iptables stop
 setenforce 0


 nmcli con add type bond con-name bond0 ifname bond0 mode 0
 nmcli con add type bond-slave con-name bondeno1 ifname eno1 master bond0
 nmcli con add type bond-slave con-name bondeno2 ifname eno2 master bond0
 nmcli con add type bond-slave con-name bondeno3 ifname eno3 master bond0
 nmcli con add type bond-slave con-name bondeno4 ifname eno4 master bond0

 cd /etc/sysconfig/network-scripts/
 vim ifcfg-bond0
    BOOTPROTO=static
    IPADDR=192.168.*.*
    PREFIX=24
    GATEWAY=192.168.*.*

 service network restart

 nmcli con reload

 nmcli con up bondeno4
 nmcli con up bondeno1
 nmcli con up bondeno2
 nmcli con up bondeno3
 nmcli con up bond0

2.安装配置Cloudera-Manager（离线）
在线安装方式由于需要安装的安装包过大，时间可能非常长，建议大家下载安装包进行离线安装。主要安装Cloudera Manager Server 和Agent。
2.1 离线仓库安装准备
在cloudrea下载离线仓库，下载地址 
    下载cm5： 
https://archive.cloudera.com/cm5/repo-as-tarball/5.8.0/cm5.8.0-centos6.tar.gz 
    下载cdh5： 
https://archive.cloudera.com/cdh5/parcels/5.8.0/ 
        列表： 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1 
        manifest.json 
    下载验证：https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.8.0/repodata/ 
    下载安装脚本： 
http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
2.2 主节点解压安装
cloudera manager的目录默认位置在/opt下，解压：tar xzvf cloudera-manager*.tar.gz将解压后的cm-5.*和cloudera目录放到/opt目录下(类似在windows把软件安装在D：/software)。
为Cloudera Manager 5建立数据库，可以用Mysql，或者自带的postgresql ，本文采用自带的数据库进行测试。
配置离线仓库地址：

开启apache服务：service httpd start
将下载的cloudera仓库移到/var/www/html目录下，调整目录结构：

 
cdh5目录结构： 

cm5目录结构: 

chmod u+x cloudera-manager-installer.bin，然后./*.bin该文件相关启动脚本，就可以进入安装界面进行安装啦。

service cloudera-scm-server start (这个启动有点慢，可以关注日志变动情况 ) 
  service cloudera-scm-agent start 

其中，日志所在路径是  
/var/log/cloudera-scm-server/cloudera-scm-server.log  
启动server后，使用:

/sbin/iptables -I INPUT -p tcp –dport 7180 -j ACCEPT ( 打开7180端口 )

2.3 配置集群

1.根据CM引导界面，用户名admin ，密码admin。选择Cloudera Express 免费版。点击下一步到为CDH集群安装指定主机。 




2.输入需要安装集群的机器IP地址，包括Cloudera Manager Server 机器。
3.选择集群的安装方式，选择使用数据包，CDH版本选择自定义，并输入yum源地址（基建中已经配置了的） 


 
（上图链接地址https可能会出错）
升级过程中遇到的问题 
提示Error Cannot retrieve repository metadata [repomod.xml] for cloudera-cdh5.Please verify its path and try again
(1) 检查机器的yum及cloudera的yum源配置是否正确 
(2) 在Cloudera升级步骤(5)中填写的apache上cm5包地址是否正确，协议应该使用http而不是https，不然就会出现这种错误 
(3)   若没有显示本地parcel包，可能是路径填写错误，可以根据配置的远程yum地址重新填写。

4.集群安装状态，可以看到每台集群的安装状态，如果正常则进入下一步。
5.选择要安装的CDH组件，我们选择安装HBase、HDFS、Hive、Spark、YARN、Zookeeper服务。点击继续（hibench测试主要需要这几个组件），角色服务分配参考如下：



6. CM会检测安装环境，可能会提示一处安装警告，比如： 
cloudera 建议将/proc/sys/vm/swappiness设置为0，当前设置为60，  
则我们需要在集群每台机器上执行命令：


echo 0> /proc/sys/vm/swappiness

王道就是有错就看日志调试。 


7.选择集群机器的角色分配，对于默认的选择都可以选择在Master机器上，当然像Second NameNode可以选择在非NameNode机器上。注意Cloudera Management Service都选Master。
8.数据库配置。根据创建数据表选择所对应的服务即可。
9.集群设置。选择默认，集群开始安装，完成，访问集群serverIP:7180/cmf，ok。

2.4 集群基本优化
2.4.1 关闭Linux THG服务
检查集群中的各个主机的THG（对虚拟化等的内存资源分配是有好处的，但是对hadoop离线计算IO密集型操作是没有优势的，关闭THG可加快处理速度）

1.查看THG

cat /sys/kernel/mm/redhat_transparent_hugepage/defrag

2.关闭THG

echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag


2.4.2 设置linux内核参数：vm.swappiness
vm.swappiness值的范围为0~100，作用是控制应用数据在物理内存和虚拟内存之间的交换，值越低，交换的越少。默认值为60。
查看集群各个主机的此参数值：

cat /proc/sys/vm/swappiness

建议调整值为1：

sysctl -w vm.swappiness=1

2.4.3 配置HDFS
点击HDFS -> 配置 -> 高级：hdfs-site.xml 的 HDFS 服务高级配置代码段（安全阀），加入配置使用公平队列
<property>  
    <name>ipc.8020.callqueue.impl</name>
    <value>org.apache.hadoop.ipc.FairCallQueue</value>
</property>
2.4.4 配置Yarn资源
关于Yarn内存分配与管理，主要涉及到了ResourceManage（集群资源调度协调）、ApplicationMatser（任务资源配置）、NodeManager（YARN节点代理配置）这几个概念，相关的优化也要紧紧围绕着这几方面来开展。
点击Yarn -> 资源管理：

设置ApplicationMaster Java最大堆栈：800M(AM内存默认1G)
容器内存yarn.nodemanager.resource.memory-mb 
计算一个节点需要分配的容器内存方法： 
主机内存-操作系统预留内存(12G) - Cloudera Manager Agent(1G) - HDFS DN(1G) – Yarn    NM(1G) 
= 主机内存-15G

如果安装了hive.需减掉12G左右内存. 
如果安装了hbase.还需减掉12-16G内存。 
如果安装impala.还需减掉至少16G内存。
例：64G内存主机，如果安装了hbase,hive，则建议分配的容器内存大约为：25~30G

容器虚拟CPU内核yarn.nodemanager.resource.cpu-vcores
计算一个节点需要分配的容器虚拟内核方法： 
(主机cpu核数 – 系统预留1 – Cloudera1 – HDFS1 – Yarn NN 1) * 4 
Hbase : -1 
例：24核机器，为yarn分配可用cpu核数大约20核左右，按照 核数:处理任务数=1:4(比例可酌情调整)，建议分配为80。由于本次集群CPU计算能力没达到官网建议的比例的要求，大约分配的比例为1:2，分配的核数为30核左右。
高级配置中：mapred-site.xml 的 MapReduce 客户端高级配置代码段（安全阀）

<property>
    <name>mapreduce.tasktracker.outofband.heartbeat</name>
    <value>true</value>
</property>
2.4.5 配置oozie
点击oozie –> 配置 -> 高级 ： oozie-site.xml 的 Oozie Server 高级配置代码段（安全阀），增加配置：
<property>
<name>oozie.launcher.fs.hdfs.impl.disable.cache</name>
  <value>true</value>
</property>
<property>
<name>oozie.action.max.output.data</name>
  <value>5000000</value>
</property>
2.4.6 配置Oozie HA(用HAproxy负载均衡)

Web界面操作略
error： 
Oozie could not be start 
REASON:java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
ERROR: java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
 Org.cod… jaskson…

导致上面错误是oozie的jaskson版本低，替换成1.9.13版本即可 
只替换jackson-mapper-asl和jackson-core-asl即可
替换步骤：
1. 
先将192.168.188.13的两jar包拷贝到/opt/cloudera/parcels/CDH/lib/oozie下
2.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} | sort |uniq | xargs -i cp jackson-* {}

3.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-mapper-asl-1.8.8.jar .

4.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-core-asl-1.8.8.jar .

2.4.7 其他优化
1.DRF策略
CDH集群调优：内存、Vcores和DRF
默认配置下，CPU核数和内存是1：1G的比例来启动任务的。可通过调整参数yarn.nodemanager.resource.memory-mb进行调整
2.每个container的分配多少内存和cpu
当应用程序向resource manager 申请资源（即申请container ）时， RM分配给一个container 多大的内存是按照一个最小单位进行分配的。 例如， 我们设置分配的最小单位为4GB， 则RM分配出来的container的内存一定是4G的倍数。  假设现在有一个程序向RM申请 5.1G的内存， 则RM会分配给它一个8GB的container去执行。 

yarn.scheduler.minimum-allocation-mb=4096

在实际执行map reduce的job中， 一个container实际上是执行一个map 或者reduce task的jvm的进程。 那么这个jvm在执行中会不断的请求内存，假设它的物理内存或虚拟内存占用超出了container的内存设定， 则node manager 会主动的把这个进程kill 掉。 
这里需要澄清一点， JVM使用的内存实际上分为虚拟内存和物理内存。  JVM中所有存在内存中的对象都是虚拟内存， 但在实际运行中只有一部分是实际加载在物理内存中的。 我们使用linux的top 可以看到 VM, RES,    前者是虚拟内存，后者可以看成近似是实际占用的物理内存。 因此在设置mapreduce的task的 jvm opts 参数时， 应将heap size 设置的比container允许的最大虚拟内存小。 这样jvm 不会因为申请过多的内存而被node manager 强制关闭。 当然设置最大heap size 如果在执行中被超过， jvm就会报 OutOfMemoryException。 
同时还有一个参数，设定了RM可以分配的最大的container是多大。   假设应用程序向RM申请的资源超过了这个值， RM会直接拒绝这个请求。 

yarn.scheduler.maximum-allocation-mb


3.HiBench集群性能测试
在大数据领域中，集群的性能很大程度上我认为主要是由整体的网络，数据吞吐量决定的，在使用HiBench测试时候发现，使用传统电口千兆网络的任务运行时间比光网任务运行时间要慢10s左右。HiBench的基准测试集是用来衡量一个大数据平台（基于Hadoop）性能的基准测试集，包含了文件系统的IO性能，系统的批处理吞吐，数据仓库用的OLAP分析算子，机器学习的处理能力，以及流处理系统的能力。
切换到光纤后，需要修改机器机器ip，这时候cdh居然没法启动了，百度之后，发现如果使用自带数据库postgresql，需要修改hosts表中记录的元数据信息：修改CDH集群ip
3.1 简介
hibench作为一个测试hadoop的基准测试框架，提供了对于hive：（aggregation，scan，join），排序（sort，TeraSort），大数据基本算法（wordcount，pagerank，nutchindex），机器学习算法（kmeans，bayes），集群调度（sleep），吞吐（dfsio），以及新加入5.0版本的流测试： 
we provide following streaming workloads for SparkStreaming, Storm . 

一个完整的TeraSort测试需要按以下三步执行：

用TeraGen生成随机数据
对输入数据运行TeraSort
用TeraValidate验证排好序的输出数据

所有hibench测试基本都是这样的流程，生成数据，运行，输出结果。
3.2 配置并编译HiBench
从GitHub下载HiBench开源包，本篇会基于HiBench-5.0为例。https://github.com/intel-hadoop/HiBench。如果是基于CDH 5.5测试，建议使用HiBench-5.0，其中包含了Spark 1.5的编译包。
编译

添加JAVA_HOME 环境变量
注释掉${HIBENCH_HOME} /src/streambench/pom.xml中两行

<!-- <module>stormbench</module> -->
<!-- <module>samzabench</module> -->

调用编译脚本：${HIBENCH_HOME}/bin/build-all.sh

配置

编辑 HiBench Configuration File：

cd ${HIBENCH_HOME}/conf
cp 99-user_defined_properties.conf.template 99-user_defined_properties.conf
编译配置文件，如下修改一些参数：
hibench.hadoop.home      /opt/cloudera/parcels/CDH/lib/hadoop 
  hibench.hadoop.mapreduce.home         /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce 
  hibench.spark.home                    /opt/cloudera/parcels/CDH/lib/spark 
  hibench.hdfs.master                   hdfs://cdh-node-11.cdhtest.com 
  hibench.hadoop.configure.dir          /etc/hadoop/conf 
  hibench.masters.hostnames            master # Resource Manager addresses 
  hibench.slaves.hostnames             hostname…
# Node Manager addresses
hibench.spark.master                  yarn-client 
  hibench.spark.version                spark1.6 
  spark.kryoserializer.buffer            2000m # 否则会出现大量spark.kryoserializer.buffer.mb被启用的警告 
  hibench.streamingbench.zookeeper.host         zookeeper-hostnames 
  hibench.streamingbench.brokerList             all-hostnames 
  hibench.streamingbench.kafka.home             /opt/cloudera/parcels/KAFKA

修改benchmarks.lst文件，只运行有必要的测试集，例：

#aggregation 
  #join 
  #kmeans 
  #pagerank 
  #scan 
  #sleep 
  sort 
  wordcount 
  #bayes 
  terasort 
  #nutchindexing 
  dfsioe

修改language.lst文件，只运行有必要的语言

cd ${HIBENCH_HOME}/conf
在language.lst文件中，将以下两行删除
spark/java 
  spark/python

修改load-config.py文件，确保Bench在运行时能找到唯一的包：

$HiBench-Home/bin/functions/load-config.py
将hadoop-mapreduce-client-jobclient*-tests.jar改为hadoop-mapreduce-client-jobclient-tests.jar

Bench在运行时有一些固化的目录和CDH不一致，需要建立目录引用

建立目录引用
mkdir -p /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  cd /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  ln -sf /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce mapreduce2

Bench会在HDFS根目录下生成文件，将HDFS的根目录权限修改为777：

sudo -u hdfs hadoop fs -chmod 777 /

（可选）如果在Kerberos启用的状况下，请增加以下步骤：

# 设置环境变量 
  export HIBENCH_HOME=/root/Downloads/HiBench-master 
  export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera 
  export JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export SPARK_YARN_USER_ENV=”JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH,LD_LIBRARY_PATH=$LD_LIBRARY_PATH”
# 重新登录Kerberos 
  kdestroy 
  kinit -k -t  


运行

命令行输入 

  ${HIBENCH_HOME}/bin/run-all.sh

3.3 HiBench基本优化配置

**优化基本原则**

在固定数据量的前提下，一般设置成让MapReduce作业在一轮Map、Reduce内结束，否则会增加MapReduce进程的调度开销。但如果输入的数据量过大，有可能会因为单个Map或者Reduce的内存消耗过大而到时严重的GC问题，这个需要在运行时对Map或者Reduce任务进程需要监测。

**YARN基本配置**





–
–



NodeManager
Container vCores数量就是系统的virtual core的数量Container Memory配置成节点上可用内存的75%到80%之间（如128GB的机器，可以设置96GB）


ResourceManager
Fair Scheduler调度器最小容器内存1GB 最小容器CPU 1个核最大容器内存=NodeManager Container内存的75%~80%最大容器CPU=NodeManager Container CPU的75%~80%增量内存512MB增量CPU 1个核


Gateway
mapreduce.map/reduce.max.mb = 2GBmapreduce.map/reduce.java.opts = max.mb * 0.8



附录（CDH 相关目录结构功能简介）

**1.相关目录**




/var/log/cloudera-scm-installer : 安装日志目录。 
  /var/log/* : 相关日志文件（相关服务的及CM的）。 
  /usr/lib64/cmf/ : Agent程序代码。 
  /var/lib/cloudera-scm-server-db/data : 内嵌数据库目录。 
  /usr/bin/postgres : 内嵌数据库程序。 
  /etc/cloudera-scm-agent/ : agent的配置目录。 
  /etc/cloudera-scm-server/ : server的配置目录。 
  /etc/clouder-scm-server/db.properties 默认元数据库用户名密码配置 
  /opt/cloudera/parcels/ : Hadoop相关服务安装目录。 
  /opt/cloudera/parcel-repo/ : 下载的服务软件包数据，数据格式为parcels。 
  /opt/cloudera/parcel-cache/ : 下载的服务软件包缓存数据。 
  /etc/hadoop/* : 客户端配置文件目录。


**2.配置**


Hadoop配置文件：

配置文件放置于/var/run/cloudera-scm-agent/process/目录下。如：

/var/run/cloudera-scm-agent/process/193-hdfs-NAMENODE/core-site.xml

这些配置文件是通过Cloudera Manager启动相应服务（如HDFS）时生成的，内容从数据库中获得（即通过界面配置的参数）。
在CM界面上更改配置是不会立即反映到配置文件中，这些信息会存储于数据库中，等下次重启服务时才会生成配置文件。且每次启动时都会产生新的配置文件。
CM Server主要数据库为scm基中放置配置的数据表为configs。里面包含了服务的配置信息，每一次配置的更改会把当前页面的所有配置内容添加到数据库中，以此保存配置修改历史。
scm数据库被配置成只能从localhost访问，如果需要从外部连接此数据库，修改

vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf

文件,之后重启数据库。运行数据库的用户为cloudera-scm。

查看配置内容

直接查询scm数据库的configs数据表的内容。 
访问REST API： http://hostname:7180/api/v4/cm/deployment，返回JSON格式部署配置信息。

配置生成方式

CM为每个服务进程生成独立的配置目录（文件）。所有配置统一在服务端查询数据库生成（因为scm数据库只能在localhost下访问）生成配置文件，再由agent通过网络下载包含配置文件的zip包到本地解压到指定的目录。

配置修改 
CM对于需要修改的配置预先定义，对于没有预先定义的配置,则通过在高级配置项中使用xml配置片段的方式进行配置。而对于/etc/hadoop/下的配置文件是客户端的配置，可以在CM通过部署客户端生成客户端配置。
数据库 
Cloudera manager主要的数据库为scm,存储Cloudera manager运行所需要的信息：配置，主机，用户等。
CM结构 
CM分为Server与Agent两部分及数据库（自带更改过的嵌入Postgresql）。它主要做三件事件： 
管理监控集群主机。 
统一管理配置。 
管理维护Hadoop平台系统。 
实现采用C/S结构，Agent为客户端负责执行服务端发来的命令，执行方式一般为使用python调用相应的服务shell脚本。Server端为Java REST服务，提供REST API，Web管理端通过REST API调用Server端功能，Web界面使用富客户端技术（Knockout）。 
Server端主体使用Java实现。 
Agent端主体使用Python, 服务的启动通过调用相应的shell脚本进行启动，如果启动失败会重复4次调用启动脚本。 
Agent与Server保持心跳，使用Thrift RPC框架。
升级 
在CM中可以通过界面向导升级相关服务。升级过程为三步： 
1.下载服务软件包。 
2.把所下载的服务软件包分发到集群中受管的机器上。 
3.安装服务软件包，使用软链接的方式把服务程序目录链接到新安装的软件包目录上。
卸载 
sudo /usr/share/cmf/uninstall-scm-express.sh, 然后删除/var/lib/cloudera-scm-server-db/目录，不然下次安装可能不成功。
开启postgresql远程访问 
CM内嵌数据库被配置成只能从localhost访问，如果需要从外部查看数据，数据修改vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf文件,之后重启数据库。运行数据库的用户为cloudera-scm。


参考文献
1.CDH官方文档 
2.http://www.cloudera.com/documentation.html 
3.CDH5.8官方文档 http://www.cloudera.com/documentation/enterprise/latest.html 
4.http://blog.selfup.cn/1631.html#comment-403 
5.https://github.com/intel-hadoop/HiBench 






 
2012-2-8 星期三
文件搜索命令:

which [命令名称]
功能：显示系统命令所在目录(绝对路径)

$which ls
whereis可以表现出命令的帮助信息，帮助文件说存放的信息
 

find --通用查找命令

语法：find[搜索路径][搜索关键字]
功能：查找文件或目录
 
-name 根据文件名来查找
find /etc -name init
在目录/etc中查找文件init（只匹配文件名init，通配符*匹配任意字符包括零个字符）
init* ： 以init开头的文件
？：匹配单个字符 init？？？：init后面还有三个符号
-size 文件大小 block数据块 512字节
100MB=102400kb=204800数据块block（只支持数据块的表示方法）
find /-size+204800
在根目录下查找大于100mb的文件
（大于+  小于-    等于 ）
find /home -user samlee
在根目录下查找所有者为samlee的文件
 
时间
1.ctime ，atime ，mtime天为单位
2.cmin，amin，mmin分钟为单位
c-change改变，表示文件的属性被修改过
a-access访问
m-modify修改 ，表示文件的内容被修改过
-之内
+超过
 
find /etc -mmin -120
find /etc -ctime -1


在/etc下查找24小时内被修改过属性的文件和目录
find /etc -size +163840 -a -size -204800

在/etc下查找大于80mb小于100mb的文件
find /etc -name inittab -exec ls -l{} \;

在/etc 下查找inittab文件并显示其详细信息

-type 文件类型 f 二进制文件 l 软链接文件 d 目录
1.连接符 -a and 逻辑与 -o or 逻辑或
2.连接符 find .....-exec 命令 {} \;
                              {}find查询的结果
                               \转义符，使用符号命令本身的意思
                   -ok 询问确认
 


无论文件名叫什么都可以根据文件的i节点来进行查找
内核才能调用他。
 

文件搜索命令：locate

locate（搜索关键字）
列出所有跟file相关的文件
文件搜索命令：updatedb
执行权限：root
语法：updatedb
功能描述：建立整个系统目录文件的数据库
范例：#updatedb
 
文件搜索命令：grep


语法：grep[指定字串][源文件]
功能描述：在文件中搜索字串匹配的行并输出
范例：grep ftp /etc/services
 

帮助命令：
命令名称：man

命令的英文原意：manual
命令所在的路径：/user/bin/man
执行权限：所用用户
语法：man[命令或者配置文件]
功能描述：获得帮助信息
man ls 查看ls命令的帮助信息
man services 查看配置文件services的帮助信息
 
 
帮助指令：info
语法：info[任何关键字]
功能描述：获得帮助信息{unix中没有这个命令}
 
帮助命令：whatis

whatis whatis
指令名称：whatis apropos makewhatis
search the whatis database for strings
 
语法：whatis apropos [任何关键字]
功能描述：获得索引的简短说明信息
apropos fstab 相当于man -k
补充命令：help 查看shell内置命令的帮助
 
linux 常用命令：压缩解压命令

-gz
命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
 
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz






                                            
 
2012-3-2
linux用户管理
用户信息文件：/etc/passwd
密码文件:/etc/shadow
用户组文件:/etc/group
用户组密码文件:/etc/gshadow
用户配置文件: /etc/login.defs  etc/default/useradd
新用户信息文件:/etc/ske 1
登陆信息:/etc/motd

linux用户分为三种:
超级用户:(root,UID =0)
普通用户:(UID:500-60000)
伪用户:(UID 1-499)

echo "123456" |md5sum ---产生123456的md5 加密密码
man 5 shadow 查看/etc/shadow中shadow的帮助,
 





 
centos6.0如果采用默认的最小化安装是没有安装桌面环境的，因此需要手动安装桌面环境。
我们可以用 #yum grouplist 查看已经安装的组件，以及支持安装的组件 首先，安装 X window system# yum groupinstall "
X Window system"由于centos6.0中只支持KDE组件，因此，安装KDE桌面环境#yum groupinstall "KDE Desktop"

开机为文本界面，由文本界面切换到图形界面：
    方法1：运行命令
          #startx ， 需要先配置图形界面信息
    方法2：修改/etc/inittab文件中的 
          id:3:initdefault ， 将3改为5 ，重新启动系统； 
    方法3：进入图形界面： init 5
 从图形界面进入文本界面： init 3
 重启： init 6
 关机： init 3 
真机环境中，在图形界面和文本界面间快捷键切换：
    Ctrl+Alt+F(n) , 其中F(n)为F1-F6 ，为6个控制台；
    Ctrl+ALT+F7 ；
eg:CTRL+ALT+F1是进入文本界面，CTRL+ALT+F7才是图形界面。
 

centos 下shutdown的命令后跟时间的单位是分钟
shutdown 60是60分钟后关机。

2012-1-20
从新安装了centos，选择desktop 安装桌面以及xwindows环境。1063个软件包。
2012-2-2
1.除了/之外所有字符都合法
2.有的字符，空格符，制表符，退格符和@#最好不要使用
3.避免使用.作为普通文件名的第一个字符。（.开头表示隐藏文件）
4.大小写敏感






                                            
 
2012-2-13
linux 引导流程
1.固件firmware（cmos，bios）-》post加点自检
2.自举程序Bootloader（grub）-》载入内核
3.载入内核                  -》驱动硬件
4.启动进程init              -》系统启动的第一个进程
5.读取执行配置文件 /etc/inittab
 
master boot record->MBR主引导扇区 位置：0驻面0磁头1扇区
插入图片：
bootloader中存放的是自举程序：
windows中为：--》ntldr 以及 boot.ini文件中的内容
linux中为：  --》/etc/grub.conf
 
 
init的工作：
init启动后读取inittab文件，执行缺省运行级别而继续从而引导过程。在unix系统中
，init时第一个可以存在的进程，它的PID恒为1，但他也同时必须向一个更高级的功能负责
：PID为0的内核调度器（kernel scheduler），从而获得cpu时间
 
 
 

inittab 文件剖析

在inittab中，所有的条目采取以下格式：
id：run-level:action:process
id:标示符，一般为两位数字或者字母或者数字
run—level：指定运行级别可以指定多个
action：指定运行状态
process：指定要运行的脚本/命令
 
action常用取值：
initdefault：指定系统缺省启动的运行级别
sysinit：系统启动执行process中的运行级别
wait：执行process中指定的命令，并等起结束再运行其他命令
once：执行process中指定的命令，不等待其结果
ctrlaltdel：按下Ctrl+alt+del时执行process指定的命令
powerfail：当出现电源错误时执行process指定的命令，不等待其结束
powerokwait：当电源恢复是执行process指定的命令
respawn：一旦process指定的命令中止，便重新运行该命名
 
任何的系统级别都会起动系统的启动脚本：
/etc/rc.d/rc.sysinit         
ls /etc/rc.d/rc3.d 可以看到系统启动对应级别下需要执行的脚本操作
/etc/rc.d/rc[0123456].d
分别存放对应于运行级别的服务程序脚本的符号链接，链接到init.d目录中相应的脚本
 
比如：s12syslog
s—start
k—kill
数字
脚本名称
 
启动流程：插入图片：

 
 






1.注意事项编译的办法参见：http://blog.csdn.net/wangyaninglm/article/details/39997113 以下是程序代码，网上搜的例子：注意事项：32位工程添加64位的支持（主要取决于你编译的版本），配置好cuda的项目路径include2.代码//swap.cu


#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <opencv2/core/cuda_devptrs.hpp>
using namespace cv;
using namespace cv::gpu;

//自定义内核函数
__global__ void swap_rb_kernel(const PtrStepSz<uchar3> src,PtrStep<uchar3> dst)
{
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    if(x < src.cols && y < src.rows)
    {
        uchar3 v = src(y,x);
        dst(y,x) = make_uchar3(v.z,v.y,v.x);
    }
}

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream)
{
    dim3 block(32,8);
    dim3 grid((src.cols + block.x - 1)/block.x,(src.rows + block.y - 1)/block.y);

    swap_rb_kernel<<<grid,block,0,stream>>>(src,dst);
    if(stream == 0)
        cudaDeviceSynchronize();
}  //swap.cpp



#include <opencv2/gpu/gpu.hpp>
#include <opencv2/gpu/stream_accessor.hpp>


using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream);

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null())
{
	CV_Assert(src.type() == CV_8UC3);
	dst.create(src.size(),src.type());
	cudaStream_t s = StreamAccessor::getStream(stream);
	swap_rb_caller(src,dst,s);
}
 //main.cpp

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/gpu/gpu.hpp>

#pragma comment(lib,"opencv_gpu2410d.lib")
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")

using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null());

int main()
{
	Mat image = imread("lena.jpg");
	imshow("src",image);
	GpuMat gpuMat,output;

	gpuMat.upload(image);
	swap_rb(gpuMat,output);
	output.download(image);

	imshow("gpu",image);
	getchar();
	waitKey(0);
	return 0;
} 3.实现效果： 4.其他注意事项假设有两个工程：CUDA工程TestCuda；C++工程CallCuda 1. 在CUDA工程TestCuda中， （1）.cpp文件（类成员函数定义）调用.cu文件下的函数例如.cu文件下的函数void run_kernel(); 其前面必须用 extern “C” 修饰。而.cpp文件（类成员函数定义）下的类成员函数，如，void cpp_run();如果它想调用 run_kernel()，则首先可在.h文件（类定义）中的类定义的外面先声明.cu文件下的C函数，例如，extern “C” void run_kernel();（2）CUDA工程属性-->常规中，选择配置类型为“静态库(.lib)”-->应用； 同时在工程属性下的库管理器-->常规项下的附加依赖项中，添加CUDA库：cudart.lib，curand.lib等；在附加库目录添加相应的库所在目录。2.另外的C++工程CallCuda 在CallCuda工程属性下，找到附加依赖项，添加：CUDA库(cudart.lib等)和TestCuda生成的静态库(TestCuda.lib)；以及添加附加库目录。 至此，该工程下的.cpp文件下的函数，就可以调用CUDA工程下的cpp_run()函数了，不过首先要实例化类。1.将example.cu添加到工程中。在已有工程上右键单击，选择添加已有项。2.添加编译规则。右键单击工程文件，选择“自定义生成规则”，在弹出的对话框中选择CUDA Build Rule x.x。3.修改.cu文件的编译器。右键单击.cu文件，单击属性，修改编译规则，选择刚才添加的CUDA编译器。4.添加包含目录。在项目属性-》C++->常规->附加包含目录中添加CUDA SDK的目录。例如"C:\Program Files\NVIDIA Corporation\NVIDIA GPU Computing SDK 3.2\C\common\inc";"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.0\include"5.添加.lib文件。在链接器-》输入中添加cudart.lib cutil32D.lib6.修改代码生成为多线程(/MT)方式。7.Done.  以上是工程配置。 除此之外，还要把调用cuda代码的c++函数在.cu文件中用extern "C" 包含起来。并且在调用文件.cpp中用extern "C"声明该函数，然后调用。   





 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
 
//得9 分
//为了实现链式操作，将目的地址返回，加2 分！
char * strcpy( char *strDest, const char *strSrc )
{
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while( (*strDest++ = * strSrc++) != '/0' );
return address;
}

//得10 分，基本上所有的情况，都考虑到了
//如果有考虑到源目所指区域有重叠的情况，加1 分！
char * strcpy( char *strDest, const char *strSrc )
{
if(strDest == strSrc) { return strDest; }
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while((*strDest++ = *strSrc++)!='/0');
return address;
}


 
 
strncpy 是 C语言的函数之一，来自 C语言标准库，定义于 string.h，char *strncpy(char *destin, char *source, int maxlen)，把src所指由NULL结束的字符串的前n个字节复制到dest所指的数组中。
char *strncpy(char *strDes, const char *strSrc, unsigned int count)
{
assert(strDes != NULL && strSrc != NULL);
char *address = strDes;
while (count-- && *strSrc != '/0')
*strDes++ = *strSrc++;
*strDes = '/0';
return address;
}
 
 
 
strcpy和memcpy都是标准C库函数，它们有下面特点：
strcpy提供了字符串的复制。即strcpy只用于字符串复制，并且它不仅复制字符串内容外，还会复制字符串的结束符。
strcpy的函数原型是：char* strcpy(char* dest, const char* src);
 
memcpy只提供一般的内存复制，即memcpy对于需要复制的内容没有限制，因此用途更广。
memcpy的函数原型是：void *memcpy(void *dest,  const char* src,  size_t count);
 
  char *strcpy(char *dest, const char *src)  {     if((src == NULL) || (dest == NULL))      {          return NULL;     }
      char *strdest = dest; // 保存目标字符串的首地址     while((*dest++ = *str) != '\0');
     return strdest;
 }


 
 


void *memcpy(void *memTo, const char *memFrom, size_t size)
{
     if((memTo == NULL) || (memFrom == NULL))
     {
          return NULL;
     }
     char *tempFrom = (char *)memFrom; //保存memFrom的首地址     char *tempTo = (char *)memTo; //保存memTo的首地址      while(size-- > 0)
     {
          *tempTo++ = *tempFrom++;
     }
     return memTo;
}


 
strcpy 和 memcpy主要有以下三方面的区别：
1、复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符串、整型、结构体、类等。
2、复制的方法不同。strcpy不需要指定长度，它遇到被复制字符串的结束符"\0”才结束，所以容易溢出。memcpy则是根据第3个参数决定复制的长度。
3、用途不同。通常在复制字符串时用strcpy，而需要复制其它类型的数据是用memcpy。
 
memcpy 和 memmove 都是C语言中的库函数，在库函数 string.h中，其原型相似，它们都是从src所指向的内存中复制count个字节到dest所指内存中。并返回dest的值。
当源内存区域 和 目标内存区域无交叉重叠时，两者的结果是一样的，但如果有交叉呢？
memcpy是从src的其实部分开始复制，所以虽然第一种情况下没有问题，但如果遇到第二种情况，则会发生错误，交叉部分的src内容就会被覆盖掉了。
而memmove则由于采用不同的复制机制，所以可以正确处理第二种情况。
 
 


void *memmove(void *dst,const void *src,int n)
{
     char *dp = (char *)dst;
     char *sp = (char *)src; 
     assert((src!=0)&&(dst!=0)&&(n>0));//not　null 
     //非重叠 
      //dp < sp 
     //dp > (sp+n)     if(sp>dp||(sp+n)<dp)
     { 
         while(n--) 
             *(dp++) = *(sp++);
         *dp = '\0';
     }
     else if(sp<dp)//重叠 (此时条件 sp<dp<(sp+n))如果sp==dp则快速的返回     {//反向拷贝            sp += n; 
         dp += n; 
         *dp = '\0'; 
         while(n--)
            *(--dp) = *(--sp); 
     }
     return dst;
}       


 
在很多库函数上看到使用了assert()函数，assert函数的作用是计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条错误信息，然后调用abort()来终止进程。
函数名: abort
功 能: 异常终止一个进程
描述：abort()函数首先解除进程对SIGABRT信号的阻止，然后向调用进程发送该信号。abort()函数会导致进程的异常终止除非SIGABRT信号被捕捉并且信号处理句柄没有返回。
abort()函数导致所有的流被关闭和冲洗。
abort()函数没有返回值：void abort(void);
用 法: void abort(void);
程序例:
#include <stdio.h>
#include <stdlib.h>
int main(void) 
{ 
printf("Calling abort()\n");
abort();
return 0; /* This is never reached */
 }




 






下面是一个百度空间的：
http://hi.baidu.com/jensenliao

博客园的一篇博客：theONE模拟器简介（主要讲述，软件配置，软件结构）
http://www.cnblogs.com/dreamfactory/archive/2012/07/27/2612215.html

博客园，theONE模拟器简介，图表脚本生成，路由修改
http://www.cnblogs.com/jcleung/archive/2011/05/23/2054713.html

csdn，theONE消息转发流程分析
http://blog.csdn.net/u010816631/article/details/8984596


QQ交流群：


DTN--(ONE)  群   号：9859819
DTN            群号：17384685
















 
 图割论文大合集下载：
http://download.csdn.net/detail/wangyaninglm/8292305
 
代码：
/* graph.h */
/* Vladimir Kolmogorov (vnk@cs.cornell.edu), 2001. */

/*
	This software library is a modification of the maxflow algorithm
	described in

	An Experimental Comparison of Min-Cut/Max-Flow Algorithms
	for Energy Minimization in Computer Vision.
	Yuri Boykov and Vladimir Kolmogorov.
	In Third International Workshop on Energy Minimization
	Methods in Computer Vision and Pattern Recognition, September 2001

	This algorithm was originally developed at Siemens.
	The main modification is that two trees are used for finding
	augmenting paths - one grows from the source and the other
	from the sink. (The original algorithm used only the former one).
	Details will be described in my PhD thesis.

	This implementation uses an adjacency list graph representation.邻接链表
	Memory allocation:
		Nodes: 22 bytes + one field to hold a residual capacity
		       of t-links (by default it is 'short' - 2 bytes)
		Arcs: 12 bytes + one field to hold a residual capacity 剩余容量
		      (by default it is 'short' - 2 bytes)
	(Note that arcs are always added in pairs （弧都是成对的添加）- in forward and reverse directions)

	Example usage (computes a maxflow on the following graph):

		        SOURCE
		       /       \
		     1/         \2
		     /      3    \
		   node0 -----> node1
		     |   <-----   |
		     |      4     |
		     \            /
		     5\          /6
		       \        /
		          SINK

	///////////////////////////////////////////////////

	#include <stdio.h>
	#include "graph.h"

	void test_maxflow()
	{
		Graph::node_id nodes[2];
		Graph *g = new Graph();

		nodes[0] = g -> add_node();
		nodes[1] = g -> add_node();
		g -> set_tweights(nodes[0], 1, 5);
		g -> set_tweights(nodes[1], 2, 6);
		g -> add_edge(nodes[0], nodes[1], 3, 4);

		Graph::flowtype flow = g -> maxflow();

		printf("Flow = %d\n", flow);
		printf("Minimum cut:\n");
		if (g->what_segment(nodes[0]) == Graph::SOURCE)
			printf("node0 is in the SOURCE set\n");
		else
			printf("node0 is in the SINK set\n");
		if (g->what_segment(nodes[1]) == Graph::SOURCE)
			printf("node1 is in the SOURCE set\n");
		else
			printf("node1 is in the SINK set\n");

		delete g;
	}

	///////////////////////////////////////////////////
*/

 
 
void test_maxflow()
{
	Graph::node_id nodes[2];
	Graph *g = new Graph();

	nodes[0] = g -> add_node();
	nodes[1] = g -> add_node();
	g -> set_tweights(nodes[0], 3, 3);
	g -> set_tweights(nodes[1], 3, 1);
	g -> add_edge(nodes[0], nodes[1], 1, 0);

	Graph::flowtype flow = g -> maxflow();

	printf("Flow = %d\n", flow);
	printf("Minimum cut:\n");
	if (g->what_segment(nodes[0]) == Graph::SOURCE)
		printf("node0 is in the SOURCE set\n");
	else
		printf("node0 is in the SINK set\n");
	if (g->what_segment(nodes[1]) == Graph::SOURCE)
		printf("node1 is in the SOURCE set\n");
	else
		printf("node1 is in the SINK set\n");

	delete g;
}

 
 

 
 
这块主要就是要理解，什么是maxflow，以及节点最后分割的类型是SOURCE还是SINK分别意味着什么
 
graphcuts算法时间复杂度与其他最大流算法的比较：

 
 
 
添加几篇文章地址：
 
graphcuts资料博客大合集
http://vision.csd.uwo.ca/code/
 
http://lincccc.blogspot.tw/2011/04/graph-cut-and-its-application-in.html
http://blog.csdn.net/zouxy09/article/details/8532106
http://lincccc.blogspot.tw/2011/03/cuda-cuts-fast-graph-cuts-on-gpu_03.html
http://blog.csdn.net/hebby06/article/details/5341228









1.HiBench算法简介
Hibench 包含9个典型的hadoop负载（micro benchmarks,hdfs benchmarks,web search bench marks,machine learning benchmarks和data analytics benchmarks）
具体参考CDH集群安装&测试总结：第三节内容

micro benchmarks 
Sort:使用hadoop randomtextwriter生成数据，并对数据进行排序。 
Wordcount:统计输入数据中每个单词的出现次数，输入数据使用hadoop randomtextwriter生成。 
TeraSort：输入数据由hadoop teragen产生，通过key值进行排序。
hdfs benchmarks 
增强行的dfsio：通过产生大量同时执行读写请求的任务测试hadoop机群的hdfs吞吐量
web search bench marks 
Nutch indexing:大规模收索引擎，这个是负载测试nutch（apache的一个开源搜索引擎）的搜索子系统，使用自动生成的web数据，web数据中的连接和单词符合zipfian分布（一个单词出现的次数与它在频率表的排名成反比） 
Pagerank:这个负载包含在一种在hadoop上的pagerank的算法实现，使用自动生成的web数据，web数据中的链接符合zipfian分布。（对于任意一个term其频度（frequency）的排名（rank）和frequency的乘积大致是一个常数）
machine learning benchmarks 
Mahout bayesian classification(bayes):大规模机器学习，这个负载测试mahout（apache开源机器学习库）中的naive bayesian 训练器，输入的数据是自动生成的文档，文档中的单词符合zipfian分布。 
Mahout k-means clustering(kmeans):测试mahout中的k-means聚类算法，输入的数据集由基于平均分布和高斯分布的genkmeansdataset产生。
data analytics benchmarks 
Hive query benchmarks(hivebench):包含执行的典型olap查询的hive查询（aggregation和join），使用自动生成的web数据，web数据的链接符合zipfian分布。

注：使用的生成数据程序在hadoop-mapreduce-examples-2.6.0 jar 包内，可以使用反编译工具查看。


2.HiBench中bayes算法流程

主要流程为conf下配置测试项，测试语言和DataSize，然后运行bin下run-all.sh完成一次测试，此流程为手动完成，可以编写脚本重复此步骤完成多次测试减少手动操作； 
e.g.

#!/bin/bash

#       Time: 20160930,created by sunfei
#       Describe: automatic run the hibench
#       Functions :
#            search(): Find the style of application in the  99-user_defined_properties.conf,eg:tiny,small..
#                               exec_application_noSQL(): run the application for times,and no use hive
#                               exec_application_SQL(): run the application for times,and use hive
#                               save_result(): save the result of application
#                               main_function(): the main function of running all the appliction
#                               main(): the main function of running different kind application


cpuLoad()
{
        cpu=`grep -c 'model name' /proc/cpuinfo`
        load_15=`uptime | awk '{print $NF}'`
        average_load=`echo "scale=2;a=${load_15}/${cpu};if(length(a)==scale(a)) print 0;print a" | bc`
        date >> datetime-load.txt
        ${average_load} >> cpu-load.txt
        paste datetime-load.txt cpu-load.txt >> load-day.txt
}

search()
{
        #config="/opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf"
        config=/usr/HiBench-master/conf/99-user_defined_properties.conf
        sed -n '/hibench.scale.profile/p' ${config} >> hibench.txt
        var=''
        while read line
        do
                        if [ ${line:0:13} = "hibench.scale" ];then
                                        echo -e "\033[32m match sucessfull! \033[0m"
                                        var=${line:22}
                        fi
        done<"hibench.txt"

        if [ "$var" = "${1}" ];then
                echo -e "\033[31m The style of application can't same,do you want to continue? yes | no \033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The ${1}  style of application will be run! \033[0m"
                fi
        fi

        if [ -f "hibench.txt" ];then
                        rm -rf "hibench.txt"
                        echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi

        echo -e "\033[32m The application will run the "${1}" style \033[0m"
    sed -i "s/${var}/${1}/" ${config}
}

exec_application_noSQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m ********************** The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"
}

exec_application_SQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        echo "drop table uservisits;drop table uservisits_aggre;drop table rankings;drop table rankings_uservisits_join;drop table uservisits_copy;exit;" | /usr/bin/hive
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m **********************The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"

}

save_result()
{
        if [ -f result.txt ];then
                        rm -rf result.txt
                         echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi
        #select the words in the report
        #filepath=/opt/HiBench/HiBench-master/report/hibench.report
        filepath=/usr/HiBench-master/report/hibench.report
        word=""
        var1=`date +"%m/%d/%Y-%k:%M:%S"`
        var2=${1}
        var5=".txt"
        var4=${var2}${var5}
        case ${1} in
        "aggregation")
                word="JavaSparkAggregation"
                ;;
        "join")
                word="JavaSparkJoin"
                ;;
        "scan")
                word="JavaSparkScan"
                ;;
        "kmeans")
                word="JavaSparkKmeans"
                ;;
        "pagerank")
                word="JavaSparkPagerank"
                ;;
        "sleep")
                word="JavaSparkSleep"
                ;;
        "sort")
                word="JavaSparkSort"
                ;;
        "wordcount")
                word="JavaSparkWordcount"
                ;;
        "bayes")
                word="JavaSparkBayes"
                ;;
        "terasort")
                word="JavaSparkTerasort"
                ;;
        *)
                echo -e "\033[32m The name of application is wrong,please change it! \033[0m"
                ;;
        esac

        while read line
        do
                        echo $line | sed -n "/${word}/p" >> ${var4}
        done <$filepath
        echo -e "\033[32m The job has finished! \033[0m"
}

main_function()
{
        #Input the name of application need to exec
        for appName in aggregation join scan pagerank sleep sort wordcount bayes terasort kmeans
        do
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                echo "The name of application is :"${appName}
                echo ${appName} > ${appConfig}
                        for style in tiny small large huge gigantic
                        do
                                search ${style}
                                if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${1}
                                else
                                                        exec_application_noSQL ${1}
                                fi
                        done
                save_result ${appName}
        done
}

main()
{
        # run the application
        read -p "Input the times of exec: " times
        if [ "${times}" -eq 0 -o "${times}" -gt 60 ];then
                echo -e "\033[31m The times of application can't be empty or gt 60 ! Do you want to continue ? yes | no\033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The application will be run ${times} times ! \033[0m"
                fi
        fi
        echo -e "\033[33m Select the style of application : \033[0m \033[31m All | Signal \033[0m"
        read -p "Input your chose :" style
        if [ "${style}" = "" ];then
                echo -e "\033[31m The style of application can't be empty \033[0m"
                exit 1
        elif [ "${style}" != "All" -a "${style}" != "Signal" ];then
                echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                exit 1
        else
                echo -e "\033[32m The style of application is ok ! \033[0m"
        fi
        if [ "All" = "${style}" ];then
                main_function ${times}
        else
                echo -e "\033[033m Input the name of apliaction,eg:\033[0m \033[31m aggregation | join | scan | kmeans | pagerank | sleep | sort | wordcount | bayes | terasort\033[0m"
                read -p "Input you chose :" application
                if [ "${application}" = "" ];then
                                echo -e "\033[31m The name of application can't be empty! \033[0m"
                                exit 1
                fi
                echo "********************The ${application} will be exec**********************"
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                read -p "Do you want exec all the style of application,eg:tiny,small,large,huge,gigantic? yes | no " chose
                if [ "${chose}" = "" ];then
                        echo -e "\033[31m The style of application can't be empty! \033[0m"
                        exit 1
                elif [ "yes" != ${chose} ] && [ "no" != ${chose} ];then
                        echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                        exit 1
                else
                        echo -e "\033[32m The style of application is ok ! \033[0m"
                fi
                read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                echo "***************************The ${appStyle} style will be exec***************************"
                for appName in ${application}
                do
                        echo ${appName} > ${appConfig}
                        if [ "yes" = "${chose}" ];then
                                for var in tiny small large huge gigantic
                                do
                                        echo "******************The ${appName} will be exec!************************************"
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${times}
                                        else
                                                        exec_application_noSQL ${times}
                                        fi
                                done
                        else
                        #       read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                                echo "**************************The ${appName} will be exec!************************"
                                if [ "${appStyle}" = "" ];then
                                                echo -e "\033[31m The style of application can't be empty! \033[0m"
                                                exit 1
                                fi
                                for var in ${appStyle}
                                do
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                exec_application_SQL ${times}
                                        else
                                                exec_application_noSQL ${times}
                                        fi
                                done
                        fi
                        save_result ${appName}
                done
        fi
}

# the main function of application
main

prepare.sh->run.sh为run-all.sh的子流程；
enter_bench->…->leave_bench为prepare.sh和run.sh的子流程；
enter_bench…..gen_report等为workload-functions.sh中的公共函数。

流程图如下：

2.1 数据生成代码分析，接口：HiBench.DataGen
对java代码我不太熟悉，接口中我看主要用了一个switch语句
DataGen类中DataOptions options = new DataOptions(args); 
如果是bayes测试的话，就调用对应的数据生成类，进行数据生成。生成的数据接口部分代码：
case BAYES: {
                BayesData data = new BayesData(options);
                data.generate();
                break;
            }
BayesData实现：
package HiBench;

import java.io.IOException;
import java.net.URISyntaxException;
import java.util.Random;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.Mapper;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapred.SequenceFileOutputFormat;
import org.apache.hadoop.mapred.lib.NLineInputFormat;

public class BayesData {

    private static final Log log = LogFactory.getLog(BayesData.class.getName());

    private DataOptions options;
    private Dummy dummy;
    private int cgroups;

    BayesData(DataOptions options) {
        this.options = options;
        parseArgs(options.getRemainArgs());
    }

    private void parseArgs(String[] args) {

        for (int i=0; i<args.length; i++) {
            if ("-class".equals(args[i])) {
                cgroups = Integer.parseInt(args[++i]);
            } else {
                DataOptions.printUsage("Unknown bayes data arguments -- " + args[i] + "!!!");
                System.exit(-1);
            }
        }
    }

    private static class CreateBayesPages extends MapReduceBase implements
    Mapper<LongWritable, Text, Text, Text> {

        private static final Log log = LogFactory.getLog(CreateBayesPages.class.getName());

        private long pages, slotpages;
        private int groups;
        private HtmlCore generator;
        private Random rand;

        public void configure(JobConf job) {
            try {
                pages = job.getLong("pages", 0);
                slotpages = job.getLong("slotpages", 0);
                groups = job.getInt("groups", 0);

                generator = new HtmlCore(job);
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }

        @Override
        public void map(LongWritable key, Text value,
                OutputCollector<Text, Text> output, Reporter reporter)
                throws IOException {

            int slotId = Integer.parseInt(value.toString().trim());
            long[] range = HtmlCore.getPageRange(slotId, pages, slotpages);
            generator.fireRandom(slotId);
            rand = new Random(slotId * 1000 + 101);

            Text k = new Text();
            for (long i=range[0]; i<range[1]; i++) {
                String classname = "/class" + rand.nextInt(groups);
                k.set(classname);
                value.set(generator.genBayesWords());
                output.collect(k, value);
                reporter.incrCounter(HiBench.Counters.BYTES_DATA_GENERATED,
                    k.getLength()+value.getLength());
                if (0==(i % 10000)) {
                    log.info("still running: " + (i - range[0]) + " of " + slotpages);
                }
            }
        }
    }

    private void setBayesOptions(JobConf job) throws URISyntaxException {
        job.setLong("pages", options.getNumPages());
        job.setLong("slotpages", options.getNumSlotPages());
        job.setInt("groups", cgroups);

        Utils.shareWordZipfCore(options, job);
    }

    private void createBayesData() throws IOException, URISyntaxException {

        log.info("creating bayes text data ... ");

        JobConf job = new JobConf();

        Path fout = options.getResultPath();
        Utils.checkHdfsPath(fout);

        String jobname = "Create bayes data";
        job.setJobName(jobname);

        Utils.shareDict(options, job);

        setBayesOptions(job);

        FileInputFormat.setInputPaths(job, dummy.getPath());
        job.setInputFormat(NLineInputFormat.class);

        job.setJarByClass(CreateBayesPages.class);
        job.setMapperClass(CreateBayesPages.class);
        job.setNumReduceTasks(0);

        FileOutputFormat.setOutputPath(job, fout);
        job.setOutputFormat(SequenceFileOutputFormat.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);

        log.info("Running Job: " +jobname);
        log.info("Pages file " + dummy.getPath() + " as input");
        log.info("Rankings file " + fout + " as output");
        JobClient.runJob(job);
        log.info("Finished Running Job: " + jobname);
    }

    private void init() throws IOException {

        Utils.checkHdfsPath(options.getResultPath(), true);
        Utils.checkHdfsPath(options.getWorkPath(), true);

        dummy = new Dummy(options.getWorkPath(), options.getNumMaps());

        int words = RawData.putDictToHdfs(new Path(options.getWorkPath(), HtmlCore.getDictName()), options.getNumWords());
        options.setNumWords(words);

        Utils.serialWordZipf(options);
    }

    public void generate() throws Exception {

        init();

        createBayesData();

        close();
    }

    private void close() throws IOException {
        log.info("Closing bayes data generator...");
        Utils.checkHdfsPath(options.getWorkPath());
    }
}

prepare.sh运行时输出如下，可以看到刚开始主要是读取配置文件中的内容，随后调用hadoop和jar包跑了一个任务，这个就是bayes文本分类的生成数据，按照第一节以及介绍的和官网的说明，这个文本主要使用linux中的字典：”/usr/share/dict/words”并且符合zipfian分布。
[hdfs@sf11 prepare]$ ./prepare.sh  
patching args= 
Parsing conf: /opt/HiBench/HiBench-master/conf/00-default-properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/01-default-streamingbench.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/10-data-scale-profile.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/20-samza-common.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/30-samza-workloads.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/00-bayes-default.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/10-bayes-userdefine.conf 
probe sleep jar: /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-tests.jar 
start HadoopPrepareBayes bench 
/opt/HiBench/HiBench-master/bin/functions/workload-functions.sh: line 120: /dev/stderr: Permission denied 
rm: `hdfs://archive.cloudera.com:8020/HiBench/Bayes/Input’: No such file or directory 
Submit MapReduce Job: /opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop –config /etc/hadoop/conf jar /opt/HiBench/HiBench-master/src/autogen/target/autogen-5.0-SNAPSHOT-jar-with-dependencies.jar HiBench.DataGen -t bayes -b hdfs://archive.cloudera.com:8020/HiBench/Bayes -n Input -m 300 -r 1600 -p 500000 -class 100 -o sequence 
16/10/21 16:34:02 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this. 
16/10/21 16:34:32 INFO HiBench.BayesData: Closing bayes data generator… 
finish HadoopPrepareBayes bench
部分生成数据：

在看了将近两周的HiBench代码进行测试后，终于摸清上述的运行流程，intel 的这个测试框架确实比较简介，通过配置文件和shell以及一些大数据框架自带的例子（如Hibench中的workcount测试就是直接调用hadoop或者spark自带的程序）完成了整个庞大的测试工作，下面我们针对贝叶斯文本分类算法中HiBench使用的三种语言：python，scala，java分别进行分析：
2.3 python代码分析
 

部分python代码：
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""
A naive bayes program using MLlib.

This example requires NumPy (http://www.numpy.org/).
"""

import sys

from pyspark import SparkContext
from pyspark.mllib.util import MLUtils
from pyspark.mllib.classification import NaiveBayes
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.linalg import Vectors
from pyspark.storagelevel import StorageLevel
from operator import add
from itertools import groupby
#
# Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
#
def parseVector(line):
    return np.array([float(x) for x in line.split(' ')])

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print >> sys.stderr, "Usage: bayes <file>"
        exit(-1)
    sc = SparkContext(appName="PythonNaiveBayes")
    filename = sys.argv[1]


    data = sc.sequenceFile(filename, "org.apache.hadoop.io.Text", "org.apache.hadoop.io.Text")
    wordCount = data                                \
        .flatMap(lambda (key, doc):doc.split(" "))    \
        .map(lambda x:(x, 1))                                \
        .reduceByKey(add)

    wordSum = wordCount.map(lambda x:x[1]).reduce(lambda x,y:x+y)
    wordDict = wordCount.zipWithIndex()             \
        .map(lambda ((key, count), index): (key, (index, count*1.0 / wordSum)) )             \
        .collectAsMap()
    sharedWordDict = sc.broadcast(wordDict)

    # for each document, generate vector based on word freq
    def doc2vector(dockey, doc):
        # map to word index: freq
        # combine freq with same word
        docVector = [(key, sum((z[1] for z in values))) for key, values in
                     groupby(sorted([sharedWordDict.value[x] for x in doc.split(" ")],
                                    key=lambda x:x[0]),
                             key=lambda x:x[0])]

        (indices, values) = zip(*docVector)      # unzip
        label = float(dockey[6:])
        return label, indices, values

    vector = data.map( lambda (dockey, doc) : doc2vector(dockey, doc))

    vector.persist(StorageLevel.MEMORY_ONLY)
    d = vector.map( lambda (label, indices, values) : indices[-1] if indices else 0)\
              .reduce(lambda a,b:max(a,b)) + 1


#    print "###### Load svm file", filename
    #examples = MLUtils.loadLibSVMFile(sc, filename, numFeatures = numFeatures)
    examples = vector.map( lambda (label, indices, values) : LabeledPoint(label, Vectors.sparse(d, indices, values)))

    examples.cache()

    # FIXME: need randomSplit!
    training = examples.sample(False, 0.8, 2)
    test = examples.sample(False, 0.2, 2)

    numTraining = training.count()
    numTest = test.count()
    print " numTraining = %d, numTest = %d." % (numTraining, numTest)
    model = NaiveBayes.train(training, 1.0)

    model_share = sc.broadcast(model)
    predictionAndLabel = test.map( lambda x: (x.label, model_share.value.predict(x.features)))
#    prediction = model.predict(test.map( lambda x: x.features ))
#    predictionAndLabel = prediction.zip(test.map( lambda x:x.label ))
    accuracy = predictionAndLabel.filter(lambda x: x[0] == x[1]).count() * 1.0 / numTest

    print "Test accuracy = %s." % accuracy


2.4 scala 代码分析
run-spark-job org.apache.spark.examples.mllib.SparseNaiveBayes ${INPUT_HDFS}
显然scala 的朴素贝叶斯就是调用spark mllib库中的代码了
 
 

2.5 java 代码分析
run-spark-job com.intel.sparkbench.bayes.JavaBayes ${INPUT_HDFS}
java部分比较意外的HiBench没有采用原生的代码或者jar包，而是自己写了一个 
代码如下，回头慢慢分析：
/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.intel.sparkbench.bayes;

import org.apache.spark.SparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.broadcast.Broadcast;
import org.apache.spark.mllib.classification.NaiveBayesModel;
import org.apache.spark.mllib.linalg.Vectors;
import org.apache.spark.rdd.RDD;
import org.apache.spark.storage.StorageLevel;
import scala.*;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.mllib.regression.LabeledPoint;
import org.apache.spark.mllib.util.MLUtils;
import org.apache.spark.mllib.classification.NaiveBayes;
import org.apache.hadoop.io.Text;

import java.lang.Boolean;
import java.lang.Double;
import java.lang.Long;
import java.util.*;
import java.util.regex.Pattern;


/*
 * Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
 */
public final class JavaBayes {
  private static final Pattern SPACE = Pattern.compile(" ");

  public static void main(String[] args) throws Exception {

    if (args.length < 1) {
      System.err.println("Usage: JavaBayes <file>");
      System.exit(1);
    }

    Random rand = new Random();

    SparkConf sparkConf = new SparkConf().setAppName("JavaBayes");
    JavaSparkContext ctx = new JavaSparkContext(sparkConf);
//    int numFeatures = Integer.parseInt(args[1]);

    // Generate vectors according to input documents
    JavaPairRDD<String, String> data = ctx.sequenceFile(args[0], Text.class, Text.class)
            .mapToPair(new PairFunction<Tuple2<Text, Text>, String, String>() {
                @Override
                public Tuple2<String, String> call(Tuple2<Text, Text> e) {
                    return new Tuple2<String, String>(e._1().toString(), e._2().toString());
                }
            });

    JavaPairRDD<String, Long> wordCount = data
            .flatMap(new FlatMapFunction<Tuple2<String, String>, String>() {
                @Override
                public Iterable<String> call(Tuple2<String, String> e) {
                    return Arrays.asList(SPACE.split(e._2()));
                }
            })
            .mapToPair(new PairFunction<String, String, Long>() {
                @Override
                public Tuple2<String, Long> call(String e) {
                    return new Tuple2<String, Long>(e, 1L);
                }
            })
            .reduceByKey(new Function2<Long, Long, Long>() {
                @Override
                public Long call(Long i1, Long i2) {
                    return i1 + i2;
                }
            });

      final Long wordSum = wordCount.map(new Function<Tuple2<String, Long>, Long>(){
          @Override
          public Long call(Tuple2<String, Long> e) {
              return e._2();
          }
      })
      .reduce(new Function2<Long, Long, Long>() {
          @Override
          public Long call(Long v1, Long v2) throws Exception {
              return v1 + v2;
          }
      });

    List<Tuple2<String, Tuple2<Long, Double>>> wordDictList = wordCount.zipWithIndex()
            .map(new Function<Tuple2<Tuple2<String, Long>, Long>, Tuple2<String, Tuple2<Long, Double>>>() {
                @Override
                public Tuple2<String, Tuple2<Long, Double>> call(Tuple2<Tuple2<String, Long>, Long> e) throws Exception {
                    String key = e._1()._1();
                    Long count = e._1()._2();
                    Long index = e._2();
                    return new Tuple2<String, Tuple2<Long, Double>>(key, new Tuple2<Long, Double>(index,
                            count.doubleValue() / wordSum));
                }
            }).collect();

    Map<String, Tuple2<Long, Double>> wordDict = new HashMap();
    for (Tuple2<String, Tuple2<Long, Double>> item : wordDictList) {
        wordDict.put(item._1(), item._2());
    }

    final Broadcast<Map<String, Tuple2<Long, Double>>> sharedWordDict = ctx.broadcast(wordDict);

    // for each document, generate vector based on word freq
      JavaRDD<Tuple3<Double, Long[], Double[]>> vector = data.map(new Function<Tuple2<String, String>, Tuple3<Double, Long[], Double[]>>() {
          @Override
          public Tuple3<Double, Long[], Double[]> call(Tuple2<String, String> v1) throws Exception {
              String dockey = v1._1();
              String doc = v1._2();
              String[] keys = SPACE.split(doc);
              Tuple2<Long, Double>[] datas = new Tuple2[keys.length];
              for (int i = 0; i < keys.length; i++) {
                  datas[i] = sharedWordDict.getValue().get(keys[i]);
              }
              Map<Long, Double> vector = new HashMap<Long, Double>();
              for (int i = 0; i < datas.length; i++) {
                  Long indic = datas[i]._1();
                  Double value = datas[i]._2();
                  if (vector.containsKey(indic)) {
                      vector.put(indic, value + vector.get(indic));
                  } else {
                      vector.put(indic, value);
                  }
              }

              Long[] indices = new Long[vector.size()];
              Double[] values = new Double[vector.size()];

              SortedSet<Long> sortedKeys = new TreeSet<Long>(vector.keySet());
              int c = 0;
              for (Long key : sortedKeys) {
                  indices[c] = key;
                  values[c] = vector.get(key);
                  c+=1;
              }

              Double label = Double.parseDouble(dockey.substring(6));
              return new Tuple3<Double, Long[], Double[]>(label, indices, values);
          }
      });

      vector.persist(StorageLevel.MEMORY_ONLY());
       final Long d = vector
               .map(new Function<Tuple3<Double,Long[],Double[]>, Long>() {
                   @Override
                   public Long call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
                       Long[] indices = v1._2();
                       if (indices.length > 0) {
//                           System.out.println("v_length:"+indices.length+"  v_val:" + indices[indices.length - 1]);
                           return indices[indices.length - 1];
                       } else return Long.valueOf(0);
                   }
               })
              .reduce(new Function2<Long, Long, Long>() {
                  @Override
                  public Long call(Long v1, Long v2) throws Exception {
//                      System.out.println("v1:"+v1+"  v2:"+v2);
                      return v1 > v2 ? v1 : v2;
                  }
              }) + 1;

    RDD<LabeledPoint> examples = vector.map(new Function<Tuple3<Double,Long[],Double[]>, LabeledPoint>() {
        @Override
        public LabeledPoint call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
            int intIndices [] = new int[v1._2().length];
            double intValues [] = new double[v1._3().length];
            for (int i=0; i< v1._2().length; i++){
                intIndices[i] = v1._2()[i].intValue();
                intValues[i] = v1._3()[i];
            }
            return new LabeledPoint(v1._1(), Vectors.sparse(d.intValue(),
                    intIndices, intValues));
        }
    }).rdd();

    //RDD<LabeledPoint> examples = MLUtils.loadLibSVMFile(ctx.sc(), args[0], false, numFeatures);
    RDD<LabeledPoint>[] split = examples.randomSplit(new double[]{0.8, 0.2}, rand.nextLong());

    JavaRDD<LabeledPoint> training = split[0].toJavaRDD();
    JavaRDD<LabeledPoint> test = split[1].toJavaRDD();

    final NaiveBayesModel model = NaiveBayes.train(training.rdd(), 1.0);
    JavaRDD<Double> prediction =
        test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return model.predict(p.features());
            }
        });

    JavaPairRDD < Double, Double > predictionAndLabel =
        prediction.zip(test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return p.label();
            }
        }));

    double accuracy = (double) predictionAndLabel.filter(
            new Function<Tuple2<Double, Double>, Boolean>() {
                @Override
                public Boolean call(Tuple2<Double, Double> pl) {
                    return pl._1().equals(pl._2());
                }
            }).count() / test.count();

    System.out.println(String.format("Test accuracy = %f", accuracy));
    ctx.stop();
  }
}



3.运行结果



Type
Date
Time
Input_data_size
Duration(s)
Throughput(bytes/s)
Throughput/node



JavaSparkBayes
2016-10-09
16:41:09
113387030
48.857
2320793
2320793


ScalaSparkBayes
2016-10-09
16:42:00
113387030
45.164
2510562
2510562


PythonSparkBayes
2016-10-09
16:44:03
113387030
118.521
956683
956683


bayes算法数据规模参考：
#Bayes 
hibench.bayes.tiny.pages                        25000 
hibench.bayes.tiny.classes                      10 
hibench.bayes.tiny.ngrams                       1 
hibench.bayes.small.pages                       30000 
hibench.bayes.small.classes                     100 
hibench.bayes.small.ngrams                      2 
hibench.bayes.large.pages                       100000 
hibench.bayes.large.classes                     100 
hibench.bayes.large.ngrams                      2 
hibench.bayes.huge.pages                        500000 
hibench.bayes.huge.classes                      100 
hibench.bayes.huge.ngrams                       2 
hibench.bayes.gigantic.pages                    1000000 
hibench.bayes.gigantic.classes                  100 
hibench.bayes.gigantic.ngrams                   2 
hibench.bayes.bigdata.pages                     20000000 
hibench.bayes.bigdata.classes                   20000 
hibench.bayes.bigdata.ngrams                    2

参考文献

https://github.com/intel-hadoop/HiBench
 









不是混不下去了才写生存指南，因为我妈指着新闻联播说，娃呀，你要是不在国企干了，在这上面见你的机会就基本没了，我。。。

特别提醒：含有保密协议的国企，研究所，慎重选择！！！ 
一旦离职很有可能是完全脱产一年时间来进行脱密

1. 真实的找工作故事
2016年我要毕业于是从2015年底我就开始准备找工作了。当时还在IBM实习，实习期间，并没有做出什么出彩的工作。只是按照师傅的要求，对于组内调查问卷的pc端产品。移植到ISO上做了一个简单的demo，使用tinyxml2解析xml生成调查问卷模板并展示，白天做这个，晚上回去改自己写的一个没啥创新点的论文，用图论做立体匹配，分割后构造图的时候多给边上加个权值。平时还要练习leetcode，成天瞎忙，然而结果没有陪我演戏。金九银十没有一家互联网企业给我发offer。
bat加京东笔试全挂，我已经开始怀疑人生。信心的丧失部分影响了我对后续单位情况的判断。
只有绿盟过了一面，完美世界和Intel到了二面就杳无音讯，我当时一直在应聘c++程序员，完美世界二面全问的tcp网络协议，滑动窗口拥塞控制，不会，至今，也不会，毫无悬念的跪了。
Intel二面和一个女面试官聊了一个多小时，异常开心，说了很多很多IBM的实习见闻，感觉高端养老院的企业文化在哪都是喜闻乐见的，结果还是没过，非常费解。
绿盟就有一些意思了，笔试题做的不错，一面聊了两句我说我是CSDN博客专家斑竹，好了回去等消息，二面我说我在IBM实习过，好了回去等消息，结果说要等副总来面谈，这一下又等了好久，三面是副总，直接问想要多钱，我说我不是为了钱，主要是看中企业文化和未来发展，副总上下打量着我说8500咋样，我心想offer终于来了，已经很超出我的预期了。
在等绿盟三面的过程中，一个本地的研究所邀我去面试，暂且称为S所。 
S所面试一共来了两波人，第一波校招五个，第二波社招五个，校招五个一问，交大，西大，长大，好家伙不会是叫我来充数的吧，面试也没问啥，自我介绍一完，问了三个问题，会这个嘛，会那个嘛，我说，会，熟练，精通。
然后就是二面，直接人事处处长开始介绍待遇了，交大的同学问了很多和切身利益相关的具体问题，比如工资具体是多少。然后我惊奇的发现，入职工资是根据学校划分的，比如，西电的5500，西农的6000，师大的5000，后来我很费解，为啥师大这么低，原来我本科不行，西农由于是985所以碾压了大家，有趣的事情就此开始了。

2. 困惑
我曾经在国企非常困惑的一点就是，我每天在单位干了不少活，为啥那么像丙方，而且工资那么低呢？参考文献中说道，你干的活其实没有什么财富价值。
为什么要离开现在的单位，因为根本没有为社会创造财富。所以我现在的工作只有单位支付工资，他并不值钱。
在国企工作的IT从业人员难免会因为周围的环境变的迷失，一个清晰的职业生涯规划是非常重要的，我一度一段时间里一壶茶一支烟一张报纸看半天搓完手机搓电脑，也有通宵蹲在机房忍受机器的轰鸣。反正我是越干越困惑，我到底是为谁在卖命？
最近有幸和IBM的一些高级架构方案师们有了一些交流，有句老话说：单位就像一棵爬满猴子的大树，向上看全是屁股，向下看都是笑脸，左右皆是耳目。每个人都在颠簸的尘世中寻找平衡的支点，我们平时在国企唯领导马首是瞻，这是一种深井病，我们只关注领导的一举一动，对了也不是，错了也不是，因为你只能看到领导的屁股，你又能猜测出些什么有价值的东西呢？所以干活缺乏主观能动性。
假如加入的是创业型公司，这样的态度是不能有的。你需要时刻想着，我能为单位做些什么，我能怎么利用我的才能让单位、团队向着好的方向发展。 
假如你身处任何位置都能有这样的想法，那么成功指日可待。

3. 建议
过来人给出几个小tips，还望大家海涵

多与领导沟通，因为会哭的孩子有奶吃，领导干部那么忙，他根本不知道你干了多少活，怎么给你涨工资？kpi考核，不存在的。。。
勤于表现，是金子总会发光，炼丹炉里面的金子，发什么光！ 
在国企的技术人员不好混，人员关系特别复杂，要想专心把技术搞上来，可能要比在互联网公司付出更大代价。
工作不饱和，强度小是国企IT人员的显著特点，多利用闲暇时间系统的学习一门手艺，更多的领导注意意味着更多的资源与平台，早日出人头地实现梦想在于抓住机会表现自己的闪光点。
懂得拒绝，不是自己的活一般不要干，比如你文章写的好，领导有个新闻稿让你写，你写还是不写？写了以后是不是都归你写了？清晰的职业规划告诉你，咱应该focus on 一些东西，技术人员要成为T字型人才，宽度要足够，但也要有一项立足之本的技术做到足够深入。
不要和周围的人同流合污，别人没时间看书，成天玩，你不能玩，要高标准高要求自己。别人雄安新区2亩地，咱呢？
调整心态，在国有企业的IT从业者，要有一种健康的心理状态，不要总想着自己拿着卖白菜的心，操着卖白粉的心，还拿钱最少，心态不好了干活的效果也不好。人从来都不是累死的，而是懒死的，生于忧患死于安乐，天道酬勤对于年轻人来说一点都不假。

未完待续
今天先说到这里，有兴趣的欢迎留言评论，说出你自己的故事。

参考文献
年薪50万美金的工程师到底牛在哪里? 






// Lambda_test20140801.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <algorithm>
#include <iostream>
#include <vector>
using namespace std;


int main()
{
	//创建一个包含10个元素的集合对象
	vector<int> v;

	for (int i = 0; i < 10; ++i)
	{
		v.push_back(i);
	}

	//使用for_each 语句和lambda表达式来实现对偶元素的计数

	int evenCount = 0;
	for_each(v.begin(),v.end(),[&evenCount](int n){
		
		cout<<n;

		if (n % 2 == 0)
		{
			cout<<" is even"<<endl;

			//increment the counter
			evenCount++;

		}
		else
		{
			cout<<" is odd"<<endl;

		}
	
	
	
	});

	//将偶元素个数打印出来
	cout<<"There are "<<evenCount<<" even numbers in the vector"<<endl;


	getchar();




	return 0;
}

 








完成于2014年年初

文章大纲1.影评2.经典3.成长！
 每当新年，我都在这里为你祝福，也在这里为你剖白。
 剖白是为了沟通，沟通是为了理解，理解是为了共识，共识是为了共行。
 此时此刻，你我虽远隔千山万水，然你却横跨五湖四海，不远万里送上一赞，
  我受此大恩，定然不能让你失望。
                                                                      ----题记



1.影评
去年的致辞还历历在目，马年已经姗姗的到来了。
去电影院的时候，我发现其实片头的预告片广告一般都是最精彩的。今年就早早的坐定，发现春晚换成电影导演了，果然晚会也有了预告片。对春晚二字的解读还甚是有那么点味道。冯小刚的整个电影生涯，他一直在为人民群众造梦，从《甲方乙方》《不见不散》这种宣扬人情冷暖的影片到《集结哨》《1942》等表现战争灾难的佳作，他一直在拍摄自己迷恋的生活。冯导在《我把青春先给你》中说道：“王朔那种与时俱进的视野和观察生活的角度，对我日后的导演生涯产生了深远的影响，成为了指导我拍摄贺岁片的纲领性文献。”今年的春晚自然又是冯导的又一部贺岁大片，只是这部影片得迎合太多人的口味。
电影跟晚会不同，电影终将不过是一场虚幻，眼泪，惆怅，失落，恐惧，惊喜，慌乱，爱不得，生离别，相见欢。。。。。。一旦灯光亮起，电影是电影，生活就还是生活了，如果你的人生是一部电影，那你希望她叫什么？
如果非要给人生这部电影写一篇影评，我真诚的希望她的IMDB 评分千万不要低于8分。并且电影的女主角能早点读到文章此处。截至发稿时，上一个愿望还未实现。

2.经典
前几日考研总分的时候，我记着学校影视编导的一道论述题目说，论述何为经典？（25分）
有的考生说文解字娓娓道来，说，经典是指具有典范性、权威性的著作。洋洋洒洒引经据典写了几千字，忘了自己要考导演专业，倒像是文学院的哥们走错了考场，老师画了个大大的零蛋，苍凉的摆在字里行间。有的考生写自己小时候最看的红色经典，对《地雷战》《地道战》《南征北战》解读的头头是道，笔下生花，条理清晰，读来如饮美酒，如坐春风。有的考生说，经典是符合意识形态与时代需求的，这个时代的经典并不一定是那个时代的经典，倒也算是推陈出新，最后自圆其说，自是别出心裁。
我依稀记得希区柯克说过，戏剧就是将生活的枯燥遗忘。所以即便是最冷酷无情的工作也能被渲染成激情四射。一个英国的普通公务员，却成就了50年的经典形象，这就是007.这就是经典。
小马哥干掉坏人以后，总是拖着一条血腿，还要叼着根牙签。完后信誓旦旦的向所有人宣告，我不是要证明我比别人强，而是要让他们知道，我不见了的东西一定要亲手拿回来。星爷的dry马蒂尼，还有神乎其神的ak-47扫射都让这个男人在每部电影中都那样的鲜明，那样的出色。还有一连串的影星，导演。他们是香港电影的经典，伴随我们这一代人成长的经典。是那个时代的经典。
灌篮高手，激励了一代人的篮球梦想。那一句：同学，你喜欢打篮球吗？如何真的有女生手捧篮球同样的问出来，估计谁都会束手就擒啦。
我想，经典就是能够激起我们心中共鸣最多的东西吧！

3.成长！
德国哲学家费尔巴哈曾说：我们的时代重影像而轻实在，重副本而轻原件，重表现而轻现实，重外表而轻本质。这个时代是手机的时代，时间是碎片化的时间，社交网路更让人沉醉其中不能自拔，你的每个喜怒哀乐都会以每24h一次的频率迅速被人遗忘，于是我想，到底什么才是恒久不变的珍藏？
思考这个问题的过程伴随了我一小段时间的成长。于是，我开始了品读经典的旅程，我想这些经过时间洗礼的东西多少能给出点线索。
以往的那些建立在精神上的彼此认同在经典中跃然纸上：比如，朋友应该是讲义气的，对爱情应该是忠贞不二的，对理想应该是奋不顾身的，对生活应该是充满热情的，对困难应该是充满智慧的，对灰暗应该是充满调侃的。。。
我从《卡萨布兰卡Casablanca》中得到革命时期的爱情真谛，我从《无间道》中明白为什么人在江湖身不由己，出来混总是要还的。《射雕英雄传》告诉我出来混一定要讲义气，并且做人一定要老实。不然即使碰上黄蓉，也不会喜欢你。《神雕侠侣》说，问世间，情为何物，直教人，生死相许。所以，用情要专一。
我听张学友，张国荣的歌，看刘德华，梁朝伟的电影，学学他们这些老男人的风度，梦想成长的跟他们一样。我忽然想起电影《红猪》来了，《红猪》中的波鲁克为男人们提供了一种古典而优雅的范本，其根本是轻视肉体的漂亮，摒弃虚浮的装饰。他提醒男人，尤其是疲倦操劳的中年男人，自身与美，自身与浪漫的不可分离。责任感，骑士精神，豪迈的气势，成熟的事业。这种美属于大地，朴实且厚重。时代会变，江山会易主，但是真正的战友忠于信念，至死不渝。
何时才能成长为那样一位大叔，肌肉与智慧并存，英雄与侠义的化身？
吃年夜饭的时候，新闻又报道了一例农民工讨薪的成功案例。
现在农民工辛苦了一年，难道发了工资还要感谢一下国家政策以及监管部门的大力支持，这难道不是他们TMD应该做的么？新闻联播弘扬的就是这样的中国梦？无外乎，国外媒体评论说，几千万青年人都争着去考公务员，这是对人才的浪费啊。但是我以为，至少在年跟前，不会给公务员同志拖欠半天的工资。世间的事大抵如此，我也没有什么好说的，原来，因为成熟而麻木的外表下，早已习惯了随波逐流的躯壳里，我经历了太多波澜不惊的日子而变的容易满足的内心，正在义无反顾的朝着曾经自己最厌恶的样子缓缓前去。
这样，算不算，也是一种成长？不过，显然算是长歪了。。。
然而，我终将希望青春不要像，4块钱一本的《青年文摘》青春风铃情感专栏里的小青年一样那么绚丽多彩，一会白血病，一会三角恋。成长的这些时光告诉我们，我是什么，我变拥有什么样的时代。
我还有些许阳光，我还能再烧包一会。
THE END!
ALL RIGHTS RESERVED!

p.s.
据不完全统计：
本年度共收到66条拜年短信，8份微信祝福，其中7名女生1名男生，8份QQ祝福，其中7名女生1名男生。66条拜年短信中有12条短信，由匿名者发出，为了不伤害她们的感情，我没有敢询问尊姓大名。
今天中午12时开始，我总共拨打了18个拜年电话，飞信发送79条短信，手机发送41条短信。短信内容，采用百度搜索到的小学生作文（过年啦）片段，有95.41%的童鞋们收到后，回复夸赞我的语文水平，余下的同学感叹写的字数太多，感慨自己居然看完了。
Play it Sam ,Play as time goes by.

我的博客即将同步至腾讯云+社区，邀请大家一同入驻：
https://cloud.tencent.com/developer/support-plan?invite_code=377j9p19ivc40










作者：一人

Featuretools如你所言能够自动完成特征工程，它属于AutoML范畴，接下来我还是主要谈AutoML1吧。由于机器学习应用高门槛和应用范围的广阔，所以很多组织于2017和2018年开始自动化的机器学习尝试，想降低机器学习应用的门槛，让非专业人员也能够应用。机器学习的工作流通常为数据清洗、特征工程、模型选择、模型训练、模型评估，针对机器学习的自动化尝试，也在这几个步骤展开。
由于数据清洗和数据强关联，在这一部分只能根据具体应用和情景进行处理，无法抽象出来使用通用方法解决；针对特征工程部分，据我查阅所看，自动化工具很少，Featuretools算是一个吧；但是针对后面模型选择与模型训练、模型评估的自动化工具就比较多了，例如Google的automl,Microsoft的NNI2以及autosklearn3等。
当前自动化的工具主要根据机器学习算法分为两个类别4：
自动传统机器学习方法与自动神经网络方法。自动传统机器学习方法最为典型的应用就是auto-sklearn，面向的算法主要是LR，SVM，GBDT等。而针对自动化神经网络的工具当前处于研究的前沿，具有代表性的工具除过上面google和Microsoft之外还有auto-Keras,百度的AutoDL等，由于神经网络能够自动化完成特征工程，因此所有的工具都主要集中在网络架构和参数搜索上了。
automl从2017年开始引起关注，2018号称automl的元年，由此也能看出来其离实际应用还有比较长的距离。虽然如此说，但是针对传统机器学习的自动化工具现在还是值得尝试。
传统机器学习方法已经发展很多年了，针对这部分自动化工具也诞生有些年头了，auto-sklearn已4年。但是很不幸，据使用过的人说，效果还是比较有限，不如人工做出来的效果好，如果对于效果要求不很高，不妨试试，毕竟构建快成本低。自动神经网络就不用在说了。从目前发展状况来看，短期内这个领域应该不会有什么大的突破，但是长期看自动化机器学习还是很有前途的。
如果要想进一步了解AutoML的内容，可以查看zhihu中automl话题下的讨论，https://www.zhihu.com/topic/20173754/hot

机器学习技术落地难，急需懂算法的产品人员。
算法工程师从业人员已经饱和。学习资料易得，学习门槛降低。还记得在2016年底时我们俩谈过：由于现在的各种教程漫天飞，这个领域必将涌入大量的从业人员。
从近两年发展来看现状确实如此，去年校招的很多报道说：算法岗收到的简历与职位的比例远远大于100:1，各大公司现如今对于算法工程师的门槛要求也是水涨船高，高的我看见都发怵。机器学习在产品上的应用远没有想象的那样迅速铺展开来，新进入人员没有新坑能占。当前机器学习应用比较广的领域：

图像的监控与文字识别，
NLP的智能助手与智能客服；
推荐、搜索、广告系统等。

这些都是发展很多年的领域并不新，所以也就没有新的岗位创造出来，进一步加深了行业人员的饱和。因此，当前行业并不缺懂算法的工程师，或者说并不缺初中级算法工程师。
急需能够让算法落地的产品人员。不用质疑机器学习的应用范围是很广的，但是应用的落地速度并不如预期，这在一定程度上反应出来：算法人员不懂产品，产品人员不懂算法。这种隔阂才是算法不能迅速落地的关键因素。
所以，如果在这个方向的从业人员应该多多将精力放在如何填补这鸿沟上，要么产品人员多学学算法，要么算法人员多多了解产品知识。
个人观点：能够掌握主流的算法原理，有两三个算法实际项目，能够掌握产品方面的技能，这种人才才是当前的香饽饽。



机器之心，AutoML、AutoKeras…这四个「Auto」的自动机器学习方法你分得清吗？https://zhuanlan.zhihu.com/p/49494212 ↩︎

Microsoft, NNI,  https://github.com/Microsoft/nni ↩︎

Machine Learning Professorship Freiburg, Auto-sklearn, https://automl.github.io/auto-sklearn/stable/# ↩︎

第四范式，AutoML在推荐系统中的应用，https://zhuanlan.zhihu.com/p/52907645 ↩︎













文章大纲Elastic search & kibana & 分词器 安装版本控制下载地址Elastic search安装kibana 安装分词器配置

Elastic search & kibana & 分词器 安装
版本控制
ES版本：7.2.0
分词器版本：
kibana 版本：7.2.0
下载地址
ES 下载地址：https://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-2-0
kibana 下载地址：https://www.elastic.co/cn/downloads/past-releases/kibana-7-2-0
hanlp 分词器下载地址： https://github.com/KennFalcon/elasticsearch-analysis-hanlp 
Elastic search安装

0.添加es 用户，并新建目录

不能以root 方式运行elasticSearch
groupadd elasticsearch 
useradd elasticsearch -g elasticsearch

chown -R elasticsearch:elasticsearch /home/elasticsearch



1.修改 配置文件 elasticsearch.yml

cluster.name: fastclaim
node.name: node-test
network.host: 172.31.3.50
http.port: 9200
cluster.initial_master_nodes: ["node-test"]


2.针对无法创建本地文件问题，用户最大可创建文件数太小


切换到root用户，编辑limits.conf配置文件
vi /etc/security/limits.conf
#末尾添加
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536


3.针对无法创建本地线程问题，用户最大可创建线程数太小

vi /etc/security/limits.d/90-nproc.conf
将
 * soft nproc 1024
修改为
 * soft nproc 4096
 


4.针对最大虚拟内存太小
解决方法：切换到root用户下，修改配置文件sysctl.conf

vi /etc/sysctl.conf
添加配置
vm.max_map_count=655360
执行命令
sysctl -p


5.重新启动，启动成功

如果要在后台运行，使用./bin/elasticsearch -d启动
curl 172.31.3.50:9200

{
  "name" : "node-test",
  "cluster_name" : "fastclaim",
  "cluster_uuid" : "VtYF-EQIQNKHR1XWk7sE4g",
  "version" : {
    "number" : "7.2.0",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "508c38a",
    "build_date" : "2019-06-20T15:54:18.811730Z",
    "build_snapshot" : false,
    "lucene_version" : "8.0.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}

kibana 安装

1.安装及启动

tar -xzvf 解压缩后，进行安装，
vim config/kibana.yml
# 修改如下四行
server.port: 5601
server.host: "172.31.3.50"
elasticsearch.hosts: ["http://172.31.3.50:9200"]
kibana.index: ".kibana"

# 后台启动

nohup ./bin/kibana >/dev/null &


2.开发工具地址

http://IP:5601/app/kibana#/dev_tools/console?_g=()
分词器配置
参考链接：https://github.com/KennFalcon/elasticsearch-analysis-hanlp

1.下载安装ES对应Plugin Release版本

安装方式：
方式一
a. 下载对应的release安装包，最新release包可从baidu盘下载（链接:https://pan.baidu.com/s/1mFPNJXgiTPzZeqEjH_zifw 密码:i0o7）
b. 执行如下命令安装，其中PATH为插件包绝对路径：
./bin/elasticsearch-plugin install file://${PATH}
方式二
a. 使用elasticsearch插件脚本安装command如下：
./bin/elasticsearch-plugin install https://github.com/KennFalcon/elasticsearch-analysis-hanlp/releases/download/v7.2.0/elasticsearch-analysis-hanlp-7.2.0.zip

2.安装数据包
release包中存放的为HanLP源码中默认的分词数据，若要下载完整版数据包，请查看HanLP Release。
数据包目录：ES_HOME/plugins/analysis-hanlp
注：因原版数据包自定义词典部分文件名为中文，这里的hanlp.properties中已修改为英文，请对应修改文件名
hanlp.properties 在
/home/elasticsearch/elasticsearch-7.2.0/config/analysis-hanlp 目录中

因为aws ec2 里面网络环境比较好，推荐直接在线安装。

3.重启Elasticsearch

注：上述说明中的ES_HOME为自己的ES安装路径，需要绝对路径

4.配置自定义词典并热更新

在本版本中，增加了词典热更新，修改步骤如下：

a. 在ES_HOME/plugins/analysis-hanlp/data/dictionary/custom目录中新增自定义词典
b. 修改hanlp.properties，修改CustomDictionaryPath，增加自定义词典配置
c. 等待1分钟后，词典自动加载

具体脚本，以医学常用词典medical.txt 为例
mv /tmp/medical.txt /home/elasticsearch/

cp /home/elasticsearch/medical.txt /home/elasticsearch/elasticsearch-7.2.0/plugins/analysis-hanlp/data/dictionary/custom/

#移动完成后修改权限

chown -R elasticsearch:elasticsearch /home/elasticsearch/


ll /home/elasticsearch/elasticsearch-7.2.0/plugins/analysis-hanlp/data/dictionary/custom/

#修改添加自定义目录

vim /home/elasticsearch/elasticsearch-7.2.0/config/analysis-hanlp/hanlp.properties

# Custom dictinary path
CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; ModernChineseSupplementaryWord.txt; ChinesePlaceName.txt ns; PersonalName.txt; OrganizationName.txt; ShanghaiPlaceName.txt ns;data/dictionary/person/nrf.txt nrf; medical.txt;

注：每个节点都需要做上述更改

5.提供的分词方式说明

hanlp: hanlp默认分词
hanlp_standard: 标准分词
hanlp_index: 索引分词
hanlp_nlp: NLP分词
hanlp_n_short: N-最短路分词
hanlp_dijkstra: 最短路分词
hanlp_crf: CRF分词（已有最新方式）
hanlp_speed: 极速词典分词

6.分词样例

GET /_analyze?pretty
{
  "analyzer" : "hanlp_crf",
  "text" : ["南京市长江大桥"]
}
{
  "tokens" : [
    {
      "token" : "南京市",
      "start_offset" : 0,
      "end_offset" : 3,
      "type" : "ns",
      "position" : 0
    },
    {
      "token" : "长江大桥",
      "start_offset" : 0,
      "end_offset" : 4,
      "type" : "nz",
      "position" : 1
    }
  ]
}











文章大纲ssh登录设置并安装vsftp使用本地用户模式 配置vsftp conf编辑允许访问ftp服务器的用户列表：非受限用户启动ftp服务ec2 权限设置客户端安装与说明报错处理530 Login incorrect. Login failed.参考文献

ssh登录
pem 文件下载：
从aws 下载pem 文件
使用ssh登录

ssh -i "xxx.pem" ec2-user@ec2-xxx.cn-north-1.compute.amazonaws.com.cn



设置并安装vsftp
sudo yum install vsftpd

useradd -d /dir username 

sudo passwd username

sudo chmod 777 /dir/upload/ -R

#限制用户仅能通过 FTP 访问
#限制用户 ftpuser只能通过 FTP 访问服务器，而不能直接登录服务器：
sudo usermod -s /sbin/nologin username

#设置为用户的主目录：
sudo usermod -d /data/ username


#开放ftp 21 端口 或者 关闭防火墙
#关闭SELinux服务
setenforce 0
#关闭防火墙
iptables -F



使用本地用户模式 配置vsftp conf
修改vsftpd配置文件：

sudo vi /etc/vsftpd/vsftpd.conf  

修改后的内容如下：

# Allow anonymous FTP? (Beware - allowed by default if you comment this out).
anonymous_enable=NO
#
# Uncomment this to allow local users to log in.
# When SELinux is enforcing check for SE bool ftp_home_dir
local_enable=YES
local_root=/your_dir
#
# Uncomment this to enable any form of FTP write command.
write_enable=YES
#
# Default umask for local users is 077. You may wish to change this to 022,
# if your users expect that (022 is used by most other ftpd's)
local_umask=022
#

# Activate directory messages - messages given to remote users when they
# go into a certain directory.
dirmessage_enable=YES
#
# Activate logging of uploads/downloads.
xferlog_enable=YES
#
# Make sure PORT transfer connections originate from port 20 (ftp-data).
connect_from_port_20=YES
#

# If you want, you can have your log file in standard ftpd xferlog format.
# Note that the default log file location is /var/log/xferlog in this case.
xferlog_std_format=YES
#

# You may specify an explicit list of local users to chroot() to their home
# directory. If chroot_local_user is YES, then this list becomes a list of
# users to NOT chroot().
# (Warning! chroot'ing can be very dangerous. If using chroot, make sure that
# the user does not have write access to the top level directory within the
# chroot)
chroot_local_user=YES
chroot_list_enable=YES
# (default follows)
chroot_list_file=/etc/vsftpd/chroot_list
#
# You may activate the "-R" option to the builtin ls. This is disabled by
# default to avoid remote users being able to cause excessive I/O on large
# sites. However, some broken FTP clients such as "ncftp" and "mirror" assume
# the presence of the "-R" option, so there is a strong case for enabling it.
ls_recurse_enable=YES
#
# When "listen" directive is enabled, vsftpd runs in standalone mode and
# listens on IPv4 sockets. This directive cannot be used in conjunction
# with the listen_ipv6 directive.
listen=YES
#

# Make sure, that one of the listen options is commented !!
#listen_ipv6=YES

pam_service_name=vsftpd
userlist_enable=YES
tcp_wrappers=YES

#############
userlist_deny=NO
userlist_file=/etc/vsftpd/user_list

##vsftpd.chroot_list需要手动建立
##允许文本模式下载
ascii_download_enable=YES
##允许文本模式上传
ascii_upload_enable=YES


##启用被动模式
pasv_enable=YES
pasv_promiscuous=YES
pasv_min_port=60000
pasv_max_port=60020


由于该配置使用了被动模式，所以需要在linux防火墙配置中，开放路由器转发端口

sudo iptables -A INPUT -p tcp --dport 60000:60020 -j ACCEPT


编辑允许访问ftp服务器的用户列表：
sudo vi /etc/vsftpd/user_list  

把不需要的注释掉，最后加上一行ftpUserName
非受限用户
凡是加在文件vsftpd/chroot_list中的用户都是不受限止的用户,即, 可以浏览其主目录的上级目录。在这里默认为空：
sudo vi /etc/vsftpd/chroot_list 

直接保存退出
启动ftp服务
sudo service vsftpd start  

ec2 权限设置
最后，需要在EC2控制台中设置Security Group，增加ftp所需端口
20，21以及60000-60020

客户端安装与说明
https://filezilla-project.org/
推荐使用FileZilla，并设置为被动模式
如果出现如下错误：
ftp> ls
200 PORT command successful. Consider using PASV.
425 Failed to establish connection.
ftp> put
(local-file) iz_
usage: put local-file remote-file
ftp> put
(local-file) test.txt
(remote-file) test.txt
local: test.txt remote: test.txt
200 PORT command successful. Consider using PASV.
425 Failed to establish connection.
ftp> bye
421 Timeout.

有可能是windows 本地防火墙的问题，可以关闭防火墙
或者首先使用被动模式
quote PASV
解决问题的思路如下：
1、防火墙（本机、客户机）
2、FTP目录的权限
3、客户机是否是IPv6网络
4、客户机的网关限制了外网ftp

报错处理
530 Login incorrect. Login failed.
在客户端登录vsftpd时报530 login incorret 错误，发现是PAM鉴权造成的，解决方法如下：
方法（1）：注释掉/etc/pam.d/vsftpd文件里这后一行：
auth    required        pam_shells.so，这样不去鉴权
方法（2）：在/etc/shells文件里面增加一行：
/sbin/nologin,这样允许不能登录系统的用户通过鉴权
按照方法（1）操作

#备份：

cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bak

#修改：

vim /etc/pam.d/vsftpd

#注释掉以下这一行：

#auth   required        pam_shells.so

#然后再次登陆，就可以了。



参考文献
userlist_enable和userlist_deny两个配置项的解释
Linux_vsftpd服务安装及配置（三种登陆方式）










文章大纲Aws 的优势架构完善的框架（WAF）

Aws 学习笔记
Aws架构中心
Aws 的优势
4.速度优势
5.全球优势
数分钟内实现全球部署
Aws全球基础设施
Aws 数据中心
来自多家ODM（白牌机器）
1.考虑当地法律法律法规
2.考虑速度，和用户的距离，是否提供对应的业务
3.考虑成本
Aws 可用区
每个区由一个或者多个数据中心组成
专为故障隔离而设计
使用高速专用链接与其他可用区域互联
您可以选择可用区
Aws建议跨可用区复制以便实现弹性。
Aws 边缘站点协助客户实现高可用、高响应
架构完善的框架（WAF）
5大支柱：
1.安全性
2.可靠性
3.成本优化
4.性能效率
5.卓越运维
安全性
身份机制
实现可追踪性
在所有层确保安全性
风险评估与缓解策略
可靠性
动态获取计算资源以满足要求
成本优化
衡量效率
消除不必要的支出
考虑使用托管服务
卓越运维
能够运行和监控各种系统
持续改进支持流程和程序
部署方式
更新方式
操作方式
性能效率
选择有效的资源并在需求变化时保持资源效率
普及先进技术
了解技术


20191017 下午课程 aws 简单架构
Aws s3
Amazon s3 对象存储（扁平化，对象，元数据）
设计为提供99.999999999%的持久性（9个九+2个九= 11个九）
事件触发器
静态网站托管
S3访问控制
S3 使用案例
计算和大规模分析的的数据存储
限制：上传5G，存放5T
版本控制
备份工具
Aws Glacier
右上角换成amazon s3 智能分层
EC2 添加计算功能
使用amazon 系统镜像AMI 启动 Amazon EC2 实例
自定义启动配置的相关组件
EC2 和数据存储
EBS 弹性实例存储
实例存储是临时性的
跨可用区的数据复制要收钱，快照是可以复制。
跨可用区复制。
先对卷做快照-实际上是在s3上面，在另一个可用区用快照恢复
用户数据及实例元数据
https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-instance-metadata.html
EC2 实例类型
EC2定价选项
会话处理放在外部，ec2只是一个计算的模块。
架构一定是无状态的。
EMR按需结合竞价来做.任务可以提前完成而且成本更低。
标签最佳实践
添加数据库层
选择什么样的数据更适合什么样的场景
数据库层的选择注意事项
关系型与非关系型数据库对比
Oracle 大部分扩展是用垂直扩展，mysql 支持水平扩展
事务查询用关系型数据库。
Nosql 天生支持水平扩展形式
amazon aurora
老师强烈推荐了 amazon aurora 是自己提升了性能，并开始将自身的Oracle逐渐下线改为amazon aurora
Amazon DynamoDB
以购买火车票场景为例
查看余票：最终一致性
下单：强一致性
为什么有这两个区别：
CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。
数据库的安全管理
RDS
DynamoDB
数据库的迁移

20191018 早上课程 网络
云中的安全性
链接网络
虚拟私有网络
VGW需要购买
Aws Direct Connect
多个vpc 互联互通

20191018 下午课程
AWS 负载均衡器
高可用
多区域高可用及DNS
Aws Identity and access management
弹性高可用和监控
弹性
高可用
监控
CloudWatch
获得弹性并扩展架构

20191019 上午课程
实现基础设施自动化
Aws CloudFormation
可以直接托拉拽的设计方式
快速入门由AWS 解决方案架构师和合作伙伴编写,旨在依据安全性和高可用性 方面的AWS 最佳实践,帮助您部署基于AWS 的热门解决方案。这些参考部署可在AWS 云上自动实施关键技术,通常只需单击一下即可在一小时内完成实施。 您可以通过简单几步构建测试或生产环境,然后便可立即开始使用。 (AWS)
Aws system manager
AWS Systems Manager 是一项管理服务,可帮助您自动收集软件清单、应用操作 系统修补程序、创建系统映像并配置Windows 和 Linux 操作系统。这些功能可 帮助您定义和跟踪系统配置,防止偏差,并确保Amazon EC2 和本地配置的软件 合规性。AWS Systems Manager 提供的管理方法是根据云的规模和敏捷性专门设 计的,可以扩展到您的本地数据中心,使您可以更轻松地将现有基础设施与 AWS 进行无缝桥接。
Aws Opsworks
缓存
Aws cloudfront
构建解耦架构
传统基础设施以紧密集成的服务器链为中心,其中每个服务器都有特定的目的。 然而,当其中一个组件/层发生故障时,就会对系统的造成灾难性的破坏。此外, 它这种情况也妨碍了扩展。如果在一个层添加或删除服务器,则每个连接层上 的每个服务器也必须相应地进行连接 (AWS)
Aws SQS
引入 SQS 队列有助于改进您的订购应用程序。您可以使用队列将处理逻辑隔离 到其组件中,并在一个独立于Web 应用程序的进程中运行它。这反过来又让系 统能够更灵活地应对流量峰值,同时支持系统仅在必要时快速执行工作以便管 理成本。此外,这还为您提供了一种机制,让您可以将订单作为消息持久保存 (队列充当临时数据库),并将您的事务范围与数据库向堆栈更下层移动。如 果发生应用程序异常或事务失败,这可以确保将订单处理停用或重定向到 Amazon SQS 死信队列 (DLQ),以便日后进行重新处理。 (AWS)
Amazon Simple Queue Service (Amazon SQS) 是一种分布式队列系统,它使Web 服务应用程序能够对应用程序中的一个组件生成的消息(以供另一个组件使用) 进行排队。队列是一个临时存储库,用于存储等待处理的消息,并将消息保留 1 到 14 天(默认为 4 天)。使用Amazon SQS,您可以将应用程序的组件解耦,以 便它们独立运行。消息可包含最多 256KB 的任何格式的文本。Amazon SQS 支持 多个生产者和使用者与同一队列进行交互。Amazon SQS 可与多种AWS 产品一起 使用,包括:Amazon EC2、Amazon S3、Amazon ECS、AWS Lambda 和Amazon DynamoDB。
Amazon SQS 提供了两种类型的消息队列。标准队列提供最大吞吐量、尽力排序 和至少一次传递。Amazon SQS FIFO 队列旨在保证消息严格按照其发送顺序仅处 理一次,吞吐量有限。以下情景描述了Amazon SQS 队列中消息的生命周期(从 创建到删除)。在这个情景中,有一个生产者向队列发送了一条消息,消息以 冗余方式跨Amazon SQS 服务器分布。 (AWS)
Amazon SNS
Amazon Simple Notification Service (SNS) 是一种Web 服务,让用户可以轻松地在 云中设置、操作和发送通知。该服务遵循“发布 – 订阅”(pub-sub)消息收发范 例,使用“推送”机制将通知传递给客户端。
您可以创建一个主题,然后定义策略来确定哪些发布者和订阅者可以与其进行 通信,从而控制对该主题的访问。发布者可以向他们创建的主题或他们发布权 限的主题发送消息。发布者不需要在每条消息中包含特定的目标地址,只需将 消息发送至主题。然后,Amazon SNS 会将主题与该主题的订阅者列表进行匹配, 并将消息传递给每个订阅者。每个主题都有一个唯一的名称,为发布者和订阅 者标识Amazon SNS 终端节点,以便他们发布消息和订阅注册通知。订阅者会收 到发布至他们所订阅主题的所有消息,且一个主题的所有订阅者收到的消息都 相同。
Amazon SNS 支持加密主题。当您将消息发送至加密主题时,Amazon SNS 会使用 由AWS KMS (https://aws.amazon.com/kms/) 提供支持的客户主密钥 (CMK) 来加密 您的消息。Amazon SNS 支持客户托管的 CMK,也支持AWS 托管的 CMK。只要 收到您的消息,Amazon SNS 便在服务器上使用 256 位AES-GCM 算法进行加密。 为实现持久性,这些消息以加密形式存储在多个可用区 (AZ) 中,并在传输到订 阅终端节点(例如,Amazon Simple Queue Service [Amazon SQS] 队列、AWS
Lambda 函数,以及HTTP 和HTTPS Webhook)之前解密。 (AWS)
上述两个组件的消息的延迟性比较大，而kinesis 的处理主要是针对近实时性的。
kinesis stream 相当于管道。
Kinesis firehouse 进行转发转接，kinesis 转发到另外的组件进行集成展示业务。
Kinesis 是一整套系统，kafka 只是数据接下来存好。
20191019 下午课程
微服务和无服务架构
Amazon ECS
Amazon Elastic Container Service (Amazon ECS) 是一种高度可扩展的高性能容器管 理服务,其支持Docker 容器,让您能够在托管的Amazon EC2 实例集群上轻松 运行应用程序。
Amazon ECS 是一种可扩展的集群服务,用于托管容器,可以: • 扩展到数千个实例 • 监控容器的部署 • 管理集群的完整状态 • 使用内置的计划程序或第三方计划程序(例如 Apache Mesos、Blox)对容器 进行计划
• 使用API 来扩展 群集可以使用 Spot 实例和预留实例 (AWS)
无服务架构
Aws api Gateway
防止暴露终端节点
防护DDos 攻击和注入攻击
灾难预防
存储备份
计算备份
恢复策略
参考资料
EMR 弹性扩展
https://aws.amazon.com/cn/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/
https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-automatic-scaling.html







表达式求值
[问题描述]
一个算术表达式是由操作数(operand)、运算符(operator)和界限符(delimiter)组成的。假设操作数是正整数，运算符只含加减乘除等四种运算符，界限符有左右括号和表达式起始、结束符“#”，如：#（7+15）*（23-28/4）#。引入表达式起始、结束符是为了方便。编程利用“算符优先法”求算术表达式的值。
[基本要求]
（1） 从键盘读入一个合法的算术表达式，输出正确的结果。
（2） 显示输入序列和栈的变化过程。
[选作内容]
（1） 扩充运算符集合。
（2） 引入变量操作数。
（3） 操作数类型扩充到实数。
 
#include <stdio.h>
#include <string.h>
#include <stdlib.h>
#include <math.h>
#include <conio.h>

#define TRUE 1
#define FALSE 0
#define Stack_Size 50

char ops[7]={'+','-','*','/','(',')','#'};  /*运算符数组*/

int  cmp[7][7]={{2,2,1,1,1,2,2},    /*用来进行比较运算符优先级的矩阵,3代表'=',2代表'>',1代表'<',0代表不可比*/
                {2,2,1,1,1,2,2},
                {2,2,2,2,1,2,2},
                {2,2,2,2,1,2,2},
                {1,1,1,1,1,3,0},
                {2,2,2,2,0,2,2},
                {1,1,1,1,1,0,3}};

typedef struct
{ 
	char elem[Stack_Size];
	int top;
}SeqStack;     /*运算符栈的定义*/

typedef struct
{
	int elem[Stack_Size];
	int top;
}nSeqStack;   /* 运算数栈的定义*/


void InitStack(SeqStack *S)   /*初始化运算符栈*/
{
	S->top =-1;
}

void InitStackn(nSeqStack *S)   /*初始化运算数栈*/
{
	S->top =-1;
}

int IsEmpty(SeqStack *S)    /*判断栈S为空栈时返回值为真，反之为假*/
{
	return(S->top==-1?TRUE:FALSE);
}

int IsEmptyn(nSeqStack *S)    /*判断栈S为空栈时返回值为真，反之为假*/
{
	return(S->top==-1?TRUE:FALSE);
}

/*判栈满*/
int IsFull(SeqStack *S)	    /*判断栈S为满栈时返回值为真，反之为假*/
{
	return(S->top==Stack_Size-1?TRUE:FALSE);
}

int IsFulln(nSeqStack *S)	    /*判断栈S为满栈时返回值为真，反之为假*/
{
	return(S->top==Stack_Size-1?TRUE:FALSE);
}

int Push(SeqStack *S, char x)   /*运算符栈入栈函数*/
{
	if (S->top==Stack_Size-1)
	{
		printf("Stack is full!\n");
		return FALSE;
	}
	else
	{
		S->top++;
		S->elem[S->top]=x;
		return TRUE;
	}
}

int Pushn(nSeqStack *S, int x)   /*运算数栈入栈函数*/
{
	if (S->top==Stack_Size-1)
	{
		printf("Stack is full!\n");
		return FALSE;
	}
	else
	{
		S->top++;
		S->elem[S->top]=x;
		return TRUE;
	}
}
 
int Pop(SeqStack *S, char *x)    /*运算符栈出栈函数*/
{
	if (S->top==-1)
	{
		printf("运算符栈空!\n");
		return FALSE;
	}
	else
	{
		*x=S->elem[S->top];
		S->top--;
		return TRUE;
	}
}
 
int Popn(nSeqStack *S, int *x)    /*运算数栈出栈函数*/
{
	if (S->top==-1)
	{
		printf("运算符栈空!\n");
		return FALSE;
	}
	else
	{
		*x=S->elem[S->top];
		S->top--;
		return TRUE;
	}
}

char GetTop(SeqStack *S)    /*运算符栈取栈顶元素函数*/     
{
	if (S->top ==-1)
	{
		printf("运算符栈为空!\n");
		return FALSE;
	}
	else
	{
		return (S->elem[S->top]);
	}
}

int GetTopn(nSeqStack *S)    /*运算数栈取栈顶元素函数*/     
{
	if (S->top ==-1)
	{
		printf("运算符栈为空!\n");
		return FALSE;
	}
	else
	{
		return (S->elem[S->top]);
	}
}


int Isoperator(char ch)        /*判断输入字符是否为运算符函数,是返回TRUE,不是返回FALSE*/
{
	int i;
	for (i=0;i<7;i++)
	{
		if(ch==ops[i])
			return TRUE;
	}
	return FALSE;
}

/*
int isvariable(char ch)
{ if (ch>='a'&&ch<='z')
      return true;
   else 
	   return false;
}*/


char Compare(char ch1, char ch2)   /*比较运算符优先级函数*/
{
	int i,m,n;
	char pri;
	int priority;
	for(i=0;i<7;i++)              /*找到相比较的两个运算符在比较矩阵里的相对位置*/
	{
		if(ch1==ops[i])	
			m=i;
		if (ch2==ops[i])
			n=i;
	}

	priority = cmp[m][n];
	switch(priority)
	{
	case 1:
		pri='<';
		break;
	case 2:
		pri='>';
		break;
	case 3:
		pri='=';
		break;
	case 0:
		pri='$';
		printf("表达式错误!\n");
		break;
	}
	return pri;
}
	
int Execute(int a, char op, int b)    /*运算函数*/
{
	int result;
	switch(op)
	{
	case '+':
		result=a+b;
		break;
	case '-':
		result=a-b;
		break;
	case '*':
		result=a*b;
		break;
	case '/':
		result=a/b;
		break;
	}
    return result;
}

int ExpEvaluation() 
/*读入一个简单算术表达式并计算其值。optr和operand分别为运算符栈和运算数栈，OPS为运算符集合*/
{
	int a,b,v,temp;
	char ch,op;
	char *str;
	int i=0;
	
	SeqStack optr;
	nSeqStack operand;

	InitStack(&optr);
	InitStackn(&operand);
	Push(&optr,'#');
	printf("请输入表达式(以#结束):\n");            /*表达式输入*/
	str =(char *)malloc(50*sizeof(char));
	gets(str);

	ch=str[i];
	i++;
	while(ch!='#'||GetTop(&optr)!='#')
	{ 
		if(!Isoperator(ch))
		{
			temp=ch-'0';    /*将字符转换为十进制数*/
			ch=str[i];
			i++;
			while(!Isoperator(ch))
			{
				temp=temp*10 + ch-'0'; /*将逐个读入运算数的各位转化为十进制数*/
				ch=str[i];
				i++;
			}
			Pushn(&operand,temp);
		}
		else
		{
			switch(Compare(GetTop(&optr),ch))
			{
			case '<':
				Push(&optr,ch); 
				ch=str[i];
				i++;
				break;
			case '=':
				Pop(&optr,&op);
				ch=str[i];
				i++;
				break;
			case '>':
				Pop(&optr,&op);
				Popn(&operand,&b);
				Popn(&operand,&a);
				v=Execute(a,op,b);  /* 对a和b进行op运算 */
				Pushn(&operand,v);
				break;
			}
		}		
	}
	v=GetTopn(&operand);
	return v;
}

void main()                               /*主函数*/
{
	int result;
	result=ExpEvaluation();
	printf("\n表达式结果是%d\n",result);
}	








 
 
下面这个是在网上找的：
用 C++ 实现的加、减、乘、除表达式计算

前些日子面试一个开发工作，考官出了这么一笔试题目，要我写出实现过程， 思量半天，终于
用 C++ 完成，现将代码贴出，与诸同道共分享。

// 头文件 Calc.h
#ifndef __CALC_H__
#define __CALC_H__
#include <stack>
#define ascii_int(x) (x >= 0x30 && x <= 0x39) ? (x - 0x30) : (x)
const int GREATER =  1;
const int EQUAL   =  0;
const int LESS    = -1;
class Calculate {
public:
  int  evaluteExpr(char *exp);
private:
  int  getLevel(char ch);
  bool isOperator(char ch);
  int  compareOpteratorLevel(char inputChar, char optrStackTop);
  int  calc(int num1, int num2, char op);
  void evaluate(char ch);
private:
  std::stack<int>  _opnd_stack;
  std::stack<char> _optr_stack;
  static char _optr[];
  static int  _level[];
};
#endif


// 头文件的实现代码 Calc.cxx
#include "Calc.h"
char Calculate::_optr[] = {'#', '(', '+', '-', '*', '/', ')'};
int Calculate::_level[] = { 0,   1,   2,   2,   3,   3,   4 };
// Get current operator level for calculating
int Calculate::getLevel(char ch) {
  for (int i = 0; *(_optr+i) != '\0'; ++i) 
    if (*(_optr+i) == ch) 
      return *(_level+i);
}
// Calculate the operands
int Calculate::calc(int num1, int num2, char op) {
  switch (op) 
    {
    case '+':
      return num1 + num2;
    case '-':
      return num1 - num2;
    case '*':
      return num1 * num2;
    case '/':
      return num1 / num2;
    }
}
// judge inputing character is operator or not
bool Calculate::isOperator(char ch) {
  for (char *p = _optr; *p != '\0'; ++p)
    if (*p == ch) 
      return true;
  return false;
}
// Compare level of input operator and the top operator of operator stack
int Calculate::compareOpteratorLevel(char inputChar, char optrStackTop) {
//   if (inputChar == '(' && optrStackTop == ')') 
//     return EQUAL;
//   else 
  if (inputChar == '(')
    return GREATER;
  if (inputChar == ')' && optrStackTop == '(') 
    return EQUAL;
  else if (inputChar == ')') 
    return LESS;
  if (inputChar == '#' && optrStackTop == '#') 
    return EQUAL;
//   else if (inputChar == '#')
//     return LESS;
  return (getLevel(inputChar) > getLevel(optrStackTop)) ? GREATER : LESS;
}
// Evaluate value while inputing operators
void Calculate::evaluate(char ch) {
  char op;
  int num, result;
  if (!isOperator(ch)) {
    _opnd_stack.push(ascii_int(ch));
    return ;
  }
  switch (compareOpteratorLevel(ch, _optr_stack.top())) 
    {
    case GREATER :
      _optr_stack.push(ch);
      break;
    case EQUAL :
      _optr_stack.pop();
      break;
    case LESS :
      num = _opnd_stack.top();
      _opnd_stack.pop();
      result = _opnd_stack.top();
      _opnd_stack.pop();
      op = _optr_stack.top();
      _optr_stack.pop();
      result = calc(result, num, op);
      _opnd_stack.push(result);
      evaluate(ch);
      break;
    }
}
// Evaluate user specified expression
int Calculate::evaluteExpr(char *exp) {
  _optr_stack.push('#');
  for (char *p =exp; *p != '\0'; ++p )
    evaluate(*p);
  int result = _opnd_stack.top();
  _opnd_stack.pop();
  return result;
}


// 测试代码 calc_test.cxx
#include <iostream>
#include "Calc.h"
using namespace std;
int main(void) {
  Calculate *calc = new Calculate();
  cout << "1+3*(4+7) = " 
       << calc->evaluteExpr("1+3*(4+7)#") 
       << endl;
  cout << "((1+2)) = " 
       << calc->evaluteExpr("((1+2))#") 
       << endl;
  cout << "3*8+9/7-5-9+(1-9)/4 = " 
       << calc->evaluteExpr("3*8+9/7-5-9+(1-9)/4#") 
       << endl;
  cout << "(6-7)*(5+9) = " 
       << calc->evaluteExpr("(6-7)*(5+9)#") 
       << endl;
  cout << "0*8+0/6-9+(7-1) = " 
       << calc->evaluteExpr("0*8+0/6-9+(7-1)#") 
       << endl;
  delete calc;
}

用 MinGW/G++ 3.4.5 编译如下: 
  g++  -o test.exe  Calc.cxx  Calc_test.cxx

作为一个演示算法够了， 但代码还是有一些缺点:
   (1) 只能处理一位数的加、减、乘、除表达式计算(可带括号)

 









上次写了CDH安装测试总结，由于那个博客篇幅略长， 但是主要集中在第二章，所以单独把CDH安装、卸载这块的内容拉出来在一篇记录一下。
一．搭建远程yum源
1.启动http服务：

service httpd start

2.挂载镜像文件rhel6.6.iso到/var/www/html下的任意文件夹

mount -o loop /RHEL-6.6Server.iso /var/www/html/rhel66

3.cd 到/etc/yum.repos.d 目录下，先把已有的repo做备份，并建立以”.repo”结尾的文件，这里我建立的是rhel66.repo，内容如下：

[rhel66] 
  name=rhel66 
  baseurl=http://serverIP/rhel66 
  enabled=1 
  gpgcheck = 0 
  #gpgkey = http://yourIP/rhel65/RPM-GPG-KEY-redhat-release

4.配置完成后用命令：

yum clean all 进行刷新 
  yum makecache

5.输入yum install httpd，打开浏览器，输入ip/rhel66 验证是否成功
二．准备CDH安装包
1.开启apache服务：

service httpd start

2.将已有的cloudera安装包和文件

CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel， 
  CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1， 
  manifest.json移到/var/www/html目录下，权限均为777，用户为root。

三. 安装cloudera

将cloudera-manager-installer.bin文件修改成可执行权限，在/var/www/html里执行cloudera-manager-installer.bin文件，开始安装
登录网址： ip:7180，用户，密码为admin
填写主机名 

集群存储库，使用parcel,选择更多选项，将其中https改为http，多余url删除，只保留第一个，{latest_support}删除  
 

选择自定义存储库，将示例的网址复制粘贴，把https改为http 

点击安装Oracle Java SE开发工具包(JDK)，点击继续按钮

输入所有主机的root密码，确定后点击继续

自定义选择安装的服务

安装其他内容，不详细的请参考上一篇： 
CDH安装测试总结
四．卸载CDH
CDH5.X，完全卸载步骤步骤如下：
1.关闭集群中的所有服务。
通过clouder manger 主页关闭集群。
2.卸载

[root@master ~]# /usr/share/cmf/uninstall-cloudera-manager.sh 
[root@slave1 ~]# service cloudera-scm-agent stop 
  [root@slave1 ~]# service cloudera-scm-agent stop

以下都是所有要卸载的集群均要执行清除工作：

[root@master ~]# umount /var/run/cloudera-scm-agent/process 
  [root@slave1 ~]# umount /var/run/cloudera-scm-agent/process 
  [root@slave2 ~]# umount /var/run/cloudera-scm-agent/process
[root@master ~]# rm -rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/x86_64/6/cloudera* /var/log/cloudera* /var/run/cloudera*  /etc/cloudera* 

3.卸载安装包：

[root@slave1 ~]# rpm -qa | grep cloudera
[root@slave2 ~]# for f in `rpm -qa | grep cloudera `  ; do rpm -e ${f} ; done     

（如果有保存，在执行一遍）
4.清除安装文件
shell 脚本如下：这一行很长，请复制全 
 
 rm -rf /var/lib/hadoop-* /var/lib/impala /var/lib/solr /var/lib/zookeeper /var/lib/hue /var/lib/oozie  /var/lib/pgsql  /var/lib/sqoop2  /data/dfs/  /data/impala/ /data/yarn/  /dfs/ /impala/ /yarn/  /var/run/hadoop-*/ /var/run/hdfs-*/ /usr/bin/hadoop* /usr/bin/zookeeper* /usr/bin/hbase* /usr/bin/hive* /usr/bin/hdfs /usr/bin/mapred /usr/bin/yarn /usr/bin/sqoop* /usr/bin/oozie /etc/hadoop* /etc/zookeeper* /etc/hive* /etc/hue /etc/impala /etc/sqoop* /etc/oozie /etc/hbase* /etc/hcatalog  

//只删除hadoop系列的，不要删除其他软件的，否则其他软件的版本控制会被破坏

[root@master alternatives]# rm -rf ` find /var/lib/alternatives/* ! -name “mta” ! -name “print” ! -name “zlibrary-ui”  -mtime -3` 
[root@master alternatives]# rm -rf /etc/alternatives/* 

5.杀死相关进程

for u in hdfs mapred cloudera-scm hbase hue zookeeper oozie hive impala flume; do sudo kill $(ps -u $u -o pid=); done

6.删除parcel包分发文件和解压文件

rm -rf /opt/cloudera/parcel-cache /opt/cloudera/parcels

到此卸载完毕。 










0.绪论
之前完全没有接触过大数据相关的东西，都是书上啊，媒体上各种吹嘘啊，我对大数据，集群啊，分布式计算等等概念真是高山仰止，充满了仰望之情，觉得这些东西是这样的：

当我搭建的过程中，发现这些东西是这样的：

对于初学者来说，我认为缺点如下：

1.需要控制，配置的东西太多，并且配置对应并不是很清晰（以后优化集群是否会有很高含金量？）
2.整个集群，我觉的从硬件到软件整体来说还是稳定性有待提高，尤其CDH   集群这块一会这个主机失去联系，一会NameNode挂，一会monitor挂，整个使用过程就是在不断的挂，看日志，挑错。基本离自动化，智能化还有很大距离。

CDH集群测试主要包括以下几个方面的内容：
1.装机（pxe），搭建服务器集群基础环境 
2.安装CDH集群，调试集群的健康状况，使集群可用 
3.测试集群性能，优化集群，使用测试框架（如Intel的HiBench框架）测试集群性能

1.基础建设简称基建
上一篇文章，我们已经介绍了集群安装操作系统的大杀器：
 pxe无人值守安装linux机器笔记
在批量安装完毕系统之后，本节主要围绕搭建CDH集群的基础建设进行介绍，基础建设简称基建，主要是为了支撑CDH集群后序工作流畅进行的一系列Linux系统的设置工作，基础建设工作没有做好，后面安装使用集群过程中会出现很多莫名奇妙的错误。基建主要包括，免密登录，时间同步，格式化硬盘，挂载目录等一些设置，下面为大家分别介绍：
1.1 建立主机分发脚本
新建一个host文件里面逐行设置为主机ip 
eg.

192.168.1.1 
  192.168.1.2 
  192.168.1.3

新建一个自定义脚本文件：

#!/bin/sh 
      host= `cat host` 
      for i in   $host 
      do 
      echo $i 
   #将需要分发的命令复制在此处 
  Done

1.2 免密码登陆
配置免密码登录 
1. 执行ssh-keygen命令，点击两次“回车”，生成/root/.ssh/id_rsa.pub文件；(使用脚本分发下面两条命令) 
2. cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys 
3. scp -r /root/.ssh $hostname:/root/
1.3 配置主机基础环境

修改默认语言为英文

vi /etc/sysconfig/i18n  
  LANG=”en_US.UTF-8”

修改host文件

scp /etc/hosts root@$i:/etc

关闭防火墙以及SELinux

ssh $i ‘service iptables stop’ 
  ssh $i ‘chkconfig iptables off’ 
  ssh $i ‘service ip6tables stop’ 
  ssh $i ‘chkconfig ip6tables off’ 
  ssh $i ‘setenforce 0’ 
  ssh $i ‘echo ‘service iptables stop’ >> /etc/rc.local’ 
  ssh $i ‘echo ‘service ip6tables stop’ >> /etc/rc.local’ 
  ssh $i ‘sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config’

同步时间 启动ntp服务，每5分钟向服务器同步一次（还需修改时间服务器上的部分配置，具体请百度）

ssh $i ‘cat >>/var/spool/cron/root  << EOF 
  */5 * * * * /usr/sbin/ntpdate serverIP> /dev/null 2>&1 
  EOF’ 
  ssh $i ‘echo ‘SYNC_HWCLOCK=yes’ >> /etc/sysconfig/ntpd’ 
  ssh $i ‘hwclock -w’

修改用户句柄限制

ssh $i ‘cat >> /etc/security/limits.conf << EOF 
  hadoop  soft    nofile  65000 
  hadoop  hard    nofile  65000 
  hadoop  soft    nproc  401408 
  hadoop  hard    nproc  401408 
  *  soft    nofile  65000 
  *  hard    nofile  65000 
  *  soft    nproc  401408 
  *  hard    nproc  401408 
  EOF’

建立挂载目录(根据自己的硬盘个数)

ssh $i ‘mkdir /data01 /data02 /data03 /data04 /data05  /data06  /data07  /data08  /data09  ‘

格式化硬盘（需批量执行，此处脚本有待升级）

ssh $i  
  ‘yes|parted /dev/sdb mklabel gpt  
  parted /dev/sdb mkpart primary 0% 100% 
  mkfs.ext4 -T largefile /dev/sdb1

修改/etc/fstab文件

ssh $i ‘cat >> /etc/fstab << EOF 
  /dev/sdb1   /data01            ext4    defaults,noatime        0    0

挂载目录

ssh $i  
  ‘mount /dev/sdb1   /data01

关闭swap交换分区

ssh $i ‘swapoff -a’ 
  ssh $i ‘sysctl -w vm.swappiness=0’ 
  ssh $i ‘echo ‘vm.swappiness=0’ >> /etc/sysctl.conf’

关闭大内存页面

ssh $i ‘cat >> /sys/kernel/mm/transparent_hugepage/defrag << EOF 
  never 
  EOF
ssh $i ‘cat >> /etc/rc.local << EOF 
  echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag 
  EOF

卸载自带的java环境，可以根据自己的java版本卸载 
检查集群机器是否安装过openJDK,如果有安装过，请卸载，执行命令 ：

rpm -qa | grep jdk 
  rpm -e xxx #xxx为上一步输出的rpm包名
ssh $i  
  ‘rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-devel-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-javadoc-1.6.0.0-1.66.1.13.0.el6.x86_64’

安装pscp和scala包

ssh $i ‘rpm -i /root/rpms/pssh-2.3.1-5.el6.noarch.rpm /root/rpms/scala-2.10.4.rpm’

配置java1.8.0_66环境

scp -r /usr/java/jdk1.8.0_66 root@$i:/usr/java/ 
  ssh $i ‘rm -rf /usr/java/lastest’ 
  ssh $i ‘ln -s /usr/java/jdk1.8.0_66 /usr/java/lastest’
ssh $i ‘cat >> /etc/profile << EOF 
  JAVA_HOME=/usr/java/jdk1.8.0_66 
  CLASS_PATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar 
  export JAVA_HOME 
  PATH=\$HOME/bin:\$JAVA_HOME/bin:\$PATH 
  export PATH 
  export CLASS_PATH 
  EOF’
scp /etc/profile root@$i:/etc/ 
  ssh $i ‘source /etc/profile’
done

时间同步

ssh $i ‘service ntpd stop 
  ntpdate lcgm2 
  ssh $i ‘hwclock -w’ 
  ssh $i ‘chkconfig ntpd on’ 
  done

配置yum源，开启http服务 
Yum源先mount在var/www/html/下面，在 
/etc/yum.repos.d/rhel-source.repo文件修改内容


一些可能用到的命令：
建立多级目录: mkdir -p /x/xx 
查看系统是否开启cloudera相关服务：chkconfig –list|grep cloudera 
查看eth0网卡网络速度：ethtool eth0|grep -i speed
1.4 绑定网卡
决定集群性能很大因素是集群的网络性能呢，所以一般大数据集群都是多个网卡绑定的bond0模式，绑定shell如下 
nmcli命令可能需要NetworkManager服务来支撑
 ifconfig
 systemctl stop firewalld.service 
 service iptables stop
 setenforce 0


 nmcli con add type bond con-name bond0 ifname bond0 mode 0
 nmcli con add type bond-slave con-name bondeno1 ifname eno1 master bond0
 nmcli con add type bond-slave con-name bondeno2 ifname eno2 master bond0
 nmcli con add type bond-slave con-name bondeno3 ifname eno3 master bond0
 nmcli con add type bond-slave con-name bondeno4 ifname eno4 master bond0

 cd /etc/sysconfig/network-scripts/
 vim ifcfg-bond0
    BOOTPROTO=static
    IPADDR=192.168.*.*
    PREFIX=24
    GATEWAY=192.168.*.*

 service network restart

 nmcli con reload

 nmcli con up bondeno4
 nmcli con up bondeno1
 nmcli con up bondeno2
 nmcli con up bondeno3
 nmcli con up bond0

2.安装配置Cloudera-Manager（离线）
在线安装方式由于需要安装的安装包过大，时间可能非常长，建议大家下载安装包进行离线安装。主要安装Cloudera Manager Server 和Agent。
2.1 离线仓库安装准备
在cloudrea下载离线仓库，下载地址 
    下载cm5： 
https://archive.cloudera.com/cm5/repo-as-tarball/5.8.0/cm5.8.0-centos6.tar.gz 
    下载cdh5： 
https://archive.cloudera.com/cdh5/parcels/5.8.0/ 
        列表： 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1 
        manifest.json 
    下载验证：https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.8.0/repodata/ 
    下载安装脚本： 
http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
2.2 主节点解压安装
cloudera manager的目录默认位置在/opt下，解压：tar xzvf cloudera-manager*.tar.gz将解压后的cm-5.*和cloudera目录放到/opt目录下(类似在windows把软件安装在D：/software)。
为Cloudera Manager 5建立数据库，可以用Mysql，或者自带的postgresql ，本文采用自带的数据库进行测试。
配置离线仓库地址：

开启apache服务：service httpd start
将下载的cloudera仓库移到/var/www/html目录下，调整目录结构：

 
cdh5目录结构： 

cm5目录结构: 

chmod u+x cloudera-manager-installer.bin，然后./*.bin该文件相关启动脚本，就可以进入安装界面进行安装啦。

service cloudera-scm-server start (这个启动有点慢，可以关注日志变动情况 ) 
  service cloudera-scm-agent start 

其中，日志所在路径是  
/var/log/cloudera-scm-server/cloudera-scm-server.log  
启动server后，使用:

/sbin/iptables -I INPUT -p tcp –dport 7180 -j ACCEPT ( 打开7180端口 )

2.3 配置集群

1.根据CM引导界面，用户名admin ，密码admin。选择Cloudera Express 免费版。点击下一步到为CDH集群安装指定主机。 




2.输入需要安装集群的机器IP地址，包括Cloudera Manager Server 机器。
3.选择集群的安装方式，选择使用数据包，CDH版本选择自定义，并输入yum源地址（基建中已经配置了的） 


 
（上图链接地址https可能会出错）
升级过程中遇到的问题 
提示Error Cannot retrieve repository metadata [repomod.xml] for cloudera-cdh5.Please verify its path and try again
(1) 检查机器的yum及cloudera的yum源配置是否正确 
(2) 在Cloudera升级步骤(5)中填写的apache上cm5包地址是否正确，协议应该使用http而不是https，不然就会出现这种错误 
(3)   若没有显示本地parcel包，可能是路径填写错误，可以根据配置的远程yum地址重新填写。

4.集群安装状态，可以看到每台集群的安装状态，如果正常则进入下一步。
5.选择要安装的CDH组件，我们选择安装HBase、HDFS、Hive、Spark、YARN、Zookeeper服务。点击继续（hibench测试主要需要这几个组件），角色服务分配参考如下：



6. CM会检测安装环境，可能会提示一处安装警告，比如： 
cloudera 建议将/proc/sys/vm/swappiness设置为0，当前设置为60，  
则我们需要在集群每台机器上执行命令：


echo 0> /proc/sys/vm/swappiness

王道就是有错就看日志调试。 


7.选择集群机器的角色分配，对于默认的选择都可以选择在Master机器上，当然像Second NameNode可以选择在非NameNode机器上。注意Cloudera Management Service都选Master。
8.数据库配置。根据创建数据表选择所对应的服务即可。
9.集群设置。选择默认，集群开始安装，完成，访问集群serverIP:7180/cmf，ok。

2.4 集群基本优化
2.4.1 关闭Linux THG服务
检查集群中的各个主机的THG（对虚拟化等的内存资源分配是有好处的，但是对hadoop离线计算IO密集型操作是没有优势的，关闭THG可加快处理速度）

1.查看THG

cat /sys/kernel/mm/redhat_transparent_hugepage/defrag

2.关闭THG

echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag


2.4.2 设置linux内核参数：vm.swappiness
vm.swappiness值的范围为0~100，作用是控制应用数据在物理内存和虚拟内存之间的交换，值越低，交换的越少。默认值为60。
查看集群各个主机的此参数值：

cat /proc/sys/vm/swappiness

建议调整值为1：

sysctl -w vm.swappiness=1

2.4.3 配置HDFS
点击HDFS -> 配置 -> 高级：hdfs-site.xml 的 HDFS 服务高级配置代码段（安全阀），加入配置使用公平队列
<property>  
    <name>ipc.8020.callqueue.impl</name>
    <value>org.apache.hadoop.ipc.FairCallQueue</value>
</property>
2.4.4 配置Yarn资源
关于Yarn内存分配与管理，主要涉及到了ResourceManage（集群资源调度协调）、ApplicationMatser（任务资源配置）、NodeManager（YARN节点代理配置）这几个概念，相关的优化也要紧紧围绕着这几方面来开展。
点击Yarn -> 资源管理：

设置ApplicationMaster Java最大堆栈：800M(AM内存默认1G)
容器内存yarn.nodemanager.resource.memory-mb 
计算一个节点需要分配的容器内存方法： 
主机内存-操作系统预留内存(12G) - Cloudera Manager Agent(1G) - HDFS DN(1G) – Yarn    NM(1G) 
= 主机内存-15G

如果安装了hive.需减掉12G左右内存. 
如果安装了hbase.还需减掉12-16G内存。 
如果安装impala.还需减掉至少16G内存。
例：64G内存主机，如果安装了hbase,hive，则建议分配的容器内存大约为：25~30G

容器虚拟CPU内核yarn.nodemanager.resource.cpu-vcores
计算一个节点需要分配的容器虚拟内核方法： 
(主机cpu核数 – 系统预留1 – Cloudera1 – HDFS1 – Yarn NN 1) * 4 
Hbase : -1 
例：24核机器，为yarn分配可用cpu核数大约20核左右，按照 核数:处理任务数=1:4(比例可酌情调整)，建议分配为80。由于本次集群CPU计算能力没达到官网建议的比例的要求，大约分配的比例为1:2，分配的核数为30核左右。
高级配置中：mapred-site.xml 的 MapReduce 客户端高级配置代码段（安全阀）

<property>
    <name>mapreduce.tasktracker.outofband.heartbeat</name>
    <value>true</value>
</property>
2.4.5 配置oozie
点击oozie –> 配置 -> 高级 ： oozie-site.xml 的 Oozie Server 高级配置代码段（安全阀），增加配置：
<property>
<name>oozie.launcher.fs.hdfs.impl.disable.cache</name>
  <value>true</value>
</property>
<property>
<name>oozie.action.max.output.data</name>
  <value>5000000</value>
</property>
2.4.6 配置Oozie HA(用HAproxy负载均衡)

Web界面操作略
error： 
Oozie could not be start 
REASON:java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
ERROR: java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
 Org.cod… jaskson…

导致上面错误是oozie的jaskson版本低，替换成1.9.13版本即可 
只替换jackson-mapper-asl和jackson-core-asl即可
替换步骤：
1. 
先将192.168.188.13的两jar包拷贝到/opt/cloudera/parcels/CDH/lib/oozie下
2.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} | sort |uniq | xargs -i cp jackson-* {}

3.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-mapper-asl-1.8.8.jar .

4.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-core-asl-1.8.8.jar .

2.4.7 其他优化
1.DRF策略
CDH集群调优：内存、Vcores和DRF
默认配置下，CPU核数和内存是1：1G的比例来启动任务的。可通过调整参数yarn.nodemanager.resource.memory-mb进行调整
2.每个container的分配多少内存和cpu
当应用程序向resource manager 申请资源（即申请container ）时， RM分配给一个container 多大的内存是按照一个最小单位进行分配的。 例如， 我们设置分配的最小单位为4GB， 则RM分配出来的container的内存一定是4G的倍数。  假设现在有一个程序向RM申请 5.1G的内存， 则RM会分配给它一个8GB的container去执行。 

yarn.scheduler.minimum-allocation-mb=4096

在实际执行map reduce的job中， 一个container实际上是执行一个map 或者reduce task的jvm的进程。 那么这个jvm在执行中会不断的请求内存，假设它的物理内存或虚拟内存占用超出了container的内存设定， 则node manager 会主动的把这个进程kill 掉。 
这里需要澄清一点， JVM使用的内存实际上分为虚拟内存和物理内存。  JVM中所有存在内存中的对象都是虚拟内存， 但在实际运行中只有一部分是实际加载在物理内存中的。 我们使用linux的top 可以看到 VM, RES,    前者是虚拟内存，后者可以看成近似是实际占用的物理内存。 因此在设置mapreduce的task的 jvm opts 参数时， 应将heap size 设置的比container允许的最大虚拟内存小。 这样jvm 不会因为申请过多的内存而被node manager 强制关闭。 当然设置最大heap size 如果在执行中被超过， jvm就会报 OutOfMemoryException。 
同时还有一个参数，设定了RM可以分配的最大的container是多大。   假设应用程序向RM申请的资源超过了这个值， RM会直接拒绝这个请求。 

yarn.scheduler.maximum-allocation-mb


3.HiBench集群性能测试
在大数据领域中，集群的性能很大程度上我认为主要是由整体的网络，数据吞吐量决定的，在使用HiBench测试时候发现，使用传统电口千兆网络的任务运行时间比光网任务运行时间要慢10s左右。HiBench的基准测试集是用来衡量一个大数据平台（基于Hadoop）性能的基准测试集，包含了文件系统的IO性能，系统的批处理吞吐，数据仓库用的OLAP分析算子，机器学习的处理能力，以及流处理系统的能力。
切换到光纤后，需要修改机器机器ip，这时候cdh居然没法启动了，百度之后，发现如果使用自带数据库postgresql，需要修改hosts表中记录的元数据信息：修改CDH集群ip
3.1 简介
hibench作为一个测试hadoop的基准测试框架，提供了对于hive：（aggregation，scan，join），排序（sort，TeraSort），大数据基本算法（wordcount，pagerank，nutchindex），机器学习算法（kmeans，bayes），集群调度（sleep），吞吐（dfsio），以及新加入5.0版本的流测试： 
we provide following streaming workloads for SparkStreaming, Storm . 

一个完整的TeraSort测试需要按以下三步执行：

用TeraGen生成随机数据
对输入数据运行TeraSort
用TeraValidate验证排好序的输出数据

所有hibench测试基本都是这样的流程，生成数据，运行，输出结果。
3.2 配置并编译HiBench
从GitHub下载HiBench开源包，本篇会基于HiBench-5.0为例。https://github.com/intel-hadoop/HiBench。如果是基于CDH 5.5测试，建议使用HiBench-5.0，其中包含了Spark 1.5的编译包。
编译

添加JAVA_HOME 环境变量
注释掉${HIBENCH_HOME} /src/streambench/pom.xml中两行

<!-- <module>stormbench</module> -->
<!-- <module>samzabench</module> -->

调用编译脚本：${HIBENCH_HOME}/bin/build-all.sh

配置

编辑 HiBench Configuration File：

cd ${HIBENCH_HOME}/conf
cp 99-user_defined_properties.conf.template 99-user_defined_properties.conf
编译配置文件，如下修改一些参数：
hibench.hadoop.home      /opt/cloudera/parcels/CDH/lib/hadoop 
  hibench.hadoop.mapreduce.home         /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce 
  hibench.spark.home                    /opt/cloudera/parcels/CDH/lib/spark 
  hibench.hdfs.master                   hdfs://cdh-node-11.cdhtest.com 
  hibench.hadoop.configure.dir          /etc/hadoop/conf 
  hibench.masters.hostnames            master # Resource Manager addresses 
  hibench.slaves.hostnames             hostname…
# Node Manager addresses
hibench.spark.master                  yarn-client 
  hibench.spark.version                spark1.6 
  spark.kryoserializer.buffer            2000m # 否则会出现大量spark.kryoserializer.buffer.mb被启用的警告 
  hibench.streamingbench.zookeeper.host         zookeeper-hostnames 
  hibench.streamingbench.brokerList             all-hostnames 
  hibench.streamingbench.kafka.home             /opt/cloudera/parcels/KAFKA

修改benchmarks.lst文件，只运行有必要的测试集，例：

#aggregation 
  #join 
  #kmeans 
  #pagerank 
  #scan 
  #sleep 
  sort 
  wordcount 
  #bayes 
  terasort 
  #nutchindexing 
  dfsioe

修改language.lst文件，只运行有必要的语言

cd ${HIBENCH_HOME}/conf
在language.lst文件中，将以下两行删除
spark/java 
  spark/python

修改load-config.py文件，确保Bench在运行时能找到唯一的包：

$HiBench-Home/bin/functions/load-config.py
将hadoop-mapreduce-client-jobclient*-tests.jar改为hadoop-mapreduce-client-jobclient-tests.jar

Bench在运行时有一些固化的目录和CDH不一致，需要建立目录引用

建立目录引用
mkdir -p /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  cd /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  ln -sf /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce mapreduce2

Bench会在HDFS根目录下生成文件，将HDFS的根目录权限修改为777：

sudo -u hdfs hadoop fs -chmod 777 /

（可选）如果在Kerberos启用的状况下，请增加以下步骤：

# 设置环境变量 
  export HIBENCH_HOME=/root/Downloads/HiBench-master 
  export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera 
  export JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export SPARK_YARN_USER_ENV=”JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH,LD_LIBRARY_PATH=$LD_LIBRARY_PATH”
# 重新登录Kerberos 
  kdestroy 
  kinit -k -t  


运行

命令行输入 

  ${HIBENCH_HOME}/bin/run-all.sh

3.3 HiBench基本优化配置

**优化基本原则**

在固定数据量的前提下，一般设置成让MapReduce作业在一轮Map、Reduce内结束，否则会增加MapReduce进程的调度开销。但如果输入的数据量过大，有可能会因为单个Map或者Reduce的内存消耗过大而到时严重的GC问题，这个需要在运行时对Map或者Reduce任务进程需要监测。

**YARN基本配置**





–
–



NodeManager
Container vCores数量就是系统的virtual core的数量Container Memory配置成节点上可用内存的75%到80%之间（如128GB的机器，可以设置96GB）


ResourceManager
Fair Scheduler调度器最小容器内存1GB 最小容器CPU 1个核最大容器内存=NodeManager Container内存的75%~80%最大容器CPU=NodeManager Container CPU的75%~80%增量内存512MB增量CPU 1个核


Gateway
mapreduce.map/reduce.max.mb = 2GBmapreduce.map/reduce.java.opts = max.mb * 0.8



附录（CDH 相关目录结构功能简介）

**1.相关目录**




/var/log/cloudera-scm-installer : 安装日志目录。 
  /var/log/* : 相关日志文件（相关服务的及CM的）。 
  /usr/lib64/cmf/ : Agent程序代码。 
  /var/lib/cloudera-scm-server-db/data : 内嵌数据库目录。 
  /usr/bin/postgres : 内嵌数据库程序。 
  /etc/cloudera-scm-agent/ : agent的配置目录。 
  /etc/cloudera-scm-server/ : server的配置目录。 
  /etc/clouder-scm-server/db.properties 默认元数据库用户名密码配置 
  /opt/cloudera/parcels/ : Hadoop相关服务安装目录。 
  /opt/cloudera/parcel-repo/ : 下载的服务软件包数据，数据格式为parcels。 
  /opt/cloudera/parcel-cache/ : 下载的服务软件包缓存数据。 
  /etc/hadoop/* : 客户端配置文件目录。


**2.配置**


Hadoop配置文件：

配置文件放置于/var/run/cloudera-scm-agent/process/目录下。如：

/var/run/cloudera-scm-agent/process/193-hdfs-NAMENODE/core-site.xml

这些配置文件是通过Cloudera Manager启动相应服务（如HDFS）时生成的，内容从数据库中获得（即通过界面配置的参数）。
在CM界面上更改配置是不会立即反映到配置文件中，这些信息会存储于数据库中，等下次重启服务时才会生成配置文件。且每次启动时都会产生新的配置文件。
CM Server主要数据库为scm基中放置配置的数据表为configs。里面包含了服务的配置信息，每一次配置的更改会把当前页面的所有配置内容添加到数据库中，以此保存配置修改历史。
scm数据库被配置成只能从localhost访问，如果需要从外部连接此数据库，修改

vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf

文件,之后重启数据库。运行数据库的用户为cloudera-scm。

查看配置内容

直接查询scm数据库的configs数据表的内容。 
访问REST API： http://hostname:7180/api/v4/cm/deployment，返回JSON格式部署配置信息。

配置生成方式

CM为每个服务进程生成独立的配置目录（文件）。所有配置统一在服务端查询数据库生成（因为scm数据库只能在localhost下访问）生成配置文件，再由agent通过网络下载包含配置文件的zip包到本地解压到指定的目录。

配置修改 
CM对于需要修改的配置预先定义，对于没有预先定义的配置,则通过在高级配置项中使用xml配置片段的方式进行配置。而对于/etc/hadoop/下的配置文件是客户端的配置，可以在CM通过部署客户端生成客户端配置。
数据库 
Cloudera manager主要的数据库为scm,存储Cloudera manager运行所需要的信息：配置，主机，用户等。
CM结构 
CM分为Server与Agent两部分及数据库（自带更改过的嵌入Postgresql）。它主要做三件事件： 
管理监控集群主机。 
统一管理配置。 
管理维护Hadoop平台系统。 
实现采用C/S结构，Agent为客户端负责执行服务端发来的命令，执行方式一般为使用python调用相应的服务shell脚本。Server端为Java REST服务，提供REST API，Web管理端通过REST API调用Server端功能，Web界面使用富客户端技术（Knockout）。 
Server端主体使用Java实现。 
Agent端主体使用Python, 服务的启动通过调用相应的shell脚本进行启动，如果启动失败会重复4次调用启动脚本。 
Agent与Server保持心跳，使用Thrift RPC框架。
升级 
在CM中可以通过界面向导升级相关服务。升级过程为三步： 
1.下载服务软件包。 
2.把所下载的服务软件包分发到集群中受管的机器上。 
3.安装服务软件包，使用软链接的方式把服务程序目录链接到新安装的软件包目录上。
卸载 
sudo /usr/share/cmf/uninstall-scm-express.sh, 然后删除/var/lib/cloudera-scm-server-db/目录，不然下次安装可能不成功。
开启postgresql远程访问 
CM内嵌数据库被配置成只能从localhost访问，如果需要从外部查看数据，数据修改vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf文件,之后重启数据库。运行数据库的用户为cloudera-scm。


参考文献
1.CDH官方文档 
2.http://www.cloudera.com/documentation.html 
3.CDH5.8官方文档 http://www.cloudera.com/documentation/enterprise/latest.html 
4.http://blog.selfup.cn/1631.html#comment-403 
5.https://github.com/intel-hadoop/HiBench 









1.首先安装pip-install
在使用centos7的软件包管理程序yum安装python-pip的时候会报一下错误：
No package python-pip available. 
Error: Nothing to do 
说没有python-pip软件包可以安装。
这是因为像centos这类衍生出来的发行版，他们的源有时候内容更新的比较滞后，或者说有时候一些扩展的源根本就没有。所以在使用yum来search  python-pip的时候，会说没有找到该软件包。 
因此为了能够安装这些包，需要先安装扩展源EPEL。EPEL(http://fedoraproject.org/wiki/EPEL) 是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。 
首先安装epel扩展源：
sudo yum -y install epel-release

然后安装python-pip：
sudo yum -y install python-pip

安装完之后别忘了清除一下cache：
sudo yum clean all

搞定！
2.在隔离容器中安装TensorFlow
推荐使用virtualenv 创建一个隔离的容器, 来安装 TensorFlow. 这是可选的, 但是这样做能使排查安装问 
题变得更容易，照着敲命令就行了
安装主要分成下面四个步骤： 
  ● Install pip and Virtualenv.（这一步装过了） 
  ● Create a Virtualenv environment. 
  ● Activate the Virtualenv environment and install TensorFlow in it. 
  ● After the install you will activate the Virtualenv environment each time you want to use TensorFlow. 
Install pip and Virtualenv: 
 # Ubuntu/Linux 64-bit
$ sudo apt-get install python-pip python-dev python-virtualenv

# Mac OS X
$ sudo easy_install pip
$ sudo pip install --upgrade virtualenv

Create a Virtualenv environment in the directory ~/tensorflow:
$ virtualenv --system-site-packages ~/tensorflow

Activate the environment:
$ source ~/tensorflow/bin/activate  # If using bash
$ source ~/tensorflow/bin/activate.csh  # If using csh

(tensorflow)$  # Your prompt should change
Now, install TensorFlow just as you would for a regular Pip installation. First select the correct binary to install: 
 # Ubuntu/Linux 64-bit, CPU only, Python 2.7
    (tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl

Finally install TensorFlow: 
 # Python 2
(tensorflow)$ pip install --upgrade $TF_BINARY_URL

出现了如下错误：
InstallationError: Command python setup.py egg_info failed with error code 1 in /root/tensorflow/build/mock

解决方案是： 
Distribute has been merged into Setuptools as of version 0.7. If you are using a version <=0.6, upgrade using :
pip install --upgrade setuptools 

or 
easy_install -U setuptools.

其实就是安装的egg需要升级一下把，我猜测
升级之后重新 ：
(tensorflow)$ pip install --upgrade $TF_BINARY_URL

等待一段时间，（我似乎看到tensorflow在用gcc编译c++，c，时间还挺长大概十来分钟） 
看到 
Successfully installed tensorflow protobuf six wheel mock numpy funcsigs pbr 
Cleaning up… 
就ok
3.测试代码
import tensorflow as tf
import numpy as np
# 使用 NumPy 生成假数据(phony data), 总共 100 个点.
x_data = np.float32(np.random.rand(2, 100)) # 随机输入
y_data = np.dot([0.100, 0.200], x_data) + 0.300

# 构造一个线性模型
b = tf.Variable(tf.zeros([1]))
W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))
y = tf.matmul(W, x_data) + b

# 最小化方差
loss = tf.reduce_mean(tf.square(y - y_data))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)
# 初始化变量
init = tf.initialize_all_variables()
# 启动图 (graph)
sess = tf.Session()
sess.run(init)
# 拟合平面
for step in xrange(0, 201):
        sess.run(train)
if step % 20 == 0:
        print step, sess.run(W), sess.run(b)

在命令行输入：
source ~/tensorflow/bin/activate

激活tensorflow环境，运行上述代码
(tensorflow)[root@www test]# python nihe.py

# 得到最佳拟合结果
  W: [[0.100 0.200]], b: [0.300]

退出虚拟环境：
(tensorflow)$ source deactivate

参考文献

https://github.com/tensorflow/tensorflow/blob/8cb0558da924e891aa1bb5d79a6c0c846301e4eb/tensorflow/g3doc/get_started/os_setup.md 
https://github.com/jikexueyuanwiki/tensorflow-zh 
http://www.tensorflow.org/（需要梯子）
 






 
2012-2-9 星期4
linux 常用命令：压缩解压命令
-gz命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz
tar -zcvf dir1.tar.gz dir1
将目录dir1压缩成一个打包文件并压缩文件
file命令：查看文件的格式，文件类型
zip解压缩命令.zip默认的win和linux通用的格式
语法：zip 选项-r 
              -r压缩目录
zip services.zip /etc/services
压缩文件
zip -r test.zip /test
压缩目录
 
解压缩命令：
unzip功能描述：解压.zip的压缩文件
范例：unzip test.zip
压缩解压缩命令：bzip2
bzip2 选项-k
          -k产生压缩文件 保留源文件
范例：bzip2 -k file1 
 
 
网络通信命令：
指令名称：write指令所在路径：/usr/bin/write
语法：write<用户名>
向另外一个用户发信息，以ctrl+d作为结束
范例：write samlee
 
wall命令：广播信息。所用linux的用户都能收到
 
 
shutdown -h now 立即关机
系统关机命令：reboot 功能：重启系统
 
命令别名的定义：alias copy=cp                alias xrm=“rm -r” 带选项的用双引号括起来
查看别名信息：alias
删除别名 ：unalias copy
 
 
输入输出重定向
同标准IO一样，shell对于每一个进程预先定义3个文件描述字
0 STDIN 标准输入
1 STDOUT标准输出
2 STDERR标准错误输出
>或者>>输出重定向
ls -l /tmp> /tmp.msg
date >> /tmp        追加结果
< 输入重定向
范例：wall < /etc/motd
2>错误输出重定向
范例：cp -R /usr/backup/usr/bak 2> /bak/error
 
 
管道
：将一个命令的输出传送给另一个命令，作为另一个命令的输入
使用方法：
命令1|命令2
范例：
ls-l /etc |more
ls -l /etc|grep init |wc -l
相当于统计出了在/etc目录下包含关键字init 的文件有几个
 
 
；
间隔的个命令按照顺序依次执行
&&
前后命令的执行存在逻辑关系只有&&前面的命令执行成功后，它后面的命令才能被执行
||
前后命令的执行存在逻辑关系，只有||前的命令执行失败后它后面的命令才会执行
 






                                            
 
2012-3-2
linux用户管理
用户信息文件：/etc/passwd
密码文件:/etc/shadow
用户组文件:/etc/group
用户组密码文件:/etc/gshadow
用户配置文件: /etc/login.defs  etc/default/useradd
新用户信息文件:/etc/ske 1
登陆信息:/etc/motd

linux用户分为三种:
超级用户:(root,UID =0)
普通用户:(UID:500-60000)
伪用户:(UID 1-499)

echo "123456" |md5sum ---产生123456的md5 加密密码
man 5 shadow 查看/etc/shadow中shadow的帮助,
 





 
centos6.0如果采用默认的最小化安装是没有安装桌面环境的，因此需要手动安装桌面环境。
我们可以用 #yum grouplist 查看已经安装的组件，以及支持安装的组件 首先，安装 X window system# yum groupinstall "
X Window system"由于centos6.0中只支持KDE组件，因此，安装KDE桌面环境#yum groupinstall "KDE Desktop"

开机为文本界面，由文本界面切换到图形界面：
    方法1：运行命令
          #startx ， 需要先配置图形界面信息
    方法2：修改/etc/inittab文件中的 
          id:3:initdefault ， 将3改为5 ，重新启动系统； 
    方法3：进入图形界面： init 5
 从图形界面进入文本界面： init 3
 重启： init 6
 关机： init 3 
真机环境中，在图形界面和文本界面间快捷键切换：
    Ctrl+Alt+F(n) , 其中F(n)为F1-F6 ，为6个控制台；
    Ctrl+ALT+F7 ；
eg:CTRL+ALT+F1是进入文本界面，CTRL+ALT+F7才是图形界面。
 

centos 下shutdown的命令后跟时间的单位是分钟
shutdown 60是60分钟后关机。

2012-1-20
从新安装了centos，选择desktop 安装桌面以及xwindows环境。1063个软件包。
2012-2-2
1.除了/之外所有字符都合法
2.有的字符，空格符，制表符，退格符和@#最好不要使用
3.避免使用.作为普通文件名的第一个字符。（.开头表示隐藏文件）
4.大小写敏感






 
2012-2-4
文件处理命令：cat 命令英文原意： concateate and display files
命令所在路径：/bin/cat
执行权限：所有用户
语法：cat[文件名]
功能描述：显示文件内容
范例：$cat/etc/issue
      $cat/etc/services
文件处理命令：more  //可以分页显示文件
范例：$more /etc/services
语法：more【文件名】
     （空格）或f    显示下一页
      （Enter）     显示下一行
      q或Q        退出 
     
文件处理命令：head 查看文件的前几行
head -num[文件名]
范例：$head -5 /etc/services
文件处理命令：tail查看文件的前几行
tail -num[文件名]
tail -f  动态显示更新内容
范例：$tail -5 /etc/services
 
文件处理命令 ：ln 
命令的英文原意：link
语法：ln -s[源文件][目标文件]
范例： $ln -s /etc/issue /issue.soft
软链接文件的权限： lrwxrwxrwx-->指向源文件，只是一个符号链接
时间值：软链接创建时候的时间值
类似于windows的快捷方式。
硬链接：ln /etc/issue /issue.hard
我们发现硬链接所有的属性和源文件相同。
硬链接的大小和源文件的大小一样，而且是和源文件同步更新的
ls -i i-inode i节点
内核需要处理响应的数字表示来确认相应的对象，每个文件必须有一个i节点。
但并不是一个i节点就对应一个文件。
硬链接和源文件有相同的i节点，软连接和源文件的i节点不同
所以硬链接和源文件可以同时更新。
 
权限处理命令：chmod
命令的英文原意：
语法 chmod [{ugo}{+-=}{rwx}][文件或目录]
           [mode=421][文件或目录]
功能描述：改变文件或目录的权限
chmod u +
      g -
      o =
u--所有者
g--所属组
o--其他人
rwx 可读可写可执行
ls -a a
chmod u+wx 文件或目录
chmod o-rx
chmod g=rwx
rwx 可读可写可执行
r-4
w-2
x-1
数字代表相应的权限
rwx r-x r--
7   5   4
rw- r-x --x
6   5   1
chmod 641 a 也可以改变权限
对文件有r权限
r-cat more head tail
w-echo vi 对一个文件具有写权限并不代表能够删除文件
x-命令，脚本
目录的权限
r-表示可以列出目录中的内容
w-表示可以在目录中创建删除文件touch， mkdir，rm
x-表示可以进入这个目录
 
 
权限管理命令：chown
改变文件的所有者
chgrp：改变文件的所属组
 
 
权限管理命令：umask
默认创建文件的权限掩码值
umask -S
 
 
linux权限规则：
缺省创建的文件不能授予可执行x权限（因此比较安全）






 
2012-2-8 星期三
文件搜索命令:

which [命令名称]
功能：显示系统命令所在目录(绝对路径)

$which ls
whereis可以表现出命令的帮助信息，帮助文件说存放的信息
 

find --通用查找命令

语法：find[搜索路径][搜索关键字]
功能：查找文件或目录
 
-name 根据文件名来查找
find /etc -name init
在目录/etc中查找文件init（只匹配文件名init，通配符*匹配任意字符包括零个字符）
init* ： 以init开头的文件
？：匹配单个字符 init？？？：init后面还有三个符号
-size 文件大小 block数据块 512字节
100MB=102400kb=204800数据块block（只支持数据块的表示方法）
find /-size+204800
在根目录下查找大于100mb的文件
（大于+  小于-    等于 ）
find /home -user samlee
在根目录下查找所有者为samlee的文件
 
时间
1.ctime ，atime ，mtime天为单位
2.cmin，amin，mmin分钟为单位
c-change改变，表示文件的属性被修改过
a-access访问
m-modify修改 ，表示文件的内容被修改过
-之内
+超过
 
find /etc -mmin -120
find /etc -ctime -1


在/etc下查找24小时内被修改过属性的文件和目录
find /etc -size +163840 -a -size -204800

在/etc下查找大于80mb小于100mb的文件
find /etc -name inittab -exec ls -l{} \;

在/etc 下查找inittab文件并显示其详细信息

-type 文件类型 f 二进制文件 l 软链接文件 d 目录
1.连接符 -a and 逻辑与 -o or 逻辑或
2.连接符 find .....-exec 命令 {} \;
                              {}find查询的结果
                               \转义符，使用符号命令本身的意思
                   -ok 询问确认
 


无论文件名叫什么都可以根据文件的i节点来进行查找
内核才能调用他。
 

文件搜索命令：locate

locate（搜索关键字）
列出所有跟file相关的文件
文件搜索命令：updatedb
执行权限：root
语法：updatedb
功能描述：建立整个系统目录文件的数据库
范例：#updatedb
 
文件搜索命令：grep


语法：grep[指定字串][源文件]
功能描述：在文件中搜索字串匹配的行并输出
范例：grep ftp /etc/services
 

帮助命令：
命令名称：man

命令的英文原意：manual
命令所在的路径：/user/bin/man
执行权限：所用用户
语法：man[命令或者配置文件]
功能描述：获得帮助信息
man ls 查看ls命令的帮助信息
man services 查看配置文件services的帮助信息
 
 
帮助指令：info
语法：info[任何关键字]
功能描述：获得帮助信息{unix中没有这个命令}
 
帮助命令：whatis

whatis whatis
指令名称：whatis apropos makewhatis
search the whatis database for strings
 
语法：whatis apropos [任何关键字]
功能描述：获得索引的简短说明信息
apropos fstab 相当于man -k
补充命令：help 查看shell内置命令的帮助
 
linux 常用命令：压缩解压命令

-gz
命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
 
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz






                                            
 
2012-2-13
linux 引导流程
1.固件firmware（cmos，bios）-》post加点自检
2.自举程序Bootloader（grub）-》载入内核
3.载入内核                  -》驱动硬件
4.启动进程init              -》系统启动的第一个进程
5.读取执行配置文件 /etc/inittab
 
master boot record->MBR主引导扇区 位置：0驻面0磁头1扇区
插入图片：
bootloader中存放的是自举程序：
windows中为：--》ntldr 以及 boot.ini文件中的内容
linux中为：  --》/etc/grub.conf
 
 
init的工作：
init启动后读取inittab文件，执行缺省运行级别而继续从而引导过程。在unix系统中
，init时第一个可以存在的进程，它的PID恒为1，但他也同时必须向一个更高级的功能负责
：PID为0的内核调度器（kernel scheduler），从而获得cpu时间
 
 
 

inittab 文件剖析

在inittab中，所有的条目采取以下格式：
id：run-level:action:process
id:标示符，一般为两位数字或者字母或者数字
run—level：指定运行级别可以指定多个
action：指定运行状态
process：指定要运行的脚本/命令
 
action常用取值：
initdefault：指定系统缺省启动的运行级别
sysinit：系统启动执行process中的运行级别
wait：执行process中指定的命令，并等起结束再运行其他命令
once：执行process中指定的命令，不等待其结果
ctrlaltdel：按下Ctrl+alt+del时执行process指定的命令
powerfail：当出现电源错误时执行process指定的命令，不等待其结束
powerokwait：当电源恢复是执行process指定的命令
respawn：一旦process指定的命令中止，便重新运行该命名
 
任何的系统级别都会起动系统的启动脚本：
/etc/rc.d/rc.sysinit         
ls /etc/rc.d/rc3.d 可以看到系统启动对应级别下需要执行的脚本操作
/etc/rc.d/rc[0123456].d
分别存放对应于运行级别的服务程序脚本的符号链接，链接到init.d目录中相应的脚本
 
比如：s12syslog
s—start
k—kill
数字
脚本名称
 
启动流程：插入图片：

 
 






                                            
 
2012-2-14 linux 软件包的管理
 
1.二进制软件包管理（RPM,YUM）
2.源代码包安装
3.脚本安装（shell或者java脚本）
4.debian系linux软件包管理简介
 
强行卸载-》插入图片


命令：rpm -e --nodeps samba
 
1.rpm包管理： 插入图片
 

2.rpm安装选项：插入图片

3.rpm覆盖安装：插入图片

 
4.文件冲突： 插入图片

 
5.文件依赖关系：


应用yum 的好处
1.自动解决软件包的依赖关系
2.方便的软件包的升级
yum包管理：图片
 
6.rpm包管理：
 
 





    
        clistctrl 虚拟列表             

       

一、什么是虚拟列表控件
虚拟列表控件是指带有LVS_OWNERDATA风格的列表控件。。
二、为什么使用虚拟列表控件
我们知道，通常使用列表控件CListCtrl，需要调用InsertItem把要显示的数据插入列表中，之后我们就不必关心数据在哪里了，这是因为控件自己开辟了内存空间来保存这些数据。现在假设我们要显示一个数据库，里面的信息量很大，有几十万条记录。通常有两种方法解决这个问题：1是仅仅在ListCtrl中插入少量的数据，比如100个，然后通过[上一页][下一页]两个按钮进行控制，某一时刻显示的只是从xxx到xxx+100之间的记录。2是把所有数据全部插入到ListCtrl中，然后让用户通过滚动来查看数据。无疑，很多用户喜欢采用第二种方式，特别是对于已经排序的数据，用户只需用键盘输入某行的开头字符，就可以快速定位到某一行。但是，如果这样做，InsertItem插入数据的过程将是很漫长的，而且用户会看到ListCtrl刷新速度也很慢，而且所有数据都位于内存中消耗了大量的内存，当数据多达上万以后几乎是不能忍受的。
为此，mfc特别提供了虚拟列表的支持。一个虚拟列表看起来和普通的ListCtrl一样，但是不用通过InsertItem来插入数据，它仅仅知道自己应该显示多少数据。但是它如何知道要显示什么数据呢？秘密就在于当列表控件需要显示某个数据的时候，它向父窗口要。假设这个列表控件包含100个元素，第10到20个元素（行）是可见的。当列表控件重画的时候 ，它首先请求父窗口给它第10个元素的数据，父窗口收到请求以后，把数据信息填充到列表提供的一个结构中，列表就可以用来显示了，显示第10个数据后，列表会继续请求下一个数据。
在虚拟的样式下，ListCtrl可以支持多达DWORD个数据项。(缺省的listctrl控件最多支持int个数据项)。但是，虚拟列表的最大优点不在于此，而是它仅仅需要在内存中保持极少量的数据，从而加快了显示的速度。所以，在使用列表控件显示一个很大的数据库的情况下，采用虚拟列表最好不过了。
不仅CListCtrl提供虚拟列表的功能， MFC的CListView类也有同样的功能。
三、虚拟列表控件的消息
虚拟列表总共发送三个消息给父窗口：当它需要数据的时候，它发送LVN_GETDISPINFO消息。这是最重要的消息。当用户试图查找某个元素的时候，它发送LVN_ODFINDITEM消息；还有一个消息是LVN_ODCACHEHINT，用来缓冲数据，基本上很少用到这个消息。
虚拟列表控件使用起来非常简单。它总共只有三个相关的消息，如果你直接使用CListCtrl，应该在对话框中响应这三个消息。如果你使用CListCtrl派生类，可以在派生类中响应这三个消息的反射消息。这三个消息分别是：
  （1）LVN_GETDISPINFO 控件请求某个数据
  （2）LVN_ODFINDITEM  查找某个数据
  （3）LVN_ODCACHEHINT 缓冲某一部分数据
我们必须响应的消息是（1），多数情况下要响应(2)，极少数的情况下需要响应（3）
四、如何使用虚拟列表控件
1、首先要创建控件，创建一个虚拟列表和创建一个正常的 CListCtrl差不多。先在资源编辑器里面添加一个list control资源。然后选中"Owner data"属性，然后给它捆绑一个CListCtrl变量。添加列，添加imagelist等都和使用正常的listctrl一样。
2、给虚拟列表添加元素。假设 m_list 是这个列表的控制变量。通常的情况下这样添加数据：
m_list.InsertItem(0, _T("Hello world"));
但是对于虚拟列表，不能这么做。只需告诉列表有多少个数据:
//总共显示100行
m_list.SetItemCount(100);
3、处理它的通知消息。
五、如何响应虚拟列表的消息
1、处理 LVN_GETDISPINFO 通知消息
当虚拟列表控件需要某个数据的时候，它给父窗口发送一个 LVN_GETDISPINFO通知消息，表示请求某个数据。因此列表的所有者窗口（或者它自己）必须处理这个消息。例如派生类的情况 (CMyListCtrl是一个虚拟列表类对象):
//这里处理的是反射消息
BEGIN_MESSAGE_MAP(CMyListCtrl, CListCtrl)
   //{{AFX_MSG_MAP(CMyListCtrl)
   ON_NOTIFY_REFLECT(LVN_GETDISPINFO, OnGetdispinfo)
   //}}AFX_MSG_MAP
END_MESSAGE_MAP()
在LVN_GETDISPINFO的处理函数中，必须首先检查列表请求的是什么数据，可能的值包括:
（1）LVIF_TEXT   必须填充 pszText
（2）LVIF_IMAGE  必须填充 iImage 
（3）LVIF_INDENT 必须填充 iIndent
（4）LVIF_PARAM  必须填充 lParam 
（5）LVIF_STATE  必须填充 state 
根据它的请求，填充所需的数据即可。
//================= 例子代码=====================================
下面的给出一个例子，填充的是列表所需的某个数据项的文字以及图像信息：
LV_DISPINFO* pDispInfo = (LV_DISPINFO*)pNMHDR;
LV_ITEM* pItem= &(pDispInfo)->item;
int iItemIndx= pItem->iItem;
if (pItem->mask & LVIF_TEXT) //字符串缓冲区有效
{
    switch(pItem->iSubItem){
        case 0: //填充数据项的名字
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strItemText);
            break;
        case 1: //填充子项1
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem1Text);
            break;
        case 2: //填充子项2
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem2Text);
            break;
    }
}
/*注意，多数情况下要使用lstrcpyn ，因为最多复制字符的个数由pItem->cchTextMax给出：
        lstrcpyn(pItem->pszText, text, pItem->cchTextMax);
*/
if (pItem->mask & LVIF_IMAGE) //是否请求图像
        pItem->iImage= m_Items[iItemIndx].m_iImageIndex;
甚至连某行数据是否选中（当有checkbox的情况下）的信息也需要由用户自己来维护，例如：
//是否显示该行的选择信息?
if(IsCheckBoxesVisible()) //自定义函数
{
    pItem->mask |= LVIF_STATE;
    pItem->stateMask = LVIS_STATEIMAGEMASK;
    if(m_database[itemid].m_checked)
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(2);
    }
    else
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(1);
     }
}
2、处理 LVN_ODFINDITEM 消息
在资源管理器里面，定位到某个文件夹，会显示很多文件，如果按下键盘的‘A’，则资源管理器会自动找到名字以 'A'打头的文件夹或者文件, 并选择该文件。继续按 A，如果还有其它名字以'A'打头的文件，则下一个文件被选中。如果输入 "AB"，则 'AB'打头的文件被选中。这就是列表控件的自动查找功能。
当虚拟列表收到一个LVM_FINDITEM消息，它也会发送这个消息通知父窗口查找目标元素。要搜索的信息通过 LVFINDINFO 结构给出。它是 NMLVFINDITEM 结构的一个成员。当找到要搜索的数据后，应该把该数据的索引（行号）返回，如果没有找到，则返回-1。
以对话框为例，响应函数大致如下:
//================= 例子代码=====================================
void CVirtualListDlg::OnOdfinditemList(NMHDR* pNMHDR, LRESULT* pResult) 
{
    // pNMHDR 里面是要查找的元素的信息
    // 要选中的目标元素的行号最后要保存在 pResult 中， 这是关键！
    NMLVFINDITEM* pFindInfo = (NMLVFINDITEM*)pNMHDR;
    /* pFindInfo->iStart 是查找的起始位置，一直到最后，然后从头开始，如果没有找到合适的，最终停留在iStart*/
    *pResult = -1;
    //是否按照文字查找？
    if( (pFindInfo->lvfi.flags & LVFI_STRING) == 0 )
    {
        return;
    }
    //这是我们要找的字符串
    CString searchstr = pFindInfo->lvfi.psz;
    int startPos = pFindInfo->iStart;//保存起始位置
    //判断是否最后一行
    if(startPos >= m_list.GetItemCount())
        startPos = 0;
    int currentPos=startPos;
    
    //开始查找
    do
    {        
        if( _tcsnicmp(m_database[currentPos].m_name, 
                 searchstr, searchstr.GetLength()) == 0)
        {
            //选中这个元素，停止查找
            *pResult = currentPos;
            break;
        }
        currentPos++;
        //从头开始
        if(currentPos >= m_list.GetItemCount())
            currentPos = 0;
    }while(currentPos != startPos);       
}
显然，如果数据很多，必须实现一个快速查找的方法。
关于pFindInfo->lvfi里面的信息的详细说明可以参考 MSDN。
3、处理 LVN_ODCACHEHINT 消息。
假如我们从数据库或者其它地方读取数据的速度比较慢，则可以利用这个消息，批量读取一些数据，然后根据请求，逐个提供给虚拟列表。LVN_ODCACHEHINT消息的用途就是给程序一个缓冲数据的机会。以提高程序的性能。
//================= 例子代码=====================================
使用 ClassWizard 重载 OnChildNotify 函数，检查是否 LVN_ODCACHEHINT 消息，然后准备缓冲数据：
NMLVCACHEHINT* pcachehint=NULL;
NMHDR* phdr = (NMHDR*)lParam;
if(phdr->code == LVN_ODCACHEHINT)
{
     pcachehint= (NMLVCACHEHINT*) phdr;
     //自定义函数，准备指定范围的数据到缓冲区
     PrepCache(pcachehint->iFrom, pcachehint->iTo);
}
else ...
注意，如果消息不是 LVN_ODCACHEHINT，则要传递给基类进行处理。
五、如何修改ListCtrl显示的数据。
由于是程序自己维护数据，所以只需修改数据库中的数据，然后调用CListCtrl::RedrawItems函数进行重画即可。
六、数据的选择状态和选择框
CListCtrl可以显示checkbox选择框。有些情况下是很有用的。对于正常的listctrl，用户可以用鼠标来修改某个元素的选择状态，但是对于虚拟列表就不行了。必须自己处理一些消息，然后自己保存数据的选中状态:
void CVirtualListDlg::ToggleCheckBox(int item)
{
    m_database[item].m_checked = !m_database[item].m_checked;
    m_list.RedrawItems(item, item);
}
处理 LVN_KEYDOWN消息，添加对空格键 的响应，用于切换选择状态：
void CVirtualListDlg::OnKeydownList(NMHDR* pNMHDR, LRESULT* pResult)
{
    LV_KEYDOWN* pLVKeyDown = (LV_KEYDOWN*)pNMHDR;
    if( pLVKeyDown->wVKey == VK_SPACE )
    {
       int item = m_list.GetSelectionMark();
        if(item != -1)
            ToggleCheckBox(item);
    }
    *pResult = 0;
}
然后处理 NM_CLICK 消息:
void CVirtualListDlg::OnClickList(NMHDR* pNMHDR, LRESULT* pResult)
{
    NMLISTVIEW* pNMListView = (NM_LISTVIEW*)pNMHDR;
    LVHITTESTINFO hitinfo;
    hitinfo.pt = pNMListView->ptAction;
    int item = m_list.HitTest(&hitinfo);
    if(item != -1)
    {
        //看看鼠标是否单击在 check box上面了?
        if( (hitinfo.flags & LVHT_ONITEMSTATEICON) != 0)
        {
            ToggleCheckBox(item);
        }
    }
    
    *pResult = 0;
}
七、备注：
    1、虚拟列表无法进行排序。
    2、虚表的一个优点是容易保持和数据库的同步。修改数据库中的数据，然后重画list十分容易而且高效。
    3、虚表的另一个优点是可以根据需要产生数据。比如在某一列加上行号。http://blog.vckbase.com/iwaswzq/archive/2006/07/07/21113.htmlhttp://www.codeproject.com/KB/list/virtuallist.aspx





一、什么是虚拟列表控件
虚拟列表控件是指带有LVS_OWNERDATA风格的列表控件。。
二、为什么使用虚拟列表控件
我们知道，通常使用列表控件CListCtrl，需要调用InsertItem把要显示的数据插入列表中，之后我们就不必关心数据在哪里了，这是因为控件自己开辟了内存空间来保存这些数据。现在假设我们要显示一个数据库，里面的信息量很大，有几十万条记录。通常有两种方法解决这个问题：1是仅仅在ListCtrl中插入少量的数据，比如100个，然后通过[上一页][下一页]两个按钮进行控制，某一时刻显示的只是从xxx到xxx+100之间的记录。2是把所有数据全部插入到ListCtrl中，然后让用户通过滚动来查看数据。无疑，很多用户喜欢采用第二种方式，特别是对于已经排序的数据，用户只需用键盘输入某行的开头字符，就可以快速定位到某一行。但是，如果这样做，InsertItem插入数据的过程将是很漫长的，而且用户会看到ListCtrl刷新速度也很慢，而且所有数据都位于内存中消耗了大量的内存，当数据多达上万以后几乎是不能忍受的。
为此，mfc特别提供了虚拟列表的支持。一个虚拟列表看起来和普通的ListCtrl一样，但是不用通过InsertItem来插入数据，它仅仅知道自己应该显示多少数据。但是它如何知道要显示什么数据呢？秘密就在于当列表控件需要显示某个数据的时候，它向父窗口要。假设这个列表控件包含100个元素，第10到20个元素（行）是可见的。当列表控件重画的时候 ，它首先请求父窗口给它第10个元素的数据，父窗口收到请求以后，把数据信息填充到列表提供的一个结构中，列表就可以用来显示了，显示第10个数据后，列表会继续请求下一个数据。
在虚拟的样式下，ListCtrl可以支持多达DWORD个数据项。(缺省的listctrl控件最多支持int个数据项)。但是，虚拟列表的最大优点不在于此，而是它仅仅需要在内存中保持极少量的数据，从而加快了显示的速度。所以，在使用列表控件显示一个很大的数据库的情况下，采用虚拟列表最好不过了。
不仅CListCtrl提供虚拟列表的功能， MFC的CListView类也有同样的功能。
三、虚拟列表控件的消息
虚拟列表总共发送三个消息给父窗口：当它需要数据的时候，它发送LVN_GETDISPINFO消息。这是最重要的消息。当用户试图查找某个元素的时候，它发送LVN_ODFINDITEM消息；还有一个消息是LVN_ODCACHEHINT，用来缓冲数据，基本上很少用到这个消息。
虚拟列表控件使用起来非常简单。它总共只有三个相关的消息，如果你直接使用CListCtrl，应该在对话框中响应这三个消息。如果你使用CListCtrl派生类，可以在派生类中响应这三个消息的反射消息。这三个消息分别是：
  （1）LVN_GETDISPINFO 控件请求某个数据
  （2）LVN_ODFINDITEM  查找某个数据
  （3）LVN_ODCACHEHINT 缓冲某一部分数据
我们必须响应的消息是（1），多数情况下要响应(2)，极少数的情况下需要响应（3）
四、如何使用虚拟列表控件
1、首先要创建控件，创建一个虚拟列表和创建一个正常的 CListCtrl差不多。先在资源编辑器里面添加一个list control资源。然后选中"Owner data"属性，然后给它捆绑一个CListCtrl变量。添加列，添加imagelist等都和使用正常的listctrl一样。
2、给虚拟列表添加元素。假设 m_list 是这个列表的控制变量。通常的情况下这样添加数据：
m_list.InsertItem(0, _T("Hello world"));
但是对于虚拟列表，不能这么做。只需告诉列表有多少个数据:
//总共显示100行
m_list.SetItemCount(100);
3、处理它的通知消息。
五、如何响应虚拟列表的消息
1、处理 LVN_GETDISPINFO 通知消息
当虚拟列表控件需要某个数据的时候，它给父窗口发送一个 LVN_GETDISPINFO通知消息，表示请求某个数据。因此列表的所有者窗口（或者它自己）必须处理这个消息。例如派生类的情况 (CMyListCtrl是一个虚拟列表类对象):
//这里处理的是反射消息
BEGIN_MESSAGE_MAP(CMyListCtrl, CListCtrl)
   //{{AFX_MSG_MAP(CMyListCtrl)
   ON_NOTIFY_REFLECT(LVN_GETDISPINFO, OnGetdispinfo)
   //}}AFX_MSG_MAP
END_MESSAGE_MAP()
在LVN_GETDISPINFO的处理函数中，必须首先检查列表请求的是什么数据，可能的值包括:
（1）LVIF_TEXT   必须填充 pszText
（2）LVIF_IMAGE  必须填充 iImage 
（3）LVIF_INDENT 必须填充 iIndent
（4）LVIF_PARAM  必须填充 lParam 
（5）LVIF_STATE  必须填充 state 
根据它的请求，填充所需的数据即可。
//================= 例子代码=====================================
下面的给出一个例子，填充的是列表所需的某个数据项的文字以及图像信息：
LV_DISPINFO* pDispInfo = (LV_DISPINFO*)pNMHDR;
LV_ITEM* pItem= &(pDispInfo)->item;
int iItemIndx= pItem->iItem;
if (pItem->mask & LVIF_TEXT) //字符串缓冲区有效
{
    switch(pItem->iSubItem){
        case 0: //填充数据项的名字
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strItemText);
            break;
        case 1: //填充子项1
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem1Text);
            break;
        case 2: //填充子项2
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem2Text);
            break;
    }
}
/*注意，多数情况下要使用lstrcpyn ，因为最多复制字符的个数由pItem->cchTextMax给出：
        lstrcpyn(pItem->pszText, text, pItem->cchTextMax);
*/
if (pItem->mask & LVIF_IMAGE) //是否请求图像
        pItem->iImage= m_Items[iItemIndx].m_iImageIndex;
甚至连某行数据是否选中（当有checkbox的情况下）的信息也需要由用户自己来维护，例如：
//是否显示该行的选择信息?
if(IsCheckBoxesVisible()) //自定义函数
{
    pItem->mask |= LVIF_STATE;
    pItem->stateMask = LVIS_STATEIMAGEMASK;
    if(m_database[itemid].m_checked)
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(2);
    }
    else
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(1);
     }
}
2、处理 LVN_ODFINDITEM 消息
在资源管理器里面，定位到某个文件夹，会显示很多文件，如果按下键盘的‘A’，则资源管理器会自动找到名字以 'A'打头的文件夹或者文件, 并选择该文件。继续按 A，如果还有其它名字以'A'打头的文件，则下一个文件被选中。如果输入 "AB"，则 'AB'打头的文件被选中。这就是列表控件的自动查找功能。
当虚拟列表收到一个LVM_FINDITEM消息，它也会发送这个消息通知父窗口查找目标元素。要搜索的信息通过 LVFINDINFO 结构给出。它是 NMLVFINDITEM 结构的一个成员。当找到要搜索的数据后，应该把该数据的索引（行号）返回，如果没有找到，则返回-1。
以对话框为例，响应函数大致如下:
//================= 例子代码=====================================
void CVirtualListDlg::OnOdfinditemList(NMHDR* pNMHDR, LRESULT* pResult) 
{
    // pNMHDR 里面是要查找的元素的信息
    // 要选中的目标元素的行号最后要保存在 pResult 中， 这是关键！
    NMLVFINDITEM* pFindInfo = (NMLVFINDITEM*)pNMHDR;
    /* pFindInfo->iStart 是查找的起始位置，一直到最后，然后从头开始，如果没有找到合适的，最终停留在iStart*/
    *pResult = -1;
    //是否按照文字查找？
    if( (pFindInfo->lvfi.flags & LVFI_STRING) == 0 )
    {
        return;
    }
    //这是我们要找的字符串
    CString searchstr = pFindInfo->lvfi.psz;
    int startPos = pFindInfo->iStart;//保存起始位置
    //判断是否最后一行
    if(startPos >= m_list.GetItemCount())
        startPos = 0;
    int currentPos=startPos;
    
    //开始查找
    do
    {        
        if( _tcsnicmp(m_database[currentPos].m_name, 
                 searchstr, searchstr.GetLength()) == 0)
        {
            //选中这个元素，停止查找
            *pResult = currentPos;
            break;
        }
        currentPos++;
        //从头开始
        if(currentPos >= m_list.GetItemCount())
            currentPos = 0;
    }while(currentPos != startPos);       
}
显然，如果数据很多，必须实现一个快速查找的方法。
关于pFindInfo->lvfi里面的信息的详细说明可以参考 MSDN。
3、处理 LVN_ODCACHEHINT 消息。
假如我们从数据库或者其它地方读取数据的速度比较慢，则可以利用这个消息，批量读取一些数据，然后根据请求，逐个提供给虚拟列表。LVN_ODCACHEHINT消息的用途就是给程序一个缓冲数据的机会。以提高程序的性能。
//================= 例子代码=====================================
使用 ClassWizard 重载 OnChildNotify 函数，检查是否 LVN_ODCACHEHINT 消息，然后准备缓冲数据：
NMLVCACHEHINT* pcachehint=NULL;
NMHDR* phdr = (NMHDR*)lParam;
if(phdr->code == LVN_ODCACHEHINT)
{
     pcachehint= (NMLVCACHEHINT*) phdr;
     //自定义函数，准备指定范围的数据到缓冲区
     PrepCache(pcachehint->iFrom, pcachehint->iTo);
}
else ...
注意，如果消息不是 LVN_ODCACHEHINT，则要传递给基类进行处理。
五、如何修改ListCtrl显示的数据。
由于是程序自己维护数据，所以只需修改数据库中的数据，然后调用CListCtrl::RedrawItems函数进行重画即可。
六、数据的选择状态和选择框
CListCtrl可以显示checkbox选择框。有些情况下是很有用的。对于正常的listctrl，用户可以用鼠标来修改某个元素的选择状态，但是对于虚拟列表就不行了。必须自己处理一些消息，然后自己保存数据的选中状态:
void CVirtualListDlg::ToggleCheckBox(int item)
{
    m_database[item].m_checked = !m_database[item].m_checked;
    m_list.RedrawItems(item, item);
}
处理 LVN_KEYDOWN消息，添加对空格键 的响应，用于切换选择状态：
void CVirtualListDlg::OnKeydownList(NMHDR* pNMHDR, LRESULT* pResult)
{
    LV_KEYDOWN* pLVKeyDown = (LV_KEYDOWN*)pNMHDR;
    if( pLVKeyDown->wVKey == VK_SPACE )
    {
       int item = m_list.GetSelectionMark();
        if(item != -1)
            ToggleCheckBox(item);
    }
    *pResult = 0;
}
然后处理 NM_CLICK 消息:
void CVirtualListDlg::OnClickList(NMHDR* pNMHDR, LRESULT* pResult)
{
    NMLISTVIEW* pNMListView = (NM_LISTVIEW*)pNMHDR;
    LVHITTESTINFO hitinfo;
    hitinfo.pt = pNMListView->ptAction;
    int item = m_list.HitTest(&hitinfo);
    if(item != -1)
    {
        //看看鼠标是否单击在 check box上面了?
        if( (hitinfo.flags & LVHT_ONITEMSTATEICON) != 0)
        {
            ToggleCheckBox(item);
        }
    }
    
    *pResult = 0;
}
七、备注：
    1、虚拟列表无法进行排序。
    2、虚表的一个优点是容易保持和数据库的同步。修改数据库中的数据，然后重画list十分容易而且高效。
    3、虚表的另一个优点是可以根据需要产生数据。比如在某一列加上行号。http://blog.vckbase.com/iwaswzq/archive/2006/07/07/21113.htmlhttp://www.codeproject.com/KB/list/virtuallist.aspx






#include <list>
#include <iostream>
using namespace std;

//list  链表的打印
void print(list<int>& l)
{
	list<int>::iterator i,iend;
	iend = l.end();

	for (i=l.begin();i!=iend;i++)
	{
		cout<<*i<<' ';
	}
}

int main()
{

	list<int> l;

	for (int j = 1;j <=10;j++ )
	{
		l.push_back(j);
	}

	//splice()函数
	/*
	//void splice(iterator position , list& x)
	将x的链表归并到当前list链表的position位置之前， list对象x将被清空

	 void splice(iterator position , list& , iterator i)
	 将一个list的迭代器i值所指的元素，归并到当前list链表中， 并将被归并元素从原链表中删除


	//
	*/

	list<int> carry;
	carry.splice(carry.begin(),l,l.begin());

	cout<<"carry的链表元素为：";
	print(carry);
	cout<<endl;

	cout<<"l 的链表元素为：";
	print(l);
	cout<<endl;


	//merge()函数用法
	/*

	void merge()合并两个链表并使之默认升序(也可改)：
	*/

	list<int> x;
	x.push_back(32);
	x.push_back(33);
	x.push_back(34);

	l.merge(x);

	cout<<"l 的链表元素为：";
	print(l);
	cout<<endl;


	getchar();
	return 0;

} 





  原文出处：http://lincccc.blogspot.tw/2011/03/cuda-cuts-fast-graph-cuts-on-gpu_03.html现在需要代理才能访问，所以就转载了。  [论文笔记] CUDA Cuts: Fast Graph Cuts on the GPUPaper：V. Vineet, P. J. Narayanan. CUDA cuts: Fast graph cuts on the GPU. In Proc. CVPR Workshop, 2008.问题概述：Graph cut是一种十分有用和流行的能量优化算法，在计算机视觉领域普遍应用于前背景分割（Image segmentation）、立体视觉（stereo vision）、抠图（Image matting）等。但在获得不错效果的同时，Max-flow / Min-cost问题求解的时间代价却很大。本文作者称其所知最佳的Graph cut实现求解一张640×480的图至少需100毫秒（平均数据会差得多），无法满足实时应用的需求。但事实上，Max-flow求解中经典的Push-relabel算法在流的计算和维护上只与局部相关，具有潜在的可并行性，适于GPU加速。因此，作者实现了push-relabel算法的GPU版。作者称其算法于一张640×480的图平均每秒可以求解150次Graph cut（Nvidia 8800 GTX），也就是约6.7毫秒速，是传统CPU算法约30-40倍速。作者还提供源码的下载，点我。代码在这个大学网站的资源里面：http://cvit.iiit.ac.in/（上述代码链接失效了，有大牛找到一份，我上传到csdn了：http://download.csdn.net/download/haihong84/3481581）Definition & Notation： 对于一个图 G = (V, E) ，其中 V 为节点集合，包括源点 s 和终点 t （也可以定义多个端点，其可以优化为双顶点图）、以及其他诸多中间节点集合 V’ ，E 为连接这些节点的边，每条边附有容量 c(u, v) 代表节点 u 通过这条边流向节点 v 所能承受的最大流量，在具体应用中边的容量通常等价于其能量值。Graph cut的目的在于找到图的Min-cut，Cut将 V’ 分割为两个部分，去掉这些边将使舍得图中的任意一个节点只与 s 或 t 相连通（如下图），而Min-cut是所有cut中边的能量值总和最小的一个。  算法上要直接找Min-cut是十分困难的，通常要将问题转化为与之等价的Max-flow问题（理论推导点我）。Graph cut具体应用的性能关键在于能量函数的定义，用于计算机视觉中的一种常见能量函数定义如下：  Dp 定义数据能量，Vp, q 定义平滑度能量，N 定义相邻关系，fp 为像素 p 的标签（属于 s 或 t ）。  经典Push-relabel算法： 求解Max-flow有两种经典的算法：Ford-Fulkerson和Push-relabel算法。Ford-Fulkerson算法的大意是在图中不断寻找 s 和 t 之间可用路径，记入总流量，并维护一张残余网络（Residual graph），直到再也找不到可用路径为止，此时的总流量就是Max-flow（具体算法点我）。Ford-Fulkerson算法的串行性很大，因为可用路径的查找是全局性的，这是GPU所不擅长的。   Push-relabel算法，相对的，具有很强的局部性和可并行性，在每一个子操作中指关心节点及其相邻节点。Push-relabel的基本思路是将尽可能多的流量从 s 推向 t ，但是当 t 已经无法再接受更多的流量时，这些流量将会被反推回 s，最终达到平衡（和Ford-Fulkerson算法一样，再也找不到 s 到 t 的可用路径）。算法过程中的“流”称为Preflow（先流），它并不像Ford-Fulkerson算法过程中的流一样总是持续升高直至Max-flow，而是初始预测一个值，在不断趋近于Max-flow，过程中可能出现回流的现象。Preflow对每一个节点满足 e(u) = in(u) – out(u)，且 e(u) ≥ 0。当 e(u) > 0 时，节点 u 溢出（overflowing）。溢出的节点需要将多余的流量Push向其相邻的节点，即Push操作。当一条从 s 到 t 的路径上所有的节点都不溢出时，此路径上的Preflow就变成真正的Flow了。   Push-relabel算法和Ford-Fulkerson算法一样都会维护一张残余网络。对于图中的每一个节点 u，若在残余网络中存在 e(u, v)，则 h(u) ≤ h(v) + 1。Push操作只能在 h(u) ＞ h(v) ，u 节点溢出且 e(u, v) 残留容量时进行；而当 u 节点溢出，且与之相邻所有残留边节点的 h(v) ≥ h(u) 时，只能进行Label操作，增加节点 u 的高度，即 h(u) += 1。在初始化时，h(s) = n，t 及其他所有节点的高度均为 0；从 s 出发的所有边初始化 f(e) = c(e)，其余边 f(e) =0。Push-relabel算法将不断重复Push和Label操作，直至任意操作都无法进行。 （更详细的算法步骤推荐查阅Tutorial，点我）   比较形象点，Push-relabel是泛滥的洪水，奔腾向前，堵了就倒流；Ford-Fulkerson则是很温吞的做法，先找个人探路，回来报告能流多少水就开闸放多少。  Push-relabel算法的GPU版： 存储和线程结构： Grid拥有和输入图片一样的维度，并被分为若干个Block，每个Block的维度为 B×B。每个线程对应一个节点（像素），即每个Block对应 B×B 个节点、需要访问 (B+2)×(B+2) 个节点的数据。每个节点包含以下数据：溢出量 e(u)，高度 h(u)，活跃状态 flag(u) 以及与其相邻节点间的边的容量。活跃状态共3种：Active，e(u) ＞ 0 且 h(u) = h(v) + 1；Passive，e(u) ＞ 0 且 h(u) ≠ h(v) + 1，这种状态在Relabel后可能变成Active；Inactive，没有溢出且没有相邻残留边， 这些数据存储在全局或设备内存中，被所有线程共享。 （GPU架构及Cuda指南参考NVidia相关手册，点我）   本文作者通过4个Kernel实现GPU版Push-relabel算法： 1) Push Kernel (node u)：   ■将 h(u) 和 e(u) 从全局内存读入到Block共享内存中（使用共享内存是因为一些数据会被相邻线程共享，这种读入方式相对单独的读入更节省时间）；   ■同步线程（使用共享内存都需要做这一步，为了保证所有内存都被完全读入了）；   ■将 e(u) 按照Push规则推向相邻节点（不大于边的剩余容量，且 h(u) ≥ h(v) ）；   ■将以上Preflow记入一个特殊的全局数组 F。之所以记入 F，而不直接写入相邻节点，是因为在并行Push操作时，一个节点的溢出值同时受到多个相邻节点的影响，如果直接写入，可能造成数据的不一致性（Read-after-write data consistency）。因此，作者将原来的Push操作分成了Push和Pull两个Kernel执行（另一种选择是在同一个Kernel中分两部分执行，之间进行一次同步，但是对于Block边缘的节点，这种同步需要等待其他Block的线程，这种Block间的同步并不被所有GPU支持）。   2) Pull Kernel (node u)：   ■读入 F 中推向 u 的Preflow；   ■累加所有新的Preflow，得到最终的溢出值，记入 e(u) 到全局内存。   3) Local Relabel Kernal (node u)： 按照经典Push-relabel算法中的Relabel操作，局部地调整节点的高度   ■将 h(u) 和 flag(u) 从全局内存读入到Block共享内存中；   ■同步线程；   ■计算 u 相邻 active / passive 节点的最小高度；   ■该最小高度+1，作为新高度写入 h(u) 到全局内存。   4) Global Relabel Kernal： 从终点 t 开始，按照广度优先策略，遍历所有节点，更新其高度至正确的距离（节点的高度总是其与终点距离的下限）。迭代次数 k 被记录与全局内存中。   ■如果 k == 1，所有与 t 相邻且有残留边的节点高度被设为 1；   ■所有未被设置的节点检查其相邻节点，若其相邻节点的高度为 k，则设置该节点高度为 k+1；   ■更新高度值到全局内存。   算法总体流程： a. 计算能量矩阵 → b. Push+Pull Kernel循环 → c. Local Relabel Kernel循环 → d. Global Relabel Kernel循环 → e. 重复b到d至收敛（没有可进行的Push和Relabel操作）   作者还基于GPU实现了Dynamic graph cut，应用于连续细微变化的Graph cut，通过对前一帧的简单修改形成新图，重用其他数据，加速Max-flow的求解。作者的实验数据称GPU实现可以提速70-100倍。不过具体应用具体分析，提速肯定是有的，多少未知，要待我实现过试验过。据说这个印度人提供的代码Bug颇多，虽然不太信，但还是先做了要重新实现的准备。末了，吐个槽，这论文贡献不大，确实只是发Workshop的水平。  





 参考文献：
http://blog.csdn.net/neoxmu/article/details/8866928
我安装的是CUDA5.5,代码如下：
 
//#include "stdafx.h"
#include "CL\cl.h"
#include <stdlib.h>
#include <stdio.h>

#pragma comment(lib,"OpenCL.lib")

#define CL_VERBOSE
void openclRetTackle(cl_int retValue, char* processInfo){
	if(retValue!=CL_SUCCESS){
#if (defined CL_DEBUG) || (defined CL_VERBOSE)
		printf("%s Error!\n",processInfo);
#endif
		exit(-1);
	}else{
#ifdef CL_VERBOSE
		printf("%s Success!\n",processInfo);
#endif
	}
}

cl_platform_id cpPlatform;
cl_device_id cdDevice;
cl_context cxGPUContext;
cl_command_queue cqCommandQueue;


int openclInit()
{
	cl_int ret;
	//得到平台ID
	openclRetTackle( clGetPlatformIDs(1, &cpPlatform, NULL), "clGetPlatFormIDs");
	//得到GPU设备ID
	openclRetTackle( clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU,1,&cdDevice,NULL), "clGetDeviceIDs");
	//获取GPU设备上下文
	cxGPUContext = clCreateContext(0, 1, &cdDevice, NULL, NULL, &ret);
	openclRetTackle( ret , "clCreateContext" );
	//开辟任务队列
	cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ret);
	openclRetTackle( ret , "clCreateCommandQueue");
	return CL_SUCCESS;
}

int run()
{
	openclInit();	
	system("pause");
	return 0;
}


 
<span style="font-family:Microsoft YaHei;font-size:18px;">//#include "stdafx.h"
#include <stdio.h>
#include <vector>
#include <CL/cl.h>
#include <iostream>
#include <fstream>
#include <string>

#pragma comment(lib,"OpenCL.lib")

int print_device()
{
	cl_int err;
	cl_uint num;
	err = clGetPlatformIDs(0, 0, &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platforms\n";
		return 0;
	}
	std::vector<cl_platform_id> platforms(num);
	err = clGetPlatformIDs(num, &platforms[0], &num);
	if(err != CL_SUCCESS)
	{
		std::cerr << "Unable to get platform ID\n";
		return 0;
	}

	cl_context_properties prop[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platforms[0]), 0 };
	cl_context context = clCreateContextFromType(prop, CL_DEVICE_TYPE_DEFAULT, NULL, NULL, NULL);
	if(context == 0)
	{
		std::cerr << "Can't create OpenCL context\n";
		return 0;
	}

	size_t cb;
	clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &cb);
	std::vector<cl_device_id> devices(cb / sizeof(cl_device_id));
	clGetContextInfo(context, CL_CONTEXT_DEVICES, cb, &devices[0], 0);

	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, 0, NULL, &cb);
	std::string devname;
	devname.resize(cb);
	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, cb, &devname[0], 0);
	std::cout << "Device: " << devname.c_str() << "\n";

	clReleaseContext(context);
	return 0;

}

cl_program load_program(cl_context context, const char* filename)
{
	std::ifstream in(filename, std::ios_base::binary);
	if(!in.good()) 
	{
		return 0;

	}// get file length
	in.seekg(0, std::ios_base::end);
	size_t length = in.tellg();
	in.seekg(0, std::ios_base::beg);

	// read program source
	std::vector<char> data(length + 1);
	in.read(&data[0], length);
	data[length] = 0;

	// create and build program 
	const char* source = &data[0];
	cl_program program = clCreateProgramWithSource(context, 1, &source, 0, 0);
	if(program == 0) 
	{
		return 0;
	}
	if(clBuildProgram(program, 0, 0, 0, 0, 0) != CL_SUCCESS) 
	{
		return 0;
	}
	return program;
}
int main()
{
	print_device();
	cl_int err;
	cl_uint num;
	err = clGetPlatformIDs(0, 0, &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platforms\n";
		return 0;
	}

	std::vector<cl_platform_id> platforms(num);
	err = clGetPlatformIDs(num, &platforms[0], &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platform ID\n";
		return 0;
	}
	cl_context_properties prop[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platforms[0]), 0 };
	cl_context context = clCreateContextFromType(prop, CL_DEVICE_TYPE_DEFAULT, NULL, NULL, NULL);
	if(context == 0) 
	{
		std::cerr << "Can't create OpenCL context\n";
		return 0;
	}

	size_t cb;
	clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &cb);
	std::vector<cl_device_id> devices(cb / sizeof(cl_device_id));
	clGetContextInfo(context, CL_CONTEXT_DEVICES, cb, &devices[0], 0);

	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, 0, NULL, &cb);
	std::string devname;
	devname.resize(cb);
	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, cb, &devname[0], 0);
	std::cout << "Device: " << devname.c_str() << "\n";

	cl_command_queue queue = clCreateCommandQueue(context, devices[0], 0, 0);
	if(queue == 0)
	{
		std::cerr << "Can't create command queue\n";
		clReleaseContext(context);
		return 0;
	}

	const int DATA_SIZE = 1048576;
	std::vector<float> a(DATA_SIZE), b(DATA_SIZE), res(DATA_SIZE);
	for(int i = 0; i < DATA_SIZE; i++) 
	{
		a[i] = std::rand();
		b[i] = std::rand();
	}

	cl_mem cl_a = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(cl_float) * DATA_SIZE, &a[0], NULL);
	cl_mem cl_b = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(cl_float) * DATA_SIZE, &b[0], NULL);
	cl_mem cl_res = clCreateBuffer(context, CL_MEM_WRITE_ONLY, sizeof(cl_float) * DATA_SIZE, NULL, NULL);
	if(cl_a == 0 || cl_b == 0 || cl_res == 0)
	{
		std::cerr << "Can't create OpenCL buffer\n";
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}

	cl_program program = load_program(context, "..\\shader.txt");
	if(program == 0) 
	{
		std::cerr << "Can't load or build program\n";
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}
	cl_kernel adder = clCreateKernel(program, "adder", 0);
	if(adder == 0)
	{
		std::cerr << "Can't load kernel\n";
		clReleaseProgram(program);
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}

	clSetKernelArg(adder, 0, sizeof(cl_mem), &cl_a);

	clSetKernelArg(adder, 1, sizeof(cl_mem), &cl_b);

	clSetKernelArg(adder, 2, sizeof(cl_mem), &cl_res);

	size_t work_size = DATA_SIZE;

	err = clEnqueueNDRangeKernel(queue, adder, 1, 0, &work_size, 0, 0, 0, 0);
	if(err == CL_SUCCESS)
	{

		err = clEnqueueReadBuffer(queue, cl_res, CL_TRUE, 0, sizeof(float) * DATA_SIZE, &res[0], 0, 0, 0);
	}
	if(err == CL_SUCCESS)
	{
		bool correct = true;
		for(int i = 0; i < DATA_SIZE; i++) 
		{
			if(a[i] + b[i] != res[i])
			{
				correct = false;
				break;
			}
		}
		if(correct) 
		{

			std::cout << "Data is correct\n";
		}
		else 
		{

			std::cout << "Data is incorrect\n";

		}
	}

	else 
	{
		std::cerr << "Can't run kernel or read back data\n";
	}


	clReleaseKernel(adder);
	clReleaseProgram(program);
	clReleaseMemObject(cl_a);
	clReleaseMemObject(cl_b);
	clReleaseMemObject(cl_res);
	clReleaseCommandQueue(queue);
	clReleaseContext(context);	
	return 0;

}</span>
 
 
需要使用的数据：
 
shader.txt
<span style="font-family:Microsoft YaHei;font-size:18px;">__kernel void adder(__global const float* a, __global const float* b, __global float* result)
{
    int idx = get_global_id(0);
    result[idx] = a[idx] + b[idx];
}</span>
 






1.注意事项编译的办法参见：http://blog.csdn.net/wangyaninglm/article/details/39997113 以下是程序代码，网上搜的例子：注意事项：32位工程添加64位的支持（主要取决于你编译的版本），配置好cuda的项目路径include2.代码//swap.cu


#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <opencv2/core/cuda_devptrs.hpp>
using namespace cv;
using namespace cv::gpu;

//自定义内核函数
__global__ void swap_rb_kernel(const PtrStepSz<uchar3> src,PtrStep<uchar3> dst)
{
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    if(x < src.cols && y < src.rows)
    {
        uchar3 v = src(y,x);
        dst(y,x) = make_uchar3(v.z,v.y,v.x);
    }
}

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream)
{
    dim3 block(32,8);
    dim3 grid((src.cols + block.x - 1)/block.x,(src.rows + block.y - 1)/block.y);

    swap_rb_kernel<<<grid,block,0,stream>>>(src,dst);
    if(stream == 0)
        cudaDeviceSynchronize();
}  //swap.cpp



#include <opencv2/gpu/gpu.hpp>
#include <opencv2/gpu/stream_accessor.hpp>


using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream);

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null())
{
	CV_Assert(src.type() == CV_8UC3);
	dst.create(src.size(),src.type());
	cudaStream_t s = StreamAccessor::getStream(stream);
	swap_rb_caller(src,dst,s);
}
 //main.cpp

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/gpu/gpu.hpp>

#pragma comment(lib,"opencv_gpu2410d.lib")
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")

using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null());

int main()
{
	Mat image = imread("lena.jpg");
	imshow("src",image);
	GpuMat gpuMat,output;

	gpuMat.upload(image);
	swap_rb(gpuMat,output);
	output.download(image);

	imshow("gpu",image);
	getchar();
	waitKey(0);
	return 0;
} 3.实现效果： 4.其他注意事项假设有两个工程：CUDA工程TestCuda；C++工程CallCuda 1. 在CUDA工程TestCuda中， （1）.cpp文件（类成员函数定义）调用.cu文件下的函数例如.cu文件下的函数void run_kernel(); 其前面必须用 extern “C” 修饰。而.cpp文件（类成员函数定义）下的类成员函数，如，void cpp_run();如果它想调用 run_kernel()，则首先可在.h文件（类定义）中的类定义的外面先声明.cu文件下的C函数，例如，extern “C” void run_kernel();（2）CUDA工程属性-->常规中，选择配置类型为“静态库(.lib)”-->应用； 同时在工程属性下的库管理器-->常规项下的附加依赖项中，添加CUDA库：cudart.lib，curand.lib等；在附加库目录添加相应的库所在目录。2.另外的C++工程CallCuda 在CallCuda工程属性下，找到附加依赖项，添加：CUDA库(cudart.lib等)和TestCuda生成的静态库(TestCuda.lib)；以及添加附加库目录。 至此，该工程下的.cpp文件下的函数，就可以调用CUDA工程下的cpp_run()函数了，不过首先要实例化类。1.将example.cu添加到工程中。在已有工程上右键单击，选择添加已有项。2.添加编译规则。右键单击工程文件，选择“自定义生成规则”，在弹出的对话框中选择CUDA Build Rule x.x。3.修改.cu文件的编译器。右键单击.cu文件，单击属性，修改编译规则，选择刚才添加的CUDA编译器。4.添加包含目录。在项目属性-》C++->常规->附加包含目录中添加CUDA SDK的目录。例如"C:\Program Files\NVIDIA Corporation\NVIDIA GPU Computing SDK 3.2\C\common\inc";"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.0\include"5.添加.lib文件。在链接器-》输入中添加cudart.lib cutil32D.lib6.修改代码生成为多线程(/MT)方式。7.Done.  以上是工程配置。 除此之外，还要把调用cuda代码的c++函数在.cu文件中用extern "C" 包含起来。并且在调用文件.cpp中用extern "C"声明该函数，然后调用。   





 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
 
//得9 分
//为了实现链式操作，将目的地址返回，加2 分！
char * strcpy( char *strDest, const char *strSrc )
{
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while( (*strDest++ = * strSrc++) != '/0' );
return address;
}

//得10 分，基本上所有的情况，都考虑到了
//如果有考虑到源目所指区域有重叠的情况，加1 分！
char * strcpy( char *strDest, const char *strSrc )
{
if(strDest == strSrc) { return strDest; }
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while((*strDest++ = *strSrc++)!='/0');
return address;
}


 
 
strncpy 是 C语言的函数之一，来自 C语言标准库，定义于 string.h，char *strncpy(char *destin, char *source, int maxlen)，把src所指由NULL结束的字符串的前n个字节复制到dest所指的数组中。
char *strncpy(char *strDes, const char *strSrc, unsigned int count)
{
assert(strDes != NULL && strSrc != NULL);
char *address = strDes;
while (count-- && *strSrc != '/0')
*strDes++ = *strSrc++;
*strDes = '/0';
return address;
}
 
 
 
strcpy和memcpy都是标准C库函数，它们有下面特点：
strcpy提供了字符串的复制。即strcpy只用于字符串复制，并且它不仅复制字符串内容外，还会复制字符串的结束符。
strcpy的函数原型是：char* strcpy(char* dest, const char* src);
 
memcpy只提供一般的内存复制，即memcpy对于需要复制的内容没有限制，因此用途更广。
memcpy的函数原型是：void *memcpy(void *dest,  const char* src,  size_t count);
 
  char *strcpy(char *dest, const char *src)  {     if((src == NULL) || (dest == NULL))      {          return NULL;     }
      char *strdest = dest; // 保存目标字符串的首地址     while((*dest++ = *str) != '\0');
     return strdest;
 }


 
 


void *memcpy(void *memTo, const char *memFrom, size_t size)
{
     if((memTo == NULL) || (memFrom == NULL))
     {
          return NULL;
     }
     char *tempFrom = (char *)memFrom; //保存memFrom的首地址     char *tempTo = (char *)memTo; //保存memTo的首地址      while(size-- > 0)
     {
          *tempTo++ = *tempFrom++;
     }
     return memTo;
}


 
strcpy 和 memcpy主要有以下三方面的区别：
1、复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符串、整型、结构体、类等。
2、复制的方法不同。strcpy不需要指定长度，它遇到被复制字符串的结束符"\0”才结束，所以容易溢出。memcpy则是根据第3个参数决定复制的长度。
3、用途不同。通常在复制字符串时用strcpy，而需要复制其它类型的数据是用memcpy。
 
memcpy 和 memmove 都是C语言中的库函数，在库函数 string.h中，其原型相似，它们都是从src所指向的内存中复制count个字节到dest所指内存中。并返回dest的值。
当源内存区域 和 目标内存区域无交叉重叠时，两者的结果是一样的，但如果有交叉呢？
memcpy是从src的其实部分开始复制，所以虽然第一种情况下没有问题，但如果遇到第二种情况，则会发生错误，交叉部分的src内容就会被覆盖掉了。
而memmove则由于采用不同的复制机制，所以可以正确处理第二种情况。
 
 


void *memmove(void *dst,const void *src,int n)
{
     char *dp = (char *)dst;
     char *sp = (char *)src; 
     assert((src!=0)&&(dst!=0)&&(n>0));//not　null 
     //非重叠 
      //dp < sp 
     //dp > (sp+n)     if(sp>dp||(sp+n)<dp)
     { 
         while(n--) 
             *(dp++) = *(sp++);
         *dp = '\0';
     }
     else if(sp<dp)//重叠 (此时条件 sp<dp<(sp+n))如果sp==dp则快速的返回     {//反向拷贝            sp += n; 
         dp += n; 
         *dp = '\0'; 
         while(n--)
            *(--dp) = *(--sp); 
     }
     return dst;
}       


 
在很多库函数上看到使用了assert()函数，assert函数的作用是计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条错误信息，然后调用abort()来终止进程。
函数名: abort
功 能: 异常终止一个进程
描述：abort()函数首先解除进程对SIGABRT信号的阻止，然后向调用进程发送该信号。abort()函数会导致进程的异常终止除非SIGABRT信号被捕捉并且信号处理句柄没有返回。
abort()函数导致所有的流被关闭和冲洗。
abort()函数没有返回值：void abort(void);
用 法: void abort(void);
程序例:
#include <stdio.h>
#include <stdlib.h>
int main(void) 
{ 
printf("Calling abort()\n");
abort();
return 0; /* This is never reached */
 }




 






 Dijkstra(迪杰斯特拉)算法是典型的最短路径路由算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。Dijkstra算法能得出最短路径的最优解，但由于它遍历计算的节点很多，所以效率低。
　　Dijkstra算法是很有代表性的最短路算法，在很多专业课程中都作为基本内容有详细的介绍，如数据结构，图论，运筹学等等。
其基本思想是，设置顶点集合S并不断地作贪心选择来扩充这个集合。一个顶点属于集合S当且仅当从源到该顶点的最短路径长度已知。
初始时，S中仅含有源。设u是G的某一个顶点，把从源到u且中间只经过S中顶点的路称为从源到u的特殊路径，并用数组dist记录当前每个顶点所对应的最短特殊路径长度。Dijkstra算法每次从V-S中取出具有最短特殊路长度的顶点u，将u添加到S中，同时对数组dist作必要的修改。一旦S包含了所有V中顶点，dist就记录了从源到所有其它顶点之间的最短路径长度。
例如，对下图中的有向图，应用Dijkstra算法计算从源顶点1到其它顶点间最短路径的过程列在下表中。
 
 


Dijkstra算法的迭代过程：
 
 

 
 
 
 
#include <stdio.h>
#include <conio.h>
#include <stdlib.h>

#define X 10000
#define VertexNum  7  //实际上共有六个顶点（1---6）
#define EdgeNum  9

int Graph[VertexNum][VertexNum] =
//0  1  2  3  4  5  6
{ X, X, X, X, X, X, X,  //0
  X, X, 6, 3, X, X, X,  //1
  X, X, X, X, 5, X, X,  //2
  X, X, 2, X, 3, 4, X,  //3
  X, X, X, X, X, X, 3,  //4
  X, X, X, X, 2, X, 5,  //5
  X, X, X, X, X, X, X   //6
};

int Visited[VertexNum];
int path[VertexNum];
int Distance[VertexNum];

void Dijkstra(int Begin)
{
  int MinEdge, Vertex, i,j, Edges;
  Edges = 1;
  Visited[Begin] = 1;
  for (i = 1; i<VertexNum; i++) Distance[i] = Graph[Begin][i];

  Distance[Begin] = 0;
  printf("     1  2  3  4  5  6\\n");
  printf("-----------------------------------\\n");
  printf("s:%d", Edges);
  for( i=1; i<VertexNum; i++)
  if (Distance[i] == X) printf("  *"); else printf("%3d",Distance[i]);
  printf("\\n");
  while( Edges<VertexNum-1)
  {
    Edges++; MinEdge = X;
    for(j=1; j<VertexNum; j++)
    if (Visited[j]==0 && MinEdge > Distance[j] )
    {
 Vertex = j; MinEdge = Distance[j];
    }
    Visited[Vertex] = 1;
    printf("s:%d",Edges);
    for(j=1; j<VertexNum; j++)
    {
      if (Visited[j] == 0 && Distance[Vertex] + Graph[Vertex][j] <Distance[j])
      {   Distance[j] = Distance[Vertex] + Graph[Vertex][j];
   path[j] = Vertex;
      }
      //printf("%6d",Distance[j]);
       if (Distance[j] == X) printf("  *"); else printf("%3d",Distance[j]);
    }
    printf("\\n");
  }
}

void main()
{
  
  int i;
  int k;
 // clrscr();
  for(i=0; i<VertexNum; i++) { Visited[i] = 0;  path[i] = 1;}
  Dijkstra(1);
  printf("\\n\\nAll Path-------------------------\\n");


  for(i=2; i<VertexNum; i++) //printf("%5d",Visited[i]);
  {
     printf("[%d] ",Distance[i]);
     k = i;
     do
     {
       printf("%d<--",k);
       k  = path[k];
     } while (k!=1);
     printf("1 \\n");
  }
}


以上代码参考了数据结构课本
 
 
下面的是网上的代码：
以下是具体的实现(C/C++):
/***************************************
* About:    有向图的Dijkstra算法实现
* Author:   Tanky Woo
* Blog:     www.WuTianQi.com
***************************************/
 
#include <iostream>
using namespace std;
 
const int maxnum = 100;
const int maxint = 999999;
 
 
void Dijkstra(int n, int v, int *dist, int *prev, int c[maxnum][maxnum])
{
    bool s[maxnum];    // 判断是否已存入该点到S集合中
    for(int i=1; i<=n; ++i)
    {
        dist[i] = c[v][i];
        s[i] = 0;     // 初始都未用过该点
        if(dist[i] == maxint)
            prev[i] = 0;
        else
            prev[i] = v;
    }
    dist[v] = 0;
    s[v] = 1;
 
    // 依次将未放入S集合的结点中，取dist[]最小值的结点，放入结合S中
    // 一旦S包含了所有V中顶点，dist就记录了从源点到所有其他顶点之间的最短路径长度
    for(int i=2; i<=n; ++i)
    {
        int tmp = maxint;
        int u = v;
        // 找出当前未使用的点j的dist[j]最小值
        for(int j=1; j<=n; ++j)
            if((!s[j]) && dist[j]<tmp)
            {
                u = j;              // u保存当前邻接点中距离最小的点的号码
                tmp = dist[j];
            }
        s[u] = 1;    // 表示u点已存入S集合中
 
        // 更新dist
        for(int j=1; j<=n; ++j)
            if((!s[j]) && c[u][j]<maxint)
            {
                int newdist = dist[u] + c[u][j];
                if(newdist < dist[j])
                {
                    dist[j] = newdist;
                    prev[j] = u;
                }
            }
    }
}
 
void searchPath(int *prev,int v, int u)
{
    int que[maxnum];
    int tot = 1;
    que[tot] = u;
    tot++;
    int tmp = prev[u];
    while(tmp != v)
    {
        que[tot] = tmp;
        tot++;
        tmp = prev[tmp];
    }
    que[tot] = v;
    for(int i=tot; i>=1; --i)
        if(i != 1)
            cout << que[i] << " -> ";
        else
            cout << que[i] << endl;
}
 
int main()
{
    freopen("input.txt", "r", stdin);
    // 各数组都从下标1开始
    int dist[maxnum];     // 表示当前点到源点的最短路径长度
    int prev[maxnum];     // 记录当前点的前一个结点
    int c[maxnum][maxnum];   // 记录图的两点间路径长度
    int n, line;             // 图的结点数和路径数
 
    // 输入结点数
    cin >> n;
    // 输入路径数
    cin >> line;
    int p, q, len;          // 输入p, q两点及其路径长度
 
    // 初始化c[][]为maxint
    for(int i=1; i<=n; ++i)
        for(int j=1; j<=n; ++j)
            c[i][j] = maxint;
 
    for(int i=1; i<=line; ++i)  
    {
        cin >> p >> q >> len;
        if(len < c[p][q])       // 有重边
        {
            c[p][q] = len;      // p指向q
            c[q][p] = len;      // q指向p，这样表示无向图
        }
    }
 
    for(int i=1; i<=n; ++i)
        dist[i] = maxint;
    for(int i=1; i<=n; ++i)
    {
        for(int j=1; j<=n; ++j)
            printf("%8d", c[i][j]);
        printf("\n");
    }
 
    Dijkstra(n, 1, dist, prev, c);
 
    // 最短路径长度
    cout << "源点到最后一个顶点的最短路径长度: " << dist[n] << endl;
 
    // 路径
    cout << "源点到最后一个顶点的路径为: ";
    searchPath(prev, 1, n);
}
输入数据:
5
7
1 2 10
1 4 30
1 5 100
2 3 50
3 5 10
4 3 20
4 5 60
输出数据:
999999 10 999999 30 100
10 999999 50 999999 999999
999999 50 999999 20 10
30 999999 20 999999 60
100 999999 10 60 999999
源点到最后一个顶点的最短路径长度: 60
源点到最后一个顶点的路径为: 1 -> 4 -> 3 -> 5
最后给出两道题目练手，都是直接套用模版就OK的：
1.HDOJ 1874 畅通工程续
http://www.wutianqi.com/?p=1894
2.HDOJ 2544 最短路
http://www.wutianqi.com/?p=1892


 









在Docker – 系统整洁之道 – 1中已经对Docker的一些命令和Docker镜像的使用及操作做了记录。 
这次就利用docker进行一次真正的实例使用，使用docker搭建一个简单的答题系统，这个系统是当时做来给网络安全周做手机答题的系统，很简单，代码风格很差。
这篇主要记录了三种docker使用的方式。

用supervisor方式运行一个多进程的docker实例
创建一个ngnix和php运行的环境
创建一个ngnix，php，mysql集合运行的环境，使用docker-compose构建




感觉docker的东西越看越多，从刚开始的简简单单的一个docker run，到现在看到要build自己的镜像，compose,也就是以前的Fig，配置网络，还有swarm的docker集群，一点一点来吧。

先把两个附件写在这里吧 
此片博客中构建php+ngnix+mysql测试环境的脚本 
在测试环境中的答题网站源码
supervisor方式运行一个多进程的docker实例

Docker 容器在启动的时候开启单个进程，比如，一个 ssh 或者 apache 的 daemon 服务。但我们经常需要在一个机器上开启多个服务，这可以有很多方法，最简单的就是把多个启动命令放到一个启动脚本里面，启动的时候直接启动这个脚本，另外就是安装进程管理工具。这里使用进程管理工具 supervisor 来管理容器中的多个进程。使用 Supervisor 可以更好的控制、管理、重启我们希望运行的进程。
首先创一个文件夹叫做supervisor,目录结构为
~/Docker tree supervisor
supervisor
├── Dockerfile
└── supervisord
其中文件Dockerfile文件内容为：
#使用时哪个镜像
FROM ubuntu:13.04
MAINTAINER examples@docker.com
RUN echo "deb http://archive.ubuntu.com/ubuntu precise main universe" > /etc/apt/sources.list
RUN apt-get update
RUN apt-get upgrade -y

#这里安装 3 个软件，还创建了 2 个 ssh 和 supervisor 服务正常运行所需要的目录。
RUN apt-get install -y --force-yes perl-base=5.14.2-6ubuntu2
RUN apt-get install -y apache2.2-common
RUN apt-get install -y openssh-server apache2 supervisor
RUN mkdir -p /var/run/sshd
RUN mkdir -p /var/log/supervisor

#添加 supervisord 的配置文件，并复制配置文件到对应目录下面。
COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf

#映射了 22 和 80 端口，使用 supervisord 的可执行路径启动服务
EXPOSE 22 80
CMD ["/usr/bin/supervisord"]
文件supervisord内容为：
#supervsord 配置软件本身，使用 nodaemon 参数来运行
[supervisord]
nodaemon=true

#配置两个服务
[program:sshd]
command=/usr/sbin/sshd -D
[program:apache2]
command=/bin/bash -c "source /etc/apache2/envvars && exec /usr/sbin/apache2 -DFOREGROUND"
使用命令进行构建
sudo docker build -t supervisor
输出：
~/Docker/supervisor  sudo docker build -t supervisord .
Password:
Sending build context to Docker daemon 3.584 kB
Step 1 : FROM ubuntu:13.04
---> a58cd502f927
Step 2 : MAINTAINER examples@docker.com
---> Using cache
---> 15f104cdeb77
Step 3 : RUN echo "deb http://archive.ubuntu.com/ubuntu precise main universe" > /etc/apt/sources.list
---> Using cache
---> c6bb44d794ea
Step 4 : RUN apt-get update
---> Using cache
---> adcd83eecb0d
Step 5 : RUN apt-get upgrade -y
---> Using cache
---> 89e045811261
Step 6 : RUN apt-get install -y --force-yes perl-base=5.14.2-6ubuntu2
---> Using cache
---> bcdc472cc73a
Step 7 : RUN apt-get install -y apache2.2-common
---> Using cache
---> d8991f8aa3c6
Step 8 : RUN apt-get install -y openssh-server apache2 supervisor
---> Using cache
---> a713034800d6
Step 9 : RUN mkdir -p /var/run/sshd
---> Using cache
---> 3138e3644958
Step 10 : RUN mkdir -p /var/log/supervisor
---> Using cache
---> 958c08978b0c
Step 11 : COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf
---> 8e9a0c97a133
Removing intermediate container d95b58057f73
Step 12 : EXPOSE 22 80
---> Running in 9cabb0865159
---> b4aa8b82cd57
Removing intermediate container 9cabb0865159
Step 13 : CMD /usr/bin/supervisord
---> Running in 237f71166211
---> 569f95736129
Removing intermediate container 237f71166211
Successfully built 569f95736129
使用docker ps 一下
~/Docker/supervisor  docker ps
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS              PORTS                                          NAMES
c82c830770bc        supervisord:latest   "/usr/bin/supervisord"   32 seconds ago      Up 30 seconds       0.0.0.0:32770->22/tcp, 0.0.0.0:32769->80/tcp   supervisord
发现刚才build的镜像已经跑起来了，访问 http://127.0.0.1:32769，可以web服务已经跑起来了。

使用命令docker exec进入container里面看看
 ~/Docker/supervisor  docker exec -it c82c830770bc bash
root@c82c830770bc:/# hello
bash: hello: command not found
root@c82c830770bc:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  selinux  srv  sys  tmp  usr  var
root@c82c830770bc:/#
使用passwd修改一下密码，然后在本机的命令行里进行ssh连接吧。
ngnix和php运行的环境

该方法就是直接使用docker命令进行构建一个ngnix,php结合运行的环境，没有使用docker-compose。
先用户根目录~下创建目录，并将该目录设置为Docker的共享目录。
Workspace
└── tmp
    ├── docker
    │   └── nginx
    │       └── conf.d
    │           └── default.conf
    └── www
        ├── index.html
        └── phpinfo.php
其中default.conf文件内容，这是个nginx的配置文件
server {
    listen       80;
    server_name  localhost;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    location ~ \.php$ {
        fastcgi_pass   php:9000;
        fastcgi_index  index.php;
        fastcgi_param  SCRIPT_FILENAME  /var/www/html/$fastcgi_script_name;
        include        fastcgi_params;
    }
}
index.html 里写一句 HelloW0rld，phpinfo.php里面写一个<?php phpinfo();?>。
然后在命令行下执行命令
docker pull php:5.6-fpm-alpine

docker pull ngnix:1.10.2

docker run --name dream.php -d -v ~/Workspace/tmp/www:/var/www/html:ro php:5.6-fpm

docker run --name dream.nginx -p 80:80 -d -v ~/Workspace/tmp/www:/usr/share/nginx/html:ro -v ~/Workspace/tmp/docker/nginx/conf.d:/etc/nginx/conf.d:ro --link dream.php:php nginx:1.10.2
好的，如果不出意外，就可以看到phpinfo的界面了。这个是没有添加mysql的测试环境，直接在目录~/Workspace/tmp/www下面放网页就可以直接使用了。
ngnix，php，mysql集合运行的环境

Supervisor给出了一种能够在container中运行多个线程的方法，但是现在还是不知道要怎么样把自己的web服务部署到container中，数据库怎么建，可以有人会说直接使用SFTP将网站直接传到container里，安装数据库，配环境，但是docker中一旦container被删除，内容就没了。像这样将所有服务放在一个容器内的模式有个形象的非官方称呼：Fat Container。与之相对的是将服务分拆到容器的模式。从Docker的设计可以看到，构建镜像的过程中可以指定唯一一个容器启动的指令，因此Docker天然适合一个容器只运行一种服务，而这也是官方更推崇的。下面就记录一下部署一个简单的php程序和数据库联动的测试环境。
整体的文件结构是这样的 
我们创建一个这样的目录
Docker
└── test
    ├── data  数据库文件夹
    │   └── mysql
    ├── docker-compose.yml docker-compose配置文件
    ├── htdocs 网站文件夹
    │   ├── index.html
    │   └── index.php
    ├── log 日志文件
    │   └── nginx
    ├── mysql mysql构建文件
    │   └── Dockerfile
    ├── nginx nginx构建文件
    │   ├── Dockerfile
    │   ├── conf.d
    │   │   └── default.conf
    │   └── nginx.conf
    └── php php构建文件
        └── Dockerfile

mysql 独立部署

mysql目录下的Dockerfile文件只有一行FROM mysql:5.6，也就是直接使用mysql官方镜像5.6，然后使用命令
docker build -t phpenv/mysql mysql
构建自己的镜像phpenv/mysql。 
使用命令
docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
启动镜像，将容器的3306端口绑定到本机的3306端口，其中参数-v后代表使用~/Docker/test/data/mysql挂在到镜像的/var/lib/mysql，也就是替代源镜像的数据库文件目录，让数据库文件目录暴露在本机上，做到数据库内容的持久化。MYSQL_ROOT_PASSWORD为设置mysql的一个root密码。
运行结果
~/Docker/test docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
2016-12-27 15:06:49 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
2016-12-27 15:06:49 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
2016-12-27 15:06:49 1 [Note] Plugin 'FEDERATED' is disabled.
2016-12-27 15:06:49 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
2016-12-27 15:06:49 1 [Note] InnoDB: The InnoDB memory heap is disabled
2016-12-27 15:06:49 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
2016-12-27 15:06:49 1 [Note] InnoDB: Memory barrier is not used
2016-12-27 15:06:49 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
2016-12-27 15:06:49 1 [Note] InnoDB: Using Linux native AIO
2016-12-27 15:06:49 1 [Note] InnoDB: Using CPU crc32 instructions
2016-12-27 15:06:49 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
2016-12-27 15:06:49 1 [Note] InnoDB: Completed initialization of buffer pool
2016-12-27 15:06:49 1 [Note] InnoDB: Highest supported file format is Barracuda.
2016-12-27 15:06:49 1 [Note] InnoDB: 128 rollback segment(s) are active.
2016-12-27 15:06:49 1 [Note] InnoDB: Waiting for purge to start
2016-12-27 15:06:49 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626027
2016-12-27 15:06:49 1 [Note] Server hostname (bind-address): '*'; port: 3306
2016-12-27 15:06:49 1 [Note] IPv6 is available.
2016-12-27 15:06:49 1 [Note]   - '::' resolves to '::';
2016-12-27 15:06:49 1 [Note] Server socket created on IP: '::'.
2016-12-27 15:06:49 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
2016-12-27 15:06:49 1 [Note] Event Scheduler: Loaded 0 events
2016-12-27 15:06:49 1 [Note] mysqld: ready for connections.
Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
使用DBeaver连接后 

查看一下当前~/Docker/test/data/mysql数据库目录下的文件
~/Docker/test/data/mysql  ls
auto.cnf           ib_logfile0        ib_logfile1        ibdata1            mysql              performance_schema
新建一个库docker_test后~/Docker/test/data/mysql数据库目录下的文件
~/Docker/test/data/mysql ls
auto.cnf           docker_test        ib_logfile0        ib_logfile1        ibdata1            mysql              performance_schema
可以发现数据库已经创建好了，也如下图 

为了验证数据库数据的持久型，我们先停止当前运行的container并产出它，然后从镜像启动一个新的container，如命令
~/Docker ⮀ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
970dec0f7de9        phpenv/mysql        "docker-entrypoint.sh"   30 minutes ago      Up 30 minutes       0.0.0.0:3306->3306/tcp   berserk_brown
~/Docker ⮀ docker stop 970dec0f7de9
970dec0f7de9
~/Docker ⮀ docker rm 970dec0f7de9
970dec0f7de9
~/Docker ⮀ docker ps -a
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                      PORTS               NAMES
c82c830770bc        supervisord:latest   "/usr/bin/supervisord"   35 hours ago        Exited (0) 32 minutes ago                       supervisord
~/Docker ⮀ docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
2016-12-27 15:38:04 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
2016-12-27 15:38:04 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
2016-12-27 15:38:04 1 [Note] Plugin 'FEDERATED' is disabled.
2016-12-27 15:38:04 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
2016-12-27 15:38:04 1 [Note] InnoDB: The InnoDB memory heap is disabled
2016-12-27 15:38:04 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
2016-12-27 15:38:04 1 [Note] InnoDB: Memory barrier is not used
2016-12-27 15:38:04 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
2016-12-27 15:38:04 1 [Note] InnoDB: Using Linux native AIO
2016-12-27 15:38:04 1 [Note] InnoDB: Using CPU crc32 instructions
2016-12-27 15:38:04 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
2016-12-27 15:38:04 1 [Note] InnoDB: Completed initialization of buffer pool
2016-12-27 15:38:04 1 [Note] InnoDB: Highest supported file format is Barracuda.
2016-12-27 15:38:04 1 [Note] InnoDB: 128 rollback segment(s) are active.
2016-12-27 15:38:04 1 [Note] InnoDB: Waiting for purge to start
2016-12-27 15:38:04 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626037
2016-12-27 15:38:04 1 [Note] Server hostname (bind-address): '*'; port: 3306
2016-12-27 15:38:04 1 [Note] IPv6 is available.
2016-12-27 15:38:04 1 [Note]   - '::' resolves to '::';
2016-12-27 15:38:04 1 [Note] Server socket created on IP: '::'.
2016-12-27 15:38:04 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
2016-12-27 15:38:04 1 [Note] Event Scheduler: Loaded 0 events
2016-12-27 15:38:04 1 [Note] mysqld: ready for connections.
Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
再次连接数据库验证，发现刚才新建的库docker_test还在，数据库文件持久型保存了。
docker-compose 中mysql配置
待完善
docker-compose 中nginx部署
nginx在构建的时候要替换两个配置文件，Dockfile
FROM nginx:1.10.2

ADD  nginx.conf      /etc/nginx/nginx.conf
ADD  conf.d/*    /etc/nginx/conf.d/
挂载文件在docker-compose里进行定义。
待完善
docker-compose 中php配置
php什么也不做，只通过Dockfile
FROM php:5.6-fpm
来构建
待完善
docker-compose 构建

docker-compose文件
nginx:
    build: ./nginx
    ports:
      - "40080:80"
    links:
      - "php"
    volumes:
      - ~/Docker/test/htdocs:/usr/share/nginx/html

php:
    build: ./php
    ports:
      - "49000:9000"
    links:
      - "mysql"
    volumes:
      - ~/Docker/test/htdocs:/var/www/html

mysql:
    build: ./mysql
    ports:
      - "43306:3306"
    volumes:
      - ~/Docker/test/data/mysql:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: 123456
记录一下，首先docker-compse是用来集合构建多个镜像的工具，这里我们集合了nginx，php，mysql来搭建一个php的测试环境，在文件中，有一个links参数，是用来连接其他实例，让多个实例之间可以进行通信。
这里有整合文件的下载链接,下载后，将文件放在用户根目录下，命令行执行docker-compose up，结果
~/Docker/test ⮀ docker-compose up
Building mysql
Step 1 : FROM mysql:5.6
---> e1406e1f7c42
Successfully built e1406e1f7c42
WARNING: Image for service mysql was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building php
Step 1 : FROM php:5.6-fpm
5.6-fpm: Pulling from library/php
75a822cd7888: Already exists
e4d8a4e038be: Pull complete
81d4d961577a: Pull complete
54283fea14a4: Pull complete
a1b82ddb6e57: Pull complete
fe532c795718: Pull complete
f02389f3f13e: Pull complete
5777f6cf03c5: Pull complete
24b45111f193: Pull complete
Digest: sha256:022410892774f45ebd39bdb4df39a4a72e6ae5db96a31ee83e7eb25382cd2491
Status: Downloaded newer image for php:5.6-fpm
---> 55423bcf0cfc
Successfully built 55423bcf0cfc
WARNING: Image for service php was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building nginx
Step 1 : FROM nginx:1.10.2
---> c2d83d8cde8d
Step 2 : ADD nginx.conf /etc/nginx/nginx.conf
---> e45c0dceafb9
Removing intermediate container ca538d0f2fd1
Step 3 : ADD conf.d/* /etc/nginx/conf.d/
---> bf0d37221331
Removing intermediate container ebaa3b27453a
Successfully built bf0d37221331
WARNING: Image for service nginx was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating test_mysql_1
Creating test_php_1
Creating test_nginx_1
Attaching to test_mysql_1, test_php_1, test_nginx_1
mysql_1  | 2016-12-28 07:29:43 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
mysql_1  | 2016-12-28 07:29:43 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
mysql_1  | 2016-12-28 07:29:43 1 [Note] Plugin 'FEDERATED' is disabled.
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: The InnoDB memory heap is disabled
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Memory barrier is not used
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using Linux native AIO
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using CPU crc32 instructions
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Completed initialization of buffer pool
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Highest supported file format is Barracuda.
php_1    | [28-Dec-2016 07:29:43] NOTICE: fpm is running, pid 1
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: 128 rollback segment(s) are active.
php_1    | [28-Dec-2016 07:29:43] NOTICE: ready to handle connections
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Waiting for purge to start
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626263
mysql_1  | 2016-12-28 07:29:43 1 [Note] Server hostname (bind-address): '*'; port: 3306
mysql_1  | 2016-12-28 07:29:43 1 [Note] IPv6 is available.
mysql_1  | 2016-12-28 07:29:43 1 [Note]   - '::' resolves to '::';
mysql_1  | 2016-12-28 07:29:43 1 [Note] Server socket created on IP: '::'.
mysql_1  | 2016-12-28 07:29:43 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
mysql_1  | 2016-12-28 07:29:43 1 [Note] Event Scheduler: Loaded 0 events
mysql_1  | 2016-12-28 07:29:43 1 [Note] mysqld: ready for connections.
mysql_1  | Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
访问一下 http://localhost:40080/index.php ，正常的话，如下图

启动一个真实的代码
下面的代码是今年网络安全周的一个手机在线答题系统，代码很挫，大牛误笑
源码在这里。
将目录直接放在~/Docker/test/htdocs下面，然后在test目录下执行docker-compose up，正常情况下，就会跑起来上面的容器，然后按照代码的README将数据库部署就可以运行了。

参考链接


Docker 从入门到实践
第一本Docker书
如何进入一个正在运行的Container
Docker在PHP项目开发环境中的应用

原文链接： 
http://dengnanyi.com/2016/12/24/2016_12/docker-learn-3/ 









在我的小 rmbp 256G的硬盘里，实在是装不下100多个G的虚拟机了，所以想把一些东西迁移到这两年很火的Docker下，Docker以前也有过一两次，只是按着别人给的用法用的，具体的一些细节并没有深入，和git一样，这么牛掰的东西怎么能不好好学一些呢？


Docker和虚拟机的区别

Docker是一种容器，虚拟机是一种管理程序虚拟机化(hypervisor virtualization,HV)。管理程序虚拟化通过中间层将一台或者多台独立的机器虚拟运行在物理硬件之上，而容器(比如Docker)则是直接运行在操作系统内核之上的用户空间。由于容器是运行在操作系统上的，所以只能运行底层和宿主机相同或者类似的操作系统，比如说在Ubuntu下可以在容器里运行Centos，却不能运行Windows。

目前Windows上的Docker可以跑Linux的Docker容器，是因为底下跑了Linux的VM，但是马上就可以支持Windows Server 2016了，如链接[Introducing the Technical Preview of Docker Engine for Windows Server 2016](http://Introducing the Technical Preview of Docker Engine for Windows Server 2016)。

容器的优点：

一次save，到处运行。
启动速度快，消耗资源少。Docker与虚拟机性能比较

容器缺点：

资源隔离方面不如虚拟机。
安全性问题，“权限隔离”做的不够好，只要有Docker的命令权限，就可以操作所有的Docker实例。

Docker的目标


提供一个简单、轻量的建模方式。
职责的逻辑分离，防止开发环境和部署环境不一致，导致出现“开发时一切正常，肯定是运维问题”的情况。
快速、高效的开发生命周期。

Docker的核心组件


Docker客户端和服务器
Docker是一个C/S架构的程序，Docker客户端需要向Docker服务器发出请求，服务器完成请求后返回信息。一个本地Docker客户端可以连接远端的Docker服务器进行操作，如下图。

Docker镜像
镜像是构建Docker世界的基石。用户基于镜像来维护自己的容器。Docker镜像是Docker容器运行时的只读模板，每一个镜像由一系列的层 (layers) 组成。Docker使用 UnionFS来将这些层联合到单独的镜像中。UnionFS允许独立文件系统中的文件和文件夹(称之为分支)被透明覆盖，形成一个单独连贯的文件系统。正因为有了这些层的存在，Docker是如此的轻量。当你改变了一个Docker镜像，比如升级到某个程序到新的版本，一个新的层会被创建。因此，不用替换整个原先的镜像或者重新建立(在使用虚拟机的时候你可能会这么做)，只是一个新的层被添加或升级了。现在你不用重新发布整个镜像，只需要升级，层使得分发Docker镜像变得简单和快速。
Docker仓库(Registry)
Docker使用Registry来保存用户构建的镜像，就像苹果的apple store。Registry分为私有和公有两种，Docker公司自己运营的Registry叫做Docker Hub。
Docker容器
Docker可以帮你构建和部署容器，用户只需要把自己的应用程序或服务打包放进容器即可。每一个Docker容器都是从Docker镜像创建的。Docker容器可以运行、开始、停止、移动和删除。每一个Docker容器都是独立和安全的应用平台，Docker容器是Docker的运行部分。
Docker的技术组件
Docker可以被安装在x64架构，内核3.10以上的linux系主机、win10以上windows和OS X 10.10.3且2010年以后的Mac上。在2013年Docker刚发布的时候，它是一款基于LXC的开源容器管理引擎。把LXC复杂的容器创建与使用方式简化为Docker自己的一套命令体系。 随着Docker的不断发展，它开始有了更为远大的目标，那就是反向定义容器的实现标准，将底层实现都抽象化到Libcontainer的接口。这就意味 着，底层容器的实现方式变成了一种可变的方案，无论是使用namespace、cgroups技术抑或是使用systemd等其他方案，只要实现了 Libcontainer定义的一组接口，Docker都可以运行。

安装

安装方法都很简单，值得注意的是当前Docker版本的安装需求，比如现在Linux下安装的需求就上x64架构，内核3.10以上。
Mac下安装方法，直接在官网上下载docker app，安装即可。 
Linux下安装方法，Linux下最简单的安装方法就是apt和yum包管理工具进行安装了。 
Windows下安装方法
还有一个比较好用的安装脚本，这个脚本只支持在lsb、debian、fedora、oracle、centos、redhat、os这几个发行版中使用。
在安装结束后，可以使用docker info命令来查看Docker是否装好了。Mac下的docker info结果：
~  docker info
Containers: 0
Running: 0
Paused: 0
Stopped: 0
Images: 0
Server Version: 1.12.1
Storage Driver: aufs
Root Dir: /var/lib/docker/aufs
Backing Filesystem: extfs
Dirs: 0
Dirperm1 Supported: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
Plugins:
Volume: local
Network: null bridge host overlay
Swarm: inactive
Runtimes: runc
Default Runtime: runc
Security Options: seccomp
Kernel Version: 4.4.20-moby
Operating System: Alpine Linux v3.4
OSType: linux
Architecture: x86_64
CPUs: 4
Total Memory: 1.952 GiB
Name: moby
ID: FSZQ:ZPKN:NEUW:55GH:Q33R:7L7M:5FLN:GW6E:CLHJ:NO66:WL4K:A3L5
Docker Root Dir: /var/lib/docker
Debug Mode (client): false
Debug Mode (server): true
File Descriptors: 34
Goroutines: 98
System Time: 2016-09-29T01:48:55.851895948Z
EventsListeners: 2
Registry: https://index.docker.io/v1/
Insecure Registries:
127.0.0.0/8
Mac装好后如下图的样子，基本功能都已经在菜单上了。

同时Mac还有一个GUI界面Kitmatic，目前还是beta版，但是用起来还是很不错的。

各种各样的image看起来很好看。
使用入门

先把Docker的命令行打印出来。
~  docker --help
Usage: docker [OPTIONS] COMMAND [arg...]
      docker [ --help | -v | --version ]

A self-sufficient runtime for containers.

Options:

 --config=~/.docker              Location of client config files
 -D, --debug                     Enable debug mode
 -H, --host=[]                   Daemon socket(s) to connect to
 -h, --help                      Print usage
 -l, --log-level=info            Set the logging level
 --tls                           Use TLS; implied by --tlsverify
 --tlscacert=~/.docker/ca.pem    Trust certs signed only by this CA
 --tlscert=~/.docker/cert.pem    Path to TLS certificate file
 --tlskey=~/.docker/key.pem      Path to TLS key file
 --tlsverify                     Use TLS and verify the remote
 -v, --version                   Print version information and quit

Commands:
   attach    Attach to a running container
   build     Build an image from a Dockerfile
   commit    Create a new image from a container's changes
   cp        Copy files/folders between a container and the local filesystem
   create    Create a new container
   diff      Inspect changes on a container's filesystem
   events    Get real time events from the server
   exec      Run a command in a running container
   export    Export a container's filesystem as a tar archive
   history   Show the history of an image
   images    List images
   import    Import the contents from a tarball to create a filesystem image
   info      Display system-wide information
   inspect   Return low-level information on a container, image or task
   kill      Kill one or more running containers
   load      Load an image from a tar archive or STDIN
   login     Log in to a Docker registry.
   logout    Log out from a Docker registry.
   logs      Fetch the logs of a container
   network   Manage Docker networks
   node      Manage Docker Swarm nodes
   pause     Pause all processes within one or more containers
   port      List port mappings or a specific mapping for the container
   ps        List containers
   pull      Pull an image or a repository from a registry
   push      Push an image or a repository to a registry
   rename    Rename a container
   restart   Restart a container
   rm        Remove one or more containers
   rmi       Remove one or more images
   run       Run a command in a new container
   save      Save one or more images to a tar archive (streamed to STDOUT by default)
   search    Search the Docker Hub for images
   service   Manage Docker services
   start     Start one or more stopped containers
   stats     Display a live stream of container(s) resource usage statistics
   stop      Stop one or more running containers
   swarm     Manage Docker Swarm
   tag       Tag an image into a repository
   top       Display the running processes of a container
   unpause   Unpause all processes within one or more containers
   update    Update configuration of one or more containers
   version   Show the Docker version information
   volume    Manage Docker volumes
   wait      Block until a container stops, then print its exit code

Run 'docker COMMAND --help' for more information on a command.'
我相信能用Docker都是的大神，就不翻译了。
在安装好以后来运行一个最简单的hello world吧。
docker run hello-world
所见即所得，如图。

在运行docker run的时候，可以看到打印出了Hello from Docker!，首先docker在本地去检查了是否有一个叫做hello-world的镜像，在这里，我们刚装好的docker里必然是没有的，所以docker就去Docker Hub上找这个镜像，找到以后下载下来，run。读一下这个helloworld的输出，可以docker run -it ubuntu bash来运行一个ubuntu。来试一试
# -i 代表保持STDIN开启，-t 代表为容器分配一个tty。
docker run -it ubuntu bash
运行以后，在docker hub里下载好ubuntu镜像后，docker构造好容器启动，就可以和正常的shell一样的进行操作了。

更多内容尽在docker-learn1。
参考链接


[Introducing the Technical Preview of Docker Engine for Windows Server 2016](http://Introducing the Technical Preview of Docker Engine for Windows Server 2016)
Docker与虚拟机性能比较
第一本Docker书
5分钟弄懂Docker
一次“奇幻”的Docker libcontainer代码阅读之旅
Docker背后的容器管理—Libcontainer深度解析
LXC：Linux 容器工具
阿里云Registry加速器
docker使用阿里云Docker镜像库加速
非常好的一篇Docker教程，比较全面
知乎_Docker的应用场景在哪里
一个比较详细的命令用法

原文链接：http://dengnanyi.com/2016/09/28/docker-learn-0/ 









在上文Docker – 系统整洁之道 – 0中已经对Docker是什么，安装Docker以及怎么运行一个简单的容器有了初步了解，这篇文章介绍Docker的一些命令和Docker镜像的使用及操作。


一些Docker命令

Docker的命令按照使用一个容器的顺序进行。
docker info 查看Docker的信息
~  docker info
Containers: 0
Running: 0
Paused: 0
Stopped: 0
Images: 8
Server Version: 1.12.1
Storage Driver: aufs
Root Dir: /var/lib/docker/aufs
...
能查看到docker信息，说明docker是安装好的。
docker run 运行一个容器
~  docker run -it ubuntu
root@8eac2e6cf194:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
root@8eac2e6cf194:/#
由于在上文中已经运行过一次该条命令，所以ubuntu的镜像已经下载到了本地，此次运行就可以使用该镜像产生一个容器，在容器启动后，上过-it获取到命令行，运行命令ls。
使用–name标志可以给容器定义一个名字，如 
docker run –name this_is_first_ubunt_container -it ubuntu 
就会创建一个名字叫做this_is_first_ubunt_container的ubuntu的容器。名字只能使用大小写字母，数字，下划线，原点和横线，即[a-zA-Z0-9_.-]。

关于docker run的帮助可以使用docker run --help获取。

docker ps 列出所有的容器
~  docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
8eac2e6cf194        ubuntu              "/bin/bash"         5 minutes ago       Up 5 minutes                            modest_davinci
使用docker ps命令可以看到当前正在运行的容器有哪些，并给出了一些相应的属性。给命令增加参数-a就可以获取当前所有的容器，包括已经停止的，如下。
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                          PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            About a minute ago   Exited (0) About a minute ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         4 minutes ago        Up 4 minutes                                        modest_davinci
docker ps -n x，显示最后x个容器，不管容器正在运行还是停止。
docker start 重新启动已经停止的容器
docker start 
docker start this_is_first_ubunt_container
docker attatch 附着容器
docker attach this_is_first_ubunt_container
docker stop 停止一个容器
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            4 minutes ago       Exited (0) 4 minutes ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         8 minutes ago       Up 8 minutes                                   modest_davinci
~  docker stop 8eac2e6cf194
8eac2e6cf194
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            4 minutes ago       Exited (0) 4 minutes ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         8 minutes ago       Exited (0) 5 seconds ago                       modest_davinci
前几个命令整体练习
创建一个有名字的container，停止它，启动它。
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                  PORTS               NAMES
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago          Exited (0) 2 days ago                       tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago          Exited (0) 4 days ago                       
~ docker run --name this_is_first_ubunt_container -it ubuntu
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
894b1f0fa739        ubuntu              "/bin/bash"         21 seconds ago      Exited (0) 14 seconds ago                       this_is_first_ubunt_container
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago          Exited (0) 2 days ago                           tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago          Exited (0) 4 days ago                           small_roentgen
~ docker start 894b1f0fa739
894b1f0fa739
~ docker attach 894b1f0fa739
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                     PORTS               NAMES
894b1f0fa739        ubuntu              "/bin/bash"         About a minute ago   Exited (0) 8 seconds ago                       this_is_first_ubunt_container
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago           Exited (0) 2 days ago                          tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago           Exited (0) 4 days ago                          small_roentgen
~ docker start this_is_first_ubunt_container
this_is_first_ubunt_container
~ docker attach this_is_first_ubunt_container
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
守护式容器
上面创建的ubuntu是交互式运行的容器(interactive container)，也可以创建一个长期运行的容器–守护式容器(daemonized container)。
~ docker run --name daemon_ubuntu -d ubuntu /bin/sh -c "while true;do echo hello world;sleep 1;done"
e56ae29adaf1d27cf49e05bccda5a7214be458fecc2afb0ff7721f16af8e044c
~ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES
e56ae29adaf1        ubuntu              "/bin/sh -c 'while tr"   About a minute ago   Up About a minute                       daemon_ubuntu
docker logs 容器日志
~ docker logs daemon_ubuntu
hello world
hello world
hello world
hello world
...

~ docker logs --tail 0 -f daemon_ubuntu
hello world
hello world
hello world
hello world
hello world
docker top 容器进程
~ docker top daemon_ubuntu
PID                 USER                TIME                COMMAND
2792                root                0:00                /bin/sh -c while true;do echo hello world;sleep 1;done
3264                root                0:00                sleep 1
容器内运行进程
~ docker exec -d daemon_ubuntu touch /etc/new_config_file
~ docker exec -it daemon_ubuntu /bin/sh
# ls -l /etc | grep new
-rw-r--r-- 1 root root       0 Oct 13 02:21 new_config_file
docker inspect 容器详细信息
~  docker inspect daemon_ubuntu
# 获取容器运行状态
~  docker inspect --format='{{.State.Running}}' daemon_ubuntu
# 查看容器IP地址
~ docker inspect --format='{{.NetworkSettings.IPAddress}}' daemon_ubuntu
自动重启容器
docker run –restart=always –name daemon_ubuntu -d ubuntu /bin/sh -c “while true;do echo hello world;sleep 1;done”
–restart=always 无论容器的退出代码为何，都自动重启。 
–restart=on-failure 当容器退出代码不为0时，自动重启。 
–restart=on-failure:5 重启5次。
docker rm 删除容器

运行中的Docker容器是无法删除的。

# 删除所有容器
docker rm `docker ps -a -q`
Docker 镜像
docker images

Linux  /var/lib/docker 
  Mac $HOME/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/Docker.qcow2

docker pull ubuntu:16.10 获取ubuntu仓库中tag为16.10的镜像。
docker pull -a ubuntu 获取ubuntu仓库中所有镜像。
docker images ubuntu 列出本地所有ubuntu仓库的镜像。
docker run 的时候如果没有指定镜像的版本，则拉取最新版本进行创建。
Docker Hub 中仓库分为两种，一种是用户仓库（user repository），这种是用户创建使用的的，命名方式为username/repositoryname，意义为用户名/仓库名；一种是顶层仓库（top－repository），由docker内部人员管理。
docker search 查找Docker Hub上公用可用镜像。

获取镜像时，格式其实可以看做 用户/仓库:标签。 由于很多仓库为官网所有，所有很多都变成了 仓库:标签，如上面写的 ubuntu:16.10，ubutnu仓库的tag为16.10的镜像。

构建镜像
docker commit 
docker build 和 Dockerfile文件

一般来说，我们不是真正「创建」了一个镜像，而是基于一个已有的镜像，构建了一个新的镜像。

参考链接


Docker 从入门到实践
第一本Docker书
一个比较详细的命令用法
 






下面是一个百度空间的：
http://hi.baidu.com/jensenliao

博客园的一篇博客：theONE模拟器简介（主要讲述，软件配置，软件结构）
http://www.cnblogs.com/dreamfactory/archive/2012/07/27/2612215.html

博客园，theONE模拟器简介，图表脚本生成，路由修改
http://www.cnblogs.com/jcleung/archive/2011/05/23/2054713.html

csdn，theONE消息转发流程分析
http://blog.csdn.net/u010816631/article/details/8984596


QQ交流群：


DTN--(ONE)  群   号：9859819
DTN            群号：17384685
















// 为包含指针的关联容器指定比较类型.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <set>
#include <string> 
#include <iostream>

using namespace  std;


struct  StringPtrLess:
	public binary_function<const string*, const string*, bool>
	{
		bool operator()(const string *ps1, const string *ps2) const
		{
			return *ps1 < *ps2;
		}
	};


typedef set<string*, StringPtrLess> StringPtrSet;
StringPtrSet ssp;

int main()
{

	
	

	ssp.insert(new string("apple"));
	ssp.insert(new string("toy"));
	ssp.insert(new string("cat"));


	for (StringPtrSet::const_iterator i = ssp.begin();i != ssp.end();++i)
	{
		cout<<(**i)<<endl;
	}


	getchar();
	return 0;


}

 








文章大纲flask通用项目结构flask 简介主体代码逻辑flask 跨域问题的处理flask 日志flask 微服务Flask-RESTful启动服务命令

flask通用项目结构
| - projectName
	| - app  //程序包
		| - templates //jinjia2模板
		|- static //css,js 图片等静态文件
		| - main  //py程序包 ，可以有多个这种包，每个对应不同的功能
			| - __init__.py
			|- errors.py
			|- forms.py
			|- views.py
		|- __init__.py
		|- email.py //邮件处理程序
		|- models.py //数据库模型
	|- migrations //数据迁移文件夹
	| - tests  //单元测试
		|- __init__.py
		|- test*.py //单元测试程序，可以包含多个对应不同的功能点测试
	|- venv  //虚拟环境
	|- requirements.txt //列出了所有依赖包以及版本号，方便在其他位置生成相同的虚拟环境以及依赖
	|- config.py //全局配置文件，配置全局变量
	|- manage.py //启动程序
	

flask 简介
http://docs.jinkan.org/docs/flask/quickstart.html#a-minimal-application
主体代码逻辑
一个最简单的查询服务样例

#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {shiter@live.cn}
@Software:   PyCharm
@File    : 
@Time    :   2019/4/25 14:57
@Desc    :

'''
#-------------------------------------------------------------------------------

import json
import random
import logging

from flask import Flask

from flask_sqlalchemy import SQLAlchemy
from flask import request,Response
from flask_cors import CORS


log_file_str = 'shuanghe_demo.log'
log_level = logging.INFO
app = Flask(__name__)
CORS(app)

app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql+pymysql://username:password@ip:3306/database'
app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True

db = SQLAlchemy(app)

english_chinese_dict = {'id':'身份证号',
'name':'姓名',
'sex':'性别',
'age':'年龄',
}


class neihuang_underwriting_search_result(db.Model):
    __tablename__ = 'neihuang_underwriting_search_result'

    id = db.Column(db.String(32),primary_key=True)
    name = db.Column(db.String(32))
    sex = db.Column(db.String(32))
    age = db.Column(db.String(32))
    


    def __repr__(self):
        return '<neihuang_underwriting_search_result %r>' % self.id

def convert_to_dict(obj):
    '''把Object对象转换成Dict对象'''
    result_dict = {}
    result_dict.update(obj.__dict__)
    result_dict.pop('_sa_instance_state', None)
    result_dict = random_value_of_labels(result_dict)
    return result_dict




def get_id_result(id):
    result = neihuang_underwriting_search_result.query.filter_by(id=id).one()

    result_dict = convert_to_dict(result)
    # result_list = database_name_conversion(result_dict)
    result_json = json.dumps(result_dict,ensure_ascii=False)
    return result_json


@app.route('/api/search',methods=['POST','GET'])
def search():

    #result_json  = get_id_result(id)
    if request.method == 'GET':
        user_id = json.loads(''.join(x for x in request.args))['id']
        print(user_id)
        app.logger.info(user_id + ' is search ING .......')
        result_json  = get_id_result(user_id)

    return Response(result_json)


if __name__ == '__main__':

    handler = logging.FileHandler(log_file_str, encoding='UTF-8')
    handler.setLevel(log_level)
    logging_format = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(filename)s - %(funcName)s - %(lineno)s - %(message)s')
    handler.setFormatter(logging_format)
    app.logger.addHandler(handler)


    app.run(debug=True, host='0.0.0.0', port=18081)
    #放在这里是不对的
    # CORS(app, supports_credentials=True)

flask 跨域问题的处理
在处理跨域问题时候，应该把下列代码弄成全局的，也就是放
app = Flask(name)
cors = CORS(app)
否则跨域问题依然存在，报错信息为：
Access to XMLHttpRequest at ‘-----’ from origin ‘http://localhost:63342’ has been blocked by CORS policy: Response to preflight request doesn’t pass access control check: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.
flask 日志
https://blog.csdn.net/iszhenyu/article/details/56846551
flask 微服务Flask-RESTful
写完了发现
https://flask-restful.readthedocs.io/en/latest/
启动服务命令
参考：https://www.cnblogs.com/zzyoucan/p/7764590.html
nohup command > myout.file 2>&1 &







 
 
// 读取jpg图像像素rgb值.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <fstream>
#include <string>
#include <windows.h>
#include <gdiplus.h>
#pragma comment(lib, "gdiplus.lib")

using namespace std;
using namespace Gdiplus;


int main()
{
	GdiplusStartupInput gdiplusstartupinput;
	ULONG_PTR gdiplustoken;

	GdiplusStartup(&gdiplustoken, &gdiplusstartupinput, NULL);

	wstring infilename(L"1.jpg");
	string outfilename("color.txt");
	//读图片
	Bitmap* bmp = new Bitmap(infilename.c_str());
	UINT height = bmp->GetHeight();
	UINT width = bmp->GetWidth();
	cout << "width " << width << ", height " << height << endl;

	Color color;
	ofstream fout(outfilename.c_str());

	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
		{
			bmp->GetPixel(x, y, &color);
			fout << x << ";" << y << ";"
				<< (int)color.GetRed() << ";"
				<< (int)color.GetGreen() << ";"
				<< (int)color.GetBlue() << endl;
		}

		fout.close();

		delete bmp;
		GdiplusShutdown(gdiplustoken);
		return 0;
}
 
 
txt：
 







﻿﻿
One cut in grabcut（grabcut算法的非迭代实现？）
本文针对交互式图像分割中的图割算法，主要想翻译一篇英文文献。不足之处请大家指正。

    这是博主近期看到的效果最好，实现最简单，运算时间最短的交互式图割算法，而且由于是发明图割算法实验室原班人马的文章和代码，所以非常值得研究。
 
摘要
    该方法使用少量的辅助节点（这个辅助节点我没看出来代码在哪块提现的，还望高手指点）来实现高效率的分割，传统的基于梯度下降的方法的分割方法，如grabcut，可能会收敛到局部极值（在图像较大时），而实验结果表明，对于图像比较复杂的图像如果我们使用足够过的辅助节点也能得到较好的效果：一次分割时间大概一秒以内，在图割里面算很快的了。

论文的贡献如下：
1.提出了一整个简单的基于l1距离的appearance overlap（这个怎么翻译？），可以看成高级形式的一致性标号，提出了一种简单的图建立方法，避免将问题陷入np难，并且论文通过实验发现l1距离能够更好的分离颜色信息。

2.使用颜色索引（从代码中可以看出），作者使用一个grb三通道的像素值计算了一个索引，类似hash-code的东西，相同像素值的（grb）的hash-code算出来是一样的，可以作为一个相似的节点（也就是索引节点）。
 
3.简化的能量函数
 
 


利用种子点分割时候简化为下面形式：



下面是我写了一些注释的代码：（对原来部分代码做了修改，没改算法，改的输入输出）
配置好OpenCV就直接能用，效果非常好，甚至可以直接集成到app里面去。


//
//@inproceedings{iccv2013onecut,
//	title	= {Grabcut in One Cut},
//	author	= {Tang, Meng and Gorelick, Lena and Veksler, Olga and Boykov, Yuri},
//	booktitle={International Conference on Computer Vision},
//	month	= {December},
//	year	= {2013}}
//
//THIS SOFTWARE USES maxflow/min-cut CODE THAT WAS IMPLEMENTED BY VLADIMIR KOLMOGOROV,
//THAT CAN BE DOWNLOADED FROM http://vision.csd.uwo.ca/code/.
//PLEASE USE THE FOLLOWING CITATION:
//
//@ARTICLE{Boykov01anexperimental,
//    author = {Yuri Boykov and Vladimir Kolmogorov},
//    title = {An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision},
//    journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE},
//    year = {2001},
//    volume = {26},
//    pages = {359--374}}
//

//
//##################################################################
//
//  USAGE  INSTRUCTIONS
//
//	In the command line type:
//	
//	OneCut <imageFileName> [<beta> <numBinsPerChannel>]
//
//	Default values: beta= 0.1, numBinsPerChannel=64
//
//	Example: OneCut frida_small.jpg 0.1 64
//	or       OneCut frida_small.jpg 
//
//
//	Once the image is opened you can scribble with left and right
//	mouse buttons on the object and the background in the 
//	"Scribble Image" window. Once the scribbles are given you can 
//	segment the image.You can keep repeatedly adding scribbles and 
//	segmenting until the result is satisfactory.
//
//	Use the following Short Keys:
//		'q' - quit
//		's' - segment
//		'r' - reset (removes all strokes and clears all results)
//		'+' - increase brush stroke radius
//		'-' - decrease brush stroke radius
//		'right mouse button drug' - draw blue scribble
//		'left mouse button drug' - draw red scribble
//
//
#include <iostream> // for standard I/O
#include <string>   // for strings
#include <iomanip>  // for controlling float print precision 
#include <sstream>  // string to number conversion 

#include <opencv2/imgproc/imgproc.hpp>  // Gaussian Blur
#include <opencv2/core/core.hpp>        // Basic OpenCV structures (cv::Mat, Scalar)
#include <opencv2/highgui/highgui.hpp>  // OpenCV window I/O

#include "graph.h"
#include "ComputeTime.h"


using namespace std;
using namespace cv;


// images
Mat inputImg, showImg, binPerPixelImg, showEdgesImg, segMask, segShowImg;

// mask
Mat fgScribbleMask, bgScribbleMask;

// user clicked mouse buttons flags
bool rButtonDown = false;
bool lButtonDown = false;
int numUsedBins = 0;
float varianceSquared = 0;
int scribbleRadius = 5;//画笔半径


// default arguments
float bha_slope = 0.1f;
int numBinsPerChannel = 64;


const float INT32_CONST = 1000;
const float HARD_CONSTRAINT_CONST = 1000;


#define NEIGHBORHOOD_8_TYPE 1;
#define NEIGHBORHOOD_25_TYPE 2;

const int NEIGHBORHOOD = NEIGHBORHOOD_8_TYPE;


//************************************
// F u n c t i o n     d e c l a r a t i o n s 

// init all images/vars
int  init(char * imgFileName);

// clear everything before closing
void destroyAll();

// mouse listener
static void onMouse( int event, int x, int y, int, void* );

// set bin index for each image pixel, store it in binPerPixelImg
void getBinPerPixel(Mat & binPerPixelImg, Mat & inputImg, int numBinsPerChannel, int & numUsedBins);

// compute the variance of image edges between neighbors
void getEdgeVariance(Mat & inputImg, Mat & showEdgesImg, float & varianceSquared);

typedef Graph<int,int,int> GraphType;
GraphType *myGraph; 
	



//***********************************
// M a i n 

/*
    if( argc > 4 || argc < 2)
    {
     cout <<" Usage: seedsAndOverlap ImageToSegment [numBinsPerChannel bha_slope]" << endl;
     return -1;
    }
	if (argc >= 3)
	{
		// get the second arg
		String numBinsStr(argv[2]);

		// convert to int 
		numBinsPerChannel = atoi(numBinsStr.c_str());
	    cout << "Using " << numBinsPerChannel <<  " bins per channel " << endl; 
		if (argc >=4)
		{
			//get third argument
			String bhaSlopeStr(argv[3]);
			bha_slope = (float)atof(bhaSlopeStr.c_str());
			cout << "Using beta  = " << bha_slope << endl;
		}
		else
			cout << "Using default beta = " << bha_slope << endl; 
	}
	else
	{
		cout << "Using default " << numBinsPerChannel <<  " bins per channel " << endl; 
		cout << "Using default beta = " << bha_slope << endl; 
	}

	*/

int main(int argc, char *argv[])
{

	
	String image_name,numBinsStr,bhaSlopeStr;
	cout<<"input Parameters:"<<endl;
	cout<<"image name: ";
	cin>>image_name;
	cout<<endl<<"numBinsPerChannel: ";
	cin>>numBinsStr;
	cout<<endl<<"beta: ";
	cin>>bhaSlopeStr;

	// get img name parameter
	char * imgFileName = (char *)image_name.c_str();


	// convert to int 
	numBinsPerChannel = atoi(numBinsStr.c_str());
	cout << "Using " << numBinsPerChannel <<  " bins per channel " << endl; 

	bha_slope = (float)atof(bhaSlopeStr.c_str());
	cout << "Using beta  = " << bha_slope << endl;

	//cout << "Using default beta = " << bha_slope << endl; 


	ComputeTime ct_init;//计算代码运行时间的类
	ct_init.Begin();
	if (init(imgFileName)==-1)
	{
		cout <<  "Could not initialize" << endl ;
		return -1;
	}


	cout<<"初始化运行时间：  "<<ct_init.End()<<"ms"<<endl;



	    	                      
	
	// Wait for a keystroke in the window
    for (;;)
	{
		char key = waitKey(0);                          
		switch (key)
		{
			case 'q':
				cout << "goodbye" << endl;
				destroyAll();
				return 0;
			case '-':
				//缩小画笔直径
				if (scribbleRadius > 2)
					scribbleRadius --;
				cout << "current radius is " << scribbleRadius << endl;
				break;
			case '+':
				if (scribbleRadius < 100)
					scribbleRadius ++;
				cout << "current radius is " << scribbleRadius << endl;
				break;
			case 's':
			{
				ComputeTime ct;//计算代码运行时间的类
				ct.Begin();
				cout << "setting the hard constraints..." << endl;
				for(int i=0; i<inputImg.rows; i++)
				{
					for(int j=0; j<inputImg.cols; j++) 
					{
						// this is the node id for the current pixel
						GraphType::node_id currNodeId = i * inputImg.cols + j;
	
						// add hard constraints based on scribbles
						if (fgScribbleMask.at<uchar>(i,j) == 255)
							myGraph->add_tweights(currNodeId,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5),0);
						else if (bgScribbleMask.at<uchar>(i,j) == 255)
							myGraph->add_tweights(currNodeId,0,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5));
					}
				}
				cout << "maxflow..." << endl;
				int flow = myGraph -> maxflow();
				cout << "done maxflow..." << endl;

				// this is where we store the results
				segMask = 0;
				inputImg.copyTo(segShowImg);
				//inputImg.copyTo(showImg);

				// empty scribble masks are ready to record additional scribbles for additional hard constraints
				// to be used next time
				fgScribbleMask = 0;
				bgScribbleMask = 0;

				// copy the segmentation results on to the result images
				for (int i = 0; i<inputImg.rows * inputImg.cols; i++)
				{
					// if it is foreground - color blue
					if (myGraph->what_segment((GraphType::node_id)i ) == GraphType::SOURCE)
					{
						segMask.at<uchar>(i/inputImg.cols, i%inputImg.cols) = 255;
						//(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[2] =  200;
					}
					// if it is background - color red
					else
					{
						segMask.at<uchar>(i/inputImg.cols, i%inputImg.cols) = 0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[0] =  0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[1] =  0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[2] =  0;
					}
				}

				imshow("Segmentation Mask", segMask);
				imshow("Segmentation Image", segShowImg);

				cout<<"运行时间：  "<<ct.End()<<"ms"<<endl;
				

				imwrite("seg_result.bmp",segShowImg);
				waitKey(0);
				break;

			}
			case 'r':
			{
				cout << "resetting" << endl;
				destroyAll();
				if (init(imgFileName)==-1)
				{
					cout <<  "could not initialize" << std::endl ;
					return -1;
				}
				break;
			}
		}
	}

	
    return 0;
}

// mouse listener
static void onMouse( int event, int x, int y, int, void* )
{
	//cout << "On Mouse: (" << x << "," << y << ")" <<endl;
	

	if (event == CV_EVENT_LBUTTONDOWN)
    {
		lButtonDown = true;
        
    }
    else if (event == CV_EVENT_RBUTTONDOWN)
    {
		rButtonDown = true;
		
    }
	else if (event == CV_EVENT_LBUTTONUP)
	{
		lButtonDown = false;
	}
	else if (event == CV_EVENT_RBUTTONUP)
	{
		rButtonDown = false;
	}
    else if (event == CV_EVENT_MOUSEMOVE)
	{
		if (rButtonDown)
		{
			// scribble the background

			circle(bgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(0,0,255),-1);

		}
		else if (lButtonDown)
		{
			// scribble the foreground

			circle(fgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(255,0,0),-1);

			//fgScribbleMask.at<char>(y,x)=(char)255;
			// set variables using mask
			//showImg.setTo(redColorElement,fgScribbleMask);

			//showImg.at<Vec3b>(y,x)[0] = 0;
			//showImg.at<Vec3b>(y,x)[1] = 0;
			//showImg.at<Vec3b>(y,x)[2] = 255;
		}

	}
	
	
	imshow("Scribble Image", showImg);
	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);
}

// clear everything before closing
void destroyAll()
{
	// destroy all windows
	destroyWindow("Input Image");
	destroyWindow("Scribble Image");
	destroyWindow("Bin Per Pixel");
	destroyWindow("Edges");
	destroyWindow("bg mask");
	destroyWindow("fg mask");
	destroyWindow("Segmentation Mask");
	destroyWindow("Segmentation Image");

	// clear all data
	fgScribbleMask.release();
	bgScribbleMask.release();
	inputImg.release();
	showImg.release();
	showEdgesImg.release();
	binPerPixelImg.release();
	segMask.release();
	segShowImg.release();

	delete myGraph;
	

}

// init all images/vars
int init(char * imgFileName)
{
	// Read the file
    inputImg = imread(imgFileName, CV_LOAD_IMAGE_COLOR);   
	showImg = inputImg.clone();
	segShowImg = inputImg.clone();

	

	// Check for invalid input
    if(!inputImg.data )                              
    {
        cout <<  "Could not open or find the image: " << imgFileName << std::endl ;
        return -1;
    }

	// this is the mask to keep the user scribbles
	fgScribbleMask.create(2,inputImg.size,CV_8UC1);
	fgScribbleMask = 0;
	bgScribbleMask.create(2,inputImg.size,CV_8UC1);
	bgScribbleMask = 0;
	segMask.create(2,inputImg.size,CV_8UC1);
	segMask = 0;
	showEdgesImg.create(2, inputImg.size, CV_32FC1);
	showEdgesImg = 0;
	binPerPixelImg.create(2, inputImg.size,CV_32F);


	// get bin index for each image pixel, store it in binPerPixelImg
	getBinPerPixel(binPerPixelImg, inputImg, numBinsPerChannel, numUsedBins);

	// compute the variance of image edges between neighbors
	getEdgeVariance(inputImg, showEdgesImg, varianceSquared);

	

	// Create a window for display.
    namedWindow( "Input Image", CV_WINDOW_AUTOSIZE );
	namedWindow( "Scribble Image", CV_WINDOW_AUTOSIZE);
	namedWindow("Bin Per Pixel", CV_WINDOW_AUTOSIZE );
	namedWindow("Edges", CV_WINDOW_AUTOSIZE );
	namedWindow("Segmentation Mask",CV_WINDOW_AUTOSIZE);
	namedWindow("Segmentation Image",CV_WINDOW_AUTOSIZE);
	namedWindow( "fg mask", CV_WINDOW_AUTOSIZE );
	namedWindow( "bg mask", CV_WINDOW_AUTOSIZE );


	//namedWindow("Input Image", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO | CV_GUI_EXPANDED);


	// Show our image inside it.
    imshow( "Input Image", inputImg );                        
	imshow( "Scribble Image", showImg );  
	imshow("Segmentation Mask", segMask);
	imshow("Segmentation Image", segShowImg);
	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);
	

	moveWindow("Scribble Image", 1,1);
	moveWindow("Input Image", inputImg.cols + 50,1);
	moveWindow("Bin Per Pixel", 2*(inputImg.cols + 50),1);
	moveWindow("Edges", 2*(inputImg.cols + 55),1);
	

	// set the callback on mouse
	setMouseCallback("Scribble Image", onMouse, 0);

	
	myGraph = new GraphType(/*estimated # of nodes*/ inputImg.rows * inputImg.cols + numUsedBins, 
		/*estimated # of edges=11 spatial neighbors and one link to auxiliary*/ 12 * inputImg.rows * inputImg.cols); 

	GraphType::node_id currNodeId = myGraph -> add_node((int)inputImg.cols * inputImg.rows + numUsedBins); 
			
	
	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		//#pragma omp parallel for
		for(int j=0; j<inputImg.cols; j++) 
		{
			// this is the node id for the current pixel
			GraphType::node_id currNodeId = i * inputImg.cols + j;

			// add hard constraints based on scribbles
			if (fgScribbleMask.at<uchar>(i,j) == 255)
				myGraph->add_tweights(currNodeId,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5),0);
			else if (bgScribbleMask.at<uchar>(i,j) == 255)
				myGraph->add_tweights(currNodeId,0,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5));
				
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];

			// go over the neighbors
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0 ; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols; sj++)
				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) || 
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					// this is the node id for the neighbor
					GraphType::node_id nNodeId = (i+si) * inputImg.cols + (j + sj);
					
					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					//   ||I_p - I_q||^2  /   2 * sigma^2
					float currEdgeStrength = exp(-((b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr))/(2*varianceSquared));
					float currDist = sqrt((float)si*(float)si + (float)sj*(float)sj);

					// this is the edge between the current two pixels (i,j) and (i+si, j+sj)
					currEdgeStrength = ((float)0.95 * currEdgeStrength + (float)0.05) /currDist;
					myGraph -> add_edge(currNodeId, nNodeId,    /* capacities */ (int) ceil(INT32_CONST*currEdgeStrength + 0.5), (int)ceil(INT32_CONST*currEdgeStrength + 0.5));
					
				}
			}
			// add the adge to the auxiliary node
			int currBin =  (int)binPerPixelImg.at<float>(i,j);

			myGraph -> add_edge(currNodeId, (GraphType::node_id)(currBin + inputImg.rows * inputImg.cols),
				/* capacities */ (int) ceil(INT32_CONST*bha_slope+ 0.5), (int)ceil(INT32_CONST*bha_slope + 0.5));
		}

	}
	
	return 0;
}

// get bin index for each image pixel, store it in binPerPixelImg
void getBinPerPixel(Mat & binPerPixelImg, Mat & inputImg, int numBinsPerChannel, int & numUsedBins)
{
	// this vector is used to through away bins that were not used 计算x的y次幂。初值64*64*64空间中初值都是-1
	vector<int> occupiedBinNewIdx((int)pow((double)numBinsPerChannel,(double)3),-1);
	

	// go over the image
	int newBinIdx = 0;

	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
		for(int j=0; j<inputImg.cols; j++) 
		{
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];

			// this is the bin assuming all bins are present
			int bin = (int)(floor(b/256.0 *(float)numBinsPerChannel) + (float)numBinsPerChannel * floor(g/256.0*(float)numBinsPerChannel) 
				+ (float)numBinsPerChannel * (float)numBinsPerChannel * floor(r/256.0*(float)numBinsPerChannel)); 

			
			// if we haven't seen this bin yet
			if (occupiedBinNewIdx[bin]==-1)
			{
				// mark it seen and assign it a new index
				occupiedBinNewIdx[bin] = newBinIdx;
				newBinIdx ++;
			}
			// if we saw this bin already, it has the new index
			binPerPixelImg.at<float>(i,j) = (float)occupiedBinNewIdx[bin];
			
        //cout << bin << endl;
		}

		double maxBin;
		minMaxLoc(binPerPixelImg,NULL,&maxBin);//图像中的最大值
		numUsedBins = (int) maxBin + 1;
		imshow("Bin Per Pixel", binPerPixelImg/maxBin);

		occupiedBinNewIdx.clear();
		cout << "Num occupied bins:" << numUsedBins<< endl;

} 

// compute the variance(变化，方差) of image edges between neighbors
void getEdgeVariance(Mat & inputImg, Mat & showEdgesImg, float & varianceSquared)
{


	varianceSquared = 0;
	int counter = 0;

	#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		for(int j=0; j<inputImg.cols; j++) 
		{
			
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0 ; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols ; sj++)

				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) || 
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					varianceSquared+= (b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr); 
					counter ++;
					
				}
				
			}
		}
	}
	varianceSquared/=counter;

	// just for visualization
	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		for(int j=0; j<inputImg.cols; j++) 
		{
			

			float edgeStrength = 0;
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols   ; sj++)
				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) ||
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					//   ||I_p - I_q||^2  /   2 * sigma^2
					float currEdgeStrength = exp(-((b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr))/(2*varianceSquared));
					float currDist = sqrt((float)si*(float)si + (float)sj * (float)sj);

					
					// this is the edge between the current two pixels (i,j) and (i+si, j+sj)
					edgeStrength = edgeStrength + ((float)0.95 * currEdgeStrength + (float)0.05) /currDist;
					
				}
			}
			// this is the avg edge strength for pixel (i,j) with its neighbors
			showEdgesImg.at<float>(i,j) = edgeStrength;

		}
	}
	
	double maxEdge;
	Point maxPoint;
	minMaxLoc(showEdgesImg,NULL,&maxEdge, NULL, &maxPoint);
	//cout << showEdgesImg.at<float>(maxPoint) << endl;
	imshow("Edges", showEdgesImg/maxEdge);

}




/*
*******************************
Mat myMat(size(3, 3), CV_32FC2);

myMat.ptr<float>(y)[2*x]; // first channel
myMat.ptr<float>(y)[2*x+1]; // second channel
*/





测量时间的类：

#pragma once
/*
//计算代码段运行时间的类
//
*/
#include <iostream>

#ifndef ComputeTime_h
#define ComputeTime_h


class   ComputeTime    
{  
private:  
	int Initialized;  
	__int64 Frequency;  
	__int64 BeginTime;  
		    
public:  

	bool Avaliable();  
	double End();  
	bool Begin();  
	ComputeTime();  
	virtual   ~ComputeTime();    

};  






#endif


#include "ComputeTime.h"
#include <iostream>
#include <Windows.h>

ComputeTime::ComputeTime()  
{  
	Initialized=QueryPerformanceFrequency((LARGE_INTEGER   *)&Frequency);  
}  
   
 ComputeTime::~ComputeTime()  
{  
		    
}  
   
 bool   ComputeTime::Begin()  
{  
	if(!Initialized)  
		return 0;

	 return   QueryPerformanceCounter((LARGE_INTEGER   *)&BeginTime);  
 }
     
 double   ComputeTime::End()
{  
	 if(!Initialized)  
		return 0;

		   
	 __int64   endtime;  
		   
	 QueryPerformanceCounter((LARGE_INTEGER   *)&endtime);  
		    
		  
	 __int64   elapsed = endtime-BeginTime;  
		    
		  
	 return   ((double)elapsed/(double)Frequency)*1000.0;  //单位毫秒
 }  

 bool   ComputeTime::Avaliable()
{  
	 return Initialized;  
}   








项目主页：
http://vision.csd.uwo.ca/code/
 
Code：http://vision.csd.uwo.ca/wiki/vision/upload/7/77/OneCutWithSeeds_v1.03.zip
Paper：http://www.csd.uwo.ca/~ygorelic/iccv13_one_cut.pdf
 
OpenCV代码实现grabcut：：
http://www.morethantechnical.com/2010/05/05/bust-out-your-own-graphcut-based-image-segmentation-with-opencv-w-code/

我调试好的工程代码下载链接：点击打开链接






Graph Cut and Its Application in Computer Vision
 
原文出处：
http://lincccc.blogspot.tw/2011/04/graph-cut-and-its-application-in.html
现在好像需要代理才能访问了。。。
 
 

网络流算法最初用于解决流网络的优化问题，比如水管网络、通信传输和城市的车流等。Graph cut作为其中一类最常见的算法，用于求解流网络的最小割，即寻找一个总容量最小的边集合，去掉这个集合中的所有边将阻断这个网络。图像和视频也能被视作网络（或者MRF），以像素作为节点，具体应用定义相邻像素间边的能量值（容量）。因此从九十年代末开始，Graph
 cut渐渐被引入计算机视觉、图像处理和机器学习领域，用于优化分类、分割和合成等问题。
The Max-Flow and Min-Cost Problem： 定义图（或者流网络）G = (V, E)，可以为有向图或无向图。图中所有的边 e(u,
 v) ∈ E 附有一个非负的容量 c(u, v) ≥ 0，即该边所能承受的最大流量。图中通常定义两个特殊的节点，源点 s 和终点 t；存在拥有多个端点的图，对其的Max-flow求解为NP问题，需要转化为双端点问题求解次优解。定义满足以下条件的 f
 : VXV → R 为图 G 上的流：   ●  Capacity Constrain，对于所有 u, v ∈ V，f(u,
 v) ≤ c(u, v)   ●  Skew Symmetry，对于所有 u, v ∈ V，f(u,
 v) = ﹣f(u, v)   ●  Flow Conservation，对于所有 u ∈ V﹣{s, t} 和 v
 ∈ V，∑ f(u, v) = 0从 s 出发的所有流量的总和就是整个图的总流量。如下图所示，图的当前总流量为19，没有达到最大值。 Cut（割）将整个图的所有节点分为两个不相交的集合 S 和 T，比如s
 ∈ S，t ∈ T。割的容量定义为：     c(S, T) = ∑x∈S ∑y∈T c(x, y)。Min-cut（最小割）就是图的所有割中容量最小的一个。算法上要直接找Min-cut是十分困难的，根据最大流最小割定理，即图的最大流量等于图的最小割容量，通常要将问题转化为与之等价的Max-flow问题（理论推导点我）。
Max-Flow and Min-Cost Algorithms：Max-flow问题的求解有两类经典的算法，增广路径[1] 和Push-relabel [2]。增广路径类算法遵循循序渐进的原则，不断在图上查找从 s 到 t 的可用路径，从0开始慢慢地提升图的总流量至最大；而Push-relabel类算法则从局部出发，总是尽可能地向图中输送更多的流量，在不断重复的Push和Relabel操作中达到节点间的平衡，是水流的一种拟态。Push-relabel类算法具有较高的并行性，适用于GPU加速，大体流程点我。增广路径类算法有很多衍生，但大多具有以下特性：1）维护残余容量网络；2）通过寻找Augmenting path逼近最大流。Augmenting path具有形式：s, e1, v1, e2, v2, … , ek, t，其中没有重复的节点、没有饱和的前向边和空流量的后向边。对残余网络的定义有很多形式，这里我们定义边的残余容量（Redsidual
 capacity，RC）当其为前向边时等于 c(i, j) – f(i, j)，当其为后向边时等于 f(i, j)，如下图所示。
 
Augmenting path的残余容量为其每条边残余容量的最小值，如上图路径的残余容量为1。Ford-Fulkerson算法不断在残余网络中查询Augmenting path，比如使用广度或深度优先搜索，直到再也找不到任何路径。例子点我。Boykov[3]
 提出一种双向搜索并重用搜索树的增广路径算法，虽然理论复杂度较高，但在实际应用中却效率较高，因此很多需要Graph cut的应用都采用Boykov提供的源代码。
Applications in Computer Vision：计算机视觉中很多问题，都可以归结为量化方程的优化问题。比如图像分割的问题，定义每一个像素属于前景或背景的可能性度量，那整个问题就变成了如何让整个可能性量化方程取值最大的问题。当然有时，我们还需要定义平滑项，用于约束相邻像素的属性变化。这就形成了在视觉中最为常见的一类能量优化方程：      E(f) = Esmooth(f) + Edata(f)
1维图还可用动态规划方法求解，但2维以上由于其几何级的复杂度增长，则大多使用Graph cut。典型的应用有Segmentation、Stereo matching、Image Restoration、Motion estimation等。根据不同的应用有不同的图构、相邻约束和能量函数。Kolmogorov[4] 研究了什么样的能量方程能用Graph cut优化，并提出了三元及以下能量函数自动转换成图的方法。
Multi-label Graph Cut：根据应用的需要，有时定义的图构是多个label的，也就是有多个灭点，如下图所示。这种图的Min-cut是Multi-way的，求解过程是一个NP问题（Boykov[3]在他的论文中有详细证明）。比如Stereo matching中的disparity、Image Restoration中的intensity等，其本质都是一个Multi-label的优化问题。虽然有些方法可以将其人为地转变为2-label，但这在很大程度上限制了能量函数的定义。

 


 

Boykov[3]提出了两种算法，能够在多项式时间内逼近Muli-label问题的最优解，并给出了详细证明和两种算法的optimality property讨论。这是一篇值得细读的文章。这两种方法都是在寻找Local minima，最终使得图中的任意一个像素改变其label都不能产生更好的解。在每一次迭代中，两种方法分别进行 α-expansion 和 α-β-swap 形式的move
 优化。α-expansion move 是指扩展 α-label 区域，使原本其他 label 的点属于 α；α-β-swap move 则只针对 α-label 和 β-label 区域，使其中的一些点的label从 α 变为 β 或相反。每一部迭代都是一次2-label的优化过程，形成以 α 和 非α 为灭点、以及以 α 和 β 为灭点的图，寻找最优cut，重整label，不断逼近最优解。α-expansion 要求平滑项满足三边定理，而 α-β-swap 可用于任意平滑项定义；但 α-expansion 有严格的optimality
 property bound，总不会产生太坏的结果，因此被较多地使用。



Dynamic Graph Cut：动态图指一个图序列，在时序上前后图直接会保持平滑的过渡，因此，是否可以在前一张图的residual graph基础上修改变化了的像素点的能量以快速地求解？Dynamic graph cut并不寻求最优解，而是次优的快速的解。Kohli[12] 使用重新参数化图（Graph Reparameterization）的方法修改动态变化的数值，并保持Capacity、Flow等基本约束，而后直接得到次优解。这种方法可以容忍少量边的修改和少量任意节点拓扑的重构，但是和其他所有Dynamic
 graph cut算法一样，以少量、也就是轻微的时序变化为前提。主要应用于视频相关的视觉方法，如Video segmentation。
 
 
 
