





作者：黄永刚
前段时间有幸读到了@老师木的文章1,里面在探讨一个问题，为什么在神经网络的节点上面使用的是sigmoid函数？其中谈到一个点：

当知道X的概率密度为f(x)时，什么样的函数h能把x变换成均匀分布的信号？也可以是这样的一道面试题：如何用C的库函数rand()生成服从高斯分布或者β分布，or其他分布的随机数？


上面第一个问题，是将其他分布转换成均匀分布的问题，第二个问题刚好相反。当然有了这个抽象之后，答案很容易上网就能够查到，具体如下[^tjjs]：

用大白话说：  变量x服从概率密度是f(x)的分布，概率分布函数是F(x)[^gainian],

根据上面的定理1.1-1，如果x服从任意分布，作为自己的累积分布F(x)的输入，则变换后值的分布必将服从U(0,1)即0,1之间的均匀分布。相反如定理1.1-2，假设目标分布的密度函数f(x),求取概率分布F(x)，之后求逆F(x)^-1，然后将R[R~U(0,1),即R服从0,1之间的均匀分布]作为逆函数的输入，变换后值的累积分布将是F(x)函数。
为什么要说这枯燥的数学知识？我们都有一个共识，生活处处存在着概率分布，尤其以钟形曲线的分布为要，其他的分布当然也很多。要想把握事物的内在规律，必须掌握事物的概率分布，之后根据需要对分布进行转化。在老师木的探讨的文章中，需要通过转换放大非长尾数据的作用，进而尽可能使得源信息在数学模型中得到保留。

而且那个文章中也提到一个重要的点，信息熵在均匀分布的时候最大，就对于这种问题，我在找工作的过程中碰到多次，给几组数让选择信息熵最大的那组，很容易知道，越靠近均匀分布熵的值越大。更进一步考虑，如果用熵来描述一个系统的混乱程度，那么当系统的混乱越均匀则熵值越大，类比战国七雄时候最为混乱，毕竟各家的实力相当。在蒙古时期，只有忽必烈部落一家独大，其他部落就是跟着大哥混的，这个时候的混乱程度就低很多，此时熵值就小。
那么这个混乱程度，用在现代生活中，如代码混淆，信息的加密，密码加密等，这些都是想办法怎么来加大其中的混乱程度，进而来增加系统中的信息熵。我们从前文已经知道越靠近均匀分布熵的值越大，因此这些领域我们可以看做是一个概率分布转换的过程。究竟如何在具体的领域中衡量一个系统信息的概率分布并如何构造转换函数，这些领域中大量的牛人肯定能解决这个问题。
上次在知乎看到一个题目，关于密码破译，不知是不是欧阳大神的回答，貌似很像。提到通过截获大量的密文，统计其中字符出现的概率分布，然后对照现实中各个字符出现的概率就能够找到加密字符和真实字符的对应关系。这种情况就属于信息熵较小的情况，很容易被破解，所以现在的加密很难通过统计进行解密。这个过程其实也可视作概率分布的转化。
上面的例子大多是加大系统的熵，然而我们生活中还有很多人的工作是来减小熵，消除不确定性。现在的人工智能的东西，为什么说刚开始的时候是“人工智障”，大家经常听人说是由于缺少数据积累，等到数据积累多了就慢慢的聪明起来了。其中的原理是，在应用刚推出的时候，每种行为策略对于智能应用来说是等可能性的，随着数据的积累，各种策略的分布发生变化，渐渐的形成了优势策略，所以看起来变得智能起来。人们常说推荐系统存在“冷启动”问题，就是由于新来的用户没有数据积累，对于推荐系统来说，不同类别得商品都是等可能的；随着用户的数据积累，逐渐形成了清晰的用户画像，然后根据用户画像进行个性化的推荐，这个时候大家就会感觉到推荐还是挺靠谱得。

还记得上学的时候，大多老师检查家庭作业喜欢每天只检查一组学生，有的老师选择每组按天轮流检查，这样没有轮流到组的学生就不做作业；有的老师是随机选择抽查一组，这样大家怕被抽到时没有完成而受罚，大多同学就会完成作业。对于第一种老师的选择来说，检查作业的分布的不确定性非常的小，结果很多学生没有做作业，所以老师的目的并没有达到，而第二种老师的选择不确定性就很大，所以获得了较好的效果。这其实也是老师和学生博弈的一个过程。聪明老师的选择，在博弈论里面被称作“纳什均衡”，不错就是《美丽心灵》的那个Nash。大家肯定知道经济学同学考研也是要考《概率论》地，所以我们今天所说概率分布的转化不仅仅局限于工程领域。
当然要很好的发现和应用这些知识还需要很多知识的积累，前路漫漫……
推荐大家有空闲的时候好好看看@老师木的文章，【参考文献1】！
愿与诸君共勉！
reference:  1. 为什么我们喜欢用sigmoid这类S型非线性变换?  2. 所有的概率分布都可以转化成正态分布吗？  3. zhihu:在连续随机变量中，概率密度函数（PDF）、概率分布函数、累积分布函数（CDF）之间的关系是什么？

本文原创首发于公众号：老王和他的IT界朋友们
微信扫描关注微信号：（原创投稿有惊喜！！！）



请参阅 参考1  [^tjjs]: 高惠璇教授《统计计算》  [^gainian]:概念不熟悉的可以参阅 参考3 ↩





